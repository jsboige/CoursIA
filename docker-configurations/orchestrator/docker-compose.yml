version: '3.8'

services:
  orchestrator:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: coursia-genai-orchestrator
    hostname: orchestrator
    
    ports:
      - "${ORCHESTRATOR_PORT:-8090}:8090"
    
    volumes:
      - type: bind
        source: ./config
        target: /app/config
        read_only: true
      - type: bind
        source: ../../shared/models
        target: /shared/models
      - type: bind
        source: ../../shared/cache
        target: /shared/cache
      - type: bind
        source: ../../shared/outputs
        target: /shared/outputs
      - type: bind
        source: ../../logs
        target: /app/logs
      - type: bind
        source: ../../.secrets
        target: /app/secrets
        read_only: true
    
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - TZ=${TZ:-Europe/Paris}
      - ORCHESTRATOR_PORT=8090
      - ORCHESTRATOR_HOST=0.0.0.0
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - HEALTH_CHECK_INTERVAL=${HEALTH_CHECK_INTERVAL:-30}
      - SERVICE_TIMEOUT=${SERVICE_TIMEOUT:-60}
      - MAX_RESTART_ATTEMPTS=${MAX_RESTART_ATTEMPTS:-3}
      - GPU_ENABLED=${GPU_ENABLED:-true}
      - DOCKER_HOST=${DOCKER_HOST:-unix:///var/run/docker.sock}
    
    working_dir: /app
    
    command: >
      bash -c "
        echo 'Initialisation de lorchestrateur GenAI...';
        python3 orchestrator.py;
      "
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/health", "--max-time", "10"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    
    restart: unless-stopped
    
    networks:
      - orchestrator-network
    
    labels:
      - "com.myia.service=genai-orchestrator"
      - "com.myia.phase=production"
      - "com.myia.type=orchestration"
      - "com.myia.managed=true"

  # Service FLUX.1-dev
  flux-1-dev:
    image: python:3.11
    container_name: coursia-flux-1-dev
    hostname: flux-1-dev
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${FLUX_GPU_DEVICE_ID:-0}']
              capabilities: [gpu]
    
    ports:
      - "${FLUX_PORT:-8189}:8188"
    
    volumes:
      - type: bind
        source: ./scripts/flux_service.py
        target: /app/flux_service.py
        read_only: true
      - type: bind
        source: ../../shared/models
        target: /workspace/models
      - type: bind
        source: ../../shared/cache
        target: /workspace/cache
      - type: bind
        source: ../../shared/outputs
        target: /workspace/outputs
      - type: bind
        source: ../../.secrets
        target: /workspace/.secrets
        read_only: true
    
    environment:
      - CUDA_VISIBLE_DEVICES=${FLUX_CUDA_VISIBLE_DEVICES:-0}
      - NVIDIA_VISIBLE_DEVICES=${FLUX_NVIDIA_VISIBLE_DEVICES:-0}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - TZ=${TZ:-Europe/Paris}
      - SERVICE_NAME=flux-1-dev
      - SERVICE_PORT=8188
      - HF_TOKEN=${HF_TOKEN}
      - CIVITAI_TOKEN=${CIVITAI_TOKEN}
    
    working_dir: /workspace
    
    command: >
      bash -c "
        echo 'Démarrage du service FLUX.1-dev...';
        python3 /app/flux_service.py;
      "
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8188/system_stats", "--max-time", "10"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    
    restart: unless-stopped
    
    networks:
      - orchestrator-network
    
    labels:
      - "com.myia.service=flux-1-dev"
      - "com.myia.type=image-generation"
      - "com.myia.model=FLUX.1-dev"
      - "com.myia.managed=true"

  # Service Stable Diffusion 3.5
  stable-diffusion-35:
    image: python:3.11
    container_name: coursia-sd35
    hostname: stable-diffusion-35
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${SD35_GPU_DEVICE_ID:-0}']
              capabilities: [gpu]
    
    ports:
      - "${SD35_PORT:-8190}:8000"
    
    volumes:
      - type: bind
        source: ./scripts/sd35_service.py
        target: /app/sd35_service.py
        read_only: true
      - type: bind
        source: ../../shared/models
        target: /workspace/models
      - type: bind
        source: ../../shared/cache
        target: /workspace/cache
      - type: bind
        source: ../../shared/outputs
        target: /workspace/outputs
      - type: bind
        source: ../../.secrets
        target: /workspace/.secrets
        read_only: true
    
    environment:
      - CUDA_VISIBLE_DEVICES=${SD35_CUDA_VISIBLE_DEVICES:-0}
      - NVIDIA_VISIBLE_DEVICES=${SD35_NVIDIA_VISIBLE_DEVICES:-0}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - TZ=${TZ:-Europe/Paris}
      - SERVICE_NAME=stable-diffusion-35
      - SERVICE_PORT=8000
      - HF_TOKEN=${HF_TOKEN}
      - CIVITAI_TOKEN=${CIVITAI_TOKEN}
    
    working_dir: /workspace
    
    command: >
      bash -c "
        echo 'Démarrage du service Stable Diffusion 3.5...';
        python3 /app/sd35_service.py;
      "
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health", "--max-time", "10"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    
    restart: unless-stopped
    
    networks:
      - orchestrator-network
    
    labels:
      - "com.myia.service=stable-diffusion-35"
      - "com.myia.type=image-generation"
      - "com.myia.model=SD3.5-Large"
      - "com.myia.managed=true"

  # Service ComfyUI Workflows
  comfyui-workflows:
    image: python:3.11
    container_name: coursia-comfyui-workflows
    hostname: comfyui-workflows
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${COMFYUI_WORKFLOWS_GPU_DEVICE_ID:-0}']
              capabilities: [gpu]
    
    ports:
      - "${COMFYUI_WORKFLOWS_PORT:-8191}:8188"
    
    volumes:
      - type: bind
        source: ./scripts/comfyui_workflows_service.py
        target: /app/comfyui_workflows_service.py
        read_only: true
      - type: bind
        source: ../../shared/models
        target: /workspace/ComfyUI/models
      - type: bind
        source: ../../shared/cache
        target: /workspace/cache
      - type: bind
        source: ../../shared/outputs
        target: /workspace/ComfyUI/output
      - type: bind
        source: ../../.secrets
        target: /workspace/ComfyUI/.secrets
        read_only: true
    
    environment:
      - CUDA_VISIBLE_DEVICES=${COMFYUI_WORKFLOWS_CUDA_VISIBLE_DEVICES:-0}
      - NVIDIA_VISIBLE_DEVICES=${COMFYUI_WORKFLOWS_NVIDIA_VISIBLE_DEVICES:-0}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - TZ=${TZ:-Europe/Paris}
      - SERVICE_NAME=comfyui-workflows
      - SERVICE_PORT=8188
      - COMFYUI_PORT=8188
      - COMFYUI_LISTEN=0.0.0.0
      - HF_TOKEN=${HF_TOKEN}
      - CIVITAI_TOKEN=${CIVITAI_TOKEN}
    
    working_dir: /workspace/ComfyUI
    
    command: >
      bash -c "
        echo 'Démarrage du service ComfyUI Workflows...';
        python3 /app/comfyui_workflows_service.py;
      "
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8188/system_stats", "--max-time", "10"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    
    restart: unless-stopped
    
    networks:
      - orchestrator-network
    
    labels:
      - "com.myia.service=comfyui-workflows"
      - "com.myia.type=workflow-engine"
      - "com.myia.model=ComfyUI"
      - "com.myia.managed=true"

networks:
  orchestrator-network:
    driver: bridge
    name: orchestrator-network
    ipam:
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1