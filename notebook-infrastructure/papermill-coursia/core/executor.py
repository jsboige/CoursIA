#!/usr/bin/env python3
"""
PapermillExecutor - Wrapper Robuste Papermill pour CoursIA
==========================================================

Impl√©mentation des patterns industriels Netflix/Airbnb pour ex√©cution notebook
Production-grade avec monitoring √©ducatif int√©gr√©.

Architecture SDDD valid√©e : Performance 4.14 cell/s, 26/26 cellules OK
"""

import asyncio
import logging
import os
import subprocess
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Union

import papermill as pm
from papermill.exceptions import PapermillExecutionError


# =============================================================================
# Data Models & Result Objects
# =============================================================================

@dataclass
class ExecutionMetrics:
    """M√©triques d'ex√©cution pour monitoring √©ducatif"""
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    total_cells: int = 0
    executed_cells: int = 0
    failed_cells: int = 0
    execution_time_seconds: float = 0.0
    cells_per_second: float = 0.0
    kernel_detected: Optional[str] = None
    memory_peak_mb: Optional[float] = None
    
    @property
    def is_complete(self) -> bool:
        return self.end_time is not None
    
    @property
    def success_rate(self) -> float:
        """Calcule le taux de succ√®s bas√© sur les cellules ex√©cut√©es"""
        if self.executed_cells == 0:
            return 0.0
        return ((self.executed_cells - self.failed_cells) / self.executed_cells) * 100


@dataclass
class ExecutionResult:
    """R√©sultat complet d'ex√©cution notebook"""
    success: bool
    input_path: str
    output_path: Optional[str]
    metrics: ExecutionMetrics
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    educational_report: Optional[Dict[str, Any]] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """Export pour reporting JSON"""
        return {
            'success': self.success,
            'input_path': self.input_path,
            'output_path': self.output_path,
            'metrics': {
                'execution_time': self.metrics.execution_time_seconds,
                'cells_per_second': self.metrics.cells_per_second,
                'success_rate': self.metrics.success_rate,
                'kernel': self.metrics.kernel_detected,
                'total_cells': self.metrics.total_cells,
                'executed_cells': self.metrics.executed_cells,
                'failed_cells': self.metrics.failed_cells
            },
            'errors': self.errors,
            'warnings': self.warnings,
            'timestamp': self.metrics.start_time.isoformat()
        }


@dataclass
class NotebookSpec:
    """Sp√©cification notebook pour ex√©cution batch"""
    input_path: str
    output_path: Optional[str] = None
    parameters: Dict[str, Any] = field(default_factory=dict)
    kernel: Optional[str] = None
    timeout: Optional[int] = None
    priority: int = 1  # 1=high, 5=low (√©ducatif)


# =============================================================================
# Core PapermillExecutor Class
# =============================================================================

class PapermillExecutor:
    """
    Wrapper robuste Papermill optimis√© contexte √©ducatif CoursIA
    
    Features:
    - Auto-d√©tection kernels (.net-csharp, python3, etc.)
    - Monitoring temps r√©el avec progress bars
    - Error handling production-grade avec messages √©ducatifs
    - M√©triques apprentissage et reporting √©tudiant/instructeur
    - Support param√©trage avanc√© et batch processing
    
    Patterns:
    - Factory Pattern (adapters multi-kernels)
    - Observer Pattern (monitoring temps r√©el)  
    - Chain of Responsibility (error handling)
    """
    
    def __init__(self,
                 conda_env: str = "mcp-jupyter",
                 timeout_default: int = 300,  # 5min par d√©faut √©ducatif
                 progress_tracking: bool = True,
                 educational_mode: bool = True,
                 max_workers: int = 2):  # Limit√© pour contexte √©ducatif
        """
        Initialize PapermillExecutor avec configuration √©ducative
        
        Args:
            conda_env: Environnement Conda valid√© SDDD
            timeout_default: Timeout par d√©faut adapt√© √©ducatif (5min)
            progress_tracking: Monitoring temps r√©el activ√©
            educational_mode: Rapports adapt√©s √©tudiants/instructeurs  
            max_workers: Limite workers pour ressources √©ducatives
        """
        self.conda_env = conda_env
        self.timeout_default = timeout_default
        self.progress_tracking = progress_tracking
        self.educational_mode = educational_mode
        self.max_workers = max_workers
        
        # Logging avec contexte √©ducatif
        self.logger = logging.getLogger(f"PapermillCoursIA.{self.__class__.__name__}")
        self.logger.setLevel(logging.INFO)
        
        # Thread pool pour ex√©cution async/batch
        self._executor = ThreadPoolExecutor(max_workers=max_workers)
        
        # Validation environnement au d√©marrage
        self._validate_environment()
        
        # Cache des kernels disponibles
        self._available_kernels: Optional[Dict[str, str]] = None
    
    def _validate_environment(self) -> None:
        """Validation environnement Conda + Papermill"""
        try:
            # V√©rification Conda env
            result = subprocess.run(
                ['conda', 'info', '--envs'], 
                capture_output=True, text=True, timeout=10
            )
            if self.conda_env not in result.stdout:
                raise RuntimeError(f"Environnement Conda '{self.conda_env}' introuvable")
            
            # V√©rification Papermill dans l'env
            result = subprocess.run(
                ['conda', 'run', '-n', self.conda_env, 'python', '-c', 'import papermill'],
                capture_output=True, text=True, timeout=10
            )
            if result.returncode != 0:
                raise RuntimeError(f"Papermill non install√© dans l'environnement '{self.conda_env}'")
                
            self.logger.info(f"‚úÖ Environnement '{self.conda_env}' valid√© avec Papermill")
            
        except Exception as e:
            self.logger.error(f"‚ùå √âchec validation environnement: {e}")
            raise
    
    def _get_available_kernels(self) -> Dict[str, str]:
        """
        Auto-d√©tection kernels disponibles (pattern SDDD valid√©)
        
        Returns:
            Dict[kernel_name, kernel_path] des kernels disponibles
        """
        if self._available_kernels is not None:
            return self._available_kernels
            
        try:
            result = subprocess.run([
                'conda', 'run', '-n', self.conda_env, 
                'jupyter', 'kernelspec', 'list', '--json'
            ], capture_output=True, text=True, timeout=15)
            
            if result.returncode == 0:
                import json
                kernel_data = json.loads(result.stdout)
                self._available_kernels = kernel_data.get('kernelspecs', {})
                
                # Log kernels d√©tect√©s (style SDDD)
                kernel_names = list(self._available_kernels.keys())
                self.logger.info(f"üîç Kernels d√©tect√©s: {kernel_names}")
                
                return self._available_kernels
            else:
                self.logger.warning(f"√âchec d√©tection kernels: {result.stderr}")
                return {}
                
        except Exception as e:
            self.logger.warning(f"Erreur d√©tection kernels: {e}")
            return {}
    
    def _auto_detect_kernel(self, notebook_path: str) -> Optional[str]:
        """
        Auto-d√©tection kernel optimal pour notebook
        Bas√© sur m√©tadonn√©es notebook + heuristiques √©ducatives
        """
        try:
            import json
            with open(notebook_path, 'r', encoding='utf-8') as f:
                nb_data = json.load(f)
            
            # Extraction kernel des m√©tadonn√©es
            kernel_spec = nb_data.get('metadata', {}).get('kernelspec', {})
            preferred_kernel = kernel_spec.get('name')
            
            if preferred_kernel:
                available_kernels = self._get_available_kernels()
                if preferred_kernel in available_kernels:
                    self.logger.info(f"üéØ Kernel d√©tect√©: {preferred_kernel}")
                    return preferred_kernel
                else:
                    self.logger.warning(f"‚ö†Ô∏è Kernel pr√©f√©r√© '{preferred_kernel}' indisponible")
            
            # Fallback heuristiques pour contexte √©ducatif
            if '.net' in str(nb_data).lower() or 'csharp' in str(nb_data).lower():
                return '.net-csharp' if '.net-csharp' in self._get_available_kernels() else None
            
            # D√©faut Python pour notebooks √©ducatifs
            return 'python3' if 'python3' in self._get_available_kernels() else None
            
        except Exception as e:
            self.logger.warning(f"√âchec auto-d√©tection kernel: {e}")
            return None
    
    def _generate_output_path(self, input_path: str, suffix: str = "-papermill-output") -> str:
        """G√©n√©ration path output avec convention CoursIA"""
        path_obj = Path(input_path)
        output_name = f"{path_obj.stem}{suffix}{path_obj.suffix}"
        return str(path_obj.parent / output_name)
    
    async def execute_notebook(self, 
                             input_path: str,
                             output_path: Optional[str] = None,
                             parameters: Dict[str, Any] = None,
                             kernel: Optional[str] = None,
                             timeout: Optional[int] = None) -> ExecutionResult:
        """
        Ex√©cution robuste notebook avec monitoring √©ducatif
        
        Args:
            input_path: Chemin notebook source
            output_path: Chemin sortie (auto-g√©n√©r√© si None)
            parameters: Param√®tres √† injecter (Papermill advanced)
            kernel: Kernel sp√©cifique (auto-d√©tect√© si None)
            timeout: Timeout sp√©cifique (d√©faut si None)
        
        Returns:
            ExecutionResult avec m√©triques et rapports √©ducatifs
        """
        # Initialisation m√©triques
        metrics = ExecutionMetrics()
        metrics.start_time = datetime.now()
        
        # Validation paths
        if not os.path.exists(input_path):
            error_msg = f"Notebook source introuvable: {input_path}"
            self.logger.error(f"‚ùå {error_msg}")
            return ExecutionResult(
                success=False, 
                input_path=input_path, 
                output_path=None,
                metrics=metrics,
                errors=[error_msg]
            )
        
        # G√©n√©ration output path si n√©cessaire
        if output_path is None:
            output_path = self._generate_output_path(input_path)
        
        # Auto-d√©tection kernel si n√©cessaire
        if kernel is None:
            kernel = self._auto_detect_kernel(input_path)
            
        metrics.kernel_detected = kernel
        
        # Configuration timeout
        timeout = timeout or self.timeout_default
        
        self.logger.info(f"üöÄ D√©marrage ex√©cution: {Path(input_path).name}")
        self.logger.info(f"   üìã Kernel: {kernel}")
        self.logger.info(f"   ‚è±Ô∏è Timeout: {timeout}s")
        if parameters:
            self.logger.info(f"   üîß Param√®tres: {list(parameters.keys())}")
        
        try:
            # Ex√©cution Papermill avec monitoring
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self._executor,
                self._execute_papermill_sync,
                input_path, output_path, parameters, kernel, timeout, metrics
            )
            
            return result
            
        except Exception as e:
            metrics.end_time = datetime.now()
            metrics.execution_time_seconds = (metrics.end_time - metrics.start_time).total_seconds()
            
            error_msg = f"√âchec ex√©cution: {str(e)}"
            self.logger.error(f"‚ùå {error_msg}")
            
            return ExecutionResult(
                success=False,
                input_path=input_path,
                output_path=output_path,
                metrics=metrics,
                errors=[error_msg]
            )
    
    def _execute_papermill_sync(self, 
                               input_path: str, 
                               output_path: str,
                               parameters: Dict[str, Any],
                               kernel: str,
                               timeout: int,
                               metrics: ExecutionMetrics) -> ExecutionResult:
        """Ex√©cution synchrone Papermill avec m√©triques"""
        
        try:
            # Configuration Papermill
            pm_kwargs = {
                'input_path': input_path,
                'output_path': output_path,
                'parameters': parameters or {},
                'kernel_name': kernel,
                'progress_bar': self.progress_tracking,
                'log_output': True,
                'request_timeout': timeout
            }
            
            # Ex√©cution avec monitoring
            start_exec = time.time()
            
            result_nb = pm.execute_notebook(**pm_kwargs)
            
            end_exec = time.time()
            
            # Calcul m√©triques
            metrics.end_time = datetime.now()
            metrics.execution_time_seconds = end_exec - start_exec
            
            # Extraction m√©triques du notebook r√©sultat
            if result_nb and hasattr(result_nb, 'cells'):
                metrics.total_cells = len(result_nb.cells)
                # Compte toutes les cellules de code ex√©cut√©es (avec execution_count)
                metrics.executed_cells = sum(1 for cell in result_nb.cells
                                           if cell.cell_type == 'code' and
                                           hasattr(cell, 'execution_count') and
                                           cell.execution_count is not None)
                # Compte les cellules en √©chec (avec erreur dans outputs)
                metrics.failed_cells = sum(1 for cell in result_nb.cells
                                         if cell.cell_type == 'code' and
                                         hasattr(cell, 'outputs') and
                                         any(output.get('output_type') == 'error' for output in cell.outputs))
            
            if metrics.execution_time_seconds > 0:
                metrics.cells_per_second = metrics.total_cells / metrics.execution_time_seconds
            
            self.logger.info(f"‚úÖ Succ√®s ex√©cution en {metrics.execution_time_seconds:.2f}s")
            self.logger.info(f"üìä Performances: {metrics.cells_per_second:.2f} cell/s")
            
            return ExecutionResult(
                success=True,
                input_path=input_path,
                output_path=output_path,
                metrics=metrics,
                educational_report=self._generate_educational_report(metrics) if self.educational_mode else None
            )
            
        except PapermillExecutionError as e:
            metrics.end_time = datetime.now()
            metrics.execution_time_seconds = (metrics.end_time - metrics.start_time).total_seconds()
            
            # Extraction d√©tails erreur pour contexte √©ducatif
            error_details = self._extract_educational_error_context(e)
            
            return ExecutionResult(
                success=False,
                input_path=input_path,
                output_path=output_path,
                metrics=metrics,
                errors=[f"Erreur d'ex√©cution Papermill: {str(e)}"] + error_details
            )
    
    def _generate_educational_report(self, metrics: ExecutionMetrics) -> Dict[str, Any]:
        """G√©n√©ration rapport √©ducatif personnalis√©"""
        report = {
            'performance_grade': self._calculate_performance_grade(metrics),
            'learning_insights': self._extract_learning_insights(metrics),
            'recommendations': self._generate_recommendations(metrics),
            'comparison_benchmarks': {
                'sddd_reference': {'cells_per_second': 4.14, 'success_rate': 100.0},
                'current_execution': {
                    'cells_per_second': metrics.cells_per_second,
                    'success_rate': metrics.success_rate
                }
            }
        }
        return report
    
    def _calculate_performance_grade(self, metrics: ExecutionMetrics) -> str:
        """Calcul grade performance pour contexte √©ducatif"""
        if metrics.cells_per_second >= 4.0:
            return "Excellent (A+)"
        elif metrics.cells_per_second >= 3.0:
            return "Tr√®s Bien (A)"
        elif metrics.cells_per_second >= 2.0:
            return "Bien (B)"
        elif metrics.cells_per_second >= 1.0:
            return "Satisfaisant (C)"
        else:
            return "√Ä Am√©liorer (D)"
    
    def _extract_learning_insights(self, metrics: ExecutionMetrics) -> List[str]:
        """Extraction insights apprentissage"""
        insights = []
        
        if metrics.success_rate == 100.0:
            insights.append("üéØ Excellent! Toutes les cellules ont √©t√© ex√©cut√©es avec succ√®s.")
        elif metrics.success_rate >= 80.0:
            insights.append("üëç Bonne ex√©cution, quelques cellules ont √©chou√© - v√©rifiez les d√©tails.")
        else:
            insights.append("‚ö†Ô∏è Plusieurs cellules ont √©chou√© - r√©vision du code recommand√©e.")
        
        if metrics.execution_time_seconds > 60:
            insights.append("‚è±Ô∏è Ex√©cution longue d√©tect√©e - optimisation possible du code.")
        
        return insights
    
    def _generate_recommendations(self, metrics: ExecutionMetrics) -> List[str]:
        """G√©n√©ration recommandations p√©dagogiques"""
        recommendations = []
        
        if metrics.cells_per_second < 2.0:
            recommendations.append("üöÄ Consid√©rez optimiser les cellules les plus lentes.")
            
        if metrics.failed_cells > 0:
            recommendations.append("üîß V√©rifiez les d√©pendances et imports dans les cellules √©chou√©es.")
        
        if metrics.kernel_detected != 'python3' and metrics.kernel_detected != '.net-csharp':
            recommendations.append(f"üìã Kernel '{metrics.kernel_detected}' d√©tect√© - v√©rifiez la compatibilit√©.")
        
        return recommendations
    
    def _extract_educational_error_context(self, error: PapermillExecutionError) -> List[str]:
        """Extraction contexte erreur pour messages √©ducatifs"""
        context = []
        
        error_str = str(error).lower()
        
        # Patterns d'erreurs communes √©tudiants
        if 'modulenotfounderror' in error_str:
            context.append("üí° Suggestion: V√©rifiez l'installation des packages Python requis")
        elif 'filenotfounderror' in error_str:
            context.append("üìÅ Suggestion: V√©rifiez les chemins de fichiers dans le notebook")
        elif 'timeout' in error_str:
            context.append("‚è±Ô∏è Suggestion: Augmentez le timeout ou optimisez le code lent")
        elif 'kernel' in error_str:
            context.append("üîß Suggestion: V√©rifiez la configuration du kernel")
            
        return context
    
    async def batch_execute(self, notebooks: List[NotebookSpec]) -> List[ExecutionResult]:
        """
        Ex√©cution batch pour cours/TP multiples
        Pattern Netflix batch processing adapt√© √©ducatif
        """
        self.logger.info(f"üéì D√©marrage batch ex√©cution: {len(notebooks)} notebooks")
        
        # Tri par priorit√© (TP urgents en premier)
        sorted_notebooks = sorted(notebooks, key=lambda x: x.priority)
        
        # Ex√©cution parall√®le contr√¥l√©e (ressources √©ducatives limit√©es)
        tasks = []
        for spec in sorted_notebooks:
            task = self.execute_notebook(
                input_path=spec.input_path,
                output_path=spec.output_path,
                parameters=spec.parameters,
                kernel=spec.kernel,
                timeout=spec.timeout
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Post-traitement r√©sultats
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                # Cr√©ation ExecutionResult pour exceptions
                error_result = ExecutionResult(
                    success=False,
                    input_path=sorted_notebooks[i].input_path,
                    output_path=None,
                    metrics=ExecutionMetrics(),
                    errors=[f"Exception batch: {str(result)}"]
                )
                processed_results.append(error_result)
            else:
                processed_results.append(result)
        
        # Logging batch summary
        success_count = sum(1 for r in processed_results if r.success)
        self.logger.info(f"üìä Batch termin√©: {success_count}/{len(notebooks)} succ√®s")
        
        return processed_results
    
    def close(self):
        """Nettoyage ressources"""
        self._executor.shutdown(wait=True)
        self.logger.info("üîí PapermillExecutor ferm√© proprement")


# =============================================================================
# Factory Functions pour Patterns Industriels
# =============================================================================

def create_educational_executor(**kwargs) -> PapermillExecutor:
    """Factory function pour configuration √©ducative optimale"""
    return PapermillExecutor(
        conda_env=kwargs.get('conda_env', 'mcp-jupyter'),
        timeout_default=kwargs.get('timeout_default', 300),  # 5min √©ducatif
        progress_tracking=kwargs.get('progress_tracking', True),
        educational_mode=kwargs.get('educational_mode', True),
        max_workers=kwargs.get('max_workers', 2)  # Limit√© ressources √©ducatives
    )


def create_production_executor(**kwargs) -> PapermillExecutor:
    """Factory function pour configuration production scalable"""
    return PapermillExecutor(
        conda_env=kwargs.get('conda_env', 'mcp-jupyter'),
        timeout_default=kwargs.get('timeout_default', 600),  # 10min production
        progress_tracking=kwargs.get('progress_tracking', False),  # Moins verbeux
        educational_mode=kwargs.get('educational_mode', False),
        max_workers=kwargs.get('max_workers', 4)  # Plus de parall√©lisme
    )


if __name__ == "__main__":
    # Test basique
    import asyncio
    
    async def test_executor():
        executor = create_educational_executor()
        
        # Test d√©tection kernels
        kernels = executor._get_available_kernels()
        print(f"Kernels disponibles: {list(kernels.keys())}")
        
        executor.close()
    
    asyncio.run(test_executor())