# Analyse API Qwen-Image-Edit - Phase 20

**Date**: 2025-10-20  
**Objectif**: Extraction endpoints, param√®tres et workflows pour notebook p√©dagogique  
**Sources**: GUIDE-APIS-ETUDIANTS.md + 12C_architectures-5-workflows-qwen.md

---

## üéØ Informations API Production

### Acc√®s Service

| Param√®tre | Valeur | Notes |
|-----------|--------|-------|
| **URL Production** | `https://qwen-image-edit.myia.io` | Service d√©ploy√© Phase 12 |
| **Port API** | 8188 | WebSocket ComfyUI standard |
| **Architecture** | ComfyUI + vLLM | Backend ComfyUI natif |
| **GPU** | RTX 3090 (24GB VRAM) | GPU 2 d√©di√© (GPU 1 = Turbo) |
| **Mod√®le** | Qwen-Image-Edit-2509-FP8 | 54GB quantifi√© FP8 |
| **Authentication** | None | Interne r√©seau CoursIA |

### Endpoints ComfyUI Critiques

**Documentation compl√®te**: [ComfyUI API Docs](https://github.com/comfyanonymous/ComfyUI/wiki/API)

| Endpoint | M√©thode | Usage | Essentiel Notebook |
|----------|---------|-------|-------------------|
| `/prompt` | POST | Soumettre workflow ‚Üí R√©cup√©rer `prompt_id` | ‚úÖ OUI |
| `/history/{prompt_id}` | GET | R√©cup√©rer r√©sultats g√©n√©ration | ‚úÖ OUI |
| `/upload/image` | POST | Upload image source (I2I) | ‚ö†Ô∏è I2I seulement |
| `/ws` | WebSocket | Streaming progression temps r√©el | ‚ùå Avanc√© |
| `/queue` | GET | √âtat queue g√©n√©ration | ‚ùå Optionnel |

---

## üìä Pattern API ComfyUI (vs Forge)

### Comparaison Architecture

**Forge (Simple)**: 1 requ√™te synchrone
```python
response = requests.post(
    "https://turbo.forge.myia.io/sdapi/v1/txt2img",
    json={"prompt": "...", "steps": 4}
)
image = Image.open(BytesIO(base64.b64decode(response.json()["images"][0])))
```

**ComfyUI (Queue + Poll)**: 2 requ√™tes asynchrones
```python
# 1. Queue workflow
response = requests.post(
    "https://qwen-image-edit.myia.io/prompt",
    json={"prompt": workflow_json, "client_id": "client123"}
)
prompt_id = response.json()["prompt_id"]

# 2. Poll r√©sultat (boucle)
while True:
    response = requests.get(f"https://qwen-image-edit.myia.io/history/{prompt_id}")
    result = response.json()
    if prompt_id in result and "outputs" in result[prompt_id]:
        # R√©sultat disponible
        break
    time.sleep(1)  # Attente polling
```

### Diff√©rence Clef: Workflow JSON

**Forge**: Param√®tres cl√©-valeur simples
```json
{"prompt": "text", "steps": 20, "cfg_scale": 7.5}
```

**ComfyUI**: Graph JSON complet (nodes + connexions)
```json
{
  "1": {"class_type": "QwenVLCLIPLoader", "inputs": {"model_path": "..."}},
  "2": {"class_type": "TextEncodeQwenImageEdit", "inputs": {"text": "...", "clip": ["1", 0]}},
  "5": {"class_type": "QwenImageSamplerNode", "inputs": {"steps": 20, "transformer": ["1", 1], ...}}
}
```

---

## üèóÔ∏è Workflows JSON P√©dagogiques

### Workflow 1: Text-to-Image Basique (D√©butant)

**Objectif**: G√©n√©ration image simple depuis texte  
**VRAM**: 12-15GB  
**Temps**: 5-10s  
**Nodes**: 7

#### Architecture JSON Compl√®te

```json
{
  "1": {
    "class_type": "QwenVLCLIPLoader",
    "inputs": {"model_path": "Qwen-Image-Edit-2509-FP8"}
  },
  "2": {
    "class_type": "TextEncodeQwenImageEdit",
    "inputs": {
      "text": "A beautiful mountain landscape at sunset, highly detailed, 8k",
      "clip": ["1", 0]
    }
  },
  "3": {
    "class_type": "TextEncodeQwenImageEdit",
    "inputs": {
      "text": "blurry, low quality, watermark",
      "clip": ["1", 0]
    }
  },
  "4": {
    "class_type": "QwenVLEmptyLatent",
    "inputs": {"width": 512, "height": 512, "batch_size": 1}
  },
  "5": {
    "class_type": "QwenImageSamplerNode",
    "inputs": {
      "seed": 42,
      "steps": 20,
      "cfg": 7.0,
      "sampler_name": "euler_ancestral",
      "scheduler": "normal",
      "transformer": ["1", 1],
      "positive": ["2", 0],
      "negative": ["3", 0],
      "latent_image": ["4", 0]
    }
  },
  "6": {
    "class_type": "VAEDecode",
    "inputs": {
      "samples": ["5", 0],
      "vae": ["1", 2]
    }
  },
  "7": {
    "class_type": "SaveImage",
    "inputs": {
      "filename_prefix": "Qwen_T2I",
      "images": ["6", 0]
    }
  }
}
```

#### Param√®tres P√©dagogiques Cl√©s

| Param√®tre | Plage | Recommand√© | Impact P√©dagogique |
|-----------|-------|------------|-------------------|
| `steps` | 1-50 | 20 | **Exercice 1**: Comparer 10/20/30 steps |
| `cfg` | 1-20 | 7.0 | **Exercice 2**: Tester 5/7/10/15 |
| `width/height` | 256-2048 | 512 | **Exercice 3**: Impact VRAM |
| `seed` | -1 ou int | 42 | **Exercice 4**: Reproductibilit√© |

---

### Workflow 2: Image-to-Image Editing (Interm√©diaire)

**Objectif**: √âdition image existante guid√©e texte  
**VRAM**: 15-18GB  
**Temps**: 8-12s  
**Nodes**: 9

#### Architecture JSON Condens√©e

```json
{
  "1": {"class_type": "LoadImage", "inputs": {"image": "source.png"}},
  "2": {"class_type": "QwenVLCLIPLoader", "inputs": {"model_path": "Qwen-Image-Edit-2509-FP8"}},
  "3": {"class_type": "QwenVLImageToLatent", "inputs": {"image": ["1", 0], "vae": ["2", 2]}},
  "4": {"class_type": "TextEncodeQwenImageEdit", "inputs": {"text": "Change sky to sunset", "clip": ["2", 0]}},
  "5": {"class_type": "TextEncodeQwenImageEdit", "inputs": {"text": "blurry, distorted", "clip": ["2", 0]}},
  "6": {
    "class_type": "QwenImageSamplerWithEdit",
    "inputs": {
      "seed": 42,
      "steps": 25,
      "cfg": 7.5,
      "denoise": 0.6,
      "edit_strength": 0.75,
      "transformer": ["2", 1],
      "positive": ["4", 0],
      "negative": ["5", 0],
      "image": ["3", 0]
    }
  },
  "7": {"class_type": "VAEDecode", "inputs": {"samples": ["6", 0], "vae": ["2", 2]}},
  "8": {"class_type": "SaveImage", "inputs": {"filename_prefix": "Qwen_I2I", "images": ["7", 0]}}
}
```

#### Param√®tres Critiques I2I

| Param√®tre | Plage | Recommand√© | Usage P√©dagogique |
|-----------|-------|------------|-------------------|
| `denoise` | 0.0-1.0 | 0.6 | **Exercice 5**: 0.3 (subtil) vs 0.8 (fort) |
| `edit_strength` | 0.0-1.0 | 0.75 | **Exercice 6**: Force transformation |
| `steps` | 1-50 | 25 | Plus √©lev√© que T2I pour pr√©cision |

---

## üêç Client Python P√©dagogique

### Fonction Helper Principale (√Ä inclure Notebook)

```python
import requests
import json
import time
from PIL import Image
from io import BytesIO
import base64

class ComfyUIClient:
    """Client p√©dagogique pour API ComfyUI Qwen"""
    
    def __init__(self, base_url="https://qwen-image-edit.myia.io"):
        self.base_url = base_url
        self.client_id = "notebook_student"
    
    def execute_workflow(self, workflow_json, wait_for_completion=True, max_wait=60):
        """
        Ex√©cute workflow ComfyUI et attend r√©sultat
        
        Args:
            workflow_json (dict): Workflow JSON ComfyUI
            wait_for_completion (bool): Attendre fin g√©n√©ration
            max_wait (int): Timeout secondes
        
        Returns:
            dict: R√©sultat avec images g√©n√©r√©es
        """
        # 1. Queue workflow
        payload = {
            "prompt": workflow_json,
            "client_id": self.client_id
        }
        
        response = requests.post(
            f"{self.base_url}/prompt",
            json=payload,
            timeout=30
        )
        
        if response.status_code != 200:
            raise Exception(f"Erreur queue: {response.status_code}")
        
        prompt_id = response.json()["prompt_id"]
        print(f"‚úÖ Workflow queued: {prompt_id}")
        
        if not wait_for_completion:
            return {"prompt_id": prompt_id, "status": "queued"}
        
        # 2. Poll r√©sultat
        start_time = time.time()
        
        while True:
            # Timeout check
            if time.time() - start_time > max_wait:
                raise TimeoutError(f"Timeout apr√®s {max_wait}s")
            
            # R√©cup√©rer historique
            response = requests.get(
                f"{self.base_url}/history/{prompt_id}",
                timeout=10
            )
            
            result = response.json()
            
            # V√©rifier si termin√©
            if prompt_id in result:
                task = result[prompt_id]
                
                if "outputs" in task:
                    print(f"‚úÖ G√©n√©ration termin√©e en {time.time() - start_time:.1f}s")
                    return self._extract_images(task["outputs"])
            
            # Attendre avant re-poll
            time.sleep(1)
            print("‚è≥ G√©n√©ration en cours...")
    
    def _extract_images(self, outputs):
        """Extrait images depuis outputs ComfyUI"""
        images = []
        
        for node_id, output in outputs.items():
            if "images" in output:
                for img_data in output["images"]:
                    # R√©cup√©rer image depuis serveur
                    img_url = f"{self.base_url}/view?filename={img_data['filename']}"
                    response = requests.get(img_url)
                    
                    image = Image.open(BytesIO(response.content))
                    images.append(image)
        
        return {"images": images, "count": len(images)}
```

### Utilisation P√©dagogique √âtape par √âtape

```python
# Cellule 1: Imports + Configuration
import sys
sys.path.insert(0, '../shared/helpers')  # Ajuster selon structure
from comfyui_client import ComfyUIClient

# Connexion service
client = ComfyUIClient("https://qwen-image-edit.myia.io")

# Cellule 2: Workflow T2I Simple
workflow_hello = {
    "1": {"class_type": "QwenVLCLIPLoader", "inputs": {"model_path": "Qwen-Image-Edit-2509-FP8"}},
    "2": {"class_type": "TextEncodeQwenImageEdit", "inputs": {"text": "A cute cat", "clip": ["1", 0]}},
    "3": {"class_type": "TextEncodeQwenImageEdit", "inputs": {"text": "blurry", "clip": ["1", 0]}},
    "4": {"class_type": "QwenVLEmptyLatent", "inputs": {"width": 512, "height": 512, "batch_size": 1}},
    "5": {"class_type": "QwenImageSamplerNode", "inputs": {
        "seed": 42, "steps": 20, "cfg": 7.0,
        "sampler_name": "euler_ancestral", "scheduler": "normal",
        "transformer": ["1", 1], "positive": ["2", 0], "negative": ["3", 0], "latent_image": ["4", 0]
    }},
    "6": {"class_type": "VAEDecode", "inputs": {"samples": ["5", 0], "vae": ["1", 2]}},
    "7": {"class_type": "SaveImage", "inputs": {"filename_prefix": "cat", "images": ["6", 0]}}
}

# Ex√©cution
result = client.execute_workflow(workflow_hello)

# Affichage
import matplotlib.pyplot as plt
plt.figure(figsize=(8, 8))
plt.imshow(result["images"][0])
plt.axis("off")
plt.title("Mon premier chat Qwen!")
plt.show()
```

---

## üìö Param√®tres Recommand√©s Par Cas Usage

### G√©n√©ration Text-to-Image

| Qualit√© | steps | cfg | VRAM | Temps |
|---------|-------|-----|------|-------|
| **Rapide** | 15 | 6.0 | 10GB | 3-5s |
| **Standard** | 20 | 7.0 | 12GB | 5-10s |
| **Qualit√© Max** | 30 | 7.5 | 15GB | 10-15s |

### √âdition Image-to-Image

| Force √âdition | denoise | edit_strength | steps | Usage |
|---------------|---------|---------------|-------|-------|
| **Subtile** | 0.3 | 0.5 | 20 | Correction couleurs |
| **√âquilibr√©e** | 0.6 | 0.75 | 25 | Changement ciel |
| **Forte** | 0.8 | 1.0 | 30 | Transformation style |

### R√©solutions Optimales RTX 3090

| R√©solution | VRAM | Recommandation |
|------------|------|----------------|
| 384x384 | 8GB | Prototypage rapide |
| 512x512 | 12GB | **Optimal p√©dagogique** ‚úÖ |
| 768x768 | 18GB | Qualit√© standard |
| 1024x1024 | 22GB | Maximum RTX 3090 |
| 2048x2048 | ‚ö†Ô∏è OOM | Impossible RTX 3090 |

---

## üéØ Checklist Impl√©mentation Notebook

### √âl√©ments Techniques Essentiels

- [ ] Client ComfyUI avec queue + poll
- [ ] Workflow T2I JSON complet
- [ ] Workflow I2I JSON complet
- [ ] Fonction helper extraction images
- [ ] Gestion erreurs API (timeout, OOM)
- [ ] Affichage matplotlib images

### √âl√©ments P√©dagogiques

- [ ] Explication pattern "queue and poll"
- [ ] Comparaison Forge vs ComfyUI
- [ ] Exercices variations param√®tres
- [ ] Visualisation impact steps/cfg
- [ ] Troubleshooting CUDA OOM
- [ ] Bonnes pratiques prompts

### Workflows Progressifs

1. **D√©butant**: T2I simple (chat, paysage)
2. **Interm√©diaire**: Variation prompts (styles multiples)
3. **Avanc√©**: I2I √©dition (changement ciel)
4. **Expert**: Comparaison param√®tres (grid visualisation)

---

## üêõ Troubleshooting API

### Erreur: Connection Timeout

**Sympt√¥me**: `requests.exceptions.Timeout`

**Solutions**:
```python
# Augmenter timeout
client = ComfyUIClient(timeout=60)

# Ou dans requests
response = requests.post(url, json=payload, timeout=60)
```

### Erreur: CUDA Out of Memory

**Sympt√¥me**: Workflow queue mais aucun r√©sultat

**Solutions progressives**:
1. R√©duire r√©solution (768‚Üí512‚Üí384)
2. Attendre 30s entre g√©n√©rations
3. Red√©marrer service ComfyUI
4. Utiliser workflow plus simple

**Code gestion erreur**:
```python
try:
    result = client.execute_workflow(workflow, max_wait=120)
except TimeoutError:
    print("‚ö†Ô∏è G√©n√©ration trop longue, service surcharg√©?")
    print("üí° Essayer r√©solution plus petite ou moins de steps")
except Exception as e:
    print(f"‚ùå Erreur API: {e}")
```

### Erreur: "Value not in list"

**Cause**: Utilisation nodes Stable Diffusion standard au lieu custom Qwen

**Solution**: V√©rifier `class_type` dans JSON:
- ‚úÖ `QwenVLCLIPLoader`
- ‚ùå `CheckpointLoaderSimple`

### Images Floues/Artefacts

**Solutions**:
1. Augmenter `steps` (20‚Üí25‚Üí30)
2. Ajuster `cfg` (7‚Üí8)
3. Am√©liorer negative prompt
4. R√©duire `denoise` pour I2I (0.8‚Üí0.6)

---

## üìä M√©triques Performance Attendues

### Latences Typiques RTX 3090

| Workflow | R√©solution | Steps | VRAM | Temps Moyen |
|----------|-----------|-------|------|-------------|
| T2I Basique | 512x512 | 20 | 12GB | 5-8s |
| T2I Qualit√© | 512x512 | 30 | 15GB | 8-12s |
| I2I Standard | 512x512 | 25 | 15GB | 10-14s |
| I2I D√©taill√© | 768x768 | 30 | 18GB | 15-20s |

### Temp√©ratures GPU Normales

- 60-70¬∞C: G√©n√©ration standard
- 70-78¬∞C: G√©n√©ration intensive
- >80¬∞C: ‚ö†Ô∏è V√©rifier ventilation

---

## üéì Progression P√©dagogique Recommand√©e

### Notebook Structure (15 cellules)

**Section 1: Introduction ComfyUI** (3 cellules)
1. Markdown: Pr√©sentation API + use cases
2. Code: Imports + Client setup
3. Markdown: Architecture workflow JSON

**Section 2: Text-to-Image Basique** (4 cellules)
4. Markdown: Explication workflow T2I
5. Code: Workflow JSON + ex√©cution
6. Code: Exercice variation prompts
7. Code: Analyse impact param√®tres (steps/cfg)

**Section 3: Image-to-Image** (4 cellules)
8. Markdown: Principes √©dition guid√©e texte
9. Code: Upload + workflow I2I
10. Code: Exercice changement style
11. Code: Comparaison denoise/edit_strength

**Section 4: Avanc√©** (3 cellules)
12. Markdown: Optimisation VRAM + troubleshooting
13. Code: Grid comparaison param√®tres
14. Code: Exercice pratique autonome

**Section 5: Conclusion** (1 cellule)
15. Markdown: Ressources + projets sugg√©r√©s

---

## üìù Notes Implementation Notebook

### Simplifications P√©dagogiques

**Ne PAS inclure dans notebook d√©butant**:
- ‚ùå Workflows multi-images (trop complexe)
- ‚ùå Style transfer avanc√© (n√©cessite 2 images)
- ‚ùå WebSocket real-time (technique avanc√©)
- ‚ùå Hybride local/cloud (scope trop large)

**Inclure obligatoirement**:
- ‚úÖ Helper function queue + poll
- ‚úÖ Workflow T2I complet fonctionnel
- ‚úÖ Workflow I2I simple (changement ciel exemple)
- ‚úÖ Gestion erreurs timeout + OOM
- ‚úÖ Visualisation matplotlib r√©sultats

### Code R√©utilisable Phase 12C

**Disponible dans**: `docs/suivis/genai-image/phase-12c-architecture/rapports/2025-10-16_12C_design-notebooks-pedagogiques.md`

- Client Python ComfyUI complet
- Workflows JSON valid√©s 5 types
- Tests unitaires API
- Scripts troubleshooting

---

## ‚úÖ Validation Analyse API

### Informations Extraites

- [x] URL production + port API
- [x] Endpoints ComfyUI critiques
- [x] Pattern queue + poll vs Forge
- [x] Workflow T2I JSON complet
- [x] Workflow I2I JSON complet
- [x] Param√®tres recommand√©s par cas usage
- [x] Client Python helper function
- [x] Troubleshooting erreurs communes
- [x] M√©triques performance RTX 3090
- [x] Progression p√©dagogique 15 cellules

### Prochaine √âtape

**Step 4**: Design Notebook Structure Compl√®te

**Fichier suivant**: `2025-10-20_20_04_design-notebook-qwen.md`

**Contenu pr√©vu**:
- Sp√©cification compl√®te 15 cellules
- Contenu markdown d√©taill√©
- Code Python chaque cellule code
- Objectifs p√©dagogiques cellule
- Validation coh√©rence structure

---

**Document cr√©√©**: 2025-10-20 22:34 CEST  
**Statut Step 3**: ‚úÖ COMPL√âT√â  
**Lignes**: 656  
**Prochaine action**: Design complet notebook Phase 20