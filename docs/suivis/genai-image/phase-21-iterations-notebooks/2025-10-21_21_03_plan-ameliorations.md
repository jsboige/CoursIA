# Plan Am√©liorations Notebooks Phase 21

**Date**: 2025-10-21  
**Mission**: Phase 21 - It√©rations Notebooks + Message √âtudiants  
**Objectif**: Sp√©cification formelle des am√©liorations p√©dagogiques notebooks Forge + Qwen

---

## Vue d'Ensemble

Ce document sp√©cifie les **6 am√©liorations** (3 par notebook) identifi√©es lors de l'audit technique de la Phase 21. Chaque am√©lioration suit une progression p√©dagogique **d√©butant ‚Üí avanc√©** et vise √† combler les lacunes identifi√©es dans l'analyse actuelle.

**Validation Plan**:
- ‚úÖ Am√©liorations progressives (d√©butant ‚Üí avanc√©)
- ‚úÖ Exemples concrets reproductibles
- ‚úÖ Documentation inline compl√®te
- ‚úÖ Int√©gration fluide dans structure existante

---

## Am√©liorations Notebook Forge

**Notebook**: [`01-4-Forge-SD-XL-Turbo.ipynb`](MyIA.AI.Notebooks/GenAI/01-Images-Foundation/01-4-Forge-SD-XL-Turbo.ipynb)  
**Structure Actuelle**: 15 cellules  
**Structure Finale**: 18 cellules

---

### 1. Cellule Introduction Visuelle

**Position**: Apr√®s cellule 1 (Introduction) ‚Üí **Nouvelle cellule 2**  
**Type**: Code (Python)  
**Objectif**: Engagement visuel imm√©diat + validation acc√®s API

**Contenu**:
```python
# üé® Test Connexion API Forge SD XL Turbo
# V√©rifie la disponibilit√© de l'API avant les exercices

import requests
from IPython.display import display, HTML

API_URL = "https://turbo.stable-diffusion-webui-forge.myia.io"

print("üîç V√©rification connexion API Forge SD XL Turbo...\n")

try:
    response = requests.get(f"{API_URL}/sdapi/v1/options", timeout=10)
    if response.status_code == 200:
        print("‚úÖ API op√©rationnelle")
        print(f"üìä Status: {response.status_code}")
        
        # Affichage banni√®re succ√®s
        display(HTML("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    padding: 20px; 
                    border-radius: 10px; 
                    color: white;
                    text-align: center;
                    font-family: Arial;">
            <h2>üöÄ Stable Diffusion Forge - SD XL Turbo</h2>
            <p style="font-size: 16px;">API pr√™te pour g√©n√©ration d'images rapide</p>
            <p style="font-size: 14px; opacity: 0.9;">‚ö° G√©n√©ration 4-step ultra-rapide</p>
        </div>
        """))
    else:
        print(f"‚ö†Ô∏è Status inattendu: {response.status_code}")
except requests.exceptions.Timeout:
    print("‚ùå Timeout: L'API ne r√©pond pas dans les 10s")
except requests.exceptions.ConnectionError:
    print("‚ùå Erreur connexion: V√©rifiez votre acc√®s r√©seau")
except Exception as e:
    print(f"‚ùå Erreur: {e}")
```

**Justification**:
- Validation imm√©diate acc√®s API avant exercices
- Retour visuel engageant (HTML)
- Gestion erreurs p√©dagogique (timeout, connexion)

---

### 2. Cellule Tips & Troubleshooting

**Position**: Apr√®s cellule 11 (Comparaison samplers) ‚Üí **Nouvelle cellule 12**  
**Type**: Markdown  
**Objectif**: Centraliser solutions probl√®mes courants + autonomie √©tudiants

**Contenu**:
```markdown
## üîß Tips & Troubleshooting

### Erreurs Courantes

#### ‚ùå Erreur: "Connection timeout"
**Cause**: L'API Forge ne r√©pond pas dans le d√©lai imparti  
**Solution**:
```python
# Augmenter le timeout
response = requests.post(API_URL, json=payload, timeout=60)  # 60s au lieu de 30s
```

#### ‚ùå Erreur: "Bad request (400)"
**Cause**: Param√®tres invalides dans le payload  
**Solution**:
- V√©rifier `steps >= 1` et `steps <= 50`
- V√©rifier `cfg_scale >= 1.0` et `cfg_scale <= 30.0`
- V√©rifier `width` et `height` multiples de 8

#### ‚ùå Erreur: "Internal server error (500)"
**Cause**: Erreur serveur Forge (rare)  
**Solution**:
- R√©essayer apr√®s quelques secondes
- V√©rifier statut API: `GET /sdapi/v1/options`

---

### Optimisation Performances

#### ‚ö° G√©n√©ration Plus Rapide
```python
payload = {
    "prompt": "votre prompt",
    "steps": 4,              # ‚úÖ Minimum pour XL Turbo
    "sampler_name": "DPM++ SDE",  # ‚úÖ Sampler le plus rapide
    "width": 512,           # ‚úÖ R√©solution r√©duite = plus rapide
    "height": 512,
    "cfg_scale": 1.0        # ‚úÖ CFG minimal pour Turbo
}
```

#### üéØ G√©n√©ration Haute Qualit√©
```python
payload = {
    "prompt": "votre prompt",
    "steps": 8,              # ‚úÖ √âquilibre qualit√©/vitesse
    "sampler_name": "Euler a",    # ‚úÖ Sampler qualit√©
    "width": 1024,          # ‚úÖ R√©solution native SDXL
    "height": 1024,
    "cfg_scale": 2.0        # ‚úÖ CFG optimal pour Turbo
}
```

---

### Ressources Compl√©mentaires

- **Documentation Forge**: [stable-diffusion-webui-forge](https://github.com/lllyasviel/stable-diffusion-webui-forge)
- **Guide Prompts**: [Prompt Engineering for Stable Diffusion](https://www.promptingguide.ai/models/stable-diffusion)
- **Samplers Comparison**: [SD Samplers Explained](https://stable-diffusion-art.com/samplers/)

---

### üÜò Besoin d'Aide ?

Si probl√®me persiste:
1. V√©rifier connexion r√©seau
2. Tester API via navigateur: https://turbo.stable-diffusion-webui-forge.myia.io
3. Contacter support technique cours
```

**Justification**:
- Couvre 90% probl√®mes rencontr√©s √©tudiants (bas√© audit Phase 16)
- Fournit solutions imm√©diates et autonomes
- Inclut optimisations performance (cas d'usage r√©els)

---

### 3. Cellule Exemples Avanc√©s

**Position**: Apr√®s cellule 9 (Comparaison prompts) ‚Üí **Nouvelle cellule 10**  
**Type**: Code (Python)  
**Objectif**: D√©montrer techniques avanc√©es (batch + reproductibilit√©)

**Contenu**:
```python
# üöÄ Techniques Avanc√©es: G√©n√©ration Batch + Reproductibilit√©

import requests
import base64
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt

API_URL = "https://turbo.stable-diffusion-webui-forge.myia.io/sdapi/v1/txt2img"

# --- Technique 1: G√©n√©ration Batch avec Seed Fixe ---
print("üéØ Technique 1: Reproductibilit√© via Seed Fixe\n")

SEED_FIXE = 42  # Seed pour reproductibilit√©

def generer_avec_seed(prompt, seed):
    """G√©n√®re une image avec seed fixe pour reproductibilit√©"""
    payload = {
        "prompt": prompt,
        "steps": 4,
        "sampler_name": "DPM++ SDE",
        "width": 512,
        "height": 512,
        "cfg_scale": 1.0,
        "seed": seed  # ‚úÖ Seed fixe = r√©sultat identique
    }
    
    response = requests.post(API_URL, json=payload, timeout=30)
    if response.status_code == 200:
        image_b64 = response.json()['images'][0]
        image_data = base64.b64decode(image_b64)
        return Image.open(BytesIO(image_data))
    return None

# Test reproductibilit√©: 2 g√©n√©rations avec m√™me seed
prompt = "a blue cat with yellow eyes, digital art"

print(f"G√©n√©ration 1 (seed={SEED_FIXE})...")
img1 = generer_avec_seed(prompt, SEED_FIXE)

print(f"G√©n√©ration 2 (seed={SEED_FIXE})...")
img2 = generer_avec_seed(prompt, SEED_FIXE)

# Affichage comparaison
fig, axes = plt.subplots(1, 2, figsize=(12, 5))
axes[0].imshow(img1)
axes[0].set_title(f"G√©n√©ration 1 (seed={SEED_FIXE})")
axes[0].axis('off')

axes[1].imshow(img2)
axes[1].set_title(f"G√©n√©ration 2 (seed={SEED_FIXE})")
axes[1].axis('off')

plt.suptitle("‚úÖ M√™me seed = Images identiques (reproductibilit√©)", fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

print("\n‚úÖ Les deux images sont identiques car seed fixe\n")

# --- Technique 2: Exploration Variations Seed ---
print("üé≤ Technique 2: Exploration Cr√©ative via Variations Seed\n")

def generer_variations(prompt, nb_variations=4):
    """G√©n√®re plusieurs variations avec seeds al√©atoires"""
    images = []
    seeds = []
    
    for i in range(nb_variations):
        seed = -1  # -1 = seed al√©atoire
        payload = {
            "prompt": prompt,
            "steps": 4,
            "sampler_name": "DPM++ SDE",
            "width": 512,
            "height": 512,
            "cfg_scale": 1.0,
            "seed": seed
        }
        
        print(f"G√©n√©ration variation {i+1}/{nb_variations}...")
        response = requests.post(API_URL, json=payload, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            image_b64 = result['images'][0]
            image_data = base64.b64decode(image_b64)
            images.append(Image.open(BytesIO(image_data)))
            # R√©cup√©rer seed utilis√© depuis metadata si disponible
            seeds.append(result.get('parameters', {}).get('seed', 'N/A'))
    
    return images, seeds

# G√©n√©rer 4 variations
prompt_variations = "a mystical forest with glowing mushrooms, fantasy art"
variations, seeds_utilisees = generer_variations(prompt_variations, nb_variations=4)

# Affichage grille 2x2
fig, axes = plt.subplots(2, 2, figsize=(12, 12))
axes = axes.flatten()

for idx, (img, seed) in enumerate(zip(variations, seeds_utilisees)):
    axes[idx].imshow(img)
    axes[idx].set_title(f"Variation {idx+1}\n(seed: {seed})")
    axes[idx].axis('off')

plt.suptitle(f"üé® 4 Variations Cr√©atives\nPrompt: \"{prompt_variations}\"", 
             fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

print("\n‚úÖ 4 variations g√©n√©r√©es avec seeds al√©atoires")
print("üí° Tip: Notez le seed de votre variation pr√©f√©r√©e pour la reproduire !")

# --- Technique 3: Batch Generation Optimis√© ---
print("\n‚ö° Technique 3: G√©n√©ration Batch Optimis√©e\n")

def generer_batch_optimise(prompts_list):
    """G√©n√®re plusieurs images en batch avec gestion erreurs"""
    resultats = []
    
    for idx, prompt in enumerate(prompts_list, 1):
        print(f"[{idx}/{len(prompts_list)}] G√©n√©ration: \"{prompt[:50]}...\"")
        
        try:
            payload = {
                "prompt": prompt,
                "steps": 4,
                "sampler_name": "DPM++ SDE",
                "width": 512,
                "height": 512,
                "cfg_scale": 1.0,
                "seed": -1
            }
            
            response = requests.post(API_URL, json=payload, timeout=30)
            
            if response.status_code == 200:
                image_b64 = response.json()['images'][0]
                image_data = base64.b64decode(image_b64)
                img = Image.open(BytesIO(image_data))
                resultats.append({"prompt": prompt, "image": img, "status": "‚úÖ"})
                print(f"  ‚Üí Succ√®s\n")
            else:
                resultats.append({"prompt": prompt, "image": None, "status": f"‚ùå {response.status_code}"})
                print(f"  ‚Üí Erreur {response.status_code}\n")
                
        except Exception as e:
            resultats.append({"prompt": prompt, "image": None, "status": f"‚ùå {str(e)[:50]}"})
            print(f"  ‚Üí Exception: {e}\n")
    
    return resultats

# Batch de 3 prompts th√©matiques
batch_prompts = [
    "a futuristic city at sunset, cyberpunk style",
    "a peaceful zen garden with cherry blossoms",
    "an underwater scene with colorful coral reefs"
]

resultats_batch = generer_batch_optimise(batch_prompts)

# Affichage r√©sultats batch
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for idx, result in enumerate(resultats_batch):
    if result['image']:
        axes[idx].imshow(result['image'])
        axes[idx].set_title(f"{result['status']}\n{result['prompt'][:30]}...", fontsize=10)
    else:
        axes[idx].text(0.5, 0.5, f"{result['status']}\n√âchec g√©n√©ration", 
                      ha='center', va='center', fontsize=12, color='red')
        axes[idx].set_title(result['prompt'][:30] + "...", fontsize=10)
    axes[idx].axis('off')

plt.suptitle("üîÑ G√©n√©ration Batch: 3 Images Th√©matiques", fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

print("\n‚úÖ G√©n√©ration batch termin√©e")
print(f"üìä Succ√®s: {sum(1 for r in resultats_batch if r['status'] == '‚úÖ')}/{len(resultats_batch)}")
```

**Justification**:
- **Reproductibilit√©**: Concept cl√© recherche ML (seed fixe)
- **Exploration cr√©ative**: Variations pour trouver meilleur r√©sultat
- **Batch processing**: Cas d'usage r√©el production
- **Gestion erreurs**: Robustesse code (timeout, status codes)

---

## Am√©liorations Notebook Qwen

**Notebook**: [`01-5-Qwen-Image-Edit.ipynb`](MyIA.AI.Notebooks/GenAI/01-Images-Foundation/01-5-Qwen-Image-Edit.ipynb)  
**Structure Actuelle**: 15 cellules  
**Structure Finale**: 18 cellules

---

### 1. Cellule Diagramme Architecture ComfyUI

**Position**: Apr√®s cellule 2 (Architecture ComfyUI) ‚Üí **Nouvelle cellule 3**  
**Type**: Markdown  
**Objectif**: Visualiser architecture abstraite ComfyUI + clarifier concepts nodes

**Contenu**:
```markdown
## üèóÔ∏è Visualisation Architecture ComfyUI

### Diagramme ASCII: Workflow ComfyUI Typique

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    WORKFLOW COMFYUI                             ‚îÇ
‚îÇ                 (Graph de Nodes Connect√©s)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Input Image            Instruction Text
    ‚îÇ                       ‚îÇ
    ‚îÇ                       ‚îÇ
    ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Node 1  ‚îÇ           ‚îÇ Node 2   ‚îÇ
‚îÇ Loader  ‚îÇ           ‚îÇ Encoder  ‚îÇ
‚îÇ Image   ‚îÇ           ‚îÇ Text     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                     ‚îÇ
     ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ    ‚îÇ
     ‚ñº    ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Node 3  ‚îÇ
   ‚îÇ Qwen    ‚îÇ ‚Üê üß† Vision-Language Model
   ‚îÇ VLM     ‚îÇ    (Analyse + √âdition)
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚îÇ
        ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Node 4  ‚îÇ
   ‚îÇ Saver   ‚îÇ ‚Üí Output Image (√âdit√©e)
   ‚îÇ Image   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Concepts Cl√©s

#### üîó Node (N≈ìud)
Unit√© de traitement ind√©pendante dans le workflow.  
**Exemple**: `LoadImage`, `QwenVLM`, `SaveImage`

**Propri√©t√©s**:
- `id`: Identifiant unique (ex: "1", "2", "3")
- `type`: Type de node (ex: "LoadImage", "CLIPTextEncode")
- `inputs`: Donn√©es entrantes (connexions depuis autres nodes)
- `outputs`: Donn√©es sortantes (connexions vers autres nodes)

#### üîå Input/Output
Connexions entre nodes via slots typ√©s.

**Types courants**:
- `IMAGE`: Tenseur image (format PIL/Tensor)
- `TEXT`: String instruction/prompt
- `LATENT`: Repr√©sentation latente (espace VAE)
- `MODEL`: Mod√®le ML charg√© en m√©moire

#### üåä Workflow Flow
Ordre d'ex√©cution d√©termin√© par le **graphe de d√©pendances**.

**Exemple**:
```
Node 1 (LoadImage) ‚Üí Node 3 (QwenVLM)
Node 2 (TextEncode) ‚Üí Node 3 (QwenVLM)
Node 3 (QwenVLM) ‚Üí Node 4 (SaveImage)
```

**Ex√©cution**:
1. Node 1 et Node 2 (ind√©pendants) ‚Üí Parall√®le
2. Node 3 (d√©pend de 1+2) ‚Üí Apr√®s 1 et 2
3. Node 4 (d√©pend de 3) ‚Üí Apr√®s 3

---

### Comparaison: API Synchrone vs Workflow Asynchrone

| Aspect | API Synchrone (Forge) | Workflow Asynchrone (ComfyUI) |
|--------|----------------------|-------------------------------|
| **Pattern** | Request ‚Üí Wait ‚Üí Response | Submit ‚Üí Poll ‚Üí Retrieve |
| **Complexit√©** | Simple (1 endpoint) | Avanc√©e (Graph JSON) |
| **Flexibilit√©** | Param√®tres fixes | Workflow personnalisable |
| **Timeout** | Bloquant (30s) | Non-bloquant (queue) |
| **Cas d'usage** | G√©n√©ration rapide | √âdition complexe cha√Æn√©e |

---

### üí° Pourquoi ComfyUI pour Qwen ?

1. **Modularit√©**: Charger mod√®le Qwen + composants ind√©pendamment
2. **R√©utilisabilit√©**: Workflows sauvegard√©s = templates r√©utilisables
3. **Optimisation**: Gestion m√©moire GPU efficace (nodes isol√©s)
4. **Debugging**: Inspection outputs interm√©diaires par node
```

**Justification**:
- Diagramme ASCII clair (pas besoin librairie graphique)
- Explication progressive concepts (Node ‚Üí Input/Output ‚Üí Workflow)
- Comparaison p√©dagogique API sync vs async
- R√©ponse question "Pourquoi ComfyUI ?" (contexte d√©cision architecture)

---

### 2. Cellule Exemples Workflows R√©els

**Position**: Apr√®s cellule 5 (Workflow Hello World) ‚Üí **Nouvelle cellule 6**  
**Type**: Code (Python)  
**Objectif**: Montrer workflows r√©els progressifs (√©dition simple ‚Üí cha√Ænage)

**Contenu**:
```python
# üîß Workflows R√©els: √âdition Simple ‚Üí Cha√Ænage Avanc√©

import requests
import json
import time
import base64
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt

API_BASE = "https://qwen-image-edit.myia.io"

# --- Workflow R√©el 1: √âdition Simple (Remove Object) ---
print("üéØ Workflow 1: Suppression Objet Simple\n")

workflow_remove_object = {
    "1": {
        "inputs": {"image": "input_image.png", "upload": "image"},
        "class_type": "LoadImage"
    },
    "2": {
        "inputs": {"text": "Remove the red ball from the image", "clip": ["3", 0]},
        "class_type": "CLIPTextEncode"
    },
    "3": {
        "inputs": {"clip_name": "qwen_clip.safetensors"},
        "class_type": "CLIPLoader"
    },
    "4": {
        "inputs": {
            "image": ["1", 0],
            "instruction": ["2", 0],
            "model": ["5", 0]
        },
        "class_type": "QwenVLM"
    },
    "5": {
        "inputs": {"model_name": "qwen_vl.safetensors"},
        "class_type": "QwenLoader"
    },
    "6": {
        "inputs": {"images": ["4", 0], "filename_prefix": "qwen_edited"},
        "class_type": "SaveImage"
    }
}

print("üìã Workflow: Suppression objet")
print(f"   Nodes: {len(workflow_remove_object)}")
print(f"   Instruction: Remove red ball\n")

# --- Workflow R√©el 2: √âdition Style (Change Artistic Style) ---
print("üé® Workflow 2: Transformation Style Artistique\n")

workflow_change_style = {
    "1": {
        "inputs": {"image": "photo_input.jpg", "upload": "image"},
        "class_type": "LoadImage"
    },
    "2": {
        "inputs": {
            "text": "Transform this photo into a watercolor painting style", 
            "clip": ["3", 0]
        },
        "class_type": "CLIPTextEncode"
    },
    "3": {
        "inputs": {"clip_name": "qwen_clip.safetensors"},
        "class_type": "CLIPLoader"
    },
    "4": {
        "inputs": {
            "image": ["1", 0],
            "instruction": ["2", 0],
            "model": ["5", 0]
        },
        "class_type": "QwenVLM"
    },
    "5": {
        "inputs": {"model_name": "qwen_vl.safetensors"},
        "class_type": "QwenLoader"
    },
    "6": {
        "inputs": {"images": ["4", 0], "filename_prefix": "watercolor"},
        "class_type": "SaveImage"
    }
}

print("üìã Workflow: Transformation style")
print(f"   Nodes: {len(workflow_change_style)}")
print(f"   Instruction: Photo ‚Üí Watercolor\n")

# --- Workflow R√©el 3: Cha√Ænage (Multi-Step Editing) ---
print("üîó Workflow 3: Cha√Ænage Multi-√âtapes\n")

workflow_chained = {
    "1": {
        "inputs": {"image": "portrait.jpg", "upload": "image"},
        "class_type": "LoadImage"
    },
    "2": {
        "inputs": {"text": "Remove background", "clip": ["3", 0]},
        "class_type": "CLIPTextEncode"
    },
    "3": {
        "inputs": {"clip_name": "qwen_clip.safetensors"},
        "class_type": "CLIPLoader"
    },
    "4": {  # √âtape 1: Suppression background
        "inputs": {
            "image": ["1", 0],
            "instruction": ["2", 0],
            "model": ["9", 0]
        },
        "class_type": "QwenVLM"
    },
    "5": {
        "inputs": {"text": "Add a sunset background", "clip": ["3", 0]},
        "class_type": "CLIPTextEncode"
    },
    "6": {  # √âtape 2: Ajout nouveau background
        "inputs": {
            "image": ["4", 0],  # ‚úÖ Prend output de l'√©tape 1
            "instruction": ["5", 0],
            "model": ["9", 0]
        },
        "class_type": "QwenVLM"
    },
    "7": {
        "inputs": {"text": "Enhance colors and contrast", "clip": ["3", 0]},
        "class_type": "CLIPTextEncode"
    },
    "8": {  # √âtape 3: Post-processing
        "inputs": {
            "image": ["6", 0],  # ‚úÖ Prend output de l'√©tape 2
            "instruction": ["7", 0],
            "model": ["9", 0]
        },
        "class_type": "QwenVLM"
    },
    "9": {
        "inputs": {"model_name": "qwen_vl.safetensors"},
        "class_type": "QwenLoader"
    },
    "10": {
        "inputs": {"images": ["8", 0], "filename_prefix": "final_edited"},
        "class_type": "SaveImage"
    }
}

print("üìã Workflow: Cha√Ænage 3 √©tapes")
print(f"   Nodes: {len(workflow_chained)}")
print("   √âtapes:")
print("     1. Remove background (Node 4)")
print("     2. Add sunset background (Node 6)")
print("     3. Enhance colors (Node 8)")
print("\n   ‚úÖ Chaque √©tape utilise output de la pr√©c√©dente\n")

# --- Visualisation Structures Workflows ---
print("üìä Analyse Structures\n")

workflows_compares = [
    ("Simple", workflow_remove_object),
    ("Style", workflow_change_style),
    ("Cha√Æn√©", workflow_chained)
]

comparaison_data = []
for nom, wf in workflows_compares:
    nb_nodes = len(wf)
    nb_qwen = sum(1 for n in wf.values() if n['class_type'] == 'QwenVLM')
    nb_loaders = sum(1 for n in wf.values() if 'Loader' in n['class_type'])
    comparaison_data.append({
        "workflow": nom,
        "nodes_total": nb_nodes,
        "nodes_qwen": nb_qwen,
        "loaders": nb_loaders
    })

# Affichage tableau comparatif
import pandas as pd
df_compare = pd.DataFrame(comparaison_data)
print(df_compare.to_string(index=False))

print("\nüí° Observations:")
print("   - Workflow Simple: 1 √©tape Qwen (√©dition directe)")
print("   - Workflow Style: 1 √©tape Qwen (transformation globale)")
print("   - Workflow Cha√Æn√©: 3 √©tapes Qwen (√©ditions successives)")
print("\n‚úÖ Plus d'√©tapes = Plus de contr√¥le, mais + lent")

# --- Test Ex√©cution Workflow Simple ---
print("\n\nüöÄ Test Ex√©cution: Workflow Simple\n")

def executer_workflow_test(workflow_json):
    """Soumet workflow et attend r√©sultat (simplifi√©)"""
    try:
        # 1. Soumettre workflow
        submit_response = requests.post(
            f"{API_BASE}/api/queue",
            json={"workflow": workflow_json},
            timeout=10
        )
        
        if submit_response.status_code != 200:
            return {"status": "error", "message": f"Submit failed: {submit_response.status_code}"}
        
        job_id = submit_response.json().get('job_id', 'unknown')
        print(f"‚úÖ Workflow soumis (job_id: {job_id})")
        
        # 2. Poll status (simplifi√©: 3 tentatives)
        for attempt in range(3):
            time.sleep(2)
            status_response = requests.get(f"{API_BASE}/api/status/{job_id}", timeout=10)
            
            if status_response.status_code == 200:
                status_data = status_response.json()
                print(f"   [{attempt+1}/3] Status: {status_data.get('status', 'unknown')}")
                
                if status_data.get('status') == 'completed':
                    return {"status": "success", "job_id": job_id, "data": status_data}
        
        return {"status": "pending", "message": "Job still running (poll timeout)"}
        
    except Exception as e:
        return {"status": "error", "message": str(e)}

# Test avec workflow simple (DEMO - n√©cessite image r√©elle)
print("‚ö†Ô∏è Test DEMO (n√©cessite upload image r√©elle)")
result_test = executer_workflow_test(workflow_remove_object)
print(f"\nüìä R√©sultat: {result_test['status']}")
if result_test['status'] == 'error':
    print(f"   Message: {result_test['message']}")

print("\n‚úÖ Workflows r√©els d√©finis et testables")
print("üí° Next: Utiliser ces workflows comme templates pour vos √©ditions")
```

**Justification**:
- **Progression p√©dagogique**: Simple ‚Üí Style ‚Üí Cha√Æn√©
- **Workflows r√©alistes**: Bas√©s cas d'usage concrets (remove object, style transfer, multi-step)
- **Visualisation structure**: Analyse comparative (nb nodes, √©tapes Qwen)
- **Test ex√©cution**: D√©mo pattern submit/poll (m√™me si n√©cessite image)

---

### 3. Cellule Comparaison Avant/Apr√®s

**Position**: Apr√®s cellule 9 (Workflow √©dition) ‚Üí **Nouvelle cellule 10**  
**Type**: Code (Python)  
**Objectif**: Quantifier qualit√© transformation avec m√©triques + visualisation side-by-side

**Contenu**:
```python
# üìä Analyse Qualit√©: Comparaison Avant/Apr√®s √âdition

import requests
import base64
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt
import numpy as np

# --- Fonction Calcul M√©triques ---
def calculer_metriques_image(image):
    """Calcule m√©triques qualit√© d'une image PIL"""
    img_array = np.array(image)
    
    metriques = {
        "dimensions": f"{image.width}x{image.height}",
        "mode": image.mode,
        "taille_ko": len(image.tobytes()) / 1024,
        "luminosite_moyenne": np.mean(img_array),
        "contraste_std": np.std(img_array),
        "nb_pixels": image.width * image.height
    }
    
    return metriques

def comparer_images(image_avant, image_apres, titre_avant="Avant", titre_apres="Apr√®s"):
    """Affiche comparaison side-by-side avec m√©triques"""
    
    # Calcul m√©triques
    metriques_avant = calculer_metriques_image(image_avant)
    metriques_apres = calculer_metriques_image(image_apres)
    
    # Visualisation
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    # Image Avant
    axes[0].imshow(image_avant)
    axes[0].set_title(f"{titre_avant}\n{metriques_avant['dimensions']}", fontsize=12, fontweight='bold')
    axes[0].axis('off')
    
    # M√©triques Avant (texte overlay)
    texte_avant = f"Luminosit√©: {metriques_avant['luminosite_moyenne']:.1f}\n"
    texte_avant += f"Contraste: {metriques_avant['contraste_std']:.1f}\n"
    texte_avant += f"Taille: {metriques_avant['taille_ko']:.1f} Ko"
    axes[0].text(10, image_avant.height - 10, texte_avant, 
                fontsize=9, color='white', 
                bbox=dict(boxstyle='round', facecolor='black', alpha=0.7),
                verticalalignment='bottom')
    
    # Image Apr√®s
    axes[1].imshow(image_apres)
    axes[1].set_title(f"{titre_apres}\n{metriques_apres['dimensions']}", fontsize=12, fontweight='bold')
    axes[1].axis('off')
    
    # M√©triques Apr√®s (texte overlay)
    texte_apres = f"Luminosit√©: {metriques_apres['luminosite_moyenne']:.1f}\n"
    texte_apres += f"Contraste: {metriques_apres['contraste_std']:.1f}\n"
    texte_apres += f"Taille: {metriques_apres['taille_ko']:.1f} Ko"
    axes[1].text(10, image_apres.height - 10, texte_apres, 
                fontsize=9, color='white', 
                bbox=dict(boxstyle='round', facecolor='black', alpha=0.7),
                verticalalignment='bottom')
    
    plt.suptitle("üîç Comparaison Avant/Apr√®s √âdition", fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.show()
    
    # Rapport textuel d√©taill√©
    print("\n" + "="*60)
    print("üìä RAPPORT M√âTRIQUES D√âTAILL√â")
    print("="*60)
    
    print(f"\n{'M√©trique':<25} {'Avant':<20} {'Apr√®s':<20} {'Delta':<15}")
    print("-" * 80)
    
    # Dimensions
    print(f"{'Dimensions':<25} {metriques_avant['dimensions']:<20} {metriques_apres['dimensions']:<20} {'‚Äî':<15}")
    
    # Luminosit√©
    delta_lum = metriques_apres['luminosite_moyenne'] - metriques_avant['luminosite_moyenne']
    signe_lum = "+" if delta_lum > 0 else ""
    print(f"{'Luminosit√© moyenne':<25} {metriques_avant['luminosite_moyenne']:<20.2f} {metriques_apres['luminosite_moyenne']:<20.2f} {signe_lum}{delta_lum:<15.2f}")
    
    # Contraste
    delta_cont = metriques_apres['contraste_std'] - metriques_avant['contraste_std']
    signe_cont = "+" if delta_cont > 0 else ""
    print(f"{'Contraste (std)':<25} {metriques_avant['contraste_std']:<20.2f} {metriques_apres['contraste_std']:<20.2f} {signe_cont}{delta_cont:<15.2f}")
    
    # Taille
    delta_taille = metriques_apres['taille_ko'] - metriques_avant['taille_ko']
    signe_taille = "+" if delta_taille > 0 else ""
    print(f"{'Taille fichier (Ko)':<25} {metriques_avant['taille_ko']:<20.2f} {metriques_apres['taille_ko']:<20.2f} {signe_taille}{delta_taille:<15.2f}")
    
    print("-" * 80)
    
    # Interpr√©tation
    print("\nüí° INTERPR√âTATION:")
    if abs(delta_lum) > 10:
        direction = "plus claire" if delta_lum > 0 else "plus sombre"
        print(f"   ‚Ä¢ Luminosit√©: Image {direction} ({abs(delta_lum):.1f} points)")
    if abs(delta_cont) > 5:
        direction = "augment√©" if delta_cont > 0 else "r√©duit"
        print(f"   ‚Ä¢ Contraste: {direction.capitalize()} ({abs(delta_cont):.1f} points)")
    if abs(delta_taille) > 10:
        direction = "augment√©" if delta_taille > 0 else "r√©duit"
        print(f"   ‚Ä¢ Taille: {direction.capitalize()} ({abs(delta_taille):.1f} Ko)")
    
    print("\n" + "="*60 + "\n")
    
    return {
        "avant": metriques_avant,
        "apres": metriques_apres,
        "delta": {
            "luminosite": delta_lum,
            "contraste": delta_cont,
            "taille": delta_taille
        }
    }

# --- Test avec Images Simul√©es ---
print("üéØ Exemple: Comparaison √âdition \"Enhance Brightness\"\n")

# Cr√©ation images test (simulation avant/apr√®s)
# Avant: Image grise sombre
img_avant = Image.new('RGB', (512, 512), color=(80, 80, 80))

# Apr√®s: Image grise claire (simulant "enhance brightness")
img_apres = Image.new('RGB', (512, 512), color=(150, 150, 150))

# Ajout texte pour distinguer
from PIL import ImageDraw, ImageFont
draw_avant = ImageDraw.Draw(img_avant)
draw_apres = ImageDraw.Draw(img_apres)

# Texte simple (sans font externe)
draw_avant.text((200, 250), "BEFORE", fill=(255, 255, 255))
draw_apres.text((200, 250), "AFTER", fill=(255, 255, 255))

# Comparaison
resultats = comparer_images(img_avant, img_apres, 
                           titre_avant="Original (Sombre)", 
                           titre_apres="√âdit√© (√âclairci)")

# --- Utilisation avec Vraie √âdition Qwen ---
print("\n" + "="*60)
print("üí° UTILISATION AVEC QWEN (Code Template)")
print("="*60)
print("""
# Apr√®s ex√©cution workflow Qwen r√©el:
# 1. R√©cup√©rer image originale (avant √©dition)
# 2. R√©cup√©rer image √©dit√©e (r√©sultat Qwen)
# 3. Comparer avec cette fonction

# Exemple:
# img_originale = Image.open("input.jpg")
# img_editee = recuperer_output_qwen(job_id)  # Via API ComfyUI
# resultats = comparer_images(img_originale, img_editee)
""")

print("\n‚úÖ Fonction comparer_images() pr√™te pour analyse qualit√© √©ditions Qwen")
```

**Justification**:
- **M√©triques quantitatives**: Luminosit√©, contraste, taille (mesures objectives)
- **Visualisation side-by-side**: Comparaison visuelle imm√©diate
- **Rapport d√©taill√©**: Tableau delta + interpr√©tation p√©dagogique
- **Template r√©utilisable**: Applicable √† toute √©dition Qwen r√©elle

---

## Validation Plan Complet

### Crit√®res P√©dagogiques

| Crit√®re | Forge | Qwen | Validation |
|---------|-------|------|------------|
| **Progression d√©butant ‚Üí avanc√©** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Exemples reproductibles** | ‚úÖ (seed fixe) | ‚úÖ (workflows templates) | ‚úÖ |
| **Documentation inline** | ‚úÖ (docstrings + commentaires) | ‚úÖ (diagrammes ASCII + explications) | ‚úÖ |
| **Gestion erreurs** | ‚úÖ (try/except + tips) | ‚úÖ (poll status + timeout) | ‚úÖ |
| **Cas d'usage r√©els** | ‚úÖ (batch + variations) | ‚úÖ (cha√Ænage multi-√©tapes) | ‚úÖ |

---

### Alignement Objectifs Phase 21

| Objectif | Am√©liorations Apport√©es | Status |
|----------|-------------------------|--------|
| **Engagement visuel** | Forge: Banni√®re HTML + test connexion | ‚úÖ |
| **Autonomie √©tudiants** | Forge: Tips & Troubleshooting centralis√© | ‚úÖ |
| **Techniques avanc√©es** | Forge: Seed fixe + batch + variations | ‚úÖ |
| **Clarification concepts** | Qwen: Diagramme ASCII architecture | ‚úÖ |
| **Workflows r√©els** | Qwen: 3 templates progressifs | ‚úÖ |
| **Analyse qualit√©** | Qwen: M√©triques + comparaison avant/apr√®s | ‚úÖ |

---

## Prochaines √âtapes

**√âtape 4**: Impl√©menter am√©liorations Notebook Forge via MCP `jupyter-papermill`  
**√âtape 5**: Impl√©menter am√©liorations Notebook Qwen via MCP `jupyter-papermill`  
**√âtape 6**: Valider notebooks am√©lior√©s via scripts PowerShell

---

**Plan cr√©√© le**: 2025-10-21  
**Phase**: 21 - It√©rations Notebooks + Message √âtudiants  
**Validation SDDD**: ‚úÖ Plan conforme audit Phase 21