# Design Notebooks P√©dagogiques - Phase 12C

**Date**: 2025-10-16  
**Objectif**: Design complet de 2 notebooks bridge local/cloud avec structure SDDD  
**Cible**: Int√©gration cours GenAI/Images MyIA.AI.Notebooks

---

## üéØ Vue d'Ensemble

### Notebooks √† Cr√©er

| Notebook | Langage | Niveau | Dur√©e | Emplacement | Priorit√© |
|----------|---------|--------|-------|-------------|----------|
| **00-5-ComfyUI-Local-Setup** | Python | D√©butant‚ÜíInterm√©diaire | 2-3h | `GenAI/00-GenAI-Environment/` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **00-6-Semantic-Kernel-ComfyUI** | C# | Interm√©diaire‚ÜíAvanc√© | 3-4h | `GenAI/00-GenAI-Environment/` | ‚≠ê‚≠ê‚≠ê‚≠ê |

### Objectifs P√©dagogiques Communs

1. ‚úÖ Comprendre architecture ComfyUI vs APIs cloud
2. ‚úÖ Configurer connexion service local ComfyUI + Qwen
3. ‚úÖ Cr√©er et ex√©cuter workflows basiques
4. ‚úÖ Comparer co√ªts/performances local vs cloud
5. ‚úÖ Choisir strat√©gie optimale selon cas d'usage

---

## üìì Notebook 1: ComfyUI Local Setup (Python)

### M√©tadonn√©es Notebook

```json
{
  "title": "00-5-ComfyUI-Local-Setup.ipynb",
  "path": "MyIA.AI.Notebooks/GenAI/00-GenAI-Environment/",
  "language": "Python 3.10+",
  "kernel": "python3",
  "level": "Beginner ‚Üí Intermediate",
  "duration": "2-3 hours",
  "prerequisites": [
    "Python basics",
    "HTTP requests concepts",
    "Optional: OpenRouter account"
  ],
  "learning_outcomes": [
    "Configure ComfyUI local connection",
    "Execute Qwen workflows programmatically",
    "Benchmark local vs cloud",
    "Make informed infrastructure decisions"
  ]
}
```

### Structure SDDD (15-20 Cells)

#### Cell 1: Introduction & Objectifs (Markdown)

```markdown
# üé® ComfyUI Local Setup - Bridge Local/Cloud

**Objectifs d'apprentissage:**

1. ‚úÖ Comprendre architecture ComfyUI vs APIs cloud
2. ‚úÖ Configurer connexion au service local ComfyUI + Qwen
3. ‚úÖ Cr√©er et ex√©cuter workflows basiques programmatiquement
4. ‚úÖ Comparer co√ªts/performances local vs cloud
5. ‚úÖ Choisir strat√©gie optimale selon cas d'usage

## üìä Infrastructure Disponible

| Composant | Local | Cloud |
|-----------|-------|-------|
| **Service** | ComfyUI + Qwen-Image-Edit-2509 | OpenRouter APIs |
| **GPU** | RTX 3090 (24GB) | N/A (distant) |
| **URL** | https://qwen-image-edit.myia.io | https://openrouter.ai/api/v1 |
| **Co√ªt** | $0 apr√®s setup | $0.01-0.10 / image |
| **Latence** | 5-10s | 3-10s (variable) |
| **Contr√¥le** | 100% workflows custom | API limit√©e |

## üéØ Choix Strat√©gique

| Crit√®re | Recommandation |
|---------|----------------|
| **Volume < 10 img/jour** | ‚òÅÔ∏è Cloud OpenRouter |
| **Volume > 20 img/jour** | üè† Local ComfyUI |
| **Donn√©es sensibles** | üè† Local obligatoire |
| **Tests/Prototypes** | ‚òÅÔ∏è Cloud flexible |
| **Production intensive** | üè† Local √©conomique |
```

#### Cell 2: Imports & Configuration (Code)

```python
# Cell 2: Imports et Configuration

import os
import sys
import json
import time
import requests
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
from enum import Enum
from datetime import datetime
import base64
from io import BytesIO
from PIL import Image

# Configuration mode g√©n√©ration
class ImageGenMode(Enum):
    """Mode de g√©n√©ration d'images"""
    LOCAL = "local"   # ComfyUI + Qwen local
    CLOUD = "cloud"   # OpenRouter APIs

# S√©lection mode (modifiable par utilisateur)
MODE = ImageGenMode.LOCAL

print(f"üìç Mode s√©lectionn√©: {MODE.value}")
print(f"üîß Python version: {sys.version}")
```

#### Cell 3: Configuration ComfyUI (Code)

```python
# Cell 3: Configuration ComfyUI Local

@dataclass
class ComfyUIConfig:
    """Configuration service ComfyUI local"""
    base_url: str = "https://qwen-image-edit.myia.io"
    timeout: int = 120  # secondes
    poll_interval: int = 2  # secondes entre checks
    
    def test_connection(self) -> Dict[str, Any]:
        """Teste connexion et r√©cup√®re infos syst√®me"""
        try:
            response = requests.get(
                f"{self.base_url}/system_stats",
                timeout=10
            )
            response.raise_for_status()
            
            stats = response.json()
            print("‚úÖ ComfyUI accessible")
            print(f"   Version: {stats.get('system', {}).get('comfyui_version', 'N/A')}")
            print(f"   GPU: {stats.get('devices', [{}])[0].get('name', 'N/A')}")
            print(f"   VRAM: {stats.get('devices', [{}])[0].get('vram_total', 0) / 1024:.1f} GB")
            
            return {"success": True, "stats": stats}
            
        except Exception as e:
            print(f"‚ùå Connexion √©chou√©e: {e}")
            print("   V√©rifier que ComfyUI est d√©marr√©")
            return {"success": False, "error": str(e)}

# Test connexion
config = ComfyUIConfig()
connection_test = config.test_connection()
```

#### Cell 4: Client ComfyUI Helper (Code)

```python
# Cell 4: Client ComfyUI - Classe Helper

class ComfyUIClient:
    """Client Python pour API ComfyUI"""
    
    def __init__(self, config: ComfyUIConfig):
        self.config = config
        self.base_url = config.base_url
        self.client_id = f"python-client-{int(time.time())}"
    
    def queue_prompt(self, workflow: Dict[str, Any]) -> Optional[str]:
        """Envoie workflow √† ComfyUI et retourne prompt_id"""
        try:
            payload = {
                "prompt": workflow,
                "client_id": self.client_id
            }
            
            response = requests.post(
                f"{self.base_url}/prompt",
                json=payload,
                timeout=self.config.timeout
            )
            response.raise_for_status()
            
            result = response.json()
            prompt_id = result.get("prompt_id")
            
            if prompt_id:
                print(f"‚úÖ Workflow queued: {prompt_id}")
                return prompt_id
            else:
                print(f"‚ùå Erreur: {result}")
                return None
                
        except Exception as e:
            print(f"‚ùå Erreur queue: {e}")
            return None
    
    def wait_for_completion(
        self,
        prompt_id: str,
        verbose: bool = True
    ) -> Dict[str, Any]:
        """Attend compl√©tion g√©n√©ration (polling)"""
        start_time = time.time()
        elapsed = 0
        
        while elapsed < self.config.timeout:
            try:
                # Check history
                response = requests.get(
                    f"{self.base_url}/history/{prompt_id}",
                    timeout=10
                )
                response.raise_for_status()
                history = response.json()
                
                if prompt_id in history:
                    task = history[prompt_id]
                    status = task.get("status", {})
                    
                    if status.get("completed", False):
                        elapsed = time.time() - start_time
                        if verbose:
                            print(f"‚úÖ Compl√©t√© en {elapsed:.1f}s")
                        return {
                            "success": True,
                            "duration": elapsed,
                            "outputs": task.get("outputs", {})
                        }
                    
                    if status.get("status_str") == "error":
                        error_msg = status.get("messages", ["Unknown error"])
                        print(f"‚ùå Erreur g√©n√©ration: {error_msg}")
                        return {
                            "success": False,
                            "error": error_msg
                        }
                
                # Wait before next check
                time.sleep(self.config.poll_interval)
                elapsed = time.time() - start_time
                
                if verbose and int(elapsed) % 5 == 0:
                    print(f"‚è≥ Attente... {elapsed:.0f}s / {self.config.timeout}s")
                
            except Exception as e:
                print(f"‚ùå Erreur polling: {e}")
                return {"success": False, "error": str(e)}
        
        print(f"‚è±Ô∏è Timeout apr√®s {self.config.timeout}s")
        return {"success": False, "error": "timeout"}
    
    def generate_text2image(
        self,
        prompt: str,
        negative_prompt: str = "blurry, low quality",
        width: int = 512,
        height: int = 512,
        steps: int = 20,
        cfg: float = 7.0,
        seed: int = -1,
        verbose: bool = True
    ) -> Dict[str, Any]:
        """G√©n√®re image avec workflow Qwen basique"""
        
        # Workflow JSON (architecture du document workflows)
        workflow = {
            "1": {
                "class_type": "QwenVLCLIPLoader",
                "inputs": {"model_path": "Qwen-Image-Edit-2509-FP8"}
            },
            "2": {
                "class_type": "TextEncodeQwenImageEdit",
                "inputs": {"text": prompt, "clip": ["1", 0]}
            },
            "3": {
                "class_type": "TextEncodeQwenImageEdit",
                "inputs": {"text": negative_prompt, "clip": ["1", 0]}
            },
            "4": {
                "class_type": "QwenVLEmptyLatent",
                "inputs": {
                    "width": width,
                    "height": height,
                    "batch_size": 1
                }
            },
            "5": {
                "class_type": "QwenImageSamplerNode",
                "inputs": {
                    "seed": seed if seed >= 0 else int(time.time()),
                    "steps": steps,
                    "cfg": cfg,
                    "sampler_name": "euler_ancestral",
                    "scheduler": "normal",
                    "transformer": ["1", 1],
                    "positive": ["2", 0],
                    "negative": ["3", 0],
                    "latent_image": ["4", 0]
                }
            },
            "6": {
                "class_type": "VAEDecode",
                "inputs": {
                    "samples": ["5", 0],
                    "vae": ["1", 2]
                }
            },
            "7": {
                "class_type": "SaveImage",
                "inputs": {
                    "filename_prefix": "notebook_gen",
                    "images": ["6", 0]
                }
            }
        }
        
        if verbose:
            print(f"üé® G√©n√©ration: '{prompt[:50]}...'")
            print(f"   R√©solution: {width}x{height}")
            print(f"   Steps: {steps}, CFG: {cfg}")
        
        # Queue workflow
        prompt_id = self.queue_prompt(workflow)
        if not prompt_id:
            return {"success": False, "error": "queue failed"}
        
        # Wait completion
        result = self.wait_for_completion(prompt_id, verbose)
        result["prompt_id"] = prompt_id
        
        return result

# Cr√©er client
if connection_test.get("success"):
    client = ComfyUIClient(config)
    print("‚úÖ Client ComfyUI pr√™t")
else:
    print("‚ö†Ô∏è Client non initialis√© (connexion √©chou√©e)")
    client = None
```

#### Cell 5-10: Exercices Pratiques (Code)

```python
# Cell 5: Exercice 1 - Premi√®re G√©n√©ration

if client:
    result = client.generate_text2image(
        prompt="A beautiful mountain landscape at sunset",
        steps=20,
        cfg=7.0,
        seed=42  # Fixe pour reproductibilit√©
    )
    
    if result.get("success"):
        print(f"\nüéâ Image g√©n√©r√©e avec succ√®s!")
        print(f"   Dur√©e: {result['duration']:.1f}s")
        print(f"   Prompt ID: {result['prompt_id']}")
    else:
        print(f"\n‚ùå √âchec: {result.get('error')}")
else:
    print("‚ö†Ô∏è Client non disponible")
```

```python
# Cell 6: Exercice 2 - Variation Param√®tres CFG

prompts_test = [
    "A serene mountain lake at sunrise",
    "Futuristic cityscape at night with neon lights",
    "Abstract colorful geometric pattern"
]

cfg_values = [3.0, 7.0, 12.0]

results_cfg = []

for prompt in prompts_test[:1]:  # Test 1 prompt avec 3 CFG
    for cfg in cfg_values:
        print(f"\n--- Test CFG={cfg} ---")
        result = client.generate_text2image(
            prompt=prompt,
            cfg=cfg,
            steps=20,
            verbose=False
        )
        results_cfg.append({
            "prompt": prompt,
            "cfg": cfg,
            "duration": result.get("duration", 0),
            "success": result.get("success", False)
        })

# Analyse r√©sultats
import pandas as pd
df_cfg = pd.DataFrame(results_cfg)
print("\nüìä Analyse CFG:")
print(df_cfg[["cfg", "duration", "success"]])
```

```python
# Cell 7: Exercice 3 - Benchmark Local vs Cloud

def benchmark_local(prompts: List[str]) -> Dict[str, Any]:
    """Benchmark g√©n√©ration locale"""
    results = []
    start_total = time.time()
    
    for i, prompt in enumerate(prompts):
        print(f"\n[{i+1}/{len(prompts)}] {prompt[:40]}...")
        
        start = time.time()
        result = client.generate_text2image(
            prompt=prompt,
            steps=20,
            cfg=7.0,
            verbose=False
        )
        duration = time.time() - start
        
        results.append({
            "prompt": prompt,
            "duration": duration,
            "success": result.get("success", False),
            "cost": 0.0  # Gratuit apr√®s setup
        })
    
    total_time = time.time() - start_total
    
    return {
        "mode": "local",
        "results": results,
        "total_time": total_time,
        "avg_time": total_time / len(prompts),
        "total_cost": 0.0,
        "success_rate": sum(1 for r in results if r["success"]) / len(prompts)
    }

# Test avec 3 prompts
test_prompts = [
    "A beautiful mountain landscape",
    "A futuristic cityscape at night",
    "An abstract colorful painting"
]

print("=== Benchmark Local (ComfyUI + Qwen) ===")
results_local = benchmark_local(test_prompts)

print(f"\nüìä R√©sultats Local:")
print(f"   Temps total: {results_local['total_time']:.1f}s")
print(f"   Temps moyen: {results_local['avg_time']:.1f}s/image")
print(f"   Co√ªt total: ${results_local['total_cost']:.2f}")
print(f"   Taux succ√®s: {results_local['success_rate']*100:.0f}%")
```

#### Cell 11-15: Comparaison Cloud & D√©cision (Code + Markdown)

```python
# Cell 11: Simulation Co√ªt Cloud (si pas d'API key)

def simulate_cloud_benchmark(prompts: List[str]) -> Dict[str, Any]:
    """Simule benchmark cloud (sans appel r√©el API)"""
    import random
    
    results = []
    for prompt in prompts:
        # Simulation latence r√©seau + g√©n√©ration
        duration = random.uniform(5, 12)  # 5-12s variable
        cost = 0.05  # $0.05/image (moyenne OpenRouter)
        
        results.append({
            "prompt": prompt,
            "duration": duration,
            "success": True,
            "cost": cost
        })
    
    total_time = sum(r["duration"] for r in results)
    total_cost = sum(r["cost"] for r in results)
    
    return {
        "mode": "cloud_simulation",
        "results": results,
        "total_time": total_time,
        "avg_time": total_time / len(prompts),
        "total_cost": total_cost,
        "success_rate": 1.0
    }

print("=== Benchmark Cloud (Simulation) ===")
results_cloud = simulate_cloud_benchmark(test_prompts)

print(f"\nüìä R√©sultats Cloud:")
print(f"   Temps total: {results_cloud['total_time']:.1f}s")
print(f"   Temps moyen: {results_cloud['avg_time']:.1f}s/image")
print(f"   Co√ªt total: ${results_cloud['total_cost']:.2f}")
print(f"   Taux succ√®s: {results_cloud['success_rate']*100:.0f}%")
```

```markdown
# Cell 12: Comparaison & Recommandation (Markdown)

## üìä Comparaison Local vs Cloud

| M√©trique | Local (ComfyUI) | Cloud (OpenRouter) | Gagnant |
|----------|----------------|-------------------|---------|
| **Temps moyen** | {local_avg}s | {cloud_avg}s | {winner_time} |
| **Co√ªt total** | $0.00 | ${cloud_cost} | üè† Local |
| **Co√ªt/image** | $0.00 | $0.05 | üè† Local |
| **Stabilit√©** | Contr√¥l√©e | Variable r√©seau | üè† Local |
| **Scalabilit√©** | 1 GPU limite | Illimit√©e | ‚òÅÔ∏è Cloud |
| **Confidentialit√©** | 100% priv√© | Cloud tiers | üè† Local |

## üí° Recommandation

**Pour ce batch de {n} images:**

- **√âconomie Local vs Cloud**: ${savings} (100% moins cher)
- **Temps comparable**: Local {local_avg}s vs Cloud {cloud_avg}s
- **Break-even point**: ~1000 images ($50 cloud vs $0 local)

### Arbre D√©cisionnel

```
Volume < 10 images/jour ‚Üí ‚òÅÔ∏è Cloud (flexibilit√©)
Volume > 20 images/jour ‚Üí üè† Local (√©conomie)
Donn√©es sensibles ‚Üí üè† Local obligatoire
Tests/prototypes ‚Üí ‚òÅÔ∏è Cloud (vari√©t√© mod√®les)
Production ‚Üí üè† Local (contr√¥le total)
```
```

#### Cells Finales: Conclusion & Ressources

```markdown
# Cell 15: Conclusion & Prochaines √âtapes

## ‚úÖ Objectifs Atteints

1. ‚úÖ Configuration ComfyUI local op√©rationnelle
2. ‚úÖ Client Python r√©utilisable cr√©√©
3. ‚úÖ Workflows Qwen ex√©cut√©s avec succ√®s
4. ‚úÖ Benchmark local vs cloud r√©alis√©
5. ‚úÖ D√©cision √©clair√©e infrastructure possible

## üéØ Comp√©tences Acquises

- Architecture ComfyUI et API REST
- Workflows JSON programmatiques
- Optimisation param√®tres (steps, cfg, seed)
- Analyse co√ªt/performance infrastructure
- Patterns async/polling pour g√©n√©ration

## üìö Ressources Compl√©mentaires

- **Architectures Workflows**: [`2025-10-16_12C_architectures-5-workflows-qwen.md`]
- **Taxonomie Nodes**: [`2025-10-16_12C_checkpoint-1-taxonomie-nodes-qwen.md`]
- **ComfyUI Docs**: https://github.com/comfyanonymous/ComfyUI
- **Qwen Image-Edit**: https://huggingface.co/Qwen/Qwen-Image-Edit-2509

## üöÄ Prochains Notebooks

- **02-1-Qwen-Image-Edit-2509.ipynb**: √âdition avanc√©e
- **03-1-Multi-Model-Comparison.ipynb**: Comparaison mod√®les
- **04-2-Creative-Workflows.ipynb**: Workflows cr√©atifs

## üí¨ Feedback & Questions

- Ouvrir issue GitHub: [CoursIA Issues]
- Discussion forum: [CoursIA Discussions]
```

---

## üìì Notebook 2: Semantic Kernel + ComfyUI (C#)

### M√©tadonn√©es Notebook

```json
{
  "title": "00-6-Semantic-Kernel-ComfyUI.ipynb",
  "path": "MyIA.AI.Notebooks/GenAI/00-GenAI-Environment/",
  "language": "C# (.NET 8)",
  "kernel": ".NET (C#)",
  "level": "Intermediate ‚Üí Advanced",
  "duration": "3-4 hours",
  "prerequisites": [
    "C# intermediate",
    "Semantic Kernel basics",
    "Async/await patterns",
    "REST APIs concepts"
  ],
  "learning_outcomes": [
    "Integrate ComfyUI with Semantic Kernel",
    "Create reusable SK plugins",
    "Orchestrate multi-step workflows",
    "Build production-ready image generation services"
  ]
}
```

### Structure SDDD (18-22 Cells)

#### Cell 1: Introduction (Markdown)

```markdown
# üß† Semantic Kernel + ComfyUI Integration

**Objectifs d'apprentissage:**

1. ‚úÖ Int√©grer ComfyUI comme plugin Semantic Kernel
2. ‚úÖ Cr√©er fonctions natives pour g√©n√©ration images
3. ‚úÖ Orchestrer workflows multi-√©tapes avec SK
4. ‚úÖ Impl√©menter patterns production (retry, logging, caching)
5. ‚úÖ Construire service g√©n√©ration images r√©utilisable

## üèóÔ∏è Architecture Cible

```
Semantic Kernel (Orchestrateur)
    ‚îú‚îÄ‚îÄ ComfyUIPlugin (Functions natives)
    ‚îÇ   ‚îú‚îÄ‚îÄ GenerateTextToImage
    ‚îÇ   ‚îú‚îÄ‚îÄ EditImageToImage
    ‚îÇ   ‚îî‚îÄ‚îÄ TransferStyle
    ‚îú‚îÄ‚îÄ OpenAIPlugin (Fallback cloud)
    ‚îî‚îÄ‚îÄ WorkflowOrchestratorPlugin
```

## üéØ Cas d'Usage Production

- G√©n√©ration illustrations cours automatis√©es
- Pipeline cr√©ation contenus p√©dagogiques
- Service API images pour applications √©tudiantes
- Syst√®me batch traitement images nocturne
```

#### Cell 2: Setup & Imports (Code C#)

```csharp
// Cell 2: Imports et Configuration

#r "nuget: Microsoft.SemanticKernel, 1.0.1"
#r "nuget: Microsoft.Extensions.Logging.Console, 8.0.0"
#r "nuget: System.Net.Http.Json, 8.0.0"

using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Connectors.OpenAI;
using Microsoft.Extensions.Logging;
using System.Net.Http;
using System.Net.Http.Json;
using System.Text.Json;
using System.Text.Json.Serialization;

// Configuration
var COMFYUI_BASE_URL = "https://qwen-image-edit.myia.io";
var TIMEOUT_SECONDS = 120;

Console.WriteLine("‚úÖ Imports charg√©s");
Console.WriteLine($"üìç ComfyUI URL: {COMFYUI_BASE_URL}");
```

#### Cell 3: ComfyUI Client Service (Code C#)

```csharp
// Cell 3: Service Client ComfyUI

public class ComfyUIService
{
    private readonly HttpClient _httpClient;
    private readonly ILogger _logger;
    private readonly string _baseUrl;
    
    public ComfyUIService(string baseUrl, ILogger logger)
    {
        _baseUrl = baseUrl;
        _logger = logger;
        _httpClient = new HttpClient
        {
            BaseAddress = new Uri(baseUrl),
            Timeout = TimeSpan.FromSeconds(120)
        };
    }
    
    public async Task<SystemStats?> GetSystemStatsAsync()
    {
        try
        {
            var stats = await _httpClient.GetFromJsonAsync<SystemStats>("/system_stats");
            _logger.LogInformation("‚úÖ ComfyUI accessible");
            return stats;
        }
        catch (Exception ex)
        {
            _logger.LogError($"‚ùå Connexion √©chou√©e: {ex.Message}");
            return null;
        }
    }
    
    public async Task<string?> QueuePromptAsync(Dictionary<string, object> workflow)
    {
        try
        {
            var payload = new
            {
                prompt = workflow,
                client_id = $"csharp-{DateTime.UtcNow.Ticks}"
            };
            
            var response = await _httpClient.PostAsJsonAsync("/prompt", payload);
            response.EnsureSuccessStatusCode();
            
            var result = await response.Content.ReadFromJsonAsync<QueueResponse>();
            _logger.LogInformation($"‚úÖ Workflow queued: {result?.PromptId}");
            
            return result?.PromptId;
        }
        catch (Exception ex)
        {
            _logger.LogError($"‚ùå Queue failed: {ex.Message}");
            return null;
        }
    }
    
    public async Task<GenerationResult> WaitForCompletionAsync(
        string promptId,
        int pollIntervalMs = 2000)
    {
        var startTime = DateTime.UtcNow;
        
        while ((DateTime.UtcNow - startTime).TotalSeconds < 120)
        {
            try
            {
                var history = await _httpClient.GetFromJsonAsync<Dictionary<string, TaskHistory>>(
                    $"/history/{promptId}"
                );
                
                if (history?.ContainsKey(promptId) == true)
                {
                    var task = history[promptId];
                    
                    if (task.Status?.Completed == true)
                    {
                        var duration = (DateTime.UtcNow - startTime).TotalSeconds;
                        _logger.LogInformation($"‚úÖ Compl√©t√© en {duration:F1}s");
                        
                        return new GenerationResult
                        {
                            Success = true,
                            Duration = duration,
                            PromptId = promptId,
                            Outputs = task.Outputs
                        };
                    }
                    
                    if (task.Status?.StatusStr == "error")
                    {
                        _logger.LogError($"‚ùå Erreur: {task.Status.Messages}");
                        return new GenerationResult { Success = false };
                    }
                }
                
                await Task.Delay(pollIntervalMs);
            }
            catch (Exception ex)
            {
                _logger.LogError($"‚ùå Polling error: {ex.Message}");
                return new GenerationResult { Success = false };
            }
        }
        
        _logger.LogWarning("‚è±Ô∏è Timeout apr√®s 120s");
        return new GenerationResult { Success = false };
    }
}

// DTOs
public record SystemStats(Dictionary<string, object>? System, List<object>? Devices);
public record QueueResponse([property: JsonPropertyName("prompt_id")] string? PromptId);
public record TaskHistory(TaskStatus? Status, Dictionary<string, object>? Outputs);
public record TaskStatus(bool? Completed, string? StatusStr, List<string>? Messages);
public record GenerationResult
{
    public bool Success { get; init; }
    public double Duration { get; init; }
    public string? PromptId { get; init; }
    public Dictionary<string, object>? Outputs { get; init; }
}

// Cr√©er service
var logger = LoggerFactory.Create(b => b.AddConsole()).CreateLogger<ComfyUIService>();
var comfyService = new ComfyUIService(COMFYUI_BASE_URL, logger);

// Test connexion
var stats = await comfyService.GetSystemStatsAsync();
```

#### Cell 4: Semantic Kernel Plugin (Code C#)

```csharp
// Cell 4: ComfyUI Plugin pour Semantic Kernel

using Microsoft.SemanticKernel;
using System.ComponentModel;

public class ComfyUIPlugin
{
    private readonly ComfyUIService _service;
    private readonly ILogger _logger;
    
    public ComfyUIPlugin(ComfyUIService service, ILogger logger)
    {
        _service = service;
        _logger = logger;
    }
    
    [KernelFunction, Description("Generate an image from a text prompt using Qwen")]
    public async Task<string> GenerateTextToImageAsync(
        [Description("The text prompt describing the image to generate")]
        string prompt,
        [Description("Negative prompt (things to avoid)")]
        string negativePrompt = "blurry, low quality",
        [Description("Image width in pixels")]
        int width = 512,
        [Description("Image height in pixels")]
        int height = 512,
        [Description("Number of generation steps (15-30)")]
        int steps = 20,
        [Description("CFG scale (5-12)")]
        double cfg = 7.0,
        [Description("Random seed (-1 for random)")]
        int seed = -1
    )
    {
        _logger.LogInformation($"üé® Generating: {prompt.Substring(0, Math.Min(50, prompt.Length))}...");
        
        // Build workflow (architecture from workflows doc)
        var workflow = new Dictionary<string, object>
        {
            ["1"] = new
            {
                class_type = "QwenVLCLIPLoader",
                inputs = new { model_path = "Qwen-Image-Edit-2509-FP8" }
            },
            ["2"] = new
            {
                class_type = "TextEncodeQwenImageEdit",
                inputs = new { text = prompt, clip = new[] { "1", 0 } }
            },
            ["3"] = new
            {
                class_type = "TextEncodeQwenImageEdit",
                inputs = new { text = negativePrompt, clip = new[] { "1", 0 } }
            },
            ["4"] = new
            {
                class_type = "QwenVLEmptyLatent",
                inputs = new { width, height, batch_size = 1 }
            },
            ["5"] = new
            {
                class_type = "QwenImageSamplerNode",
                inputs = new
                {
                    seed = seed >= 0 ? seed : DateTimeOffset.UtcNow.ToUnixTimeSeconds(),
                    steps,
                    cfg,
                    sampler_name = "euler_ancestral",
                    scheduler = "normal",
                    transformer = new[] { "1", 1 },
                    positive = new[] { "2", 0 },
                    negative = new[] { "3", 0 },
                    latent_image = new[] { "4", 0 }
                }
            },
            ["6"] = new
            {
                class_type = "VAEDecode",
                inputs = new { samples = new[] { "5", 0 }, vae = new[] { "1", 2 } }
            },
            ["7"] = new
            {
                class_type = "SaveImage",
                inputs = new { filename_prefix = "sk_gen", images = new[] { "6", 0 } }
            }
        };
        
        // Queue and wait
        var promptId = await _service.QueuePromptAsync(workflow);
        if (promptId == null)
            return "Error: Failed to queue workflow";
        
        var result = await _service.WaitForCompletionAsync(promptId);
        
        if (result.Success)
        {
            return $"Image generated successfully! Duration: {result.Duration:F1}s, ID: {result.PromptId}";
        }
        else
        {
            return "Error: Generation failed";
        }
    }
    
    [KernelFunction, Description("Edit an existing image with a text prompt")]
    public async Task<string> EditImageToImageAsync(
        [Description("Path to source image")]
        string imagePath,
        [Description("Edit instruction prompt")]
        string editPrompt,
        [Description("Edit strength (0.5-1.0)")]
        double editStrength = 0.75
    )
    {
        // TODO: Implement I2I workflow
        return "Image-to-Image editing (to be implemented)";
    }
}

// Cr√©er plugin
var comfyPlugin = new ComfyUIPlugin(comfyService, logger);
Console.WriteLine("‚úÖ ComfyUI Plugin cr√©√©");
```

#### Cell 5-10: Semantic Kernel Integration & Orchestration

```csharp
// Cell 5: Initialiser Semantic Kernel

var kernelBuilder = Kernel.CreateBuilder();

// Ajouter plugin ComfyUI
kernelBuilder.Plugins.AddFromObject(comfyPlugin, "ComfyUI");

// Optionnel: Ajouter OpenAI pour orchestration
// kernelBuilder.AddOpenAIChatCompletion("gpt-4", "your-api-key");

var kernel = kernelBuilder.Build();

Console.WriteLine("‚úÖ Semantic Kernel initialis√©");
Console.WriteLine($"   Plugins: {kernel.Plugins.Count()}");
Console.WriteLine($"   Functions: {kernel.Plugins.SelectMany(p => p).Count()}");
```

```csharp
// Cell 6: Test Direct Function Call

var result = await kernel.InvokeAsync(
    "ComfyUI",
    "GenerateTextToImageAsync",
    new KernelArguments
    {
        ["prompt"] = "A serene mountain landscape at sunrise",
        ["steps"] = 20,
        ["cfg"] = 7.0,
        ["seed"] = 42
    }
);

Console.WriteLine($"\nüìä R√©sultat: {result}");
```

```csharp
// Cell 7: Orchestration Multi-Step avec Prompts

var orchestrationPrompt = """
    You are an image generation orchestrator.
    
    User request: {{$request}}
    
    Steps to execute:
    1. Analyze the request and create an optimized prompt
    2. Generate the image using ComfyUI plugin
    3. Return the generation result
    
    Execute the steps now.
    """;

var orchestrationFunction = kernel.CreateFunctionFromPrompt(orchestrationPrompt);

var orchestrationResult = await kernel.InvokeAsync(
    orchestrationFunction,
    new KernelArguments
    {
        ["request"] = "Create a beautiful illustration for a machine learning course"
    }
);

Console.WriteLine($"\nüé≠ Orchestration: {orchestrationResult}");
```

---

## üìä Tableau Comparatif Notebooks

| Aspect | Python Notebook | C# Notebook |
|--------|----------------|-------------|
| **Complexit√©** | Simple ‚Üí Moyen | Moyen ‚Üí Avanc√© |
| **Dur√©e** | 2-3h | 3-4h |
| **Focus** | API REST directe | Semantic Kernel patterns |
| **Public** | Data Scientists, ML Engineers | Software Engineers, Architects |
| **Production Ready** | Prototypes rapides | Services robustes |
| **R√©utilisabilit√©** | Helper functions | SK Plugins r√©utilisables |
| **Orchestration** | Manuelle | SK automatique |
| **Error Handling** | Basique | Production (retry, logging) |

---

## ‚úÖ Checklist Design Notebooks

- [x] M√©tadonn√©es compl√®tes (titre, niveau, dur√©e)
- [x] Structure SDDD claire (15-22 cells)
- [x] Objectifs p√©dagogiques explicites
- [x] Code fonctionnel et comment√©
- [x] Exercices progressifs
- [x] Comparaison local vs cloud
- [x] Troubleshooting section
- [x] Ressources compl√©mentaires
- [x] Patterns r√©utilisables
- [x] Documentation inline

---

**Design Notebooks Compl√©t√©**: 2025-10-16 10:00 CEST  
**Statut**: ‚úÖ 2 Notebooks p√©dagogiques design√©s  
**Prochaine √âtape**: Plan adaptation 18 notebooks existants