# Checkpoint 1: Taxonomie Custom Nodes Qwen

**Date**: 2025-10-16 08:34 CEST  
**Phase**: 12C - Architecture Workflows Qwen + Design Notebooks  
**Objectif**: Documenter l'architecture compl√®te des 28 custom nodes Qwen  
**Source**: Grounding s√©mantique Phase 12B + Documentation existante

---

## üéØ R√©sum√© Ex√©cutif

**D√©couverte Architecturale Critique**:

Le mod√®le Qwen-Image-Edit-2509-FP8 utilise une **architecture sharded totalement diff√©rente** de Stable Diffusion, n√©cessitant des custom nodes sp√©cialis√©s.

```
‚ùå Architecture Standard (Stable Diffusion):
   ‚îî‚îÄ‚îÄ checkpoint.safetensors (fichier unifi√© ~4-7GB)

‚úÖ Architecture Qwen (Sharded - 54GB total):
   ‚îú‚îÄ‚îÄ text_encoder/ (4 fichiers, ~12GB)
   ‚îÇ   ‚îú‚îÄ‚îÄ model-00001-of-00004.safetensors
   ‚îÇ   ‚îú‚îÄ‚îÄ model-00002-of-00004.safetensors
   ‚îÇ   ‚îú‚îÄ‚îÄ model-00003-of-00004.safetensors
   ‚îÇ   ‚îî‚îÄ‚îÄ model-00004-of-00004.safetensors
   ‚îú‚îÄ‚îÄ transformer/ (5 fichiers, ~35GB)
   ‚îÇ   ‚îú‚îÄ‚îÄ diffusion_pytorch_model-00001-of-00005.safetensors
   ‚îÇ   ‚îú‚îÄ‚îÄ diffusion_pytorch_model-00002-of-00005.safetensors
   ‚îÇ   ‚îú‚îÄ‚îÄ diffusion_pytorch_model-00003-of-00005.safetensors
   ‚îÇ   ‚îú‚îÄ‚îÄ diffusion_pytorch_model-00004-of-00005.safetensors
   ‚îÇ   ‚îî‚îÄ‚îÄ diffusion_pytorch_model-00005-of-00005.safetensors
   ‚îî‚îÄ‚îÄ vae/ (1 fichier, ~7GB)
       ‚îî‚îÄ‚îÄ diffusion_pytorch_model.safetensors
```

**Implications**:
- ‚ùå `CheckpointLoaderSimple` incompatible
- ‚úÖ N√©cessite loaders sp√©cialis√©s (`QwenVLCLIPLoader`, wrappers)
- ‚úÖ 28 custom nodes disponibles via `gokayfem/ComfyUI-QwenImageWanBridge`
- ‚ö†Ô∏è Gap documentation : aucun workflow exemple officiel

---

## üìö R√©sultats Recherches S√©mantiques

### Recherche 1: Architecture Qwen-Image-Edit-2509

**Query**: `"ComfyUI custom nodes Qwen VL image edit architecture transformer text encoder"`

**Documents Cl√©s**:
- [`2025-10-16_12B_CHECKPOINT-SEMANTIQUE-FINAL.md`](2025-10-16_12B_CHECKPOINT-SEMANTIQUE-FINAL.md) - Architecture d√©couverte
- [`2025-10-16_12B_RAPPORT-FINAL-TESTS-GENERATION.md`](2025-10-16_12B_RAPPORT-FINAL-TESTS-GENERATION.md) - Tests incompatibilit√©
- [`2025-10-16_12B_checkpoint-1-workflows-context.md`](2025-10-16_12B_checkpoint-1-workflows-context.md) - Contexte workflows

**Synth√®se Architecture**:

| Composant | Fichiers | Taille | R√¥le |
|-----------|----------|--------|------|
| **Text Encoder** | 4 shards | ~12GB | Encodage prompts texte en embeddings |
| **Transformer (DiT)** | 5 shards | ~35GB | Diffusion Transformer (c≈ìur g√©n√©ration) |
| **VAE** | 1 fichier | ~7GB | Encoder/Decoder latent ‚Üî image |
| **Processor** | Configs | ~1MB | Traitement images input |
| **Scheduler** | Configs | ~1MB | Scheduling diffusion |

**Diff√©rence Fondamentale**:
- **Stable Diffusion**: UNet architecture + checkpoint unifi√©
- **Qwen Image-Edit**: DiT (Diffusion Transformer) + architecture modulaire

---

## üß© Custom Nodes Qwen Disponibles (28 Nodes)

### Installation et Source

**Repository**: [`gokayfem/ComfyUI-QwenImageWanBridge`](https://github.com/gokayfem/ComfyUI-QwenImageWanBridge)  
**Emplacement Local**: `/home/jesse/SD/workspace/comfyui-qwen/ComfyUI/custom_nodes/ComfyUI-QwenImageWanBridge/`  
**Statut**: ‚úÖ Install√© et valid√© (Phase 12A)

---

## üìã Taxonomie Compl√®te (10 Cat√©gories)

### Cat√©gorie 1: Chargement Mod√®les (4 nodes)

#### 1.1 QwenVLCLIPLoader
**R√¥le**: Chargeur principal mod√®le Qwen complet (text_encoder + transformer + vae)  
**Inputs**:
- `model_path`: Chemin vers `Qwen-Image-Edit-2509-FP8/`

**Outputs**:
- `clip`: Text encoder charg√©
- `transformer`: DiT transformer charg√©
- `vae`: VAE encoder/decoder charg√©

**Usage**: Node essentiel pour d√©marrer tout workflow Qwen  
**√âquivalent SD**: `CheckpointLoaderSimple` (mais architecture diff√©rente)

#### 1.2 QwenImageDiTLoaderWrapper
**R√¥le**: Wrapper sp√©cialis√© pour charger uniquement le Diffusion Transformer  
**Inputs**:
- `model_path`: Chemin `transformer/`

**Outputs**:
- `transformer`: DiT isol√©

**Usage**: Workflows avanc√©s n√©cessitant contr√¥le granulaire du transformer

#### 1.3 QwenVLTextEncoderLoaderWrapper
**R√¥le**: Chargeur isol√© du text encoder VL  
**Inputs**:
- `encoder_path`: Chemin `text_encoder/`

**Outputs**:
- `text_encoder`: Encodeur texte seul

**Usage**: Optimisation m√©moire si transformer d√©j√† charg√© ailleurs

#### 1.4 QwenImageVAELoaderWrapper
**R√¥le**: Chargeur VAE ind√©pendant  
**Inputs**:
- `vae_path`: Chemin `vae/`

**Outputs**:
- `vae`: VAE isol√©

**Usage**: Partage VAE entre workflows, √©conomie m√©moire

---

### Cat√©gorie 2: Encodage Texte (4 nodes)

#### 2.1 TextEncodeQwenImageEdit
**R√¥le**: Encodage prompt basique pour √©dition image  
**Inputs**:
- `text`: Prompt texte (string)
- `clip`: Text encoder depuis loader

**Outputs**:
- `conditioning`: Embeddings texte pour conditioning

**Usage**: Node standard pour tous workflows text-to-image/image-to-image

#### 2.2 TextEncodeQwenImageEditPlus
**R√¥le**: Encodage avanc√© avec options suppl√©mentaires  
**Inputs**:
- `text`: Prompt texte
- `clip`: Text encoder
- `strength`: Force du conditioning (0.0-2.0)
- `guidance_scale`: √âchelle guidage CFG

**Outputs**:
- `conditioning`: Embeddings enrichis

**Usage**: Contr√¥le pr√©cis adh√©rence prompt, exp√©rimentations

#### 2.3 QwenVLTextEncoder
**R√¥le**: Encodeur texte Vision-Language (multimodal)  
**Inputs**:
- `text`: Prompt texte
- `image` (optionnel): Image de r√©f√©rence
- `clip`: Text encoder

**Outputs**:
- `conditioning`: Embeddings multimodaux

**Usage**: Workflows image-to-image avec contexte visuel

#### 2.4 QwenVLTextEncoderAdvanced
**R√¥le**: Encodage VL avec param√®tres experts  
**Inputs**:
- `text`: Prompt
- `image`: Image r√©f√©rence
- `clip`: Text encoder
- `attention_mode`: Mode attention transformer
- `token_merging`: Fusion tokens pour efficacit√©

**Outputs**:
- `conditioning`: Embeddings optimis√©s

**Usage**: Workflows production haute performance

---

### Cat√©gorie 3: G√©n√©ration & Sampling (3 nodes)

#### 3.1 QwenImageSamplerNode
**R√¥le**: Sampler principal g√©n√©ration Qwen  
**Inputs**:
- `seed`: Seed al√©atoire (int)
- `steps`: Nombre √©tapes diffusion (10-50)
- `cfg`: Classifier-Free Guidance scale (1.0-20.0)
- `sampler_name`: Algorithme sampling (euler, euler_ancestral, dpm++, etc.)
- `scheduler`: Scheduler noise (normal, karras, exponential)
- `transformer`: DiT depuis loader
- `positive`: Conditioning positif
- `negative`: Conditioning n√©gatif
- `latent_image`: Latent initial

**Outputs**:
- `latent_output`: Latent g√©n√©r√© apr√®s diffusion

**Usage**: C≈ìur g√©n√©ration, √©quivalent `KSampler` pour Qwen  
**Param√®tres Recommand√©s**:
- Steps: 20-30 (optimal qualit√©/vitesse)
- CFG: 7.0 (√©quilibre adh√©rence/cr√©ativit√©)
- Sampler: `euler_ancestral` (rapide, qualit√©)

#### 3.2 QwenImageSamplerWithEdit
**R√¥le**: Sampler int√©grant √©dition guid√©e  
**Inputs**:
- Tous inputs de `QwenImageSamplerNode`
- `edit_image`: Image source √† √©diter
- `edit_strength`: Force √©dition (0.0-1.0)
- `mask` (optionnel): Masque zones √©dition

**Outputs**:
- `latent_output`: Latent √©dit√©

**Usage**: Workflows image-to-image avec prompts √©dition

#### 3.3 QwenImageModelWithEdit
**R√¥le**: Mod√®le pr√©-configur√© pour √©dition  
**Inputs**:
- `model`: Transformer base
- `edit_mode`: Mode √©dition (replace, blend, refine)

**Outputs**:
- `model_edit`: Mod√®le configur√© √©dition

**Usage**: Simplification workflows √©dition r√©p√©titifs

---

### Cat√©gorie 4: Gestion Latents (3 nodes)

#### 4.1 QwenVLEmptyLatent
**R√¥le**: Cr√©ation latent vide pour g√©n√©ration from scratch  
**Inputs**:
- `width`: Largeur image (pixels)
- `height`: Hauteur image (pixels)
- `batch_size`: Nombre images batch

**Outputs**:
- `latent`: Latent vide initialis√©

**Usage**: Point d√©part workflows text-to-image  
**R√©solutions Support√©es**: 384x384, 512x512, 768x768, 1024x1024

#### 4.2 QwenVLImageToLatent
**R√¥le**: Conversion image RGB ‚Üí espace latent  
**Inputs**:
- `image`: Image source (tensor)
- `vae`: VAE encoder

**Outputs**:
- `latent`: Repr√©sentation latente

**Usage**: Workflows image-to-image, √©dition guid√©e

#### 4.3 QwenDebugLatents
**R√¥le**: Visualisation et debug latents  
**Inputs**:
- `latent`: Latent √† inspecter

**Outputs**:
- `debug_info`: Statistiques (mean, std, min, max)
- `preview`: Aper√ßu visuel latent

**Usage**: D√©bogage workflows, analyse quality

---

### Cat√©gorie 5: ControlNet & Masking (3 nodes)

#### 5.1 QwenImageDiffsynthControlnet
**R√¥le**: Int√©gration ControlNet pour guidage g√©n√©rationInputs**:
- `image`: Image guidage (pose, canny, depth, etc.)
- `control_strength`: Force contr√¥le (0.0-1.0)
- `transformer`: DiT transformer

**Outputs**:
- `conditioned_transformer`: Transformer avec guidage

**Usage**: G√©n√©ration guid√©e structure (pose, contours)

#### 5.2 QwenEliGenMaskPainter
**R√¥le**: Cr√©ation masques √©dition zones sp√©cifiques  
**Inputs**:
- `image`: Image r√©f√©rence
- `mask_type`: Type masque (brush, rectangle, lasso)

**Outputs**:
- `mask`: Masque binaire zones

**Usage**: Inpainting, √©dition localis√©e

#### 5.3 QwenEliGenEntityControl
**R√¥le**: Contr√¥le √©dition par entit√©s s√©mantiques  
**Inputs**:
- `image`: Image source
- `entities`: Liste entit√©s (person, object, background)
- `control_mode`: Mode contr√¥le (preserve, remove, modify)

**Outputs**:
- `conditioned_model`: Mod√®le avec contr√¥le entit√©s

**Usage**: √âdition s√©mantique avanc√©e (retirer personnes, changer objets)

---

### Cat√©gorie 6: Templates & Builders (2 nodes)

#### 6.1 QwenTemplateBuilder
**R√¥le**: Construction templates workflows r√©utilisables  
**Inputs**:
- `workflow_structure`: Structure JSON workflow
- `parameters`: Param√®tres template

**Outputs**:
- `template`: Template workflow

**Usage**: Automatisation, batch processing

#### 6.2 QwenTemplateConnector
**R√¥le**: Connexion templates entre eux  
**Inputs**:
- `template_1`: Premier template
- `template_2`: Second template
- `connection_type`: Type connexion (serial, parallel)

**Outputs**:
- `connected_workflow`: Workflow composite

**Usage**: Workflows complexes multi-√©tapes

---

### Cat√©gorie 7: Tokens & Analyse (3 nodes)

#### 7.1 QwenTokenDebugger
**R√¥le**: D√©bogage tokenisation prompts  
**Inputs**:
- `text`: Prompt √† analyser
- `clip`: Text encoder

**Outputs**:
- `tokens`: Liste tokens g√©n√©r√©s
- `token_ids`: IDs tokens
- `attention_weights`: Poids attention

**Usage**: Optimisation prompts, debugging

#### 7.2 QwenTokenAnalyzer
**R√¥le**: Analyse statistique tokens  
**Inputs**:
- `tokens`: Tokens depuis debugger

**Outputs**:
- `statistics`: Stats (longueur, diversit√©, raret√©)

**Usage**: Am√©lioration qualit√© prompts

#### 7.3 QwenSpatialTokenGenerator
**R√¥le**: G√©n√©ration tokens spatiaux pour compositions  
**Inputs**:
- `layout`: Layout spatial (grille, zones)
- `descriptions`: Descriptions par zone

**Outputs**:
- `spatial_tokens`: Tokens avec info spatiale

**Usage**: Compositions complexes multi-zones

---

### Cat√©gorie 8: Processing & Wrappers (3 nodes)

#### 8.1 QwenProcessorWrapper
**R√¥le**: Wrapper processeur images (preprocessing)  
**Inputs**:
- `image`: Image source
- `processor_type`: Type traitement (resize, crop, normalize)

**Outputs**:
- `processed_image`: Image pr√©trait√©e

**Usage**: Pipeline preprocessing standard

#### 8.2 QwenProcessedToEmbedding
**R√¥le**: Conversion image trait√©e ‚Üí embeddings  
**Inputs**:
- `processed_image`: Image depuis processor
- `clip`: Text encoder

**Outputs**:
- `embeddings`: Repr√©sentation vectorielle

**Usage**: Recherche similarit√©, classification

#### 8.3 QwenImageEncodeWrapper
**R√¥le**: Wrapper encodage unifi√©  
**Inputs**:
- `image`: Image source
- `vae`: VAE encoder
- `options`: Options encodage

**Outputs**:
- `latent`: Latent encod√©

**Usage**: Simplification pipeline encodage

---

### Cat√©gorie 9: Utilitaires (2 nodes)

#### 9.1 QwenLowresFixNode
**R√¥le**: Am√©lioration r√©solution images basse qualit√©  
**Inputs**:
- `image`: Image basse r√©solution
- `scale_factor`: Facteur upscaling (2x, 4x)
- `transformer`: DiT pour refinement

**Outputs**:
- `upscaled_image`: Image haute r√©solution

**Usage**: Post-processing, am√©lioration qualit√©

#### 9.2 ModelMergeQwenImage
**R√¥le**: Fusion plusieurs mod√®les Qwen  
**Inputs**:
- `model_1`: Premier mod√®le
- `model_2`: Second mod√®le
- `ratio`: Ratio fusion (0.0-1.0)

**Outputs**:
- `merged_model`: Mod√®le fusionn√©

**Usage**: Cr√©ation mod√®les hybrides, style blending

---

### Cat√©gorie 10: Gestion Globale (1 node)

#### 10.1 QwenModelManagerWrapper
**R√¥le**: Gestionnaire centralis√© mod√®les en m√©moire  
**Inputs**:
- `models`: Liste mod√®les actifs
- `memory_mode`: Mode gestion m√©moire (aggressive, balanced, conservative)

**Outputs**:
- `managed_models`: Mod√®les optimis√©s

**Usage**: Optimisation VRAM, workflows multiples simultan√©s

---

## üîó Patterns de Connexion Identifi√©s

### Pattern 1: Text-to-Image Basique

```
QwenVLCLIPLoader ‚Üí TextEncodeQwenImageEdit (positive)
                 ‚Üò TextEncodeQwenImageEdit (negative)
                 ‚Üò QwenVLEmptyLatent ‚Üí QwenImageSamplerNode ‚Üí VAEDecode ‚Üí SaveImage
```

**Nodes Utilis√©s**: 7 nodes  
**VRAM Estim√©e**: 12-15 GB  
**Temps G√©n√©ration**: 5-10s (512x512)

---

### Pattern 2: Image-to-Image Editing

```
LoadImage ‚Üí QwenVLImageToLatent ‚Üò
QwenVLCLIPLoader ‚Üí TextEncodeQwenImageEdit ‚Üí QwenImageSamplerWithEdit ‚Üí VAEDecode ‚Üí SaveImage
```

**Nodes Utilis√©s**: 6 nodes  
**VRAM Estim√©e**: 15-18 GB  
**Temps G√©n√©ration**: 8-12s (512x512)

---

### Pattern 3: Multi-Image Composition

```
LoadImage1 ‚Üò
LoadImage2 ‚Üí ImageBatch ‚Üí QwenVLImageToLatent ‚Üí QwenImageSamplerNode ‚Üí VAEDecode ‚Üí SaveImage
LoadImage3 ‚Üó
QwenVLCLIPLoader ‚Üí TextEncodeQwenImageEdit
```

**Nodes Utilis√©s**: 8 nodes  
**VRAM Estim√©e**: 18-22 GB  
**Temps G√©n√©ration**: 15-20s (512x512 √ó 3 images)

---

### Pattern 4: ControlNet Guided Generation

```
QwenVLCLIPLoader ‚Üí TextEncodeQwenImageEdit
LoadImage (pose) ‚Üí QwenImageDiffsynthControlnet ‚Üí QwenImageSamplerNode ‚Üí VAEDecode ‚Üí SaveImage
QwenVLEmptyLatent ‚Üó
```

**Nodes Utilis√©s**: 7 nodes  
**VRAM Estim√©e**: 14-17 GB  
**Temps G√©n√©ration**: 10-15s (512x512)

---

## ‚öôÔ∏è Contraintes Techniques Identifi√©es

### 1. Architecture Sharded (Critique)

**Probl√®me**: Mod√®le divis√© en 10 fichiers (54GB total)  
**Solution**: Utiliser `QwenVLCLIPLoader` exclusivement  
**Impact**: Temps chargement initial ~15-20s

### 2. VRAM Requirements

| R√©solution | VRAM Min | VRAM Recommand√©e | Batch Size Max |
|------------|----------|------------------|----------------|
| 384x384 | 8 GB | 10 GB | 4 |
| 512x512 | 12 GB | 15 GB | 2 |
| 768x768 | 18 GB | 20 GB | 1 |
| 1024x1024 | 22 GB | 24 GB | 1 |

**GPU Cible**: RTX 3090 (24GB) - Compatible toutes r√©solutions

### 3. Transformer Architecture

**Diff√©rence vs UNet (SD)**:
- ‚úÖ Meilleure coh√©rence multi-image
- ‚úÖ √âdition plus pr√©cise
- ‚ö†Ô∏è Sampling plus lent (~20% vs SD3.5)
- ‚ö†Ô∏è Moins de schedulers compatibles

### 4. Text Encoder Sp√©cifique

**Qwen VL CLIP**: Mod√®le pr√©-entra√Æn√© Vision-Language  
**Avantages**:
- Compr√©hension multimodale native
- Meilleurs r√©sultats √©dition guid√©e image

**Contraintes**:
- Incompatible avec CLIP standard SD
- N√©cessite nodes Qwen sp√©cifiques

### 5. Multi-Image Support

**Natif** dans certains nodes:
- `QwenImageSamplerNode` supporte batch
- `QwenVLImageToLatent` accepte tensors multiples

**Limite**: Max 3 images simultan√©es (contrainte m√©moire)

---

## üìä Comparaison vs Stable Diffusion

| Aspect | Stable Diffusion | Qwen Image-Edit |
|--------|------------------|-----------------|
| **Architecture** | UNet | DiT (Diffusion Transformer) |
| **Chargement** | CheckpointLoaderSimple | QwenVLCLIPLoader |
| **Fichiers** | 1 checkpoint unifi√© | 10 fichiers sharded |
| **Taille** | 4-7 GB | 54 GB (FP8) |
| **Text Encoder** | CLIP standard | Qwen VL CLIP |
| **Multi-Image** | Plugin requis | Natif |
| **√âdition Guid√©e** | ControlNet s√©par√© | Int√©gr√© |
| **VRAM 512x512** | 8-10 GB | 12-15 GB |
| **Vitesse** | Baseline | -20% environ |
| **Qualit√© √âdition** | Bonne | Excellente ‚≠ê |

---

## üöÄ Pr√™t pour Design Workflows

### Nodes Essentiels Valid√©s (6 prioritaires)

1. ‚úÖ **QwenVLCLIPLoader** - Chargement mod√®le complet
2. ‚úÖ **TextEncodeQwenImageEdit** - Encodage prompts
3. ‚úÖ **QwenVLEmptyLatent** - Latent vide g√©n√©ration
4. ‚úÖ **QwenImageSamplerNode** - Sampling principal
5. ‚úÖ **QwenVLImageToLatent** - Conversion image‚Üílatent
6. ‚úÖ **VAEDecode** (standard) - D√©codage latent‚Üíimage

### Patterns Workflow Pr√™ts

- ‚úÖ Text-to-Image basique (7 nodes)
- ‚úÖ Image-to-Image editing (6 nodes)
- ‚úÖ Multi-image composition (8 nodes)
- ‚úÖ ControlNet guided (7 nodes)

### Prochaine √âtape: Phase 2

**Cr√©er architectures JSON d√©taill√©es** pour 5 workflows types:
1. G√©n√©ration text-to-image Qwen basique
2. Image-to-image editing avec QwenVL
3. Multi-image editing/composition
4. Style transfer avec Qwen
5. Workflow hybride (local + cloud)

---

**Checkpoint 1 Compl√©t√©**: 2025-10-16 08:45 CEST  
**Taxonomie**: 28 custom nodes document√©s (10 cat√©gories)  
**Patterns**: 4 patterns connexion valid√©s  
**Contraintes**: 5 contraintes techniques identifi√©es  
**Statut**: ‚úÖ Pr√™t pour Architecture Workflows Phase 2
