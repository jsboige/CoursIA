# Guide APIs GÃ©nÃ©ration Images - Ã‰tudiants CoursIA

**Version**: 1.0  
**Date**: 2025-10-16  
**Public**: Ã‰tudiants Master IA  
**PrÃ©requis**: Python 3.10+, bases REST API

---

## ğŸ¯ Vue d'Ensemble

CoursIA met Ã  votre disposition **2 APIs complÃ©mentaires** de gÃ©nÃ©ration d'images par IA:

| API | Cas d'usage | Force | Latence |
|-----|-------------|-------|---------|
| **Qwen Image-Edit 2.5** | Production, Ã©dition avancÃ©e | Multimodal haute qualitÃ© | 5-10s |
| **SD XL Turbo** | Prototypage rapide | Vitesse, itÃ©rations | 1-3s |
| **Z-Image Turbo (Lumina)** | GÃ©nÃ©ration ultra-rapide next-gen | QualitÃ© photorÃ©aliste + Vitesse | 2-4s |

**Recommandation workflow**:
1. ğŸš€ **Exploration** â†’ SD XL Turbo (itÃ©rations rapides)
2. ğŸ¨ **Raffinement** â†’ Qwen (qualitÃ© production)
3. ğŸ“ **Production finale** â†’ Qwen (contrÃ´le prÃ©cis)

---

## ğŸ“š Table des MatiÃ¨res

1. [API 1: Qwen Image-Edit 2.5](#api-1-qwen-image-edit-25)
2. [API 2: SD XL Turbo (Forge)](#api-2-sd-xl-turbo-forge)
3. [API 3: Z-Image Turbo (Lumina-Next)](#api-3-z-image-turbo-lumina-next)
4. [Comparaison Technique](#comparaison-technique)
5. [Exemples Pratiques](#exemples-pratiques)
6. [Troubleshooting](#troubleshooting)
7. [Ressources ComplÃ©mentaires](#ressources-complÃ©mentaires)

---

## API 1: Qwen Image-Edit 2.5

### ğŸ¯ PrÃ©sentation

**Qwen Image-Edit** est un modÃ¨le multimodal avancÃ© capable de:
- âœ… GÃ©nÃ©ration text-to-image haute qualitÃ©
- âœ… Ã‰dition d'images guidÃ©e par texte
- âœ… ComprÃ©hension contextuelle avancÃ©e
- âœ… Support multi-langues (dont franÃ§ais)

**Architecture**: ComfyUI + vLLM + Qwen-Image-Edit-2509-FP8  
**GPU**: RTX 3090 (24GB VRAM)  
**ModÃ¨le**: 54GB (quantification FP8)

### ğŸ”— AccÃ¨s

- **URL Production**: `https://qwen-image-edit.myia.io`
- **API Endpoint**: Port 8188 (WebSocket)
- **Documentation complÃ¨te**: [`docs/suivis/genai-image/phase-12-production/`](../suivis/genai-image/phase-12a-production/)

### ğŸ” Authentification (NOUVEAU - Phase 23C)

**Depuis le 2025-10-21**, l'API Qwen requiert une authentification par token Bearer pour garantir la sÃ©curitÃ© et la disponibilitÃ© du service.

#### Obtention du Token

**MÃ©thode 1 - Interface Web** :
1. AccÃ©dez Ã  https://qwen-image-edit.myia.io/login
2. Connectez-vous avec :
   - **Username** : `etudiant`
   - **Password** : `CourIA2025!`
3. Copiez le token affichÃ© aprÃ¨s connexion

**Methode 2 - Fourni par l'Enseignant** :
Contactez votre enseignant pour obtenir votre token personnel.

> **Note Technique** : ComfyUI-Login utilise une implementation particuliere ou le hash bcrypt EST le bearer token (pas le mot de passe en clair). Les tokens fournis sont donc des hashes commencant par `$2b$12$...`

#### Configuration dans les Notebooks

**Ã‰tape 1 : CrÃ©er le fichier `.env`**

```bash
cd MyIA.AI.Notebooks/GenAI/01-Images-Foundation/
cp .env.example .env
```

**Ã‰tape 2 : Ã‰diter `.env` avec votre token**

```env
# Fichier: MyIA.AI.Notebooks/GenAI/01-Images-Foundation/.env
QWEN_API_TOKEN=votre_token_copie_ici
```

**Ã‰tape 3 : Le notebook charge automatiquement le token**

```python
from dotenv import load_dotenv
import os

load_dotenv()
QWEN_API_TOKEN = os.getenv("QWEN_API_TOKEN")

# Headers d'authentification (ajoutÃ© automatiquement par ComfyUIClient)
AUTH_HEADERS = {"Authorization": f"Bearer {QWEN_API_TOKEN}"}
```

#### SÃ©curitÃ© du Token

âš ï¸ **RÃ¨gles CRITIQUES** :
- âŒ Ne JAMAIS partager votre token
- âŒ Ne JAMAIS commiter le fichier `.env` dans Git (dÃ©jÃ  dans `.gitignore`)
- âœ… Utiliser TOUJOURS le fichier `.env` pour stocker le token
- âœ… Contacter l'enseignant en cas de perte du token

**Note** : Le fichier `.env` est automatiquement ignorÃ© par Git pour votre sÃ©curitÃ©.


### ğŸ’» Exemple Python - GÃ©nÃ©ration Simple

```python
import sys
sys.path.insert(0, '../shared')
from helpers.comfyui_client import create_client

# 1. Connexion au service
client = create_client("https://qwen-image-edit.myia.io")

# 2. GÃ©nÃ©ration text-to-image
prompt_id = client.generate_text2image(
    prompt="A serene mountain landscape at sunset with a lake reflection",
    negative_prompt="blurry, low quality, distorted",
    width=1024,
    height=1024,
    steps=25,  # Plus de steps = meilleure qualitÃ©
    cfg_scale=7.5,  # Guidance (7-8 recommandÃ©)
    seed=-1  # -1 pour alÃ©atoire
)

print(f"GÃ©nÃ©ration lancÃ©e: {prompt_id}")

# 3. Attendre et rÃ©cupÃ©rer rÃ©sultat
images = client.wait_for_images(prompt_id)
print(f"âœ… {len(images)} image(s) gÃ©nÃ©rÃ©e(s)")
```

### ğŸ’» Exemple Python - Ã‰dition Image

```python
# Ã‰diter une image existante
from PIL import Image

# Charger image source
input_image = Image.open("mon_image.png")

# Ã‰dition guidÃ©e par texte
prompt_id = client.edit_image(
    image=input_image,
    prompt="Add a rainbow in the sky",
    strength=0.7,  # 0.0-1.0 (force modification)
    steps=30
)

edited_images = client.wait_for_images(prompt_id)
edited_images[0].save("image_editee.png")
```

### ğŸ“Š ParamÃ¨tres Clefs

| ParamÃ¨tre | Plage | RecommandÃ© | Impact |
|-----------|-------|------------|--------|
| `steps` | 1-50 | 20-30 | QualitÃ© (+ = meilleur mais + lent) |
| `cfg_scale` | 1-20 | 7-8 | Respect prompt (trop haut = artefacts) |
| `strength` | 0.0-1.0 | 0.6-0.8 | Force Ã©dition (Ã©dition seule) |
| `seed` | -1 ou int | -1 | ReproductibilitÃ© (-1 = alÃ©atoire) |

### âš ï¸ Limites & Conseils

**Limites**:
- â±ï¸ Latence: 5-10s par gÃ©nÃ©ration
- ğŸ–¼ï¸ RÃ©solution max: 2048x2048 (au-delÃ  = VRAM overflow)
- ğŸ”„ Pas de batch generation (1 image Ã  la fois)

**Conseils qualitÃ©**:
- ğŸ“ Prompts dÃ©taillÃ©s en anglais donnent meilleurs rÃ©sultats
- ğŸ¨ Utiliser negative prompts pour Ã©viter artefacts
- ğŸ”¢ Fixer seed pour reproductibilitÃ© expÃ©riences

**Notebook complet**: [`MyIA.AI.Notebooks/GenAI/00-GenAI-Environment/00-5-ComfyUI-Local-Test.ipynb`](../../MyIA.AI.Notebooks/GenAI/00-GenAI-Environment/00-5-ComfyUI-Local-Test.ipynb)

---

## API 2: SD XL Turbo (Forge)

### ğŸ¯ PrÃ©sentation

**SD XL Turbo** est une version optimisÃ©e de Stable Diffusion XL pour:
- âš¡ GÃ©nÃ©ration ultra-rapide (1-3 secondes)
- ğŸ¯ Prototypage et itÃ©rations rapides
- ğŸ’¾ Faible consommation VRAM (4-6GB)
- ğŸ¨ QualitÃ© standard satisfaisante

**Architecture**: Stable Diffusion WebUI Forge  
**GPU**: RTX 3090 (24GB VRAM) - GPU 1 dÃ©diÃ©  
**ModÃ¨le**: turbovisionxlSuperFastXLBasedOnNew v4.31 (~6.5GB)

### ğŸ”— AccÃ¨s

- **URL Production**: `https://turbo.stable-diffusion-webui-forge.myia.io`
- **WebUI**: Interface Gradio (browser)
- **API REST**: Endpoints Forge standard
- **Authentication**: Basic Auth (credentials fournis par enseignant)

### ğŸ’» Exemple Python - GÃ©nÃ©ration Rapide (WebUI)

```python
import requests
import base64
from io import BytesIO
from PIL import Image

# Configuration
BASE_URL = "https://turbo.stable-diffusion-webui-forge.myia.io"
# Credentials fournis par l'enseignant
AUTH = ("username", "password")

def generate_image_turbo(prompt, negative_prompt="", steps=4):
    """
    GÃ©nÃ©ration rapide avec SD XL Turbo
    Note: Steps rÃ©duits (4-8) car modÃ¨le "turbo" optimisÃ©
    """
    payload = {
        "prompt": prompt,
        "negative_prompt": negative_prompt,
        "steps": steps,  # Turbo: 4-8 steps suffisent
        "width": 1024,
        "height": 1024,
        "cfg_scale": 2.0,  # Turbo: CFG bas (1.5-3.0)
        "sampler_name": "Euler",
        "scheduler": "simple"
    }
    
    response = requests.post(
        f"{BASE_URL}/sdapi/v1/txt2img",
        json=payload,
        auth=AUTH,
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        # DÃ©coder image base64
        image_data = base64.b64decode(result['images'][0])
        image = Image.open(BytesIO(image_data))
        return image
    else:
        raise Exception(f"Erreur API: {response.status_code}")

# Utilisation
image = generate_image_turbo(
    prompt="A futuristic city at night, neon lights, cyberpunk style",
    negative_prompt="blurry, low quality",
    steps=6
)
image.save("turbo_output.png")
print("âœ… Image gÃ©nÃ©rÃ©e en ~2-3 secondes")
```

### ğŸ’» Exemple Python - Variation Rapide

```python
def generate_variations(base_prompt, variations, steps=4):
    """
    GÃ©nÃ©rer rapidement plusieurs variations d'un concept
    IdÃ©al pour exploration crÃ©ative
    """
    results = []
    
    for i, variation in enumerate(variations):
        full_prompt = f"{base_prompt}, {variation}"
        print(f"GÃ©nÃ©ration {i+1}/{len(variations)}: {variation}")
        
        image = generate_image_turbo(
            prompt=full_prompt,
            steps=steps
        )
        results.append((variation, image))
    
    return results

# Exploration rapide de styles
base = "A cozy coffee shop interior"
styles = [
    "modern minimalist design",
    "vintage rustic atmosphere", 
    "futuristic sci-fi aesthetic",
    "warm traditional style"
]

variations = generate_variations(base, styles, steps=4)

# Sauvegarder toutes les variations
for style, img in variations:
    filename = f"coffee_shop_{style.replace(' ', '_')}.png"
    img.save(filename)

print(f"âœ… {len(variations)} variations gÃ©nÃ©rÃ©es en ~10 secondes")
```

### ğŸ“Š ParamÃ¨tres Turbo SpÃ©cifiques

| ParamÃ¨tre | Turbo | Standard | Explication |
|-----------|-------|----------|-------------|
| `steps` | **4-8** | 20-50 | Turbo optimisÃ© pour peu de steps |
| `cfg_scale` | **1.5-3.0** | 7-8 | CFG bas car guidance intÃ©grÃ©e |
| `sampler` | **Euler** | DPM++/DDIM | Euler plus rapide avec Turbo |

### âš ï¸ Limites & Conseils

**Limites**:
- ğŸ¨ QualitÃ© lÃ©gÃ¨rement infÃ©rieure Ã  Qwen
- ğŸ“ Moins bon avec prompts complexes
- ğŸ”„ Pas d'Ã©dition image (txt2img seulement)

**Quand utiliser**:
- âœ… Phase exploration (tester 10+ concepts rapidement)
- âœ… Prototypage interface (placeholder images)
- âœ… Workshops/dÃ©mos temps rÃ©el
- âŒ Production finale (prÃ©fÃ©rer Qwen)

**Astuce**: GÃ©nÃ©rer avec Turbo â†’ Affiner avec Qwen (workflow hybride)

---

## API 3: Z-Image Turbo (Lumina-Next)

### ğŸ¯ PrÃ©sentation

**Z-Image Turbo** (basÃ© sur l'architecture Lumina-Next-SFT) reprÃ©sente la nouvelle gÃ©nÃ©ration de modÃ¨les rapides :
- ğŸš€ **Architecture native Diffusers** : IntÃ©gration optimisÃ©e et robuste
- ğŸ–¼ï¸ **QualitÃ© photorÃ©aliste** supÃ©rieure Ã  SD XL Turbo
- âš¡ **Vitesse impressionnante** : 2-4 secondes pour une image HD
- ğŸ”§ **ContrÃ´le prÃ©cis** : Respect strict du prompt

**Architecture**: ComfyUI + Diffusers Wrapper + Gemma 2B (Text Encoder)
**GPU**: RTX 3090 (24GB VRAM)
**ModÃ¨le**: Z-Image-Turbo (Safetensors, ~2.5GB) + Gemma-2-2B-It

### ğŸ”— AccÃ¨s

- **Via ComfyUI** : Utilise le mÃªme endpoint que Qwen (`http://localhost:8188`)
- **Workflow** : `workflow_z_image_reboot.json`

### ğŸ’» Exemple Python - Z-Image Turbo

```python
import json
from helpers.comfyui_client import create_client

# 1. Charger le workflow spÃ©cifique
# Note: Assurez-vous d'avoir le fichier JSON du workflow
with open('workflow_z_image_reboot.json', 'r') as f:
    workflow = json.load(f)

client = create_client("http://localhost:8188")

# 2. Configurer le prompt (Node ID 6 = CLIP Text Encode)
# Note: Les IDs peuvent varier selon le workflow, vÃ©rifiez le JSON
workflow["6"]["inputs"]["text"] = "A futuristic cityscape, cyberpunk style, neon lights, 8k, photorealistic"

# 3. Lancer la gÃ©nÃ©ration
try:
    print("ğŸš€ Lancement de la gÃ©nÃ©ration Z-Image...")
    prompt_id = client.queue_prompt(workflow)
    images = client.wait_for_images(prompt_id)
    
    if images:
        images[0].save("z_image_cyberpunk.png")
        print("âœ… Image sauvegardÃ©e : z_image_cyberpunk.png")
    else:
        print("âŒ Aucune image gÃ©nÃ©rÃ©e")
except Exception as e:
    print(f"âŒ Erreur : {e}")
```

---

## ğŸ“Š Comparaison Technique

### Tableau RÃ©capitulatif

| CritÃ¨re | Qwen Image-Edit | SD XL Turbo | Gagnant |
|---------|-----------------|-------------|---------|
| **Latence moyenne** | 5-10s | 1-3s | ğŸ† Turbo |
| **QualitÃ© visuelle** | â­â­â­â­â­ | â­â­â­â­ | ğŸ† Qwen |
| **VRAM utilisÃ©e** | 10-15GB | 4-6GB | ğŸ† Turbo |
| **Respect prompt** | Excellent | Bon | ğŸ† Qwen |
| **Ã‰dition images** | âœ… Oui | âŒ Non | ğŸ† Qwen |
| **Multilingue** | âœ… Oui | âš ï¸ LimitÃ© | ğŸ† Qwen |
| **ItÃ©rations/min** | 6-12 | 20-60 | ğŸ† Turbo |
| **Apprentissage** | Moyen | Facile | ğŸ† Turbo |

### Cas d'Usage RecommandÃ©s

#### Utilisez Qwen pour:
- ğŸ“š **Projets acadÃ©miques** nÃ©cessitant qualitÃ©
- ğŸ¨ **Ã‰dition fine** d'images existantes
- ğŸŒ **Prompts multilingues** (franÃ§ais, etc.)
- ğŸ“Š **Visualisations** pour prÃ©sentations
- ğŸ”¬ **Recherche** nÃ©cessitant reproductibilitÃ©

#### Utilisez SD XL Turbo pour:
- âš¡ **Brainstorming visuel** rapide
- ğŸ® **Prototypes** applications
- ğŸƒ **Workshops** temps rÃ©el
- ğŸ§ª **Tests A/B** multiples variations
- ğŸš€ **DÃ©mos** interactives

---

## ğŸš€ Exemples Pratiques

### Exemple 1: Workflow Hybride (RecommandÃ©)

```python
# Phase 1: Exploration rapide avec Turbo (2 min)
concepts = [
    "minimalist logo design",
    "geometric abstract pattern",
    "nature-inspired organic shapes"
]

best_concepts = []
for concept in concepts:
    img = generate_image_turbo(f"professional {concept}", steps=6)
    # Ã‰valuation humaine ou automatique
    best_concepts.append(img)

# Phase 2: Raffinement avec Qwen (10 min)
final_image = client.generate_text2image(
    prompt="professional minimalist logo design, clean lines, modern",
    steps=30,
    cfg_scale=7.5,
    width=1024,
    height=1024
)

print("âœ… Workflow complet: exploration + raffinement")
```

### Exemple 2: GÃ©nÃ©ration Dataset Ã‰ducatif

```python
# CrÃ©er dataset images pour classification
categories = {
    "animals": ["cat", "dog", "bird", "fish"],
    "vehicles": ["car", "bicycle", "airplane", "train"],
    "food": ["pizza", "burger", "salad", "pasta"]
}

dataset = []

for category, items in categories.items():
    for item in items:
        # GÃ©nÃ©ration rapide avec Turbo
        img = generate_image_turbo(
            prompt=f"photo of a {item}, clear background, centered",
            steps=6
        )
        dataset.append({
            "category": category,
            "item": item,
            "image": img
        })

print(f"âœ… Dataset de {len(dataset)} images crÃ©Ã© en <5 min")
```

### Exemple 3: Comparaison ModÃ¨les (Recherche)

```python
import time

test_prompts = [
    "A serene landscape with mountains",
    "Abstract geometric pattern",
    "Portrait of a scientist"
]

results = []

for prompt in test_prompts:
    # Test Turbo
    start = time.time()
    img_turbo = generate_image_turbo(prompt, steps=6)
    time_turbo = time.time() - start
    
    # Test Qwen
    start = time.time()
    prompt_id = client.generate_text2image(prompt, steps=25)
    img_qwen = client.wait_for_images(prompt_id)[0]
    time_qwen = time.time() - start
    
    results.append({
        "prompt": prompt,
        "turbo_time": time_turbo,
        "qwen_time": time_qwen,
        "speedup": time_qwen / time_turbo
    })

# Analyse
import pandas as pd
df = pd.DataFrame(results)
print(df)
print(f"Speedup moyen: {df['speedup'].mean():.1f}x")
```

---

## ğŸ”§ Troubleshooting

### ProblÃ¨mes Communs

#### âŒ Erreur "Connection timeout" (Qwen)

```python
# Solution: Augmenter timeout
client = create_client(
    "https://qwen-image-edit.myia.io",
    timeout=60  # 60 secondes au lieu de 30
)
```

#### âŒ Erreur "Unauthorized" (SD XL Turbo)

```python
# VÃ©rifier credentials
AUTH = ("votre_username", "votre_password")

# Tester connexion
response = requests.get(
    f"{BASE_URL}/sdapi/v1/sd-models",
    auth=AUTH
)
print(f"Status: {response.status_code}")  # Doit Ãªtre 200
```

#### âŒ Images floues/artefacts (Les deux)

**Qwen**:
- Augmenter `steps` (30-40)
- Ajuster `cfg_scale` (6-8)
- Ajouter negative prompt dÃ©taillÃ©

**Turbo**:
- Utiliser `steps=6` (ni trop bas ni trop haut)
- CFG entre 2.0-2.5
- Simplifier prompt (pas trop complexe)

#### âŒ "Out of memory" (VRAM)

**Qwen**:
- RÃ©duire rÃ©solution (1024x1024 â†’ 768x768)
- Attendre 30s entre gÃ©nÃ©rations

**Turbo**:
- Rare (modÃ¨le Ã©conome), vÃ©rifier autres processus GPU

### Bonnes Pratiques

1. **Gestion erreurs**:
```python
try:
    image = generate_image_turbo(prompt)
except Exception as e:
    print(f"Erreur: {e}")
    # Fallback ou retry
```

2. **Logging**:
```python
import logging
logging.basicConfig(level=logging.INFO)

logger = logging.getLogger(__name__)
logger.info(f"GÃ©nÃ©ration: {prompt}")
```

3. **Rate limiting**:
```python
import time

# Ã‰viter surcharge serveur
for prompt in prompts:
    image = generate_image_turbo(prompt)
    time.sleep(2)  # 2s entre requÃªtes
```

---

## ğŸ“š Ressources ComplÃ©mentaires

### Documentation Technique

- **Qwen Architecture**: [`docs/suivis/genai-image/phase-12-production/rapports/2025-10-16_12C_architectures-5-workflows-qwen.md`](../suivis/genai-image/phase-12a-production/rapports/2025-10-16_12C_architectures-5-workflows-qwen.md)
- **Tests Validation Qwen**: [`docs/suivis/genai-image/phase-12-production/rapports/2025-10-16_12B_RAPPORT-FINAL-TESTS-GENERATION.md`](../suivis/genai-image/phase-12a-production/rapports/2025-10-16_12B_RAPPORT-FINAL-TESTS-GENERATION.md)
- **Audit Infrastructure**: [`docs/suivis/genai-image/phase-14-audit-infrastructure/2025-10-16_AUDIT-INFRASTRUCTURE-COMPLETE.md`](../suivis/genai-image/phase-14-audit-infrastructure/2025-10-16_AUDIT-INFRASTRUCTURE-COMPLETE.md)

### Notebooks Jupyter

1. **Qwen - Tests Complets**:
   - Path: [`MyIA.AI.Notebooks/GenAI/00-GenAI-Environment/00-5-ComfyUI-Local-Test.ipynb`](../../MyIA.AI.Notebooks/GenAI/00-GenAI-Environment/00-5-ComfyUI-Local-Test.ipynb)
   - Contenu: Client Python, tests gÃ©nÃ©ration, workflows

2. **Applications Images** (Ã  adapter):
   - Path: [`MyIA.AI.Notebooks/GenAI/04-Images-Applications/`](../../MyIA.AI.Notebooks/GenAI/04-Images-Applications/)
   - Exemples: Contenu Ã©ducatif, workflows crÃ©atifs

### Code Source

- **Client ComfyUI**: [`MyIA.AI.Notebooks/GenAI/shared/helpers/comfyui_client.py`](../../MyIA.AI.Notebooks/GenAI/shared/helpers/comfyui_client.py)
- **Tests**: [`MyIA.AI.Notebooks/GenAI/tests/test_comfyui_client.py`](../../MyIA.AI.Notebooks/GenAI/tests/test_comfyui_client.py)

### Liens Externes

- **Qwen Documentation**: [Qwen-VL GitHub](https://github.com/QwenLM/Qwen-VL)
- **ComfyUI**: [ComfyUI Documentation](https://github.com/comfyanonymous/ComfyUI)
- **Stable Diffusion**: [SD WebUI Forge](https://github.com/lllyasviel/stable-diffusion-webui-forge)
- **Automatic1111 API**: [SD API Wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/API)

---

## ğŸ“ Support & Contact

### Assistance Technique

- **Documentation complÃ¨te**: Ce guide + notebooks
- **Tests de validation**: Scripts Python fournis
- **Troubleshooting**: Section dÃ©diÃ©e ci-dessus

### Contact Enseignant

Pour obtenir:
- ğŸ”‘ Credentials accÃ¨s SD XL Turbo
- ğŸ’¡ Conseils projets spÃ©cifiques
- ğŸ› Support erreurs bloquantes
- ğŸ“Š AccÃ¨s ressources supplÃ©mentaires

---

## ğŸ“ Changelog

### Version 1.0 (2025-10-16)
- âœ… Documentation initiale complÃ¨te
- âœ… Exemples Python Qwen + Turbo
- âœ… Comparaison technique dÃ©taillÃ©e
- âœ… Workflows pratiques recommandÃ©s
- âœ… Troubleshooting exhaustif

---

**Guide crÃ©Ã© par**: Ã‰quipe CoursIA  
**DerniÃ¨re mise Ã  jour**: 2025-10-16  
**ValidÃ© pour**: Production Ã©tudiants Master IA

---

## ğŸš€ Quick Start (TL;DR)

```python
# QWEN (QualitÃ©)
from helpers.comfyui_client import create_client
client = create_client("https://qwen-image-edit.myia.io")
img = client.generate_text2image("mountain sunset", steps=25)

# TURBO (Vitesse)
import requests
response = requests.post(
    "https://turbo.stable-diffusion-webui-forge.myia.io/sdapi/v1/txt2img",
    json={"prompt": "mountain sunset", "steps": 6},
    auth=("user", "pass")
)

# WORKFLOW HYBRIDE
# 1. Explorer avec Turbo (rapide)
# 2. Affiner avec Qwen (qualitÃ©)
```

**Bon dÃ©veloppement! ğŸ¨ğŸš€**
