{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Le Framework Rational Speech Act (RSA)\n",
        "\n",
        "Le langage humain repose sur l’hypothèse de **coopération** : les locuteurs tentent de fournir des informations pertinentes à l’interlocuteur ; les interlocuteurs peuvent alors raisonner **pragmatiquement** sur l’état du monde le plus probable étant donné l’énoncé choisi par le locuteur.\n",
        "\n",
        "Le **framework RSA** (Rational Speech Act) formalise ces idées à l’aide de modèles de décision et de raisonnement probabilistes. L’idée générale est :\n",
        "\n",
        "- On définit un **\"écouteur littéral\"** (*literal_listener*) qui interprète un énoncé littéralement (l’énoncé doit être vrai dans l’état).\n",
        "- On définit un **\"locuteur coopératif\"** (*speaker*) qui choisit un énoncé pour que l’écouteur littéral devine l’état.\n",
        "- On définit enfin un **\"récepteur pragmatique\"** (*pragmatic_listener*) qui se dit : « Si le locuteur a choisi cet énoncé, c’est parce qu’il voulait que l’écouteur littéral l’interprète d’une certaine manière ; donc l’état le plus probable est… ».\n",
        "\n",
        "Nous allons illustrer ce cadre RSA à travers deux exemples :\n",
        "1. Un **RSA simple** (domaines *none / some / all*), mettant en évidence une **implicature scalaire**.\n",
        "2. Un **RSA plus avancé** pour capturer l’**hyperbole** (ex. : « Ça coûte un million ! »). On modélise un **état** contenant un prix et un degré d’excitation/irritation (*arousal*), et on introduit la notion de **QUD** (Question Under Discussion) pour représenter ce que le locuteur souhaite vraiment communiquer.\n",
        "\n",
        "Nous verrons également comment prolonger ce cadre pour expliquer :\n",
        "- Les **imprécisions** numérales (ou *pragmatic halo*), ex. “Il a coûté 50 dollars” signifiant en réalité ~50.\n",
        "- L’**ironie**, en ajoutant des dimensions affectives (valence + arousal).\n",
        "\n",
        "*(Remarque : ce notebook suppose une version de Pyro postérieure à [4392d54], mais la plupart des fonctionnalités devraient marcher sur des versions récentes.)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Infrastructure pour l’inférence par recherche exhaustive\n",
        "\n",
        "[Pyro](https://pyro.ai/) est une bibliothèque de **programmation probabiliste**, construite au-dessus de PyTorch.  \n",
        "Elle permet de définir des modèles stochastiques et d'effectuer l’inférence via diverses méthodes (variationnelle, MCMC, etc.).\n",
        "\n",
        "Ici, nous utilisons une approche simplifiée basée sur la **recherche exhaustive** via `Search`, bien adaptée aux **espaces d’états restreints**.  \n",
        "Concrètement, `Search` explore toutes les trajectoires possibles, puis `HashingMarginal` regroupe les résultats pour obtenir la **distribution marginale**.\n",
        "\n",
        "### Outils utilisés :\n",
        "- `Search(fn).run(*args)`: exécute `fn` en explorant **toutes** les options possibles (jusqu’à une limite).\n",
        "- `HashingMarginal(...)`: agrège les trajectoires identiques et calcule les probabilités marginales.\n",
        "- `memoize` (`functools.lru_cache`) : met en cache les résultats pour éviter les recomputations inutiles.\n",
        "\n",
        "Ainsi, si `literal_listener(\"some\")` est appelé plusieurs fois, le résultat est directement récupéré du cache.\n",
        "\n",
        "### Limite de l’approche exhaustive\n",
        "Cette approche est idéale pour **des micro-domaines** où le nombre d’états est gérable, mais elle devient vite coûteuse si l’espace d’états grandit trop (ex. avec 100 valeurs de prix).  \n",
        "Dans ces cas, on privilégiera des méthodes d’inférence plus scalables comme MCMC ou SVI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pyro-ppl\n",
        "\n",
        "import collections\n",
        "import functools\n",
        "import queue\n",
        "import torch\n",
        "\n",
        "import pyro.distributions as dist\n",
        "import pyro.poutine as poutine\n",
        "from pyro.infer.abstract_infer import TracePosterior\n",
        "\n",
        "def memoize(fn=None, **kwargs):\n",
        "    if fn is None:\n",
        "        return lambda _fn: memoize(_fn, **kwargs)\n",
        "    return functools.lru_cache(**kwargs)(fn)\n",
        "\n",
        "class HashingMarginal(dist.Distribution):\n",
        "    \"\"\"\n",
        "    Convertit un `TracePosterior` (ensemble de traces d’exécution Pyro) en distribution marginale\n",
        "    sur la valeur de retour (ou sur certains sites Pyro spécifiques).\n",
        "    \"\"\"\n",
        "    def __init__(self, trace_dist, sites=None):\n",
        "        super().__init__()\n",
        "        self.trace_dist = trace_dist\n",
        "        if sites is None:\n",
        "            sites = \"_RETURN\"\n",
        "        self.sites = sites\n",
        "        self.has_enumerate_support = True\n",
        "\n",
        "    @memoize(maxsize=10)\n",
        "    def _dist_and_values(self):\n",
        "        vals_map = collections.OrderedDict()\n",
        "        logits_map = collections.OrderedDict()\n",
        "        for tr, logwt in zip(self.trace_dist.exec_traces, self.trace_dist.log_weights):\n",
        "            if isinstance(self.sites, str):\n",
        "                val = tr.nodes[self.sites][\"value\"]\n",
        "            else:\n",
        "                val = {s: tr.nodes[s][\"value\"] for s in self.sites}\n",
        "            if not torch.is_tensor(logwt):\n",
        "                logwt = torch.tensor(logwt)\n",
        "\n",
        "            # Clef de hachage pour le dictionnaire\n",
        "            h = self._hash_value(val)\n",
        "            if h in logits_map:\n",
        "                from pyro.distributions.util import logsumexp\n",
        "                old = logits_map[h]\n",
        "                new = logsumexp(torch.stack([old, logwt]), dim=-1)\n",
        "                logits_map[h] = new\n",
        "            else:\n",
        "                logits_map[h] = logwt\n",
        "                vals_map[h] = val\n",
        "\n",
        "        # Normalisation\n",
        "        from pyro.distributions.util import logsumexp\n",
        "        all_logits = torch.stack(list(logits_map.values()))\n",
        "        norm = logsumexp(all_logits, dim=-1)\n",
        "        final_logits = all_logits - norm\n",
        "        cat_dist = dist.Categorical(logits=final_logits)\n",
        "        return cat_dist, vals_map\n",
        "\n",
        "    def _hash_value(self, v):\n",
        "        if torch.is_tensor(v):\n",
        "            return hash(v.cpu().numpy().tobytes())\n",
        "        elif isinstance(v, dict):\n",
        "            return hash(tuple(sorted(v.items())))\n",
        "        else:\n",
        "            return hash(v)\n",
        "\n",
        "    def sample(self):\n",
        "        catd, vals_map = self._dist_and_values()\n",
        "        idx = catd.sample()\n",
        "        return list(vals_map.values())[idx]\n",
        "\n",
        "    def log_prob(self, val):\n",
        "        catd, vals_map = self._dist_and_values()\n",
        "        h = self._hash_value(val)\n",
        "        keys = list(vals_map.keys())\n",
        "        if h not in keys:\n",
        "            return torch.tensor(float(\"-inf\"))\n",
        "        idx = keys.index(h)\n",
        "        return catd.log_prob(torch.tensor([idx]))\n",
        "\n",
        "    def enumerate_support(self):\n",
        "        catd, vals_map = self._dist_and_values()\n",
        "        return list(vals_map.values())\n",
        "\n",
        "class Search(TracePosterior):\n",
        "    \"\"\"Effectue une recherche exhaustive (ou quasi) sur le modèle Pyro.\"\"\"\n",
        "    def __init__(self, model, max_tries=int(1e6), **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model = model\n",
        "        self.max_tries = max_tries\n",
        "\n",
        "    def _traces(self, *args, **kwargs):\n",
        "        q = queue.Queue()\n",
        "        q.put(poutine.Trace())\n",
        "        queue_model = poutine.queue(self.model, queue=q, max_tries=self.max_tries)\n",
        "        p = poutine.trace(queue_model)\n",
        "        while not q.empty():\n",
        "            tr = p.get_trace(*args, **kwargs)\n",
        "            yield tr, tr.log_prob_sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Décorateur `Marginal` pour créer facilement des distributions\n",
        "\n",
        "Nous définissons ci-dessous un décorateur `Marginal` qui, appliqué à une fonction stochastique Pyro (par exemple, un *listener*), renvoie **directement** la distribution marginale sur sa valeur de retour (ou sur un site `obs`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "import pyro.poutine as poutine\n",
        "import torch\n",
        "import functools\n",
        "\n",
        "def Marginal(fn):\n",
        "    \"\"\"\n",
        "    Décorateur : transforme une fonction stochastique (Pyro)\n",
        "    en distribution marginale (via Search + HashingMarginal).\n",
        "    \"\"\"\n",
        "    @functools.lru_cache(None)\n",
        "    def run_and_marginal(*args):\n",
        "        posterior = Search(fn).run(*args)\n",
        "        return HashingMarginal(posterior)\n",
        "    return run_and_marginal\n",
        "\n",
        "print(\"Pyro version =\", pyro.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Partie A : Un RSA simple (none / some / all)\n",
        "\n",
        "Nous illustrons d’abord un micro-domaine :\n",
        "- Il y a 4 objets (par exemple 4 boules) et un certain nombre peut être bleu : 0, 1, 2, 3, ou 4.\n",
        "- Le locuteur peut dire « none are blue », « some are blue », ou « all are blue ».\n",
        "\n",
        "### Priors et fonction de sens (meaning)\n",
        "1. `state_prior()` : distribution **uniforme** sur le nombre d’objets bleus (0,1,2,3,4).\n",
        "2. `utterance_prior()` : distribution **uniforme** sur les trois énoncés.\n",
        "3. `meaning(utt, n)` : renvoie True si l’énoncé `utt` est littéralement vrai pour un état où il y a `n` objets bleus.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_number = 4\n",
        "\n",
        "def state_prior():\n",
        "    # Nombre d’objets bleus, uniform 0..4\n",
        "    n = pyro.sample(\"state\", dist.Categorical(probs=torch.ones(total_number+1)/(total_number+1)))\n",
        "    return n\n",
        "\n",
        "def utterance_prior():\n",
        "    # 3 énoncés : none / some / all\n",
        "    ix = pyro.sample(\"utt\", dist.Categorical(probs=torch.ones(3)/3))\n",
        "    return [\"none\", \"some\", \"all\"][ix]\n",
        "\n",
        "meanings = {\n",
        "    \"none\": lambda n: (n == 0),\n",
        "    \"some\": lambda n: (n > 0),\n",
        "    \"all\":  lambda n: (n == total_number)\n",
        "}\n",
        "\n",
        "def meaning(utt, n):\n",
        "    return meanings[utt](n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Les définitions RSA\n",
        "\n",
        "1. **`literal_listener(u)`** impose que l’énoncé `u` soit littéralement vrai. Concrètement :\n",
        "   ```python\n",
        "   pyro.factor(\"literal\", 0.) if meaning(...) else pyro.factor(\"literal\", -9999999.)\n",
        "   ```\n",
        "\n",
        "2. **`speaker(s)`** : choisit un énoncé pour que le `literal_listener` retrouve l’état `s`. On peut pondérer la qualité de ce choix par un paramètre alpha (1.0 pour un log-softmax).\n",
        "\n",
        "3. **`pragmatic_listener(u)`** : infère l’état plausible si le locuteur a effectivement choisi l’énoncé `u`. Cela se fait en observant l’échantillonage `pyro.sample(\"speaker\", speaker(s), obs=u)`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WRONG_COST = -10.0  # pénalité quand l'énoncé est faux\n",
        "\n",
        "@Marginal\n",
        "def literal_listener(utt):\n",
        "    s = state_prior()\n",
        "    pyro.factor(\"literal_meaning\", 0. if meaning(utt, s) else WRONG_COST)\n",
        "    return s\n",
        "\n",
        "@Marginal\n",
        "def speaker(s):\n",
        "    alpha = 1.0\n",
        "    with poutine.scale(scale=torch.tensor(alpha)):\n",
        "        u = utterance_prior()\n",
        "        # On impose que le literal_listener(u) = s\n",
        "        pyro.sample(\"listener\", literal_listener(u), obs=s)\n",
        "    return u\n",
        "\n",
        "@Marginal\n",
        "def pragmatic_listener(u):\n",
        "    s = state_prior()\n",
        "    pyro.sample(\"speaker\", speaker(s), obs=u)\n",
        "    return s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Le locuteur et son degré de rationalité\n",
        "\n",
        "Dans la définition du `speaker`, on a :\n",
        "    \n",
        "    with poutine.scale(scale=torch.tensor(alpha)):\n",
        "\n",
        "Ce `poutine.scale` multiplie la **log-probabilité** de tout ce qui se passe dans ce bloc par le facteur `alpha`.  \n",
        "En pratique, cela joue le rôle d’un **tempérage** (temperature) :\n",
        "\n",
        "- Si `alpha = 1.0`, on obtient un choix \"log-softmax\" standard.\n",
        "- Si `alpha > 1.0` (ex. 5.0), le locuteur devient plus **strictement rationnel** (le meilleur énoncé est surpondéré de manière exponentielle).\n",
        "- Si `alpha < 1.0` (ex. 0.5), le locuteur est plus \"bruyant\" ou moins optimal ; il choisit parfois des énoncés suboptimaux.\n",
        "\n",
        "Vous pouvez expérimenter différentes valeurs de `alpha` pour voir l’effet sur la distribution des énoncés produits par le `speaker`, ainsi que sur la distribution inférée par le `pragmatic_listener`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualisation d’une distribution discrète\n",
        "\n",
        "Pour observer les distributions résultantes, on utilise un petit helper de plotting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_dist(d, title=None):\n",
        "    support = d.enumerate_support()\n",
        "    probs = [d.log_prob(s).exp().item() for s in support]\n",
        "    names = [str(s) for s in support]\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    width = 0.3\n",
        "    xvals = [i+1 for i in range(len(names))]\n",
        "    ax.bar([x - width/2 for x in xvals], probs, width)\n",
        "    ax.set_xticks(xvals)\n",
        "    ax.set_xticklabels(names, rotation=45, ha='right')\n",
        "    if title:\n",
        "        ax.set_title(title)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exemple : comment le *pragmatic_listener* interprète « some »\n",
        "\n",
        "On observe la distribution renvoyée par `pragmatic_listener(\"some\")`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dist_some = pragmatic_listener(\"some\")\n",
        "plot_dist(dist_some, title=\"Interprétation de 'some'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On voit que l’état « 4 bleus » devient peu probable, illustrant l’**implicature scalaire** :\n",
        "\n",
        "- Littéralement, \"some\" = \"au moins 1\". Mais pragmatiquement, le locuteur aurait probablement choisi \"all\" s’il y avait 4 bleus.\n",
        "- Donc \"some\" suggère qu’il n’y a pas 4.\n",
        "\n",
        "Vous pouvez essayer d’autres énoncés, par exemple : `plot_dist(pragmatic_listener(\"none\"))` ou `plot_dist(pragmatic_listener(\"all\"))`.\n",
        "\n",
        "\n",
        "### Interpréter les histogrammes\n",
        "\n",
        "La fonction `plot_dist(d)` affiche un histogramme :  \n",
        "- L’axe X liste les valeurs (par exemple, les états 0, 1, 2, etc.).  \n",
        "- La hauteur des barres indique la probabilité associée à chaque valeur.\n",
        "\n",
        "Exemple : pour `pragmatic_listener(\"some\")`, vous verrez des barres en face de 0, 1, 2, 3, 4. On attend à peu près zéro probabilité pour 0 (car “some” impose > 0), et une probabilité faible pour 4 (car sinon le locuteur aurait dit “all”).\n",
        "\n",
        "### Quelques exercices\n",
        "\n",
        "1. **Changer le prior** : dans le RSA simple (\"none/some/all\"), faites en sorte que la probabilité de 2 et 3 soit plus élevée que 0 et 4. Regardez comment cela modifie l’interprétation de “some”.\n",
        "2. **Jouer avec alpha** : mettez `alpha = 5.0` ou `alpha = 0.1` et observez les changements dans les choix d’énoncés du `speaker`.\n",
        "3. **Modifier le coût** dans l’exemple d’hyperbole : si vous mettez un coût très élevé pour dire un nombre exact, le locuteur préférera presque toujours les nombres arrondis (souvent interprétés comme de l’exagération ou de l’imprécision).\n",
        "4. **Nouvelle QUD** : ajoutez un QUD \"isExpensive\" (booléen) pour signifier “est-ce que ça coûte plus de 100 ?”. Voyez si la phrase “10000” devient un moyen efficace de signaler que c’est cher.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Partie B : Modéliser l’hyperbole dans le RSA\n",
        "\n",
        "## 1) Description générale\n",
        "\n",
        "Exemple :\n",
        "« Ma bouilloire m’a coûté **un million** de dollars ! »\n",
        "\n",
        "C’est bien sûr **faux** littéralement, mais commun en langage humain. Dans un RSA naïf, un locuteur **cohérent** ne peut pas prononcer un énoncé faux. Pour réconcilier cela avec l’observation de l’hyperbole, on introduit deux idées (Kao et al., 2014) :\n",
        "\n",
        "1. L’état mental que le locuteur veut transmettre inclut un **aspect affectif** (par ex. l’irritation devant un prix élevé).\n",
        "2. Le locuteur n’a pas nécessairement l’objectif de communiquer le prix exact, mais plutôt **la partie de l’état pertinente** au contexte (la QUD). Par exemple, si la QUD est « Suis-je irrité ? », dire « Ça m’a coûté un million ! » est un bon moyen de signaler que *c’est vraiment cher*.\n",
        "\n",
        "Le récepteur pragmatique, ne sachant pas quelle était la QUD, va raisonnablement conclure qu’il y a *de fortes chances* que le vrai prix soit moins que “un million”, mais que le locuteur est très irrité.\n",
        "\n",
        "On va illustrer cela avec un petit domaine discret pour le **prix** et un booléen pour l’**arousal**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Domaine : `(price, arousal)`\n",
        "\n",
        "On définit :\n",
        "- Un prior sur `price` (en prenant quelques valeurs discrètes : 50, 51, 500, 501, 1000, 1001, 5000, 5001, 10000, 10001).\n",
        "- Pour chaque prix, une probabilité (modélisant la chance d’être irrité si c’est cher).\n",
        "- L’état est alors un couple `(price, arousal)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "State = collections.namedtuple(\"State\", [\"price\", \"arousal\"])\n",
        "\n",
        "def price_prior():\n",
        "    values = [50, 51, 500, 501, 1000, 1001, 5000, 5001, 10000, 10001]\n",
        "    probs = torch.tensor([\n",
        "        0.4205, 0.3865,\n",
        "        0.0533, 0.0538,\n",
        "        0.0223, 0.0211,\n",
        "        0.0112, 0.0111,\n",
        "        0.0083, 0.0120\n",
        "    ])\n",
        "    ix = pyro.sample(\"price\", dist.Categorical(probs=probs))\n",
        "    return values[ix]\n",
        "\n",
        "def arousal_prior(price):\n",
        "    # plus le prix est élevé, plus on a de chance d’être irrité\n",
        "    # (valeurs de Kao et al.)\n",
        "    d = {\n",
        "        50: 0.3173,\n",
        "        51: 0.3173,\n",
        "        500: 0.7920,\n",
        "        501: 0.7920,\n",
        "        1000: 0.8933,\n",
        "        1001: 0.8933,\n",
        "        5000: 0.9524,\n",
        "        5001: 0.9524,\n",
        "        10000: 0.9864,\n",
        "        10001: 0.9864\n",
        "    }\n",
        "    val = pyro.sample(\"arousal\", dist.Bernoulli(d[price])).item()\n",
        "    return (val == 1)\n",
        "\n",
        "def state_prior_h():\n",
        "    p = price_prior()\n",
        "    a = arousal_prior(p)\n",
        "    return State(price=p, arousal=a)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Les QUD : \"price\", \"arousal\" ou les deux\n",
        "\n",
        "La QUD (*Question Under Discussion*) représente l’information que le locuteur souhaite vraiment transmettre. Exemples :\n",
        "- **price** : « je veux juste faire comprendre la valeur du prix »\n",
        "- **arousal** : « je veux juste faire comprendre que je suis très irrité »\n",
        "- **priceArousal** : « je veux communiquer à la fois le prix et le fait que je suis irrité »\n",
        "\n",
        "Nous définissons un prior uniforme sur ces 3 QUD, et trois fonctions qui projettent un état `(price, arousal)` sur la dimension choisie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def qud_is_expensive(st):\n",
        "    # Renvoie True si le prix est > 100\n",
        "    return st.price > 100\n",
        "\n",
        "qud_fns = {\n",
        "    \"price\":         lambda st: State(price=st.price, arousal=None),\n",
        "    \"arousal\":       lambda st: State(price=None, arousal=st.arousal),\n",
        "    \"priceArousal\":  lambda st: State(price=st.price, arousal=st.arousal),\n",
        "    \"isExpensive\":   qud_is_expensive   # Nouvelle QUD\n",
        "}\n",
        "\n",
        "def qud_prior():\n",
        "    keys = list(qud_fns.keys())\n",
        "    ix = pyro.sample(\"qud\", dist.Categorical(probs=torch.ones(len(keys)) / len(keys)))\n",
        "    return keys[ix]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Les énoncés possibles = un nombre (p. ex. 50, 51, 500, ...)\n",
        "\n",
        "On prend un prior **uniforme** sur ces 10 valeurs d’énoncés. Littéralement, dire « 500 » signifie \"le prix est 500\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def utterance_prior_h():\n",
        "    utts = [50, 51, 500, 501, 1000, 1001, 5000, 5001, 10000, 10001]\n",
        "    ix = pyro.sample(\"utt_h\", dist.Categorical(probs=torch.ones(len(utts))/len(utts)))\n",
        "    return utts[ix]\n",
        "\n",
        "def meaning_h(utt, price):\n",
        "    # littéralement, dire utt = price\n",
        "    return (utt == price)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Définitions RSA + projection\n",
        "\n",
        "Pour modéliser la transmission de l’information *pertinente* à la QUD, on procède ainsi :\n",
        "1. On définit `literal_listener_h(utt)`, qui impose que `price == utt`.\n",
        "2. On définit une fonction *project(d, qud)* qui projette une distribution d’états `d` sur la QUD choisie.\n",
        "3. Le *speaker_h(st, qud)* pioche un énoncé `utt` (selon `utterance_prior_h`) et s’assure que, **une fois compris littéralement**, cela permette de transmettre la bonne valeur sur la QUD.\n",
        "4. Le *pragmatic_listener_h(utt)* ne sait pas la QUD, donc il échantillonne `qud` selon `qud_prior()`, puis regarde comment le locuteur aurait pu produire `utt`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@Marginal\n",
        "def project(d, qud):\n",
        "    \"\"\"Projection d’une distribution d’états sur la QUD\"\"\"\n",
        "    v = pyro.sample(\"proj\", d)\n",
        "    return qud_fns[qud](v)\n",
        "\n",
        "@Marginal\n",
        "def literal_listener_h(utt):\n",
        "    st = state_prior_h()\n",
        "    pyro.factor(\"literal_h\", 0. if meaning_h(utt, st.price) else -9999999.)\n",
        "    return st\n",
        "\n",
        "@Marginal\n",
        "def speaker_h(st, qud):\n",
        "    alpha = 1.\n",
        "    qudValue = qud_fns[qud](st)\n",
        "    with poutine.scale(scale=torch.tensor(alpha)):\n",
        "        utt = utterance_prior_h()\n",
        "        lit_marg = literal_listener_h(utt)\n",
        "        # On projette sur la QUD pour voir si ça correspond\n",
        "        proj_dist = project(lit_marg, qud)\n",
        "        pyro.sample(\"listener\", proj_dist, obs=qudValue)\n",
        "    return utt\n",
        "\n",
        "@Marginal\n",
        "def pragmatic_listener_h(utt):\n",
        "    st = state_prior_h()\n",
        "    q = qud_prior()\n",
        "    sp = speaker_h(st, q)\n",
        "    pyro.sample(\"speaker_obs\", sp, obs=utt)\n",
        "    return st\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Exemple : l’énoncé « 10000 » (hyperbole)\n",
        "\n",
        "Imaginons que nous observions le locuteur disant « Ça coûte 10.000 ». La probabilité a priori que le prix soit vraiment 10000 n’est pas négligeable, mais c’est plutôt rare.\n",
        "\n",
        "En revanche, s’il voulait juste exprimer **son irritation** (QUD=\"arousal\"), alors dire \"10.000\" est un moyen d’être informatif sur le fait que le locuteur est outré. Le *pragmatic_listener* va donc juger plus probable que le prix soit inférieur à 10.000, mais que l’arousal est haut.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_10000 = pragmatic_listener_h(10000)\n",
        "sup_10000 = d_10000.enumerate_support()\n",
        "probs_10000 = [d_10000.log_prob(s).exp().item() for s in sup_10000]\n",
        "for s, p in zip(sup_10000, probs_10000):\n",
        "    print(f\"Etat={s}  -> prob={p:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On devrait voir que **plusieurs** états (notamment ceux avec un prix plus bas mais arousal=TRUE) récoltent une probabilité appréciable, illustrant l’usage hyperbolique.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Pragmatic Halo : l’imprécision numérale\n",
        "\n",
        "« J’ai payé 50 dollars » peut vouloir dire que le prix exact est 50 ou **à peu près** 50. Mais dire « 51 » implique une précision plus stricte. C’est ce que certains appellent le **pragmatic halo** ou slack.\n",
        "\n",
        "Pour modéliser cela, on peut :\n",
        "1. Ajouter une QUD \"approxPrice\" qui arrondit le prix.\n",
        "2. Définir un **coût** plus bas pour un nombre \"rond\" (ex. 50, 500, 1000, 5000, 10000), et un coût plus élevé pour un nombre précis (51, 501, …).\n",
        "\n",
        "Ensuite, le locuteur a tendance (via le paramètre alpha) à choisir l’énoncé de plus haut *utility* = *log(prob d’être correct) - coût*.\n",
        "\n",
        "### Extension du code\n",
        "On modifie :\n",
        "- Les QUD pour ajouter `\"approxPrice\"`.\n",
        "- Une fonction `utterance_cost(u)` plus élevée si *u* est un nombre précis plutôt qu’arrondi.\n",
        "- Le prior sur les énoncés `utterance_prior()` devient un *Categorical(logits=...)* dépendant du coût.\n",
        "\n",
        "Puis on peut définir le *speaker* et le *pragmatic_listener* de la même façon.\n",
        "On verra alors :\n",
        "- Dire \"50\" peut être interprété (par le pragmatic_listener) comme **à peu près 50**.\n",
        "- Dire \"51\" sera interprété plus strictement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# On définit pour arrondir un nombre au multiple de 10\n",
        "def approx(x, b=10.):\n",
        "    div = float(x)/b\n",
        "    # arrondi simple\n",
        "    rounded = int(div) + 1 if (div - int(div)) >= 0.5 else int(div)\n",
        "    return int(b) * rounded\n",
        "\n",
        "# On enrichit qud_fns avec 2 nouvelles QUD \"approxPrice\" et \"approxPriceArousal\"\n",
        "qud_fns_extended = {\n",
        "    \"price\":              lambda st: State(price=st.price, arousal=None),\n",
        "    \"arousal\":            lambda st: State(price=None, arousal=st.arousal),\n",
        "    \"priceArousal\":       lambda st: State(price=st.price, arousal=st.arousal),\n",
        "    \"approxPrice\":        lambda st: State(price=approx(st.price), arousal=None),\n",
        "    \"approxPriceArousal\": lambda st: State(price=approx(st.price), arousal=st.arousal)\n",
        "}\n",
        "\n",
        "def qud_prior_extended():\n",
        "    keys = list(qud_fns_extended.keys())\n",
        "    ix = pyro.sample(\"qud\", dist.Categorical(probs=torch.ones(len(keys))/len(keys)))\n",
        "    return keys[ix]\n",
        "\n",
        "def utterance_cost(u):\n",
        "    # coût = 0 si c’est un multiple de 10, sinon plus élevé\n",
        "    # (valeurs arbitraires)\n",
        "    return 0.0 if (approx(u)==u) else 10.0\n",
        "\n",
        "def utterance_prior_with_cost():\n",
        "    utts = [50, 51, 500, 501, 1000, 1001, 5000, 5001, 10000, 10001]\n",
        "    costs = [utterance_cost(u) for u in utts]\n",
        "    # On convertit en logits = -coût\n",
        "    logits = [-c for c in costs]\n",
        "    ix = pyro.sample(\"utt_h2\", dist.Categorical(logits=torch.tensor(logits)))\n",
        "    return utts[ix]\n",
        "\n",
        "@Marginal\n",
        "def literal_listener_h2(utt):\n",
        "    st = state_prior_h()\n",
        "    # impose price=utt\n",
        "    pyro.factor(\"literal_h2\", 0. if (utt == st.price) else -9999999.)\n",
        "    return st\n",
        "\n",
        "@Marginal\n",
        "def project2(d, qud):\n",
        "    v = pyro.sample(\"proj2\", d)\n",
        "    return qud_fns_extended[qud](v)\n",
        "\n",
        "@Marginal\n",
        "def speaker_h2(st, qud):\n",
        "    alpha = 1.\n",
        "    qudValue = qud_fns_extended[qud](st)\n",
        "    with poutine.scale(scale=torch.tensor(alpha)):\n",
        "        utt = utterance_prior_with_cost()\n",
        "        lit_marg = literal_listener_h2(utt)\n",
        "        # proj\n",
        "        proj_dist = project2(lit_marg, qud)\n",
        "        pyro.sample(\"listener2\", proj_dist, obs=qudValue)\n",
        "    return utt\n",
        "\n",
        "@Marginal\n",
        "def pragmatic_listener_h2(utt):\n",
        "    st = state_prior_h()\n",
        "    q = qud_prior_extended()\n",
        "    sp = speaker_h2(st, q)\n",
        "    pyro.sample(\"speaker_obs2\", sp, obs=utt)\n",
        "    return st\n",
        "\n",
        "# Optionnel : si on veut juste la distribution sur le price (marginalisant le arousal)\n",
        "@Marginal\n",
        "def pragmatic_listener_price_marginal(utt):\n",
        "    return pyro.sample(\"pl_price\", pragmatic_listener_h2(utt)).price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Illustration : \"50\" vs \"51\"\n",
        "\n",
        "On compare la distribution *pragmatique* sur le **prix** lorsque le locuteur dit \"50\" ou \"51\". On s’attend à voir un effet d’**halo pragmatique** :\n",
        "- \"50\" peut facilement correspondre à un prix de 50 ou 51 (ou 52, etc.) si la QUD est \"approxPrice\".\n",
        "- \"51\" est plus coûteux à dire et donc sera choisi plus volontiers si le prix est **vraiment** 51.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_dist(pragmatic_listener_price_marginal(50), title=\"Interprétation de '50'\")\n",
        "plot_dist(pragmatic_listener_price_marginal(51), title=\"Interprétation de '51'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On observe que l’énoncé \"50\" va regrouper de la masse de probabilité sur \"env. 50\", tandis que \"51\" exclut la plupart des autres valeurs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice : Étendre le halo pragmatique\n",
        "\n",
        "On a défini une fonction d’approximation :\n",
        "\n",
        "    def approx(x, b=10.):\n",
        "        # arrondir x au multiple de b\n",
        "\n",
        "Idée : créer une deuxième version qui arrondit au multiple de 100, par exemple :\n",
        "\n",
        "    def approx100(x):\n",
        "        return <...>\n",
        "\n",
        "Puis ajoutez une nouvelle QUD, par exemple \"approxPrice100\", qui projette le price en arrondissant au multiple de 100.  \n",
        "Incorporez cette nouvelle QUD dans `qud_fns_extended` et `qud_prior_extended`.  \n",
        "\n",
        "Comparez alors :\n",
        "- L’interprétation de \"1000\" sous la QUD \"approxPrice\" (arrondi au multiple de 10)  \n",
        "- L’interprétation de \"1000\" sous la QUD \"approxPrice100\" (arrondi au multiple de 100)\n",
        "\n",
        "Vous devriez voir encore plus de souplesse pour la QUD arrondie au multiple de 100, créant un \"halo\" plus grand autour de 1000.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Remarque : Ironie et affect plus complexe\n",
        "\n",
        "Dans l’exemple hyperbole, on a supposé un **affect** unidimensionnel : arousal = True/False. En réalité, on peut modéliser un espace en deux dimensions : (valence, arousal). L’étude de Kao et Goodman (2015) montre que cela permet de capturer de nouveaux phénomènes comme l’**ironie** : dire un énoncé joyeux quand on est en réalité en colère, etc.\n",
        "\n",
        "Le cadre RSA est donc **extrêmement flexible** pour modéliser toutes sortes d’usages non littéraux (hyperbole, ironie, imprécision, litotes, métaphores, etc.), du moment qu’on formalise :\n",
        "- l’**état** (incluant possiblement l’affect),\n",
        "- la **QUD** (ou l’aspect pertinent de l’état),\n",
        "- un **coût** (ou prior) sur les énoncés,\n",
        "- un **paramètre** alpha pour la “rationalité” du choix du locuteur.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion générale\n",
        "\n",
        "Le RSA (Rational Speech Act) modélise la coopération dans le langage :\n",
        "- Le **locuteur** choisit un énoncé pour être informatif (selon la QUD et son coût).\n",
        "- L’**écouteur** infère l’état qui rendrait cet énoncé le plus probable, \n",
        "  en supposant un locuteur rationnel.\n",
        "\n",
        "Cela permet d’expliquer :\n",
        "- Les **implicatures** (ex. « some » => « pas all »),\n",
        "- Les **hyperboles** (« un million ! » => forte irritation, même si littéralement faux),\n",
        "- Les **imprécisions** numérales (« 50 » => ~50, quand préciser 51 a un coût plus grand),\n",
        "- Voire l’**ironie** (si on modélise l’affect, ex. valence + arousal).\n",
        "\n",
        "## Perspectives\n",
        "\n",
        "- Pour un **grand** domaine, l’approche exhaustive (`Search`) est rapidement inapplicable ; on passerait à des méthodes MCMC ou d’inférence variationnelle.\n",
        "- Le RSA peut aussi s’étendre à des **dialogues** multi-tours, ou intégrer des aspects plus complexes (métaphores, contextes multimodaux, etc.).\n",
        "\n",
        "**Références :**\n",
        "- [Kao et al., 2014] « Nonliteral number words » (*Cognitive Psychology*).\n",
        "- [Kao & Goodman, 2015] « Formalizing the pragmatics of metaphor understanding ».\n",
        "- [Frank & Goodman, 2012] « Predicting pragmatic reasoning in language games ».\n",
        "- [Stanford Computation & Cognition Lab](https://langcog.stanford.edu/) pour en savoir plus.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
