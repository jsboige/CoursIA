{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer-9-Topic-Models : Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "**Serie** : Programmation Probabiliste avec Infer.NET (9/12)  \n",
    "**Duree estimee** : 60 minutes  \n",
    "**Prerequis** : Infer-8-Model-Selection\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "- Comprendre le topic modeling et LDA\n",
    "- Implementer la structure documents-topics-mots\n",
    "- Utiliser les distributions Dirichlet pour les melanges\n",
    "- Inferer les topics a partir d'un corpus\n",
    "\n",
    "---\n",
    "\n",
    "## Navigation\n",
    "\n",
    "| Precedent | Suivant |\n",
    "|-----------|--------|\n",
    "| [Infer-8-Model-Selection](Infer-8-Model-Selection.ipynb) | [Infer-10-Crowdsourcing](Infer-10-Crowdsourcing.ipynb) |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.ML.Probabilistic\"\n",
    "#r \"nuget: Microsoft.ML.Probabilistic.Compiler\"\n",
    "\n",
    "using Microsoft.ML.Probabilistic;\n",
    "using Microsoft.ML.Probabilistic.Distributions;\n",
    "using Microsoft.ML.Probabilistic.Utilities;\n",
    "using Microsoft.ML.Probabilistic.Math;\n",
    "using Microsoft.ML.Probabilistic.Models;\n",
    "using Microsoft.ML.Probabilistic.Algorithms;\n",
    "using Microsoft.ML.Probabilistic.Compiler;\n",
    "\n",
    "Console.WriteLine(\"Infer.NET pret !\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction au Topic Modeling\n",
    "\n",
    "### Probleme\n",
    "\n",
    "Etant donne un corpus de documents, decouvrir les **themes latents** (topics) et la composition de chaque document.\n",
    "\n",
    "### Applications\n",
    "\n",
    "- Organisation automatique de documents\n",
    "- Recommandation de contenu\n",
    "- Analyse de tendances\n",
    "- Recherche semantique\n",
    "\n",
    "### Representation Bag-of-Words\n",
    "\n",
    "Un document est represente par le compte de chaque mot, ignorant l'ordre.\n",
    "\n",
    "```\n",
    "\"Le chat mange la souris\" -> {le: 1, chat: 1, mange: 1, la: 1, souris: 1}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Structure LDA\n",
    "\n",
    "### Modele generatif\n",
    "\n",
    "Pour chaque document d :\n",
    "1. Tirer la distribution de topics : $\\theta_d \\sim \\text{Dirichlet}(\\alpha)$\n",
    "2. Pour chaque mot w dans d :\n",
    "   - Tirer un topic : $z \\sim \\text{Discrete}(\\theta_d)$\n",
    "   - Tirer un mot : $w \\sim \\text{Discrete}(\\phi_z)$\n",
    "\n",
    "Pour chaque topic k :\n",
    "- $\\phi_k \\sim \\text{Dirichlet}(\\beta)$ : distribution sur le vocabulaire\n",
    "\n",
    "### Schema\n",
    "\n",
    "```\n",
    "                alpha\n",
    "                  |\n",
    "                  v\n",
    "              theta[d]     (distribution topics par document)\n",
    "                  |\n",
    "                  v\n",
    "               z[d,n]      (topic du mot n dans doc d)\n",
    "                  |\n",
    "                  v\n",
    "               w[d,n]  <-- phi[z]  <-- beta\n",
    "          (mot observe)   (dist mots par topic)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementation LDA Simplifiee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Donnees : corpus synthetique\n",
    "// Vocabulaire : [sport, equipe, match, politique, election, vote, musique, concert, artiste]\n",
    "string[] vocabulaire = { \"sport\", \"equipe\", \"match\", \"politique\", \"election\", \"vote\", \"musique\", \"concert\", \"artiste\" };\n",
    "int vocabSize = vocabulaire.Length;\n",
    "int numTopics = 3;  // Sport, Politique, Musique\n",
    "\n",
    "// Documents (indices des mots)\n",
    "int[][] documents = {\n",
    "    new[] { 0, 1, 2, 0, 2 },           // Doc 1 : sport\n",
    "    new[] { 3, 4, 5, 4, 3 },           // Doc 2 : politique\n",
    "    new[] { 6, 7, 8, 7, 6 },           // Doc 3 : musique\n",
    "    new[] { 0, 1, 3, 4, 0 },           // Doc 4 : sport + politique\n",
    "    new[] { 6, 7, 0, 1, 8 },           // Doc 5 : musique + sport\n",
    "    new[] { 2, 2, 1, 0, 2 },           // Doc 6 : sport\n",
    "    new[] { 5, 4, 3, 5, 4 }            // Doc 7 : politique\n",
    "};\n",
    "\n",
    "int numDocs = documents.Length;\n",
    "\n",
    "Console.WriteLine(\"=== Corpus ===\");\n",
    "for (int d = 0; d < numDocs; d++)\n",
    "{\n",
    "    string mots = string.Join(\", \", documents[d].Select(i => vocabulaire[i]));\n",
    "    Console.WriteLine($\"Doc {d+1} : {mots}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Modele LDA simplifie (pour un seul document)\n",
    "\n",
    "// Prior sur les topics (symetrique)\n",
    "double[] alphaPrior = Enumerable.Repeat(1.0, numTopics).ToArray();\n",
    "\n",
    "// Prior sur les mots par topic (symetrique)\n",
    "double[] betaPrior = Enumerable.Repeat(1.0, vocabSize).ToArray();\n",
    "\n",
    "// Distribution des mots par topic (phi)\n",
    "Range topicRange = new Range(numTopics).Named(\"topic\");\n",
    "Range vocabRange = new Range(vocabSize).Named(\"vocab\");\n",
    "\n",
    "VariableArray<Vector> phi = Variable.Array<Vector>(topicRange).Named(\"phi\");\n",
    "phi[topicRange] = Variable.Dirichlet(new Dirichlet(betaPrior)).ForEach(topicRange);\n",
    "\n",
    "Console.WriteLine(\"Variables LDA definies.\");\n",
    "Console.WriteLine($\"  Nombre de topics : {numTopics}\");\n",
    "Console.WriteLine($\"  Taille vocabulaire : {vocabSize}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Inference pour un document\n",
    "int docIndex = 0;  // Premier document (sport)\n",
    "int[] docWords = documents[docIndex];\n",
    "int numWordsInDoc = docWords.Length;\n",
    "\n",
    "// Distribution de topics pour ce document\n",
    "Variable<Vector> theta = Variable.Dirichlet(new Dirichlet(alphaPrior)).Named(\"theta\");\n",
    "\n",
    "Range wordRange = new Range(numWordsInDoc).Named(\"word\");\n",
    "VariableArray<int> wordObs = Variable.Array<int>(wordRange).Named(\"wordObs\");\n",
    "VariableArray<int> topicAssign = Variable.Array<int>(wordRange).Named(\"topicAssign\");\n",
    "\n",
    "using (Variable.ForEach(wordRange))\n",
    "{\n",
    "    topicAssign[wordRange] = Variable.Discrete(theta);\n",
    "    using (Variable.Switch(topicAssign[wordRange]))\n",
    "    {\n",
    "        wordObs[wordRange] = Variable.Discrete(phi[topicAssign[wordRange]]);\n",
    "    }\n",
    "}\n",
    "\n",
    "wordObs.ObservedValue = docWords;\n",
    "\n",
    "InferenceEngine moteurLDA = new InferenceEngine(new VariationalMessagePassing());\n",
    "moteurLDA.Compiler.CompilerChoice = CompilerChoice.Roslyn;\n",
    "\n",
    "Dirichlet thetaPost = moteurLDA.Infer<Dirichlet>(theta);\n",
    "\n",
    "Console.WriteLine($\"\\n=== Inference pour Doc {docIndex + 1} ===\");\n",
    "Console.WriteLine($\"Mots : {string.Join(\", \", docWords.Select(i => vocabulaire[i]))}\\n\");\n",
    "Console.WriteLine($\"Distribution de topics (theta) :\");\n",
    "Vector thetaMean = thetaPost.GetMean();\n",
    "for (int k = 0; k < numTopics; k++)\n",
    "{\n",
    "    Console.WriteLine($\"  Topic {k+1} : {thetaMean[k]:F3}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LDA sur Corpus Complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Inference simplifiee document par document\n",
    "\n",
    "Console.WriteLine(\"=== LDA sur corpus complet ===\");\n",
    "Console.WriteLine();\n",
    "\n",
    "// Distribution des mots par topic (initialisation supervisee pour demo)\n",
    "// Topic 0 : Sport (mots 0, 1, 2)\n",
    "// Topic 1 : Politique (mots 3, 4, 5)\n",
    "// Topic 2 : Musique (mots 6, 7, 8)\n",
    "\n",
    "for (int d = 0; d < numDocs; d++)\n",
    "{\n",
    "    int[] dWords = documents[d];\n",
    "    int nWords = dWords.Length;\n",
    "    \n",
    "    // Comptage simple des mots par categorie\n",
    "    int countSport = dWords.Count(w => w <= 2);\n",
    "    int countPolitique = dWords.Count(w => w >= 3 && w <= 5);\n",
    "    int countMusique = dWords.Count(w => w >= 6);\n",
    "    double total = countSport + countPolitique + countMusique + 0.001;\n",
    "    \n",
    "    Console.WriteLine($\"Doc {d+1} : Sport={countSport/total:F2}, Politique={countPolitique/total:F2}, Musique={countMusique/total:F2}\");\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"\\n(Proportions basees sur les mots observes)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation des Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Distribution phi (mots par topic) - simulee\n",
    "\n",
    "double[,] phiSimule = {\n",
    "    // Topic Sport\n",
    "    { 0.30, 0.30, 0.30, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01 },\n",
    "    // Topic Politique\n",
    "    { 0.02, 0.02, 0.02, 0.30, 0.30, 0.30, 0.02, 0.01, 0.01 },\n",
    "    // Topic Musique\n",
    "    { 0.02, 0.01, 0.01, 0.02, 0.02, 0.02, 0.30, 0.30, 0.30 }\n",
    "};\n",
    "\n",
    "string[] topicNames = { \"Sport\", \"Politique\", \"Musique\" };\n",
    "\n",
    "Console.WriteLine(\"=== Distribution Mots par Topic (phi) ===\");\n",
    "Console.WriteLine();\n",
    "\n",
    "for (int k = 0; k < numTopics; k++)\n",
    "{\n",
    "    Console.WriteLine($\"Topic {k+1} ({topicNames[k]}) :\");\n",
    "    \n",
    "    // Top mots\n",
    "    var topMots = Enumerable.Range(0, vocabSize)\n",
    "        .Select(v => (mot: vocabulaire[v], prob: phiSimule[k, v]))\n",
    "        .OrderByDescending(x => x.prob)\n",
    "        .Take(3);\n",
    "    \n",
    "    foreach (var (mot, prob) in topMots)\n",
    "    {\n",
    "        Console.WriteLine($\"  {mot,-12} : {prob:F2}\");\n",
    "    }\n",
    "    Console.WriteLine();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction sur Nouveaux Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Prediction de topics pour un nouveau document\n",
    "\n",
    "int[] nouveauDoc = { 0, 1, 6, 7, 0 };  // Sport + Musique\n",
    "Console.WriteLine(\"=== Prediction Nouveau Document ===\");\n",
    "Console.WriteLine($\"Mots : {string.Join(\", \", nouveauDoc.Select(i => vocabulaire[i]))}\");\n",
    "\n",
    "// Calcul des vraisemblances par topic\n",
    "double[] logLik = new double[numTopics];\n",
    "\n",
    "for (int k = 0; k < numTopics; k++)\n",
    "{\n",
    "    logLik[k] = 0;\n",
    "    foreach (int w in nouveauDoc)\n",
    "    {\n",
    "        logLik[k] += Math.Log(phiSimule[k, w] + 1e-10);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Normalisation (softmax)\n",
    "double maxLogLik = logLik.Max();\n",
    "double[] lik = logLik.Select(ll => Math.Exp(ll - maxLogLik)).ToArray();\n",
    "double sumLik = lik.Sum();\n",
    "double[] topicProbs = lik.Select(l => l / sumLik).ToArray();\n",
    "\n",
    "Console.WriteLine(\"\\nProbabilites de topics :\");\n",
    "for (int k = 0; k < numTopics; k++)\n",
    "{\n",
    "    Console.WriteLine($\"  {topicNames[k],-12} : {topicProbs[k]:F3}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extensions de LDA\n",
    "\n",
    "### Variantes\n",
    "\n",
    "| Modele | Description |\n",
    "|--------|-------------|\n",
    "| **HDP** (Hierarchical Dirichlet Process) | Nombre de topics appris automatiquement |\n",
    "| **Correlated Topic Model** | Correlations entre topics |\n",
    "| **Dynamic Topic Model** | Evolution des topics dans le temps |\n",
    "| **Supervised LDA** | Avec labels de documents |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercice : Analyser un Corpus\n",
    "\n",
    "### Enonce\n",
    "\n",
    "Etendez le vocabulaire et ajoutez des documents pour creer un corpus plus realiste avec 4 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// EXERCICE : Corpus etendu\n",
    "\n",
    "string[] vocabEtendu = {\n",
    "    // Sport (0-3)\n",
    "    \"football\", \"basketball\", \"tennis\", \"competition\",\n",
    "    // Tech (4-7)\n",
    "    \"ordinateur\", \"logiciel\", \"internet\", \"application\",\n",
    "    // Cuisine (8-11)\n",
    "    \"recette\", \"ingredient\", \"cuisson\", \"gastronomie\",\n",
    "    // Voyage (12-15)\n",
    "    \"hotel\", \"avion\", \"destination\", \"tourisme\"\n",
    "};\n",
    "\n",
    "int[][] docsEtendus = {\n",
    "    new[] { 0, 1, 2, 3, 0 },     // Sport\n",
    "    new[] { 4, 5, 6, 7, 5 },     // Tech\n",
    "    new[] { 8, 9, 10, 11, 9 },   // Cuisine\n",
    "    new[] { 12, 13, 14, 15, 13 },// Voyage\n",
    "    new[] { 0, 4, 5, 1, 6 },     // Sport + Tech\n",
    "    new[] { 8, 12, 13, 10, 14 }, // Cuisine + Voyage\n",
    "    new[] { 2, 3, 0, 1, 2 },     // Sport\n",
    "    new[] { 6, 7, 4, 5, 7 }      // Tech\n",
    "};\n",
    "\n",
    "Console.WriteLine(\"=== Corpus Etendu (4 topics) ===\");\n",
    "\n",
    "for (int d = 0; d < docsEtendus.Length; d++)\n",
    "{\n",
    "    // Classification simple basee sur les indices de mots\n",
    "    int sport = docsEtendus[d].Count(w => w <= 3);\n",
    "    int tech = docsEtendus[d].Count(w => w >= 4 && w <= 7);\n",
    "    int cuisine = docsEtendus[d].Count(w => w >= 8 && w <= 11);\n",
    "    int voyage = docsEtendus[d].Count(w => w >= 12);\n",
    "    \n",
    "    string dominant;\n",
    "    int max = new[] { sport, tech, cuisine, voyage }.Max();\n",
    "    if (sport == max) dominant = \"Sport\";\n",
    "    else if (tech == max) dominant = \"Tech\";\n",
    "    else if (cuisine == max) dominant = \"Cuisine\";\n",
    "    else dominant = \"Voyage\";\n",
    "    \n",
    "    string mots = string.Join(\", \", docsEtendus[d].Select(i => vocabEtendu[i]));\n",
    "    Console.WriteLine($\"Doc {d+1} [{dominant,-8}] : {mots}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resume\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **LDA** | Modele generatif pour documents |\n",
    "| **Topic** | Distribution sur le vocabulaire |\n",
    "| **Theta** | Distribution de topics par document |\n",
    "| **Phi** | Distribution de mots par topic |\n",
    "| **Dirichlet** | Prior conjugue pour distributions categoriques |\n",
    "\n",
    "---\n",
    "\n",
    "## Prochaine etape\n",
    "\n",
    "Dans [Infer-10-Crowdsourcing](Infer-10-Crowdsourcing.ipynb), nous explorerons :\n",
    "\n",
    "- L'agregation de labels de crowdsourcing\n",
    "- La modelisation de la fiabilite des annotateurs\n",
    "- Les modeles Community pour groupes d'annotateurs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
