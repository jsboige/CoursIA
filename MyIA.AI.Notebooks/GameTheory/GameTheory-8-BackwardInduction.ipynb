{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GameTheory-8-BackwardInduction\n",
    "\n",
    "## Induction Arriere : Resoudre les Jeux Sequentiels\n",
    "\n",
    "Ce notebook presente l'**induction arriere** (backward induction), la methode fondamentale pour resoudre les jeux a information parfaite.\n",
    "\n",
    "### Objectifs\n",
    "\n",
    "1. Maitriser l'algorithme d'induction arriere\n",
    "2. Comprendre le **jeu du mille-pattes** (centipede) et ses paradoxes\n",
    "3. Analyser les jeux d'**escalade** (war of attrition)\n",
    "4. Etudier le **paradoxe de la chaine de magasins** (Selten)\n",
    "5. Explorer les limites de la rationalite parfaite\n",
    "\n",
    "### Prerequis\n",
    "\n",
    "- Notebook 7 : Jeux sous forme extensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration et imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple, Any\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "\n",
    "# Style matplotlib\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes de base (reprises du notebook 7)\n",
    "\n",
    "@dataclass\n",
    "class GameNode:\n",
    "    \"\"\"Noeud dans un arbre de jeu.\"\"\"\n",
    "    node_id: str\n",
    "    player: int  # -1 pour terminal, 0 pour nature\n",
    "    actions: List[str] = field(default_factory=list)\n",
    "    children: Dict[str, 'GameNode'] = field(default_factory=dict)\n",
    "    payoffs: Optional[Tuple[float, ...]] = None\n",
    "    infoset: Optional[str] = None\n",
    "    chance_probs: Optional[Dict[str, float]] = None\n",
    "    \n",
    "    def is_terminal(self) -> bool:\n",
    "        return self.player == -1\n",
    "    \n",
    "    def is_chance(self) -> bool:\n",
    "        return self.player == 0\n",
    "\n",
    "\n",
    "class ExtensiveFormGame:\n",
    "    \"\"\"Jeu sous forme extensive.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, num_players: int):\n",
    "        self.name = name\n",
    "        self.num_players = num_players\n",
    "        self.root: Optional[GameNode] = None\n",
    "        self.nodes: Dict[str, GameNode] = {}\n",
    "        self.infosets: Dict[str, List[str]] = defaultdict(list)\n",
    "    \n",
    "    def add_node(self, node: GameNode):\n",
    "        self.nodes[node.node_id] = node\n",
    "        if node.infoset:\n",
    "            self.infosets[node.infoset].append(node.node_id)\n",
    "    \n",
    "    def set_root(self, node: GameNode):\n",
    "        self.root = node\n",
    "        self.add_node(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. L'Algorithme d'Induction Arriere\n",
    "\n",
    "### 1.1 Principe\n",
    "\n",
    "Pour les jeux a **information parfaite** et **finis**, l'induction arriere est une methode de resolution optimale :\n",
    "\n",
    "1. **Partir des feuilles** : identifier les noeuds de decision juste avant les terminaux\n",
    "2. **Remonter** : a chaque noeud, le joueur choisit l'action qui maximise son gain (sachant ce qui se passera ensuite)\n",
    "3. **Repeter** jusqu'a la racine\n",
    "\n",
    "### 1.2 Proprietes\n",
    "\n",
    "- Trouve un **equilibre de Nash parfait en sous-jeux** (SPE)\n",
    "- Unique dans les jeux generiques (sans indifferences)\n",
    "- Complexite lineaire en le nombre de noeuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_induction(game: ExtensiveFormGame) -> Dict[str, Tuple[str, Tuple[float, ...]]]:\n",
    "    \"\"\"\n",
    "    Resout un jeu a information parfaite par induction arriere.\n",
    "    \n",
    "    Returns:\n",
    "        Dict {node_id: (optimal_action, equilibrium_payoffs)}\n",
    "    \"\"\"\n",
    "    solution = {}\n",
    "    \n",
    "    def solve(node: GameNode) -> Tuple[float, ...]:\n",
    "        \"\"\"Retourne les gains a l'equilibre depuis ce noeud.\"\"\"\n",
    "        if node.is_terminal():\n",
    "            return node.payoffs\n",
    "        \n",
    "        if node.is_chance():\n",
    "            # Esperance sur les resultats de nature\n",
    "            expected = np.zeros(game.num_players)\n",
    "            for action, prob in node.chance_probs.items():\n",
    "                child_payoffs = solve(node.children[action])\n",
    "                expected += prob * np.array(child_payoffs)\n",
    "            return tuple(expected)\n",
    "        \n",
    "        # Noeud de decision : le joueur maximise son gain\n",
    "        player = node.player\n",
    "        best_action = None\n",
    "        best_payoffs = None\n",
    "        best_value = float('-inf')\n",
    "        \n",
    "        for action in node.actions:\n",
    "            child_payoffs = solve(node.children[action])\n",
    "            player_value = child_payoffs[player - 1]  # Indices 0-based\n",
    "            \n",
    "            if player_value > best_value:\n",
    "                best_value = player_value\n",
    "                best_action = action\n",
    "                best_payoffs = child_payoffs\n",
    "        \n",
    "        solution[node.node_id] = (best_action, best_payoffs)\n",
    "        return best_payoffs\n",
    "    \n",
    "    equilibrium_payoffs = solve(game.root)\n",
    "    return solution, equilibrium_payoffs\n",
    "\n",
    "\n",
    "def display_backward_induction(game: ExtensiveFormGame, solution: Dict):\n",
    "    \"\"\"Affiche la solution d'induction arriere.\"\"\"\n",
    "    print(f\"\\nSolution par induction arriere : {game.name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for node_id, (action, payoffs) in solution.items():\n",
    "        node = game.nodes[node_id]\n",
    "        print(f\"  Noeud {node_id} (J{node.player}): joue '{action}' -> {payoffs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : Jeu d'entree sur le marche\n",
    "\n",
    "def create_entry_game() -> ExtensiveFormGame:\n",
    "    \"\"\"Jeu d'entree avec Entrant et Incumbant.\"\"\"\n",
    "    game = ExtensiveFormGame(\"Entry Game\", num_players=2)\n",
    "    \n",
    "    out_terminal = GameNode(\"out\", -1, payoffs=(0, 2))\n",
    "    fight_terminal = GameNode(\"fight\", -1, payoffs=(-1, -1))\n",
    "    accommodate_terminal = GameNode(\"accommodate\", -1, payoffs=(1, 1))\n",
    "    \n",
    "    incumbent_node = GameNode(\"incumbent\", 2, [\"Fight\", \"Accommodate\"], infoset=\"I2\")\n",
    "    incumbent_node.children = {\"Fight\": fight_terminal, \"Accommodate\": accommodate_terminal}\n",
    "    \n",
    "    entrant_node = GameNode(\"entrant\", 1, [\"Enter\", \"Out\"], infoset=\"I1\")\n",
    "    entrant_node.children = {\"Enter\": incumbent_node, \"Out\": out_terminal}\n",
    "    \n",
    "    game.set_root(entrant_node)\n",
    "    for node in [incumbent_node, out_terminal, fight_terminal, accommodate_terminal]:\n",
    "        game.add_node(node)\n",
    "    \n",
    "    return game\n",
    "\n",
    "entry_game = create_entry_game()\n",
    "solution, eq_payoffs = backward_induction(entry_game)\n",
    "\n",
    "display_backward_induction(entry_game, solution)\n",
    "print(f\"\\nGains a l'equilibre: {eq_payoffs}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Si l'Entrant entre, l'Incumbant prefere Accommoder (-1 < 1)\")\n",
    "print(\"  - Sachant cela, l'Entrant prefere Entrer (1 > 0)\")\n",
    "print(\"  -> La menace de 'Fight' n'est pas credible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Le Jeu du Mille-Pattes (Centipede Game)\n",
    "\n",
    "### 2.1 Description\n",
    "\n",
    "Le jeu du mille-pattes est un paradoxe celebre de la theorie des jeux :\n",
    "\n",
    "- Deux joueurs alternent\n",
    "- A chaque tour, le joueur actif peut **prendre** (T) le pot ou **passer** (P)\n",
    "- Si on passe, les gains augmentent\n",
    "- Le jeu s'arrete apres n tours ou quand quelqu'un prend\n",
    "\n",
    "```\n",
    "J1    J2    J1    J2    ...\n",
    " o-----o-----o-----o-----o\n",
    " |     |     |     |     |\n",
    " T     T     T     T     T\n",
    " |     |     |     |     |\n",
    "(1,0) (0,2) (3,1) (2,4) ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_centipede_game(n_rounds: int = 6) -> ExtensiveFormGame:\n",
    "    \"\"\"\n",
    "    Cree le jeu du mille-pattes.\n",
    "    \n",
    "    Gains pour \"Take\" au tour t:\n",
    "    - Joueur qui prend: 1 + 2*(t//2) si t pair, 2*(t//2) si t impair\n",
    "    - Autre joueur: le reste de la cagnotte\n",
    "    \n",
    "    Formule simplifiee: gains croissants\n",
    "    \"\"\"\n",
    "    game = ExtensiveFormGame(\"Centipede\", num_players=2)\n",
    "    nodes = []\n",
    "    \n",
    "    # Gains a chaque tour si \"Take\"\n",
    "    def payoffs_at_round(t):\n",
    "        # Les gains augmentent exponentiellement\n",
    "        big_pile = t + 1\n",
    "        small_pile = max(0, t - 1)\n",
    "        # Classic centipede: taker gets big pile, other gets small pile\n",
    "        player = 1 if t % 2 == 0 else 2\n",
    "        if player == 1:\n",
    "            return (big_pile, small_pile)\n",
    "        else:\n",
    "            return (small_pile, big_pile)\n",
    "    \n",
    "    # Creer les noeuds de la fin vers le debut\n",
    "    # Dernier terminal (si tous passent)\n",
    "    # Final payoffs if everyone passes\n",
    "    final_payoffs = (n_rounds, n_rounds)\n",
    "    last_pass = GameNode(f\"end\", -1, payoffs=final_payoffs)\n",
    "    nodes.append(last_pass)\n",
    "    \n",
    "    next_node = last_pass\n",
    "    for t in range(n_rounds - 1, -1, -1):\n",
    "        player = 1 if t % 2 == 0 else 2\n",
    "        payoffs = payoffs_at_round(t)\n",
    "        \n",
    "        take_terminal = GameNode(f\"take_{t}\", -1, payoffs=payoffs)\n",
    "        nodes.append(take_terminal)\n",
    "        \n",
    "        decision = GameNode(f\"node_{t}\", player, [\"Take\", \"Pass\"], infoset=f\"I{player}_{t}\")\n",
    "        decision.children = {\"Take\": take_terminal, \"Pass\": next_node}\n",
    "        nodes.append(decision)\n",
    "        \n",
    "        next_node = decision\n",
    "    \n",
    "    game.set_root(next_node)\n",
    "    for node in nodes[:-1]:  # La racine est deja ajoutee\n",
    "        game.add_node(node)\n",
    "    \n",
    "    return game\n",
    "\n",
    "\n",
    "# Creer et resoudre le jeu\n",
    "centipede = create_centipede_game(n_rounds=6)\n",
    "solution, eq_payoffs = backward_induction(centipede)\n",
    "\n",
    "print(\"Jeu du Mille-Pattes (6 tours)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nGains a l'equilibre: {eq_payoffs}\")\n",
    "print(f\"\\nStrategies optimales (induction arriere):\")\n",
    "for node_id in sorted(solution.keys(), key=lambda x: int(x.split('_')[1])):\n",
    "    action, payoffs = solution[node_id]\n",
    "    print(f\"  {node_id}: {action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_centipede(n_rounds: int = 6, figsize=(14, 5)):\n",
    "    \"\"\"Visualise le jeu du mille-pattes.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Positions\n",
    "    x_positions = np.arange(n_rounds + 1)\n",
    "    y_main = 1\n",
    "    y_take = 0\n",
    "    \n",
    "    # Calculer les gains\n",
    "    def payoffs_at_round(t):\n",
    "        big_pile = t + 1\n",
    "        small_pile = max(0, t - 1)\n",
    "        # Classic centipede: taker gets big pile, other gets small pile\n",
    "        player = 1 if t % 2 == 0 else 2\n",
    "        if player == 1:\n",
    "            return (big_pile, small_pile)\n",
    "        else:\n",
    "            return (small_pile, big_pile)\n",
    "    \n",
    "    # Ligne principale (Pass)\n",
    "    ax.plot(x_positions, [y_main] * (n_rounds + 1), 'k-', linewidth=2)\n",
    "    \n",
    "    # Noeuds de decision\n",
    "    colors = ['#3498db', '#e74c3c']  # Bleu J1, Rouge J2\n",
    "    for t in range(n_rounds):\n",
    "        player = 1 if t % 2 == 0 else 2\n",
    "        color = colors[player - 1]\n",
    "        \n",
    "        # Noeud de decision\n",
    "        ax.scatter(t, y_main, s=300, c=color, zorder=5)\n",
    "        ax.annotate(f'J{player}', (t, y_main + 0.15), ha='center', fontsize=10)\n",
    "        \n",
    "        # Branche Take\n",
    "        ax.plot([t, t], [y_main, y_take], 'k--', linewidth=1)\n",
    "        payoffs = payoffs_at_round(t)\n",
    "        ax.scatter(t, y_take, s=200, c='lightgray', zorder=5)\n",
    "        ax.annotate(f'{payoffs}', (t, y_take - 0.2), ha='center', fontsize=9)\n",
    "        ax.annotate('T', (t - 0.15, (y_main + y_take) / 2), fontsize=9)\n",
    "    \n",
    "    # Noeud final\n",
    "    # Final payoffs if everyone passes\n",
    "    final_payoffs = (n_rounds, n_rounds)\n",
    "    ax.scatter(n_rounds, y_main, s=200, c='gold', zorder=5)\n",
    "    ax.annotate(f'{final_payoffs}', (n_rounds, y_main - 0.2), ha='center', fontsize=9)\n",
    "    \n",
    "    # Labels\n",
    "    ax.annotate('P', (0.5, y_main + 0.1), fontsize=9)\n",
    "    ax.annotate('P', (1.5, y_main + 0.1), fontsize=9)\n",
    "    \n",
    "    ax.set_xlim(-0.5, n_rounds + 0.5)\n",
    "    ax.set_ylim(-0.5, 1.5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Jeu du Mille-Pattes ({n_rounds} tours)\\n'\n",
    "                 f'Bleu = J1, Rouge = J2, T = Take, P = Pass', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_centipede(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Le Paradoxe du Mille-Pattes\n",
    "\n",
    "**Prediction theorique** : Par induction arriere, J1 devrait \"Take\" immediatement!\n",
    "\n",
    "**Raisonnement** :\n",
    "1. Au dernier tour, le joueur actif prefere Take\n",
    "2. Donc l'avant-dernier joueur sait que s'il passe, l'autre prendra\n",
    "3. Il prefere donc Take lui-meme\n",
    "4. Et ainsi de suite jusqu'au premier tour...\n",
    "\n",
    "**Observations experimentales** : En pratique, les joueurs humains passent souvent plusieurs tours!\n",
    "\n",
    "**Explications possibles** :\n",
    "- Rationalite limitee\n",
    "- Incertitude sur la rationalite de l'adversaire\n",
    "- Preferences sociales (altruisme, reciprocite)\n",
    "- Apprentissage et reputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation: comparaison entre equilibre et comportement \"naif\"\n",
    "\n",
    "def simulate_centipede_behavior(n_rounds, take_prob_per_round=0.3, n_simulations=10000):\n",
    "    \"\"\"\n",
    "    Simule le jeu avec des joueurs qui prennent avec probabilite p a chaque tour.\n",
    "    \n",
    "    Modele simplifie : chaque joueur a une probabilite fixe de \"Take\" a son tour.\n",
    "    Cela represente une rationalite limitee ou un comportement experimental typique.\n",
    "    \"\"\"\n",
    "    payoffs_j1 = []\n",
    "    payoffs_j2 = []\n",
    "    stop_rounds = []\n",
    "    \n",
    "    def payoffs_at_round(t, n_rounds):\n",
    "        \"\"\"Gains si quelqu'un prend au tour t.\"\"\"\n",
    "        big_pile = t + 1\n",
    "        small_pile = max(0, t - 1)\n",
    "        player = 1 if t % 2 == 0 else 2\n",
    "        if player == 1:\n",
    "            return (big_pile, small_pile)\n",
    "        else:\n",
    "            return (small_pile, big_pile)\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        for t in range(n_rounds):\n",
    "            if np.random.random() < take_prob_per_round:\n",
    "                p1, p2 = payoffs_at_round(t, n_rounds)\n",
    "                payoffs_j1.append(p1)\n",
    "                payoffs_j2.append(p2)\n",
    "                stop_rounds.append(t)\n",
    "                break\n",
    "        else:\n",
    "            # Tous ont passe - gains finaux (partage egal du pot final)\n",
    "            final_payoffs = (n_rounds, n_rounds)\n",
    "            payoffs_j1.append(final_payoffs[0])\n",
    "            payoffs_j2.append(final_payoffs[1])\n",
    "            stop_rounds.append(n_rounds)\n",
    "    \n",
    "    return {\n",
    "        'mean_j1': np.mean(payoffs_j1),\n",
    "        'mean_j2': np.mean(payoffs_j2),\n",
    "        'mean_round': np.mean(stop_rounds),\n",
    "        'stop_distribution': np.bincount(stop_rounds, minlength=n_rounds+1)\n",
    "    }\n",
    "\n",
    "\n",
    "# Comparer differentes strategies\n",
    "n = 6\n",
    "\n",
    "# Equilibre (Take immediat)\n",
    "centipede = create_centipede_game(n)\n",
    "_, eq_payoffs = backward_induction(centipede)\n",
    "\n",
    "print(\"Comparaison : Equilibre vs Comportement probabiliste\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nEquilibre (Take immediat): J1={eq_payoffs[0]}, J2={eq_payoffs[1]}\")\n",
    "print(f\"Tour d'arret: 0 (J1 prend immediatement)\")\n",
    "\n",
    "print(\"\\n--- Simulations avec differentes probabilites de Take ---\")\n",
    "for p in [0.1, 0.2, 0.3, 0.5]:\n",
    "    result = simulate_centipede_behavior(n, take_prob_per_round=p)\n",
    "    print(f\"\\np={p}: J1={result['mean_j1']:.2f}, J2={result['mean_j2']:.2f}, \" \n",
    "          f\"tour moyen d'arret={result['mean_round']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Interpretation des resultats de simulation\n",
    "\n",
    "Les simulations ci-dessus revelent un phenomene fascinant :\n",
    "\n",
    "| Strategie | Gains J1 | Gains J2 | Total | Interpretation |\n",
    "|-----------|----------|----------|-------|----------------|\n",
    "| **Equilibre Nash** | 1 | 0 | 1 | Prediction theorique |\n",
    "| **p=0.1** (patient) | ~5.4 | ~4.6 | ~10 | Cooperation emergente |\n",
    "| **p=0.5** (balance) | ~2.5 | ~2.0 | ~4.5 | Compromis theorie/pratique |\n",
    "\n",
    "**Le dilemme fondamental** : La rationalite parfaite (prendre immediatement) donne un resultat tres inferieur a ce que les joueurs pourraient obtenir en \"cooperant\" (passant plusieurs tours).\n",
    "\n",
    "C'est exactement ce qu'on observe dans les experiences de laboratoire : les sujets humains passent souvent plusieurs tours, obtenant des gains superieurs a la prediction de l'induction arriere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'efficacite\n",
    "\n",
    "def efficiency_analysis(n_rounds=6):\n",
    "    \"\"\"Analyse l'efficacite en fonction de la probabilite de Take.\"\"\"\n",
    "    probs = np.linspace(0.01, 0.99, 50)\n",
    "    mean_payoffs = []\n",
    "    \n",
    "    for p in probs:\n",
    "        result = simulate_centipede_behavior(n_rounds, p, n_simulations=5000)\n",
    "        mean_payoffs.append(result['mean_j1'] + result['mean_j2'])\n",
    "    \n",
    "    # Gains theoriques\n",
    "    optimal = 2 * n_rounds  # Si tous passent: (n_rounds, n_rounds)\n",
    "    equilibrium = 1  # Take au tour 0: (1, 0), total = 1\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(probs, mean_payoffs, 'b-', linewidth=2, label='Gains totaux moyens')\n",
    "    ax.axhline(optimal, color='g', linestyle='--', label=f'Optimal (tous passent): {optimal}')\n",
    "    ax.axhline(equilibrium, color='r', linestyle='--', label=f'Equilibre Nash: {equilibrium}')\n",
    "    \n",
    "    ax.set_xlabel('Probabilite de Take a chaque tour', fontsize=12)\n",
    "    ax.set_ylabel('Gains totaux (J1 + J2)', fontsize=12)\n",
    "    ax.set_title('Mille-Pattes: Efficacite vs Rationalite\\nLe dilemme entre theorie et pratique', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('centipede_efficiency.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return mean_payoffs\n",
    "\n",
    "mean_payoffs = efficiency_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Le graphique d'efficacite : une lecon sur les limites de la theorie\n",
    "\n",
    "Le graphique ci-dessus illustre parfaitement le **paradoxe du mille-pattes** :\n",
    "\n",
    "- **Ligne rouge** (equilibre Nash) : La theorie predit des gains totaux de seulement 1\n",
    "- **Ligne verte** (optimal social) : La cooperation parfaite donnerait 12\n",
    "- **Courbe bleue** (comportement mixte) : Des joueurs imparfaitement rationnels font souvent mieux !\n",
    "\n",
    "**Questions pour reflexion** :\n",
    "1. Pourquoi la theorie echoue-t-elle a predire le comportement reel ?\n",
    "2. Est-ce que les sujets experimentaux sont \"irrationnels\" ou \"plus intelligents\" ?\n",
    "3. Quel role jouent les croyances sur la rationalite de l'adversaire ?\n",
    "\n",
    "Ces questions ont mene au developpement de modeles plus riches : **rationalite limitee**, **jeux de reputation**, et **apprentissage**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Jeux d'Escalade (War of Attrition)\n",
    "\n",
    "### 3.1 Description\n",
    "\n",
    "Deux joueurs s'affrontent pour un prix de valeur V. A chaque tour :\n",
    "- Chacun peut **abandonner** ou **continuer**\n",
    "- Continuer coute c par tour\n",
    "- Le dernier en lice gagne V\n",
    "- Si les deux abandonnent : personne ne gagne\n",
    "\n",
    "Exemples : encheres, conflits territoriaux, greves, negociations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_war_of_attrition(max_rounds: int = 5, V: float = 10, c: float = 1) -> ExtensiveFormGame:\n",
    "    \"\"\"\n",
    "    Cree un jeu d'escalade simplifie (sequentiel pour l'induction arriere).\n",
    "    \n",
    "    A chaque tour, J1 puis J2 decident de continuer ou abandonner.\n",
    "    \"\"\"\n",
    "    game = ExtensiveFormGame(f\"War of Attrition (V={V}, c={c})\", num_players=2)\n",
    "    \n",
    "    def create_round(round_num, accumulated_cost_1, accumulated_cost_2):\n",
    "        \"\"\"Cree recursivement les noeuds d'un tour.\"\"\"\n",
    "        if round_num >= max_rounds:\n",
    "            # Fin du jeu - personne ne gagne vraiment (partage?)\n",
    "            return GameNode(f\"tie_{round_num}\", -1, \n",
    "                          payoffs=(-accumulated_cost_1, -accumulated_cost_2))\n",
    "        \n",
    "        # J1 decide\n",
    "        j1_quit = GameNode(f\"j1_quit_{round_num}\", -1,\n",
    "                          payoffs=(-accumulated_cost_1, V - accumulated_cost_2))\n",
    "        \n",
    "        # J2 decide (si J1 continue)\n",
    "        j2_quit = GameNode(f\"j2_quit_{round_num}\", -1,\n",
    "                          payoffs=(V - accumulated_cost_1 - c, -accumulated_cost_2))\n",
    "        \n",
    "        next_round = create_round(round_num + 1, \n",
    "                                  accumulated_cost_1 + c, \n",
    "                                  accumulated_cost_2 + c)\n",
    "        \n",
    "        j2_node = GameNode(f\"j2_{round_num}\", 2, [\"Quit\", \"Fight\"],\n",
    "                          infoset=f\"I2_{round_num}\")\n",
    "        j2_node.children = {\"Quit\": j2_quit, \"Fight\": next_round}\n",
    "        \n",
    "        j1_node = GameNode(f\"j1_{round_num}\", 1, [\"Quit\", \"Fight\"],\n",
    "                          infoset=f\"I1_{round_num}\")\n",
    "        j1_node.children = {\"Quit\": j1_quit, \"Fight\": j2_node}\n",
    "        \n",
    "        return j1_node\n",
    "    \n",
    "    root = create_round(0, 0, 0)\n",
    "    \n",
    "    # Ajouter tous les noeuds au jeu\n",
    "    def add_all_nodes(node):\n",
    "        game.add_node(node)\n",
    "        if hasattr(node, 'children') and node.children:\n",
    "            for child in node.children.values():\n",
    "                add_all_nodes(child)\n",
    "    \n",
    "    game.root = root\n",
    "    add_all_nodes(root)\n",
    "    \n",
    "    return game\n",
    "\n",
    "\n",
    "# Analyser le jeu d'escalade\n",
    "woa = create_war_of_attrition(max_rounds=4, V=10, c=2)\n",
    "solution, eq_payoffs = backward_induction(woa)\n",
    "\n",
    "print(\"Jeu d'Escalade\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Prix: V=10, Cout par tour: c=2\")\n",
    "print(f\"\\nGains a l'equilibre: {eq_payoffs}\")\n",
    "\n",
    "print(f\"\\nStrategies optimales:\")\n",
    "for node_id in sorted([k for k in solution.keys() if 'j1_' in k or 'j2_' in k]):\n",
    "    action, _ = solution[node_id]\n",
    "    print(f\"  {node_id}: {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Analyse des resultats : L'avantage du premier joueur\n",
    "\n",
    "Les resultats de l'analyse montrent que dans ce jeu sequentiel :\n",
    "\n",
    "1. **J1 obtient toujours V - c** (le prix moins le cout du premier tour)\n",
    "2. **J2 obtient toujours 0** (il abandonne immediatement)\n",
    "\n",
    "C'est une consequence directe de l'induction arriere : J2 sait qu'il perdra la guerre d'usure car J1 peut toujours attendre un tour de plus. Sachant cela, J2 prefere abandonner tout de suite pour eviter les couts.\n",
    "\n",
    "**En pratique** : Les vraies guerres d'usure (encheres, greves, conflits) durent souvent plus longtemps car :\n",
    "- L'horizon temporel est incertain\n",
    "- Les joueurs ont des croyances differentes sur leurs couts respectifs\n",
    "- Des considerations de reputation entrent en jeu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de l'equilibre en fonction du ratio V/c\n",
    "\n",
    "def analyze_war_of_attrition():\n",
    "    \"\"\"Analyse comment l'equilibre change avec V et c.\"\"\"\n",
    "    V_values = [5, 10, 15, 20]\n",
    "    c_values = [1, 2, 3, 4]\n",
    "    \n",
    "    results = []\n",
    "    for V in V_values:\n",
    "        for c in c_values:\n",
    "            woa = create_war_of_attrition(max_rounds=6, V=V, c=c)\n",
    "            _, eq_payoffs = backward_induction(woa)\n",
    "            total = eq_payoffs[0] + eq_payoffs[1]\n",
    "            results.append({'V': V, 'c': c, 'ratio': V/c, \n",
    "                          'J1': eq_payoffs[0], 'J2': eq_payoffs[1],\n",
    "                          'total': total})\n",
    "    \n",
    "    print(\"Analyse de l'equilibre: War of Attrition\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'V':>4} {'c':>4} {'V/c':>6} {'J1':>8} {'J2':>8} {'Total':>8}\")\n",
    "    print(\"-\"*44)\n",
    "    for r in results:\n",
    "        print(f\"{r['V']:>4} {r['c']:>4} {r['ratio']:>6.1f} {r['J1']:>8.1f} {r['J2']:>8.1f} {r['total']:>8.1f}\")\n",
    "\n",
    "analyze_war_of_attrition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Paradoxe de la Chaine de Magasins (Selten)\n",
    "\n",
    "### 4.1 Le Scenario\n",
    "\n",
    "Un monopole (chaine de magasins) fait face a N entrants potentiels sequentiellement :\n",
    "- Chaque entrant decide d'entrer ou non\n",
    "- Si entree, le monopole peut combattre (couteux pour les deux) ou accommoder\n",
    "- Combat : (-1, -1), Accommodate : (1, 1), Pas d'entree : (0, 2)\n",
    "\n",
    "**Question** : Le monopole devrait-il combattre les premiers entrants pour dissuader les suivants ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain_store_game(n_entrants: int = 3) -> ExtensiveFormGame:\n",
    "    \"\"\"\n",
    "    Cree le jeu de la chaine de magasins.\n",
    "    \n",
    "    Le monopole (J2) fait face a n_entrants sequentiellement (J1_k).\n",
    "    Pour simplifier, on considere que c'est toujours \"J1\" vs \"J2\".\n",
    "    \"\"\"\n",
    "    game = ExtensiveFormGame(f\"Chain Store ({n_entrants} entrants)\", num_players=2)\n",
    "    \n",
    "    # Gains cumules\n",
    "    # J1: gains des entrants (simplifies: somme)\n",
    "    # J2: gains du monopole\n",
    "    \n",
    "    def create_market(market_num, monopoly_total):\n",
    "        \"\"\"Cree les noeuds pour un marche.\"\"\"\n",
    "        if market_num >= n_entrants:\n",
    "            # Fin: gains du monopole\n",
    "            return GameNode(f\"end\", -1, payoffs=(0, monopoly_total))\n",
    "        \n",
    "        # Terminaux pour ce marche\n",
    "        stay_out = create_market(market_num + 1, monopoly_total + 2)\n",
    "        \n",
    "        # Fight: -1 pour les deux sur ce marche\n",
    "        fight_continue = create_market(market_num + 1, monopoly_total - 1)\n",
    "        fight_terminal = GameNode(f\"fight_{market_num}\", -1, payoffs=(-1, -1))\n",
    "        \n",
    "        # Accommodate: +1 pour les deux sur ce marche\n",
    "        acc_continue = create_market(market_num + 1, monopoly_total + 1)\n",
    "        \n",
    "        # Monopole decide\n",
    "        monopole = GameNode(f\"monopole_{market_num}\", 2, [\"Fight\", \"Accommodate\"],\n",
    "                           infoset=f\"I2_{market_num}\")\n",
    "        monopole.children = {\"Fight\": fight_continue, \"Accommodate\": acc_continue}\n",
    "        \n",
    "        # Entrant decide\n",
    "        entrant = GameNode(f\"entrant_{market_num}\", 1, [\"Enter\", \"Out\"],\n",
    "                          infoset=f\"I1_{market_num}\")\n",
    "        entrant.children = {\"Enter\": monopole, \"Out\": stay_out}\n",
    "        \n",
    "        return entrant\n",
    "    \n",
    "    root = create_market(0, 0)\n",
    "    \n",
    "    def add_all_nodes(node):\n",
    "        game.add_node(node)\n",
    "        if hasattr(node, 'children') and node.children:\n",
    "            for child in node.children.values():\n",
    "                if child.node_id not in game.nodes:\n",
    "                    add_all_nodes(child)\n",
    "    \n",
    "    game.root = root\n",
    "    add_all_nodes(root)\n",
    "    \n",
    "    return game\n",
    "\n",
    "\n",
    "# Version simplifiee pour l'analyse\n",
    "def analyze_chain_store():\n",
    "    \"\"\"Analyse le paradoxe de la chaine.\"\"\"\n",
    "    print(\"Paradoxe de la Chaine de Magasins\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nMatrice de gains par interaction:\")\n",
    "    print(\"                   Fight    Accommodate\")\n",
    "    print(f\"  Enter           (-1,-1)     (1,1)\")\n",
    "    print(f\"  Out              --        (0,2)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\\nAnalyse par induction arriere (pour chaque interaction):\")\n",
    "    print(\"  - Si l'entrant entre, le monopole prefere Accommodate (1 > -1)\")\n",
    "    print(\"  - Sachant cela, l'entrant prefere Enter (1 > 0)\")\n",
    "    print(\"  -> Equilibre: (Enter, Accommodate) avec gains (1, 1)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\\nParadoxe:\")\n",
    "    print(\"  - Intuition: Le monopole devrait combattre les premiers\")\n",
    "    print(\"    entrants pour batir une reputation et dissuader les suivants\")\n",
    "    print(\"  - Induction arriere: Cette menace n'est JAMAIS credible!\")\n",
    "    print(\"    (au dernier marche, il accommodera toujours)\")\n",
    "    print(\"  - Resolution: Besoin d'information incomplete ou\")\n",
    "    print(\"    de types 'irrationnels' (voir jeux de reputation)\")\n",
    "\n",
    "analyze_chain_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Interpretation : L'irrationalite peut etre \"rationnelle\"\n",
    "\n",
    "Le tableau ci-dessus revele un resultat contre-intuitif mais profond :\n",
    "\n",
    "| p_rational | Gains totaux | Interpretation |\n",
    "|------------|--------------|----------------|\n",
    "| 1.0 (tous rationnels) | 1 | Echec de coordination |\n",
    "| 0.5 (incertain) | ~6 | Cooperation emergente |\n",
    "| 0.0 (tous \"irrationnels\") | 12 | Resultat optimal ! |\n",
    "\n",
    "**Lecon** : Quand un joueur sait que l'autre *pourrait* etre irrationnel, il peut prendre des risques (passer un tour) qui s'averent benefiques. C'est le fondement des **jeux de reputation** (Notebook 11).\n",
    "\n",
    "**Application pratique** : Dans la vie reelle, une reputation d'\"irrationnel\" (quelqu'un qui ne cede jamais) peut etre un avantage strategique, meme si le comportement semble sous-optimal localement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Limites de l'Induction Arriere\n",
    "\n",
    "### 5.1 Hypotheses fortes\n",
    "\n",
    "L'induction arriere requiert :\n",
    "\n",
    "| Hypothese | Probleme pratique |\n",
    "|-----------|-------------------|\n",
    "| **Rationalite** | Les humains ne maximisent pas toujours |\n",
    "| **Connaissance commune** | Tous doivent savoir que tous sont rationnels |\n",
    "| **Information parfaite** | Ne s'applique pas aux jeux avec incertitude |\n",
    "\n",
    "### 5.2 Alternatives\n",
    "\n",
    "- **Rationalite limitee** : Les joueurs utilisent des heuristiques\n",
    "- **Epsilon-equilibres** : Tolerer de petites deviations\n",
    "- **Jeux de reputation** : Incertitude sur le type de l'adversaire\n",
    "- **Apprentissage** : Les strategies evoluent dans le temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation: effet de l'incertitude sur la rationalite\n",
    "\n",
    "def simulate_bounded_rationality_centipede(n_rounds, p_rational=0.9, n_sims=10000):\n",
    "    \"\"\"\n",
    "    Simule le mille-pattes avec joueurs potentiellement 'irrationnels'.\n",
    "    \n",
    "    Modele:\n",
    "    - Chaque joueur est rationnel avec probabilite p_rational\n",
    "    - Un joueur rationnel applique l'induction arriere (Take immediat)\n",
    "    - Un joueur irrationnel passe toujours (ne prend jamais)\n",
    "    \n",
    "    Ce modele simple illustre comment l'incertitude sur la rationalite\n",
    "    de l'adversaire peut changer dramatiquement les predictions.\n",
    "    \"\"\"\n",
    "    def payoffs_at_round(t, n_rounds):\n",
    "        big_pile = t + 1\n",
    "        small_pile = max(0, t - 1)\n",
    "        player = 1 if t % 2 == 0 else 2\n",
    "        if player == 1:\n",
    "            return (big_pile, small_pile)\n",
    "        else:\n",
    "            return (small_pile, big_pile)\n",
    "    \n",
    "    results = []\n",
    "    for _ in range(n_sims):\n",
    "        j1_rational = np.random.random() < p_rational\n",
    "        j2_rational = np.random.random() < p_rational\n",
    "        \n",
    "        # Strategie rationnelle: Take immediat\n",
    "        # Strategie irrationnelle: toujours Pass\n",
    "        \n",
    "        if j1_rational:\n",
    "            # J1 rationnel prend immediatement\n",
    "            p1, p2 = payoffs_at_round(0, n_rounds)\n",
    "        else:\n",
    "            # J1 passe, c'est a J2\n",
    "            if j2_rational:\n",
    "                p1, p2 = payoffs_at_round(1, n_rounds)\n",
    "            else:\n",
    "                # Les deux passent - continuer jusqu'a la fin\n",
    "                # Final payoffs if everyone passes\n",
    "                p1, p2 = n_rounds, n_rounds\n",
    "        \n",
    "        results.append((p1, p2))\n",
    "    \n",
    "    results = np.array(results)\n",
    "    return {\n",
    "        'mean_j1': results[:, 0].mean(),\n",
    "        'mean_j2': results[:, 1].mean(),\n",
    "        'mean_total': results.sum(axis=1).mean()\n",
    "    }\n",
    "\n",
    "\n",
    "# Varier la probabilite de rationalite\n",
    "print(\"Effet de l'incertitude sur la rationalite (Mille-Pattes)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'p_rational':>12} {'J1':>8} {'J2':>8} {'Total':>8}\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for p in [1.0, 0.95, 0.9, 0.8, 0.7, 0.5, 0.3, 0.0]:\n",
    "    result = simulate_bounded_rationality_centipede(6, p_rational=p)\n",
    "    print(f\"{p:>12.2f} {result['mean_j1']:>8.2f} {result['mean_j2']:>8.2f} {result['mean_total']:>8.2f}\")\n",
    "\n",
    "print(\"\\nObservation: Une petite probabilite d'irrationalite\")\n",
    "print(\"peut significativement ameliorer les gains!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exercices\n",
    "\n",
    "### Exercice 1 : Ultimatum a 3 tours\n",
    "\n",
    "Alternating offers bargaining :\n",
    "1. J1 propose x (partage de 100)\n",
    "2. J2 accepte ou refuse\n",
    "3. Si refus, J2 propose y (partage de 90, le gateau retrecit!)\n",
    "4. J1 accepte ou refuse\n",
    "5. Si refus, J1 propose z (partage de 80)\n",
    "6. J2 accepte ou refuse (si refus: (0, 0))\n",
    "\n",
    "Trouvez l'equilibre par induction arriere.\n",
    "\n",
    "### Exercice 2 : Duel\n",
    "\n",
    "Deux duellistes s'approchent l'un de l'autre. A chaque pas :\n",
    "- Probabilite de toucher augmente (distance decroit)\n",
    "- Chacun decide de tirer ou d'avancer\n",
    "- Premier qui tire: touche avec proba p(distance), rate sinon\n",
    "\n",
    "Modelisez et analysez.\n",
    "\n",
    "### Exercice 3 : Stackelberg\n",
    "\n",
    "Implementez le duopole de Stackelberg:\n",
    "- Leader choisit q1\n",
    "- Follower observe q1 et choisit q2\n",
    "- Prix: P = 100 - q1 - q2\n",
    "- Cout: C(q) = 10q\n",
    "\n",
    "Discretisez les quantites et appliquez l'induction arriere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espace pour vos solutions\n",
    "\n",
    "# Exercice 1: Bargaining\n",
    "def create_bargaining_game():\n",
    "    \"\"\"Cree le jeu de negociation a 3 tours.\"\"\"\n",
    "    # A completer...\n",
    "    pass\n",
    "\n",
    "# Exercice 3: Stackelberg\n",
    "def create_stackelberg_duopoly(quantity_choices=[10, 20, 30, 40]):\n",
    "    \"\"\"Cree le duopole de Stackelberg discretise.\"\"\"\n",
    "    # A completer...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resume\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Induction arriere** | Resoudre des feuilles vers la racine |\n",
    "| **SPE** | Equilibre de Nash parfait en sous-jeux |\n",
    "| **Mille-pattes** | Paradoxe: equilibre vs gains |\n",
    "| **War of Attrition** | Jeu d'escalade couteux |\n",
    "| **Chain Store** | Paradoxe de la reputation |\n",
    "\n",
    "### Points cles\n",
    "\n",
    "- L'induction arriere trouve l'**equilibre unique** (generique)\n",
    "- Les **menaces non credibles** sont eliminees\n",
    "- **Paradoxes** : prediction vs comportement observe\n",
    "- La **rationalite limitee** explique les deviations\n",
    "\n",
    "### Prochaine etape\n",
    "\n",
    "**Notebook 9 : Induction Avant et SPE** - Raffinements des equilibres, menaces credibles, et jeux de signaling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GameTheory WSL + OpenSpiel)",
   "language": "python",
   "name": "gametheory-wsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}