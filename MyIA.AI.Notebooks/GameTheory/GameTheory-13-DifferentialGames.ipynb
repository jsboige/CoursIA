{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GameTheory-13 : Jeux Differentiels et Equilibres de Stackelberg\n",
    "\n",
    "## Decisions Dynamiques et Leadership Strategique\n",
    "\n",
    "Ce notebook introduit les **jeux differentiels** (decisions continues dans le temps) et les **equilibres de Stackelberg** (modeles leader-follower).\n",
    "\n",
    "**Objectifs pedagogiques** :\n",
    "- Comprendre la difference entre boucle ouverte et boucle fermee\n",
    "- Maitriser les equilibres de Stackelberg\n",
    "- Analyser les jeux lineaires-quadratiques (LQ)\n",
    "- Appliquer a l'economie industrielle (oligopoles dynamiques)\n",
    "\n",
    "**Prerequis** : Notebooks 1-12, notions de calcul differentiel\n",
    "\n",
    "**Duree estimee** : 60 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction aux Jeux Dynamiques\n",
    "\n",
    "### 1.1 Jeux statiques vs dynamiques\n",
    "\n",
    "| Aspect | Jeux statiques | Jeux dynamiques |\n",
    "|--------|----------------|------------------|\n",
    "| **Temps** | Une seule periode | Plusieurs periodes ou continu |\n",
    "| **Actions** | Simultanees | Sequentielles ou continues |\n",
    "| **Etat** | Fixe | Evolue selon les actions |\n",
    "| **Information** | Connue a l'avance | Revelee progressivement |\n",
    "\n",
    "### 1.2 Types de strategies\n",
    "\n",
    "- **Boucle ouverte (open-loop)** : le joueur s'engage sur une trajectoire complete $u(t)$ au debut\n",
    "- **Boucle fermee (closed-loop/feedback)** : le joueur ajuste sa strategie $u(x(t), t)$ selon l'etat courant\n",
    "\n",
    "### 1.3 Historique\n",
    "\n",
    "Les jeux differentiels ont ete formalises par **Rufus Isaacs** (1965) dans le contexte de problemes de poursuite-evasion militaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dependances\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['numpy', 'scipy', 'matplotlib']\n",
    "for pkg in packages:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "from scipy.optimize import minimize, minimize_scalar\n",
    "from typing import Tuple, Callable, List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "print(\"Imports reussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Equilibres de Stackelberg\n",
    "\n",
    "### 2.1 Modele Leader-Follower\n",
    "\n",
    "Dans un jeu de Stackelberg :\n",
    "1. Le **leader** choisit son action $x_L$ en premier\n",
    "2. Le **follower** observe $x_L$ et choisit sa meilleure reponse $x_F(x_L)$\n",
    "3. Le leader anticipe cette reaction et optimise en consequence\n",
    "\n",
    "### 2.2 Resolution\n",
    "\n",
    "**Etape 1** : Trouver la meilleure reponse du follower\n",
    "$$x_F^*(x_L) = \\arg\\max_{x_F} \\pi_F(x_L, x_F)$$\n",
    "\n",
    "**Etape 2** : Le leader maximise en substituant\n",
    "$$x_L^* = \\arg\\max_{x_L} \\pi_L(x_L, x_F^*(x_L))$$\n",
    "\n",
    "### 2.3 Comparaison avec Cournot\n",
    "\n",
    "Dans le duopole de Cournot, les firmes choisissent simultanement. Dans Stackelberg, le leader a un **avantage du premier joueur**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LinearDemand:\n",
    "    \"\"\"Demande lineaire P(Q) = a - bQ.\"\"\"\n",
    "    a: float  # Intercept\n",
    "    b: float  # Pente\n",
    "    \n",
    "    def price(self, Q: float) -> float:\n",
    "        return max(0, self.a - self.b * Q)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"P(Q) = {self.a} - {self.b}Q\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Firm:\n",
    "    \"\"\"Firme avec cout marginal constant.\"\"\"\n",
    "    name: str\n",
    "    marginal_cost: float\n",
    "    \n",
    "    def cost(self, q: float) -> float:\n",
    "        return self.marginal_cost * q\n",
    "    \n",
    "    def profit(self, q: float, price: float) -> float:\n",
    "        return (price - self.marginal_cost) * q\n",
    "\n",
    "\n",
    "def cournot_equilibrium(demand: LinearDemand, \n",
    "                        firm1: Firm, firm2: Firm) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calcule l'equilibre de Cournot pour un duopole.\n",
    "    \n",
    "    Retourne (q1*, q2*)\n",
    "    \"\"\"\n",
    "    a, b = demand.a, demand.b\n",
    "    c1, c2 = firm1.marginal_cost, firm2.marginal_cost\n",
    "    \n",
    "    # Fonctions de reaction\n",
    "    # q1 = (a - c1 - b*q2) / (2*b)\n",
    "    # q2 = (a - c2 - b*q1) / (2*b)\n",
    "    \n",
    "    # Resolution du systeme\n",
    "    q1 = (a - 2*c1 + c2) / (3*b)\n",
    "    q2 = (a - 2*c2 + c1) / (3*b)\n",
    "    \n",
    "    return max(0, q1), max(0, q2)\n",
    "\n",
    "\n",
    "def stackelberg_equilibrium(demand: LinearDemand,\n",
    "                            leader: Firm, follower: Firm) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calcule l'equilibre de Stackelberg.\n",
    "    \n",
    "    Le leader choisit en premier, anticipant la reaction du follower.\n",
    "    Retourne (q_leader*, q_follower*)\n",
    "    \"\"\"\n",
    "    a, b = demand.a, demand.b\n",
    "    c_L, c_F = leader.marginal_cost, follower.marginal_cost\n",
    "    \n",
    "    # Fonction de reaction du follower\n",
    "    # q_F(q_L) = (a - c_F - b*q_L) / (2*b)\n",
    "    \n",
    "    # Le leader maximise pi_L(q_L, q_F(q_L))\n",
    "    # pi_L = (a - b*(q_L + q_F) - c_L) * q_L\n",
    "    # Substitution et derivation -> q_L* = (a - 2*c_L + c_F) / (2*b)\n",
    "    \n",
    "    q_L = (a - 2*c_L + c_F) / (2*b)\n",
    "    q_F = (a - c_F - b*q_L) / (2*b)\n",
    "    \n",
    "    return max(0, q_L), max(0, q_F)\n",
    "\n",
    "\n",
    "# Exemple numerique\n",
    "demand = LinearDemand(a=100, b=1)\n",
    "firm_A = Firm(\"A\", marginal_cost=10)\n",
    "firm_B = Firm(\"B\", marginal_cost=10)\n",
    "\n",
    "print(\"Duopole avec demande P(Q) = 100 - Q, couts marginaux c = 10\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cournot\n",
    "q1_c, q2_c = cournot_equilibrium(demand, firm_A, firm_B)\n",
    "Q_c = q1_c + q2_c\n",
    "P_c = demand.price(Q_c)\n",
    "pi1_c = firm_A.profit(q1_c, P_c)\n",
    "pi2_c = firm_B.profit(q2_c, P_c)\n",
    "\n",
    "print(f\"\\nEquilibre de Cournot (simultane):\")\n",
    "print(f\"  q_A = {q1_c:.2f}, q_B = {q2_c:.2f}\")\n",
    "print(f\"  Q total = {Q_c:.2f}, Prix = {P_c:.2f}\")\n",
    "print(f\"  Profits: pi_A = {pi1_c:.2f}, pi_B = {pi2_c:.2f}\")\n",
    "\n",
    "# Stackelberg avec A leader\n",
    "q_L, q_F = stackelberg_equilibrium(demand, firm_A, firm_B)\n",
    "Q_s = q_L + q_F\n",
    "P_s = demand.price(Q_s)\n",
    "pi_L = firm_A.profit(q_L, P_s)\n",
    "pi_F = firm_B.profit(q_F, P_s)\n",
    "\n",
    "print(f\"\\nEquilibre de Stackelberg (A leader):\")\n",
    "print(f\"  q_A (leader) = {q_L:.2f}, q_B (follower) = {q_F:.2f}\")\n",
    "print(f\"  Q total = {Q_s:.2f}, Prix = {P_s:.2f}\")\n",
    "print(f\"  Profits: pi_A = {pi_L:.2f}, pi_B = {pi_F:.2f}\")\n",
    "\n",
    "print(f\"\\nAvantage du leader: {pi_L - pi1_c:.2f} (vs Cournot)\")\n",
    "print(f\"Desavantage du follower: {pi_F - pi2_c:.2f} (vs Cournot)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation : fonctions de reaction et equilibres\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "q_range = np.linspace(0, 50, 100)\n",
    "\n",
    "# Fonction de reaction de A : q_A = (a - c_A - b*q_B) / (2*b)\n",
    "def reaction_A(q_B):\n",
    "    return max(0, (demand.a - firm_A.marginal_cost - demand.b * q_B) / (2 * demand.b))\n",
    "\n",
    "def reaction_B(q_A):\n",
    "    return max(0, (demand.a - firm_B.marginal_cost - demand.b * q_A) / (2 * demand.b))\n",
    "\n",
    "# Tracer les fonctions de reaction\n",
    "q_A_values = [reaction_A(q_B) for q_B in q_range]\n",
    "q_B_values = [reaction_B(q_A) for q_A in q_range]\n",
    "\n",
    "ax.plot(q_A_values, q_range, 'b-', linewidth=2, label=\"Reaction de A (R_A)\")\n",
    "ax.plot(q_range, q_B_values, 'r-', linewidth=2, label=\"Reaction de B (R_B)\")\n",
    "\n",
    "# Equilibre de Cournot\n",
    "ax.scatter([q1_c], [q2_c], s=150, c='green', marker='o', zorder=5,\n",
    "           label=f\"Cournot ({q1_c:.1f}, {q2_c:.1f})\")\n",
    "\n",
    "# Equilibre de Stackelberg\n",
    "ax.scatter([q_L], [q_F], s=150, c='purple', marker='s', zorder=5,\n",
    "           label=f\"Stackelberg ({q_L:.1f}, {q_F:.1f})\")\n",
    "\n",
    "# Isoprofits du leader (approximation)\n",
    "q_A_grid = np.linspace(0.1, 50, 50)\n",
    "q_B_grid = np.linspace(0.1, 50, 50)\n",
    "Q_A, Q_B = np.meshgrid(q_A_grid, q_B_grid)\n",
    "Profit_A = (demand.a - demand.b * (Q_A + Q_B) - firm_A.marginal_cost) * Q_A\n",
    "\n",
    "# Contours d'isoprofit\n",
    "contours = ax.contour(Q_A, Q_B, Profit_A, levels=[400, 600, 800, pi_L], \n",
    "                      colors='blue', alpha=0.3, linestyles='dashed')\n",
    "ax.clabel(contours, inline=True, fontsize=8, fmt='%.0f')\n",
    "\n",
    "ax.set_xlabel(\"Quantite de A (q_A)\", fontsize=12)\n",
    "ax.set_ylabel(\"Quantite de B (q_B)\", fontsize=12)\n",
    "ax.set_title(\"Equilibres Cournot vs Stackelberg\", fontsize=14)\n",
    "ax.set_xlim(0, 50)\n",
    "ax.set_ylim(0, 50)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('stackelberg_vs_cournot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure sauvegardee: stackelberg_vs_cournot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Jeux Differentiels : Formalisation\n",
    "\n",
    "### 3.1 Structure d'un jeu differentiel\n",
    "\n",
    "Un jeu differentiel a $n$ joueurs est defini par :\n",
    "\n",
    "- **Dynamique d'etat** : $\\dot{x}(t) = f(x(t), u_1(t), ..., u_n(t), t)$\n",
    "- **Condition initiale** : $x(0) = x_0$\n",
    "- **Objectifs** : $J_i = \\int_0^T g_i(x(t), u_1(t), ..., u_n(t), t) dt + \\phi_i(x(T))$\n",
    "\n",
    "### 3.2 Equilibre de Nash en boucle ouverte\n",
    "\n",
    "Chaque joueur s'engage sur une trajectoire $u_i^*(t)$ pour $t \\in [0, T]$ au debut du jeu.\n",
    "\n",
    "**Condition d'equilibre** : Pour tout $i$, $u_i^*$ maximise $J_i$ etant donne $u_{-i}^*$.\n",
    "\n",
    "### 3.3 Equilibre en boucle fermee (feedback)\n",
    "\n",
    "Les joueurs utilisent des strategies de feedback $u_i(x(t), t)$.\n",
    "\n",
    "**Avantage** : Robuste aux perturbations et deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferentialGame:\n",
    "    \"\"\"\n",
    "    Classe de base pour les jeux differentiels a 2 joueurs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, T: float, dt: float = 0.01):\n",
    "        \"\"\"\n",
    "        T: horizon de temps\n",
    "        dt: pas de discretisation\n",
    "        \"\"\"\n",
    "        self.T = T\n",
    "        self.dt = dt\n",
    "        self.times = np.arange(0, T + dt, dt)\n",
    "    \n",
    "    def dynamics(self, x: float, u1: float, u2: float, t: float) -> float:\n",
    "        \"\"\"Dynamique dx/dt = f(x, u1, u2, t).\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def running_cost_1(self, x: float, u1: float, u2: float, t: float) -> float:\n",
    "        \"\"\"Cout instantane pour joueur 1.\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def running_cost_2(self, x: float, u1: float, u2: float, t: float) -> float:\n",
    "        \"\"\"Cout instantane pour joueur 2.\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def terminal_cost_1(self, x_T: float) -> float:\n",
    "        \"\"\"Cout terminal pour joueur 1.\"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def terminal_cost_2(self, x_T: float) -> float:\n",
    "        \"\"\"Cout terminal pour joueur 2.\"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def simulate(self, x0: float, \n",
    "                 strategy1: Callable, strategy2: Callable,\n",
    "                 feedback: bool = False) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Simule le jeu.\n",
    "        \n",
    "        Si feedback=True, strategies sont u(x, t).\n",
    "        Si feedback=False, strategies sont u(t).\n",
    "        \n",
    "        Retourne (times, x_trajectory, u1_trajectory, u2_trajectory)\n",
    "        \"\"\"\n",
    "        n_steps = len(self.times)\n",
    "        x = np.zeros(n_steps)\n",
    "        u1 = np.zeros(n_steps)\n",
    "        u2 = np.zeros(n_steps)\n",
    "        \n",
    "        x[0] = x0\n",
    "        \n",
    "        for i, t in enumerate(self.times[:-1]):\n",
    "            if feedback:\n",
    "                u1[i] = strategy1(x[i], t)\n",
    "                u2[i] = strategy2(x[i], t)\n",
    "            else:\n",
    "                u1[i] = strategy1(t)\n",
    "                u2[i] = strategy2(t)\n",
    "            \n",
    "            # Integration Euler\n",
    "            dx = self.dynamics(x[i], u1[i], u2[i], t)\n",
    "            x[i+1] = x[i] + dx * self.dt\n",
    "        \n",
    "        # Derniere action\n",
    "        t = self.times[-1]\n",
    "        if feedback:\n",
    "            u1[-1] = strategy1(x[-1], t)\n",
    "            u2[-1] = strategy2(x[-1], t)\n",
    "        else:\n",
    "            u1[-1] = strategy1(t)\n",
    "            u2[-1] = strategy2(t)\n",
    "        \n",
    "        return self.times, x, u1, u2\n",
    "    \n",
    "    def compute_costs(self, x: np.ndarray, u1: np.ndarray, \n",
    "                      u2: np.ndarray) -> Tuple[float, float]:\n",
    "        \"\"\"Calcule les couts totaux des deux joueurs.\"\"\"\n",
    "        J1 = 0.0\n",
    "        J2 = 0.0\n",
    "        \n",
    "        for i, t in enumerate(self.times[:-1]):\n",
    "            J1 += self.running_cost_1(x[i], u1[i], u2[i], t) * self.dt\n",
    "            J2 += self.running_cost_2(x[i], u1[i], u2[i], t) * self.dt\n",
    "        \n",
    "        J1 += self.terminal_cost_1(x[-1])\n",
    "        J2 += self.terminal_cost_2(x[-1])\n",
    "        \n",
    "        return J1, J2\n",
    "\n",
    "\n",
    "print(\"Classe DifferentialGame definie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Jeux Lineaires-Quadratiques (LQ)\n",
    "\n",
    "Les jeux LQ ont une structure speciale qui permet des solutions analytiques.\n",
    "\n",
    "### 4.1 Structure\n",
    "\n",
    "- **Dynamique lineaire** : $\\dot{x} = Ax + B_1 u_1 + B_2 u_2$\n",
    "- **Couts quadratiques** : $J_i = \\int_0^T (x^T Q_i x + u_i^T R_i u_i) dt$\n",
    "\n",
    "### 4.2 Solution en boucle ouverte\n",
    "\n",
    "Les conditions necessaires (Pontryagin) donnent un systeme d'equations differentielles couplees.\n",
    "\n",
    "### 4.3 Solution en boucle fermee\n",
    "\n",
    "La strategie optimale est lineaire : $u_i^*(x, t) = -K_i(t) x$\n",
    "\n",
    "Les matrices $K_i(t)$ satisfont des equations de Riccati couplees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LQDifferentialGame(DifferentialGame):\n",
    "    \"\"\"\n",
    "    Jeu differentiel lineaire-quadratique a somme non nulle.\n",
    "    \n",
    "    Dynamique: dx/dt = a*x + b1*u1 + b2*u2\n",
    "    Cout i: Ji = integral(qi*x^2 + ri*ui^2) dt + si*x(T)^2\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, T: float, \n",
    "                 a: float, b1: float, b2: float,\n",
    "                 q1: float, r1: float, s1: float,\n",
    "                 q2: float, r2: float, s2: float,\n",
    "                 dt: float = 0.01):\n",
    "        super().__init__(T, dt)\n",
    "        self.a = a\n",
    "        self.b1, self.b2 = b1, b2\n",
    "        self.q1, self.r1, self.s1 = q1, r1, s1\n",
    "        self.q2, self.r2, self.s2 = q2, r2, s2\n",
    "    \n",
    "    def dynamics(self, x: float, u1: float, u2: float, t: float) -> float:\n",
    "        return self.a * x + self.b1 * u1 + self.b2 * u2\n",
    "    \n",
    "    def running_cost_1(self, x: float, u1: float, u2: float, t: float) -> float:\n",
    "        return self.q1 * x**2 + self.r1 * u1**2\n",
    "    \n",
    "    def running_cost_2(self, x: float, u1: float, u2: float, t: float) -> float:\n",
    "        return self.q2 * x**2 + self.r2 * u2**2\n",
    "    \n",
    "    def terminal_cost_1(self, x_T: float) -> float:\n",
    "        return self.s1 * x_T**2\n",
    "    \n",
    "    def terminal_cost_2(self, x_T: float) -> float:\n",
    "        return self.s2 * x_T**2\n",
    "    \n",
    "    def solve_feedback_nash(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Resout l'equilibre de Nash en boucle fermee.\n",
    "        \n",
    "        Retourne les gains K1(t) et K2(t) tels que ui = -Ki*x.\n",
    "        \n",
    "        Resolution via equations de Riccati couplees (backward).\n",
    "        \"\"\"\n",
    "        n = len(self.times)\n",
    "        P1 = np.zeros(n)  # Solution Riccati joueur 1\n",
    "        P2 = np.zeros(n)  # Solution Riccati joueur 2\n",
    "        K1 = np.zeros(n)  # Gain feedback joueur 1\n",
    "        K2 = np.zeros(n)  # Gain feedback joueur 2\n",
    "        \n",
    "        # Conditions terminales\n",
    "        P1[-1] = self.s1\n",
    "        P2[-1] = self.s2\n",
    "        \n",
    "        # Integration backward\n",
    "        for i in range(n-2, -1, -1):\n",
    "            # Gains optimaux (derivee de Ji par rapport a ui = 0)\n",
    "            K1[i+1] = self.b1 * P1[i+1] / self.r1\n",
    "            K2[i+1] = self.b2 * P2[i+1] / self.r2\n",
    "            \n",
    "            # Dynamique effective avec feedback de l'adversaire\n",
    "            A_cl = self.a - self.b1 * K1[i+1] - self.b2 * K2[i+1]\n",
    "            \n",
    "            # Equations de Riccati couplees (version simplifiee)\n",
    "            dP1 = -(2 * A_cl * P1[i+1] + self.q1 - P1[i+1]**2 * self.b1**2 / self.r1)\n",
    "            dP2 = -(2 * A_cl * P2[i+1] + self.q2 - P2[i+1]**2 * self.b2**2 / self.r2)\n",
    "            \n",
    "            P1[i] = P1[i+1] - dP1 * self.dt\n",
    "            P2[i] = P2[i+1] - dP2 * self.dt\n",
    "        \n",
    "        # Calcul des gains finaux\n",
    "        for i in range(n):\n",
    "            K1[i] = self.b1 * P1[i] / self.r1\n",
    "            K2[i] = self.b2 * P2[i] / self.r2\n",
    "        \n",
    "        return K1, K2\n",
    "\n",
    "\n",
    "# Exemple : Course a l'investissement (publicitaire)\n",
    "print(\"Jeu LQ : Course a l'investissement publicitaire\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\\nModele:\n",
    "- x(t) = part de marche relative (firme 1 - firme 2)\n",
    "- u1, u2 = efforts publicitaires\n",
    "- Dynamique: dx/dt = -0.1*x + u1 - u2\n",
    "- Cout: minimiser x^2 + ui^2 (equilibre + cout d'effort)\"\"\")\n",
    "\n",
    "lq_game = LQDifferentialGame(\n",
    "    T=10.0, dt=0.05,\n",
    "    a=-0.1,   # Dissipation naturelle de l'avantage\n",
    "    b1=1.0, b2=-1.0,  # Impact des efforts (oppose)\n",
    "    q1=1.0, r1=1.0, s1=0.0,  # Joueur 1 veut x=0 (equilibre)\n",
    "    q2=1.0, r2=1.0, s2=0.0   # Joueur 2 aussi\n",
    ")\n",
    "\n",
    "# Resoudre l'equilibre feedback\n",
    "K1, K2 = lq_game.solve_feedback_nash()\n",
    "\n",
    "print(f\"\\nGains feedback initiaux: K1(0) = {K1[0]:.4f}, K2(0) = {K2[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation avec differentes conditions initiales\n",
    "x0_values = [-2.0, -1.0, 0.0, 1.0, 2.0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for x0 in x0_values:\n",
    "    # Strategies feedback Nash\n",
    "    def strategy1_fb(x, t):\n",
    "        idx = min(int(t / lq_game.dt), len(K1) - 1)\n",
    "        return -K1[idx] * x\n",
    "    \n",
    "    def strategy2_fb(x, t):\n",
    "        idx = min(int(t / lq_game.dt), len(K2) - 1)\n",
    "        return -K2[idx] * x\n",
    "    \n",
    "    times, x, u1, u2 = lq_game.simulate(x0, strategy1_fb, strategy2_fb, feedback=True)\n",
    "    J1, J2 = lq_game.compute_costs(x, u1, u2)\n",
    "    \n",
    "    all_results.append((x0, times, x, u1, u2, J1, J2))\n",
    "\n",
    "# Plot trajectoires d'etat\n",
    "ax1 = axes[0, 0]\n",
    "for x0, times, x, u1, u2, J1, J2 in all_results:\n",
    "    ax1.plot(times, x, label=f\"x0={x0}\")\n",
    "ax1.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "ax1.set_xlabel('Temps')\n",
    "ax1.set_ylabel('Etat x(t)')\n",
    "ax1.set_title('Trajectoires d\\'etat (feedback Nash)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot controles\n",
    "ax2 = axes[0, 1]\n",
    "for x0, times, x, u1, u2, J1, J2 in all_results:\n",
    "    if x0 == 2.0:  # Un seul exemple\n",
    "        ax2.plot(times, u1, 'b-', label='u1 (firme 1)')\n",
    "        ax2.plot(times, u2, 'r-', label='u2 (firme 2)')\n",
    "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Temps')\n",
    "ax2.set_ylabel('Controle u(t)')\n",
    "ax2.set_title('Controles optimaux (x0=2.0)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot gains K(t)\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(lq_game.times, K1, 'b-', linewidth=2, label='K1(t)')\n",
    "ax3.plot(lq_game.times, K2, 'r-', linewidth=2, label='K2(t)')\n",
    "ax3.set_xlabel('Temps')\n",
    "ax3.set_ylabel('Gain K(t)')\n",
    "ax3.set_title('Gains feedback (u = -K*x)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot couts\n",
    "ax4 = axes[1, 1]\n",
    "x0s = [r[0] for r in all_results]\n",
    "J1s = [r[5] for r in all_results]\n",
    "J2s = [r[6] for r in all_results]\n",
    "\n",
    "width = 0.35\n",
    "x_pos = np.arange(len(x0s))\n",
    "ax4.bar(x_pos - width/2, J1s, width, label='Cout J1', color='blue', alpha=0.7)\n",
    "ax4.bar(x_pos + width/2, J2s, width, label='Cout J2', color='red', alpha=0.7)\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels([f'x0={x0}' for x0 in x0s])\n",
    "ax4.set_ylabel('Cout total')\n",
    "ax4.set_title('Couts par condition initiale')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lq_game_feedback_nash.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure sauvegardee: lq_game_feedback_nash.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stackelberg Dynamique\n",
    "\n",
    "### 5.1 Open-Loop Stackelberg\n",
    "\n",
    "Le leader annonce sa trajectoire complete $u_L(t)$ pour $t \\in [0,T]$ au debut. Le follower repond optimalement.\n",
    "\n",
    "### 5.2 Feedback Stackelberg\n",
    "\n",
    "Le leader annonce une strategie de feedback $u_L(x,t)$. Le follower observe $u_L$ et l'etat $x(t)$.\n",
    "\n",
    "**Probleme** : Le leader doit resoudre un probleme de controle optimal ou l'etat inclut les co-etats du follower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackelbergDuopoly:\n",
    "    \"\"\"\n",
    "    Duopole de Stackelberg dynamique.\n",
    "    \n",
    "    Etat: x = stock/capacite\n",
    "    Controles: u_L, u_F = taux de production\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, T: float, dt: float,\n",
    "                 a: float, b: float,  # Demande P = a - b*Q\n",
    "                 c_L: float, c_F: float,  # Couts marginaux\n",
    "                 delta: float = 0.1):  # Facteur d'actualisation\n",
    "        self.T = T\n",
    "        self.dt = dt\n",
    "        self.a, self.b = a, b\n",
    "        self.c_L, self.c_F = c_L, c_F\n",
    "        self.delta = delta\n",
    "        self.times = np.arange(0, T + dt, dt)\n",
    "    \n",
    "    def follower_reaction(self, q_L: float) -> float:\n",
    "        \"\"\"Meilleure reponse statique du follower.\"\"\"\n",
    "        q_F = (self.a - self.c_F - self.b * q_L) / (2 * self.b)\n",
    "        return max(0, q_F)\n",
    "    \n",
    "    def leader_profit(self, q_L: float, q_F: float) -> float:\n",
    "        \"\"\"Profit du leader.\"\"\"\n",
    "        Q = q_L + q_F\n",
    "        P = max(0, self.a - self.b * Q)\n",
    "        return (P - self.c_L) * q_L\n",
    "    \n",
    "    def follower_profit(self, q_L: float, q_F: float) -> float:\n",
    "        \"\"\"Profit du follower.\"\"\"\n",
    "        Q = q_L + q_F\n",
    "        P = max(0, self.a - self.b * Q)\n",
    "        return (P - self.c_F) * q_F\n",
    "    \n",
    "    def solve_static_stackelberg(self) -> Tuple[float, float, float, float]:\n",
    "        \"\"\"Resout l'equilibre de Stackelberg statique.\"\"\"\n",
    "        # Optimisation du leader anticipant la reaction du follower\n",
    "        def leader_objective(q_L):\n",
    "            q_F = self.follower_reaction(q_L)\n",
    "            return -self.leader_profit(q_L, q_F)  # Negatif car on minimise\n",
    "        \n",
    "        result = minimize_scalar(leader_objective, bounds=(0, self.a / self.b), method='bounded')\n",
    "        q_L_star = result.x\n",
    "        q_F_star = self.follower_reaction(q_L_star)\n",
    "        \n",
    "        pi_L = self.leader_profit(q_L_star, q_F_star)\n",
    "        pi_F = self.follower_profit(q_L_star, q_F_star)\n",
    "        \n",
    "        return q_L_star, q_F_star, pi_L, pi_F\n",
    "    \n",
    "    def simulate_dynamic(self, commitment_level: float = 1.0\n",
    "                        ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Simule le jeu dynamique.\n",
    "        \n",
    "        commitment_level: 1.0 = engagement total (Stackelberg)\n",
    "                         0.0 = pas d'engagement (Nash-Cournot)\n",
    "        \"\"\"\n",
    "        n = len(self.times)\n",
    "        q_L = np.zeros(n)\n",
    "        q_F = np.zeros(n)\n",
    "        profits_L = np.zeros(n)\n",
    "        profits_F = np.zeros(n)\n",
    "        \n",
    "        # Solution Stackelberg statique\n",
    "        q_L_stack, q_F_stack, _, _ = self.solve_static_stackelberg()\n",
    "        \n",
    "        # Solution Cournot\n",
    "        q_cournot = (self.a - self.c_L) / (3 * self.b)  # Symetrique\n",
    "        \n",
    "        for i in range(n):\n",
    "            # Interpolation entre Cournot et Stackelberg selon commitment\n",
    "            q_L[i] = commitment_level * q_L_stack + (1 - commitment_level) * q_cournot\n",
    "            q_F[i] = self.follower_reaction(q_L[i])\n",
    "            \n",
    "            profits_L[i] = self.leader_profit(q_L[i], q_F[i])\n",
    "            profits_F[i] = self.follower_profit(q_L[i], q_F[i])\n",
    "        \n",
    "        return q_L, q_F, profits_L, profits_F\n",
    "\n",
    "\n",
    "# Analyse du niveau d'engagement\n",
    "print(\"Stackelberg Dynamique : Impact du niveau d'engagement\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "duopoly = StackelbergDuopoly(T=10, dt=0.1, a=100, b=1, c_L=10, c_F=10)\n",
    "\n",
    "commitment_levels = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "results = []\n",
    "\n",
    "for c in commitment_levels:\n",
    "    q_L, q_F, pi_L, pi_F = duopoly.simulate_dynamic(commitment_level=c)\n",
    "    results.append((c, q_L.mean(), q_F.mean(), pi_L.mean(), pi_F.mean()))\n",
    "\n",
    "print(f\"\\n{'Engagement':<12} {'q_L':<10} {'q_F':<10} {'pi_L':<12} {'pi_F':<12}\")\n",
    "print(\"-\"*56)\n",
    "for c, q_L, q_F, pi_L, pi_F in results:\n",
    "    print(f\"{c:<12.2f} {q_L:<10.2f} {q_F:<10.2f} {pi_L:<12.2f} {pi_F:<12.2f}\")\n",
    "\n",
    "print(\"\\n0.0 = Cournot (simultane), 1.0 = Stackelberg (sequentiel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Quantites\n",
    "ax1 = axes[0]\n",
    "commitments = [r[0] for r in results]\n",
    "q_Ls = [r[1] for r in results]\n",
    "q_Fs = [r[2] for r in results]\n",
    "\n",
    "ax1.plot(commitments, q_Ls, 'bo-', markersize=10, linewidth=2, label='Leader')\n",
    "ax1.plot(commitments, q_Fs, 'rs-', markersize=10, linewidth=2, label='Follower')\n",
    "ax1.set_xlabel('Niveau d\\'engagement', fontsize=12)\n",
    "ax1.set_ylabel('Quantite moyenne', fontsize=12)\n",
    "ax1.set_title('Quantites vs Engagement')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Profits\n",
    "ax2 = axes[1]\n",
    "pi_Ls = [r[3] for r in results]\n",
    "pi_Fs = [r[4] for r in results]\n",
    "\n",
    "ax2.plot(commitments, pi_Ls, 'bo-', markersize=10, linewidth=2, label='Leader')\n",
    "ax2.plot(commitments, pi_Fs, 'rs-', markersize=10, linewidth=2, label='Follower')\n",
    "ax2.set_xlabel('Niveau d\\'engagement', fontsize=12)\n",
    "ax2.set_ylabel('Profit moyen', fontsize=12)\n",
    "ax2.set_title('Profits vs Engagement')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Bien-etre total\n",
    "ax3 = axes[2]\n",
    "total_profits = [pi_L + pi_F for pi_L, pi_F in zip(pi_Ls, pi_Fs)]\n",
    "total_quantities = [q_L + q_F for q_L, q_F in zip(q_Ls, q_Fs)]\n",
    "\n",
    "ax3.plot(commitments, total_profits, 'go-', markersize=10, linewidth=2, label='Profits totaux')\n",
    "ax3_twin = ax3.twinx()\n",
    "ax3_twin.plot(commitments, total_quantities, 'm^-', markersize=10, linewidth=2, label='Q total')\n",
    "\n",
    "ax3.set_xlabel('Niveau d\\'engagement', fontsize=12)\n",
    "ax3.set_ylabel('Profits totaux', color='green', fontsize=12)\n",
    "ax3_twin.set_ylabel('Quantite totale', color='purple', fontsize=12)\n",
    "ax3.set_title('Bien-etre vs Engagement')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('stackelberg_commitment.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure sauvegardee: stackelberg_commitment.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applications Economiques\n",
    "\n",
    "### 6.1 Competition oligopolistique dynamique\n",
    "\n",
    "Les modeles de Stackelberg sont utilises pour analyser :\n",
    "- **Entree sur le marche** : l'incumbent comme leader\n",
    "- **Capacite de production** : investissements irreversibles\n",
    "- **Publicite** : campagnes marketing\n",
    "\n",
    "### 6.2 Regulation\n",
    "\n",
    "Le regulateur (leader) fixe des regles, les entreprises (followers) s'adaptent.\n",
    "\n",
    "### 6.3 Commerce international\n",
    "\n",
    "Pays exportateurs vs importateurs, guerres commerciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application : Jeu d'entree avec couts fixes\n",
    "print(\"Application : Jeu d'entree sur le marche\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class EntryGame:\n",
    "    \"\"\"\n",
    "    Modele d'entree avec cout fixe et engagement strategique.\n",
    "    \n",
    "    Incumbent peut investir en capacite (engagement)\n",
    "    avant que l'entrant decide d'entrer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, a: float = 100, b: float = 1,\n",
    "                 c: float = 10, F: float = 200,\n",
    "                 k: float = 5):  # Cout par unite de capacite\n",
    "        self.a, self.b = a, b\n",
    "        self.c = c  # Cout marginal\n",
    "        self.F = F  # Cout fixe d'entree\n",
    "        self.k = k  # Cout de capacite\n",
    "    \n",
    "    def incumbent_profit_monopoly(self, K: float) -> float:\n",
    "        \"\"\"Profit du monopole avec capacite K.\"\"\"\n",
    "        q_monopoly = (self.a - self.c) / (2 * self.b)\n",
    "        q = min(q_monopoly, K)  # Contraint par la capacite\n",
    "        P = self.a - self.b * q\n",
    "        return (P - self.c) * q - self.k * K\n",
    "    \n",
    "    def duopoly_equilibrium(self, K: float) -> Tuple[float, float]:\n",
    "        \"\"\"Equilibre de Cournot avec incumbent ayant capacite K.\"\"\"\n",
    "        # Simplification : incumbent peut produire jusqu'a K\n",
    "        q_inc = (self.a - 2*self.c + self.c) / (3 * self.b)\n",
    "        q_ent = (self.a - 2*self.c + self.c) / (3 * self.b)\n",
    "        \n",
    "        # Si la capacite est contraignante\n",
    "        if q_inc > K:\n",
    "            q_inc = K\n",
    "            q_ent = (self.a - self.c - self.b * K) / (2 * self.b)\n",
    "        \n",
    "        return max(0, q_inc), max(0, q_ent)\n",
    "    \n",
    "    def entrant_profit(self, K: float) -> float:\n",
    "        \"\"\"Profit de l'entrant si entree.\"\"\"\n",
    "        q_inc, q_ent = self.duopoly_equilibrium(K)\n",
    "        Q = q_inc + q_ent\n",
    "        P = max(0, self.a - self.b * Q)\n",
    "        return (P - self.c) * q_ent - self.F\n",
    "    \n",
    "    def entry_deterrence_capacity(self) -> float:\n",
    "        \"\"\"Capacite minimale pour deterrer l'entree.\"\"\"\n",
    "        # Trouver K tel que entrant_profit(K) = 0\n",
    "        def objective(K):\n",
    "            return abs(self.entrant_profit(K))\n",
    "        \n",
    "        result = minimize_scalar(objective, bounds=(0, 100), method='bounded')\n",
    "        return result.x\n",
    "    \n",
    "    def analyze(self):\n",
    "        \"\"\"Analyse complete du jeu.\"\"\"\n",
    "        K_deter = self.entry_deterrence_capacity()\n",
    "        \n",
    "        # Profits selon les scenarios\n",
    "        scenarios = {}\n",
    "        \n",
    "        # 1. Pas d'engagement, pas d'entree\n",
    "        K_monopoly = 0\n",
    "        pi_monopoly = self.incumbent_profit_monopoly(100)  # Capacite illimitee\n",
    "        scenarios['Monopole sans investissement'] = (0, pi_monopoly, True)\n",
    "        \n",
    "        # 2. Entree et duopole\n",
    "        K_duopoly = 30  # Capacite standard\n",
    "        q_inc, q_ent = self.duopoly_equilibrium(K_duopoly)\n",
    "        Q = q_inc + q_ent\n",
    "        P = self.a - self.b * Q\n",
    "        pi_duopoly = (P - self.c) * q_inc - self.k * K_duopoly\n",
    "        scenarios['Duopole'] = (K_duopoly, pi_duopoly, False)\n",
    "        \n",
    "        # 3. Deterrence par capacite\n",
    "        pi_deter = self.incumbent_profit_monopoly(K_deter)\n",
    "        scenarios['Deterrence par capacite'] = (K_deter, pi_deter, True)\n",
    "        \n",
    "        return K_deter, scenarios\n",
    "\n",
    "\n",
    "entry_game = EntryGame(a=100, b=1, c=10, F=200, k=5)\n",
    "K_deter, scenarios = entry_game.analyze()\n",
    "\n",
    "print(f\"\\nCapacite de deterrence: K* = {K_deter:.2f}\")\n",
    "print(f\"Profit entrant si K = K*: {entry_game.entrant_profit(K_deter):.2f}\")\n",
    "\n",
    "print(f\"\\n{'Scenario':<30} {'Capacite':<12} {'Profit Inc.':<15} {'Monopole?'}\")\n",
    "print(\"-\"*70)\n",
    "for name, (K, pi, monopole) in scenarios.items():\n",
    "    print(f\"{name:<30} {K:<12.2f} {pi:<15.2f} {monopole}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exercices\n",
    "\n",
    "### Exercice 1 : Stackelberg asymetrique\n",
    "\n",
    "Analysez un duopole de Stackelberg ou le leader et le follower ont des couts marginaux differents ($c_L \\neq c_F$).\n",
    "\n",
    "### Exercice 2 : Jeu LQ a somme nulle\n",
    "\n",
    "Implementez et resolvez un jeu differentiel a somme nulle (poursuite-evasion).\n",
    "\n",
    "### Exercice 3 : Commitment value\n",
    "\n",
    "Calculez la \"valeur de l'engagement\" : la difference de profit pour le leader entre Stackelberg et Cournot.\n",
    "\n",
    "### Exercice 4 : Stackelberg a 3 joueurs\n",
    "\n",
    "Modelisez un jeu avec un leader et deux followers qui reagissent simultanement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espace pour les exercices\n",
    "\n",
    "# Exercice 3 : Valeur de l'engagement\n",
    "def commitment_value(demand: LinearDemand, firm_L: Firm, firm_F: Firm) -> float:\n",
    "    \"\"\"\n",
    "    Calcule la valeur de l'engagement = profit_Stackelberg - profit_Cournot\n",
    "    pour le leader.\n",
    "    \"\"\"\n",
    "    # Cournot\n",
    "    q1_c, q2_c = cournot_equilibrium(demand, firm_L, firm_F)\n",
    "    Q_c = q1_c + q2_c\n",
    "    P_c = demand.price(Q_c)\n",
    "    pi_cournot = firm_L.profit(q1_c, P_c)\n",
    "    \n",
    "    # Stackelberg\n",
    "    q_L, q_F = stackelberg_equilibrium(demand, firm_L, firm_F)\n",
    "    Q_s = q_L + q_F\n",
    "    P_s = demand.price(Q_s)\n",
    "    pi_stackelberg = firm_L.profit(q_L, P_s)\n",
    "    \n",
    "    return pi_stackelberg - pi_cournot\n",
    "\n",
    "# Test\n",
    "value = commitment_value(demand, firm_A, firm_B)\n",
    "print(f\"Valeur de l'engagement pour le leader: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resume et Points Cles\n",
    "\n",
    "### Ce que nous avons appris\n",
    "\n",
    "1. **Jeux dynamiques** : les decisions se deroulent dans le temps\n",
    "2. **Boucle ouverte vs fermee** : engagement vs adaptation\n",
    "3. **Stackelberg** : avantage du premier joueur par engagement\n",
    "4. **Jeux LQ** : solutions analytiques via equations de Riccati\n",
    "5. **Applications** : oligopoles, entree, regulation\n",
    "\n",
    "### Formules cles\n",
    "\n",
    "| Concept | Formule |\n",
    "|---------|--------|\n",
    "| Reaction follower (duopole lineaire) | $q_F(q_L) = \\frac{a - c_F - b \\cdot q_L}{2b}$ |\n",
    "| Stackelberg (leader) | $q_L^* = \\frac{a - 2c_L + c_F}{2b}$ |\n",
    "| Feedback LQ | $u^*(x,t) = -K(t) \\cdot x$ |\n",
    "| Valeur engagement | $\\Delta \\pi = \\pi_{Stack} - \\pi_{Cournot}$ |\n",
    "\n",
    "### Comparaison des equilibres\n",
    "\n",
    "| Aspect | Cournot | Stackelberg |\n",
    "|--------|---------|-------------|\n",
    "| Timing | Simultane | Sequentiel |\n",
    "| Output total | Plus bas | Plus haut |\n",
    "| Prix | Plus haut | Plus bas |\n",
    "| Profit leader | Standard | Avantage |\n",
    "| Bien-etre | Moindre | Meilleur |\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook suivant** : [GameTheory-14-MechanismDesign](GameTheory-14-MechanismDesign.ipynb) - Theorie des mecanismes et principe de revelation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GameTheory WSL + OpenSpiel)",
   "language": "python",
   "name": "gametheory-wsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}