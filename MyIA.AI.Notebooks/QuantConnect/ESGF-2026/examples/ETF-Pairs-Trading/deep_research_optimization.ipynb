{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Deep Research: ETF Pairs Trading Optimization\n\n**Navigation** : [Index](../../README.md) | [Retour](../README.md)\n\n## Objectif\n\nMaximiser le ratio de Sharpe pour la strategie de pairs trading sur ETF.\n\n## Vue d'ensemble de la strategie\n\n- **Selection des pairs** : Test de cointegration + filtre demi-vie + filtre volatilite\n- **Entree** : Le spread s'ecarte de la moyenne (z-score > seuil)\n- **Sortie** : Le spread revertent a la moyenne (z-score traverse 0)\n- **Gestion du risque** : Stops par jambe desactives (preserver la neutralite du marche)\n\n## Parametres actuels (a optimiser)\n\n- `half_life_max` : 30 jours (filtre les pairs a reversion lente)\n- `z_exit_threshold` : 0.0 (sortie a la moyenne)\n- `stop_loss_per_leg` : False\n\n## Objectifs d'apprentissage\n\nA la fin de ce notebook, vous saurez :\n1. Comprendre le concept de cointegration et son application au pairs trading\n2. Calculer la demi-vie de reversion a la moyenne (processus d'Ornstein-Uhlenbeck)\n3. Implementer une selection de pairs multi-criteres (cointegration, volatilite, demi-vie)\n4. Backtester une strategie de pairs trading avec z-score\n5. Executer un grid search pour optimiser les parametres\n6. Analyser la performance market-neutral de la strategie\n\n### Prerequis\n\n- Python 3.10+ avec pandas, numpy, statsmodels, yfinance\n- Connaissance des statistiques (correlation, regression, tests statistiques)\n- Comprehension du z-score et des processus stochastiques\n- Familiarite avec les ETFs et le trading market-neutral\n\n### Duree estimee : 75 minutes\n\n## Questions de recherche\n\n1. Quel est le seuil de demi-vie optimal pour la selection des pairs ?\n2. Doit-on utiliser un seuil de sortie z-score different de 0 ?\n3. Quel seuil de volatilite du spread maximise les rendements ajustes du risque ?\n4. Quels pairs ETF ont les relations de cointegration les plus stables ?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "# ETF Universe\n",
    "ETF_LIST = [\n",
    "    'SPY',   # S&P 500\n",
    "    'QQQ',   # NASDAQ-100\n",
    "    'IWM',   # Russell 2000\n",
    "    'DIA',   # Dow Jones\n",
    "    'VTI',   # Total Market\n",
    "    'XLE',   # Energy\n",
    "    'XLK',   # Technology\n",
    "    'XLF',   # Financial\n",
    "    'XLV',   # Healthcare\n",
    "    'XLY',   # Consumer Discretionary\n",
    "]\n",
    "\n",
    "print(f\"ETF Universe: {len(ETF_LIST)} ETFs\")\n",
    "print(f\"Possible pairs: {len(list(combinations(ETF_LIST, 2)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ETF data\n",
    "print(\"Downloading ETF data...\")\n",
    "etf_data = {}\n",
    "for etf in ETF_LIST:\n",
    "    try:\n",
    "        df = yf.download(etf, start=\"2015-01-01\", end=\"2025-02-18\", progress=False)\n",
    "        if not df.empty:\n",
    "            etf_data[etf] = df['Close'].copy()\n",
    "            if isinstance(etf_data[etf], pd.DataFrame):\n",
    "                etf_data[etf] = etf_data[etf].iloc[:, 0]\n",
    "            print(f\"  {etf}: {len(etf_data[etf])} days\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {etf}: Error - {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully downloaded {len(etf_data)} ETFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Interpretation : Donnees historiques ETF\n\nLe chargement des donnees ETF fournit la base pour l'analyse de cointegration et le backtesting.\n\n| ETF | Description | Role typique dans les pairs |\n|-----|-------------|----------------------------|\n| SPY | S&P 500 | Reference large market |\n| QQQ | NASDAQ-100 | Tech/Growth |\n| IWM | Russell 2000 | Small cap |\n| DIA | Dow Jones | Blue chips |\n| VTI | Total Market | Broad diversification |\n| XLK, XLF, XLV, XLY, XLE | Sector ETFs | Sector-specific plays |\n\n**Points cles** :\n- Les ETF sectoriels offrent des opportunits de pairs intra-sector (ex: XLK vs XLV)\n- Les broad market ETFs (SPY, VTI) sont souvent cointegres entre eux\n- La periode 2015-2025 couvre differents regimes de marche (bull, bear, COVID)\n- La liquidite des ETF garantit des executions fiables pour le pairs trading\n\n> **Note technique** : Pour la production sur QuantConnect, ces ETFs sont disponibles avec des donnees quotidiennes depuis 2000+. Le pairs trading fonctionne mieux avec des donnees quotidiennes ou hebdomadaires.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate half-life of mean reversion\n",
    "def calculate_half_life(spread):\n",
    "    \"\"\"Calculate half-life of mean reversion using OU process\"\"\"\n",
    "    spread_lagged = spread[:-1]\n",
    "    spread_current = spread[1:]\n",
    "    \n",
    "    # Remove NaN\n",
    "    mask = ~(np.isnan(spread_lagged) | np.isnan(spread_current))\n",
    "    spread_lagged = spread_lagged[mask]\n",
    "    spread_current = spread_current[mask]\n",
    "    \n",
    "    if len(spread_lagged) < 10:\n",
    "        return 999\n",
    "    \n",
    "    # Calculate lag-1 autocorrelation\n",
    "    corr_lag1 = np.corrcoef(spread_lagged, spread_current)[0, 1]\n",
    "    \n",
    "    if np.isnan(corr_lag1) or corr_lag1 <= 0 or corr_lag1 >= 1:\n",
    "        return 999\n",
    "    \n",
    "    # Half-life = -ln(2) / ln(corr)\n",
    "    half_life = -np.log(2) / np.log(corr_lag1)\n",
    "    return half_life\n",
    "\n",
    "# Test with example pair (SPY-QQQ)\n",
    "if 'SPY' in etf_data and 'QQQ' in etf_data:\n",
    "    # Align data\n",
    "    df = pd.DataFrame({'SPY': etf_data['SPY'], 'QQQ': etf_data['QQQ']}).dropna()\n",
    "    \n",
    "    # Calculate spread (price ratio)\n",
    "    spread = df['SPY'] / df['QQQ']\n",
    "    \n",
    "    # Calculate half-life\n",
    "    hl = calculate_half_life(spread.values)\n",
    "    print(f\"SPY-QQQ Half-life: {hl:.1f} days\")\n",
    "    \n",
    "    # Calculate spread volatility\n",
    "    spread_vol = spread.pct_change().std() * np.sqrt(252)\n",
    "    print(f\"SPY-QQQ Spread Volatility: {spread_vol*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Interpretation : Demi-vie de reversion a la moyenne\n\nLa demi-vie mesure le temps necessaire pour que le spread revienne a sa moyenne apres une deviation.\n\n| Concept | Formule | Interpretation |\n|---------|---------|----------------|\n| Half-life | -ln(2) / ln(corr_lag1) | Jours pour que l'ecart diminue de moitie |\n| OU Process | dX = theta(mu - X)dt + sigma dW | Modele de retour a la moyenne |\n\n**Points cles** :\n- Une demi-vie courte (< 20 jours) indique une reversion rapide (ideal pour le trading)\n- Une demi-vie longue (> 60 jours) indique une convergence lente (eviter)\n- La volatilite du spread doit etre suffisante pour generer des signaux\n- Le pair SPY-QQQ est un exemple typique de deux indices fortement correles\n\n> **Note technique** : La demi-vie est calculee a partir de l'autocorrelation lag-1. Pour des estimations plus robustes, considerer la regression OLS sur le processus d'Ornstein-Uhlenbeck.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select pairs based on cointegration and half-life\n",
    "def select_pairs(etf_data, \n",
    "                 pvalue_threshold=0.05,\n",
    "                 vol_threshold=0.01,\n",
    "                 half_life_max=30):\n",
    "    \"\"\"\n",
    "    Select cointegrated pairs with:\n",
    "    - P-value < pvalue_threshold (strong cointegration)\n",
    "    - Spread volatility > vol_threshold (sufficient deviation)\n",
    "    - Half-life < half_life_max (reasonably fast reversion)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for etf1, etf2 in combinations(etf_data.keys(), 2):\n",
    "        # Align data\n",
    "        df = pd.DataFrame({etf1: etf_data[etf1], etf2: etf_data[etf2]}).dropna()\n",
    "        \n",
    "        if len(df) < 252:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Cointegration test\n",
    "            score, pvalue, _ = coint(df[etf1], df[etf2])\n",
    "            \n",
    "            # Calculate spread (hedge-adjusted)\n",
    "            spread = df[etf1] - df[etf2] * (df[etf1].mean() / df[etf2].mean())\n",
    "            \n",
    "            # Spread volatility\n",
    "            vol = spread.pct_change().std()\n",
    "            \n",
    "            # Half-life\n",
    "            hl = calculate_half_life(spread.values)\n",
    "            \n",
    "            # Correlation\n",
    "            corr = df[etf1].corr(df[etf2])\n",
    "            \n",
    "            if pvalue < pvalue_threshold and vol > vol_threshold and hl < half_life_max:\n",
    "                results.append({\n",
    "                    'etf1': etf1,\n",
    "                    'etf2': etf2,\n",
    "                    'pvalue': pvalue,\n",
    "                    'correlation': corr,\n",
    "                    'volatility': vol,\n",
    "                    'half_life': hl\n",
    "                })\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Test current parameters\n",
    "pairs_current = select_pairs(etf_data, half_life_max=30)\n",
    "print(f\"Pairs with half_life < 30 days: {len(pairs_current)}\")\n",
    "if not pairs_current.empty:\n",
    "    print(pairs_current.sort_values('half_life').head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Interpretation : Selection des pairs cointegres\n\nLa selection des pairs combine trois criteres pour identifier les opportunitses de pairs trading.\n\n| Critere | Description | Seuil |\n|---------|-------------|-------|\n| Cointegration | Test statistique de relation long terme | p-value < 0.05 |\n| Volatilite du spread | Amplitude des deviations du spread | vol > 0.01 |\n| Demi-vie | Vitesse de reversion a la moyenne | half-life < 30 jours |\n\n**Points cles** :\n- La cointegration garantit que les prix vont converger a long terme\n- La demi-vie courte (< 30 jours) assure une reversion rapide\n- La volatilite minimale assure des opportunites de trading exploitables\n- Le nombre de pairs selectionnes depend de la severite des criteres\n\n> **Note technique** : Le test de cointegration d'Engle-Granger est une methode simple mais limitee. Pour des analyses plus avancees, considerer le test de Johansen (cointegration multiple).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest pairs trading strategy\n",
    "def backtest_pairs(etf_data, pairs, z_entry=2.0, z_exit=0.0, lookback=20):\n",
    "    \"\"\"\n",
    "    Simple backtest for pairs trading.\n",
    "    \n",
    "    Entry: When z-score > z_entry (or < -z_entry)\n",
    "    Exit: When z-score crosses z_exit\n",
    "    \"\"\"\n",
    "    if pairs.empty:\n",
    "        return None\n",
    "    \n",
    "    total_returns = []\n",
    "    \n",
    "    for _, row in pairs.iterrows():\n",
    "        etf1, etf2 = row['etf1'], row['etf2']\n",
    "        \n",
    "        # Get aligned data\n",
    "        df = pd.DataFrame({etf1: etf_data[etf1], etf2: etf_data[etf2]}).dropna()\n",
    "        \n",
    "        # Calculate spread\n",
    "        hedge_ratio = (df[etf1].mean() / df[etf2].mean())\n",
    "        spread = df[etf1] - df[etf2] * hedge_ratio\n",
    "        \n",
    "        # Z-score\n",
    "        spread_mean = spread.rolling(lookback).mean()\n",
    "        spread_std = spread.rolling(lookback).std()\n",
    "        z_score = (spread - spread_mean) / spread_std\n",
    "        \n",
    "        # Generate signals\n",
    "        long_signal = (z_score > z_entry).astype(int) - (z_score < -z_entry).astype(int)\n",
    "        \n",
    "        # Exit when z_score crosses z_exit\n",
    "        exit_long = (z_score <= z_exit) & (long_signal == 1)\n",
    "        exit_short = (z_score >= -z_exit) & (long_signal == -1)\n",
    "        \n",
    "        # Calculate returns (simplified)\n",
    "        ret1 = df[etf1].pct_change()\n",
    "        ret2 = df[etf2].pct_change()\n",
    "        \n",
    "        # Pair return (long ETF1, short ETF2)\n",
    "        pair_ret = ret1 - hedge_ratio * ret2\n",
    "        \n",
    "        # Strategy return\n",
    "        strat_ret = pair_ret * long_signal.shift(1)\n",
    "        total_returns.append(strat_ret)\n",
    "    \n",
    "    # Combine all pair returns\n",
    "    combined = pd.concat(total_returns, axis=1).mean(axis=1)\n",
    "    combined = combined.dropna()\n",
    "    \n",
    "    # Metrics\n",
    "    sharpe = np.sqrt(252) * combined.mean() / combined.std() if combined.std() > 0 else 0\n",
    "    total_return = (1 + combined).cumsum().iloc[-1]\n",
    "    max_dd = (combined.cumsum() / combined.cumsum().cummax() - 1).min()\n",
    "    \n",
    "    return {\n",
    "        'sharpe': sharpe,\n",
    "        'total_return': total_return,\n",
    "        'max_drawdown': max_dd\n",
    "    }\n",
    "\n",
    "# Test current parameters\n",
    "result = backtest_pairs(etf_data, pairs_current, z_entry=2.0, z_exit=0.0)\n",
    "if result:\n",
    "    print(\"Current Parameters (half_life_max=30, z_exit=0.0):\")\n",
    "    print(f\"  Sharpe: {result['sharpe']:.3f}\")\n",
    "    print(f\"  Total Return: {result['total_return']*100:.1f}%\")\n",
    "    print(f\"  Max Drawdown: {result['max_drawdown']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Interpretation : Performance du backtest\n\nLe backtest simule la strategie de pairs trading sur les ETF selectionnes.\n\n| Metrique | Valeur | Interpretation |\n|----------|--------|----------------|\n| Sharpe | A calculer | Ratio de Sharpe > 1 est considere bon |\n| Total Return | A calculer | Performance cumulee sur la periode |\n| Max Drawdown | A calculer | Perte maximale from peak |\n\n**Points cles** :\n- La strategie pairs trading est market-neutral : elle ne depend pas de la direction du marche\n- Le Sharpe doit etre interprete en fonction du nombre de pairs (diversification)\n- Le drawdown est limite par la construction market-neutral de la strategie\n- Les resultats dependent fortement de la qualite de la selection des pairs\n\n> **Note technique** : Le backtest simplifie ne tient pas compte des couts de transaction. En production, il faut considerer les commissions et l'impact de marche.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal parameters\n",
    "def grid_search_pairs(etf_data):\n",
    "    results = []\n",
    "    \n",
    "    for hl_max in [15, 20, 25, 30, 40, 50]:\n",
    "        # Select pairs with this half-life threshold\n",
    "        pairs = select_pairs(etf_data, half_life_max=hl_max)\n",
    "        \n",
    "        if pairs.empty:\n",
    "            continue\n",
    "        \n",
    "        for z_exit in [-0.5, 0.0, 0.5, 1.0]:\n",
    "            for lookback in [10, 20, 30, 60]:\n",
    "                result = backtest_pairs(etf_data, pairs, z_entry=2.0, z_exit=z_exit, lookback=lookback)\n",
    "                \n",
    "                if result:\n",
    "                    results.append({\n",
    "                        'half_life_max': hl_max,\n",
    "                        'z_exit': z_exit,\n",
    "                        'lookback': lookback,\n",
    "                        'num_pairs': len(pairs),\n",
    "                        'sharpe': result['sharpe'],\n",
    "                        'total_return': result['total_return'],\n",
    "                        'max_drawdown': result['max_drawdown']\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Running grid search...\")\n",
    "grid_results = grid_search_pairs(etf_data)\n",
    "grid_results = grid_results.sort_values('sharpe', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Parameter Combinations:\")\n",
    "print(grid_results.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Interpretation : Resultats du grid search\n\nLe grid search explore l'espace des parametres pour identifier la combinaison optimale maximisant le ratio de Sharpe.\n\n| Parametre | Plage testee | Impact sur la performance |\n|-----------|--------------|---------------------------|\n| `half_life_max` | 15-50 jours | Plus bas = pairs plus reactifs, moins de pairs |\n| `z_exit` | -0.5 a 1.0 | Seuil de sortie : 0 = moyenne, >0 = plus conservateur |\n| `lookback` | 10-60 jours | Fenetre de calcul du z-score |\n\n**Points cles** :\n- Le nombre de pairs disponibles diminue avec un seuil de demi-vie plus bas\n- Un z_exit positif (0.5) reduit le whipsaw mais peut reduire le nombre de trades\n- Un lookback court (10-20) est plus reactif mais plus sensible au bruit\n- Le Sharpe doit etre interprete en fonction du nombre de pairs (diversification)\n\n> **Note technique** : Les pairs ETF sont des actifs tres liquides avec des spreads etroits. L'impact des couts de transaction est donc limite, permettant des periodes de holding plus courtes.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Conclusion : Recommandations de recherche\n\n### Resume des resultats\n\nL'analyse par grid search a permis d'identifier les parametres optimaux pour la strategie de pairs trading ETF.\n\n| Parametre | Valeur optimale | Impact |\n|-----------|-----------------|--------|\n| HALF_LIFE_MAX | A determiner par grid search | Filtre les pairs a reversion lente |\n| Z_EXIT_THRESHOLD | A determiner | Seuil de sortie (0 = moyenne) |\n| LOOKBACK_PERIOD | A determiner | Fenetre de calcul du z-score |\n\n### Points cles a retenir\n\n1. **Demi-vie (Half-life)** : Les pairs avec une demi-vie courte (10-25 jours) revertent plus rapidement\n2. **Seuil de sortie Z** : Un seuil positif (0.5) peut reduire le whipsaw mais reduit le nombre de trades\n3. **Periode de lookback** : Une fenetre courte (10-20 jours) est plus reactive aux changements de regime\n4. **Neutralite du marche** : La strategie pairs trading est market-neutral par construction\n\n> **Note technique** : La selection des pairs doit etre reevaluee periodiquement (mensuellement ou trimestriellement) car les relations de cointegration peuvent evoluer avec le temps.\n\n### Prochaines etapes\n\n1. Appliquer les parametres trouves au code C# QuantConnect\n2. Implementer la reselection periodique des pairs\n3. Ajouter des filtres supplementaires (correlation minime, volume minimum)\n4. Backtester sur QuantConnect avec les donnees reelles\n5. Valider la robustesse avec walk-forward analysis"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}