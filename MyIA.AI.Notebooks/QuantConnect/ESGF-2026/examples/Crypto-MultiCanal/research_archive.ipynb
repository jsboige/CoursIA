{"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["# Analyse de Canaux Multi-Échelles avec ZigZag et Lignes de Régression Pondérées\n","\n","Ce notebook explore une approche d'analyse technique multi-échelles pour l'actif BTCUSDT (sur Binance), basée sur l'identification de pivots via l'indicateur ZigZag et la construction de canaux de tendance hiérarchiques (Macro, Méso, Micro).\n","\n","**Objectifs :**\n","\n","1.  **Extraire les points pivots significatifs** du prix horaire à l'aide d'une implémentation personnalisée de l'indicateur ZigZag.\n","2.  **Développer un algorithme** pour tracer des lignes de support et de résistance formant des canaux, en privilégiant les lignes qui \"contiennent\" strictement les pivots récents et en minimisant une erreur quadratique pondérée par le temps (`WSSE`).\n","3.  **Construire une hiérarchie de canaux** (Macro, Méso, Micro) où chaque niveau utilise les pivots définissant le niveau supérieur comme point de départ temporel.\n","4.  **Visualiser** les pivots, les canaux et leur évolution temporelle.\n","5.  **Explorer la sensibilité** de l'algorithme aux paramètres de pondération (`weight_power`, `wp`) et de fraction de pivots récents (`recent_pivot_fraction`, `rpf`).\n","6.  **(Optionnel / Futur)** Définir et backtester des stratégies de trading basées sur les interactions du prix avec ces canaux multi-échelles.\n","\n","**Étapes Initiales :**\n","\n","* Mise en place de l'environnement QuantConnect et téléchargement des données horaires BTCUSDT.\n","* Calcul d'une stratégie HODL simple comme référence de performance.\n","* Implémentation et visualisation de l'indicateur ZigZag."]},{"cell_type":"markdown","metadata":{},"source":["## 1. Initialisation : Environnement et Données\n","\n","Mise en place de l'environnement QuantConnect, définition de l'actif (BTCUSDT), de la période d'analyse et téléchargement des données horaires nécessaires."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# Import necessary libraries from the QC framework\n","from AlgorithmImports import *\n","from datetime import datetime\n","import pandas as pd\n","\n","# Initialize QuantBook\n","qb = QuantBook()\n","qb.SetBrokerageModel(BrokerageName.Binance, AccountType.Cash)\n","# For this example, we use BTCUSDT and set it as our benchmark.\n","btc_symbol = qb.AddCrypto('BTCUSDT', Resolution.Hour, Market.Binance).Symbol\n","qb.SetBenchmark(btc_symbol)\n","\n","# Define the backtesting period\n","start_date = datetime(2022, 1, 1)\n","end_date = datetime(2025, 4, 21)\n","\n","# Download hourly history for BTCUSDT\n","bars_df = qb.History(btc_symbol, start_date, end_date, Resolution.Hour)\n","bars_df = bars_df.reset_index()\n","\n","print('History loaded: ')\n","print(bars_df.head())\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Stratégie de Référence : HODL\n","\n","Calcul et visualisation de la performance d'une stratégie simple \"Buy and Hold\" (HODL) sur la période d'analyse. Ceci sert de benchmark pour évaluer toute stratégie de trading ultérieure."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# Assume we use the close prices from the hourly DataFrame as the HODL basis\n","initial_investment = 10000  # in USDT\n","first_price = bars_df['close'].iloc[0]\n","bars_df['HODL_Value'] = initial_investment * (bars_df['close'] / first_price)\n","\n","# Print final portfolio value\n","final_value = bars_df['HODL_Value'].iloc[-1]\n","print(f\"Final HODL portfolio value: {final_value:.2f} USDT\")\n","\n","# Plot HODL performance (optional: using matplotlib)\n","import matplotlib.pyplot as plt\n","\n","# Disabling visualization temporarily for easier json copy\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(bars_df['time'], bars_df['HODL_Value'], label='HODL Portfolio Value ')\n","plt.xlabel('Time')\n","plt.ylabel('Portfolio Value (USDT)')\n","plt.title('HODL Strategy Performance')\n","plt.legend()\n","# plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Détection des Pivots : Indicateur ZigZag\n","\n","Cette section se concentre sur l'identification des points de retournement significatifs du marché à l'aide de l'indicateur ZigZag.\n","\n","### 3.1. Fonction `classic_chart_zigzag`\n","\n","Pour identifier les retournements de tendance significatifs, nous utilisons l'indicateur ZigZag. L'indicateur natif de QuantConnect pouvant présenter des comportements inattendus dans certains contextes de recherche, nous employons ici une fonction personnalisée `classic_chart_zigzag`.\n","\n","**Fonctionnement :**\n","\n","*   Elle identifie les points hauts (pivots High, type -1) et bas (pivots Low, type +1) sur les prix de clôture (`close`).\n","*   Un pivot est confirmé uniquement si le prix retrace d'un certain pourcentage (`thresholdPercent`) depuis le dernier extrême enregistré.\n","*   Dans cet exemple, `thresholdPercent=0.05` signifie qu'une baisse de 5% depuis le dernier plus haut est nécessaire pour confirmer ce plus haut comme un pivot High, et une hausse de 5% depuis le dernier plus bas est requise pour confirmer ce plus bas comme un pivot Low.\n","*   La fonction retourne une liste de pivots `(timestamp, price, type)`, garantissant une alternance stricte entre High et Low.\n","\n","Cette liste de pivots (`pivotList`) servira de base à la construction de nos canaux."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def classic_chart_zigzag(df, thresholdPercent=0.05):\n","    \"\"\"\n","    Manually computes ZigZag pivots in the style of typical charting platforms.\n","    df must have columns 'time' and 'close'.\n","    thresholdPercent=0.05 => 5% retracement needed to lock in a pivot.\n","    Returns a list of pivots: (time, price, +1 or -1)\n","    +1 => Low pivot\n","    -1 => High pivot\n","    \"\"\"\n","    if len(df) < 2:\n","        return []\n","    # We'll store (time, price, sign)\n","    pivots = []\n","\n","    # 1) Start with the first bar as pivot\n","    firstBar = df.iloc[0]\n","    lastPivotPrice = firstBar['close']\n","    lastPivotTime  = firstBar['time']\n","\n","    # 2) Determine initial direction (up or down) by comparing the second bar\n","    secondBar = df.iloc[1]\n","    directionUp = secondBar['close'] > lastPivotPrice  # True => up, False => down\n","\n","    # If directionUp => we want to find new 'high extremes'\n","    # If directionUp=False => we want to find new 'low extremes'\n","\n","    # Track the extreme in the current direction\n","    currentExtremePrice = lastPivotPrice\n","    currentExtremeTime  = lastPivotTime\n","\n","    # We record the sign for the first pivot:\n","    #   if directionUp => first pivot is a Low (+1)\n","    #   else => first pivot is a High (-1)\n","    lastSign = +1 if directionUp else -1\n","\n","    # We'll add that initial pivot to the list\n","    pivots.append((lastPivotTime, lastPivotPrice, lastSign))\n","\n","    for i in range(1, len(df)):\n","        row = df.iloc[i]\n","        price = row['close']\n","        time  = row['time']\n","\n","        # Update extremes in the current direction\n","        if directionUp:\n","            # If price is higher than currentExtreme => update extreme\n","            if price > currentExtremePrice:\n","                currentExtremePrice = price\n","                currentExtremeTime  = time\n","            else:\n","                # Check if we retraced enough to confirm a new pivot\n","                retrace = 1.0 - (price / currentExtremePrice)\n","                if retrace >= thresholdPercent:\n","                    # That means we lock in the old extreme as a High pivot\n","                    # Switch direction to down\n","                    pivots.append((currentExtremeTime, currentExtremePrice, -1))\n","\n","                    # Now the new pivot is the current bar as 'low start'\n","                    directionUp = False\n","                    currentExtremePrice = price\n","                    currentExtremeTime  = time\n","        else:\n","            # directionDown => track new low extremes\n","            if price < currentExtremePrice:\n","                currentExtremePrice = price\n","                currentExtremeTime  = time\n","            else:\n","                # Check if we rallied enough to confirm a new pivot\n","                rally = (price / currentExtremePrice) - 1.0\n","                if rally >= thresholdPercent:\n","                    # Lock in the old extreme as a Low pivot\n","                    pivots.append((currentExtremeTime, currentExtremePrice, +1))\n","\n","                    directionUp = True\n","                    currentExtremePrice = price\n","                    currentExtremeTime  = time\n","\n","    # The last extreme can be appended as the final pivot if you want\n","    # e.g., treat the last bar as a pivot if you prefer\n","    finalPrice = currentExtremePrice\n","    finalTime  = currentExtremeTime\n","    finalSign  = +1 if not directionUp else -1  # Because if we ended going up, the last pivot is High\n","    pivots.append((finalTime, finalPrice, finalSign))\n","\n","    # Now we have a strictly alternating pivot list\n","    return pivots\n","\n","pivotList = classic_chart_zigzag(bars_df[['time','close']], thresholdPercent=0.04)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2. Visualisation du ZigZag\n","\n","Nous affichons ici les prix de clôture horaires superposés avec l'indicateur ZigZag (lignes de connexion et marqueurs de pivots High/Low) pour vérifier visuellement la pertinence des points détectés."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_manual_zigzag(bars_df, pivotList):\n","    import plotly.graph_objects as go\n","\n","    # A) lines for raw price\n","    fig = go.Figure()\n","    fig.add_trace(go.Scatter(\n","        x=bars_df['time'],\n","        y=bars_df['close'],\n","        mode='lines',\n","        name='Close Price',\n","        line=dict(color='blue')\n","    ))\n","\n","    # B) build x and y arrays to connect pivot → pivot\n","    xline = []\n","    yline = []\n","    for (dt, price, _) in pivotList:\n","        xline.append(dt)\n","        yline.append(price)\n","\n","    fig.add_trace(go.Scatter(\n","        x=xline, \n","        y=yline,\n","        mode='lines',\n","        name='Classic ZigZag',\n","        line=dict(color='orange')\n","    ))\n","\n","    # C) separate pivot sign for red or green markers\n","    high_x, high_y = [], []\n","    low_x,  low_y  = [], []\n","\n","    for (dt, price, sign) in pivotList:\n","        if sign < 0:\n","            high_x.append(dt)\n","            high_y.append(price)\n","        else:\n","            low_x.append(dt)\n","            low_y.append(price)\n","\n","    fig.add_trace(go.Scatter(\n","        x=high_x, \n","        y=high_y,\n","        mode='markers',\n","        marker=dict(color='green', size=7),\n","        name='High Pivot'\n","    ))\n","    fig.add_trace(go.Scatter(\n","        x=low_x, \n","        y=low_y,\n","        mode='markers',\n","        marker=dict(color='red', size=7),\n","        name='Low Pivot'\n","    ))\n","\n","    fig.update_layout(\n","        title='BTCUSDT Hourly - Classic ZigZag (from scratch)',\n","        xaxis_title='Time',\n","        yaxis_title='Price (USDT)'\n","    )\n","    fig.show()\n","\n","# THEN:\n","\n","# plot_manual_zigzag(bars_df, pivotList)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.3. Préparation des Données Pivots pour les Canaux\n","\n","Avant de construire les canaux, une étape cruciale est de préparer les données des pivots extraits par le ZigZag :\n","\n","1.  **Conversion en DataFrame :** Pour faciliter les manipulations.\n","2.  **Ajout de `time_numeric` :** Conversion du timestamp en secondes depuis l'epoch Unix. **Essentiel** pour les calculs géométriques (pente, ordonnée à l'origine) qui nécessitent une coordonnée 'x' numérique et linéaire.\n","3.  **Séparation High/Low :** Création de DataFrames distincts (`high_pivots`, `low_pivots`).\n","4.  **Stockage pour Vérification :** Création de copies NumPy (`all_high_pivots_for_check`, `all_low_pivots_for_check`) pour des vérifications rapides de contention lors de la recherche des meilleures lignes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert pivot list to DataFrame\n","pivots_df = pd.DataFrame(pivotList, columns=['time', 'price', 'type']) # type: +1 Low, -1 High\n","\n","# Convert time to numerical representation (seconds since epoch) for accurate line calculations\n","# Note: Using time.timestamp() is generally good. Ensure your pandas version handles it correctly.\n","# Alternatively, convert to numpy datetime64 and then to integer/float.\n","pivots_df['time_numeric'] = pivots_df['time'].apply(lambda x: x.timestamp())\n","\n","# Keep the original 'index' from the dataframe reset_index if needed for other purposes,\n","# but DO NOT use it for slope/channel calculations.\n","# pivots_df = pivots_df.reset_index() # Keep DataFrame index if needed\n","\n","# Separate High and Low pivots\n","high_pivots = pivots_df[pivots_df['type'] == -1].copy()\n","low_pivots = pivots_df[pivots_df['type'] == +1].copy()\n","\n","print(\"High Pivots with time_numeric:\")\n","print(high_pivots.head())\n","print(\"\\nLow Pivots with time_numeric:\")\n","print(low_pivots.head())\n","\n","# Store all pivots for global checks later\n","all_high_pivots_for_check = high_pivots[['time_numeric', 'price']].values\n","all_low_pivots_for_check = low_pivots[['time_numeric', 'price']].values"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Construction des Canaux : Algorithme et Paramètres\n","\n","Cette section détaille l'algorithme utilisé pour tracer les lignes de support et de résistance formant les canaux, ainsi que la configuration des paramètres qui influencent ce processus.\n","\n","\n","### 4.1. Algorithme Principal : `find_best_channel_line_strict_weighted`\n","\n","La fonction `find_best_channel_line_strict_weighted` est au cœur de notre construction de canaux. Elle vise à identifier la \"meilleure\" ligne de support ou de résistance possible, définie par une paire de pivots (`p1`, `p2`), en se basant sur des critères stricts et une optimisation pondérée.\n","\n","**Principes Clés :**\n","\n","1.  **Contention Stricte (Zéro Violation) :** Une ligne candidate (support ou résistance) définie par `p1` et `p2` n'est considérée comme **valide** que si **tous** les autres pivots pertinents (tous les Lows pour un support, tous les Highs pour une résistance) se trouvent du \"bon\" côté de la ligne sur toute la période considérée. Si aucune ligne ne satisfait ce critère, la fonction retourne `None`.\n","2.  **Minimisation de l'Erreur Pondérée (WSSE) sur Fraction Récente :** Parmi toutes les lignes _strictement valides_, l'algorithme sélectionne celle qui minimise la **Somme Pondérée des Erreurs Quadratiques (Weighted Sum of Squared Errors - WSSE)**.\n","    *   **Pondération Temporelle (`weight_power`, `wp`) :** L'erreur de chaque pivot est pondérée par son ancienneté relative (`wp > 0` donne plus d'importance aux pivots récents).\n","    *   **Fraction Récente (`recent_pivot_fraction`, `rpf`) :** La WSSE n'est calculée que sur une fraction (`rpf`) des pivots les plus récents, focalisant l'optimisation sur la pertinence récente.\n","3.  **Paramétrisation :** `wp` et `rpf` sont ajustables indépendamment pour chaque type de ligne et échelle.\n","\n","Cette approche garantit le respect de la structure globale des pivots tout en privilégiant la dynamique récente."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 13 : Définitions des Fonctions \n","\n","import numpy as np\n","import pandas as pd\n","import math \n","\n","# --- Helpers: get_line_params_time, check_point_position, calculate_weighted_sse ---\n","# (Copier ici les définitions complètes de ces 3 fonctions depuis la réponse précédente)\n","def get_line_params_time(p1_time_num, p1_price, p2_time_num, p2_price):\n","    time_diff = p2_time_num - p1_time_num\n","    if abs(time_diff) < 1e-9: return np.inf, p1_time_num\n","    m = (p2_price - p1_price) / time_diff\n","    c = p1_price - m * p1_time_num\n","    return m, c\n","\n","def check_point_position(point_time_num, point_price, m, c, check_above, epsilon=1e-9):\n","    if m == np.inf: return False \n","    line_y_at_point_x = m * point_time_num + c\n","    if check_above: return point_price >= line_y_at_point_x - epsilon\n","    else: return point_price <= line_y_at_point_x + epsilon\n","\n","def calculate_weighted_sse(p1, p2, pivots_for_sse_np, time_min_wsse, time_max_wsse, weight_power=1.0):\n","    p1_time_num, p1_price = p1['time_numeric'], p1['price']\n","    p2_time_num, p2_price = p2['time_numeric'], p2['price']\n","    m, c = get_line_params_time(p1_time_num, p1_price, p2_time_num, p2_price)\n","    if m == np.inf: return np.inf\n","    total_wsse = 0.0; total_weight = 0.0; time_range = time_max_wsse - time_min_wsse\n","    if time_range < 1e-9: time_range = 1.0\n","    if len(pivots_for_sse_np) == 0: return 0.0\n","    for k in range(len(pivots_for_sse_np)):\n","        pk_time_num, pk_price = pivots_for_sse_np[k, 0], pivots_for_sse_np[k, 1]\n","        if abs(pk_time_num - p1_time_num) < 1e-9 or abs(pk_time_num - p2_time_num) < 1e-9: continue\n","        normalized_time = (pk_time_num - time_min_wsse) / time_range if time_range > 1e-9 else 0.5 \n","        weight = max(0, normalized_time) ** weight_power + 1e-9\n","        line_y_at_pk = m * pk_time_num + c\n","        error = pk_price - line_y_at_pk\n","        total_wsse += weight * (error**2)\n","        total_weight += weight\n","    return total_wsse / total_weight if total_weight > 1e-9 else 0.0\n","\n","# --- Fonction Principale ---\n","def find_best_channel_line_strict_weighted(pivots_df, all_pivots_for_check_np, is_resistance,\n","                                           weight_power=1.0, recent_pivot_fraction=1.0):\n","    strictly_valid_lines_info = []\n","    n_pivots = len(pivots_df)\n","    if n_pivots < 2 or len(all_pivots_for_check_np) < 1: return None, None\n","\n","    check_pivots_df = pd.DataFrame(all_pivots_for_check_np, columns=['time_numeric', 'price'])\n","    check_pivots_df = check_pivots_df.sort_values('time_numeric', ascending=True)\n","    n_total_check = len(check_pivots_df)\n","    safe_rpf = max(0.0, min(1.0, recent_pivot_fraction))\n","    n_keep_for_wsse = max(1, math.ceil(n_total_check * safe_rpf))\n","    recent_pivots_for_wsse_df = check_pivots_df.tail(n_keep_for_wsse).copy()\n","    \n","    if recent_pivots_for_wsse_df.empty or len(recent_pivots_for_wsse_df) < 1: return None, None \n","    time_min_wsse = recent_pivots_for_wsse_df['time_numeric'].min()\n","    time_max_wsse = recent_pivots_for_wsse_df['time_numeric'].max()\n","\n","    for i in range(n_pivots):\n","        p1 = pivots_df.iloc[i]\n","        for j in range(i + 1, n_pivots):\n","            p2 = pivots_df.iloc[j]\n","            if p1['time_numeric'] >= p2['time_numeric']: continue\n","            p1_time_num, p1_price = p1['time_numeric'], p1['price']\n","            p2_time_num, p2_price = p2['time_numeric'], p2['price']\n","            m, c = get_line_params_time(p1_time_num, p1_price, p2_time_num, p2_price)\n","            if m == np.inf: continue\n","            line_is_strictly_valid = True\n","            for k in range(n_total_check): \n","                pk_time_num, pk_price = all_pivots_for_check_np[k, 0], all_pivots_for_check_np[k, 1]\n","                if abs(pk_time_num - p1_time_num) < 1e-9 or abs(pk_time_num - p2_time_num) < 1e-9: continue\n","                if not check_point_position(pk_time_num, pk_price, m, c, check_above=(not is_resistance)):\n","                    line_is_strictly_valid = False; break\n","            if line_is_strictly_valid:\n","                pivots_to_calc_wsse_on_df = recent_pivots_for_wsse_df[\n","                    (np.abs(recent_pivots_for_wsse_df['time_numeric'] - p1_time_num) > 1e-9) &\n","                    (np.abs(recent_pivots_for_wsse_df['time_numeric'] - p2_time_num) > 1e-9)\n","                ]\n","                if not pivots_to_calc_wsse_on_df.empty:\n","                    time_min_wsse_actual = pivots_to_calc_wsse_on_df['time_numeric'].min()\n","                    time_max_wsse_actual = pivots_to_calc_wsse_on_df['time_numeric'].max()\n","                    current_wsse = calculate_weighted_sse(p1, p2, pivots_to_calc_wsse_on_df[['time_numeric', 'price']].values,\n","                                                          time_min_wsse_actual, time_max_wsse_actual, weight_power)\n","                else: current_wsse = 0.0\n","                if current_wsse != np.inf:\n","                     strictly_valid_lines_info.append({ \"p1\": p1, \"p2\": p2, \"wsse_recent\": current_wsse })\n","\n","    if not strictly_valid_lines_info: return None, None\n","    strictly_valid_lines_info.sort(key=lambda x: x['wsse_recent'])\n","    best_line_info = strictly_valid_lines_info[0]\n","    return best_line_info['p1'], best_line_info['p2']"]},{"cell_type":"markdown","metadata":{},"source":["### 4.2. Configuration des Paramètres de Canal\n","\n","Ici, nous définissons les jeux de paramètres (`wp` et `rpf`) qui seront utilisés pour construire les canaux à différentes échelles.\n","\n","1.  **`final_config` :** Configuration unique sélectionnée (potentiellement après optimisation) pour le tracé final, les snapshots et le backtesting éventuel. Contient `wp`/`rpf` pour Support/Résistance des niveaux Macro, Méso, Micro.\n","2.  **`configurations_to_explore` :** Liste de configurations générées pour tester la sensibilité de l'algorithme (ex: variation de `wp_micro_sup` et `rpf_micro_sup`). Les résultats alimenteront une visualisation comparative."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 14 : Définition des Configurations\n","\n","import itertools\n","\n","\n","# --- Configurations à Explorer pour la Visualisation ---\n","print(\"\\nGénération des configurations pour l'exploration...\")\n","wp_ref = 2.0\n","rpf_ref = 1.0\n","rpf_micro_sup_options = [1, 0.8, 0.66, 0.5, 0.3] \n","wp_micro_sup_options = [0.3, 0.5, 1.0, 2.0, 4.0, 8.0] \n","\n","configurations_to_explore = []\n","config_id_counter = 0\n","for rpf_micsup in rpf_micro_sup_options:\n","    for wp_micsup in wp_micro_sup_options:\n","        config_id_counter += 1\n","        config = {\n","            \"label\": f\"Cfg{config_id_counter}_wpM={wp_micsup:.1f}_rpfM={rpf_micsup:.2f}\",\n","            \"wp_macro_res\": wp_ref, \"rpf_macro_res\": rpf_ref,\n","            \"wp_macro_sup\": wp_ref, \"rpf_macro_sup\": rpf_ref,\n","            \"wp_meso_res\" : wp_ref, \"rpf_meso_res\" : rpf_ref,\n","            \"wp_meso_sup\" : wp_ref, \"rpf_meso_sup\" : rpf_ref,\n","            \"wp_micro_res\": wp_ref, \"rpf_micro_res\": rpf_ref,\n","            \"wp_micro_sup\": wp_micsup, \"rpf_micro_sup\": rpf_micsup,\n","        }\n","        configurations_to_explore.append(config)\n","\n","print(f\"Nombre de configurations à explorer: {len(configurations_to_explore)}\")\n","results_list_explore = [] # Liste séparée pour les résultats de l'exploration"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Calcul et Analyse des Canaux\n","\n","Exécution des calculs pour déterminer les lignes de canal selon les configurations définies, suivie de l'analyse et de la visualisation des résultats.\n","\n","### 5.1. Exploration des Paramètres (Calcul)\n","\n","Cette cellule exécute le calcul des canaux pour **toutes** les configurations définies dans `configurations_to_explore`. Les pivots résultants pour chaque ligne de chaque configuration sont stockés dans `results_df_explore`. Ceci permet une analyse comparative ultérieure."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 15 : Calcul en Boucle pour l'Exploration (CORRIGÉE - Ajout time_numeric dans get_pivot_info)\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","from tqdm.notebook import tqdm # S'assurer que tqdm est importé\n","\n","print(\"Starting channel calculations for parameter exploration...\")\n","if 'high_pivots' not in locals() or 'low_pivots' not in locals(): raise NameError(\"Pivots non définis.\")\n","if 'find_best_channel_line_strict_weighted' not in locals(): raise NameError(\"Fonction de calcul non définie.\")\n","if 'get_line_params_time' not in locals(): # S'assurer que la dépendance est là\n","    def get_line_params_time(p1_time_num, p1_price, p2_time_num, p2_price):\n","        time_diff = p2_time_num - p1_time_num\n","        if abs(time_diff) < 1e-9: return np.inf, p1_time_num\n","        m = (p2_price - p1_price) / time_diff\n","        c = p1_price - m * p1_time_num\n","        return m, c\n","if 'np' not in locals(): import numpy as np # Assurer import numpy\n","if 'math' not in locals(): import math # Assurer import math\n","\n","\n","results_list_explore = [] # S'assurer qu'elle est vide avant de commencer\n","\n","# --- Définition de get_pivot_info DANS la cellule ---\n","# Correction: Ajouter time_numeric\n","def get_pivot_info(pivot):\n","    \"\"\"Convertit une Series pivot en dictionnaire pour stockage, incluant time_numeric.\"\"\"\n","    if pivot is None or not isinstance(pivot, pd.Series):\n","        return {'time': pd.NaT, 'price': np.nan, 'idx': -1, 'time_numeric': np.nan} # Valeurs par défaut\n","    # Récupérer 'idx' depuis le nom de la Series si disponible\n","    idx_val = pivot.name if hasattr(pivot, 'name') else -1\n","    # Assurer que time_numeric existe dans la Series source, le recalculer si besoin\n","    time_numeric_val = pivot.get('time_numeric', np.nan)\n","    if pd.isna(time_numeric_val) and not pd.isna(pivot.get('time')):\n","         try:\n","            # Convertir le timestamp pandas en objet datetime natif si nécessaire\n","            dt_obj = pivot['time']\n","            if isinstance(dt_obj, pd.Timestamp):\n","                 dt_obj = dt_obj.to_pydatetime()\n","            time_numeric_val = dt_obj.timestamp()\n","         except Exception as e:\n","             #print(f\"WARN: Could not get timestamp for {pivot.get('time')}: {e}\")\n","             time_numeric_val = np.nan # Fallback\n","\n","    return {\n","        'time': pivot.get('time', pd.NaT),\n","        'price': pivot.get('price', np.nan),\n","        'idx': idx_val,\n","        'time_numeric': time_numeric_val # Utiliser la valeur récupérée/calculée\n","    }\n","# --- Fin définition get_pivot_info ---\n","\n","\n","for idx, config in enumerate(tqdm(configurations_to_explore, desc=\"Exploring Configs\")): # Ajout tqdm ici\n","    # Stockage temporaire des résultats (tuples de Series ou (None, None))\n","    temp_channel_definitions = { \"macro\": {}, \"meso\": {}, \"micro\": {} }\n","\n","    # --- Extraire params ---\n","    wp_macro_res=config['wp_macro_res']; rpf_macro_res=config['rpf_macro_res']\n","    wp_macro_sup=config['wp_macro_sup']; rpf_macro_sup=config['rpf_macro_sup']\n","    wp_meso_res =config['wp_meso_res'];  rpf_meso_res =config['rpf_meso_res']\n","    wp_meso_sup =config['wp_meso_sup'];  rpf_meso_sup =config['rpf_meso_sup']\n","    wp_micro_res=config['wp_micro_res']; rpf_micro_res=config['rpf_micro_res']\n","    wp_micro_sup=config['wp_micro_sup']; rpf_micro_sup=config['rpf_micro_sup']\n","\n","    # --- Calcul Macro ---\n","    macro_success = False\n","    try:\n","        macro_res_series = find_best_channel_line_strict_weighted(high_pivots, all_high_pivots_for_check, True, wp_macro_res, rpf_macro_res)\n","        macro_sup_series = find_best_channel_line_strict_weighted(low_pivots, all_low_pivots_for_check, False, wp_macro_sup, rpf_macro_sup)\n","        temp_channel_definitions[\"macro\"][\"resistance\"] = macro_res_series if macro_res_series else (None, None)\n","        temp_channel_definitions[\"macro\"][\"support\"] = macro_sup_series if macro_sup_series else (None, None)\n","        if temp_channel_definitions[\"macro\"][\"resistance\"][0] is not None and temp_channel_definitions[\"macro\"][\"support\"][0] is not None:\n","            macro_success = True\n","    except Exception as e: print(f\"ERROR Macro in {config['label']}: {e}\")\n","\n","    # --- Calcul Meso ---\n","    meso_success = False\n","    meso_start_time = None\n","    temp_channel_definitions[\"meso\"][\"resistance\"] = (None, None)\n","    temp_channel_definitions[\"meso\"][\"support\"] = (None, None)\n","    if macro_success:\n","        macro_pivots_list = [p for pair in temp_channel_definitions[\"macro\"].values() for p in pair if p is not None]\n","        if len(macro_pivots_list) >= 2:\n","            try:\n","                meso_start_time = sorted([p['time'] for p in macro_pivots_list], reverse=True)[1]\n","                meso_high_f=high_pivots[high_pivots['time'] >= meso_start_time].copy(); meso_low_f=low_pivots[low_pivots['time'] >= meso_start_time].copy()\n","                if len(meso_high_f) >= 2 and len(meso_low_f) >= 2:\n","                    meso_high_np_check=meso_high_f[['time_numeric', 'price']].values; meso_low_np_check = meso_low_f[['time_numeric', 'price']].values\n","                    meso_res_series = find_best_channel_line_strict_weighted(meso_high_f, meso_high_np_check, True, wp_meso_res, rpf_meso_res)\n","                    meso_sup_series = find_best_channel_line_strict_weighted(meso_low_f, meso_low_np_check, False, wp_meso_sup, rpf_meso_sup)\n","                    temp_channel_definitions[\"meso\"][\"resistance\"] = meso_res_series if meso_res_series else (None, None)\n","                    temp_channel_definitions[\"meso\"][\"support\"] = meso_sup_series if meso_sup_series else (None, None)\n","                    if temp_channel_definitions[\"meso\"][\"resistance\"][0] is not None and temp_channel_definitions[\"meso\"][\"support\"][0] is not None:\n","                        meso_success = True\n","            except IndexError: pass\n","            except Exception as e: print(f\"ERROR Meso in {config['label']}: {e}\")\n","\n","    # --- Calcul Micro ---\n","    micro_start_time = None\n","    temp_channel_definitions[\"micro\"][\"resistance\"] = (None, None)\n","    temp_channel_definitions[\"micro\"][\"support\"] = (None, None)\n","    if meso_success:\n","        meso_pivots_list = [p for pair in temp_channel_definitions[\"meso\"].values() for p in pair if p is not None]\n","        if len(meso_pivots_list) >= 2:\n","            try:\n","                micro_start_time = sorted([p['time'] for p in meso_pivots_list], reverse=True)[1]\n","                micro_high_f=high_pivots[high_pivots['time'] >= micro_start_time].copy(); micro_low_f=low_pivots[low_pivots['time'] >= micro_start_time].copy()\n","                if len(micro_high_f) >= 2 and len(micro_low_f) >= 2:\n","                    micro_high_np_check=micro_high_f[['time_numeric', 'price']].values; micro_low_np_check=micro_low_f[['time_numeric', 'price']].values\n","                    micro_res_series = find_best_channel_line_strict_weighted(micro_high_f, micro_high_np_check, True, wp_micro_res, rpf_micro_res)\n","                    micro_sup_series = find_best_channel_line_strict_weighted(micro_low_f, micro_low_np_check, False, wp_micro_sup, rpf_micro_sup)\n","                    temp_channel_definitions[\"micro\"][\"resistance\"] = micro_res_series if micro_res_series else (None, None)\n","                    temp_channel_definitions[\"micro\"][\"support\"] = micro_sup_series if micro_sup_series else (None, None)\n","            except IndexError: pass\n","            except Exception as e: print(f\"ERROR Micro in {config['label']}: {e}\")\n","\n","    # --- Stocker les résultats (UTILISER get_pivot_info ICI) ---\n","    result_data = {\n","        \"config_index\": idx, \"config_label\": config['label'], \"params\": config,\n","        \"macro_res_p1\": get_pivot_info(temp_channel_definitions['macro'].get('resistance', (None, None))[0]),\n","        \"macro_res_p2\": get_pivot_info(temp_channel_definitions['macro'].get('resistance', (None, None))[1]),\n","        \"macro_sup_p1\": get_pivot_info(temp_channel_definitions['macro'].get('support', (None, None))[0]),\n","        \"macro_sup_p2\": get_pivot_info(temp_channel_definitions['macro'].get('support', (None, None))[1]),\n","        \"meso_res_p1\": get_pivot_info(temp_channel_definitions['meso'].get('resistance', (None, None))[0]),\n","        \"meso_res_p2\": get_pivot_info(temp_channel_definitions['meso'].get('resistance', (None, None))[1]),\n","        \"meso_sup_p1\": get_pivot_info(temp_channel_definitions['meso'].get('support', (None, None))[0]),\n","        \"meso_sup_p2\": get_pivot_info(temp_channel_definitions['meso'].get('support', (None, None))[1]),\n","        \"micro_res_p1\": get_pivot_info(temp_channel_definitions['micro'].get('resistance', (None, None))[0]),\n","        \"micro_res_p2\": get_pivot_info(temp_channel_definitions['micro'].get('resistance', (None, None))[1]),\n","        \"micro_sup_p1\": get_pivot_info(temp_channel_definitions['micro'].get('support', (None, None))[0]),\n","        \"micro_sup_p2\": get_pivot_info(temp_channel_definitions['micro'].get('support', (None, None))[1]),\n","        \"meso_start_t\": meso_start_time if meso_start_time is not None else pd.NaT,\n","        \"micro_start_t\": micro_start_time if micro_start_time is not None else pd.NaT,\n","    }\n","    results_list_explore.append(result_data)\n","    # print(f\"--> Result Micro Support: p1={result_data['micro_sup_p1'].get('time')} - p2={result_data['micro_sup_p2'].get('time')}\") # Moins verbeux\n","\n","print(\"\\n--- Channel exploration calculations finished ---\")\n","results_df_explore = pd.DataFrame(results_list_explore)\n","print(\"\\n--- Exploration Results Summary (Micro Support Pivots) ---\")\n","if not results_df_explore.empty:\n","    if 'micro_sup_p1' in results_df_explore.columns and 'micro_sup_p2' in results_df_explore.columns:\n","        pd.set_option('display.max_rows', None); pd.set_option('display.max_columns', None); pd.set_option('display.width', 2000)\n","        results_df_explore['mic_s1_t'] = results_df_explore['micro_sup_p1'].apply(lambda x: x.get('time') if isinstance(x, dict) else pd.NaT)\n","        results_df_explore['mic_s2_t'] = results_df_explore['micro_sup_p2'].apply(lambda x: x.get('time') if isinstance(x, dict) else pd.NaT)\n","        print(results_df_explore[['config_index', 'config_label', 'mic_s1_t', 'mic_s2_t']].to_string())\n","        pd.reset_option('display.max_rows'); pd.reset_option('display.max_columns'); pd.reset_option('display.width')\n","    else:\n","        print(\"WARN: Colonnes 'micro_sup_p1' ou 'micro_sup_p2' manquantes dans results_df_explore.\")\n","        print(results_df_explore.head())\n","else: print(\"results_df_explore is empty.\")"]},{"cell_type":"markdown","metadata":{},"source":["### 5.2. Identification de la Configuration Cible (`final_config`)\n","\n","Examen des résultats de l'exploration (`results_df_explore`), potentiellement basé sur des critères visuels ou quantitatifs (non implémentés ici), pour sélectionner la configuration (`final_config`) qui semble la plus pertinente pour une analyse plus approfondie (visualisation finale, snapshots, backtesting)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 16 : Identification Configuration Cible\n","\n","target_p1_date = pd.Timestamp(\"2025-04-07 07:00:00\")\n","target_p2_date = pd.Timestamp(\"2025-04-09 04:00:00\")\n","tolerance = pd.Timedelta(hours=6) \n","best_config_index = -1 # Default\n","\n","if 'results_df_explore' in locals() and not results_df_explore.empty:\n","    # Convertir les colonnes de temps si elles ne sont pas déjà datetime (elles devraient l'être)\n","    results_df_explore['mic_s1_t_dt'] = pd.to_datetime(results_df_explore['micro_sup_p1'].apply(lambda x: x['time']))\n","    results_df_explore['mic_s2_t_dt'] = pd.to_datetime(results_df_explore['micro_sup_p2'].apply(lambda x: x['time']))\n","    \n","    target_configs_df = results_df_explore[\n","        (results_df_explore['mic_s1_t_dt'] >= target_p1_date - tolerance) & (results_df_explore['mic_s1_t_dt'] <= target_p1_date + tolerance) &\n","        (results_df_explore['mic_s2_t_dt'] >= target_p2_date - tolerance) & (results_df_explore['mic_s2_t_dt'] <= target_p2_date + tolerance)\n","    ]\n","    \n","    if not target_configs_df.empty:\n","        print(f\"\\n--- Configurations Cible Trouvées ---\")\n","        print(target_configs_df[['config_index', 'config_label', 'mic_s1_t', 'mic_s2_t']].to_string())\n","        best_config_index = target_configs_df.iloc[0]['config_index']\n","        print(f\"\\n==> Sélection auto de la 1ère config cible: Index {best_config_index} ({target_configs_df.iloc[0]['config_label']})\\n\")\n","        # Stocker la meilleure configuration trouvée\n","        final_config = configurations_to_explore[best_config_index]\n","    else:\n","        print(f\"\\n--- ATTENTION : Aucune config trouvée pour Support Micro cible ({target_p1_date} - {target_p2_date}) ---\")\n","        # Fallback: Utiliser la config par défaut ou la dernière ? Utilisons la config par défaut définie plus haut.\n","        best_config_index = -99 # Marqueur spécial\n","        final_config = { \"label\": \"Default_Config\", # Fallback\n","            \"wp_macro_res\": 2.0, \"rpf_macro_res\": 1.0, \"wp_macro_sup\": 2.0, \"rpf_macro_sup\": 1.0,\n","            \"wp_meso_res\" : 2.0, \"rpf_meso_res\" : 1.0, \"wp_meso_sup\" : 2.0, \"rpf_meso_sup\" : 1.0,\n","            \"wp_micro_res\": 2.0, \"rpf_micro_res\": 1.0, \"wp_micro_sup\": 2.0, \"rpf_micro_sup\": 1.0, }\n","        print(f\"WARN: Utilisation de la configuration par défaut: {final_config['label']}\")\n","        \n","else:\n","    print(\"results_df_explore non trouvé ou vide. Utilisation d'une config par défaut.\")\n","    best_config_index = -99\n","    final_config = { \"label\": \"Default_Config\", # Fallback\n","            \"wp_macro_res\": 2.0, \"rpf_macro_res\": 1.0, \"wp_macro_sup\": 2.0, \"rpf_macro_sup\": 1.0,\n","            # ... (autres params par défaut) ...\n","             }\n","\n","# --- Calcul Final avec la Meilleure Configuration ---\n","# (Optionnel ici, on peut le faire juste avant le plot 2D final si on veut séparer)\n","print(\"Recalculating channels with the selected final configuration...\")\n","final_channel_definitions = {\"macro\": {}, \"meso\": {}, \"micro\": {}}\n","# ... (Copier/Coller la logique de calcul complète pour UNE config, utilisant final_config) ...\n","# (Identique à la structure interne de la boucle dans la Cellule 15, mais sans boucle)\n","# --- Macro ---\n","try:\n","    macro_res = find_best_channel_line_strict_weighted(high_pivots, all_high_pivots_for_check, True, final_config['wp_macro_res'], final_config['rpf_macro_res'])\n","    macro_sup = find_best_channel_line_strict_weighted(low_pivots, all_low_pivots_for_check, False, final_config['wp_macro_sup'], final_config['rpf_macro_sup'])\n","    final_channel_definitions[\"macro\"][\"resistance\"] = macro_res if macro_res else (None, None)\n","    final_channel_definitions[\"macro\"][\"support\"] = macro_sup if macro_sup else (None, None)\n","except Exception as e: print(f\"ERROR Final Macro: {e}\")\n","# --- Meso ---\n","meso_start_time = None; macro_pivots_list = [p for pair in final_channel_definitions[\"macro\"].values() if pair and pair[0] is not None and pair[1] is not None for p in pair]\n","if len(macro_pivots_list) >= 2:\n","    try:\n","        meso_start_time = sorted([p['time'] for p in macro_pivots_list], reverse=True)[1]\n","        meso_high_f=high_pivots[high_pivots['time'] >= meso_start_time].copy(); meso_low_f=low_pivots[low_pivots['time'] >= meso_start_time].copy()\n","        meso_high_np=meso_high_f[['time_numeric', 'price']].values; meso_low_np = meso_low_f[['time_numeric', 'price']].values\n","        if len(meso_high_f) >= 2 and len(meso_low_f) >= 2:\n","             meso_res = find_best_channel_line_strict_weighted(meso_high_f, meso_high_np, True, final_config['wp_meso_res'], final_config['rpf_meso_res'])\n","             meso_sup = find_best_channel_line_strict_weighted(meso_low_f, meso_low_np, False, final_config['wp_meso_sup'], final_config['rpf_meso_sup'])\n","             final_channel_definitions[\"meso\"][\"resistance\"] = meso_res if meso_res else (None, None)\n","             final_channel_definitions[\"meso\"][\"support\"] = meso_sup if meso_sup else (None, None)\n","    except Exception as e: print(f\"ERROR Final Meso: {e}\")\n","# --- Micro ---\n","micro_start_time = None; meso_pivots_list = [p for pair in final_channel_definitions[\"meso\"].values() if pair and pair[0] is not None and pair[1] is not None for p in pair]\n","if len(meso_pivots_list) >= 2:\n","    try:\n","        micro_start_time = sorted([p['time'] for p in meso_pivots_list], reverse=True)[1]\n","        micro_high_f=high_pivots[high_pivots['time'] >= micro_start_time].copy(); micro_low_f=low_pivots[low_pivots['time'] >= micro_start_time].copy()\n","        micro_high_np=micro_high_f[['time_numeric', 'price']].values; micro_low_np=micro_low_f[['time_numeric', 'price']].values\n","        if len(micro_high_f) >= 2 and len(micro_low_f) >= 2:\n","             micro_res = find_best_channel_line_strict_weighted(micro_high_f, micro_high_np, True, final_config['wp_micro_res'], final_config['rpf_micro_res'])\n","             micro_sup = find_best_channel_line_strict_weighted(micro_low_f, micro_low_np, False, final_config['wp_micro_sup'], final_config['rpf_micro_sup'])\n","             final_channel_definitions[\"micro\"][\"resistance\"] = micro_res if micro_res else (None, None)\n","             final_channel_definitions[\"micro\"][\"support\"] = micro_sup if micro_sup else (None, None)\n","    except Exception as e: print(f\"ERROR Final Micro: {e}\")\n","\n","print(\"\\nFinal channels calculated using selected configuration.\")"]},{"cell_type":"markdown","metadata":{},"source":["### 5.3. Visualisation Finale (Configuration Cible)\n","\n","Cette section utilise Plotly pour générer une visualisation complète intégrant :\n","\n","*   Le **prix** de clôture horaire.\n","*   Les **pivots** ZigZag (High/Low).\n","*   Les **lignes de connexion** du ZigZag.\n","*   Les **canaux Macro, Méso et Micro** (support et résistance) calculés en utilisant la configuration sélectionnée (`final_config`).\n","\n","**Caractéristiques du Tracé :**\n","\n","*   Niveaux de canal distincts par couleur/style.\n","*   Lignes étendues jusqu'à la fin des données.\n","*   Pivots définissant chaque ligne mis en évidence (marqueurs étoiles)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.graph_objects as go\n","\n","def plot_channels_and_zigzag(bars_df, pivotList, channel_definitions):\n","    \n","    fig = go.Figure()\n","\n","    # A) Plot raw price\n","    fig.add_trace(go.Scatter(\n","        x=bars_df['time'],\n","        y=bars_df['close'],\n","        mode='lines',\n","        name='Close Price',\n","        line=dict(color='rgba(100, 100, 200, 0.8)') # Light blue\n","    ))\n","\n","    # B) Plot ZigZag lines connecting pivots\n","    xline = [p[0] for p in pivotList]\n","    yline = [p[1] for p in pivotList]\n","    fig.add_trace(go.Scatter(\n","        x=xline, \n","        y=yline,\n","        mode='lines',\n","        name='ZigZag Line',\n","        line=dict(color='orange', dash='dot')\n","    ))\n","\n","    # C) Plot High/Low pivot markers\n","    high_x = [p[0] for p in pivotList if p[2] < 0]\n","    high_y = [p[1] for p in pivotList if p[2] < 0]\n","    low_x  = [p[0] for p in pivotList if p[2] > 0]\n","    low_y  = [p[1] for p in pivotList if p[2] > 0]\n","\n","    fig.add_trace(go.Scatter(\n","        x=high_x, y=high_y, mode='markers',\n","        marker=dict(color='red', size=7, symbol='diamond'), name='High Pivot'\n","    ))\n","    fig.add_trace(go.Scatter(\n","        x=low_x, y=low_y, mode='markers',\n","        marker=dict(color='green', size=7, symbol='circle'), name='Low Pivot'\n","    ))\n","\n","    # D) Plot Channel Lines (Revised for Extension)\n","    channel_colors = {\n","        \"macro\": \"rgba(60, 60, 60, 0.8)\", # Dark Grey\n","        \"meso\": \"rgba(0, 0, 255, 0.6)\",   # Blue\n","        \"micro\": \"rgba(255, 0, 255, 0.7)\" # Magenta\n","    }\n","    channel_styles = {\n","        \"macro\": \"solid\",\n","        \"meso\": \"dash\",\n","        \"micro\": \"dot\"\n","    }\n","    # Get the overall time range for extending lines\n","    plot_start_time = bars_df['time'].iloc[0]\n","    plot_end_time = bars_df['time'].iloc[-1]\n","    plot_start_time_num = plot_start_time.timestamp()\n","    plot_end_time_num = plot_end_time.timestamp()\n","    for name, definition in channel_definitions.items():\n","        color = channel_colors[name]\n","        style = channel_styles[name]\n","        for line_type in [\"resistance\", \"support\"]:\n","            p1, p2 = definition[line_type]\n","            if p1 is not None and p2 is not None:\n","                # Calculate line parameters using time_numeric\n","                m, c = get_line_params_time(p1['time_numeric'], p1['price'], p2['time_numeric'], p2['price'])\n","                # Calculate line extension points for plotting\n","                # Start from the time of the first defining pivot\n","                line_plot_start_time = p1['time']\n","                line_plot_start_time_num = p1['time_numeric']\n","                line_plot_start_y = p1['price'] # More accurately: m * line_plot_start_time_num + c\n","                # End at the time of the last data point in the plot\n","                line_plot_end_time = plot_end_time\n","                line_plot_end_time_num = plot_end_time_num\n","                line_plot_end_y = m * line_plot_end_time_num + c\n","                # Add the extended line trace\n","                fig.add_trace(go.Scatter(\n","                    x=[line_plot_start_time, line_plot_end_time],\n","                    y=[line_plot_start_y, line_plot_end_y],\n","                    mode='lines',\n","                    name=f'{name.capitalize()} {line_type.capitalize()}',\n","                    line=dict(color=color, width=2, dash=style)\n","                ))\n","                # Highlight the defining pivots\n","                fig.add_trace(go.Scatter(\n","                    x=[p1['time'], p2['time']],\n","                    y=[p1['price'], p2['price']],\n","                    mode='markers',\n","                    marker=dict(color=color, size=9,\n","                                symbol='star' if line_type == 'resistance' else 'star-open'),\n","                    showlegend=False\n","                ))\n","    fig.update_layout(\n","        title=\"BTCUSDT Hourly - ZigZag Pivots with Macro/Meso/Micro Channels (Hierarchical Envelope)\",\n","        xaxis_title=\"Time\",\n","        yaxis_title=\"Price (USDT)\",\n","        xaxis_rangeslider_visible=False\n","    )\n","    fig.show()\n","\n","\n","# --- Exécuter le Plotting avec la configuration FINALE ---\n","\n","# S'assurer que final_channel_definitions existe et contient les bons canaux\n","if 'final_channel_definitions' in locals():\n","    plot_channels_and_zigzag(bars_df, pivotList, final_channel_definitions)\n","    print(\"Plotting avec la configuration finale terminée.\")\n","else:\n","    print(\"ERREUR: `final_channel_definitions` non trouvées. Exécuter la cellule 16 pour recalculer les canaux finaux.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### 5.4. Visualisation Comparative (Exploration Paramètres)\n","\n","Ce graphique utilise une grille de sous-graphiques (subplots) pour visualiser comment les canaux **Macro, Méso et Micro** varient en fonction des **différentes configurations testées** dans `configurations_to_explore`.\n","\n","**Organisation de la Grille :**\n","\n","*   Chaque sous-graphique correspond à une configuration testée.\n","*   Le titre indique les paramètres variables (ex: `wp_micro_sup`, `rpf_micro_sup`).\n","*   Chaque sous-graphique **zoome automatiquement** sur une fenêtre temporelle (X) et une plage de prix (Y) déterminées par les **pivots définissant le canal Méso** de cette configuration spécifique, pour mieux voir l'impact local des paramètres.\n","*   Tous les canaux (Macro, Méso, Micro) et pivots ZigZag pertinents sont affichés dans chaque sous-graphique zoomé.\n","\n","Aide à comprendre la **stabilité** et la **sensibilité** de l'algorithme aux variations des paramètres `wp` et `rpf`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 28 : Visualisation 2D (Grille 4x4) Exploration - Tous Canaux, Zoom X/Y sur Pivots Meso par Config\n","\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","import pandas as pd\n","import numpy as np\n","import math\n","\n","# --- Pré-requis ---\n","if 'results_df_explore' not in locals() or results_df_explore.empty:\n","    print(\"ERREUR: results_df_explore non disponible pour la visualisation.\")\n","elif 'get_line_params_time' not in locals():\n","    print(\"ERREUR: La fonction get_line_params_time n'est pas définie.\")\n","elif 'bars_df' not in locals():\n","     print(\"ERREUR: `bars_df` non disponible pour tracer le prix.\")\n","elif 'pivotList' not in locals():\n","     print(\"ERREUR: `pivotList` global non disponible pour tracer les pivots.\")\n","else:\n","    # --- MODIFICATION : Sélectionner N premières configurations (16 pour une grille 4x4) ---\n","    n_configs_to_plot = 16 # <--- Changé de 9 à 16\n","    configs_to_plot = results_df_explore.head(n_configs_to_plot).copy()\n","    if len(configs_to_plot) < 1: # Vérifier s'il y a au moins une config\n","         print(\"ERREUR: Aucune configuration à plotter.\")\n","         configs_to_plot = None # Marqueur pour ne pas continuer\n","    elif len(configs_to_plot) < n_configs_to_plot:\n","        print(f\"WARN: Moins de {n_configs_to_plot} configurations disponibles ({len(configs_to_plot)}). Affichage d'une grille partielle.\")\n","        n_configs_to_plot = len(configs_to_plot) # Ajuster le nombre réel\n","\n","if 'configs_to_plot' in locals() and configs_to_plot is not None:\n","    cols = 4 # <--- Changé de 3 à 4\n","    rows = math.ceil(n_configs_to_plot / cols)\n","    subplot_titles = [row['config_label'] for index, row in configs_to_plot.iterrows()]\n","\n","    # S'assurer qu'il y a assez de titres pour la grille (remplir si besoin)\n","    subplot_titles.extend([''] * (rows * cols - len(subplot_titles)))\n","\n","    fig = make_subplots(rows=rows, cols=cols, subplot_titles=subplot_titles,\n","                        shared_xaxes=False, # Axe X indépendant\n","                        shared_yaxes=False, # Axe Y indépendant\n","                        vertical_spacing=0.06, horizontal_spacing=0.04) # Espacement ajusté\n","\n","    channel_colors = {\"macro\": \"rgba(60, 60, 60, 0.8)\", \"meso\": \"rgba(0, 0, 255, 0.6)\", \"micro\": \"rgba(255, 0, 255, 0.7)\"}\n","    channel_styles = {\"macro\": \"solid\", \"meso\": \"dash\", \"micro\": \"dot\"}\n","\n","    # Pivots globaux (ceux calculés sur tout l'historique initialement)\n","    high_x_all = [p[0] for p in pivotList if p[2] < 0]\n","    high_y_all = [p[1] for p in pivotList if p[2] < 0]\n","    low_x_all  = [p[0] for p in pivotList if p[2] > 0]\n","    low_y_all  = [p[1] for p in pivotList if p[2] > 0]\n","\n","    # --- Itérer sur les configurations SÉLECTIONNÉES ---\n","    for plot_index, (index, row_data) in enumerate(configs_to_plot.iterrows()):\n","        row_idx = (plot_index // cols) + 1\n","        col_idx = (plot_index % cols) + 1\n","\n","        config_label = row_data['config_label']\n","\n","        # 1. Récupérer les canaux pour CETTE configuration\n","        channels_for_this_config = {\n","            \"macro\": {\"resistance\": (row_data[\"macro_res_p1\"], row_data[\"macro_res_p2\"]), \"support\": (row_data[\"macro_sup_p1\"], row_data[\"macro_sup_p2\"])},\n","            \"meso\": {\"resistance\": (row_data[\"meso_res_p1\"], row_data[\"meso_res_p2\"]), \"support\": (row_data[\"meso_sup_p1\"], row_data[\"meso_sup_p2\"])},\n","            \"micro\": {\"resistance\": (row_data[\"micro_res_p1\"], row_data[\"micro_res_p2\"]), \"support\": (row_data[\"micro_sup_p1\"], row_data[\"micro_sup_p2\"])}\n","        }\n","\n","        # 2. Calculer la plage X et Y basée sur les pivots Meso de CETTE config\n","        meso_pivots_data = []\n","        yaxis_range_subplot = None\n","        xaxis_range_subplot = None\n","\n","        meso_def = channels_for_this_config.get(\"meso\", {})\n","        meso_res_p1_info, meso_res_p2_info = meso_def.get(\"resistance\", ({},{}))\n","        meso_sup_p1_info, meso_sup_p2_info = meso_def.get(\"support\", ({},{}))\n","\n","        for p_info in [meso_res_p1_info, meso_res_p2_info, meso_sup_p1_info, meso_sup_p2_info]:\n","            if isinstance(p_info, dict) and not pd.isna(p_info.get('time')) and not pd.isna(p_info.get('price')):\n","                meso_pivots_data.append({'time': pd.to_datetime(p_info['time']), 'price': p_info['price']})\n","\n","        if len(meso_pivots_data) >= 2:\n","            meso_pivots_df = pd.DataFrame(meso_pivots_data)\n","            min_p_meso = meso_pivots_df['price'].min()\n","            max_p_meso = meso_pivots_df['price'].max()\n","            min_t_meso = meso_pivots_df['time'].min()\n","            max_t_meso = meso_pivots_df['time'].max()\n","\n","            # Calcul Plage Y\n","            height_meso = max_p_meso - min_p_meso\n","            margin_y = max(height_meso * 0.30, (min_p_meso + max_p_meso)/2 * 0.05)\n","            yaxis_range_subplot = [min_p_meso - margin_y, max_p_meso + margin_y]\n","\n","            # Calcul Plage X\n","            duration_meso = max_t_meso - min_t_meso if max_t_meso > min_t_meso else pd.Timedelta(days=1)\n","            margin_t_before = max(duration_meso * 0.5, pd.Timedelta(days=60))\n","            margin_t_after = max(duration_meso * 0.2, pd.Timedelta(days=30))\n","            xaxis_range_subplot = [min_t_meso - margin_t_before, max_t_meso + margin_t_after]\n","        else:\n","            # Fallback si pas de pivots meso trouvés pour cette config\n","            if not bars_df.empty:\n","                fallback_end_time = bars_df['time'].iloc[-1]\n","                fallback_start_time = fallback_end_time - pd.Timedelta(days=180) # Lookback par défaut\n","                xaxis_range_subplot = [fallback_start_time, fallback_end_time]\n","\n","\n","        # 3. Filtrer les données à afficher dans cette plage temporelle\n","        if xaxis_range_subplot:\n","            bars_subplot = bars_df[(bars_df['time'] >= xaxis_range_subplot[0]) & (bars_df['time'] <= xaxis_range_subplot[1])].copy()\n","            high_x_plot = [t for t in high_x_all if t >= xaxis_range_subplot[0] and t <= xaxis_range_subplot[1]]\n","            high_y_plot = [high_y_all[i] for i, t in enumerate(high_x_all) if t >= xaxis_range_subplot[0] and t <= xaxis_range_subplot[1]]\n","            low_x_plot = [t for t in low_x_all if t >= xaxis_range_subplot[0] and t <= xaxis_range_subplot[1]]\n","            low_y_plot = [low_y_all[i] for i, t in enumerate(low_x_all) if t >= xaxis_range_subplot[0] and t <= xaxis_range_subplot[1]]\n","        else: # Si pas de plage X définie (ne devrait pas arriver avec le fallback)\n","            bars_subplot = bars_df.copy()\n","            high_x_plot, high_y_plot = high_x_all, high_y_all\n","            low_x_plot, low_y_plot = low_x_all, low_y_all\n","            if not bars_subplot.empty:\n","                 xaxis_range_subplot = [bars_subplot['time'].min(), bars_subplot['time'].max()] # Fallback range X\n","\n","        # Fallback pour Y si toujours None\n","        if yaxis_range_subplot is None and not bars_subplot.empty:\n","            min_p = bars_subplot['low'].min()\n","            max_p = bars_subplot['high'].max()\n","            margin_y = (max_p - min_p) * 0.1\n","            yaxis_range_subplot = [min_p - margin_y, max_p + margin_y]\n","\n","        # 4. Tracer le prix (section filtrée)\n","        if not bars_subplot.empty:\n","            fig.add_trace(go.Scatter(x=bars_subplot['time'], y=bars_subplot['close'], mode='lines',\n","                                     line=dict(color='rgba(150, 150, 150, 0.5)'), name='Close',\n","                                     showlegend=False),\n","                          row=row_idx, col=col_idx)\n","\n","        # 5. Tracer les pivots globaux (section filtrée)\n","        fig.add_trace(go.Scatter(x=high_x_plot, y=high_y_plot, mode='markers', name='High Pivot',\n","                                 marker=dict(color='red', size=4, symbol='diamond-open'), showlegend=(plot_index==0)), # Légende 1 fois\n","                      row=row_idx, col=col_idx)\n","        fig.add_trace(go.Scatter(x=low_x_plot, y=low_y_plot, mode='markers', name='Low Pivot',\n","                                 marker=dict(color='green', size=4, symbol='circle-open'), showlegend=(plot_index==0)), # Légende 1 fois\n","                      row=row_idx, col=col_idx)\n","\n","\n","        # 6. Tracer les 3 canaux pour CETTE configuration\n","        if not bars_subplot.empty:\n","            plot_start_time_dt_eff = bars_subplot['time'].min()\n","            plot_end_time_dt_eff = bars_subplot['time'].max()\n","            plot_start_time_num_eff = plot_start_time_dt_eff.timestamp()\n","            plot_end_time_num_eff = plot_end_time_dt_eff.timestamp()\n","\n","            for channel_name, definition in channels_for_this_config.items():\n","                for line_type in [\"resistance\", \"support\"]:\n","                    p1_info, p2_info = definition.get(line_type, ({}, {}))\n","\n","                    if (isinstance(p1_info, dict) and isinstance(p2_info, dict) and\n","                        not pd.isna(p1_info.get('time')) and not pd.isna(p2_info.get('time')) and\n","                        not pd.isna(p1_info.get('time_numeric')) and not pd.isna(p2_info.get('time_numeric')) and\n","                        not pd.isna(p1_info.get('price')) and not pd.isna(p2_info.get('price'))):\n","\n","                        p1_time_num = p1_info['time_numeric']\n","                        p2_time_num = p2_info['time_numeric']\n","                        p1_price = p1_info['price']\n","                        p2_price = p2_info['price']\n","                        p1_time = pd.to_datetime(p1_info['time'])\n","                        p2_time = pd.to_datetime(p2_info['time'])\n","\n","                        try:\n","                            m, c = get_line_params_time(p1_time_num, p1_price, p2_time_num, p2_price)\n","                            if m != np.inf:\n","                                # Calculer les points Y aux extrémités de la FENETRE VISIBLE\n","                                line_start_y_plot = m * plot_start_time_num_eff + c\n","                                line_end_y_plot = m * plot_end_time_num_eff + c\n","\n","                                fig.add_trace(go.Scatter(\n","                                    x=[plot_start_time_dt_eff, plot_end_time_dt_eff], y=[line_start_y_plot, line_end_y_plot],\n","                                    mode='lines', name=f\"{channel_name.capitalize()} {line_type.capitalize()}\",\n","                                    line=dict(color=channel_colors[channel_name], width=1.5, dash=channel_styles[channel_name]),\n","                                    legendgroup=f\"{channel_name}_{line_type}\",\n","                                    showlegend=(plot_index==0) # Légende juste pour le premier subplot\n","                                ), row=row_idx, col=col_idx)\n","\n","                                # Marquer les pivots utilisés (plus gros) s'ils sont visibles\n","                                pivots_x_to_mark = []\n","                                pivots_y_to_mark = []\n","                                if xaxis_range_subplot and p1_time >= xaxis_range_subplot[0] and p1_time <= xaxis_range_subplot[1]:\n","                                    pivots_x_to_mark.append(p1_time)\n","                                    pivots_y_to_mark.append(p1_price)\n","                                if xaxis_range_subplot and p2_time >= xaxis_range_subplot[0] and p2_time <= xaxis_range_subplot[1]:\n","                                    pivots_x_to_mark.append(p2_time)\n","                                    pivots_y_to_mark.append(p2_price)\n","\n","                                if pivots_x_to_mark:\n","                                    fig.add_trace(go.Scatter(\n","                                        x=pivots_x_to_mark, y=pivots_y_to_mark,\n","                                        mode='markers', marker=dict(color=channel_colors[channel_name], size=7,\n","                                                                      symbol='star' if line_type == 'resistance' else 'star-open'),\n","                                        showlegend=False, hoverinfo='skip'\n","                                    ), row=row_idx, col=col_idx)\n","                        except Exception as e: print(f\"Error plotting line {channel_name} {line_type} for {config_label}: {e}\")\n","\n","        # Appliquer les zooms X et Y calculés pour ce subplot\n","        if yaxis_range_subplot: fig.update_yaxes(range=yaxis_range_subplot, row=row_idx, col=col_idx)\n","        if xaxis_range_subplot: fig.update_xaxes(range=xaxis_range_subplot, row=row_idx, col=col_idx)\n","\n","        # Masquer les ticks X/Y inutiles\n","        if row_idx < rows: fig.update_xaxes(showticklabels=False, row=row_idx, col=col_idx)\n","        if col_idx > 1: fig.update_yaxes(showticklabels=False, row=row_idx, col=col_idx)\n","\n","\n","    # --- Configurer Layout Final ---\n","    fig.update_layout(\n","        title=f'Exploration Paramètres ({n_configs_to_plot} Configs): Canaux & Zoom X/Y sur Pivots Meso',\n","        height=250 * rows + 80, # Ajuster hauteur pour 4 lignes\n","        width=1200, # Un peu plus large pour 4 colonnes\n","        hovermode='x unified',\n","        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.05, xanchor=\"center\", x=0.5) # Légende un peu plus bas\n","    )\n","    # Mettre à jour la taille des titres des subplots\n","    for i, annot in enumerate(fig.layout.annotations):\n","        if i < n_configs_to_plot: # Seulement pour les subplots utilisés\n","            annot.update(font=dict(size=9))\n","\n","    fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Analyse Temporelle : Snapshots Historiques\n","\n","Pour évaluer la robustesse et l'évolution des canaux dans le temps, nous recalculons l'ensemble de la structure de canaux (Macro, Méso, Micro) tels qu'ils auraient été tracés à différentes **dates passées (\"snapshots\")**, en utilisant la **configuration fixe** `final_config`.\n","\n","### 6.1. Calcul des Snapshots\n","\n","**Processus :**\n","\n","1.  **Dates de Snapshot :** Une liste de dates historiques est définie (ex: fin de mois).\n","2.  **Configuration Fixe :** `final_config` est utilisée pour tous les calculs.\n","3.  **Calcul Itératif :** Pour chaque date de snapshot :\n","    *   L'historique de prix *jusqu'à cette date* est utilisé.\n","    *   Les pivots ZigZag sont recalculés sur cet historique tronqué.\n","    *   Les canaux Macro, Méso et Micro sont entièrement recalculés (avec la logique de **fallback** si nécessaire pour Meso/Micro) en utilisant les paramètres de `final_config`.\n","4.  **Stockage :** Les pivots et définitions de canaux résultants (`snapshot_results`) sont stockés pour chaque date.\n","\n","Permet de vérifier si les canaux récents étaient déjà présents ou similaires dans le passé."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE HELPER (MODIFIÉE) : Fonction pour Calculer Tous les Canaux à une Date Donnée AVEC FALLBACK\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","import traceback # Pour le débogage si besoin\n","\n","# Assurer que les dépendances sont chargées (elles devraient l'être par les cellules précédentes)\n","if 'classic_chart_zigzag' not in locals(): raise NameError(\"classic_chart_zigzag non définie\")\n","if 'find_best_channel_line_strict_weighted' not in locals(): raise NameError(\"find_best_channel_line_strict_weighted non définie\")\n","if 'get_pivot_info_snap' not in locals(): # S'assurer que la version snapshot est définie\n","    def get_pivot_info_snap(pivot_series):\n","         if pivot_series is None or not isinstance(pivot_series, pd.Series): return {'time': pd.NaT, 'price': np.nan, 'time_numeric': np.nan, 'original_index': -1}\n","         time_numeric_val = pivot_series.get('time_numeric', np.nan)\n","         if pd.isna(time_numeric_val) and not pd.isna(pivot_series.get('time')):\n","             try:\n","                 dt_obj = pivot_series['time']\n","                 if isinstance(dt_obj, pd.Timestamp): dt_obj = dt_obj.to_pydatetime()\n","                 time_numeric_val = dt_obj.timestamp()\n","             except Exception as e: time_numeric_val = np.nan\n","         return {'time': pivot_series.get('time', pd.NaT), 'price': pivot_series.get('price', np.nan), 'time_numeric': time_numeric_val, 'original_index': pivot_series.name if hasattr(pivot_series, 'name') else -1}\n","\n","def calculate_all_channels_at_date(end_date_dt, full_history_df, config, zigzag_threshold=0.05):\n","    \"\"\"\n","    Calcule les pivots ZigZag et les canaux Macro, Meso, Micro avec logique de fallback\n","    pour les dates de début de Meso et Micro.\n","    \"\"\"\n","    try:\n","        # 1. Filtrer l'historique\n","        hist_for_calc = full_history_df[full_history_df['time'] <= end_date_dt].copy()\n","        if len(hist_for_calc) < 5: return None, None\n","\n","        # 2. Calculer les pivots ZigZag\n","        snap_pivots_list = classic_chart_zigzag(hist_for_calc[['time','close']], thresholdPercent=zigzag_threshold)\n","        if not snap_pivots_list or len(snap_pivots_list) < 2: return snap_pivots_list, None\n","\n","        snap_pivots_df = pd.DataFrame(snap_pivots_list, columns=['time', 'price', 'type'])\n","        snap_pivots_df['time_numeric'] = snap_pivots_df['time'].apply(lambda x: x.timestamp())\n","        snap_high_pivots = snap_pivots_df[snap_pivots_df['type'] == -1].copy()\n","        snap_low_pivots = snap_pivots_df[snap_pivots_df['type'] == +1].copy()\n","        snap_all_high_np = snap_high_pivots[['time_numeric', 'price']].values\n","        snap_all_low_np = snap_low_pivots[['time_numeric', 'price']].values\n","\n","        if len(snap_high_pivots) < 2 or len(snap_low_pivots) < 2: return snap_pivots_list, None\n","\n","        # 3. Calculer les canaux hiérarchiques\n","        channels = {\"macro\": {}, \"meso\": {}, \"micro\": {}}\n","        # Initialiser avec None pour faciliter la détection d'échec\n","        for scale in channels:\n","            channels[scale][\"resistance\"] = (None, None)\n","            channels[scale][\"support\"] = (None, None)\n","\n","        # --- Macro ---\n","        macro_success = False\n","        try:\n","            res1_m, res2_m = find_best_channel_line_strict_weighted(snap_high_pivots, snap_all_high_np, True, config['wp_macro_res'], config['rpf_macro_res'])\n","            sup1_m, sup2_m = find_best_channel_line_strict_weighted(snap_low_pivots, snap_all_low_np, False, config['wp_macro_sup'], config['rpf_macro_sup'])\n","            # Stocker les infos seulement si les deux pivots sont trouvés\n","            if res1_m is not None and res2_m is not None:\n","                 channels[\"macro\"][\"resistance\"] = (get_pivot_info_snap(res1_m), get_pivot_info_snap(res2_m))\n","            if sup1_m is not None and sup2_m is not None:\n","                 channels[\"macro\"][\"support\"] = (get_pivot_info_snap(sup1_m), get_pivot_info_snap(sup2_m))\n","            # Macro est un succès si AU MOINS un support ET une résistance sont définis\n","            if channels[\"macro\"][\"resistance\"][0] is not None and channels[\"macro\"][\"support\"][0] is not None:\n","                macro_success = True\n","        except Exception as e_macro: pass\n","\n","        # --- Meso (avec Fallback) ---\n","        meso_success = False\n","        if macro_success:\n","            macro_pivots_info = [\n","                channels[\"macro\"][\"resistance\"][0], channels[\"macro\"][\"resistance\"][1],\n","                channels[\"macro\"][\"support\"][0], channels[\"macro\"][\"support\"][1]\n","            ]\n","            # Filtrer les pivots valides (non None et avec une date)\n","            valid_macro_pivots = [p for p in macro_pivots_info if p and not pd.isna(p.get('time'))]\n","            valid_macro_pivots.sort(key=lambda p: pd.to_datetime(p['time']), reverse=True) # Trier par date décroissante\n","\n","            meso_start_time = None\n","            # Essai 1: 2ème pivot le plus récent\n","            if len(valid_macro_pivots) >= 2:\n","                meso_start_time = pd.to_datetime(valid_macro_pivots[1]['time']) # 2ème plus récent\n","\n","            # Essai 2 (Fallback): 3ème pivot le plus récent (si essai 1 échoue et si assez de pivots)\n","            attempted_fallback_meso = False\n","            if meso_start_time is not None:\n","                meso_high_f = snap_high_pivots[snap_high_pivots['time'] >= meso_start_time].copy()\n","                meso_low_f = snap_low_pivots[snap_low_pivots['time'] >= meso_start_time].copy()\n","                # Si pas assez de pivots après le 2ème, et si on a au moins 4 pivots macro pour tenter le 3ème\n","                if (len(meso_high_f) < 2 or len(meso_low_f) < 2) and len(valid_macro_pivots) >= 4:\n","                    meso_start_time = pd.to_datetime(valid_macro_pivots[2]['time']) # 3ème plus récent\n","                    attempted_fallback_meso = True\n","            elif len(valid_macro_pivots) >= 3: # Si l'essai 1 n'a même pas pu avoir lieu (moins de 2 pivots) mais qu'on en a 3 ou 4\n","                 meso_start_time = pd.to_datetime(valid_macro_pivots[2]['time']) # Essayer directement le 3ème\n","                 attempted_fallback_meso = True\n","\n","\n","            # Calcul Meso si une date de début valide a été trouvée\n","            if meso_start_time is not None:\n","                 try:\n","                    meso_high_f = snap_high_pivots[snap_high_pivots['time'] >= meso_start_time].copy()\n","                    meso_low_f = snap_low_pivots[snap_low_pivots['time'] >= meso_start_time].copy()\n","                    if len(meso_high_f) >= 2 and len(meso_low_f) >= 2:\n","                        meso_high_np = meso_high_f[['time_numeric', 'price']].values\n","                        meso_low_np = meso_low_f[['time_numeric', 'price']].values\n","                        res1_me, res2_me = find_best_channel_line_strict_weighted(meso_high_f, meso_high_np, True, config['wp_meso_res'], config['rpf_meso_res'])\n","                        sup1_me, sup2_me = find_best_channel_line_strict_weighted(meso_low_f, meso_low_np, False, config['wp_meso_sup'], config['rpf_meso_sup'])\n","                        if res1_me is not None and res2_me is not None:\n","                            channels[\"meso\"][\"resistance\"] = (get_pivot_info_snap(res1_me), get_pivot_info_snap(res2_me))\n","                        if sup1_me is not None and sup2_me is not None:\n","                            channels[\"meso\"][\"support\"] = (get_pivot_info_snap(sup1_me), get_pivot_info_snap(sup2_me))\n","                        # Meso succès si résistance ET support trouvés\n","                        if channels[\"meso\"][\"resistance\"][0] is not None and channels[\"meso\"][\"support\"][0] is not None:\n","                             meso_success = True\n","                             # print(f\"DEBUG [{end_date_dt.date()}] Meso OK {'(Fallback)' if attempted_fallback_meso else ''}\")\n","                    # else:\n","                         # print(f\"DEBUG [{end_date_dt.date()}] Meso FAIL: Not enough pivots after start {'(Fallback)' if attempted_fallback_meso else ''}\")\n","\n","                 except Exception as e_meso: pass # print(f\"DEBUG [{end_date_dt.date()}] Meso Calc Error: {e_meso}\")\n","            # else:\n","                 # print(f\"DEBUG [{end_date_dt.date()}] Meso FAIL: No valid start time found.\")\n","\n","\n","        # --- Micro (avec Fallback) ---\n","        # Note: On ne définit pas micro_success, on calcule juste si possible\n","        if meso_success: # Micro ne peut exister que si Meso a réussi\n","            meso_pivots_info = [\n","                channels[\"meso\"][\"resistance\"][0], channels[\"meso\"][\"resistance\"][1],\n","                channels[\"meso\"][\"support\"][0], channels[\"meso\"][\"support\"][1]\n","            ]\n","            valid_meso_pivots = [p for p in meso_pivots_info if p and not pd.isna(p.get('time'))]\n","            valid_meso_pivots.sort(key=lambda p: pd.to_datetime(p['time']), reverse=True)\n","\n","            micro_start_time = None\n","            # Essai 1: 2ème pivot meso le plus récent\n","            if len(valid_meso_pivots) >= 2:\n","                micro_start_time = pd.to_datetime(valid_meso_pivots[1]['time'])\n","\n","            # Essai 2 (Fallback): 3ème pivot meso le plus récent\n","            attempted_fallback_micro = False\n","            if micro_start_time is not None:\n","                 micro_high_f_test = snap_high_pivots[snap_high_pivots['time'] >= micro_start_time].copy()\n","                 micro_low_f_test = snap_low_pivots[snap_low_pivots['time'] >= micro_start_time].copy()\n","                 if (len(micro_high_f_test) < 2 or len(micro_low_f_test) < 2) and len(valid_meso_pivots) >= 4:\n","                      micro_start_time = pd.to_datetime(valid_meso_pivots[2]['time'])\n","                      attempted_fallback_micro = True\n","            elif len(valid_meso_pivots) >= 3:\n","                 micro_start_time = pd.to_datetime(valid_meso_pivots[2]['time'])\n","                 attempted_fallback_micro = True\n","\n","\n","            # Calcul Micro si une date de début valide a été trouvée\n","            if micro_start_time is not None:\n","                try:\n","                    micro_high_f = snap_high_pivots[snap_high_pivots['time'] >= micro_start_time].copy()\n","                    micro_low_f = snap_low_pivots[snap_low_pivots['time'] >= micro_start_time].copy()\n","                    if len(micro_high_f) >= 2 and len(micro_low_f) >= 2:\n","                        micro_high_np = micro_high_f[['time_numeric', 'price']].values\n","                        micro_low_np = micro_low_f[['time_numeric', 'price']].values\n","                        res1_mi, res2_mi = find_best_channel_line_strict_weighted(micro_high_f, micro_high_np, True, config['wp_micro_res'], config['rpf_micro_res'])\n","                        sup1_mi, sup2_mi = find_best_channel_line_strict_weighted(micro_low_f, micro_low_np, False, config['wp_micro_sup'], config['rpf_micro_sup'])\n","                        if res1_mi is not None and res2_mi is not None:\n","                             channels[\"micro\"][\"resistance\"] = (get_pivot_info_snap(res1_mi), get_pivot_info_snap(res2_mi))\n","                        if sup1_mi is not None and sup2_mi is not None:\n","                            channels[\"micro\"][\"support\"] = (get_pivot_info_snap(sup1_mi), get_pivot_info_snap(sup2_mi))\n","                        # if channels[\"micro\"][\"resistance\"][0] or channels[\"micro\"][\"support\"][0]:\n","                        #     print(f\"DEBUG [{end_date_dt.date()}] Micro OK {'(Fallback)' if attempted_fallback_micro else ''}\")\n","                    # else:\n","                        # print(f\"DEBUG [{end_date_dt.date()}] Micro FAIL: Not enough pivots after start {'(Fallback)' if attempted_fallback_micro else ''}\")\n","\n","                except Exception as e_micro: pass # print(f\"DEBUG [{end_date_dt.date()}] Micro Calc Error: {e_micro}\")\n","            # else:\n","                # print(f\"DEBUG [{end_date_dt.date()}] Micro FAIL: No valid start time found.\")\n","\n","        return snap_pivots_list, channels\n","\n","    except Exception as e:\n","        print(f\"ERREUR Majeure dans calculate_all_channels_at_date pour {end_date_dt}: {e}\")\n","        # traceback.print_exc()\n","        return None, None\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 29 : Calcul des Snapshots Historiques (Révisée)\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","from datetime import datetime, timedelta\n","from tqdm.notebook import tqdm\n","import traceback # Importé pour le debug au besoin\n","\n","# --- Vérifier les dépendances clés ---\n","if 'bars_df' not in locals(): raise NameError(\"bars_df non défini\")\n","if 'final_config' not in locals(): raise NameError(\"final_config non définie\")\n","if 'calculate_all_channels_at_date' not in locals() or not callable(calculate_all_channels_at_date):\n","    raise NameError(\"Fonction 'calculate_all_channels_at_date' non définie ou non appelable.\")\n","\n","# --- Dates de Snapshot (Logique de génération inchangée) ---\n","data_tz = bars_df['time'].dt.tz # Récupérer le timezone des données sources\n","\n","# Utiliser une date de début pour les snapshots (ex: 1 an avant la fin des données ou date spécifique)\n","snapshot_start_calc_date = bars_df['time'].iloc[0] # Ou une date spécifique: pd.Timestamp(\"2024-01-01\", tz=data_tz)\n","if snapshot_start_calc_date > bars_df['time'].iloc[-1] - pd.Timedelta(days=60): # S'assurer qu'on a au moins 2 mois de snapshots\n","     snapshot_start_calc_date = bars_df['time'].iloc[-1] - pd.Timedelta(days=60)\n","\n","last_hist_date = bars_df['time'].iloc[-1]\n","\n","# Générer les dates de fin de mois (ou autre fréquence)\n","freq_snapshots = 'M' # 'M'=Fin de Mois, 'W'=Fin de Semaine, 'D'=Jour etc.\n","print(f\"Génération des dates de snapshots (freq='{freq_snapshots}') entre {snapshot_start_calc_date.date()} et {last_hist_date.date()}\")\n","try:\n","    # Générer les dates de fin de période\n","    snapshot_dates_gen = pd.date_range(\n","        start=snapshot_start_calc_date,\n","        end=last_hist_date,\n","        freq=freq_snapshots,\n","        tz=data_tz # Appliquer le timezone des données sources\n","    )\n","    # S'assurer que les dates générées ne dépassent pas la dernière date historique\n","    snapshot_dates_gen = snapshot_dates_gen[snapshot_dates_gen <= last_hist_date]\n","\n","except Exception as e:\n","    print(f\"ERREUR lors de la génération de date_range: {e}\")\n","    snapshot_dates = pd.DatetimeIndex([]) # Créer un index vide pour éviter erreur aval\n","    # raise # Optionnel: arrêter l'exécution ici\n","\n","if not snapshot_dates_gen.empty:\n","     # Ajouter la toute dernière date de l'historique si elle est significativement après la dernière date générée\n","    if last_hist_date > snapshot_dates_gen[-1] + pd.Timedelta(hours=1):\n","         snapshot_dates_list = snapshot_dates_gen.to_list()\n","         snapshot_dates_list.append(last_hist_date)\n","         snapshot_dates = pd.DatetimeIndex(snapshot_dates_list).sort_values()\n","    else:\n","         snapshot_dates = snapshot_dates_gen\n","    # S'assurer qu'il n'y a pas de doublons (si last_hist_date tombe sur une fin de période)\n","    snapshot_dates = snapshot_dates.unique()\n","else: # Si date_range est vide ou période très courte\n","     snapshot_dates = pd.DatetimeIndex([last_hist_date], tz=data_tz) # Garder le timezone\n","\n","\n","print(f\"Calcul pour {len(snapshot_dates)} dates de snapshots : {snapshot_dates.strftime('%Y-%m-%d').tolist()}\")\n","\n","# --- Calcul Effectif des Snapshots ---\n","snapshot_results = {}\n","config_for_snapshots = final_config # Utiliser la configuration finale sélectionnée\n","\n","print(f\"\\nUtilisation de final_config '{config_for_snapshots.get('label', 'N/A')}' pour les calculs de snapshots.\")\n","\n","for snap_date in tqdm(snapshot_dates, desc=\"Calculating Snapshots\"):\n","    # La fonction `calculate_all_channels_at_date` gère le filtrage de l'historique\n","    # S'assurer que la date passée a le bon TZ ou est naive si les données sont naives\n","    snap_date_to_pass = snap_date\n","    if data_tz is None and getattr(snap_date, 'tz', None) is not None:\n","        snap_date_to_pass = snap_date.tz_convert(None)\n","    elif data_tz is not None and getattr(snap_date, 'tz', None) is None:\n","         try:\n","             snap_date_to_pass = snap_date.tz_localize(data_tz)\n","         except Exception as e:\n","              print(f\"Warn: Could not localize snap_date {snap_date} to {data_tz}. Skipping snapshot.\")\n","              snapshot_results[snap_date] = {\"pivots\": None, \"channels\": None}\n","              continue # Passer au snapshot suivant\n","\n","    # Appeler la fonction de calcul dédiée\n","    pivots, channels = calculate_all_channels_at_date(snap_date_to_pass, bars_df, config_for_snapshots)\n","\n","    # Stocker les résultats (même si channels est None, on garde les pivots s'ils existent)\n","    snapshot_results[snap_date] = {\"pivots\": pivots, \"channels\": channels}\n","\n","print(\"\\nCalcul des snapshots terminé.\")\n","\n","# Optionnel: Vérifier combien de snapshots ont réussi à calculer des canaux\n","successful_channel_calcs = sum(1 for r in snapshot_results.values() if r and r.get('channels') is not None)\n","print(f\"{successful_channel_calcs} / {len(snapshot_dates)} snapshots ont pu calculer au moins une partie des canaux.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### 6.2. Analyse de Stabilité des Pivots (Optionnel)\n","\n","Cette cellule analyse les résultats des snapshots (`snapshot_results`) pour quantifier la fréquence à laquelle les pivots définissant chaque ligne de canal (Macro, Méso, Micro - Support & Résistance) changent d'un snapshot à l'autre. Une faible fréquence de changement suggère une plus grande robustesse des canaux identifiés."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 29b (Nouvelle) : Analyse de la Stabilité des Pivots Définissant les Canaux\n","\n","import pandas as pd\n","\n","if 'snapshot_results' not in locals() or not snapshot_results:\n","    print(\"ERREUR: Pas de résultats de snapshots à analyser.\")\n","else:\n","    stability_data = []\n","    previous_pivots = {} # Stocker les pivots du snapshot précédent\n","\n","    for snap_date in sorted(snapshot_results.keys()):\n","        result = snapshot_results[snap_date]\n","        if not result or not result.get('channels'):\n","            continue\n","\n","        channels = result['channels']\n","        current_pivots = {}\n","        row_data = {'snapshot_date': snap_date}\n","\n","        for scale in ['macro', 'meso', 'micro']:\n","            for line_type in ['support', 'resistance']:\n","                key = f\"{scale}_{line_type}\"\n","                p1_info, p2_info = channels.get(scale, {}).get(line_type, ({}, {}))\n","\n","                # Utiliser le timestamp comme identifiant unique (plus robuste que l'index)\n","                p1_id = pd.to_datetime(p1_info.get('time')).isoformat() if isinstance(p1_info, dict) and not pd.isna(p1_info.get('time')) else None\n","                p2_id = pd.to_datetime(p2_info.get('time')).isoformat() if isinstance(p2_info, dict) and not pd.isna(p2_info.get('time')) else None\n","                current_pivots[key] = (p1_id, p2_id)\n","\n","                row_data[f\"{key}_p1_time\"] = p1_id\n","                row_data[f\"{key}_p2_time\"] = p2_id\n","\n","                # Comparer avec le snapshot précédent\n","                changed = False\n","                if key in previous_pivots:\n","                    if previous_pivots[key] != current_pivots[key]:\n","                        changed = True\n","                row_data[f\"{key}_changed\"] = changed\n","\n","        stability_data.append(row_data)\n","        previous_pivots = current_pivots # Mettre à jour pour la prochaine itération\n","\n","    if stability_data:\n","        stability_df = pd.DataFrame(stability_data)\n","        stability_df = stability_df.set_index('snapshot_date')\n","\n","        print(\"\\n--- Analyse de Stabilité des Pivots Définissant les Canaux ---\")\n","        # Afficher les colonnes indiquant les changements\n","        change_cols = [col for col in stability_df.columns if 'changed' in col]\n","        if change_cols:\n","             print(stability_df[change_cols].to_string())\n","             # Compter le nombre total de changements pour chaque canal\n","             print(\"\\nNombre total de changements de pivots par canal:\")\n","             print(stability_df[change_cols].sum())\n","        else:\n","             print(\"Aucune colonne de changement trouvée.\")\n","\n","    else:\n","        print(\"Impossible de générer les données de stabilité.\")"]},{"cell_type":"markdown","metadata":{},"source":["### 6.3. Visualisation des Snapshots (Configuration Cible)\n","\n","Ce graphique présente les résultats de l'analyse temporelle (basée sur `final_config`) sous forme de grille de sous-graphiques (subplots).\n","\n","**Organisation de la Grille :**\n","\n","*   Chaque sous-graphique correspond à une **date de snapshot**.\n","*   Le titre indique la date de fin de l'historique utilisé.\n","*   Chaque sous-graphique affiche :\n","    *   Prix de clôture jusqu'au snapshot.\n","    *   Pivots ZigZag du snapshot.\n","    *   Canaux Macro, Méso et Micro déterminés à cette date.\n","*   Chaque sous-graphique **zoome automatiquement** sur une fenêtre temporelle et une plage de prix définies par les **pivots des canaux Meso et Micro** (si disponibles, sinon Macro) calculés pour ce snapshot spécifique, pour mieux visualiser la structure récente.\n","\n","Permet d'observer comment la structure hiérarchique (calculée avec `final_config`) a **évolué au fil du temps**."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 30 (MODIFIÉE) : Visualisation 2D Snapshots - Zoom Meso/Micro\n","\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","import pandas as pd\n","import numpy as np\n","import math\n","\n","# --- Pré-requis ---\n","if 'snapshot_results' not in locals() or not snapshot_results: print(\"ERREUR: Pas de résultats de snapshots ('snapshot_results') à visualiser.\")\n","elif 'final_config' not in locals(): print(\"ERREUR: `final_config` non définie.\")\n","elif 'get_line_params_time' not in locals(): print(\"ERREUR: `get_line_params_time` non définie.\")\n","elif 'bars_df' not in locals(): print(\"ERREUR: `bars_df` non disponible.\")\n","elif not any(res is not None and res.get('channels') is not None for date, res in snapshot_results.items() if res is not None):\n","    print(\"WARN: Aucun snapshot n'a pu calculer de canaux valides. Impossible de générer le graphique.\")\n","else:\n","    valid_snapshots = {date: res for date, res in snapshot_results.items() if res and res.get('channels') is not None}\n","    if not valid_snapshots: print(\"ERREUR: Aucun snapshot avec des canaux valides trouvé pour le plot.\")\n","    else:\n","        sorted_snap_dates = sorted(valid_snapshots.keys())\n","        n_snapshots_to_plot = len(sorted_snap_dates)\n","        print(f\"Nombre de snapshots valides à afficher: {n_snapshots_to_plot}\")\n","\n","        if n_snapshots_to_plot > 0:\n","            # --- Configuration Grille ---\n","            cols = 4; rows = math.ceil(n_snapshots_to_plot / cols)\n","            print(f\"Affichage de {n_snapshots_to_plot} snapshots sur une grille de {rows}x{cols}.\")\n","            subplot_titles=[d.strftime('%Y-%m-%d') for d in sorted_snap_dates]\n","            subplot_titles.extend([''] * (rows * cols - len(subplot_titles)))\n","            fig = make_subplots(rows=rows, cols=cols, subplot_titles=subplot_titles,\n","                                shared_xaxes=False, shared_yaxes=False,\n","                                vertical_spacing=0.08, horizontal_spacing=0.05)\n","            channel_colors = {\"macro\": \"rgba(60, 60, 60, 0.8)\", \"meso\": \"rgba(0, 0, 255, 0.6)\", \"micro\": \"rgba(255, 0, 255, 0.7)\"}\n","            channel_styles = {\"macro\": \"solid\", \"meso\": \"dash\", \"micro\": \"dot\"}\n","            data_tz = bars_df['time'].dt.tz\n","\n","            # --- Boucle de Plotting ---\n","            for i, snap_date in enumerate(sorted_snap_dates):\n","                row_idx = (i // cols) + 1; col_idx = (i % cols) + 1\n","                result = valid_snapshots[snap_date]\n","                snap_pivots_list = result.get(\"pivots\")\n","                snap_channels = result.get(\"channels\")\n","\n","                # --- Calcul Zoom X/Y (NOUVELLE LOGIQUE: Priorité Meso/Micro) ---\n","                zoom_pivots_data = []\n","                yaxis_range_subplot = None\n","                xaxis_range_subplot = None\n","                zoom_level_used = \"Fallback\" # Pour info\n","\n","                if snap_channels:\n","                    # 1. Essayer de collecter les pivots Meso ET Micro\n","                    for scale in [\"meso\", \"micro\"]:\n","                        scale_def = snap_channels.get(scale, {})\n","                        res_p12 = scale_def.get(\"resistance\", ({},{}))\n","                        sup_p12 = scale_def.get(\"support\", ({},{}))\n","                        for p_info in [res_p12[0], res_p12[1], sup_p12[0], sup_p12[1]]:\n","                            if isinstance(p_info, dict) and not pd.isna(p_info.get('time')) and not pd.isna(p_info.get('price')):\n","                                 time_val = pd.to_datetime(p_info['time']).to_pydatetime()\n","                                 if getattr(time_val, 'tzinfo', None) is not None: time_val = time_val.replace(tzinfo=None)\n","                                 zoom_pivots_data.append({'time': time_val, 'price': p_info['price']})\n","\n","                    if len(zoom_pivots_data) >= 2:\n","                         zoom_level_used = \"Meso/Micro\"\n","                    else:\n","                         # 2. Si échec, essayer avec Macro seulement\n","                         zoom_pivots_data = [] # Reset\n","                         scale_def = snap_channels.get(\"macro\", {})\n","                         res_p12 = scale_def.get(\"resistance\", ({},{}))\n","                         sup_p12 = scale_def.get(\"support\", ({},{}))\n","                         for p_info in [res_p12[0], res_p12[1], sup_p12[0], sup_p12[1]]:\n","                              if isinstance(p_info, dict) and not pd.isna(p_info.get('time')) and not pd.isna(p_info.get('price')):\n","                                   time_val = pd.to_datetime(p_info['time']).to_pydatetime()\n","                                   if getattr(time_val, 'tzinfo', None) is not None: time_val = time_val.replace(tzinfo=None)\n","                                   zoom_pivots_data.append({'time': time_val, 'price': p_info['price']})\n","                         if len(zoom_pivots_data) >= 2:\n","                              zoom_level_used = \"Macro\"\n","\n","                # 3. Calculer les ranges à partir des pivots collectés (Meso/Micro ou Macro)\n","                if len(zoom_pivots_data) >= 2:\n","                    zoom_pivots_df = pd.DataFrame(zoom_pivots_data)\n","                    min_p_zoom = zoom_pivots_df['price'].min(); max_p_zoom = zoom_pivots_df['price'].max()\n","                    min_t_zoom = zoom_pivots_df['time'].min(); max_t_zoom = zoom_pivots_df['time'].max()\n","\n","                    height_zoom = max_p_zoom - min_p_zoom\n","                    margin_y = max(height_zoom * 0.30, (min_p_zoom + max_p_zoom)/2 * 0.05) # Marge Y 30%\n","                    yaxis_range_subplot = [min_p_zoom - margin_y, max_p_zoom + margin_y]\n","\n","                    min_t_zoom_ts = pd.Timestamp(min_t_zoom, tz=data_tz); max_t_zoom_ts = pd.Timestamp(max_t_zoom, tz=data_tz)\n","                    duration_zoom = max_t_zoom_ts - min_t_zoom_ts if max_t_zoom_ts > min_t_zoom_ts else pd.Timedelta(days=1)\n","                    # Ajuster marges temporelles pour bien voir la structure ciblée\n","                    margin_t_before = max(duration_zoom * 0.5, pd.Timedelta(days=45)) # Marge avant 50%\n","                    margin_t_after = max(duration_zoom * 0.2, pd.Timedelta(days=20))  # Marge après 20%\n","                    xaxis_range_subplot = [min_t_zoom_ts - margin_t_before, max_t_zoom_ts + margin_t_after]\n","                    xaxis_range_subplot[1] = min(xaxis_range_subplot[1], pd.Timestamp(snap_date + pd.Timedelta(days=5), tz=data_tz))\n","                    # print(f\"DEBUG Zoom {snap_date.date()}: Used {zoom_level_used} pivots.\") # Décommenter pour vérifier\n","\n","                # 4. Si AUCUN pivot trouvé pour zoomer (Meso/Micro ET Macro échouent) -> Fallback temporel\n","                if xaxis_range_subplot is None:\n","                    zoom_level_used = \"Fallback Time\"\n","                    lookback_plot_days = 90\n","                    xaxis_range_subplot = [pd.Timestamp(snap_date - pd.Timedelta(days=lookback_plot_days), tz=data_tz), pd.Timestamp(snap_date + pd.Timedelta(days=5), tz=data_tz)]\n","                    bars_subplot_fallback = bars_df[(bars_df['time'] >= xaxis_range_subplot[0]) & (bars_df['time'] <= snap_date)].copy()\n","                    if not bars_subplot_fallback.empty:\n","                         min_p = bars_subplot_fallback['low'].min(); max_p = bars_subplot_fallback['high'].max(); margin_y = (max_p - min_p) * 0.1 if (max_p - min_p) > 1e-6 else max_p * 0.05\n","                         yaxis_range_subplot = [min_p - margin_y, max_p + margin_y]\n","                    # print(f\"DEBUG Zoom {snap_date.date()}: Used Fallback Time.\") # Décommenter pour vérifier\n","                # --- Fin Calcul Zoom X/Y ---\n","\n","                # --- Filtrage Données et Tracé (reste identique à la version précédente de Cell 30) ---\n","                # ... (coller ici la partie filtrage et tracé de la cellule 30 précédente) ...\n","                # ... (Assurez-vous d'utiliser xaxis_range_subplot et yaxis_range_subplot calculés ci-dessus) ...\n","\n","                # 1. Filtrage\n","                bars_subplot = bars_df[(bars_df['time'] >= xaxis_range_subplot[0]) & (bars_df['time'] <= snap_date)].copy()\n","                pivots_in_view_df = pd.DataFrame()\n","                if snap_pivots_list:\n","                    pivots_plot_df = pd.DataFrame(snap_pivots_list, columns=['time','price','type']); pivots_plot_df['time'] = pd.to_datetime(pivots_plot_df['time'])\n","                    pivot_tz = pivots_plot_df['time'].dt.tz\n","                    if data_tz is not None and pivot_tz is None:\n","                         try: pivots_plot_df['time'] = pivots_plot_df['time'].dt.tz_localize(data_tz, ambiguous='infer', nonexistent='shift_forward')\n","                         except: pass\n","                    elif data_tz is None and pivot_tz is not None: pivots_plot_df['time'] = pivots_plot_df['time'].dt.tz_convert(None)\n","                    elif data_tz is not None and pivot_tz is not None and hasattr(data_tz, 'zone') and hasattr(pivot_tz, 'zone') and data_tz.zone != pivot_tz.zone: pivots_plot_df['time'] = pivots_plot_df['time'].dt.tz_convert(data_tz)\n","                    pivots_in_view_df = pivots_plot_df[(pivots_plot_df['time'] >= xaxis_range_subplot[0]) & (pivots_plot_df['time'] <= snap_date)]\n","                if yaxis_range_subplot is None: # Fallback Y si besoin\n","                     all_prices_in_view = pd.concat([bars_subplot['low'], bars_subplot['high'], pivots_in_view_df['price']]).dropna()\n","                     if not all_prices_in_view.empty:\n","                         min_p = all_prices_in_view.min(); max_p = all_prices_in_view.max(); margin_y = (max_p - min_p) * 0.1 if (max_p - min_p) > 1e-6 else max_p * 0.05\n","                         yaxis_range_subplot = [min_p - margin_y, max_p + margin_y]\n","\n","                # 2. Tracé Prix\n","                if not bars_subplot.empty: fig.add_trace(go.Scatter(x=bars_subplot['time'], y=bars_subplot['close'], mode='lines', name='Close', line=dict(color='rgba(150, 150, 150, 0.5)'), showlegend=(i==0)), row=row_idx, col=col_idx)\n","\n","                # 3. Tracé Pivots\n","                if not pivots_in_view_df.empty:\n","                    high_x = pivots_in_view_df[pivots_in_view_df['type'] < 0]['time']; high_y = pivots_in_view_df[pivots_in_view_df['type'] < 0]['price']\n","                    low_x  = pivots_in_view_df[pivots_in_view_df['type'] > 0]['time']; low_y  = pivots_in_view_df[pivots_in_view_df['type'] > 0]['price']\n","                    fig.add_trace(go.Scatter(x=high_x, y=high_y, mode='markers', name='High Pivot', marker=dict(color='red', size=5, symbol='diamond-open'), showlegend=(i==0)), row=row_idx, col=col_idx)\n","                    fig.add_trace(go.Scatter(x=low_x, y=low_y, mode='markers', name='Low Pivot', marker=dict(color='green', size=5, symbol='circle-open'), showlegend=(i==0)), row=row_idx, col=col_idx)\n","\n","                # 4. Tracé Canaux\n","                if snap_channels and not bars_subplot.empty:\n","                    plot_start_time_eff = bars_subplot['time'].min(); plot_end_time_eff = snap_date\n","                    plot_start_time_num_eff = plot_start_time_eff.timestamp(); plot_end_time_num_eff = plot_end_time_eff.timestamp()\n","                    for channel_name in [\"macro\", \"meso\", \"micro\"]:\n","                         definition = snap_channels.get(channel_name, {})\n","                         for line_type in [\"resistance\", \"support\"]:\n","                             p1_info, p2_info = definition.get(line_type, ({}, {}))\n","                             if (isinstance(p1_info, dict) and isinstance(p2_info, dict) and # Check validité\n","                                 not pd.isna(p1_info.get('time')) and not pd.isna(p2_info.get('time')) and\n","                                 not pd.isna(p1_info.get('time_numeric')) and not pd.isna(p2_info.get('time_numeric')) and\n","                                 not pd.isna(p1_info.get('price')) and not pd.isna(p2_info.get('price'))):\n","                                 p1_time_num = p1_info['time_numeric']; p2_time_num = p2_info['time_numeric']\n","                                 p1_price = p1_info['price']; p2_price = p2_info['price']\n","                                 p1_time = pd.to_datetime(p1_info['time']); p2_time = pd.to_datetime(p2_info['time'])\n","                                 try:\n","                                     m, c = get_line_params_time(p1_time_num, p1_price, p2_time_num, p2_price)\n","                                     if m != np.inf:\n","                                         line_plot_start_time_dt = max(p1_time, plot_start_time_eff); line_plot_start_time_num = line_plot_start_time_dt.timestamp()\n","                                         line_plot_end_time_dt = plot_end_time_eff\n","                                         line_start_y_plot = m * line_plot_start_time_num + c; line_end_y_plot = m * plot_end_time_num_eff + c\n","                                         fig.add_trace(go.Scatter(x=[line_plot_start_time_dt, line_plot_end_time_dt], y=[line_start_y_plot, line_end_y_plot], mode='lines', name=f\"{channel_name.capitalize()} {line_type.capitalize()}\", line=dict(color=channel_colors[channel_name], width=1.5, dash=channel_styles[channel_name]), legendgroup=f\"{channel_name}_{line_type}\", showlegend=(i==0)), row=row_idx, col=col_idx)\n","                                         pivots_x_to_mark = []; pivots_y_to_mark = []\n","                                         if xaxis_range_subplot and p1_time >= xaxis_range_subplot[0] and p1_time <= xaxis_range_subplot[1]: pivots_x_to_mark.append(p1_time); pivots_y_to_mark.append(p1_price)\n","                                         if xaxis_range_subplot and p2_time >= xaxis_range_subplot[0] and p2_time <= xaxis_range_subplot[1]: pivots_x_to_mark.append(p2_time); pivots_y_to_mark.append(p2_price)\n","                                         if pivots_x_to_mark: fig.add_trace(go.Scatter(x=pivots_x_to_mark, y=pivots_y_to_mark, mode='markers', marker=dict(color=channel_colors[channel_name], size=7, symbol='star' if line_type == 'resistance' else 'star-open'), showlegend=False, hoverinfo='skip'), row=row_idx, col=col_idx)\n","                                 except Exception as e_plotline: pass # print(f\"WARN: Plot line {snap_date.date()}: {e_plotline}\")\n","\n","\n","                # --- Application Zoom et Mise en Forme Axes ---\n","                if yaxis_range_subplot: fig.update_yaxes(range=yaxis_range_subplot, row=row_idx, col=col_idx)\n","                if xaxis_range_subplot: fig.update_xaxes(range=xaxis_range_subplot, row=row_idx, col=col_idx)\n","                if row_idx < rows: fig.update_xaxes(showticklabels=False, row=row_idx, col=col_idx)\n","                if col_idx > 1: fig.update_yaxes(showticklabels=False, row=row_idx, col=col_idx)\n","\n","            # --- Layout Final ---\n","            fig.update_layout(\n","                title=f\"Évolution Temporelle des Canaux ({n_snapshots_to_plot} Snapshots - Config: {final_config.get('label','N/A')}) - Zoom Meso/Micro\",\n","                height=250 * rows + 80, width=1200, hovermode='x unified',\n","                legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.08, xanchor=\"center\", x=0.5)\n","            )\n","            for i_annot, annot in enumerate(fig.layout.annotations):\n","                 if i_annot < n_snapshots_to_plot: annot.update(font=dict(size=9))\n","            fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["### 6.4. Visualisation des Snapshots (Configurations Multiples)\n","\n","Similaire à la visualisation précédente, mais cette cellule génère une grille de snapshots **pour plusieurs configurations de canaux sélectionnées** (définies par `indices_configs_snapshots`).\n","\n","Cela permet de comparer directement comment différentes configurations de `wp`/`rpf` auraient influencé l'évolution historique perçue des canaux. Chaque configuration génère son propre graphique de snapshots complet. Le zoom est également basé sur les pivots Meso/Micro (ou Macro en fallback) pour chaque snapshot de chaque configuration."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 30b (MODIFIÉE) : Affichage Snapshots pour Plusieurs Configs - Zoom Meso/Micro\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","from tqdm.notebook import tqdm\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","import traceback\n","\n","# --- Indices des Configurations à Visualiser ---\n","indices_configs_snapshots = [3, 7, 11] # <--- !!! UTILISATEUR: MODIFIER CETTE LISTE D'INDICES !!!\n","\n","# --- Vérifications ---\n","if 'configurations_to_explore' not in locals(): raise NameError(\"configurations_to_explore non définie\")\n","if 'bars_df' not in locals(): raise NameError(\"bars_df non défini\")\n","if 'calculate_all_channels_at_date' not in locals() or not callable(calculate_all_channels_at_date): raise NameError(\"calculate_all_channels_at_date non définie\")\n","if 'get_line_params_time' not in locals(): raise NameError(\"get_line_params_time non définie\")\n","\n","# --- Boucle sur les Configurations ---\n","for config_idx in indices_configs_snapshots:\n","    if not (0 <= config_idx < len(configurations_to_explore)):\n","        print(f\"WARN: Index {config_idx} invalide. Skip.\"); continue\n","\n","    config_to_snapshot = configurations_to_explore[config_idx]\n","    config_label = config_to_snapshot.get('label', f'Config {config_idx}')\n","    print(f\"\\n{'='*10} Génération Snapshots pour Config: {config_label} (Index {config_idx}) {'='*10}\")\n","\n","    # --- 1. RECALCUL SNAPSHOTS pour CETTE config ---\n","    current_config_snapshot_results = {}\n","    data_tz = bars_df['time'].dt.tz\n","    snapshot_start_calc_date_cfg = bars_df['time'].iloc[0]\n","    if snapshot_start_calc_date_cfg > bars_df['time'].iloc[-1] - pd.Timedelta(days=60): snapshot_start_calc_date_cfg = bars_df['time'].iloc[-1] - pd.Timedelta(days=60)\n","    last_hist_date_cfg = bars_df['time'].iloc[-1]\n","    freq_snapshots_cfg = 'M'\n","    try:\n","        snapshot_dates_gen_cfg = pd.date_range(start=snapshot_start_calc_date_cfg, end=last_hist_date_cfg, freq=freq_snapshots_cfg, tz=data_tz)\n","        snapshot_dates_gen_cfg = snapshot_dates_gen_cfg[snapshot_dates_gen_cfg <= last_hist_date_cfg]\n","    except Exception as e_dr: print(f\"ERREUR date_range {config_label}: {e_dr}\"); continue\n","    if not snapshot_dates_gen_cfg.empty:\n","         if last_hist_date_cfg > snapshot_dates_gen_cfg[-1] + pd.Timedelta(hours=1):\n","             snapshot_dates_list_cfg = snapshot_dates_gen_cfg.to_list(); snapshot_dates_list_cfg.append(last_hist_date_cfg)\n","             snapshot_dates_cfg = pd.DatetimeIndex(snapshot_dates_list_cfg).sort_values().unique()\n","         else: snapshot_dates_cfg = snapshot_dates_gen_cfg.unique()\n","    else: snapshot_dates_cfg = pd.DatetimeIndex([last_hist_date_cfg], tz=data_tz)\n","    print(f\"Calcul pour {len(snapshot_dates_cfg)} snapshots pour {config_label}...\")\n","    for snap_date_cfg in tqdm(snapshot_dates_cfg, desc=f\"Calc Snapshots {config_label[:15]}...\", leave=False):\n","         snap_date_to_pass_cfg = snap_date_cfg\n","         if data_tz is None and getattr(snap_date_cfg, 'tz', None) is not None: snap_date_to_pass_cfg = snap_date_cfg.tz_convert(None)\n","         elif data_tz is not None and getattr(snap_date_cfg, 'tz', None) is None:\n","              try: snap_date_to_pass_cfg = snap_date_cfg.tz_localize(data_tz)\n","              except: print(f\"Warn TZ loc snap {config_label}\"); continue\n","         pivots, channels = calculate_all_channels_at_date(snap_date_to_pass_cfg, bars_df, config_to_snapshot) # Utilise config_to_snapshot\n","         current_config_snapshot_results[snap_date_cfg] = {\"pivots\": pivots, \"channels\": channels}\n","    print(f\"Calcul snapshots pour {config_label} terminé.\")\n","\n","    # --- 2. AFFICHAGE GRAPHIQUE pour CETTE config ---\n","    valid_snapshots_cfg = {date: res for date, res in current_config_snapshot_results.items() if res and res.get('channels') is not None}\n","    if not valid_snapshots_cfg:\n","        print(f\"Aucun snapshot valide pour {config_label}. Skip plot.\"); continue\n","\n","    sorted_snap_dates_cfg = sorted(valid_snapshots_cfg.keys())\n","    n_snapshots_to_plot_cfg = len(sorted_snap_dates_cfg)\n","    cols_cfg = 4; rows_cfg = math.ceil(n_snapshots_to_plot_cfg / cols_cfg)\n","    subplot_titles_cfg=[d.strftime('%Y-%m-%d') for d in sorted_snap_dates_cfg]\n","    subplot_titles_cfg.extend([''] * (rows_cfg * cols_cfg - len(subplot_titles_cfg)))\n","    fig_cfg = make_subplots(rows=rows_cfg, cols=cols_cfg, subplot_titles=subplot_titles_cfg, shared_xaxes=False, shared_yaxes=False, vertical_spacing=0.08, horizontal_spacing=0.05)\n","    channel_colors_cfg = {\"macro\": \"rgba(60, 60, 60, 0.8)\", \"meso\": \"rgba(0, 0, 255, 0.6)\", \"micro\": \"rgba(255, 0, 255, 0.7)\"}\n","    channel_styles_cfg = {\"macro\": \"solid\", \"meso\": \"dash\", \"micro\": \"dot\"}\n","\n","    # Boucle de plotting interne (utilise la logique de zoom de la Cell 30 modifiée)\n","    for i_cfg, snap_date_cfg_plot in enumerate(sorted_snap_dates_cfg):\n","         row_idx_cfg = (i_cfg // cols_cfg) + 1; col_idx_cfg = (i_cfg % cols_cfg) + 1\n","         result_cfg = valid_snapshots_cfg[snap_date_cfg_plot]\n","         snap_pivots_list_cfg = result_cfg.get(\"pivots\"); snap_channels_cfg = result_cfg.get(\"channels\")\n","\n","         # Calcul zoom X/Y (Priorité Meso/Micro - identique à Cell 30 modifiée)\n","         zoom_pivots_data_cfg = []; yaxis_range_subplot_cfg = None; xaxis_range_subplot_cfg = None; zoom_level_used_cfg = \"Fallback\"\n","         if snap_channels_cfg:\n","             for scale in [\"meso\", \"micro\"]: # Essai Meso/Micro\n","                 scale_def = snap_channels_cfg.get(scale, {}); res_p12 = scale_def.get(\"resistance\", ({},{})); sup_p12 = scale_def.get(\"support\", ({},{}))\n","                 for p_info in [res_p12[0], res_p12[1], sup_p12[0], sup_p12[1]]:\n","                      if isinstance(p_info, dict) and not pd.isna(p_info.get('time')) and not pd.isna(p_info.get('price')):\n","                           time_val = pd.to_datetime(p_info['time']).to_pydatetime();\n","                           if getattr(time_val, 'tzinfo', None) is not None: time_val = time_val.replace(tzinfo=None)\n","                           zoom_pivots_data_cfg.append({'time': time_val, 'price': p_info['price']})\n","             if len(zoom_pivots_data_cfg) >= 2: zoom_level_used_cfg = \"Meso/Micro\"\n","             else: # Essai Macro\n","                  zoom_pivots_data_cfg = []\n","                  scale_def = snap_channels_cfg.get(\"macro\", {}); res_p12 = scale_def.get(\"resistance\", ({},{})); sup_p12 = scale_def.get(\"support\", ({},{}))\n","                  for p_info in [res_p12[0], res_p12[1], sup_p12[0], sup_p12[1]]:\n","                      if isinstance(p_info, dict) and not pd.isna(p_info.get('time')) and not pd.isna(p_info.get('price')):\n","                           time_val = pd.to_datetime(p_info['time']).to_pydatetime();\n","                           if getattr(time_val, 'tzinfo', None) is not None: time_val = time_val.replace(tzinfo=None)\n","                           zoom_pivots_data_cfg.append({'time': time_val, 'price': p_info['price']})\n","                  if len(zoom_pivots_data_cfg) >= 2: zoom_level_used_cfg = \"Macro\"\n","         # Calcul ranges si pivots trouvés\n","         if len(zoom_pivots_data_cfg) >= 2:\n","              zoom_pivots_df_cfg = pd.DataFrame(zoom_pivots_data_cfg)\n","              min_p_zoom_cfg = zoom_pivots_df_cfg['price'].min(); max_p_zoom_cfg = zoom_pivots_df_cfg['price'].max()\n","              min_t_zoom_cfg = zoom_pivots_df_cfg['time'].min(); max_t_zoom_cfg = zoom_pivots_df_cfg['time'].max()\n","              height_zoom_cfg = max_p_zoom_cfg - min_p_zoom_cfg; margin_y_cfg = max(height_zoom_cfg * 0.30, (min_p_zoom_cfg + max_p_zoom_cfg)/2 * 0.05)\n","              yaxis_range_subplot_cfg = [min_p_zoom_cfg - margin_y_cfg, max_p_zoom_cfg + margin_y_cfg]\n","              min_t_zoom_ts_cfg = pd.Timestamp(min_t_zoom_cfg, tz=data_tz); max_t_zoom_ts_cfg = pd.Timestamp(max_t_zoom_cfg, tz=data_tz)\n","              duration_zoom_cfg = max_t_zoom_ts_cfg - min_t_zoom_ts_cfg if max_t_zoom_ts_cfg > min_t_zoom_ts_cfg else pd.Timedelta(days=1)\n","              margin_t_before_cfg = max(duration_zoom_cfg * 0.5, pd.Timedelta(days=45)); margin_t_after_cfg = max(duration_zoom_cfg * 0.2, pd.Timedelta(days=20))\n","              xaxis_range_subplot_cfg = [min_t_zoom_ts_cfg - margin_t_before_cfg, max_t_zoom_ts_cfg + margin_t_after_cfg]\n","              xaxis_range_subplot_cfg[1] = min(xaxis_range_subplot_cfg[1], pd.Timestamp(snap_date_cfg_plot + pd.Timedelta(days=5), tz=data_tz))\n","         # Fallback temporel si aucun pivot\n","         if xaxis_range_subplot_cfg is None:\n","              zoom_level_used_cfg = \"Fallback Time\"; lookback_plot_days_cfg = 90\n","              xaxis_range_subplot_cfg = [pd.Timestamp(snap_date_cfg_plot - pd.Timedelta(days=lookback_plot_days_cfg), tz=data_tz), pd.Timestamp(snap_date_cfg_plot + pd.Timedelta(days=5), tz=data_tz)]\n","              bars_subplot_fallback_cfg = bars_df[(bars_df['time'] >= xaxis_range_subplot_cfg[0]) & (bars_df['time'] <= snap_date_cfg_plot)].copy()\n","              if not bars_subplot_fallback_cfg.empty:\n","                   min_p_cfg = bars_subplot_fallback_cfg['low'].min(); max_p_cfg = bars_subplot_fallback_cfg['high'].max(); margin_y_cfg = (max_p_cfg - min_p_cfg) * 0.1 if (max_p_cfg - min_p_cfg) > 1e-6 else max_p_cfg * 0.05\n","                   yaxis_range_subplot_cfg = [min_p_cfg - margin_y_cfg, max_p_cfg + margin_y_cfg]\n","\n","         # Filtrage données & pivots (identique à Cell 30 modifiée)\n","         # ... (coller ici la partie filtrage de la cellule 30 modifiée, avec suffixe _cfg) ...\n","         bars_subplot_cfg = bars_df[(bars_df['time'] >= xaxis_range_subplot_cfg[0]) & (bars_df['time'] <= snap_date_cfg_plot)].copy()\n","         pivots_in_view_df_cfg = pd.DataFrame()\n","         if snap_pivots_list_cfg:\n","             pivots_plot_df_cfg = pd.DataFrame(snap_pivots_list_cfg, columns=['time','price','type']); pivots_plot_df_cfg['time'] = pd.to_datetime(pivots_plot_df_cfg['time'])\n","             pivot_tz_cfg = pivots_plot_df_cfg['time'].dt.tz # Gérer TZ...\n","             if data_tz is not None and pivot_tz_cfg is None:\n","                  try: pivots_plot_df_cfg['time'] = pivots_plot_df_cfg['time'].dt.tz_localize(data_tz, ambiguous='infer', nonexistent='shift_forward')\n","                  except: pass\n","             elif data_tz is None and pivot_tz_cfg is not None: pivots_plot_df_cfg['time'] = pivots_plot_df_cfg['time'].dt.tz_convert(None)\n","             elif data_tz is not None and pivot_tz_cfg is not None and hasattr(data_tz, 'zone') and hasattr(pivot_tz_cfg, 'zone') and data_tz.zone != pivot_tz_cfg.zone: pivots_plot_df_cfg['time'] = pivots_plot_df_cfg['time'].dt.tz_convert(data_tz)\n","             pivots_in_view_df_cfg = pivots_plot_df_cfg[(pivots_plot_df_cfg['time'] >= xaxis_range_subplot_cfg[0]) & (pivots_plot_df_cfg['time'] <= snap_date_cfg_plot)]\n","         if yaxis_range_subplot_cfg is None: # Fallback Y\n","              all_prices_in_view_cfg = pd.concat([bars_subplot_cfg['low'], bars_subplot_cfg['high'], pivots_in_view_df_cfg['price']]).dropna()\n","              if not all_prices_in_view_cfg.empty:\n","                   min_p_cfg = all_prices_in_view_cfg.min(); max_p_cfg = all_prices_in_view_cfg.max(); margin_y_cfg = (max_p_cfg - min_p_cfg) * 0.1 if (max_p_cfg - min_p_cfg) > 1e-6 else max_p_cfg * 0.05\n","                   yaxis_range_subplot_cfg = [min_p_cfg - margin_y_cfg, max_p_cfg + margin_y_cfg]\n","\n","         # Tracer Prix, Pivots, Canaux (identique à Cell 30 modifiée)\n","         # ... (coller ici la partie tracé de la cellule 30 modifiée, avec suffixe _cfg) ...\n","         # Plot Prix\n","         if not bars_subplot_cfg.empty: fig_cfg.add_trace(go.Scatter(x=bars_subplot_cfg['time'], y=bars_subplot_cfg['close'], mode='lines', name='Close', line=dict(color='rgba(150, 150, 150, 0.5)'), showlegend=(i_cfg==0)), row=row_idx_cfg, col=col_idx_cfg)\n","         # Plot Pivots\n","         if not pivots_in_view_df_cfg.empty:\n","              high_x_cfg = pivots_in_view_df_cfg[pivots_in_view_df_cfg['type'] < 0]['time']; high_y_cfg = pivots_in_view_df_cfg[pivots_in_view_df_cfg['type'] < 0]['price']\n","              low_x_cfg  = pivots_in_view_df_cfg[pivots_in_view_df_cfg['type'] > 0]['time']; low_y_cfg  = pivots_in_view_df_cfg[pivots_in_view_df_cfg['type'] > 0]['price']\n","              fig_cfg.add_trace(go.Scatter(x=high_x_cfg, y=high_y_cfg, mode='markers', name='High Pivot', marker=dict(color='red', size=5, symbol='diamond-open'), showlegend=(i_cfg==0)), row=row_idx_cfg, col=col_idx_cfg)\n","              fig_cfg.add_trace(go.Scatter(x=low_x_cfg, y=low_y_cfg, mode='markers', name='Low Pivot', marker=dict(color='green', size=5, symbol='circle-open'), showlegend=(i_cfg==0)), row=row_idx_cfg, col=col_idx_cfg)\n","         # Plot Canaux\n","         if snap_channels_cfg and not bars_subplot_cfg.empty:\n","             plot_start_time_eff_cfg = bars_subplot_cfg['time'].min(); plot_end_time_eff_cfg = snap_date_cfg_plot\n","             plot_start_time_num_eff_cfg = plot_start_time_eff_cfg.timestamp(); plot_end_time_num_eff_cfg = plot_end_time_eff_cfg.timestamp()\n","             for channel_name_cfg in [\"macro\", \"meso\", \"micro\"]: # ... (reste identique) ...\n","                 definition_cfg = snap_channels_cfg.get(channel_name_cfg, {})\n","                 for line_type_cfg in [\"resistance\", \"support\"]:\n","                     p1_info_cfg, p2_info_cfg = definition_cfg.get(line_type_cfg, ({}, {}))\n","                     if (isinstance(p1_info_cfg, dict) and isinstance(p2_info_cfg, dict) and # Check validité\n","                         not pd.isna(p1_info_cfg.get('time')) and not pd.isna(p2_info_cfg.get('time')) and\n","                         not pd.isna(p1_info_cfg.get('time_numeric')) and not pd.isna(p2_info_cfg.get('time_numeric')) and\n","                         not pd.isna(p1_info_cfg.get('price')) and not pd.isna(p2_info_cfg.get('price'))):\n","                         p1_time_num_cfg = p1_info_cfg['time_numeric']; p2_time_num_cfg = p2_info_cfg['time_numeric']; p1_price_cfg = p1_info_cfg['price']; p2_price_cfg = p2_info_cfg['price']; p1_time_cfg = pd.to_datetime(p1_info_cfg['time']); p2_time_cfg = pd.to_datetime(p2_info_cfg['time'])\n","                         try: # ... (m, c, lignes, markers identiques) ...\n","                             m_cfg, c_cfg = get_line_params_time(p1_time_num_cfg, p1_price_cfg, p2_time_num_cfg, p2_price_cfg)\n","                             if m_cfg != np.inf:\n","                                 line_plot_start_time_dt_cfg = max(p1_time_cfg, plot_start_time_eff_cfg); line_plot_start_time_num_cfg = line_plot_start_time_dt_cfg.timestamp(); line_plot_end_time_dt_cfg = plot_end_time_eff_cfg\n","                                 line_start_y_plot_cfg = m_cfg * line_plot_start_time_num_cfg + c_cfg; line_end_y_plot_cfg = m_cfg * plot_end_time_num_eff_cfg + c_cfg\n","                                 fig_cfg.add_trace(go.Scatter(x=[line_plot_start_time_dt_cfg, line_plot_end_time_dt_cfg], y=[line_start_y_plot_cfg, line_end_y_plot_cfg], mode='lines', name=f\"{channel_name_cfg.capitalize()} {line_type_cfg.capitalize()}\", line=dict(color=channel_colors_cfg[channel_name_cfg], width=1.5, dash=channel_styles_cfg[channel_name_cfg]), legendgroup=f\"{channel_name_cfg}_{line_type_cfg}\", showlegend=(i_cfg==0)), row=row_idx_cfg, col=col_idx_cfg)\n","                                 pivots_x_to_mark_cfg = []; pivots_y_to_mark_cfg = []\n","                                 if xaxis_range_subplot_cfg and p1_time_cfg >= xaxis_range_subplot_cfg[0] and p1_time_cfg <= xaxis_range_subplot_cfg[1]: pivots_x_to_mark_cfg.append(p1_time_cfg); pivots_y_to_mark_cfg.append(p1_price_cfg)\n","                                 if xaxis_range_subplot_cfg and p2_time_cfg >= xaxis_range_subplot_cfg[0] and p2_time_cfg <= xaxis_range_subplot_cfg[1]: pivots_x_to_mark_cfg.append(p2_time_cfg); pivots_y_to_mark_cfg.append(p2_price_cfg)\n","                                 if pivots_x_to_mark_cfg: fig_cfg.add_trace(go.Scatter(x=pivots_x_to_mark_cfg, y=pivots_y_to_mark_cfg, mode='markers', marker=dict(color=channel_colors_cfg[channel_name_cfg], size=7, symbol='star' if line_type_cfg == 'resistance' else 'star-open'), showlegend=False, hoverinfo='skip'), row=row_idx_cfg, col=col_idx_cfg)\n","                         except Exception as e_plotline_cfg: pass # print(f\"WARN: Plot line {config_label} {snap_date_cfg_plot.date()}: {e_plotline_cfg}\")\n","\n","\n","         # Appliquer zooms et masquer ticks (identique à Cell 30 modifiée)\n","         if yaxis_range_subplot_cfg: fig_cfg.update_yaxes(range=yaxis_range_subplot_cfg, row=row_idx_cfg, col=col_idx_cfg)\n","         if xaxis_range_subplot_cfg: fig_cfg.update_xaxes(range=xaxis_range_subplot_cfg, row=row_idx_cfg, col=col_idx_cfg)\n","         if row_idx_cfg < rows_cfg: fig_cfg.update_xaxes(showticklabels=False, row=row_idx_cfg, col=col_idx_cfg)\n","         if col_idx_cfg > 1: fig_cfg.update_yaxes(showticklabels=False, row=row_idx_cfg, col=col_idx_cfg)\n","\n","    # Layout Final pour ce graphique\n","    fig_cfg.update_layout(title=f\"Snapshots pour {config_label} (Index {config_idx}) - Zoom Meso/Micro\",\n","                          height=250 * rows_cfg + 80, width=1200, hovermode='x unified',\n","                          legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.08, xanchor=\"center\", x=0.5))\n","    for i_annot_cfg, annot_cfg in enumerate(fig_cfg.layout.annotations):\n","         if i_annot_cfg < n_snapshots_to_plot_cfg: annot_cfg.update(font=dict(size=9))\n","    fig_cfg.show()\n","    # --------------------------------------------------------\n","\n","print(\"\\n--- Visualisation des snapshots pour les configurations sélectionnées terminée ---\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Backtesting (Exemple Simplifié)\n","\n","Après avoir développé et analysé la construction des canaux multi-échelles, cette section présente un exemple **simplifié** de backtesting d'une stratégie de trading qui tente d'exploiter ces canaux.\n","\n","**Avertissement :** L'implémentation actuelle de la stratégie est **rudimentaire** et sert principalement d'illustration. Elle nécessite une refonte significative pour intégrer une logique de décision plus fine (bounce/breakout distincts, types d'ordres, gestion des risques avancée, combinaison des signaux multi-échelles).\n","\n","**Objectif de cette section (version actuelle) :**\n","\n","1.  Définir une configuration de base pour la stratégie (quels canaux utiliser, paramètres de risque simples).\n","2.  Implémenter une boucle de simulation \\\"manuelle\\\" pour tester l'idée générale sur **plusieurs configurations de *construction de canaux***.\n","3.  Comparer les performances (courbes d'équité) résultant de l'utilisation de différentes configurations de canaux dans la même logique de trading simpliste."]},{"cell_type":"markdown","metadata":{},"source":["### 7.1. Configuration de la Simulation\n","\n","Ces cellules définissent les paramètres utilisés dans la boucle de simulation simplifiée.\n","\n","**Paramètres de la Stratégie (`algo_configuration`) :**\n","\n","*   **`channel_params_for_strategy` :** Référence la `final_config` (sera *écrasée* par les configs à tester dans la boucle).\n","*   **`zigzag_threshold_percent_strategy` :** Seuil ZigZag utilisé.\n","*   **`strategy_params` :** Paramètres très basiques contrôlant la logique de trading *actuelle* (ex: `use_meso_signals`, `trade_on_bounce`, offsets). **Nécessite une refonte majeure pour une vraie stratégie.**\n","*   **`algo_general_params` :** Fréquence de recalcul théorique (`recalc_schedule`), période d'historique (`lookback_days_algo`).\n","\n","**Sélection des Configurations à Simuler (`configs_to_simulate`) :**\n","\n","*   **`indices_a_tester` :** Permet de sélectionner spécifiquement quelles configurations de *construction de canaux* (issues de `configurations_to_explore`) seront utilisées pour la simulation comparative.\n","*   **`configs_to_simulate` :** Stocke les dictionnaires de configuration complets.\n","*   **`simulation_results` :** Initialise un dictionnaire pour stocker les résultats (courbe d'équité, trades) de chaque simulation.\n","\n","**Important :** La simulation itère sur `configs_to_simulate`, utilisant chaque configuration pour recalculer les canaux *et* appliquer la *même* logique de trading simpliste (`strategy_params`). Cela compare l'impact de la *construction des canaux* sur le résultat, pas différentes *stratégies de trading*."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 21 : Configuration Stratégie\n","\n","# --- Paramètres de Construction des Canaux ---\n","# Utiliser la configuration finale déterminée précédemment\n","if 'final_config' not in locals(): raise NameError(\"`final_config` non définie.\")\n","channel_params_for_strategy = final_config \n","\n","zigzag_threshold_percent_strategy = 0.05\n","\n","# --- Paramètres de la Logique de Trading ---\n","strategy_params = {\n","    \"use_macro_signals\": False, \n","    \"use_meso_signals\": True,  # Activer Meso\n","    \"use_micro_signals\": True, # Activer Micro\n","\n","    \"trade_on_bounce\": True,\n","    \"trade_on_breakout\": False, \n","\n","    \"bounce_entry_offset_pct\": 0.001, \n","    \"bounce_reversal_bars\": 1, \n","    \"bounce_entry_type\": \"Market\", \n","    \"bounce_stop_offset_pct\": 0.005, \n","    \"bounce_target_type\": \"OppositeChannel\", \n","    \"bounce_target_rr_ratio\": 1.5, \n","    \"bounce_min_channel_width_pct\": 0.01,\n","\n","    \"max_active_trades\": 1, \n","    \"risk_per_trade_pct\": 0.01 \n","}\n","\n","# --- Paramètres Généraux Algo ---\n","algo_general_params = {\n","    \"recalc_schedule\": \"Daily\", \n","    \"lookback_days_algo\": 180 # Lookback pour recalculs stratégie (à ajuster)\n","}\n","\n","# Combiner en une config pour l'algo\n","algo_configuration = {\n","    \"channel_params\": channel_params_for_strategy,\n","    \"zigzag_threshold\": zigzag_threshold_percent_strategy,\n","    \"strategy_params\": strategy_params,\n","    \"general_params\": algo_general_params\n","}\n","\n","print(\"Configuration de l'algorithme de stratégie définie.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 21b : Sélection des Configurations à Simuler\n","\n","# Choisir les index des configurations à tester depuis 'configurations_to_explore'\n","# Exemple : l'originale (6) et une alternative (12)\n","indices_a_tester = [6, 12] # Mettez ici les index des configs que vous voulez comparer\n","\n","if 'configurations_to_explore' not in locals():\n","     raise NameError(\"La liste 'configurations_to_explore' n'est pas définie.\")\n","\n","configs_to_simulate = []\n","labels_simules = []\n","for index in indices_a_tester:\n","     if 0 <= index < len(configurations_to_explore):\n","         config = configurations_to_explore[index]\n","         configs_to_simulate.append(config)\n","         labels_simules.append(config.get('label', f'Config_{index}'))\n","     else:\n","         print(f\"WARN: Index de configuration {index} invalide.\")\n","\n","if not configs_to_simulate:\n","     raise ValueError(\"Aucune configuration valide sélectionnée pour la simulation.\")\n","\n","print(f\"Configurations sélectionnées pour la simulation comparative : {labels_simules}\")\n","\n","# Stockage des résultats de simulation par config\n","simulation_results = {}"]},{"cell_type":"markdown","metadata":{},"source":["### 7.2. Exécution de la Simulation Comparative\n","\n","Cette cellule exécute la boucle de simulation pour chacune des configurations de *construction de canaux* sélectionnées dans `configs_to_simulate`.\n","\n","**Processus pour chaque configuration testée :**\n","\n","1.  **Calcul Historique des Canaux :**\n","    *   Détermine les dates de recalcul (`recalc_frequency`).\n","    *   Pour chaque date, appelle `calculate_channels_for_simulation` (fonction helper interne) qui :\n","        *   Prend l'historique pertinent (`lookback_days_sim`).\n","        *   Calcule les pivots ZigZag.\n","        *   Calcule les canaux Macro/Meso/Micro en utilisant les paramètres `wp`/`rpf` de la *configuration de canaux actuelle*.\n","    *   Stocke l'historique des canaux calculés (`channel_history_df`).\n","2.  **Simulation Barre par Barre :**\n","    *   Itère sur les données horaires de la période de simulation.\n","    *   Pour chaque barre :\n","        *   Récupère les canaux actifs les plus récents.\n","        *   Applique une logique de trading *simplifiée* (basée sur `strategy_params`) : sortie sur canal opposé, entrée sur touche de canal actif (support/résistance).\n","        *   Calcule la taille de position (`risk_per_trade_pct`).\n","        *   Simule les ordres au marché et les frais (`fee_model`).\n","        *   Met à jour position, cash, équité.\n","    *   Enregistre la courbe d'équité et les trades.\n","3.  **Stockage des Résultats :** Stocke courbe d'équité, trades, équité finale et config utilisée dans `simulation_results`.\n","\n","**Note:** Simulation \"manuelle\" sans toutes les fonctionnalités `QCAlgorithm`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# --- AJOUT : Définition de la fonction manquante ---\n","def calculate_channels_for_simulation(current_sim_time, full_history_df, lookback_days, zigzag_threshold, config):\n","    \"\"\"\n","    Calcule les pivots et canaux pour la simulation à un temps donné.\n","    Basé sur calculate_all_channels_at_date mais simplifié pour la simulation.\n","    Retourne un dictionnaire de canaux ou None si échec.\n","    \"\"\"\n","    try:\n","        # 1. Filtrer l'historique basé sur le lookback\n","        start_hist_date = current_sim_time - pd.Timedelta(days=lookback_days)\n","        hist_for_calc = full_history_df[\n","            (full_history_df['time'] >= start_hist_date) &\n","            (full_history_df['time'] <= current_sim_time)\n","        ].copy()\n","\n","        if len(hist_for_calc) < 5: return None # Pas assez de données\n","\n","        # 2. Calculer les pivots ZigZag\n","        sim_pivots_list = classic_chart_zigzag(hist_for_calc[['time','close']], thresholdPercent=zigzag_threshold)\n","        if not sim_pivots_list or len(sim_pivots_list) < 2: return None\n","\n","        sim_pivots_df = pd.DataFrame(sim_pivots_list, columns=['time', 'price', 'type'])\n","        sim_pivots_df['time_numeric'] = sim_pivots_df['time'].apply(lambda x: x.timestamp())\n","        sim_high_pivots = sim_pivots_df[sim_pivots_df['type'] == -1].copy()\n","        sim_low_pivots = sim_pivots_df[sim_pivots_df['type'] == +1].copy()\n","        sim_all_high_np = sim_high_pivots[['time_numeric', 'price']].values\n","        sim_all_low_np = sim_low_pivots[['time_numeric', 'price']].values\n","\n","        if len(sim_high_pivots) < 2 or len(sim_low_pivots) < 2: return None\n","\n","        # Utiliser la fonction get_pivot_info (déjà définie dans la cellule de backtest)\n","        def get_pivot_info_sim(pivot_series):\n","             if pivot_series is None or not isinstance(pivot_series, pd.Series): return {'time': pd.NaT, 'price': np.nan, 'time_numeric': np.nan, 'original_index': -1}\n","             time_numeric_val = pivot_series.get('time_numeric', np.nan)\n","             if pd.isna(time_numeric_val) and not pd.isna(pivot_series.get('time')):\n","                 try:\n","                     dt_obj = pivot_series['time']\n","                     if isinstance(dt_obj, pd.Timestamp): dt_obj = dt_obj.to_pydatetime()\n","                     time_numeric_val = dt_obj.timestamp()\n","                 except Exception as e: time_numeric_val = np.nan\n","             return {'time': pivot_series.get('time', pd.NaT), 'price': pivot_series.get('price', np.nan), 'time_numeric': time_numeric_val, 'original_index': pivot_series.name if hasattr(pivot_series, 'name') else -1}\n","\n","\n","        # 3. Calculer les canaux hiérarchiques (similaire à calculate_all_channels_at_date)\n","        channels_sim = {\"macro\": {}, \"meso\": {}, \"micro\": {}}\n","        for scale in channels_sim: # Init\n","            channels_sim[scale][\"resistance\"] = (None, None)\n","            channels_sim[scale][\"support\"] = (None, None)\n","\n","        # --- Macro ---\n","        macro_success_sim = False\n","        try:\n","            res1_m, res2_m = find_best_channel_line_strict_weighted(sim_high_pivots, sim_all_high_np, True, config['wp_macro_res'], config['rpf_macro_res'])\n","            sup1_m, sup2_m = find_best_channel_line_strict_weighted(sim_low_pivots, sim_all_low_np, False, config['wp_macro_sup'], config['rpf_macro_sup'])\n","            if res1_m is not None and res2_m is not None: channels_sim[\"macro\"][\"resistance\"] = (get_pivot_info_sim(res1_m), get_pivot_info_sim(res2_m))\n","            if sup1_m is not None and sup2_m is not None: channels_sim[\"macro\"][\"support\"] = (get_pivot_info_sim(sup1_m), get_pivot_info_sim(sup2_m))\n","            if channels_sim[\"macro\"][\"resistance\"][0] is not None and channels_sim[\"macro\"][\"support\"][0] is not None: macro_success_sim = True\n","        except Exception as e_macro: pass\n","\n","        # --- Meso (avec Fallback simplifié pour la simulation) ---\n","        meso_success_sim = False\n","        if macro_success_sim:\n","            macro_pivots_info_sim = [channels_sim[\"macro\"][\"resistance\"][0], channels_sim[\"macro\"][\"resistance\"][1], channels_sim[\"macro\"][\"support\"][0], channels_sim[\"macro\"][\"support\"][1]]\n","            valid_macro_pivots_sim = [p for p in macro_pivots_info_sim if p and not pd.isna(p.get('time'))]\n","            valid_macro_pivots_sim.sort(key=lambda p: pd.to_datetime(p['time']), reverse=True)\n","            meso_start_time_sim = None\n","            if len(valid_macro_pivots_sim) >= 2: meso_start_time_sim = pd.to_datetime(valid_macro_pivots_sim[1]['time']) # 2nd plus récent\n","            # Pas de fallback complexe ici pour la simulation, on essaie juste avec cette date\n","\n","            if meso_start_time_sim is not None:\n","                 try:\n","                    meso_high_f_sim = sim_high_pivots[sim_high_pivots['time'] >= meso_start_time_sim].copy()\n","                    meso_low_f_sim = sim_low_pivots[sim_low_pivots['time'] >= meso_start_time_sim].copy()\n","                    if len(meso_high_f_sim) >= 2 and len(meso_low_f_sim) >= 2:\n","                        meso_high_np_sim = meso_high_f_sim[['time_numeric', 'price']].values; meso_low_np_sim = meso_low_f_sim[['time_numeric', 'price']].values\n","                        res1_me, res2_me = find_best_channel_line_strict_weighted(meso_high_f_sim, meso_high_np_sim, True, config['wp_meso_res'], config['rpf_meso_res'])\n","                        sup1_me, sup2_me = find_best_channel_line_strict_weighted(meso_low_f_sim, meso_low_np_sim, False, config['wp_meso_sup'], config['rpf_meso_sup'])\n","                        if res1_me is not None and res2_me is not None: channels_sim[\"meso\"][\"resistance\"] = (get_pivot_info_sim(res1_me), get_pivot_info_sim(res2_me))\n","                        if sup1_me is not None and sup2_me is not None: channels_sim[\"meso\"][\"support\"] = (get_pivot_info_sim(sup1_me), get_pivot_info_sim(sup2_me))\n","                        if channels_sim[\"meso\"][\"resistance\"][0] is not None and channels_sim[\"meso\"][\"support\"][0] is not None: meso_success_sim = True\n","                 except Exception as e_meso: pass\n","\n","        # --- Micro (avec Fallback simplifié pour la simulation) ---\n","        if meso_success_sim:\n","            meso_pivots_info_sim = [channels_sim[\"meso\"][\"resistance\"][0], channels_sim[\"meso\"][\"resistance\"][1], channels_sim[\"meso\"][\"support\"][0], channels_sim[\"meso\"][\"support\"][1]]\n","            valid_meso_pivots_sim = [p for p in meso_pivots_info_sim if p and not pd.isna(p.get('time'))]\n","            valid_meso_pivots_sim.sort(key=lambda p: pd.to_datetime(p['time']), reverse=True)\n","            micro_start_time_sim = None\n","            if len(valid_meso_pivots_sim) >= 2: micro_start_time_sim = pd.to_datetime(valid_meso_pivots_sim[1]['time']) # 2nd plus récent\n","\n","            if micro_start_time_sim is not None:\n","                try:\n","                    micro_high_f_sim = sim_high_pivots[sim_high_pivots['time'] >= micro_start_time_sim].copy()\n","                    micro_low_f_sim = sim_low_pivots[sim_low_pivots['time'] >= micro_start_time_sim].copy()\n","                    if len(micro_high_f_sim) >= 2 and len(micro_low_f_sim) >= 2:\n","                        micro_high_np_sim = micro_high_f_sim[['time_numeric', 'price']].values; micro_low_np_sim = micro_low_f_sim[['time_numeric', 'price']].values\n","                        res1_mi, res2_mi = find_best_channel_line_strict_weighted(micro_high_f_sim, micro_high_np_sim, True, config['wp_micro_res'], config['rpf_micro_res'])\n","                        sup1_mi, sup2_mi = find_best_channel_line_strict_weighted(micro_low_f_sim, micro_low_np_sim, False, config['wp_micro_sup'], config['rpf_micro_sup'])\n","                        if res1_mi is not None and res2_mi is not None: channels_sim[\"micro\"][\"resistance\"] = (get_pivot_info_sim(res1_mi), get_pivot_info_sim(res2_mi))\n","                        if sup1_mi is not None and sup2_mi is not None: channels_sim[\"micro\"][\"support\"] = (get_pivot_info_sim(sup1_mi), get_pivot_info_sim(sup2_mi))\n","                except Exception as e_micro: pass\n","\n","        return channels_sim # Retourner le dictionnaire des canaux calculés\n","\n","    except Exception as e_main:\n","        # print(f\"Erreur majeure dans calculate_channels_for_simulation pour {current_sim_time}: {e_main}\")\n","        # traceback.print_exc() # Décommenter pour le debug\n","        return None\n","# --- FIN AJOUT ---"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 31 & 32 combinée : Boucle de Simulation pour Plusieurs Configurations\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import traceback\n","import matplotlib.pyplot as plt\n","from AlgorithmImports import MarketOrder, OrderFeeParameters, ConstantFeeModel # Assurer imports pour frais\n","\n","# --- Vérifications Préalables ---\n","if 'bars_df' not in locals(): raise NameError(\"DataFrame 'bars_df' non trouvé.\")\n","if 'configs_to_simulate' not in locals() or not configs_to_simulate: raise NameError(\"Aucune configuration à simuler sélectionnée.\")\n","if 'algo_configuration' not in locals(): raise NameError(\"algo_configuration non définie.\")\n","if 'classic_chart_zigzag' not in locals(): raise NameError(\"Fonction 'classic_chart_zigzag' non trouvée.\")\n","if 'find_best_channel_line_strict_weighted' not in locals(): raise NameError(\"Fonction 'find_best_channel_line_strict_weighted' non trouvée.\")\n","if 'get_line_params_time' not in locals(): raise NameError(\"Fonction 'get_line_params_time' non trouvée.\")\n","if 'get_pivot_info' not in locals(): # Utiliser la version de Cell 15\n","     def get_pivot_info(pivot):\n","         if pivot is None or not isinstance(pivot, pd.Series): return {'time': pd.NaT, 'price': np.nan, 'idx': -1, 'time_numeric': np.nan}\n","         idx_val = pivot.name if hasattr(pivot, 'name') else -1\n","         time_numeric_val = pivot.get('time_numeric', np.nan)\n","         if pd.isna(time_numeric_val) and not pd.isna(pivot.get('time')):\n","            try:\n","                dt_obj = pivot['time'];\n","                if isinstance(dt_obj, pd.Timestamp): dt_obj = dt_obj.to_pydatetime()\n","                time_numeric_val = dt_obj.timestamp()\n","            except: time_numeric_val = np.nan\n","         return {'time': pivot.get('time', pd.NaT),'price': pivot.get('price', np.nan),'idx': idx_val,'time_numeric': time_numeric_val}\n","\n","# --- Récupérer Paramètres Communs ---\n","sim_start_date = pd.Timestamp(\"2024-01-01\", tz=bars_df['time'].dt.tz) # Utiliser tz de bars_df\n","sim_end_date = bars_df['time'].iloc[-1]\n","initial_cash = 10000\n","recalc_frequency = pd.Timedelta(days=1)\n","strategy_params_sim = algo_configuration['strategy_params'] # Règles de trading fixes\n","data_tz = bars_df['time'].dt.tz\n","\n","# Récupérer le modèle de frais une seule fois\n","try:\n","    brokerage_model = qb.BrokerageModel\n","    fee_model = brokerage_model.GetFeeModel(qb.Securities[btc_symbol])\n","    print(f\"Utilisation du modèle de frais: {fee_model.__class__.__name__}\")\n","except Exception as e:\n","    print(f\"WARN: Impossible de récupérer le modèle de frais: {e}. Simulation sans frais.\")\n","    fee_model = ConstantFeeModel(0)\n","\n","# --- Boucle Principale sur les Configurations ---\n","simulation_results = {} # Stocker {label: {equity_curve: Series, trades: DataFrame, final_equity: float}}\n","\n","for config_to_test in tqdm(configs_to_simulate, desc=\"Simulating Configs\"):\n","    config_label = config_to_test.get('label', 'Unknown_Config')\n","    print(f\"\\n--- Simulation pour Configuration: {config_label} ---\")\n","\n","    # Récupérer params spécifiques à CETTE config\n","    channel_params_sim = config_to_test # La config contient les params de canaux\n","    lookback_days_sim = algo_configuration['general_params'].get(\"lookback_days_algo\", 180)\n","    zigzag_thresh_sim = algo_configuration['zigzag_threshold']\n","\n","    # Étape 1: Calcul des canaux pour CETTE config \n","    print(f\"  Étape 1/2 : Calcul des canaux historiques...\")\n","    channel_history = {}\n","    # Utiliser l'historique complet pour le calcul des canaux glissants\n","    hist_calc_start_date = sim_start_date - pd.Timedelta(days=lookback_days_sim)\n","    sim_bars_df_full = bars_df[(bars_df['time'] >= hist_calc_start_date) & (bars_df['time'] <= sim_end_date)].copy()\n","\n","    if sim_bars_df_full.empty or sim_bars_df_full[sim_bars_df_full['time'] >= sim_start_date].empty:\n","         print(f\"  ERREUR: Pas assez de données pour config {config_label}. Skip.\")\n","         simulation_results[config_label] = {'equity_curve': pd.Series(dtype=float), 'trades': pd.DataFrame(), 'final_equity': initial_cash, 'config': config_to_test}\n","         continue\n","\n","    first_recalc_date = sim_bars_df_full[sim_bars_df_full['time'] >= sim_start_date]['time'].min().normalize()\n","    recalc_dates = pd.date_range(start=first_recalc_date, end=sim_end_date, freq=recalc_frequency, tz=data_tz)\n","    last_calculated_channels = None\n","\n","    for recalc_date in tqdm(recalc_dates, desc=f\" Channels {config_label[:15]}...\", leave=False, mininterval=1.0): # mininterval pour réduire output\n","        actual_recalc_time = min(recalc_date.normalize() + pd.Timedelta(days=1) - pd.Timedelta(seconds=1), sim_bars_df_full['time'].max())\n","        actual_recalc_time = sim_bars_df_full[sim_bars_df_full['time'] <= actual_recalc_time]['time'].max()\n","        if pd.isna(actual_recalc_time) or actual_recalc_time in channel_history: continue\n","\n","        channels = calculate_channels_for_simulation(actual_recalc_time, sim_bars_df_full, lookback_days_sim, zigzag_thresh_sim, channel_params_sim)\n","\n","        if channels is not None:\n","            channel_history[actual_recalc_time] = channels\n","            last_calculated_channels = channels\n","        elif last_calculated_channels is not None:\n","            channel_history[actual_recalc_time] = last_calculated_channels\n","\n","    # print(f\"  Calculé {len(channel_history)} jeux de canaux pour {config_label}.\")\n","    if not channel_history:\n","         print(f\"  ERREUR: Aucun historique de canal pour {config_label}. Skip.\")\n","         simulation_results[config_label] = {'equity_curve': pd.Series(dtype=float), 'trades': pd.DataFrame(), 'final_equity': initial_cash, 'config': config_to_test}\n","         continue\n","\n","    channel_history_df = pd.DataFrame.from_dict(channel_history, orient='index')\n","    channel_history_df.index = pd.to_datetime(channel_history_df.index)\n","    channel_history_df = channel_history_df.sort_index()\n","\n","    # Étape 2: Simulation de la stratégie pour CETTE config \n","    print(f\"  Étape 2/2 : Simulation de la stratégie barre par barre...\")\n","    sim_cash = initial_cash; sim_position = 0.0; sim_entry_price = 0.0; sim_equity = initial_cash\n","    equity_curve_list = [{'time': sim_start_date - pd.Timedelta(hours=1), 'equity': initial_cash}] # Point initial\n","    sim_trades = []\n","    last_trade_scale = None; last_known_channels_sim = None\n","\n","    # Itérer seulement sur les barres de la période de simulation réelle\n","    loop_bars = sim_bars_df_full[sim_bars_df_full['time'] >= sim_start_date].copy()\n","\n","    for index, row in tqdm(loop_bars.iterrows(), total=len(loop_bars), desc=f\" Trading {config_label[:15]}...\", leave=False, mininterval=1.0):\n","        current_time = row['time']\n","        current_price = row['close']\n","        current_time_num = current_time.timestamp()\n","\n","        # Trouver les canaux valides\n","        valid_channel_time_index = channel_history_df.index[channel_history_df.index <= current_time]\n","        current_active_channels = None\n","        if not valid_channel_time_index.empty:\n","            valid_channel_time = valid_channel_time_index.max()\n","            try:\n","                current_active_channels_row = channel_history_df.loc[valid_channel_time]\n","                current_active_channels = current_active_channels_row.to_dict()\n","                last_known_channels_sim = current_active_channels\n","            except KeyError:\n","                current_active_channels = last_known_channels_sim\n","        else: # Avant le premier calcul\n","             current_active_channels = last_known_channels_sim\n","\n","        if current_active_channels is None:\n","             sim_equity = sim_cash + sim_position * current_price # Mettre à jour l'équité même sans canaux\n","             equity_curve_list.append({'time': current_time, 'equity': sim_equity})\n","             continue\n","\n","        # --- Logique de Trading ---\n","        trade_executed_this_bar = False\n","        # _Logique de Sortie_\n","        if sim_position != 0 and last_trade_scale is not None:\n","            res_p12 = current_active_channels.get(last_trade_scale, {}).get(\"resistance\")\n","            sup_p12 = current_active_channels.get(last_trade_scale, {}).get(\"support\")\n","            if res_p12 and sup_p12 and isinstance(res_p12[0], dict) and isinstance(sup_p12[0], dict) and res_p12[0].get('time_numeric') and sup_p12[0].get('time_numeric'):\n","                 try:\n","                    m_res, c_res = get_line_params_time(res_p12[0]['time_numeric'], res_p12[0]['price'], res_p12[1]['time_numeric'], res_p12[1]['price'])\n","                    m_sup, c_sup = get_line_params_time(sup_p12[0]['time_numeric'], sup_p12[0]['price'], sup_p12[1]['time_numeric'], sup_p12[1]['price'])\n","                    if m_res != np.inf and m_sup != np.inf:\n","                        current_res_val = m_res * current_time_num + c_res\n","                        current_sup_val = m_sup * current_time_num + c_sup\n","                        exit_signal = False; exit_reason = \"\"\n","                        if sim_position > 0 and current_price >= current_res_val: exit_signal = True; exit_reason = f\"hit res {last_trade_scale}\"\n","                        elif sim_position < 0 and current_price <= current_sup_val: exit_signal = True; exit_reason = f\"hit sup {last_trade_scale}\"\n","                        # Ajouter SL ici si besoin\n","                        if exit_signal:\n","                            exit_order = MarketOrder(btc_symbol, -sim_position, current_time)\n","                            exit_fee = fee_model.GetOrderFee(OrderFeeParameters(qb.Securities[btc_symbol], exit_order)).Value.Amount\n","                            pnl = sim_position * (current_price - sim_entry_price)\n","                            sim_cash += sim_position * current_price\n","                            sim_cash -= exit_fee\n","                            #print(f\"{current_time}: EXIT {'LONG' if sim_position > 0 else 'SHORT'} ({exit_reason}) @ {current_price:.2f}. PnL: {pnl:.2f}, Fee: {exit_fee:.4f}\")\n","                            sim_trades.append({'time': current_time, 'type': 'exit_long' if sim_position > 0 else 'exit_short','price': current_price, 'size': -sim_position, 'scale': last_trade_scale, 'pnl': pnl, 'fee': exit_fee})\n","                            sim_position = 0.0; sim_entry_price = 0.0; last_trade_scale = None; trade_executed_this_bar = True\n","                 except KeyError: pass\n","                 except Exception as exit_e: print(f\"Error exit {config_label} @ {current_time}: {exit_e}\")\n","\n","        # _Logique d'Entrée_\n","        if not trade_executed_this_bar and sim_position == 0:\n","            for scale in [\"micro\", \"meso\", \"macro\"]:\n","                 if not strategy_params_sim.get(f\"use_{scale}_signals\", False): continue\n","                 res_p12 = current_active_channels.get(scale, {}).get(\"resistance\")\n","                 sup_p12 = current_active_channels.get(scale, {}).get(\"support\")\n","                 if res_p12 and sup_p12 and isinstance(res_p12[0], dict) and isinstance(sup_p12[0], dict) and res_p12[0].get('time_numeric') and sup_p12[0].get('time_numeric'):\n","                      try:\n","                         m_res, c_res = get_line_params_time(res_p12[0]['time_numeric'], res_p12[0]['price'], res_p12[1]['time_numeric'], res_p12[1]['price'])\n","                         m_sup, c_sup = get_line_params_time(sup_p12[0]['time_numeric'], sup_p12[0]['price'], sup_p12[1]['time_numeric'], sup_p12[1]['price'])\n","                         if m_res == np.inf or m_sup == np.inf: continue\n","                         current_res_val = m_res * current_time_num + c_res\n","                         current_sup_val = m_sup * current_time_num + c_sup\n","                         channel_width = current_res_val - current_sup_val\n","                         min_width_pct = strategy_params_sim.get(\"bounce_min_channel_width_pct\", 0.01)\n","                         if channel_width < current_price * min_width_pct: continue\n","                         if strategy_params_sim.get(\"trade_on_bounce\"):\n","                             offset_pct = strategy_params_sim.get(\"bounce_entry_offset_pct\", 0.001)\n","                             risk_per_trade_pct = strategy_params_sim.get(\"risk_per_trade_pct\", 0.01)\n","                             entry_signal = 0\n","                             if current_price <= current_sup_val * (1 + offset_pct): entry_signal = 1\n","                             elif current_price >= current_res_val * (1 - offset_pct): entry_signal = -1\n","                             if entry_signal != 0:\n","                                 available_capital = sim_equity # Utiliser l'équité actuelle pour le sizing\n","                                 qty_to_trade = (available_capital * risk_per_trade_pct) / current_price if current_price > 0 else 0\n","                                 min_order_qty = 0.00001\n","                                 if abs(qty_to_trade) < min_order_qty: continue # Skip si trop petit\n","\n","                                 entry_order = MarketOrder(btc_symbol, entry_signal * qty_to_trade, current_time)\n","                                 entry_fee = fee_model.GetOrderFee(OrderFeeParameters(qb.Securities[btc_symbol], entry_order)).Value.Amount\n","                                 sim_position = entry_signal * qty_to_trade\n","                                 sim_cash -= sim_position * current_price\n","                                 sim_cash -= entry_fee\n","                                 sim_entry_price = current_price\n","                                 last_trade_scale = scale\n","                                 #print(f\"{current_time}: {'BUY' if entry_signal > 0 else 'SELL'} on {scale} {'support' if entry_signal > 0 else 'resistance'} bounce @ {current_price:.2f}. Qty: {sim_position:.6f}, Fee: {entry_fee:.4f}\")\n","                                 sim_trades.append({'time': current_time, 'type': 'buy' if entry_signal > 0 else 'sell','price': current_price, 'size': sim_position, 'scale': scale, 'fee': entry_fee})\n","                                 trade_executed_this_bar = True\n","                                 break\n","                      except KeyError: pass\n","                      except Exception as entry_e: print(f\"Error entry {config_label} @ {current_time}: {entry_e}\")\n","\n","        # Mettre à jour la valeur du portefeuille\n","        sim_equity = sim_cash + sim_position * current_price\n","        equity_curve_list.append({'time': current_time, 'equity': sim_equity})\n","\n","    # --- Stocker Résultats pour cette config ---\n","    sim_equity_curve = pd.DataFrame(equity_curve_list).set_index('time')['equity']\n","    sim_trades_df = pd.DataFrame(sim_trades)\n","    final_equity = sim_equity_curve.iloc[-1] if not sim_equity_curve.empty else initial_cash\n","    simulation_results[config_label] = {\n","        'equity_curve': sim_equity_curve,\n","        'trades': sim_trades_df,\n","        'final_equity': final_equity,\n","        'config': config_to_test\n","    }\n","    print(f\"  Simulation {config_label} terminée. Valeur finale: {final_equity:,.2f} USDT\")\n","\n","# --- Fin de la Boucle sur les Configurations ---\n","print(\"\\n--- Toutes les simulations sont terminées ---\")"]},{"cell_type":"markdown","metadata":{},"source":["### 7.3. Analyse Comparative des Résultats de Simulation\n","\n","Cette cellule analyse et visualise les résultats stockés dans `simulation_results`.\n","\n","**Actions :**\n","\n","1.  **Tableau Récapitulatif :** Affiche pour chaque configuration testée :\n","    *   Équité finale.\n","    *   Nombre total de trades.\n","    *   Profit & Loss total approximatif.\n","2.  **Graphique Comparatif :** Trace les courbes d'équité de toutes les simulations sur un seul graphique `matplotlib`, avec la configuration et l'équité finale dans la légende.\n","\n","Permet de comparer visuellement quelle configuration de *construction de canaux* a potentiellement mené à de meilleurs résultats avec la logique de trading *simpliste* utilisée."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 33 : Analyse Comparative des Simulations\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","print(\"\\n--- Résultats Comparatifs des Simulations ---\")\n","\n","if 'simulation_results' not in locals() or not simulation_results:\n","    print(\"Aucun résultat de simulation à afficher.\")\n","else:\n","    # Afficher un résumé\n","    summary = []\n","    for label, result in simulation_results.items():\n","        trade_df = result['trades']\n","        nb_trades = len(trade_df)\n","        # Calcul PnL total (simpliste, sans frais)\n","        total_pnl = trade_df[trade_df['type'].str.contains('exit')]['pnl'].sum() if 'pnl' in trade_df.columns else 'N/A'\n","\n","        summary.append({\n","            'Configuration': label,\n","            'Final Equity (USDT)': f\"{result['final_equity']:,.2f}\",\n","            'Nb Trades': nb_trades,\n","            'Total PnL (approx)': f\"{total_pnl:,.2f}\" if isinstance(total_pnl, (int, float)) else total_pnl\n","        })\n","    summary_df = pd.DataFrame(summary)\n","    print(summary_df.to_string(index=False))\n","\n","    # Tracer les courbes d'équité\n","    fig, ax = plt.subplots(figsize=(14, 8))\n","    for label, result in simulation_results.items():\n","        if not result['equity_curve'].empty:\n","             result['equity_curve'].plot(ax=ax, label=f\"{label} ({result['final_equity']:,.0f})\") # Ajouter valeur finale à la légende\n","\n","    ax.set_title('Comparaison des Courbes d\\'Équité Simulées (par Configuration)')\n","    ax.set_ylabel('Valeur Portefeuille Simulé (USDT)')\n","    ax.set_xlabel('Date')\n","    ax.legend(fontsize=9)\n","    ax.grid(True)\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Définition des Stratégies à Tester\n","\n","import pandas as pd\n","import numpy as np\n","\n","print(\"Définition des différentes stratégies (chromosomes)...\")\n","\n","# --- Modèles d'Action Réutilisables (Simplifiés pour commencer) ---\n","# Note : Pour cette première version, on simplifie SL/TP.\n","# Une implémentation complète nécessiterait de gérer les ordres SL/TP côté backtester.\n","action_bounce_long_market = {\n","    \"action_type\": \"bounce_long\",\n","    \"order_type\": \"market\", # Exécuté si conditions remplies à la clôture\n","    \"stop_loss_pct_below_entry\": 0.01, # SL = 1% sous le prix d'entrée\n","    \"target_rr_ratio\": 1.5 # TP = 1.5 * Risque (distance au SL)\n","}\n","action_bounce_short_market = {\n","    \"action_type\": \"bounce_short\",\n","    \"order_type\": \"market\",\n","    \"stop_loss_pct_above_entry\": 0.01, # SL = 1% au-dessus du prix d'entrée\n","    \"target_rr_ratio\": 1.5\n","}\n","action_breakout_long_market = {\n","    \"action_type\": \"breakout_long\",\n","    \"order_type\": \"market\", # Exécuté si clôture confirme le breakout\n","    \"stop_loss_pct_below_level\": 0.005, # SL = 0.5% sous le niveau cassé (résistance devient support)\n","    \"target_rr_ratio\": 2.0\n","}\n","action_breakout_short_market = {\n","    \"action_type\": \"breakout_short\",\n","    \"order_type\": \"market\",\n","    \"stop_loss_pct_above_level\": 0.005, # SL = 0.5% au-dessus du niveau cassé (support devient résistance)\n","    \"target_rr_ratio\": 2.0\n","}\n","\n","# --- Liste des Stratégies à Tester ---\n","strategies_to_test = []\n","\n","# Stratégie 1: Bounce Simple sur Meso (sans conditions complexes)\n","strategies_to_test.append({\n","    \"name\": \"Meso_Bounce_Simple\",\n","    \"general_params\": {\n","        \"max_concurrent_trades\": 1,\n","        \"risk_per_trade_pct_equity\": 0.01,\n","        \"min_channel_width_pct_for_bounce\": 0.01,\n","    },\n","    \"rules\": [\n","        # Règles de sortie (gérées implicitement par SL/TP dans cette version simplifiée)\n","        # Règles d'entrée\n","        {\n","            \"conditions\": {\n","                \"in_position\": \"none\",\n","                \"price_near_level\": {\"level\": \"meso_support\", \"threshold_pct\": 0.002}, # Prix proche du support Meso\n","                 \"channel_width_ok\": {\"level\": \"meso\", \"min_pct\": 0.01}\n","            },\n","            \"action\": action_bounce_long_market\n","        },\n","        {\n","            \"conditions\": {\n","                \"in_position\": \"none\",\n","                \"price_near_level\": {\"level\": \"meso_resistance\", \"threshold_pct\": 0.002}, # Prix proche de la résistance Meso\n","                 \"channel_width_ok\": {\"level\": \"meso\", \"min_pct\": 0.01}\n","            },\n","            \"action\": action_bounce_short_market\n","        },\n","         # Règle par défaut\n","        { \"conditions\": {}, \"action\": \"do_nothing\" } # S'applique si rien d'autre ne correspond\n","    ]\n","})\n","\n","# Stratégie 2: Breakout Simple sur Micro\n","strategies_to_test.append({\n","    \"name\": \"Micro_Breakout_Simple\",\n","    \"general_params\": {\n","        \"max_concurrent_trades\": 1,\n","        \"risk_per_trade_pct_equity\": 0.015, # Risque un peu plus élevé\n","    },\n","    \"rules\": [\n","        # Règles de sortie (gérées implicitement par SL/TP)\n","        # Règles d'entrée\n","        {\n","            \"conditions\": {\n","                \"in_position\": \"none\",\n","                \"price_closes_above\": {\"level\": \"micro_resistance\"} # Clôture au-dessus\n","            },\n","            \"action\": action_breakout_long_market\n","        },\n","        {\n","            \"conditions\": {\n","                \"in_position\": \"none\",\n","                \"price_closes_below\": {\"level\": \"micro_support\"} # Clôture en dessous\n","            },\n","            \"action\": action_breakout_short_market\n","        },\n","         # Règle par défaut\n","        { \"conditions\": {}, \"action\": \"do_nothing\" }\n","    ]\n","})\n","\n","# Stratégie 3: Mixte - Bounce Micro si Tendance Meso, Breakout Meso sinon\n","strategies_to_test.append({\n","    \"name\": \"Mix_MicroBounce_MesoBreakout\",\n","    \"general_params\": {\n","        \"max_concurrent_trades\": 1,\n","        \"risk_per_trade_pct_equity\": 0.01,\n","        \"min_channel_width_pct_for_bounce\": 0.005,\n","    },\n","    \"rules\": [\n","        # Règles de sortie (gérées implicitement par SL/TP)\n","        # Règles d'entrée Bounce Micro (conditionnel)\n","        {\n","            \"conditions\": {\n","                \"in_position\": \"none\",\n","                \"price_near_level\": {\"level\": \"micro_support\", \"threshold_pct\": 0.0015},\n","                \"channel_trend\": {\"level\": \"meso\", \"direction\": \"up\"}, # Tendance Meso haussière (pente > 0)\n","                \"channel_width_ok\": {\"level\": \"micro\", \"min_pct\": 0.005}\n","            },\n","            \"action\": action_bounce_long_market\n","        },\n","        {\n","            \"conditions\": {\n","                \"in_position\": \"none\",\n","                \"price_near_level\": {\"level\": \"micro_resistance\", \"threshold_pct\": 0.0015},\n","                 \"channel_trend\": {\"level\": \"meso\", \"direction\": \"down\"}, # Tendance Meso baissière (pente < 0)\n","                \"channel_width_ok\": {\"level\": \"micro\", \"min_pct\": 0.005}\n","            },\n","            \"action\": action_bounce_short_market\n","        },\n","        # Règles d'entrée Breakout Meso (si pas de bounce micro)\n","        {\n","            \"conditions\": {\n","                \"in_position\": \"none\",\n","                \"price_closes_above\": {\"level\": \"meso_resistance\"}\n","            },\n","            \"action\": action_breakout_long_market\n","        },\n","        {\n","            \"conditions\": {\n","                \"in_position\": \"none\",\n","                \"price_closes_below\": {\"level\": \"meso_support\"}\n","            },\n","            \"action\": action_breakout_short_market\n","        },\n","         # Règle par défaut\n","        { \"conditions\": {}, \"action\": \"do_nothing\" }\n","    ]\n","})\n","\n","\n","print(f\"Nombre de stratégies définies : {len(strategies_to_test)}\")\n","# Initialisation du stockage des résultats par stratégie\n","strategy_simulation_results = {}\n","\n","# Récupérer la configuration de canaux à utiliser (celle sélectionnée avant)\n","if 'final_config' not in locals():\n","    raise NameError(\"La configuration de canaux 'final_config' n'a pas été définie ou sélectionnée.\")\n","fixed_channel_config = final_config\n","print(f\"Utilisation de la configuration de canaux fixe : '{fixed_channel_config.get('label', 'N/A')}'\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE HELPER (Mise à jour pour inclure channel_trend)\n","\n","import pandas as pd\n","import numpy as np\n","\n","print(\"Définition/Mise à jour des fonctions helper pour la simulation...\")\n","\n","# --- Fonction pour obtenir la valeur d'un canal à un temps donné ---\n","# (Aucun changement requis par rapport à la version précédente)\n","def get_channel_value_at_time(channel_info, time_numeric):\n","    if not channel_info or not isinstance(channel_info[0], dict) or not isinstance(channel_info[1], dict): return np.nan\n","    p1, p2 = channel_info[0], channel_info[1]\n","    if pd.isna(p1.get('time_numeric')) or pd.isna(p1.get('price')) or pd.isna(p2.get('time_numeric')) or pd.isna(p2.get('price')): return np.nan\n","    try:\n","        if 'get_line_params_time' not in globals(): raise NameError(\"get_line_params_time non trouvée\")\n","        m, c = get_line_params_time(p1['time_numeric'], p1['price'], p2['time_numeric'], p2['price'])\n","        return m * time_numeric + c if m != np.inf else np.nan\n","    except Exception as e: return np.nan\n","\n","\n","# --- Fonction pour vérifier les conditions d'une règle (MAJ pour channel_trend) ---\n","def check_conditions(conditions_dict, current_state):\n","    if not conditions_dict: return True\n","    price = current_state.get('price'); time_numeric = current_state.get('time_numeric')\n","    position_status = current_state.get('position_status'); active_channels = current_state.get('active_channels')\n","    if price is None or time_numeric is None or position_status is None or active_channels is None: return False\n","\n","    for condition_key, condition_value in conditions_dict.items():\n","        if condition_key == \"in_position\":\n","            if position_status != condition_value: return False\n","        elif condition_key == \"price_near_level\":\n","            level_name = condition_value.get(\"level\"); threshold = condition_value.get(\"threshold_pct\", 0.001)\n","            scale, line_type = level_name.split('_'); channel_info = active_channels.get(scale, {}).get(line_type)\n","            level_value = get_channel_value_at_time(channel_info, time_numeric)\n","            if pd.isna(level_value): return False\n","            if not (level_value * (1 - threshold) <= price <= level_value * (1 + threshold)): return False\n","        elif condition_key == \"price_closes_above\":\n","            level_name = condition_value.get(\"level\"); scale, line_type = level_name.split('_')\n","            channel_info = active_channels.get(scale, {}).get(line_type)\n","            level_value = get_channel_value_at_time(channel_info, time_numeric)\n","            if pd.isna(level_value): return False\n","            if not (price > level_value): return False\n","        elif condition_key == \"price_closes_below\":\n","            level_name = condition_value.get(\"level\"); scale, line_type = level_name.split('_')\n","            channel_info = active_channels.get(scale, {}).get(line_type)\n","            level_value = get_channel_value_at_time(channel_info, time_numeric)\n","            if pd.isna(level_value): return False\n","            if not (price < level_value): return False\n","        elif condition_key == \"channel_width_ok\":\n","            scale = condition_value.get(\"level\"); min_pct = condition_value.get(\"min_pct\", 0.01)\n","            res_info = active_channels.get(scale, {}).get(\"resistance\"); sup_info = active_channels.get(scale, {}).get(\"support\")\n","            res_value = get_channel_value_at_time(res_info, time_numeric); sup_value = get_channel_value_at_time(sup_info, time_numeric)\n","            if pd.isna(res_value) or pd.isna(sup_value) or res_value <= sup_value: return False\n","            if (res_value - sup_value) < (price * min_pct): return False\n","\n","        # --- NOUVELLE CONDITION ---\n","        elif condition_key == \"channel_trend\":\n","            level = condition_value.get(\"level\") # ex: \"meso\"\n","            required_direction = condition_value.get(\"direction\") # \"up\" or \"down\"\n","            res_info = active_channels.get(level, {}).get(\"resistance\")\n","            sup_info = active_channels.get(level, {}).get(\"support\")\n","            # Vérifier si les infos des pivots sont valides\n","            valid_res = res_info and isinstance(res_info[0], dict) and not pd.isna(res_info[0].get('time_numeric'))\n","            valid_sup = sup_info and isinstance(sup_info[0], dict) and not pd.isna(sup_info[0].get('time_numeric'))\n","            if not valid_res or not valid_sup: return False # Impossible de déterminer la tendance\n","            try:\n","                 if 'get_line_params_time' not in globals(): raise NameError(\"get_line_params_time non trouvée\")\n","                 m_res, _ = get_line_params_time(res_info[0]['time_numeric'], res_info[0]['price'], res_info[1]['time_numeric'], res_info[1]['price'])\n","                 m_sup, _ = get_line_params_time(sup_info[0]['time_numeric'], sup_info[0]['price'], sup_info[1]['time_numeric'], sup_info[1]['price'])\n","                 # Définir la tendance : haussière si les deux pentes >= 0 (avec tolérance), baissière si les deux <= 0\n","                 # Peut être affiné (ex: moyenne des pentes, une seule pente suffit ?)\n","                 tolerance = 1e-9 # Proche de zéro\n","                 is_up = (m_res >= -tolerance and m_sup >= -tolerance) and not (m_res < tolerance and m_sup < tolerance) # Au moins une pas négative, pas les deux négatives\n","                 is_down = (m_res <= tolerance and m_sup <= tolerance) and not (m_res > -tolerance and m_sup > -tolerance) # Au moins une pas positive, pas les deux positives\n","\n","                 if required_direction == \"up\" and not is_up: return False\n","                 if required_direction == \"down\" and not is_down: return False\n","            except Exception as e:\n","                 # print(f\"WARN: Erreur calcul pente tendance pour {level}: {e}\")\n","                 return False # Échec évaluation tendance\n","\n","        # else: # Gérer conditions inconnues si nécessaire\n","             # return False\n","\n","    return True # Toutes les conditions sont passées\n","\n","# --- Autres fonctions helper ---\n","# (Aucun changement requis pour calculate_position_size et apply_fees)\n","def calculate_position_size(equity, risk_per_trade_pct, price, stop_loss_price):\n","    if price <= 0 or equity <= 0: return 0.0\n","    capital_at_risk = equity * risk_per_trade_pct\n","    risk_per_unit = abs(price - stop_loss_price)\n","    if risk_per_unit <= 1e-9: return 0.0\n","    quantity = capital_at_risk / risk_per_unit\n","    min_order_qty = 0.00001 # Exemple\n","    return max(min_order_qty, quantity)\n","\n","def apply_fees(order, symbol_security, fee_model):\n","     try:\n","         fee = fee_model.GetOrderFee(OrderFeeParameters(symbol_security, order)).Value.Amount\n","         return fee\n","     except Exception as e: return 0.0\n","\n","print(\"Fonctions helper (avec check_conditions mis à jour) définies.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE PRINCIPALE : Simulation des Stratégies sur Canaux Fixes (Révisée)\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import traceback\n","import matplotlib.pyplot as plt\n","from AlgorithmImports import MarketOrder, OrderFeeParameters, ConstantFeeModel\n","\n","# --- Vérifications Préalables ---\n","if 'bars_df' not in locals(): raise NameError(\"DataFrame 'bars_df' non trouvé.\")\n","if 'strategies_to_test' not in locals() or not strategies_to_test: raise NameError(\"Aucune stratégie à tester définie.\")\n","if 'fixed_channel_config' not in locals(): raise NameError(\"Configuration de canaux 'fixed_channel_config' non définie.\")\n","if 'calculate_channels_for_simulation' not in locals(): raise NameError(\"Fonction 'calculate_channels_for_simulation' non définie.\")\n","if 'check_conditions' not in locals(): raise NameError(\"Fonction 'check_conditions' non définie.\")\n","if 'get_channel_value_at_time' not in locals(): raise NameError(\"Fonction 'get_channel_value_at_time' non définie.\")\n","if 'calculate_position_size' not in locals(): raise NameError(\"Fonction 'calculate_position_size' non définie.\")\n","if 'apply_fees' not in locals(): raise NameError(\"Fonction 'apply_fees' non définie.\")\n","\n","# --- Paramètres Communs & Calcul des Canaux (UNE SEULE FOIS) ---\n","print(\"\\n--- Préparation de la Simulation ---\")\n","sim_start_date = pd.Timestamp(\"2024-01-01\", tz=bars_df['time'].dt.tz) # Ajuster date début si besoin\n","sim_end_date = bars_df['time'].iloc[-1]\n","initial_cash = 10000\n","lookback_days_sim = 180 # Lookback pour le calcul des canaux\n","zigzag_thresh_sim = 0.05 # Seuil ZigZag pour calcul canaux\n","recalc_frequency = pd.Timedelta(days=1) # Fréquence recalcul canaux\n","data_tz = bars_df['time'].dt.tz\n","\n","# Récupérer le modèle de frais\n","try:\n","    symbol_security = qb.Securities[btc_symbol]\n","    brokerage_model = qb.BrokerageModel\n","    fee_model = brokerage_model.GetFeeModel(symbol_security)\n","    print(f\"Utilisation du modèle de frais: {fee_model.__class__.__name__}\")\n","except Exception as e:\n","    print(f\"WARN: Impossible de récupérer le modèle de frais de QC: {e}. Simulation sans frais.\")\n","    fee_model = ConstantFeeModel(0)\n","    # Créer un objet Security minimaliste si qb n'est pas entièrement fonctionnel hors QC\n","    class MinimalSecurity: pass\n","    symbol_security = MinimalSecurity()\n","\n","\n","print(f\"Calcul unique de l'historique des canaux en utilisant '{fixed_channel_config.get('label', 'N/A')}'...\")\n","channel_history = {}\n","hist_calc_start_date = sim_start_date - pd.Timedelta(days=lookback_days_sim)\n","sim_bars_df_full = bars_df[(bars_df['time'] >= hist_calc_start_date) & (bars_df['time'] <= sim_end_date)].copy()\n","\n","if sim_bars_df_full.empty or sim_bars_df_full[sim_bars_df_full['time'] >= sim_start_date].empty:\n","     raise ValueError(\"Pas assez de données historiques pour la période de simulation et le lookback.\")\n","\n","first_recalc_date = sim_bars_df_full[sim_bars_df_full['time'] >= sim_start_date]['time'].min().normalize()\n","recalc_dates = pd.date_range(start=first_recalc_date, end=sim_end_date, freq=recalc_frequency, tz=data_tz)\n","last_calculated_channels = None\n","\n","for recalc_date in tqdm(recalc_dates, desc=\"Calcul Historique Canaux\", leave=False):\n","    # Trouver la dernière barre disponible <= date de recalcul prévue\n","    actual_recalc_time = min(recalc_date.normalize() + pd.Timedelta(days=1) - pd.Timedelta(seconds=1), sim_bars_df_full['time'].max())\n","    actual_recalc_time = sim_bars_df_full[sim_bars_df_full['time'] <= actual_recalc_time]['time'].max() # Heure exacte de la dernière barre\n","    if pd.isna(actual_recalc_time) or actual_recalc_time in channel_history: continue # Déjà calculé\n","\n","    # Appel à la fonction de calcul (utilise fixed_channel_config)\n","    channels = calculate_channels_for_simulation(actual_recalc_time, sim_bars_df_full, lookback_days_sim, zigzag_thresh_sim, fixed_channel_config)\n","\n","    if channels is not None:\n","        channel_history[actual_recalc_time] = channels\n","        last_calculated_channels = channels\n","    elif last_calculated_channels is not None: # Si calcul échoue, réutiliser les derniers valides\n","        channel_history[actual_recalc_time] = last_calculated_channels\n","    # else: # Si aucun canal n'a jamais été calculé (très tôt dans l'historique)\n","        # print(f\"WARN: Impossible de calculer les canaux à {actual_recalc_time}, et aucun canal précédent disponible.\")\n","\n","if not channel_history:\n","     raise ValueError(\"Échec du calcul de l'historique des canaux. Impossible de lancer les simulations.\")\n","\n","channel_history_df = pd.DataFrame.from_dict(channel_history, orient='index')\n","channel_history_df.index = pd.to_datetime(channel_history_df.index)\n","channel_history_df = channel_history_df.sort_index()\n","print(f\"Historique des canaux calculé ({len(channel_history_df)} entrées).\")\n","\n","# --- Boucle Principale sur les STRATÉGIES ---\n","strategy_simulation_results = {} # Réinitialiser les résultats\n","\n","# for strategy_config in tqdm(strategies_to_test, desc=\"Simulating Strategies\"):\n","#     strategy_name = strategy_config.get('name', 'Unnamed_Strategy')\n","#     print(f\"\\n--- Simulation pour Stratégie: {strategy_name} ---\")\n","\n","#     # Récupérer les paramètres généraux de CETTE stratégie\n","#     strat_params = strategy_config.get('general_params', {})\n","#     risk_per_trade_pct = strat_params.get('risk_per_trade_pct_equity', 0.01)\n","#     max_trades = strat_params.get('max_concurrent_trades', 1) # Géré simplement (0 ou 1 trade)\n","\n","#     # Initialisation de l'état pour CETTE simulation\n","#     sim_cash = initial_cash\n","#     sim_position_qty = 0.0 # Quantité détenue\n","#     sim_entry_price = 0.0\n","#     sim_equity = initial_cash\n","#     active_stop_loss = None\n","#     active_take_profit = None\n","#     equity_curve_list = [{'time': sim_start_date - pd.Timedelta(hours=1), 'equity': initial_cash}] # Point initial\n","#     sim_trades = []\n","\n","#     # Filtrer les barres pour la période de simulation\n","#     loop_bars = sim_bars_df_full[sim_bars_df_full['time'] >= sim_start_date].copy()\n","#     if loop_bars.empty:\n","#          print(f\"WARN: Aucune barre à simuler pour la stratégie {strategy_name}. Skip.\")\n","#          strategy_simulation_results[strategy_name] = {'equity_curve': pd.Series(dtype=float), 'trades': pd.DataFrame(), 'final_equity': initial_cash}\n","#          continue\n","\n","#     # --- Boucle Barre par Barre ---\n","#     for index, row in tqdm(loop_bars.iterrows(), total=len(loop_bars), desc=f\" Trading {strategy_name[:15]}...\", leave=False, mininterval=1.0):\n","#         current_time = row['time']\n","#         current_price = row['close'] # Utiliser close pour la logique (simplifié)\n","#         current_high = row['high']\n","#         current_low = row['low']\n","#         current_time_num = current_time.timestamp()\n","\n","#         # Trouver les canaux actifs pour ce pas de temps\n","#         valid_channel_time_index = channel_history_df.index[channel_history_df.index <= current_time]\n","#         current_active_channels = None\n","#         if not valid_channel_time_index.empty:\n","#             valid_channel_time = valid_channel_time_index.max()\n","#             try:\n","#                 # Récupérer le dict de canaux (macro, meso, micro) à partir du DF précalculé\n","#                 current_active_channels = channel_history_df.loc[valid_channel_time].to_dict()\n","#             except Exception as e: # Si erreur (ex: ligne vide?), utiliser le dernier connu\n","#                  current_active_channels = last_known_channels_sim # Nécessite de garder le dernier connu en mémoire\n","#                  # print(f\"Debug: Error getting channels at {valid_channel_time}, using last known. Err: {e}\")\n","\n","#         if current_active_channels is None: # Si aucun canal n'est dispo (très tôt ou erreur persistante)\n","#              sim_equity = sim_cash + sim_position_qty * current_price\n","#              equity_curve_list.append({'time': current_time, 'equity': sim_equity})\n","#              continue\n","#         last_known_channels_sim = current_active_channels # Mémoriser pour le cas d'erreur ci-dessus\n","\n","#         # --- Gestion des Sorties (SL/TP) ---\n","#         exit_executed = False\n","#         if sim_position_qty != 0:\n","#             pnl = 0.0\n","#             exit_reason = \"\"\n","#             close_position_now = False\n","\n","#             # Check Stop Loss\n","#             if active_stop_loss is not None:\n","#                 if sim_position_qty > 0 and current_low <= active_stop_loss: # SL pour long touché\n","#                     close_position_now = True\n","#                     exit_reason = \"Stop Loss\"\n","#                     exit_price = active_stop_loss # Supposer exécution au niveau du SL (simplifié)\n","#                 elif sim_position_qty < 0 and current_high >= active_stop_loss: # SL pour short touché\n","#                     close_position_now = True\n","#                     exit_reason = \"Stop Loss\"\n","#                     exit_price = active_stop_loss # Supposer exécution au niveau du SL\n","\n","#             # Check Take Profit (si pas déjà stoppé)\n","#             if not close_position_now and active_take_profit is not None:\n","#                  if sim_position_qty > 0 and current_high >= active_take_profit: # TP pour long touché\n","#                     close_position_now = True\n","#                     exit_reason = \"Take Profit\"\n","#                     exit_price = active_take_profit # Supposer exécution au niveau du TP\n","#                  elif sim_position_qty < 0 and current_low <= active_take_profit: # TP pour short touché\n","#                     close_position_now = True\n","#                     exit_reason = \"Take Profit\"\n","#                     exit_price = active_take_profit # Supposer exécution au niveau du TP\n","\n","#             # Exécuter la sortie si nécessaire\n","#             if close_position_now:\n","#                 exit_order = MarketOrder(btc_symbol, -sim_position_qty, current_time) # Ordre pour fermer\n","#                 exit_fee = apply_fees(exit_order, symbol_security, fee_model)\n","#                 pnl = sim_position_qty * (exit_price - sim_entry_price) # Calcul PnL brut\n","#                 sim_cash += sim_position_qty * exit_price # Ajouter valeur de la position fermée\n","#                 sim_cash -= exit_fee # Déduire frais de sortie\n","#                 # print(f\"{current_time}: EXIT {'LONG' if sim_position_qty > 0 else 'SHORT'} ({exit_reason}) @ {exit_price:.2f}. PnL: {pnl-exit_fee:.2f}\") # PnL net\n","#                 sim_trades.append({'time': current_time,\n","#                                    'type': f'exit_{\"long\" if sim_position_qty > 0 else \"short\"}',\n","#                                    'price': exit_price, 'size': -sim_position_qty,\n","#                                    'pnl': pnl - exit_fee, # Enregistrer PnL net\n","#                                    'fee': exit_fee, 'reason': exit_reason})\n","#                 sim_position_qty = 0.0\n","#                 sim_entry_price = 0.0\n","#                 active_stop_loss = None\n","#                 active_take_profit = None\n","#                 exit_executed = True\n","\n","\n","#         # --- Gestion des Entrées (si pas en position et pas de sortie juste exécutée) ---\n","#         if sim_position_qty == 0 and not exit_executed:\n","#             # Préparer l'état actuel pour l'évaluation des règles\n","#             current_state = {\n","#                 'price': current_price,\n","#                 'time_numeric': current_time_num,\n","#                 'position_status': 'none',\n","#                 'active_channels': current_active_channels\n","#             }\n","\n","#             # Itérer sur les règles de la stratégie actuelle\n","#             for rule in strategy_config.get('rules', []):\n","#                 conditions = rule.get('conditions', {})\n","#                 action_template = rule.get('action')\n","\n","#                 if isinstance(action_template, str) and action_template == \"do_nothing\": # Cas spécial\n","#                      action_details = {\"action_type\": \"do_nothing\"}\n","#                 elif isinstance(action_template, dict):\n","#                     action_details = action_template # Utiliser le template défini\n","#                 else: continue # Ignorer règle mal formée\n","\n","#                 # Vérifier si les conditions de la règle sont remplies\n","#                 if check_conditions(conditions, current_state):\n","#                     action_type = action_details.get(\"action_type\")\n","\n","#                     # Si une action d'entrée est déclenchée\n","#                     if action_type in [\"bounce_long\", \"breakout_long\", \"bounce_short\", \"breakout_short\"]:\n","#                         entry_price = current_price # Pour ordre Market\n","#                         signal = 1 if \"long\" in action_type else -1\n","\n","#                         # --- Calculer SL et TP (Simplifié) ---\n","#                         sl_price = None\n","#                         tp_price = None\n","#                         risk_amount_per_unit = None\n","\n","#                         if signal == 1: # Long\n","#                              sl_pct_entry = action_details.get(\"stop_loss_pct_below_entry\")\n","#                              sl_pct_level = action_details.get(\"stop_loss_pct_below_level\")\n","#                              target_rr = action_details.get(\"target_rr_ratio\")\n","\n","#                              if sl_pct_entry is not None:\n","#                                  sl_price = entry_price * (1 - sl_pct_entry)\n","#                              elif sl_pct_level is not None:\n","#                                  # Trouver le niveau pertinent (ex: resistance pour breakout long)\n","#                                  level_name = \"micro_resistance\" # Default ou à extraire des conditions\n","#                                  if \"breakout_long\" in action_type:\n","#                                      # Trouver le niveau cassé à partir des conditions (suppose qu'il existe)\n","#                                      trigger_condition = conditions.get(\"price_closes_above\", conditions.get(\"price_crosses_above\"))\n","#                                      if trigger_condition: level_name = trigger_condition.get(\"level\")\n","#                                  scale, line_type = level_name.split('_')\n","#                                  channel_info = current_active_channels.get(scale, {}).get(line_type)\n","#                                  level_val = get_channel_value_at_time(channel_info, current_time_num)\n","#                                  if not pd.isna(level_val):\n","#                                      sl_price = level_val * (1 - sl_pct_level)\n","#                                  else: sl_price = entry_price * (1 - 0.01) # Fallback SL%\n","\n","#                              # Calculer TP basé sur RR si SL défini\n","#                              if sl_price is not None and target_rr is not None:\n","#                                   risk_amount_per_unit = entry_price - sl_price\n","#                                   if risk_amount_per_unit > 0:\n","#                                        tp_price = entry_price + risk_amount_per_unit * target_rr\n","\n","#                         else: # Short\n","#                             sl_pct_entry = action_details.get(\"stop_loss_pct_above_entry\")\n","#                             sl_pct_level = action_details.get(\"stop_loss_pct_above_level\")\n","#                             target_rr = action_details.get(\"target_rr_ratio\")\n","\n","#                             if sl_pct_entry is not None:\n","#                                 sl_price = entry_price * (1 + sl_pct_entry)\n","#                             elif sl_pct_level is not None:\n","#                                 level_name = \"micro_support\" # Default ou à extraire\n","#                                 if \"breakout_short\" in action_type:\n","#                                      trigger_condition = conditions.get(\"price_closes_below\", conditions.get(\"price_crosses_below\"))\n","#                                      if trigger_condition: level_name = trigger_condition.get(\"level\")\n","#                                 scale, line_type = level_name.split('_')\n","#                                 channel_info = current_active_channels.get(scale, {}).get(line_type)\n","#                                 level_val = get_channel_value_at_time(channel_info, current_time_num)\n","#                                 if not pd.isna(level_val):\n","#                                      sl_price = level_val * (1 + sl_pct_level)\n","#                                 else: sl_price = entry_price * (1 + 0.01) # Fallback SL%\n","\n","#                             if sl_price is not None and target_rr is not None:\n","#                                   risk_amount_per_unit = sl_price - entry_price\n","#                                   if risk_amount_per_unit > 0:\n","#                                        tp_price = entry_price - risk_amount_per_unit * target_rr\n","\n","\n","#                         # --- Exécuter l'Entrée si SL valide ---\n","#                         if sl_price is not None and risk_amount_per_unit > 0:\n","#                             # Calculer la taille\n","#                             sim_equity_before_trade = sim_cash # Equity = cash quand pas en position\n","#                             qty_to_trade = calculate_position_size(sim_equity_before_trade, risk_per_trade_pct, entry_price, sl_price)\n","\n","#                             if qty_to_trade > 0:\n","#                                 entry_order = MarketOrder(btc_symbol, signal * qty_to_trade, current_time)\n","#                                 entry_fee = apply_fees(entry_order, symbol_security, fee_model)\n","\n","#                                 sim_position_qty = signal * qty_to_trade\n","#                                 sim_entry_price = entry_price\n","#                                 sim_cash -= sim_position_qty * sim_entry_price # Coût de l'entrée\n","#                                 sim_cash -= entry_fee\n","#                                 active_stop_loss = sl_price\n","#                                 active_take_profit = tp_price # Peut être None si pas de RR défini\n","#                                 # print(f\"{current_time}: ENTRY {'LONG' if signal > 0 else 'SHORT'} ({action_type}) @ {entry_price:.2f}. Qty: {sim_position_qty:.6f}, SL: {sl_price:.2f}, TP: {tp_price if tp_price else 'N/A'}\")\n","#                                 sim_trades.append({'time': current_time,\n","#                                                    'type': 'buy' if signal > 0 else 'sell',\n","#                                                    'price': entry_price, 'size': sim_position_qty,\n","#                                                    'fee': entry_fee, 'sl': active_stop_loss, 'tp': active_take_profit,\n","#                                                    'reason': action_type})\n","#                                 break # Sortir de la boucle des règles, une action a été prise\n","\n","#                     # Gérer 'do_nothing' ou autre action qui n'est pas une entrée\n","#                     elif action_type == \"do_nothing\":\n","#                         break # Sortir de la boucle des règles\n","#                     # Ajouter d'autres types d'actions ici si nécessaire\n","\n","#             # --- Fin de la boucle des règles ---\n","\n","#         # Mettre à jour la valeur du portefeuille à la fin de la barre\n","#         sim_equity = sim_cash + sim_position_qty * current_price\n","#         equity_curve_list.append({'time': current_time, 'equity': sim_equity})\n","\n","#     # --- Fin de la Boucle Barre par Barre ---\n","\n","#     # Stocker les résultats pour cette stratégie\n","#     sim_equity_curve = pd.DataFrame(equity_curve_list).set_index('time')['equity']\n","#     sim_trades_df = pd.DataFrame(sim_trades)\n","#     final_equity = sim_equity_curve.iloc[-1] if not sim_equity_curve.empty else initial_cash\n","#     strategy_simulation_results[strategy_name] = {\n","#         'equity_curve': sim_equity_curve,\n","#         'trades': sim_trades_df,\n","#         'final_equity': final_equity,\n","#         'config': strategy_config # Stocker la config de la stratégie elle-même\n","#     }\n","#     print(f\"  Simulation Stratégie {strategy_name} terminée. Valeur finale: {final_equity:,.2f} USDT\")\n","\n","# # --- Fin de la Boucle sur les Stratégies ---\n","# print(\"\\n--- Toutes les simulations de stratégies sont terminées ---\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # CELLULE D'ANALYSE : Analyse Comparative des Simulations par Stratégie\n","\n","# import matplotlib.pyplot as plt\n","# import pandas as pd\n","\n","# print(\"\\n--- Résultats Comparatifs des Simulations par Stratégie ---\")\n","\n","# if 'strategy_simulation_results' not in locals() or not strategy_simulation_results:\n","#     print(\"Aucun résultat de simulation de stratégie à afficher.\")\n","# else:\n","#     # Afficher un résumé\n","#     summary = []\n","#     for strategy_name, result in strategy_simulation_results.items():\n","#         trade_df = result.get('trades', pd.DataFrame())\n","#         nb_trades = len(trade_df[trade_df['type'].isin(['buy', 'sell'])]) # Compter entrées seulement\n","#         total_pnl = trade_df['pnl'].sum() if 'pnl' in trade_df.columns and not trade_df['pnl'].empty else 0.0\n","#         total_fees = trade_df['fee'].sum() if 'fee' in trade_df.columns and not trade_df['fee'].empty else 0.0\n","#         # Calculer le taux de réussite (win rate)\n","#         winning_trades = trade_df[trade_df['pnl'] > 0]['pnl'].count() if 'pnl' in trade_df.columns else 0\n","#         losing_trades = trade_df[trade_df['pnl'] <= 0]['pnl'].count() if 'pnl' in trade_df.columns else 0\n","#         total_closed_trades = winning_trades + losing_trades\n","#         win_rate = (winning_trades / total_closed_trades * 100) if total_closed_trades > 0 else 0.0\n","\n","#         summary.append({\n","#             'Stratégie': strategy_name,\n","#             'Final Equity (USDT)': f\"{result.get('final_equity', initial_cash):,.2f}\",\n","#             'Nb Trades (Entrées)': nb_trades,\n","#             'Total PnL Net (USDT)': f\"{total_pnl:,.2f}\", # PnL est déjà net dans le df\n","#             'Total Fees (USDT)': f\"{total_fees:,.2f}\",\n","#             'Win Rate (%)': f\"{win_rate:.1f}\"\n","#         })\n","\n","#     if summary:\n","#         summary_df = pd.DataFrame(summary)\n","#         print(summary_df.to_string(index=False))\n","#     else:\n","#         print(\"Aucune donnée sommaire à afficher.\")\n","\n","#     # Tracer les courbes d'équité\n","#     fig, ax = plt.subplots(figsize=(14, 8))\n","#     found_curves = False\n","#     for strategy_name, result in strategy_simulation_results.items():\n","#         equity_curve = result.get('equity_curve')\n","#         if equity_curve is not None and not equity_curve.empty:\n","#              final_val = equity_curve.iloc[-1]\n","#              equity_curve.plot(ax=ax, label=f\"{strategy_name} ({final_val:,.0f})\")\n","#              found_curves = True\n","\n","#     if found_curves:\n","#         ax.set_title('Comparaison des Courbes d\\'Équité (par Stratégie)')\n","#         ax.set_ylabel('Valeur Portefeuille Simulé (USDT)')\n","#         ax.set_xlabel('Date')\n","#         ax.legend(fontsize=9, loc='upper left')\n","#         ax.grid(True)\n","#         plt.tight_layout()\n","#         plt.show()\n","#     else:\n","#         print(\"\\nAucune courbe d'équité à tracer.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 1 (RÉVISÉE) : Espace Paramétrique pour la Génération de Stratégies\n","\n","import itertools\n","\n","print(\"Définition de l'espace paramétrique révisé des stratégies...\")\n","\n","# --- Options pour chaque paramètre de la stratégie ---\n","\n","param_space = {\n","    # Quels niveaux utiliser pour les signaux principaux?\n","    'trade_level': ['micro', 'meso'], # Garder les deux options\n","\n","    # Quels types de signaux utiliser sur ce niveau?\n","    'signal_type': ['bounce', 'breakout', 'both'], # Essayer les trois types\n","\n","    # Faut-il un filtre de tendance basé sur un niveau supérieur?\n","    'trend_filter_level': ['none', 'meso', 'macro'], # Essentiel pour tester l'idée de la stratégie mixte\n","\n","    # Paramètres généraux\n","    'risk_per_trade_pct': [0.0075, 0.01, 0.015, 0.02], # Plus de granularité autour de 1-1.5%\n","    'min_channel_width_pct': [0.004, 0.008, 0.012, 0.016], # Plus d'options pour la largeur minimale\n","\n","    # Paramètres spécifiques aux Actions (Bounce)\n","    'bounce_sl_type': ['pct_entry', 'pct_level'], # Garder les deux types de SL\n","    'bounce_sl_value': [0.005, 0.01, 0.015, 0.02], # Élargir et ajouter des étapes\n","    'bounce_tp_type': ['rr_ratio'], # Garder RR ratio pour TP\n","    'bounce_tp_value': [1.5, 2.0, 2.5, 3.0], # Ajouter des ratios R:R plus élevés\n","    'bounce_entry_offset': [0.001, 0.002, 0.003], # Plus d'options pour la proximité\n","\n","    # Paramètres spécifiques aux Actions (Breakout)\n","    'breakout_sl_type': ['pct_level'], # SL basé sur le niveau cassé est courant\n","    'breakout_sl_value': [0.005, 0.01, 0.015, 0.02], # Élargir (idem bounce pour simplicité)\n","    'breakout_tp_type': ['rr_ratio'],\n","    'breakout_tp_value': [1.5, 2.0, 2.5, 3.0], # Élargir (idem bounce)\n","}\n","\n","# Générer toutes les combinaisons possibles (produit cartésien)\n","param_keys = list(param_space.keys())\n","param_values = list(param_space.values())\n","\n","all_combinations = list(itertools.product(*param_values))\n","\n","print(f\"Nombre total de combinaisons brutes générées avec l'espace révisé : {len(all_combinations)}\")\n","# Ce nombre sera beaucoup plus grand !\n","\n","# --- Stockage pour les stratégies générées ---\n","generated_strategies = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE NOUVELLE : Fonction pour Créer une Stratégie (Chromosome) depuis les Paramètres\n","\n","print(\"Définition de la fonction de création de stratégie...\")\n","\n","def create_strategy_from_params(param_combination, param_keys):\n","    \"\"\"\n","    Crée un dictionnaire de stratégie (chromosome) à partir d'une combinaison de paramètres.\n","    \"\"\"\n","    params = dict(zip(param_keys, param_combination))\n","    strategy_name = f\"L{params['trade_level']}_S{params['signal_type']}_TF{params['trend_filter_level']}\" \\\n","                    f\"_R{params['risk_per_trade_pct']*100:.0f}_SLB{params['bounce_sl_value']*1000:.0f}\" \\\n","                    f\"_SLK{params['breakout_sl_value']*1000:.0f}_TP{params['bounce_tp_value']}\"\n","\n","    rules = []\n","\n","    # --- Actions Modèles (basées sur les params actuels) ---\n","    current_bounce_long = {\n","        \"action_type\": \"bounce_long\", \"order_type\": \"market\",\n","        f\"stop_loss_{params['bounce_sl_type'].replace('_', '_pct_')}\" : params['bounce_sl_value'],\n","        \"target_rr_ratio\": params['bounce_tp_value']\n","    }\n","    current_bounce_short = {\n","        \"action_type\": \"bounce_short\", \"order_type\": \"market\",\n","         f\"stop_loss_{params['bounce_sl_type'].replace('pct_entry', 'pct_above_entry').replace('pct_level', 'pct_above_level')}\" : params['bounce_sl_value'],\n","        \"target_rr_ratio\": params['bounce_tp_value']\n","    }\n","    current_breakout_long = {\n","        \"action_type\": \"breakout_long\", \"order_type\": \"market\",\n","        f\"stop_loss_{params['breakout_sl_type'].replace('_', '_pct_')}\" : params['breakout_sl_value'],\n","        \"target_rr_ratio\": params['breakout_tp_value']\n","    }\n","    current_breakout_short = {\n","        \"action_type\": \"breakout_short\", \"order_type\": \"market\",\n","        f\"stop_loss_{params['breakout_sl_type'].replace('pct_level', 'pct_above_level')}\" : params['breakout_sl_value'],\n","        \"target_rr_ratio\": params['breakout_tp_value']\n","    }\n","\n","    # --- Génération des Règles ---\n","    trade_level = params['trade_level']\n","    min_width = params['min_channel_width_pct']\n","    bounce_offset = params['bounce_entry_offset']\n","    trend_filter = params['trend_filter_level']\n","\n","    # Conditions communes pour le filtre de tendance\n","    trend_cond_long = {}\n","    trend_cond_short = {}\n","    if trend_filter != 'none':\n","        trend_cond_long = {\"channel_trend\": {\"level\": trend_filter, \"direction\": \"up\"}}\n","        trend_cond_short = {\"channel_trend\": {\"level\": trend_filter, \"direction\": \"down\"}}\n","\n","    # Ajouter règles BOUNCE si signal_type est 'bounce' or 'both'\n","    if params['signal_type'] in ['bounce', 'both']:\n","        # Bounce Long Rule\n","        conditions_bl = {\n","            \"in_position\": \"none\",\n","            \"price_near_level\": {\"level\": f\"{trade_level}_support\", \"threshold_pct\": bounce_offset},\n","            \"channel_width_ok\": {\"level\": trade_level, \"min_pct\": min_width},\n","            **trend_cond_long # Ajoute le filtre de tendance s'il est défini\n","        }\n","        rules.append({\"conditions\": conditions_bl, \"action\": current_bounce_long})\n","\n","        # Bounce Short Rule\n","        conditions_bs = {\n","            \"in_position\": \"none\",\n","            \"price_near_level\": {\"level\": f\"{trade_level}_resistance\", \"threshold_pct\": bounce_offset},\n","            \"channel_width_ok\": {\"level\": trade_level, \"min_pct\": min_width},\n","             **trend_cond_short\n","        }\n","        rules.append({\"conditions\": conditions_bs, \"action\": current_bounce_short})\n","\n","    # Ajouter règles BREAKOUT si signal_type est 'breakout' or 'both'\n","    if params['signal_type'] in ['breakout', 'both']:\n","         # Breakout Long Rule\n","        conditions_kl = {\n","            \"in_position\": \"none\",\n","            \"price_closes_above\": {\"level\": f\"{trade_level}_resistance\"},\n","             # \"channel_width_ok\": {\"level\": trade_level, \"min_pct\": min_width}, # Largeur peut être moins pertinente pour breakout pur\n","             **trend_cond_long # Filtre optionnel\n","        }\n","        rules.append({\"conditions\": conditions_kl, \"action\": current_breakout_long})\n","\n","         # Breakout Short Rule\n","        conditions_ks = {\n","            \"in_position\": \"none\",\n","            \"price_closes_below\": {\"level\": f\"{trade_level}_support\"},\n","             # \"channel_width_ok\": {\"level\": trade_level, \"min_pct\": min_width},\n","             **trend_cond_short # Filtre optionnel\n","        }\n","        rules.append({\"conditions\": conditions_ks, \"action\": current_breakout_short})\n","\n","    # Règle par défaut\n","    rules.append({ \"conditions\": {}, \"action\": \"do_nothing\" })\n","\n","    # Assembler le chromosome final\n","    strategy_chromosome = {\n","        \"name\": strategy_name,\n","        \"parameters\": params, # Garder une trace des paramètres utilisés\n","        \"general_params\": {\n","            \"max_concurrent_trades\": 1,\n","            \"risk_per_trade_pct_equity\": params['risk_per_trade_pct'],\n","            \"min_channel_width_pct_for_bounce\": min_width if params['signal_type'] in ['bounce', 'both'] else 999, # Inactif si pas de bounce\n","        },\n","        \"rules\": rules\n","    }\n","    return strategy_chromosome\n","\n","print(\"Fonction de création de stratégie définie.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE 3 (MODIFIÉE) : Génération et Filtrage/Échantillonnage des Stratégies\n","\n","import random # Importer random pour l'échantillonnage\n","\n","print(\"Génération, filtrage et échantillonnage des stratégies à tester...\")\n","\n","strategies_to_test_filtered = [] # Stocker toutes les stratégies valides\n","filtered_count = 0\n","\n","for combo in tqdm(all_combinations, desc=\"Filtrage Combinaisons\"): # Ajouter tqdm ici\n","    params_dict = dict(zip(param_keys, combo))\n","\n","    # --- Règles de Filtrage ---\n","    if params_dict['trend_filter_level'] == params_dict['trade_level'] and params_dict['trend_filter_level'] != 'none':\n","        filtered_count += 1\n","        continue\n","\n","    # Ajouter d'autres filtres si besoin...\n","\n","    # Si la combinaison passe les filtres, créer la stratégie\n","    strategy = create_strategy_from_params(combo, param_keys)\n","    strategies_to_test_filtered.append(strategy)\n","\n","print(f\"Nombre total de combinaisons brutes : {len(all_combinations)}\")\n","print(f\"Nombre de combinaisons filtrées : {filtered_count}\")\n","print(f\"Nombre de stratégies valides générées : {len(strategies_to_test_filtered)}\")\n","\n","# --- Échantillonnage ---\n","max_strategies_to_simulate = 500 # <--- Augmenter cette valeur (ex: 500, 1000)\n","\n","if not strategies_to_test_filtered:\n","    print(\"WARN: Aucune stratégie valide après filtrage. Impossible de simuler.\")\n","    strategies_to_test = [] # Assurer que la liste est vide pour éviter erreur aval\n","elif len(strategies_to_test_filtered) <= max_strategies_to_simulate:\n","    print(f\"Simulation de toutes les {len(strategies_to_test_filtered)} stratégies valides.\")\n","    strategies_to_test = strategies_to_test_filtered # Prendre toutes les valides si moins que la limite\n","else:\n","    print(f\"Échantillonnage aléatoire de {max_strategies_to_simulate} stratégies parmi les {len(strategies_to_test_filtered)} valides.\")\n","    strategies_to_test = random.sample(strategies_to_test_filtered, max_strategies_to_simulate)\n","\n","# Afficher quelques noms de stratégies échantillonnées\n","if strategies_to_test:\n","    print(\"\\nExemples de noms de stratégies échantillonnées pour la simulation :\")\n","    for i in range(min(5, len(strategies_to_test))):\n","         print(f\" - {strategies_to_test[i]['name']}\")\n","else:\n","    print(\"\\nWARN: Aucune stratégie sélectionnée pour la simulation.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # CELLULE PRINCIPALE : Simulation des Stratégies Générées (CORRIGÉE pour NameError)\n","\n","# import pandas as pd\n","# import numpy as np\n","# from tqdm.notebook import tqdm\n","# import traceback\n","# import matplotlib.pyplot as plt\n","# from AlgorithmImports import MarketOrder, OrderFeeParameters, ConstantFeeModel\n","\n","# # --- Vérifications Préalables ---\n","# if 'bars_df' not in locals(): raise NameError(\"DataFrame 'bars_df' non trouvé.\")\n","# if 'strategies_to_test' not in locals(): raise NameError(\"Liste 'strategies_to_test' non générée.\")\n","# if 'fixed_channel_config' not in locals(): raise NameError(\"Configuration de canaux 'fixed_channel_config' non définie.\")\n","# if 'channel_history_df' not in locals() or channel_history_df.empty: raise NameError(\"Historique des canaux ('channel_history_df') non calculé ou vide.\")\n","# if 'check_conditions' not in locals(): raise NameError(\"Fonction 'check_conditions' non définie.\")\n","# if 'calculate_position_size' not in locals(): raise NameError(\"Fonction 'calculate_position_size' non définie.\")\n","# if 'apply_fees' not in locals(): raise NameError(\"Fonction 'apply_fees' non définie.\")\n","# if 'get_channel_value_at_time' not in locals(): raise NameError(\"Fonction 'get_channel_value_at_time' non définie.\") # Ajout vérification\n","\n","\n","# # --- Paramètres Communs & Récupération Modèle Frais ---\n","# print(\"\\n--- Préparation de la Simulation des Stratégies Générées ---\")\n","# sim_start_date = pd.Timestamp(\"2024-01-01\", tz=bars_df['time'].dt.tz) # Assurez-vous que c'est la bonne date\n","# sim_end_date = bars_df['time'].iloc[-1]\n","# initial_cash = 10000\n","# data_tz = bars_df['time'].dt.tz\n","# last_known_channels_sim = None # Pour fallback si lookup échoue\n","\n","# try:\n","#     symbol_security = qb.Securities[btc_symbol]\n","#     brokerage_model = qb.BrokerageModel\n","#     fee_model = brokerage_model.GetFeeModel(symbol_security)\n","#     print(f\"Utilisation du modèle de frais: {fee_model.__class__.__name__}\")\n","# except Exception as e:\n","#     print(f\"WARN: Impossible de récupérer le modèle de frais de QC: {e}. Simulation sans frais.\")\n","#     fee_model = ConstantFeeModel(0)\n","#     class MinimalSecurity: pass\n","#     symbol_security = MinimalSecurity()\n","\n","# --- Boucle Principale sur les STRATÉGIES GÉNÉRÉES ---\n","strategy_simulation_results = {} # Stockage final\n","\n","# Filtrer les barres pour la période de simulation globale\n","loop_bars_all = sim_bars_df_full[sim_bars_df_full['time'] >= sim_start_date].copy()\n","if loop_bars_all.empty:\n","     raise ValueError(\"Aucune barre de prix disponible pour la période de simulation.\")\n","\n","# for strategy_config in tqdm(strategies_to_test, desc=\"Simulating Generated Strategies\"):\n","#     strategy_name = strategy_config.get('name', 'Unnamed_Strategy')\n","#     strategy_params_origin = strategy_config.get('parameters', {}) # <--- Récupérer les params d'origine\n","\n","#     # Récupérer params généraux et règles pour CETTE stratégie\n","#     strat_gen_params = strategy_config.get('general_params', {})\n","#     strat_rules = strategy_config.get('rules', [])\n","#     risk_per_trade_pct = strat_gen_params.get('risk_per_trade_pct_equity', 0.01)\n","#     max_trades = strat_gen_params.get('max_concurrent_trades', 1)\n","\n","#     # Initialisation état simulation\n","#     sim_cash = initial_cash; sim_position_qty = 0.0; sim_entry_price = 0.0\n","#     sim_equity = initial_cash; active_stop_loss = None; active_take_profit = None\n","#     equity_curve_list = [{'time': sim_start_date - pd.Timedelta(hours=1), 'equity': initial_cash}]\n","#     sim_trades = []\n","\n","#     # --- Boucle Barre par Barre ---\n","#     for index, row in loop_bars_all.iterrows():\n","#         current_time = row['time']; current_price = row['close']\n","#         current_high = row['high']; current_low = row['low']\n","#         current_time_num = current_time.timestamp()\n","\n","#         # Trouver canaux actifs\n","#         valid_channel_time_index = channel_history_df.index[channel_history_df.index <= current_time]\n","#         current_active_channels = None\n","#         if not valid_channel_time_index.empty:\n","#             valid_channel_time = valid_channel_time_index.max()\n","#             try:\n","#                 current_active_channels = channel_history_df.loc[valid_channel_time].to_dict()\n","#                 last_known_channels_sim = current_active_channels\n","#             except Exception as e:\n","#                  current_active_channels = last_known_channels_sim\n","#         else: current_active_channels = last_known_channels_sim\n","\n","#         if current_active_channels is None:\n","#              sim_equity = sim_cash + sim_position_qty * current_price\n","#              equity_curve_list.append({'time': current_time, 'equity': sim_equity})\n","#              continue\n","\n","#         # --- Logique de Trading ---\n","#         exit_executed = False\n","#         # 1. Gestion Sorties (SL/TP)\n","#         if sim_position_qty != 0:\n","#             pnl = 0.0; exit_reason = \"\"; close_position_now = False; exit_price = current_price\n","#             if active_stop_loss is not None:\n","#                 if sim_position_qty > 0 and current_low <= active_stop_loss: close_position_now=True; exit_reason=\"Stop Loss\"; exit_price=active_stop_loss\n","#                 elif sim_position_qty < 0 and current_high >= active_stop_loss: close_position_now=True; exit_reason=\"Stop Loss\"; exit_price=active_stop_loss\n","#             if not close_position_now and active_take_profit is not None:\n","#                  if sim_position_qty > 0 and current_high >= active_take_profit: close_position_now=True; exit_reason=\"Take Profit\"; exit_price=active_take_profit\n","#                  elif sim_position_qty < 0 and current_low <= active_take_profit: close_position_now=True; exit_reason=\"Take Profit\"; exit_price=active_take_profit\n","#             if close_position_now:\n","#                 exit_order = MarketOrder(btc_symbol, -sim_position_qty, current_time)\n","#                 exit_fee = apply_fees(exit_order, symbol_security, fee_model)\n","#                 pnl = sim_position_qty * (exit_price - sim_entry_price)\n","#                 sim_cash += sim_position_qty * exit_price; sim_cash -= exit_fee\n","#                 sim_trades.append({'time': current_time, 'type': f'exit_{\"long\" if sim_position_qty > 0 else \"short\"}', 'price': exit_price, 'size': -sim_position_qty, 'pnl': pnl - exit_fee, 'fee': exit_fee, 'reason': exit_reason})\n","#                 sim_position_qty = 0.0; sim_entry_price = 0.0; active_stop_loss = None; active_take_profit = None; exit_executed = True\n","\n","#         # 2. Gestion Entrées\n","#         if sim_position_qty == 0 and not exit_executed:\n","#             current_state = {\n","#                 'price': current_price, 'time_numeric': current_time_num,\n","#                 'position_status': 'none', 'active_channels': current_active_channels\n","#             }\n","#             for rule in strat_rules:\n","#                 conditions = rule.get('conditions', {}); action_template = rule.get('action')\n","#                 action_details = action_template if isinstance(action_template, dict) else ({\"action_type\": \"do_nothing\"} if action_template == \"do_nothing\" else {})\n","\n","#                 if check_conditions(conditions, current_state):\n","#                     action_type = action_details.get(\"action_type\")\n","#                     if action_type in [\"bounce_long\", \"breakout_long\", \"bounce_short\", \"breakout_short\"]:\n","#                         entry_price = current_price; signal = 1 if \"long\" in action_type else -1\n","#                         sl_price = None; tp_price = None; risk_amount_per_unit = 0\n","\n","#                         # --- Calcul SL (Utilise strategy_params_origin maintenant) ---\n","#                         # Déterminer quelle valeur de SL (bounce ou breakout) est pertinente pour cette action_type\n","#                         is_bounce_action = 'bounce' in action_type\n","#                         original_sl_type = strategy_params_origin['bounce_sl_type'] if is_bounce_action else strategy_params_origin['breakout_sl_type']\n","#                         original_sl_value_key_suffix = 'bounce_sl_value' if is_bounce_action else 'breakout_sl_value'\n","#                         sl_val = strategy_params_origin[original_sl_value_key_suffix] # Valeur SL issue des params d'origine\n","\n","#                         sl_pct_entry = sl_val if original_sl_type == 'pct_entry' else None\n","#                         sl_pct_level = sl_val if original_sl_type == 'pct_level' else None\n","#                         # --- Fin Section Corrigée ---\n","\n","#                         if signal == 1: # Long SL\n","#                              if sl_pct_entry: sl_price = entry_price * (1 - sl_pct_entry)\n","#                              elif sl_pct_level:\n","#                                  # Trouver niveau pertinent (simplifié, prend le niveau de la condition si possible)\n","#                                  level_name = conditions.get(\"price_near_level\",{}).get(\"level\") or conditions.get(\"price_closes_above\",{}).get(\"level\") or f\"{strategy_params_origin['trade_level']}_resistance\" # Fallback: resistance du niveau trade\n","#                                  scale, line_type = level_name.split('_')\n","#                                  level_val = get_channel_value_at_time(current_active_channels.get(scale, {}).get(line_type), current_time_num)\n","#                                  sl_price = level_val * (1 - sl_pct_level) if not pd.isna(level_val) else entry_price * (1 - sl_val) # Fallback si niveau non trouvé\n","#                              else: sl_price = entry_price * (1 - sl_val) # Fallback si type SL inconnu (ne devrait pas arriver)\n","#                         else: # Short SL\n","#                             if sl_pct_entry: sl_price = entry_price * (1 + sl_pct_entry)\n","#                             elif sl_pct_level:\n","#                                 level_name = conditions.get(\"price_near_level\",{}).get(\"level\") or conditions.get(\"price_closes_below\",{}).get(\"level\") or f\"{strategy_params_origin['trade_level']}_support\" # Fallback: support du niveau trade\n","#                                 scale, line_type = level_name.split('_')\n","#                                 level_val = get_channel_value_at_time(current_active_channels.get(scale, {}).get(line_type), current_time_num)\n","#                                 sl_price = level_val * (1 + sl_pct_level) if not pd.isna(level_val) else entry_price * (1 + sl_val)\n","#                             else: sl_price = entry_price * (1 + sl_val)\n","\n","#                         # Calcul TP\n","#                         target_rr = action_details.get(\"target_rr_ratio\") # Le RR vient de l'action_details\n","#                         if sl_price is not None and target_rr is not None:\n","#                              risk_amount_per_unit = abs(entry_price - sl_price)\n","#                              if risk_amount_per_unit > 1e-9:\n","#                                   tp_price = entry_price + signal * risk_amount_per_unit * target_rr\n","\n","#                         # Execute Entry if SL is valid\n","#                         if sl_price is not None and risk_amount_per_unit > 1e-9:\n","#                             sim_equity_before_trade = sim_cash\n","#                             qty_to_trade = calculate_position_size(sim_equity_before_trade, risk_per_trade_pct, entry_price, sl_price)\n","#                             if qty_to_trade > 0:\n","#                                 entry_order = MarketOrder(btc_symbol, signal * qty_to_trade, current_time)\n","#                                 entry_fee = apply_fees(entry_order, symbol_security, fee_model)\n","#                                 sim_position_qty = signal * qty_to_trade; sim_entry_price = entry_price\n","#                                 sim_cash -= sim_position_qty * sim_entry_price; sim_cash -= entry_fee\n","#                                 active_stop_loss = sl_price; active_take_profit = tp_price\n","#                                 sim_trades.append({'time': current_time, 'type': 'buy' if signal > 0 else 'sell', 'price': entry_price, 'size': sim_position_qty, 'fee': entry_fee, 'sl': active_stop_loss, 'tp': active_take_profit, 'reason': action_type})\n","#                                 break\n","#                     elif action_type == \"do_nothing\":\n","#                         break\n","\n","#         # 3. Mise à jour Equity\n","#         sim_equity = sim_cash + sim_position_qty * current_price\n","#         equity_curve_list.append({'time': current_time, 'equity': sim_equity})\n","\n","#     # --- Fin Boucle Barre par Barre ---\n","#     sim_equity_curve = pd.DataFrame(equity_curve_list).set_index('time')['equity']\n","#     sim_trades_df = pd.DataFrame(sim_trades)\n","#     final_equity = sim_equity_curve.iloc[-1] if not sim_equity_curve.empty else initial_cash\n","#     strategy_simulation_results[strategy_name] = {\n","#         'equity_curve': sim_equity_curve, 'trades': sim_trades_df,\n","#         'final_equity': final_equity, 'config_params': strategy_params_origin # Stocker les params spécifiques\n","#     }\n","\n","# # --- Fin Boucle Stratégies ---\n","# print(f\"\\n--- Simulation terminée pour {len(strategy_simulation_results)} stratégies ---\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # CELLULE D'ANALYSE : Analyse Comparative des Stratégies Générées\n","\n","# import matplotlib.pyplot as plt\n","# import pandas as pd\n","# import heapq # Pour trouver les meilleurs\n","\n","# print(\"\\n--- Résultats Comparatifs des Simulations par Stratégie Générée ---\")\n","\n","# if 'strategy_simulation_results' not in locals() or not strategy_simulation_results:\n","#     print(\"Aucun résultat de simulation de stratégie à afficher.\")\n","# else:\n","#     summary = []\n","#     all_results = []\n","#     for strategy_name, result in strategy_simulation_results.items():\n","#         trade_df = result.get('trades', pd.DataFrame())\n","#         equity_curve = result.get('equity_curve', pd.Series(dtype=float))\n","#         final_equity = result.get('final_equity', initial_cash)\n","\n","#         nb_trades = len(trade_df[trade_df['type'].isin(['buy', 'sell'])])\n","#         total_pnl = trade_df['pnl'].sum() if 'pnl' in trade_df.columns and not trade_df['pnl'].empty else 0.0\n","#         total_fees = trade_df['fee'].sum() if 'fee' in trade_df.columns and not trade_df['fee'].empty else 0.0\n","#         winning_trades = trade_df[trade_df['pnl'] > 0]['pnl'].count() if 'pnl' in trade_df.columns else 0\n","#         losing_trades = trade_df[trade_df['pnl'] <= 0]['pnl'].count() if 'pnl' in trade_df.columns else 0\n","#         total_closed_trades = winning_trades + losing_trades\n","#         win_rate = (winning_trades / total_closed_trades * 100) if total_closed_trades > 0 else 0.0\n","\n","#         # Calcul simple du Max Drawdown sur l'équité\n","#         max_dd = 0.0\n","#         peak = -np.inf\n","#         if not equity_curve.empty:\n","#             for equity_value in equity_curve:\n","#                 if equity_value > peak:\n","#                     peak = equity_value\n","#                 drawdown = (peak - equity_value) / peak if peak > 0 else 0\n","#                 if drawdown > max_dd:\n","#                     max_dd = drawdown\n","\n","#         result_data = {\n","#             'Stratégie': strategy_name,\n","#             'Final Equity': final_equity,\n","#             'Nb Trades': nb_trades,\n","#             'Total PnL Net': total_pnl,\n","#             'Total Fees': total_fees,\n","#             'Win Rate (%)': win_rate,\n","#             'Max Drawdown (%)': max_dd * 100,\n","#             'Equity Curve': equity_curve # Pour plot plus tard\n","#         }\n","#         all_results.append(result_data)\n","\n","#     if all_results:\n","#         results_df = pd.DataFrame(all_results).drop(columns=['Equity Curve']) # DF sans les séries\n","#         results_df = results_df.sort_values(by='Final Equity', ascending=False) # Trier par meilleur résultat\n","\n","#         print(\"Top 10 Stratégies par Équité Finale:\")\n","#         print(results_df.head(10).to_string(index=False, formatters={\n","#              'Final Equity': '{:,.2f}'.format,\n","#              'Total PnL Net': '{:,.2f}'.format,\n","#              'Total Fees': '{:,.2f}'.format,\n","#              'Win Rate (%)': '{:.1f}'.format,\n","#              'Max Drawdown (%)': '{:.1f}'.format\n","#          }))\n","\n","#         # Tracer les courbes d'équité des N meilleures\n","#         n_best_to_plot = 10\n","#         top_n_strategies = heapq.nlargest(n_best_to_plot, all_results, key=lambda x: x['Final Equity'])\n","\n","#         fig, ax = plt.subplots(figsize=(14, 8))\n","#         found_curves = False\n","#         for result_item in top_n_strategies:\n","#             equity_curve = result_item.get('Equity Curve')\n","#             strategy_name_plot = result_item['Stratégie']\n","#             final_val_plot = result_item['Final Equity']\n","#             # Raccourcir nom pour légende si trop long\n","#             max_len = 40\n","#             label_name = strategy_name_plot if len(strategy_name_plot) <= max_len else strategy_name_plot[:max_len-3] + \"...\"\n","\n","#             if equity_curve is not None and not equity_curve.empty:\n","#                  equity_curve.plot(ax=ax, label=f\"{label_name} ({final_val_plot:,.0f})\")\n","#                  found_curves = True\n","\n","#         if found_curves:\n","#             ax.set_title(f'Courbes d\\'Équité des {len(top_n_strategies)} Meilleures Stratégies Générées')\n","#             ax.set_ylabel('Valeur Portefeuille Simulé (USDT)')\n","#             ax.set_xlabel('Date')\n","#             ax.legend(fontsize=8, loc='upper left') # Taille police réduite\n","#             ax.grid(True)\n","#             plt.tight_layout()\n","#             plt.show()\n","#         else:\n","#             print(\"\\nAucune courbe d'équité à tracer.\")\n","\n","#     else:\n","#         print(\"Aucun résultat de simulation de stratégie à afficher.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE GA-1 : Setup de l'Algorithme Génétique avec DEAP (CORRIGÉE v2 + LOGGING)\n","\n","import random\n","import numpy as np\n","import pandas as pd\n","from deap import base, creator, tools, algorithms\n","from tqdm.notebook import tqdm\n","import traceback\n","import logging\n","\n","# S'assurer que les imports spécifiques QC sont présents si nécessaire hors de l'env QC\n","try:\n","    from AlgorithmImports import MarketOrder, OrderFeeParameters, ConstantFeeModel\n","except ImportError:\n","    print(\"WARN: QuantConnect imports non trouvés. Simulation avec ConstantFeeModel(0).\")\n","    class MarketOrder:\n","        def __init__(self, symbol, quantity, time): pass\n","    class OrderFeeParameters:\n","         def __init__(self, security, order): pass\n","         class OrderFeeValue:\n","             Amount = 0.0\n","         Value = OrderFeeValue()\n","    class ConstantFeeModel:\n","        def __init__(self, fee): self.fee = fee\n","        def GetOrderFee(self, parameters): return OrderFeeParameters.Value\n","\n","\n","# --- Configuration du Logging ---\n","log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n","# Mettre logging.DEBUG pour voir l'évaluation de chaque individu (très verbeux)\n","logging.basicConfig(level=logging.INFO, format=log_format)\n","logger = logging.getLogger(\"GA_Optimizer\")\n","# ------------------------------\n","\n","logger.info(\"Configuration de l'algorithme génétique (DEAP)...\")\n","\n","# --- 1. Vérification des Dépendances ---\n","if 'strategy_simulation_results' not in locals():\n","    logger.warning(\"'strategy_simulation_results' non trouvé.\")\n","if 'calculate_position_size' not in locals(): raise NameError(\"Fonction 'calculate_position_size' non définie.\")\n","if 'apply_fees' not in locals(): raise NameError(\"Fonction 'apply_fees' non définie.\")\n","if 'check_conditions' not in locals(): raise NameError(\"Fonction 'check_conditions' non définie.\")\n","if 'get_channel_value_at_time' not in locals(): raise NameError(\"Fonction 'get_channel_value_at_time' non définie.\")\n","if 'channel_history_df' not in locals() or channel_history_df.empty:\n","     raise NameError(\"L'historique des canaux ('channel_history_df') doit être calculé avant d'exécuter le GA.\")\n","if 'fixed_channel_config' not in locals():\n","     raise NameError(\"La configuration fixe des canaux ('fixed_channel_config') doit être définie.\")\n","if 'loop_bars_all' not in locals() or loop_bars_all.empty:\n","     raise NameError(\"Le DataFrame 'loop_bars_all' contenant les barres de simulation n'est pas défini ou est vide.\")\n","if 'symbol_security' not in locals(): raise NameError(\"'symbol_security' non défini.\")\n","if 'fee_model' not in locals():\n","    logger.warning(\"Modèle de frais non défini, simulation sans frais.\")\n","    fee_model = ConstantFeeModel(0)\n","if 'initial_cash' not in locals(): initial_cash = 10000 # Définir une valeur par défaut\n","if 'btc_symbol' not in locals(): btc_symbol = None # Définir placeholder\n","\n","\n","# --- 2. Espace Paramétrique (Chromosome) ---\n","if 'param_space' not in locals(): raise NameError(\"L'espace paramétrique 'param_space' n'est pas défini.\")\n","if 'param_keys' not in locals(): raise NameError(\"'param_keys' n'est pas défini.\")\n","\n","# --- 3. Fonction Fitness (Évaluation d'un individu) ---\n","memoization_cache = {}\n","\n","def evaluate_strategy(individual):\n","    \"\"\"\n","    Fonction de fitness pour l'algorithme génétique.\n","    Évalue une stratégie (représentée par 'individual') en utilisant l'historique\n","    de canaux pré-calculé ('channel_history_df').\n","    Retourne une tuple (fitness_value,) - DEAP requiert un tuple.\n","    \"\"\"\n","    global initial_cash, loop_bars_all, channel_history_df, btc_symbol, symbol_security, fee_model # Accéder aux variables globales nécessaires\n","\n","    individual_tuple = tuple(individual)\n","    # logger.debug(f\"Début évaluation individu: {individual_tuple}\")\n","    if individual_tuple in memoization_cache:\n","        return memoization_cache[individual_tuple]\n","\n","    try:\n","        if 'create_strategy_from_params' not in globals(): raise NameError(\"create_strategy_from_params non définie\")\n","        strategy_config = create_strategy_from_params(individual, param_keys)\n","        strat_gen_params = strategy_config.get('general_params', {})\n","        strat_rules = strategy_config.get('rules', [])\n","        risk_per_trade_pct = strat_gen_params.get('risk_per_trade_pct_equity', 0.01)\n","\n","        sim_cash = initial_cash; sim_position_qty = 0.0; sim_entry_price = 0.0\n","        sim_equity = initial_cash; active_stop_loss = None; active_take_profit = None\n","        last_known_channels_sim_ga = None\n","\n","        for index, row in loop_bars_all.iterrows():\n","            current_time = row['time']; current_price = row['close']\n","            current_high = row['high']; current_low = row['low']\n","            current_time_num = current_time.timestamp()\n","\n","            valid_channel_time_index = channel_history_df.index[channel_history_df.index <= current_time]\n","            current_active_channels = None\n","            if not valid_channel_time_index.empty:\n","                valid_channel_time = valid_channel_time_index.max()\n","                try:\n","                    current_active_channels = channel_history_df.loc[valid_channel_time].to_dict()\n","                    last_known_channels_sim_ga = current_active_channels\n","                except Exception as e: current_active_channels = last_known_channels_sim_ga\n","            else: current_active_channels = last_known_channels_sim_ga\n","            if current_active_channels is None: continue\n","\n","            exit_executed = False\n","            if sim_position_qty != 0:\n","                 pnl = 0.0; exit_reason = \"\"; close_position_now = False; exit_price = current_price\n","                 if active_stop_loss is not None:\n","                     if sim_position_qty > 0 and current_low <= active_stop_loss: close_position_now=True; exit_reason=\"Stop Loss\"; exit_price=active_stop_loss\n","                     elif sim_position_qty < 0 and current_high >= active_stop_loss: close_position_now=True; exit_reason=\"Stop Loss\"; exit_price=active_stop_loss\n","                 if not close_position_now and active_take_profit is not None:\n","                      if sim_position_qty > 0 and current_high >= active_take_profit: close_position_now=True; exit_reason=\"Take Profit\"; exit_price=active_take_profit\n","                      elif sim_position_qty < 0 and current_low <= active_take_profit: close_position_now=True; exit_reason=\"Take Profit\"; exit_price=active_take_profit\n","                 if close_position_now:\n","                     exit_order = MarketOrder(btc_symbol, -sim_position_qty, current_time)\n","                     exit_fee = apply_fees(exit_order, symbol_security, fee_model)\n","                     pnl = sim_position_qty * (exit_price - sim_entry_price)\n","                     sim_cash += sim_position_qty * exit_price; sim_cash -= exit_fee\n","                     sim_position_qty = 0.0; sim_entry_price = 0.0; active_stop_loss = None; active_take_profit = None; exit_executed = True\n","\n","            if sim_position_qty == 0 and not exit_executed:\n","                current_state = { 'price': current_price, 'time_numeric': current_time_num, 'position_status': 'none', 'active_channels': current_active_channels }\n","                for rule in strat_rules:\n","                    conditions = rule.get('conditions', {}); action_template = rule.get('action')\n","\n","                    # <-- Logique corrigée pour action_details -->\n","                    if isinstance(action_template, dict):\n","                        action_details = action_template\n","                    elif action_template == \"do_nothing\":\n","                        action_details = {\"action_type\": \"do_nothing\"}\n","                    else:\n","                        action_details = {} # Cas par défaut ou erreur\n","\n","                    if check_conditions(conditions, current_state):\n","                        action_type = action_details.get(\"action_type\")\n","                        if action_type in [\"bounce_long\", \"breakout_long\", \"bounce_short\", \"breakout_short\"]:\n","                            entry_price = current_price; signal = 1 if \"long\" in action_type else -1\n","                            sl_price = None; tp_price = None; risk_amount_per_unit = 0\n","\n","                            # --- Calcul SL/TP ---\n","                            is_bounce_action = 'bounce' in action_type\n","                            # !! Utilise strategy_config['parameters'] pour les params de l'individu actuel !!\n","                            strat_origin_params = strategy_config.get('parameters', {})\n","                            original_sl_type = strat_origin_params.get('bounce_sl_type' if is_bounce_action else 'breakout_sl_type')\n","                            original_sl_value_key = 'bounce_sl_value' if is_bounce_action else 'breakout_sl_value'\n","                            sl_val = strat_origin_params.get(original_sl_value_key)\n","\n","                            if original_sl_type is None or sl_val is None: # Vérifier si les clés existent\n","                                logger.warning(f\"Paramètres SL manquants pour {action_type} dans {strategy_config.get('name')}\")\n","                                continue # Ne pas prendre le trade si SL non défini\n","\n","                            sl_pct_entry = sl_val if original_sl_type == 'pct_entry' else None\n","                            sl_pct_level = sl_val if original_sl_type == 'pct_level' else None\n","\n","                            if signal == 1: # Long SL\n","                                if sl_pct_entry: sl_price = entry_price * (1 - sl_pct_entry)\n","                                elif sl_pct_level:\n","                                    level_name = conditions.get(\"price_near_level\",{}).get(\"level\") or conditions.get(\"price_closes_above\",{}).get(\"level\") or f\"{strat_origin_params.get('trade_level','micro')}_resistance\" # Ajout fallback niveau\n","                                    scale, line_type = level_name.split('_')\n","                                    level_val = get_channel_value_at_time(current_active_channels.get(scale, {}).get(line_type), current_time_num)\n","                                    sl_price = level_val * (1 - sl_pct_level) if not pd.isna(level_val) else entry_price * (1 - sl_val)\n","                                else: sl_price = entry_price * (1 - sl_val)\n","                            else: # Short SL\n","                                if sl_pct_entry: sl_price = entry_price * (1 + sl_pct_entry)\n","                                elif sl_pct_level:\n","                                    level_name = conditions.get(\"price_near_level\",{}).get(\"level\") or conditions.get(\"price_closes_below\",{}).get(\"level\") or f\"{strat_origin_params.get('trade_level','micro')}_support\" # Ajout fallback niveau\n","                                    scale, line_type = level_name.split('_')\n","                                    level_val = get_channel_value_at_time(current_active_channels.get(scale, {}).get(line_type), current_time_num)\n","                                    sl_price = level_val * (1 + sl_pct_level) if not pd.isna(level_val) else entry_price * (1 + sl_val)\n","                                else: sl_price = entry_price * (1 + sl_val)\n","\n","                            target_rr_key = 'bounce_tp_value' if is_bounce_action else 'breakout_tp_value'\n","                            target_rr = strat_origin_params.get(target_rr_key)\n","\n","                            if sl_price is not None and target_rr is not None:\n","                                risk_amount_per_unit = abs(entry_price - sl_price)\n","                                if risk_amount_per_unit > 1e-9:\n","                                    tp_price = entry_price + signal * risk_amount_per_unit * target_rr\n","                            # --- Fin Calcul SL/TP ---\n","\n","                            if sl_price is not None and risk_amount_per_unit > 1e-9:\n","                                 sim_equity_before_trade = sim_cash\n","                                 qty_to_trade = calculate_position_size(sim_equity_before_trade, risk_per_trade_pct, entry_price, sl_price)\n","                                 if qty_to_trade > 0:\n","                                     entry_order = MarketOrder(btc_symbol, signal * qty_to_trade, current_time)\n","                                     entry_fee = apply_fees(entry_order, symbol_security, fee_model)\n","                                     sim_position_qty = signal * qty_to_trade; sim_entry_price = entry_price\n","                                     sim_cash -= sim_position_qty * sim_entry_price; sim_cash -= entry_fee\n","                                     active_stop_loss = sl_price; active_take_profit = tp_price\n","                                     # Pas de log de trade ici pour la performance\n","                                     break # Sortir boucle règles\n","                        elif action_type == \"do_nothing\":\n","                            break # Sortir boucle règles\n","\n","        # --- Fin Logique Trading ---\n","        sim_equity = sim_cash + sim_position_qty * current_price\n","\n","        final_equity = sim_cash + sim_position_qty * current_price\n","        fitness = final_equity if final_equity > 1 else 1.0\n","        result_tuple = (fitness,)\n","        memoization_cache[individual_tuple] = result_tuple\n","        # logger.debug(f\"Fin évaluation individu -> Fitness: {fitness:.2f}\")\n","        return result_tuple\n","\n","    except Exception as e:\n","        logger.exception(f\"Erreur pendant l'évaluation de l'individu {individual_tuple}:\")\n","        memoization_cache[individual_tuple] = (0.0,)\n","        return (0.0,)\n","\n","\n","# --- 4. Configuration DEAP (Identique) ---\n","# (Assurez-vous que cette partie est bien présente et correcte dans votre cellule)\n","# Si FitnessMax existe déjà, la ligne creator.create peut lever une erreur,\n","# ce qui est normal si vous exécutez la cellule plusieurs fois.\n","try:\n","    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","except Exception:\n","    logger.info(\"DEAP creators 'FitnessMax' et/ou 'Individual' existent déjà.\")\n","    pass # Continuer si elles existent déjà\n","\n","toolbox = base.Toolbox()\n","gene_generators = []\n","for key in param_keys:\n","    options = param_space[key]\n","    if isinstance(options[0], str): gene_generators.append(lambda opts=options: random.choice(opts))\n","    elif isinstance(options[0], (int, float)):\n","         if isinstance(options[0], float) or len(options) == 2:\n","             min_val, max_val = min(options), max(options)\n","             if isinstance(min_val, float) or isinstance(max_val, float): gene_generators.append(lambda mn=min_val, mx=max_val: random.uniform(mn, mx))\n","             else: gene_generators.append(lambda opts=options: random.choice(opts))\n","         else: gene_generators.append(lambda opts=options: random.choice(opts))\n","    else: raise TypeError(f\"Type de paramètre non supporté pour {key}: {type(options[0])}\")\n","\n","toolbox.register(\"individual\", tools.initCycle, creator.Individual, gene_generators, n=1)\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","toolbox.register(\"evaluate\", evaluate_strategy)\n","toolbox.register(\"mate\", tools.cxTwoPoint)\n","def mutate_individual(individual, indpb=0.1): # Fonction mutate identique\n","    for i in range(len(individual)):\n","        if random.random() < indpb:\n","            key = param_keys[i]; options = param_space[key]\n","            if isinstance(options[0], str): individual[i] = random.choice(options)\n","            elif isinstance(options[0], (int, float)):\n","                 if isinstance(options[0], float) or len(options) == 2:\n","                     min_val, max_val = min(options), max(options)\n","                     if isinstance(min_val, float) or isinstance(max_val, float): individual[i] = random.uniform(min_val, max_val)\n","                     else: individual[i] = random.choice(options)\n","                 else: individual[i] = random.choice(options)\n","    return individual,\n","toolbox.register(\"mutate\", mutate_individual, indpb=0.1)\n","toolbox.register(\"select\", tools.selTournament, tournsize=3)\n","\n","logger.info(\"Configuration DEAP (corrigée v2 avec logging) terminée.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE GA-2 : Exécution de l'Algorithme Génétique (Avec Logging)\n","\n","logger.info(\"Lancement de l'algorithme génétique...\")\n","memoization_cache.clear() # Vider le cache avant une nouvelle exécution\n","\n","# Paramètres du GA\n","POPULATION_SIZE = 50\n","GENERATIONS = 20\n","CXPB = 0.7\n","MUTPB = 0.2\n","\n","# Initialiser la population\n","logger.info(f\"Initialisation de la population (taille={POPULATION_SIZE})...\")\n","pop = toolbox.population(n=POPULATION_SIZE)\n","logger.info(\"Population initialisée.\")\n","\n","# Garder une trace du meilleur individu\n","hof = tools.HallOfFame(1)\n","\n","# Statistiques pour suivre l'évolution\n","stats = tools.Statistics(lambda ind: ind.fitness.values)\n","stats.register(\"avg\", np.mean)\n","stats.register(\"std\", np.std)\n","stats.register(\"min\", np.min)\n","stats.register(\"max\", np.max)\n","\n","# Lancer l'algorithme\n","# Note : eaSimple loggue déjà des infos si verbose=True. On ajoute des logs avant/après.\n","logger.info(f\"Début de l'évolution pour {GENERATIONS} générations...\")\n","pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=GENERATIONS,\n","                                   stats=stats, halloffame=hof, verbose=True) # verbose=True donne les stats DEAP par génération\n","\n","logger.info(\"Algorithme génétique terminé.\")\n","\n","if hof: # Vérifier si le HallOfFame n'est pas vide\n","    best_individual = hof[0]\n","    best_fitness = best_individual.fitness.values[0]\n","    logger.info(f\"Meilleure Fitness (Equity Finale) trouvée : {best_fitness:,.2f}\")\n","    logger.info(\"Paramètres du meilleur individu :\")\n","    best_params_dict = dict(zip(param_keys, best_individual))\n","    for key, value in best_params_dict.items():\n","        if isinstance(value, float):\n","            logger.info(f\"  - {key}: {value:.4f}\")\n","        else:\n","            logger.info(f\"  - {key}: {value}\")\n","else:\n","    logger.warning(\"Aucun individu dans le HallOfFame après l'exécution du GA.\")\n","    best_individual = None # Pour éviter des erreurs plus loin\n","\n","# Vider le cache après l'exécution\n","memoization_cache.clear()\n","logger.debug(\"Cache de fitness vidé.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CELLULE GA-3 : Analyse des Résultats de l'AG (CORRIGÉE - Erreur action_details)\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as mtick\n","import heapq\n","import logging # Assurer l'import si ce n'est pas fait plus haut\n","import pandas as pd # Assurer l'import\n","import numpy as np # Assurer l'import\n","\n","# Récupérer le logger défini précédemment\n","logger = logging.getLogger(\"GA_Optimizer\")\n","\n","logger.info(\"--- Analyse des Résultats de l'Algorithme Génétique ---\")\n","\n","# --- 1. Visualisation de la Convergence (Identique) ---\n","if 'logbook' in locals() and logbook: # S'assurer que logbook existe\n","    gen = logbook.select(\"gen\")\n","    fit_max = logbook.select(\"max\")\n","    fit_avg = logbook.select(\"avg\")\n","\n","    fig, ax1 = plt.subplots(figsize=(12, 6))\n","    color = 'tab:red'; ax1.set_xlabel('Génération'); ax1.set_ylabel('Max Fitness (Equity)', color=color)\n","    ax1.plot(gen, fit_max, color=color, label=\"Max Fitness\"); ax1.tick_params(axis='y', labelcolor=color)\n","    ax1.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f'))\n","    ax2 = ax1.twinx(); color = 'tab:blue'; ax2.set_ylabel('Avg Fitness (Equity)', color=color)\n","    ax2.plot(gen, fit_avg, color=color, linestyle='--', label=\"Avg Fitness\"); ax2.tick_params(axis='y', labelcolor=color)\n","    ax2.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f'))\n","    fig.tight_layout(); plt.title('Convergence de la Fitness (Equity) au fil des Générations')\n","    lines, labels = ax1.get_legend_handles_labels(); lines2, labels2 = ax2.get_legend_handles_labels()\n","    ax2.legend(lines + lines2, labels + labels2, loc='center right'); plt.grid(True); plt.show()\n","else:\n","    logger.warning(\"Logbook non disponible, impossible de tracer la convergence.\")\n","\n","# --- 2. Re-simulation de la Meilleure Stratégie Trouvée (Avec Logging) ---\n","# Assurer que 'best_individual' existe et a été assigné dans la cellule précédente\n","if 'best_individual' in locals() and best_individual is not None:\n","    logger.info(\"Re-simulation de la meilleure stratégie trouvée pour analyse détaillée...\")\n","    # S'assurer que les fonctions nécessaires sont disponibles\n","    if 'create_strategy_from_params' not in globals(): raise NameError(\"create_strategy_from_params non définie\")\n","    if 'param_keys' not in globals(): raise NameError(\"param_keys non définis\")\n","\n","    best_strategy_config = create_strategy_from_params(best_individual, param_keys)\n","    best_strategy_name = best_strategy_config['name']\n","    logger.info(f\"Stratégie à re-simuler: {best_strategy_name}\")\n","\n","    # (Logique de simulation - identique à evaluate_strategy mais stocke trades/equity)\n","    sim_cash = initial_cash; sim_position_qty = 0.0; sim_entry_price = 0.0\n","    sim_equity = initial_cash; active_stop_loss = None; active_take_profit = None\n","    equity_curve_list_best = [{'time': sim_start_date - pd.Timedelta(hours=1), 'equity': initial_cash}]\n","    sim_trades_best = []\n","    strat_rules_best = best_strategy_config.get('rules', [])\n","    strat_gen_params_best = best_strategy_config.get('general_params', {})\n","    risk_per_trade_pct_best = strat_gen_params_best.get('risk_per_trade_pct_equity', 0.01)\n","    last_known_channels_sim_best = None\n","\n","    # Utiliser loop_bars_all qui doit être défini (contient les barres pour la simulation)\n","    if 'loop_bars_all' not in locals() or loop_bars_all.empty:\n","         raise NameError(\"Le DataFrame 'loop_bars_all' pour la simulation n'est pas défini ou est vide.\")\n","\n","    for index, row in loop_bars_all.iterrows(): # Pas de tqdm ici pour éviter surcharge logs\n","        current_time = row['time']; current_price = row['close']\n","        current_high = row['high']; current_low = row['low']\n","        current_time_num = current_time.timestamp()\n","\n","        # Trouver canaux actifs\n","        valid_channel_time_index = channel_history_df.index[channel_history_df.index <= current_time]\n","        current_active_channels = None\n","        if not valid_channel_time_index.empty:\n","            valid_channel_time = valid_channel_time_index.max()\n","            try:\n","                current_active_channels = channel_history_df.loc[valid_channel_time].to_dict()\n","                last_known_channels_sim_best = current_active_channels\n","            except Exception as e: current_active_channels = last_known_channels_sim_best\n","        else: current_active_channels = last_known_channels_sim_best\n","        if current_active_channels is None:\n","            sim_equity = sim_cash + sim_position_qty * current_price\n","            equity_curve_list_best.append({'time': current_time, 'equity': sim_equity})\n","            continue\n","\n","        # --- Logique de Trading (Sorties puis Entrées) ---\n","        exit_executed = False\n","        # 1. Gestion Sorties (SL/TP)\n","        if sim_position_qty != 0:\n","            pnl = 0.0; exit_reason = \"\"; close_position_now = False; exit_price = current_price\n","            if active_stop_loss is not None:\n","                if sim_position_qty > 0 and current_low <= active_stop_loss: close_position_now=True; exit_reason=\"Stop Loss\"; exit_price=active_stop_loss\n","                elif sim_position_qty < 0 and current_high >= active_stop_loss: close_position_now=True; exit_reason=\"Stop Loss\"; exit_price=active_stop_loss\n","            if not close_position_now and active_take_profit is not None:\n","                 if sim_position_qty > 0 and current_high >= active_take_profit: close_position_now=True; exit_reason=\"Take Profit\"; exit_price=active_take_profit\n","                 elif sim_position_qty < 0 and current_low <= active_take_profit: close_position_now=True; exit_reason=\"Take Profit\"; exit_price=active_take_profit\n","            if close_position_now:\n","                exit_order = MarketOrder(btc_symbol, -sim_position_qty, current_time)\n","                exit_fee = apply_fees(exit_order, symbol_security, fee_model)\n","                pnl = sim_position_qty * (exit_price - sim_entry_price)\n","                sim_cash += sim_position_qty * exit_price; sim_cash -= exit_fee\n","                sim_trades_best.append({'time': current_time, 'type': f'exit_{\"long\" if sim_position_qty > 0 else \"short\"}', 'price': exit_price, 'size': -sim_position_qty, 'pnl': pnl - exit_fee, 'fee': exit_fee, 'reason': exit_reason})\n","                sim_position_qty = 0.0; sim_entry_price = 0.0; active_stop_loss = None; active_take_profit = None; exit_executed = True\n","\n","        # 2. Gestion Entrées\n","        if sim_position_qty == 0 and not exit_executed:\n","            current_state = { 'price': current_price, 'time_numeric': current_time_num, 'position_status': 'none', 'active_channels': current_active_channels }\n","            for rule in strat_rules_best:\n","                conditions = rule.get('conditions', {}); action_template = rule.get('action')\n","\n","                # <-- CORRECTION ICI (appliquée dans la boucle de re-simulation)\n","                if isinstance(action_template, dict):\n","                    action_details = action_template\n","                elif action_template == \"do_nothing\":\n","                    action_details = {\"action_type\": \"do_nothing\"}\n","                else:\n","                    action_details = {}\n","\n","                if check_conditions(conditions, current_state):\n","                    action_type = action_details.get(\"action_type\")\n","                    if action_type in [\"bounce_long\", \"breakout_long\", \"bounce_short\", \"breakout_short\"]:\n","                        entry_price = current_price; signal = 1 if \"long\" in action_type else -1\n","                        sl_price = None; tp_price = None; risk_amount_per_unit = 0\n","\n","                        # --- Recalcul SL/TP (Identique) ---\n","                        is_bounce_action = 'bounce' in action_type\n","                        best_strat_origin_params = best_strategy_config.get('parameters', {})\n","                        original_sl_type = best_strat_origin_params['bounce_sl_type'] if is_bounce_action else best_strat_origin_params['breakout_sl_type']\n","                        original_sl_value_key_suffix = 'bounce_sl_value' if is_bounce_action else 'breakout_sl_value'\n","                        sl_val = best_strat_origin_params[original_sl_value_key_suffix]\n","                        sl_pct_entry = sl_val if original_sl_type == 'pct_entry' else None\n","                        sl_pct_level = sl_val if original_sl_type == 'pct_level' else None\n","                        if signal == 1: # Long SL\n","                            if sl_pct_entry: sl_price = entry_price * (1 - sl_pct_entry)\n","                            elif sl_pct_level:\n","                                level_name = conditions.get(\"price_near_level\",{}).get(\"level\") or conditions.get(\"price_closes_above\",{}).get(\"level\") or f\"{best_strat_origin_params['trade_level']}_resistance\"\n","                                scale, line_type = level_name.split('_')\n","                                level_val = get_channel_value_at_time(current_active_channels.get(scale, {}).get(line_type), current_time_num)\n","                                sl_price = level_val * (1 - sl_pct_level) if not pd.isna(level_val) else entry_price * (1 - sl_val)\n","                            else: sl_price = entry_price * (1 - sl_val)\n","                        else: # Short SL\n","                            if sl_pct_entry: sl_price = entry_price * (1 + sl_pct_entry)\n","                            elif sl_pct_level:\n","                                level_name = conditions.get(\"price_near_level\",{}).get(\"level\") or conditions.get(\"price_closes_below\",{}).get(\"level\") or f\"{best_strat_origin_params['trade_level']}_support\"\n","                                scale, line_type = level_name.split('_')\n","                                level_val = get_channel_value_at_time(current_active_channels.get(scale, {}).get(line_type), current_time_num)\n","                                sl_price = level_val * (1 + sl_pct_level) if not pd.isna(level_val) else entry_price * (1 + sl_val)\n","                            else: sl_price = entry_price * (1 + sl_val)\n","                        target_rr_key_suffix = 'bounce_tp_value' if is_bounce_action else 'breakout_tp_value'\n","                        target_rr = best_strat_origin_params[target_rr_key_suffix]\n","                        if sl_price is not None and target_rr is not None:\n","                            risk_amount_per_unit = abs(entry_price - sl_price)\n","                            if risk_amount_per_unit > 1e-9:\n","                                tp_price = entry_price + signal * risk_amount_per_unit * target_rr\n","                        # --- Fin Recalcul SL/TP ---\n","\n","                        if sl_price is not None and risk_amount_per_unit > 1e-9:\n","                             sim_equity_before_trade = sim_cash\n","                             qty_to_trade = calculate_position_size(sim_equity_before_trade, risk_per_trade_pct_best, entry_price, sl_price)\n","                             if qty_to_trade > 0:\n","                                 entry_order = MarketOrder(btc_symbol, signal * qty_to_trade, current_time)\n","                                 entry_fee = apply_fees(entry_order, symbol_security, fee_model)\n","                                 sim_position_qty = signal * qty_to_trade; sim_entry_price = entry_price\n","                                 sim_cash -= sim_position_qty * sim_entry_price; sim_cash -= entry_fee\n","                                 active_stop_loss = sl_price; active_take_profit = tp_price\n","                                 # Enregistrer le trade simulé pour analyse\n","                                 sim_trades_best.append({'time': current_time, 'type': 'buy' if signal > 0 else 'sell', 'price': entry_price, 'size': sim_position_qty, 'fee': entry_fee, 'sl': active_stop_loss, 'tp': active_take_profit, 'reason': action_type})\n","                                 break # Sortir boucle règles\n","                    elif action_type == \"do_nothing\":\n","                        break # Sortir boucle règles\n","\n","        # 3. Mise à jour Equity finale\n","        sim_equity = sim_cash + sim_position_qty * current_price\n","        equity_curve_list_best.append({'time': current_time, 'equity': sim_equity})\n","\n","    # --- Fin Boucle Barre par Barre (Re-simulation) ---\n","\n","    # --- 3. Affichage des Résultats de la Meilleure Stratégie (Identique) ---\n","    best_equity_curve = pd.DataFrame(equity_curve_list_best).set_index('time')['equity']\n","    best_trades_df = pd.DataFrame(sim_trades_best)\n","    best_final_equity = best_equity_curve.iloc[-1] if not best_equity_curve.empty else initial_cash\n","\n","    logger.info(f\"--- Performance Détaillée de la Meilleure Stratégie Trouvée ({best_strategy_name}) ---\")\n","    logger.info(f\"Équité Finale: {best_final_equity:,.2f} USDT\")\n","    # (Calcul des métriques et affichage des logs identiques à la version précédente)\n","    nb_trades_best = len(best_trades_df[best_trades_df['type'].isin(['buy', 'sell'])])\n","    total_pnl_best = best_trades_df['pnl'].sum() if 'pnl' in best_trades_df.columns else 0.0\n","    total_fees_best = best_trades_df['fee'].sum() if 'fee' in best_trades_df.columns else 0.0\n","    winning_trades_best = best_trades_df[best_trades_df['pnl'] > 0]['pnl'].count() if 'pnl' in best_trades_df.columns else 0\n","    losing_trades_best = best_trades_df[best_trades_df['pnl'] <= 0]['pnl'].count() if 'pnl' in best_trades_df.columns else 0\n","    total_closed_trades_best = winning_trades_best + losing_trades_best\n","    win_rate_best = (winning_trades_best / total_closed_trades_best * 100) if total_closed_trades_best > 0 else 0.0\n","    max_dd_best = 0.0; peak_best = -np.inf\n","    if not best_equity_curve.empty:\n","        for equity_value in best_equity_curve:\n","            if equity_value > peak_best: peak_best = equity_value\n","            drawdown = (peak_best - equity_value) / peak_best if peak_best > 0 else 0\n","            if drawdown > max_dd_best: max_dd_best = drawdown\n","\n","    logger.info(f\"Nombre de Trades (Entrées): {nb_trades_best}\")\n","    logger.info(f\"Total PnL Net: {total_pnl_best:,.2f} USDT\")\n","    logger.info(f\"Total Fees: {total_fees_best:,.2f} USDT\")\n","    logger.info(f\"Win Rate: {win_rate_best:.1f}%\")\n","    logger.info(f\"Max Drawdown: {max_dd_best*100:.1f}%\")\n","\n","    plt.figure(figsize=(14, 7))\n","    best_equity_curve.plot(title=f'Courbe d\\'Équité - Meilleure Stratégie GA: {best_strategy_name[:60]}...', grid=True)\n","    plt.ylabel(\"Valeur Portefeuille (USDT)\")\n","    plt.xlabel(\"Date\")\n","    plt.show()\n","\n","    logger.info(\"Paramètres de la meilleure stratégie trouvée par le GA:\")\n","    best_params_final = best_strategy_config.get('parameters', {})\n","    for key, value in best_params_final.items():\n","         if isinstance(value, float): logger.info(f\"  - {key}: {value:.4f}\")\n","         else: logger.info(f\"  - {key}: {value}\")\n","else:\n","    logger.error(\"Aucun meilleur individu trouvé par le GA. Impossible d'analyser les résultats.\")"]}],"metadata":{"kernelspec":{"display_name":"Foundation-Py-Default","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"polyglot_notebook":{"kernelInfo":{"defaultKernelName":"csharp","items":[{"aliases":[],"name":"csharp"}]}}},"nbformat":4,"nbformat_minor":2}