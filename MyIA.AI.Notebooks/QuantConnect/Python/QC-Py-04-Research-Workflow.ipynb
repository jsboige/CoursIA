{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC-Py-04 - Research Workflow with QuantBook\n",
    "\n",
    "> **De la recherche exploratoire à l'algorithme de production**\n",
    "> Durée: 75 minutes | Niveau: Intermédiaire | Python + QuantConnect\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous serez capable de :\n",
    "\n",
    "1. Maîtriser **QuantBook** pour la recherche exploratoire\n",
    "2. Analyser des données avec **pandas** et **matplotlib**\n",
    "3. Tester des stratégies en mode **recherche** (vectorized backtesting)\n",
    "4. **Transitionner** du notebook vers un algorithme de production\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "- Notebooks QC-Py-01, 02, 03 complétés\n",
    "- Connaissance de pandas et matplotlib\n",
    "- Compréhension du lifecycle QCAlgorithm\n",
    "\n",
    "## Structure du Notebook\n",
    "\n",
    "1. Introduction au workflow de recherche\n",
    "2. Setup QuantBook\n",
    "3. Exploration de données avec pandas\n",
    "4. Test de stratégie en mode recherche\n",
    "5. Utiliser shared/features.py\n",
    "6. Transition Notebook → Algorithm\n",
    "7. Exemple complet: Feature Engineering pour ML\n",
    "8. Conclusion et prochaines étapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction au Workflow de Recherche (5 min)\n",
    "\n",
    "### Workflow Recherche vs Backtest\n",
    "\n",
    "QuantConnect propose deux modes de développement distincts :\n",
    "\n",
    "| Aspect | Mode Recherche (QuantBook) | Mode Backtest (QCAlgorithm) |\n",
    "|--------|---------------------------|-----------------------------|\n",
    "| **Environment** | Jupyter Notebook | Event-driven algorithm |\n",
    "| **Exécution** | Synchrone, interactive | Asynchrone, simulation temporelle |\n",
    "| **API principale** | `QuantBook` | `QCAlgorithm` |\n",
    "| **Lifecycle** | Pas de lifecycle | Initialize → OnData → OnEndOfAlgorithm |\n",
    "| **Données** | `qb.History()` retourne DataFrame | `History()` retourne Slice |\n",
    "| **Usage** | Exploration, analyse, prototypage | Backtesting, optimisation, production |\n",
    "| **Visualisation** | matplotlib, seaborn directement | Via Charts API |\n",
    "\n",
    "### QuantBook : API de Recherche Jupyter\n",
    "\n",
    "**QuantBook** est une classe spécialisée qui permet d'interagir avec l'infrastructure QuantConnect dans un environnement Jupyter synchrone :\n",
    "\n",
    "- Accès aux **mêmes données** que QCAlgorithm\n",
    "- **Pas de lifecycle** : exécution cellule par cellule\n",
    "- Retourne des **DataFrames pandas** au lieu de Slices\n",
    "- Idéal pour **exploration rapide** et **prototypage**\n",
    "\n",
    "### Différences Clés avec QCAlgorithm\n",
    "\n",
    "```python\n",
    "# QCAlgorithm (event-driven)\n",
    "class MyAlgorithm(QCAlgorithm):\n",
    "    def Initialize(self):\n",
    "        self.SetStartDate(2020, 1, 1)\n",
    "        self.symbol = self.AddEquity(\"SPY\").Symbol\n",
    "    \n",
    "    def OnData(self, data):\n",
    "        if data.ContainsKey(self.symbol):\n",
    "            # Event-driven logic\n",
    "            pass\n",
    "\n",
    "# QuantBook (synchronous)\n",
    "qb = QuantBook()\n",
    "spy = qb.AddEquity(\"SPY\")\n",
    "history = qb.History(qb.Securities.Keys, 252, Resolution.Daily)\n",
    "df = history.loc[\"SPY\"]  # Direct DataFrame access\n",
    "```\n",
    "\n",
    "**Workflow typique** :\n",
    "\n",
    "1. **Recherche (QuantBook)** : Explorer données, tester hypothèses, visualiser\n",
    "2. **Prototypage (QuantBook)** : Vectorized backtesting rapide\n",
    "3. **Implémentation (QCAlgorithm)** : Traduire la logique en event-driven\n",
    "4. **Validation (Backtest)** : Backtest complet avec réalisme\n",
    "5. **Production (Live Trading)** : Déploiement\n",
    "\n",
    "> **Note Pédagogique** : QuantBook est un outil de **recherche**, pas un outil de backtest. Les résultats peuvent différer légèrement d'un backtest complet QCAlgorithm (pas de slippage, frais simulés, etc.). Toujours valider avec un backtest avant production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Setup QuantBook (10 min)\n",
    "\n",
    "### Créer une Instance QuantBook\n",
    "\n",
    "Commençons par importer les modules nécessaires et créer une instance de QuantBook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports QuantConnect\n",
    "from QuantConnect import *\n",
    "from QuantConnect.Data import *\n",
    "from QuantConnect.Research import *\n",
    "\n",
    "# Imports pour analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports réussis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer instance QuantBook\n",
    "qb = QuantBook()\n",
    "\n",
    "print(\"QuantBook initialisé\")\n",
    "print(f\"Type: {type(qb)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouter des Securities\n",
    "\n",
    "Ajoutons SPY et AAPL pour notre analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter securities\n",
    "spy = qb.AddEquity(\"SPY\", Resolution.Daily)\n",
    "aapl = qb.AddEquity(\"AAPL\", Resolution.Daily)\n",
    "\n",
    "print(f\"Securities ajoutées:\")\n",
    "print(f\"  SPY: {spy.Symbol}\")\n",
    "print(f\"  AAPL: {aapl.Symbol}\")\n",
    "print(f\"\\nTotal securities: {len(qb.Securities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérer Historical Data\n",
    "\n",
    "Récupérons 1 an de données (252 jours de trading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer historical data\n",
    "history = qb.History(qb.Securities.Keys, 252, Resolution.Daily)\n",
    "\n",
    "print(f\"Type de history: {type(history)}\")\n",
    "print(f\"Shape: {history.shape}\")\n",
    "print(f\"\\nPremières lignes:\")\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Différences avec QCAlgorithm.History()\n",
    "\n",
    "**Point clé** : `qb.History()` retourne directement un **DataFrame pandas** avec MultiIndex (symbol, time), contrairement à `QCAlgorithm.History()` qui retourne un objet `Slice`.\n",
    "\n",
    "```python\n",
    "# Dans QCAlgorithm\n",
    "history = self.History([self.symbol], 252, Resolution.Daily)\n",
    "# → Retourne Slice (itérable de TradeBar)\n",
    "\n",
    "# Dans QuantBook\n",
    "history = qb.History(qb.Securities.Keys, 252, Resolution.Daily)\n",
    "# → Retourne directement pandas DataFrame\n",
    "```\n",
    "\n",
    "**Accès aux données d'un symbole spécifique** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire données SPY uniquement\n",
    "df_spy = history.loc[\"SPY\"]\n",
    "\n",
    "print(f\"SPY DataFrame shape: {df_spy.shape}\")\n",
    "print(f\"\\nColonnes: {df_spy.columns.tolist()}\")\n",
    "print(f\"\\nPremières lignes:\")\n",
    "df_spy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Observation** : Le DataFrame contient les colonnes standard : `open`, `high`, `low`, `close`, `volume`. L'index est le timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Exploration de Données avec pandas (20 min)\n",
    "\n",
    "### Statistiques Descriptives\n",
    "\n",
    "Commençons par analyser les statistiques de base de SPY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "print(\"Statistiques SPY (1 an):\")\n",
    "print(df_spy[['close', 'volume']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des Returns\n",
    "\n",
    "Calculons les returns journaliers et cumulatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer returns journaliers\n",
    "df_spy['returns'] = df_spy['close'].pct_change()\n",
    "\n",
    "# Calculer returns cumulatifs\n",
    "df_spy['cumulative_returns'] = (1 + df_spy['returns']).cumprod()\n",
    "\n",
    "print(\"Returns ajoutés:\")\n",
    "print(df_spy[['close', 'returns', 'cumulative_returns']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des Returns Cumulatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser returns cumulatifs\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df_spy.index, df_spy['close'], linewidth=2, color='navy')\n",
    "plt.title('SPY - Prix de Clôture', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Prix ($)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df_spy.index, df_spy['cumulative_returns'], linewidth=2, color='darkgreen')\n",
    "plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Baseline')\n",
    "plt.title('SPY - Returns Cumulatifs', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Return Cumulatif')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques returns\n",
    "total_return = df_spy['cumulative_returns'].iloc[-1] - 1\n",
    "print(f\"\\nReturn total sur la période: {total_return*100:.2f}%\")\n",
    "print(f\"Return annualisé: {(df_spy['returns'].mean() * 252)*100:.2f}%\")\n",
    "print(f\"Volatilité annualisée: {(df_spy['returns'].std() * np.sqrt(252))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatilité Rolling\n",
    "\n",
    "Calculons et visualisons la volatilité glissante sur 30 jours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer volatilité rolling 30 jours (annualisée)\n",
    "df_spy['volatility_30d'] = df_spy['returns'].rolling(30).std() * np.sqrt(252)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(df_spy.index, df_spy['volatility_30d'], linewidth=2, color='darkorange')\n",
    "plt.title('SPY - Volatilité Rolling 30 Jours (Annualisée)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatilité Annualisée')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=df_spy['volatility_30d'].mean(), color='red', linestyle='--', alpha=0.5, \n",
    "            label=f'Moyenne: {df_spy[\"volatility_30d\"].mean():.2%}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Volatilité moyenne: {df_spy['volatility_30d'].mean():.2%}\")\n",
    "print(f\"Volatilité min: {df_spy['volatility_30d'].min():.2%}\")\n",
    "print(f\"Volatilité max: {df_spy['volatility_30d'].max():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Interprétation** : La volatilité rolling permet d'identifier les périodes de forte incertitude du marché (pics) et les périodes calmes (creux). Utile pour ajuster dynamiquement le sizing ou éviter de trader dans des conditions défavorables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution des Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser distribution des returns\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_spy['returns'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Return')\n",
    "plt.axvline(x=df_spy['returns'].mean(), color='green', linestyle='--', linewidth=2, \n",
    "            label=f'Mean: {df_spy[\"returns\"].mean():.4f}')\n",
    "plt.title('Distribution des Returns Journaliers', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "from scipy import stats\n",
    "stats.probplot(df_spy['returns'].dropna(), dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot (Normalité)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test de normalité\n",
    "stat, p_value = stats.shapiro(df_spy['returns'].dropna())\n",
    "print(f\"\\nTest de Shapiro-Wilk (normalité):\")\n",
    "print(f\"  Statistique: {stat:.4f}\")\n",
    "print(f\"  P-value: {p_value:.4f}\")\n",
    "print(f\"  Conclusion: {'Returns normaux' if p_value > 0.05 else 'Returns non-normaux (fat tails)'} (α=0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Test de Stratégie en Mode Recherche (20 min)\n",
    "\n",
    "### Stratégie SMA Crossover\n",
    "\n",
    "Testons une stratégie classique de croisement de moyennes mobiles : SMA 50 / SMA 200.\n",
    "\n",
    "**Règles** :\n",
    "- **Long** : SMA 50 > SMA 200 (\"Golden Cross\")\n",
    "- **Flat/Short** : SMA 50 <= SMA 200 (\"Death Cross\")\n",
    "\n",
    "### Calcul des Indicateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer SMA 50 et 200\n",
    "df_spy['sma_50'] = df_spy['close'].rolling(50).mean()\n",
    "df_spy['sma_200'] = df_spy['close'].rolling(200).mean()\n",
    "\n",
    "print(\"Indicateurs ajoutés:\")\n",
    "print(df_spy[['close', 'sma_50', 'sma_200']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des Signaux\n",
    "\n",
    "Générons les signaux de trading basés sur le croisement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer signaux\n",
    "df_spy['signal'] = 0\n",
    "df_spy.loc[df_spy['sma_50'] > df_spy['sma_200'], 'signal'] = 1   # Long\n",
    "df_spy.loc[df_spy['sma_50'] <= df_spy['sma_200'], 'signal'] = -1  # Flat\n",
    "\n",
    "# Position = signal décalé d'1 période (éviter lookahead bias)\n",
    "df_spy['position'] = df_spy['signal'].shift(1)\n",
    "\n",
    "print(\"Signaux et positions:\")\n",
    "print(df_spy[['close', 'sma_50', 'sma_200', 'signal', 'position']].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Point Crucial** : Le `.shift(1)` sur la position est essentiel pour éviter le **lookahead bias**. On prend position au jour `t` en fonction du signal calculé au jour `t-1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting Vectorisé\n",
    "\n",
    "Calculons les returns de la stratégie de manière vectorisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns de la stratégie\n",
    "df_spy['strategy_returns'] = df_spy['position'] * df_spy['returns']\n",
    "\n",
    "# Returns cumulatifs de la stratégie\n",
    "df_spy['strategy_cumulative'] = (1 + df_spy['strategy_returns']).cumprod()\n",
    "\n",
    "print(\"Returns stratégie calculés:\")\n",
    "print(df_spy[['returns', 'strategy_returns', 'cumulative_returns', 'strategy_cumulative']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison Visuelle avec Buy-and-Hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Subplot 1: Prix avec SMA\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(df_spy.index, df_spy['close'], label='SPY Close', linewidth=2, color='black', alpha=0.7)\n",
    "plt.plot(df_spy.index, df_spy['sma_50'], label='SMA 50', linewidth=1.5, color='blue', alpha=0.7)\n",
    "plt.plot(df_spy.index, df_spy['sma_200'], label='SMA 200', linewidth=1.5, color='red', alpha=0.7)\n",
    "plt.title('SPY avec SMA 50/200', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Prix ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Returns cumulatifs\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(df_spy.index, df_spy['cumulative_returns'], label='Buy & Hold', \n",
    "         linewidth=2, color='gray', alpha=0.7)\n",
    "plt.plot(df_spy.index, df_spy['strategy_cumulative'], label='SMA Crossover', \n",
    "         linewidth=2, color='darkgreen', alpha=0.9)\n",
    "plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.3)\n",
    "plt.title('Comparaison Returns Cumulatifs', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Return Cumulatif')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métriques de Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer métriques\n",
    "\n",
    "# Buy & Hold\n",
    "bh_total_return = df_spy['cumulative_returns'].iloc[-1] - 1\n",
    "bh_sharpe = (df_spy['returns'].mean() / df_spy['returns'].std()) * np.sqrt(252)\n",
    "\n",
    "# Stratégie\n",
    "strat_total_return = df_spy['strategy_cumulative'].iloc[-1] - 1\n",
    "strat_sharpe = (df_spy['strategy_returns'].mean() / df_spy['strategy_returns'].std()) * np.sqrt(252)\n",
    "\n",
    "# Max Drawdown (Buy & Hold)\n",
    "cummax_bh = df_spy['cumulative_returns'].cummax()\n",
    "drawdown_bh = (df_spy['cumulative_returns'] - cummax_bh) / cummax_bh\n",
    "max_dd_bh = drawdown_bh.min()\n",
    "\n",
    "# Max Drawdown (Stratégie)\n",
    "cummax_strat = df_spy['strategy_cumulative'].cummax()\n",
    "drawdown_strat = (df_spy['strategy_cumulative'] - cummax_strat) / cummax_strat\n",
    "max_dd_strat = drawdown_strat.min()\n",
    "\n",
    "# Affichage\n",
    "print(\"=\"*60)\n",
    "print(\"MÉTRIQUES DE PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'Métrique':<30} {'Buy & Hold':<15} {'SMA Crossover':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Return Total':<30} {bh_total_return:>13.2%} {strat_total_return:>13.2%}\")\n",
    "print(f\"{'Sharpe Ratio':<30} {bh_sharpe:>13.2f} {strat_sharpe:>13.2f}\")\n",
    "print(f\"{'Max Drawdown':<30} {max_dd_bh:>13.2%} {max_dd_strat:>13.2%}\")\n",
    "print(f\"{'Volatilité Annualisée':<30} {df_spy['returns'].std() * np.sqrt(252):>13.2%} {df_spy['strategy_returns'].std() * np.sqrt(252):>13.2%}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Nombre de trades\n",
    "position_changes = (df_spy['position'].diff() != 0).sum()\n",
    "print(f\"\\nNombre de changements de position: {position_changes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Analyse** :\n",
    "> - Le **Sharpe Ratio** mesure le return ajusté au risque (plus élevé = meilleur)\n",
    "> - Le **Max Drawdown** mesure la perte maximale depuis un pic (plus proche de 0 = meilleur)\n",
    "> - Cette stratégie SMA est un **trend-following** : performant en tendance, mais génère des faux signaux en marché latéral\n",
    "> \n",
    "> **Limitation** : Ce backtest vectorisé ne simule PAS les frais de transaction, le slippage, ou les contraintes de capital. Toujours valider avec un backtest complet QCAlgorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Utiliser shared/features.py (10 min)\n",
    "\n",
    "### Importer les Helpers\n",
    "\n",
    "Le repository CoursIA fournit des helpers réutilisables dans `shared/`. Importons-les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter shared/ au path\n",
    "import sys\n",
    "sys.path.append('../shared')\n",
    "\n",
    "# Importer helpers\n",
    "from features import calculate_returns, add_technical_features\n",
    "from backtest_helpers import calculate_metrics, format_backtest_summary\n",
    "\n",
    "print(\"Helpers importés avec succès\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer Returns Multi-Période\n",
    "\n",
    "La fonction `calculate_returns` permet de calculer des returns sur plusieurs horizons temporels en une seule ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer returns sur 1, 5, 20 jours\n",
    "returns_df = calculate_returns(df_spy['close'], periods=[1, 5, 20])\n",
    "\n",
    "print(\"Returns multi-période:\")\n",
    "print(returns_df.tail())\n",
    "\n",
    "# Merger avec df principal\n",
    "df_spy = df_spy.join(returns_df, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouter Features Techniques\n",
    "\n",
    "La fonction `add_technical_features` automatise l'ajout d'indicateurs techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter features techniques\n",
    "df_with_features = add_technical_features(\n",
    "    df_spy, \n",
    "    indicators={\n",
    "        'sma': [20, 50, 200],\n",
    "        'rsi': 14,\n",
    "        'macd': (12, 26, 9),\n",
    "        'bb': (20, 2)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Features ajoutées. Nouvelles colonnes: {df_with_features.shape[1] - df_spy.shape[1]}\")\n",
    "print(f\"\\nColonnes features:\")\n",
    "print([col for col in df_with_features.columns if col not in df_spy.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer Métriques Standardisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuler une equity curve (capital initial 100k)\n",
    "initial_capital = 100000\n",
    "equity_series = df_spy['strategy_cumulative'] * initial_capital\n",
    "benchmark_series = df_spy['cumulative_returns'] * initial_capital\n",
    "\n",
    "# Calculer métriques via helper\n",
    "metrics = calculate_metrics(equity_series, benchmark=benchmark_series)\n",
    "\n",
    "# Formatter résumé\n",
    "summary = format_backtest_summary(metrics, strategy_name=\"SMA Crossover 50/200\")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Avantage** : Les helpers `shared/` standardisent les calculs entre tous les notebooks QuantConnect. Réutilisation du code, moins d'erreurs, plus de cohérence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Transition Notebook → Algorithm (15 min)\n",
    "\n",
    "### Correspondances QuantBook → QCAlgorithm\n",
    "\n",
    "Voici comment transformer le code testé en QuantBook vers un QCAlgorithm production-ready.\n",
    "\n",
    "| Aspect | QuantBook (Recherche) | QCAlgorithm (Production) |\n",
    "|--------|----------------------|-------------------------|\n",
    "| **Setup** | `qb = QuantBook()` | `class MyAlgo(QCAlgorithm):` |\n",
    "| **Initialisation** | Pas de méthode | `def Initialize(self):` |\n",
    "| **Ajouter securities** | `qb.AddEquity(\"SPY\")` | `self.AddEquity(\"SPY\", Resolution.Daily)` |\n",
    "| **Indicateurs** | Calcul pandas (`df['sma'] = df['close'].rolling(50).mean()`) | `self.SMA(symbol, 50)` (auto-warm-up) |\n",
    "| **Historical data** | `qb.History()` → DataFrame | `self.History()` → Slice (event-driven) |\n",
    "| **Trading logic** | Vectorisé (une fois) | Event-driven (`OnData`) |\n",
    "| **Orders** | Simulation | `self.SetHoldings()`, `self.Liquidate()` |\n",
    "\n",
    "### Code Testé en QuantBook (Récapitulatif)\n",
    "\n",
    "```python\n",
    "# Dans QuantBook (ci-dessus)\n",
    "qb = QuantBook()\n",
    "spy = qb.AddEquity(\"SPY\")\n",
    "history = qb.History(qb.Securities.Keys, 252, Resolution.Daily)\n",
    "df_spy = history.loc[\"SPY\"]\n",
    "\n",
    "# Indicateurs\n",
    "df_spy['sma_50'] = df_spy['close'].rolling(50).mean()\n",
    "df_spy['sma_200'] = df_spy['close'].rolling(200).mean()\n",
    "\n",
    "# Signaux\n",
    "df_spy['signal'] = 0\n",
    "df_spy.loc[df_spy['sma_50'] > df_spy['sma_200'], 'signal'] = 1\n",
    "df_spy.loc[df_spy['sma_50'] <= df_spy['sma_200'], 'signal'] = -1\n",
    "\n",
    "# Backtest vectorisé\n",
    "df_spy['position'] = df_spy['signal'].shift(1)\n",
    "df_spy['strategy_returns'] = df_spy['position'] * df_spy['returns']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation en QCAlgorithm\n",
    "\n",
    "Voici le code équivalent pour un algorithme QuantConnect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code à copier dans un fichier .py QuantConnect\n",
    "\n",
    "from AlgorithmImports import *\n",
    "\n",
    "class SMACrossoverAlgorithm(QCAlgorithm):\n",
    "    \"\"\"\n",
    "    Stratégie SMA Crossover 50/200 testée dans QC-Py-04-Research-Workflow.ipynb\n",
    "    \n",
    "    Règles:\n",
    "    - Long quand SMA 50 > SMA 200\n",
    "    - Flat quand SMA 50 <= SMA 200\n",
    "    \"\"\"\n",
    "    \n",
    "    def Initialize(self):\n",
    "        # Configuration backtest\n",
    "        self.SetStartDate(2020, 1, 1)\n",
    "        self.SetEndDate(2023, 12, 31)\n",
    "        self.SetCash(100000)\n",
    "        \n",
    "        # Ajouter SPY\n",
    "        self.symbol = self.AddEquity(\"SPY\", Resolution.Daily).Symbol\n",
    "        \n",
    "        # Indicateurs (identiques au notebook)\n",
    "        self.sma_50 = self.SMA(self.symbol, 50)\n",
    "        self.sma_200 = self.SMA(self.symbol, 200)\n",
    "        \n",
    "        # Warm-up pour avoir les indicateurs prêts dès le début\n",
    "        self.SetWarmup(200)\n",
    "    \n",
    "    def OnData(self, data):\n",
    "        # Attendre que les indicateurs soient prêts\n",
    "        if not self.sma_50.IsReady or not self.sma_200.IsReady:\n",
    "            return\n",
    "        \n",
    "        # Logique identique au notebook (event-driven)\n",
    "        if self.sma_50.Current.Value > self.sma_200.Current.Value:\n",
    "            # Golden Cross → Long 100%\n",
    "            if not self.Portfolio.Invested:\n",
    "                self.SetHoldings(self.symbol, 1.0)\n",
    "                self.Debug(f\"{self.Time}: Golden Cross - Going Long\")\n",
    "        else:\n",
    "            # Death Cross → Liquidate\n",
    "            if self.Portfolio.Invested:\n",
    "                self.Liquidate(self.symbol)\n",
    "                self.Debug(f\"{self.Time}: Death Cross - Liquidating\")\n",
    "    \n",
    "    def OnEndOfAlgorithm(self):\n",
    "        # Résumé final\n",
    "        self.Debug(f\"Final Portfolio Value: ${self.Portfolio.TotalPortfolioValue:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points Clés de la Transition\n",
    "\n",
    "1. **Indicateurs** : `self.SMA()` remplace `df['sma'] = df['close'].rolling().mean()`\n",
    "   - Auto-warm-up avec `SetWarmup(200)`\n",
    "   - Vérifier `IsReady` avant utilisation\n",
    "\n",
    "2. **Logique de trading** : De vectorisée à event-driven\n",
    "   - `OnData()` appelé à chaque barre\n",
    "   - Condition identique : `sma_50 > sma_200`\n",
    "   - Pas de `.shift(1)` nécessaire (logique naturellement décalée)\n",
    "\n",
    "3. **Orders** : `SetHoldings()` et `Liquidate()` au lieu de simulation pandas\n",
    "\n",
    "4. **Backtest réaliste** : Frais de transaction, slippage, contraintes de capital simulés automatiquement\n",
    "\n",
    "> **Workflow recommandé** :\n",
    "> 1. Prototyper et tester la logique dans **QuantBook** (rapide, itératif)\n",
    "> 2. Convertir en **QCAlgorithm** quand la logique est validée\n",
    "> 3. Lancer un **backtest complet** pour validation finale\n",
    "> 4. Optimiser les paramètres (notebook 15)\n",
    "> 5. Déployer en **paper trading** (notebook 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Exemple Complet : Feature Engineering pour ML (10 min)\n",
    "\n",
    "### Objectif\n",
    "\n",
    "Préparer un dataset avec features pour le Machine Learning (preview du workflow du notebook QC-Py-18).\n",
    "\n",
    "### Ajouter Features Techniques Complètes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter features complètes via helper\n",
    "df_ml = add_technical_features(\n",
    "    df_spy.copy(), \n",
    "    indicators={\n",
    "        'sma': [10, 20, 50],\n",
    "        'ema': [12, 26],\n",
    "        'rsi': 14,\n",
    "        'macd': (12, 26, 9)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"DataFrame ML shape: {df_ml.shape}\")\n",
    "print(f\"\\nFeatures disponibles:\")\n",
    "print(df_ml.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer Labels (Classification Binaire)\n",
    "\n",
    "Créons des labels pour prédire la direction du mouvement à 5 jours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future returns (5 jours)\n",
    "df_ml['future_returns_5d'] = df_ml['close'].pct_change(5).shift(-5)\n",
    "\n",
    "# Labels binaires: 1 = hausse, 0 = baisse\n",
    "df_ml['label'] = (df_ml['future_returns_5d'] > 0).astype(int)\n",
    "\n",
    "print(\"Labels créés:\")\n",
    "print(df_ml[['close', 'future_returns_5d', 'label']].tail(10))\n",
    "\n",
    "# Distribution des labels\n",
    "print(f\"\\nDistribution labels:\")\n",
    "print(df_ml['label'].value_counts())\n",
    "print(f\"\\nProportion hausse: {df_ml['label'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage et Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN (dus aux rolling et shift)\n",
    "df_ml_clean = df_ml.dropna()\n",
    "\n",
    "print(f\"Dataset après nettoyage: {df_ml_clean.shape}\")\n",
    "\n",
    "# Split train/test (70/30, chronologique)\n",
    "split_idx = int(len(df_ml_clean) * 0.7)\n",
    "train_df = df_ml_clean.iloc[:split_idx]\n",
    "test_df = df_ml_clean.iloc[split_idx:]\n",
    "\n",
    "print(f\"\\nTrain size: {len(train_df)} ({len(train_df)/len(df_ml_clean):.1%})\")\n",
    "print(f\"Test size: {len(test_df)} ({len(test_df)/len(df_ml_clean):.1%})\")\n",
    "\n",
    "# Distribution labels dans train/test\n",
    "print(f\"\\nLabel distribution (train): {train_df['label'].value_counts().to_dict()}\")\n",
    "print(f\"Label distribution (test): {test_df['label'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Preview\n",
    "\n",
    "Visualisons rapidement l'importance des features avec un Random Forest simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Sélectionner features (indicateurs techniques uniquement)\n",
    "feature_cols = [col for col in df_ml_clean.columns \n",
    "                if col.startswith(('sma_', 'ema_', 'rsi', 'macd', 'bb_'))]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['label']\n",
    "\n",
    "# Entraîner Random Forest rapide\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "importances = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importances['feature'], importances['importance'], color='steelblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 features:\")\n",
    "print(importances.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder pour ML (Optionnel)\n",
    "\n",
    "Si vous utilisez LEAN CLI local, vous pouvez sauvegarder le dataset pour réutilisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder datasets (optionnel)\n",
    "# train_df.to_csv('../data/SPY_features_train.csv')\n",
    "# test_df.to_csv('../data/SPY_features_test.csv')\n",
    "\n",
    "print(\"Dataset prêt pour notebooks ML (QC-Py-18 à QC-Py-21)\")\n",
    "print(f\"\\nFeatures: {len(feature_cols)}\")\n",
    "print(f\"Samples: {len(df_ml_clean)}\")\n",
    "print(f\"Train/Test split: {len(train_df)}/{len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Lien avec QC-Py-18** : Ce workflow de feature engineering sera détaillé dans le notebook **QC-Py-18-ML-Features-Engineering** où nous couvrirons :\n",
    "> - Feature engineering avancé (lag features, rolling stats, interactions)\n",
    "> - Labeling strategies (classification, régression, multi-class)\n",
    "> - Walk-forward validation\n",
    "> - Feature selection et dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Conclusion et Prochaines Étapes\n",
    "\n",
    "### Récapitulatif\n",
    "\n",
    "Dans ce notebook, nous avons appris à :\n",
    "\n",
    "1. Utiliser **QuantBook** pour la recherche exploratoire synchrone\n",
    "2. Analyser des données avec **pandas** (returns, volatilité, distributions)\n",
    "3. Tester une stratégie SMA Crossover en mode **vectorized backtesting**\n",
    "4. Utiliser les **helpers shared/** pour standardiser les analyses\n",
    "5. **Transitionner** d'un prototype QuantBook vers un QCAlgorithm production\n",
    "6. Préparer un **dataset ML** avec feature engineering\n",
    "\n",
    "### Workflow Recherche → Production\n",
    "\n",
    "```\n",
    "1. QuantBook (Exploration)\n",
    "   ↓\n",
    "   - Analyser données\n",
    "   - Tester hypothèses\n",
    "   - Vectorized backtesting rapide\n",
    "   ↓\n",
    "2. QCAlgorithm (Implémentation)\n",
    "   ↓\n",
    "   - Convertir logique en event-driven\n",
    "   - Backtest complet avec frais/slippage\n",
    "   ↓\n",
    "3. Optimisation (Notebook 15)\n",
    "   ↓\n",
    "   - Parameter optimization\n",
    "   - Walk-forward validation\n",
    "   ↓\n",
    "4. Production (Notebook 27)\n",
    "   ↓\n",
    "   - Paper trading\n",
    "   - Live trading\n",
    "```\n",
    "\n",
    "### Points Clés à Retenir\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **QuantBook** | API synchrone pour recherche Jupyter, retourne pandas DataFrame |\n",
    "| **Vectorized Backtesting** | Rapide pour prototypage, mais ne simule pas réalisme (frais, slippage) |\n",
    "| **Lookahead Bias** | Toujours utiliser `.shift(1)` sur les signaux pour éviter de \"voir le futur\" |\n",
    "| **Transition** | QuantBook → QCAlgorithm = Vectorisé → Event-driven |\n",
    "| **Helpers shared/** | Standardiser calculs entre notebooks pour cohérence |\n",
    "\n",
    "### Limitations du Backtest Vectorisé\n",
    "\n",
    "Le backtesting vectorisé en QuantBook est utile pour le prototypage rapide, mais a des limitations :\n",
    "\n",
    "- Pas de simulation de **frais de transaction**\n",
    "- Pas de simulation de **slippage**\n",
    "- Pas de gestion du **capital** (assume toujours assez de cash)\n",
    "- Pas de **warm-up** pour les indicateurs (calculs pandas directs)\n",
    "- Risque de **lookahead bias** si `.shift()` oublié\n",
    "\n",
    "**Toujours valider avec un backtest complet QCAlgorithm avant production.**\n",
    "\n",
    "### Prochaines Étapes\n",
    "\n",
    "#### Notebook Suivant : QC-Py-05-Universe-Selection\n",
    "\n",
    "Dans le prochain notebook, nous apprendrons à :\n",
    "- Gérer des **univers dynamiques** (coarse/fine selection)\n",
    "- Filtrer par **dollar volume**, **fundamentals**\n",
    "- Rebalancer automatiquement le portfolio\n",
    "- Stratégies multi-assets\n",
    "\n",
    "#### Exercice Suggéré\n",
    "\n",
    "**Tester une stratégie RSI Mean Reversion en mode recherche** :\n",
    "\n",
    "1. Calculer RSI 14 sur SPY\n",
    "2. Règles :\n",
    "   - Long quand RSI < 30 (oversold)\n",
    "   - Short/Flat quand RSI > 70 (overbought)\n",
    "3. Backtester en mode vectorisé\n",
    "4. Comparer avec Buy & Hold\n",
    "5. Convertir en QCAlgorithm\n",
    "\n",
    "**Solution dans** : `algorithms/RSI_MeanReversion.py` (repository)\n",
    "\n",
    "### Ressources Complémentaires\n",
    "\n",
    "- [QuantConnect Research Documentation](https://www.quantconnect.com/docs/v2/research-environment)\n",
    "- [QuantBook API Reference](https://www.quantconnect.com/docs/v2/research-environment/api-reference)\n",
    "- [Pandas Time Series](https://pandas.pydata.org/docs/user_guide/timeseries.html)\n",
    "- Helpers : `shared/features.py`, `shared/backtest_helpers.py`\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook complété. Prêt pour QC-Py-05-Universe-Selection.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
