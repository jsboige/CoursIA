{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC-Py-21 - Portfolio Optimization avec Machine Learning\n",
    "\n",
    "> **De Markowitz aux methodes ML modernes pour l'allocation d'actifs**\n",
    "> Duree: 90 minutes | Niveau: Avance | Python + QuantConnect\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous serez capable de :\n",
    "\n",
    "1. Comprendre la **Modern Portfolio Theory** et ses limites\n",
    "2. Implementer l'optimisation **Mean-Variance** et la frontiere efficiente\n",
    "3. Appliquer des techniques de **shrinkage** (Ledoit-Wolf) pour la covariance\n",
    "4. Utiliser le **Machine Learning** pour predire les rendements attendus\n",
    "5. Implementer le modele **Black-Litterman** avec des vues ML\n",
    "6. Maitriser **Hierarchical Risk Parity** (HRP) pour l'allocation\n",
    "7. Integrer ces techniques dans un **Portfolio Construction Model** QuantConnect\n",
    "8. Construire une **strategie complete** ML-optimisee\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Notebooks QC-Py-01 a 20 completes\n",
    "- Comprehension des concepts de risque/rendement (QC-Py-10)\n",
    "- Notions de ML et feature engineering (QC-Py-18)\n",
    "- Familiarite avec numpy, pandas, scipy, sklearn\n",
    "\n",
    "## Structure du Notebook\n",
    "\n",
    "| Partie | Sujet | Duree |\n",
    "|--------|-------|-------|\n",
    "| 1 | Modern Portfolio Theory et Mean-Variance | 20 min |\n",
    "| 2 | Estimation de Covariance et Shrinkage | 10 min |\n",
    "| 3 | ML pour Expected Returns | 15 min |\n",
    "| 4 | Black-Litterman avec vues ML | 20 min |\n",
    "| 5 | Hierarchical Risk Parity (HRP) | 15 min |\n",
    "| 6 | Integration QuantConnect | 10 min |\n",
    "| 7 | Strategie Complete ML-Optimized | 15 min |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction : Pourquoi optimiser le portefeuille ?\n",
    "\n",
    "L'**allocation d'actifs** est responsable de 90% de la performance d'un portefeuille selon les etudes academiques. L'objectif est de trouver les **poids optimaux** pour maximiser le rendement ajuste au risque.\n",
    "\n",
    "### Evolution des approches\n",
    "\n",
    "| Epoque | Approche | Avantages | Limites |\n",
    "|--------|----------|-----------|--------|\n",
    "| 1952 | **Markowitz Mean-Variance** | Fondation theorique solide | Sensible aux estimations |\n",
    "| 1992 | **Black-Litterman** | Integre les vues de l'investisseur | Complexe a parametrer |\n",
    "| 2016 | **Hierarchical Risk Parity** | Robuste, pas d'inversion de matrice | Ignore les rendements attendus |\n",
    "| 2020+ | **ML-Enhanced** | Predictions adaptatives | Risque d'overfitting |\n",
    "\n",
    "### Pipeline d'optimisation moderne\n",
    "\n",
    "```\n",
    "Donnees Historiques\n",
    "       |\n",
    "       v\n",
    "+------------------+\n",
    "| Estimation       |\n",
    "| - Expected Returns (ML)\n",
    "| - Covariance (Shrinkage)\n",
    "+--------+---------+\n",
    "         |\n",
    "         v\n",
    "+------------------+\n",
    "| Optimisation     |\n",
    "| - Mean-Variance\n",
    "| - Black-Litterman\n",
    "| - HRP\n",
    "+--------+---------+\n",
    "         |\n",
    "         v\n",
    "   Poids Optimaux\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Sklearn pour ML et covariance\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Imports reussis!\")\n",
    "print(\"Ce notebook couvre l'optimisation de portefeuille avec ML.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des donnees de demonstration\n",
    "def generate_portfolio_data(n_assets=10, n_days=500, seed=42):\n",
    "    \"\"\"\n",
    "    Genere des donnees de prix simulees pour un portefeuille.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_assets : int\n",
    "        Nombre d'actifs\n",
    "    n_days : int\n",
    "        Nombre de jours de donnees\n",
    "    seed : int\n",
    "        Graine aleatoire\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Prix des actifs\n",
    "    pd.DataFrame : Rendements des actifs\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Noms des actifs\n",
    "    assets = [f'ASSET_{i+1}' for i in range(n_assets)]\n",
    "    \n",
    "    # Dates\n",
    "    dates = pd.date_range(start='2022-01-01', periods=n_days, freq='B')\n",
    "    \n",
    "    # Parametres par actif (drift et volatilite differents)\n",
    "    drifts = np.random.uniform(0.0001, 0.0005, n_assets)  # 2.5% - 12.5% annuel\n",
    "    vols = np.random.uniform(0.01, 0.03, n_assets)  # 16% - 48% annuel\n",
    "    \n",
    "    # Matrice de correlation (structure de bloc)\n",
    "    n_blocks = 3\n",
    "    block_size = n_assets // n_blocks\n",
    "    corr_matrix = np.eye(n_assets) * 0.3\n",
    "    \n",
    "    for b in range(n_blocks):\n",
    "        start = b * block_size\n",
    "        end = min((b + 1) * block_size, n_assets)\n",
    "        corr_matrix[start:end, start:end] = 0.6\n",
    "    \n",
    "    np.fill_diagonal(corr_matrix, 1.0)\n",
    "    \n",
    "    # Convertir correlation en covariance\n",
    "    cov_matrix = np.outer(vols, vols) * corr_matrix\n",
    "    \n",
    "    # Generer rendements correles\n",
    "    returns = np.random.multivariate_normal(drifts, cov_matrix, n_days)\n",
    "    \n",
    "    # Convertir en prix\n",
    "    prices = 100 * np.exp(np.cumsum(returns, axis=0))\n",
    "    \n",
    "    # DataFrames\n",
    "    df_prices = pd.DataFrame(prices, index=dates, columns=assets)\n",
    "    df_returns = pd.DataFrame(returns, index=dates, columns=assets)\n",
    "    \n",
    "    return df_prices, df_returns\n",
    "\n",
    "# Generer donnees\n",
    "prices, returns = generate_portfolio_data(n_assets=10, n_days=500)\n",
    "\n",
    "print(f\"Donnees generees: {len(prices)} jours, {len(prices.columns)} actifs\")\n",
    "print(f\"\\nApercu des prix:\")\n",
    "print(prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des prix\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Prix normalises (base 100)\n",
    "normalized_prices = prices / prices.iloc[0] * 100\n",
    "for col in normalized_prices.columns:\n",
    "    axes[0].plot(normalized_prices.index, normalized_prices[col], label=col, alpha=0.7)\n",
    "\n",
    "axes[0].set_title('Prix Normalises (Base 100)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Prix')\n",
    "axes[0].legend(loc='upper left', ncol=5, fontsize=8)\n",
    "\n",
    "# Correlation heatmap\n",
    "corr = returns.corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0, \n",
    "            ax=axes[1], vmin=-1, vmax=1)\n",
    "axes[1].set_title('Matrice de Correlation', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 1 : Modern Portfolio Theory et Mean-Variance (20 min)\n",
    "\n",
    "### Theorie de Markowitz (1952)\n",
    "\n",
    "Harry Markowitz a formule le probleme d'optimisation de portefeuille comme un compromis entre **rendement attendu** et **risque** (variance).\n",
    "\n",
    "### Formulation mathematique\n",
    "\n",
    "**Maximiser le Sharpe Ratio :**\n",
    "\n",
    "$$\\max_w \\frac{w^T \\mu - r_f}{\\sqrt{w^T \\Sigma w}}$$\n",
    "\n",
    "**Ou minimiser la variance pour un rendement cible :**\n",
    "\n",
    "$$\\min_w w^T \\Sigma w$$\n",
    "\n",
    "Sous contraintes :\n",
    "- $w^T \\mu = r_{target}$ (rendement cible)\n",
    "- $\\sum w_i = 1$ (poids somment a 1)\n",
    "- $w_i \\geq 0$ (pas de short, optionnel)\n",
    "\n",
    "### Notations\n",
    "\n",
    "| Symbole | Description |\n",
    "|---------|-------------|\n",
    "| $w$ | Vecteur des poids |\n",
    "| $\\mu$ | Vecteur des rendements attendus |\n",
    "| $\\Sigma$ | Matrice de covariance |\n",
    "| $r_f$ | Taux sans risque |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_variance(weights, cov_matrix):\n",
    "    \"\"\"\n",
    "    Calcule la variance du portefeuille.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weights : np.array\n",
    "        Vecteur des poids\n",
    "    cov_matrix : np.array\n",
    "        Matrice de covariance\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Variance du portefeuille\n",
    "    \"\"\"\n",
    "    return weights.T @ cov_matrix @ weights\n",
    "\n",
    "\n",
    "def portfolio_return(weights, expected_returns):\n",
    "    \"\"\"\n",
    "    Calcule le rendement attendu du portefeuille.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weights : np.array\n",
    "        Vecteur des poids\n",
    "    expected_returns : np.array\n",
    "        Vecteur des rendements attendus\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Rendement attendu\n",
    "    \"\"\"\n",
    "    return weights.T @ expected_returns\n",
    "\n",
    "\n",
    "def portfolio_volatility(weights, cov_matrix):\n",
    "    \"\"\"\n",
    "    Calcule la volatilite (ecart-type) du portefeuille.\n",
    "    \"\"\"\n",
    "    return np.sqrt(portfolio_variance(weights, cov_matrix))\n",
    "\n",
    "\n",
    "def portfolio_sharpe(weights, expected_returns, cov_matrix, risk_free_rate=0.02):\n",
    "    \"\"\"\n",
    "    Calcule le Sharpe Ratio du portefeuille.\n",
    "    \"\"\"\n",
    "    ret = portfolio_return(weights, expected_returns)\n",
    "    vol = portfolio_volatility(weights, cov_matrix)\n",
    "    return (ret - risk_free_rate) / vol if vol > 0 else 0\n",
    "\n",
    "\n",
    "# Calculer rendements et covariance historiques\n",
    "expected_returns = returns.mean().values * 252  # Annualise\n",
    "cov_matrix = returns.cov().values * 252  # Annualise\n",
    "\n",
    "print(\"Rendements attendus annualises:\")\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    print(f\"  {asset}: {expected_returns[i]:.2%}\")\n",
    "\n",
    "print(f\"\\nVolatilites annualisees:\")\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    print(f\"  {asset}: {np.sqrt(cov_matrix[i,i]):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_variance_portfolio(cov_matrix, allow_short=False):\n",
    "    \"\"\"\n",
    "    Trouve le portefeuille a variance minimale (MVP).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cov_matrix : np.array\n",
    "        Matrice de covariance\n",
    "    allow_short : bool\n",
    "        Autoriser les positions short\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array : Poids optimaux\n",
    "    \"\"\"\n",
    "    n_assets = len(cov_matrix)\n",
    "    \n",
    "    # Fonction objectif\n",
    "    def objective(w):\n",
    "        return portfolio_variance(w, cov_matrix)\n",
    "    \n",
    "    # Contrainte: somme des poids = 1\n",
    "    constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]\n",
    "    \n",
    "    # Bornes\n",
    "    if allow_short:\n",
    "        bounds = [(-1, 1) for _ in range(n_assets)]\n",
    "    else:\n",
    "        bounds = [(0, 1) for _ in range(n_assets)]\n",
    "    \n",
    "    # Poids initiaux\n",
    "    w0 = np.ones(n_assets) / n_assets\n",
    "    \n",
    "    # Optimisation\n",
    "    result = minimize(objective, w0, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    return result.x if result.success else w0\n",
    "\n",
    "\n",
    "def maximum_sharpe_portfolio(expected_returns, cov_matrix, risk_free_rate=0.02, allow_short=False):\n",
    "    \"\"\"\n",
    "    Trouve le portefeuille a Sharpe Ratio maximal (tangent portfolio).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    expected_returns : np.array\n",
    "        Rendements attendus\n",
    "    cov_matrix : np.array\n",
    "        Matrice de covariance\n",
    "    risk_free_rate : float\n",
    "        Taux sans risque\n",
    "    allow_short : bool\n",
    "        Autoriser les positions short\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array : Poids optimaux\n",
    "    \"\"\"\n",
    "    n_assets = len(expected_returns)\n",
    "    \n",
    "    # Fonction objectif (minimiser le Sharpe negatif)\n",
    "    def neg_sharpe(w):\n",
    "        return -portfolio_sharpe(w, expected_returns, cov_matrix, risk_free_rate)\n",
    "    \n",
    "    # Contrainte: somme des poids = 1\n",
    "    constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]\n",
    "    \n",
    "    # Bornes\n",
    "    if allow_short:\n",
    "        bounds = [(-1, 1) for _ in range(n_assets)]\n",
    "    else:\n",
    "        bounds = [(0, 1) for _ in range(n_assets)]\n",
    "    \n",
    "    # Poids initiaux\n",
    "    w0 = np.ones(n_assets) / n_assets\n",
    "    \n",
    "    # Optimisation\n",
    "    result = minimize(neg_sharpe, w0, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    return result.x if result.success else w0\n",
    "\n",
    "\n",
    "# Calculer les portefeuilles optimaux\n",
    "mvp_weights = minimum_variance_portfolio(cov_matrix)\n",
    "msr_weights = maximum_sharpe_portfolio(expected_returns, cov_matrix)\n",
    "\n",
    "print(\"Portefeuille a Variance Minimale (MVP):\")\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    if mvp_weights[i] > 0.01:\n",
    "        print(f\"  {asset}: {mvp_weights[i]:.1%}\")\n",
    "\n",
    "print(f\"\\n  Rendement: {portfolio_return(mvp_weights, expected_returns):.2%}\")\n",
    "print(f\"  Volatilite: {portfolio_volatility(mvp_weights, cov_matrix):.2%}\")\n",
    "print(f\"  Sharpe: {portfolio_sharpe(mvp_weights, expected_returns, cov_matrix):.2f}\")\n",
    "\n",
    "print(\"\\nPortefeuille a Sharpe Maximum (MSR):\")\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    if msr_weights[i] > 0.01:\n",
    "        print(f\"  {asset}: {msr_weights[i]:.1%}\")\n",
    "\n",
    "print(f\"\\n  Rendement: {portfolio_return(msr_weights, expected_returns):.2%}\")\n",
    "print(f\"  Volatilite: {portfolio_volatility(msr_weights, cov_matrix):.2%}\")\n",
    "print(f\"  Sharpe: {portfolio_sharpe(msr_weights, expected_returns, cov_matrix):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_frontier(expected_returns, cov_matrix, num_portfolios=50, allow_short=False):\n",
    "    \"\"\"\n",
    "    Calcule la frontiere efficiente.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    expected_returns : np.array\n",
    "        Rendements attendus\n",
    "    cov_matrix : np.array\n",
    "        Matrice de covariance\n",
    "    num_portfolios : int\n",
    "        Nombre de portefeuilles sur la frontiere\n",
    "    allow_short : bool\n",
    "        Autoriser les positions short\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Portefeuilles sur la frontiere\n",
    "    \"\"\"\n",
    "    n_assets = len(expected_returns)\n",
    "    results = []\n",
    "    \n",
    "    # Range de rendements cibles\n",
    "    min_ret = expected_returns.min()\n",
    "    max_ret = expected_returns.max()\n",
    "    target_returns = np.linspace(min_ret, max_ret, num_portfolios)\n",
    "    \n",
    "    for target_return in target_returns:\n",
    "        # Fonction objectif: minimiser variance\n",
    "        def objective(w):\n",
    "            return portfolio_variance(w, cov_matrix)\n",
    "        \n",
    "        # Contraintes\n",
    "        constraints = [\n",
    "            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1},\n",
    "            {'type': 'eq', 'fun': lambda w, tr=target_return: portfolio_return(w, expected_returns) - tr}\n",
    "        ]\n",
    "        \n",
    "        # Bornes\n",
    "        if allow_short:\n",
    "            bounds = [(-1, 1) for _ in range(n_assets)]\n",
    "        else:\n",
    "            bounds = [(0, 1) for _ in range(n_assets)]\n",
    "        \n",
    "        # Poids initiaux\n",
    "        w0 = np.ones(n_assets) / n_assets\n",
    "        \n",
    "        # Optimisation\n",
    "        result = minimize(objective, w0, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "        \n",
    "        if result.success:\n",
    "            weights = result.x\n",
    "            ret = portfolio_return(weights, expected_returns)\n",
    "            vol = portfolio_volatility(weights, cov_matrix)\n",
    "            sharpe = portfolio_sharpe(weights, expected_returns, cov_matrix)\n",
    "            \n",
    "            results.append({\n",
    "                'return': ret,\n",
    "                'volatility': vol,\n",
    "                'sharpe': sharpe,\n",
    "                'weights': weights\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Calculer la frontiere efficiente\n",
    "frontier = efficient_frontier(expected_returns, cov_matrix, num_portfolios=50)\n",
    "\n",
    "print(f\"Frontiere efficiente calculee: {len(frontier)} portefeuilles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la frontiere efficiente\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Actifs individuels\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    ax.scatter(np.sqrt(cov_matrix[i, i]) * 100, expected_returns[i] * 100, \n",
    "               s=100, marker='o', label=asset, alpha=0.7)\n",
    "\n",
    "# Frontiere efficiente\n",
    "ax.plot(frontier['volatility'] * 100, frontier['return'] * 100, \n",
    "        'b-', linewidth=3, label='Frontiere Efficiente')\n",
    "\n",
    "# Portefeuille equipondere\n",
    "eq_weights = np.ones(len(expected_returns)) / len(expected_returns)\n",
    "eq_ret = portfolio_return(eq_weights, expected_returns) * 100\n",
    "eq_vol = portfolio_volatility(eq_weights, cov_matrix) * 100\n",
    "ax.scatter(eq_vol, eq_ret, s=200, marker='s', color='gray', \n",
    "           label=f'Equal Weight (Sharpe: {portfolio_sharpe(eq_weights, expected_returns, cov_matrix):.2f})', zorder=5)\n",
    "\n",
    "# MVP\n",
    "mvp_ret = portfolio_return(mvp_weights, expected_returns) * 100\n",
    "mvp_vol = portfolio_volatility(mvp_weights, cov_matrix) * 100\n",
    "ax.scatter(mvp_vol, mvp_ret, s=200, marker='*', color='green', \n",
    "           label=f'Min Variance (Sharpe: {portfolio_sharpe(mvp_weights, expected_returns, cov_matrix):.2f})', zorder=5)\n",
    "\n",
    "# MSR\n",
    "msr_ret = portfolio_return(msr_weights, expected_returns) * 100\n",
    "msr_vol = portfolio_volatility(msr_weights, cov_matrix) * 100\n",
    "ax.scatter(msr_vol, msr_ret, s=200, marker='*', color='red', \n",
    "           label=f'Max Sharpe (Sharpe: {portfolio_sharpe(msr_weights, expected_returns, cov_matrix):.2f})', zorder=5)\n",
    "\n",
    "ax.set_xlabel('Volatilite (%)', fontsize=12)\n",
    "ax.set_ylabel('Rendement Attendu (%)', fontsize=12)\n",
    "ax.set_title('Frontiere Efficiente de Markowitz', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limites de Mean-Variance\n",
    "\n",
    "| Probleme | Description | Impact |\n",
    "|----------|-------------|--------|\n",
    "| **Estimation error** | Les rendements attendus sont tres bruyants | Portefeuilles concentres, instables |\n",
    "| **Matrice mal conditionnee** | Avec peu de donnees, la covariance est mal estimee | Poids extremes |\n",
    "| **Sensibilite aux inputs** | Petits changements -> grands changements de poids | Turnover eleve |\n",
    "| **In-sample overfitting** | Optimise sur le passe, pas le futur | Sous-performance out-of-sample |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 2 : Estimation de Covariance et Shrinkage (10 min)\n",
    "\n",
    "### Le probleme de l'estimation\n",
    "\n",
    "La matrice de covariance **echantillon** est un estimateur non-biaise mais **haute variance**. Avec $N$ actifs et $T$ observations :\n",
    "\n",
    "- Si $T < N$ : La matrice est **singuliere** (non inversible)\n",
    "- Si $T \\approx N$ : La matrice est **mal conditionnee**\n",
    "- Meme si $T >> N$ : Forte erreur d'estimation\n",
    "\n",
    "### Solution : Shrinkage (Ledoit-Wolf)\n",
    "\n",
    "L'idee est de \"contracter\" la matrice echantillon vers une matrice cible plus stable :\n",
    "\n",
    "$$\\Sigma_{shrunk} = (1-\\alpha) \\times \\Sigma_{sample} + \\alpha \\times \\Sigma_{target}$$\n",
    "\n",
    "La cible est souvent la **matrice identite** (actifs non correles) ou une **matrice a correlation constante**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_covariance_estimators(returns_df):\n",
    "    \"\"\"\n",
    "    Compare la covariance echantillon vs Ledoit-Wolf.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns_df : pd.DataFrame\n",
    "        DataFrame des rendements\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (cov_sample, cov_shrunk, shrinkage_coef)\n",
    "    \"\"\"\n",
    "    # Covariance echantillon\n",
    "    cov_sample = returns_df.cov().values * 252\n",
    "    \n",
    "    # Covariance Ledoit-Wolf\n",
    "    lw = LedoitWolf()\n",
    "    lw.fit(returns_df.values)\n",
    "    cov_shrunk = lw.covariance_ * 252\n",
    "    shrinkage_coef = lw.shrinkage_\n",
    "    \n",
    "    return cov_sample, cov_shrunk, shrinkage_coef\n",
    "\n",
    "# Comparer les estimateurs\n",
    "cov_sample, cov_shrunk, shrinkage = compare_covariance_estimators(returns)\n",
    "\n",
    "print(f\"Coefficient de shrinkage: {shrinkage:.3f}\")\n",
    "print(f\"  (0 = covariance echantillon pure)\")\n",
    "print(f\"  (1 = matrice cible pure)\")\n",
    "\n",
    "# Comparer les condition numbers\n",
    "cond_sample = np.linalg.cond(cov_sample)\n",
    "cond_shrunk = np.linalg.cond(cov_shrunk)\n",
    "\n",
    "print(f\"\\nCondition Number (mesure de stabilite):\")\n",
    "print(f\"  Sample: {cond_sample:.1f}\")\n",
    "print(f\"  Shrunk: {cond_shrunk:.1f}\")\n",
    "print(f\"  Reduction: {(1 - cond_shrunk/cond_sample)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'effet du shrinkage\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Covariance echantillon\n",
    "im1 = axes[0].imshow(cov_sample, cmap='RdBu_r', aspect='auto')\n",
    "axes[0].set_title('Covariance Echantillon', fontsize=12, fontweight='bold')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Covariance shrunk\n",
    "im2 = axes[1].imshow(cov_shrunk, cmap='RdBu_r', aspect='auto')\n",
    "axes[1].set_title(f'Covariance Shrunk (alpha={shrinkage:.2f})', fontsize=12, fontweight='bold')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Difference\n",
    "diff = cov_sample - cov_shrunk\n",
    "im3 = axes[2].imshow(diff, cmap='RdBu_r', aspect='auto')\n",
    "axes[2].set_title('Difference (Sample - Shrunk)', fontsize=12, fontweight='bold')\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparer les portefeuilles optimaux\n",
    "print(\"\\nComparaison des portefeuilles Max Sharpe:\")\n",
    "\n",
    "msr_sample = maximum_sharpe_portfolio(expected_returns, cov_sample)\n",
    "msr_shrunk = maximum_sharpe_portfolio(expected_returns, cov_shrunk)\n",
    "\n",
    "print(f\"\\n{'Actif':<12} {'Sample':>10} {'Shrunk':>10} {'Diff':>10}\")\n",
    "print(\"-\" * 45)\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    print(f\"{asset:<12} {msr_sample[i]:>9.1%} {msr_shrunk[i]:>9.1%} {msr_shrunk[i]-msr_sample[i]:>9.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 3 : ML pour Expected Returns (15 min)\n",
    "\n",
    "### Pourquoi utiliser le ML ?\n",
    "\n",
    "L'estimation naive des rendements attendus (moyenne historique) est tres bruyante. Le ML permet de :\n",
    "\n",
    "1. **Incorporer des features predictives** (momentum, valuation, sentiment)\n",
    "2. **Capturer des relations non-lineaires**\n",
    "3. **S'adapter aux changements de regime**\n",
    "\n",
    "### Approche\n",
    "\n",
    "```\n",
    "Features (X)          Model           Expected Returns (y)\n",
    "- Momentum        ->  Random Forest  ->  Prediction rendement\n",
    "- Volatilite         XGBoost           prochain mois\n",
    "- RSI                Neural Net\n",
    "- Valuation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_for_returns(prices_df, lookback=20):\n",
    "    \"\"\"\n",
    "    Cree des features pour predire les rendements futurs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prices_df : pd.DataFrame\n",
    "        DataFrame des prix\n",
    "    lookback : int\n",
    "        Periode de lookback pour les features\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Features par actif et par date\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    for asset in prices_df.columns:\n",
    "        prices = prices_df[asset]\n",
    "        returns = prices.pct_change()\n",
    "        \n",
    "        # Features\n",
    "        df_feat = pd.DataFrame(index=prices_df.index)\n",
    "        df_feat['asset'] = asset\n",
    "        \n",
    "        # Momentum (rendements passes)\n",
    "        df_feat['return_1d'] = returns\n",
    "        df_feat['return_5d'] = returns.rolling(5).sum()\n",
    "        df_feat['return_20d'] = returns.rolling(20).sum()\n",
    "        \n",
    "        # Volatilite\n",
    "        df_feat['volatility_20d'] = returns.rolling(20).std()\n",
    "        \n",
    "        # Mean reversion (distance a la moyenne)\n",
    "        sma_20 = prices.rolling(20).mean()\n",
    "        df_feat['price_to_sma'] = prices / sma_20 - 1\n",
    "        \n",
    "        # Skewness et Kurtosis\n",
    "        df_feat['skewness'] = returns.rolling(20).skew()\n",
    "        df_feat['kurtosis'] = returns.rolling(20).kurt()\n",
    "        \n",
    "        # Target: rendement futur sur 20 jours\n",
    "        df_feat['future_return_20d'] = returns.shift(-20).rolling(20).sum()\n",
    "        \n",
    "        features_list.append(df_feat)\n",
    "    \n",
    "    features_df = pd.concat(features_list)\n",
    "    features_df = features_df.dropna()\n",
    "    \n",
    "    return features_df\n",
    "\n",
    "# Creer les features\n",
    "features_df = create_features_for_returns(prices)\n",
    "\n",
    "print(f\"Features creees: {len(features_df)} observations\")\n",
    "print(f\"\\nColonnes:\")\n",
    "print(features_df.columns.tolist())\n",
    "print(f\"\\nApercu:\")\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_returns_ml(features_df, model_type='random_forest'):\n",
    "    \"\"\"\n",
    "    Entraine un modele ML pour predire les rendements.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame avec features et target\n",
    "    model_type : str\n",
    "        Type de modele ('random_forest')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Rendements predits par actif\n",
    "    \"\"\"\n",
    "    feature_cols = ['return_1d', 'return_5d', 'return_20d', 'volatility_20d', \n",
    "                    'price_to_sma', 'skewness', 'kurtosis']\n",
    "    \n",
    "    # Separer features et target\n",
    "    X = features_df[feature_cols]\n",
    "    y = features_df['future_return_20d']\n",
    "    \n",
    "    # Train/Test split temporel (80/20)\n",
    "    split_idx = int(len(X) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    \n",
    "    # Normalisation\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Modele\n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions sur les dernieres observations\n",
    "    predictions = {}\n",
    "    last_features = features_df.groupby('asset').last()[feature_cols]\n",
    "    last_scaled = scaler.transform(last_features)\n",
    "    \n",
    "    for i, asset in enumerate(last_features.index):\n",
    "        pred = model.predict(last_scaled[i:i+1])[0]\n",
    "        predictions[asset] = pred * 12  # Annualiser (20 jours -> annuel)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score = model.score(X_train_scaled, y_train)\n",
    "    test_score = model.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Feature importance\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return predictions, {'train_r2': train_score, 'test_r2': test_score}, importance\n",
    "\n",
    "# Predire les rendements\n",
    "ml_returns, scores, importance = predict_returns_ml(features_df)\n",
    "\n",
    "print(\"Rendements Predits par ML (annualises):\")\n",
    "for asset, ret in sorted(ml_returns.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {asset}: {ret:.2%}\")\n",
    "\n",
    "print(f\"\\nScores du modele:\")\n",
    "print(f\"  R2 Train: {scores['train_r2']:.3f}\")\n",
    "print(f\"  R2 Test: {scores['test_r2']:.3f}\")\n",
    "\n",
    "print(f\"\\nFeature Importance:\")\n",
    "print(importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les rendements historiques vs ML\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "assets = list(returns.columns)\n",
    "hist_returns = [expected_returns[i] for i in range(len(assets))]\n",
    "ml_returns_list = [ml_returns[a] for a in assets]\n",
    "\n",
    "x = np.arange(len(assets))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, [r*100 for r in hist_returns], width, label='Historique', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, [r*100 for r in ml_returns_list], width, label='ML Prediction', color='coral')\n",
    "\n",
    "ax.set_xlabel('Actif', fontsize=12)\n",
    "ax.set_ylabel('Rendement Attendu (%)', fontsize=12)\n",
    "ax.set_title('Rendements Attendus: Historique vs ML', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(assets, rotation=45)\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 4 : Black-Litterman avec vues ML (20 min)\n",
    "\n",
    "### Le modele Black-Litterman\n",
    "\n",
    "Le modele **Black-Litterman** (1992) combine :\n",
    "\n",
    "1. **Prior** : Rendements d'equilibre du marche (derives des poids de marche)\n",
    "2. **Views** : Vues de l'investisseur sur certains actifs\n",
    "\n",
    "Cela produit des **rendements posterieurs** plus stables que l'optimisation classique.\n",
    "\n",
    "### Formulation\n",
    "\n",
    "**Prior (equilibre):**\n",
    "$$\\pi = \\delta \\Sigma w_{mkt}$$\n",
    "\n",
    "**Posterior:**\n",
    "$$E[R] = [(\\tau\\Sigma)^{-1} + P'\\Omega^{-1}P]^{-1} [(\\tau\\Sigma)^{-1}\\pi + P'\\Omega^{-1}Q]$$\n",
    "\n",
    "Ou:\n",
    "- $\\pi$ : Rendements d'equilibre\n",
    "- $P$ : Matrice des vues (quels actifs)\n",
    "- $Q$ : Vecteur des vues (rendements attendus)\n",
    "- $\\Omega$ : Incertitude sur les vues\n",
    "- $\\tau$ : Scaling factor (~0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_litterman(\n",
    "    market_cap_weights,\n",
    "    sigma,\n",
    "    P,\n",
    "    Q,\n",
    "    omega,\n",
    "    tau=0.05,\n",
    "    risk_aversion=2.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Implemente le modele Black-Litterman.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_cap_weights : np.array\n",
    "        Poids de capitalisation de marche\n",
    "    sigma : np.array\n",
    "        Matrice de covariance\n",
    "    P : np.array\n",
    "        Matrice des vues (K x N)\n",
    "    Q : np.array\n",
    "        Vecteur des vues (K x 1)\n",
    "    omega : np.array\n",
    "        Matrice d'incertitude des vues (K x K)\n",
    "    tau : float\n",
    "        Scaling factor pour la covariance\n",
    "    risk_aversion : float\n",
    "        Coefficient d'aversion au risque\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array : Rendements posterieurs\n",
    "    \"\"\"\n",
    "    # Prior: rendements d'equilibre\n",
    "    pi = risk_aversion * sigma @ market_cap_weights\n",
    "    \n",
    "    # Matrice de covariance scalee\n",
    "    tau_sigma = tau * sigma\n",
    "    tau_sigma_inv = np.linalg.inv(tau_sigma)\n",
    "    \n",
    "    # Inverse de omega\n",
    "    omega_inv = np.linalg.inv(omega)\n",
    "    \n",
    "    # Posterior covariance\n",
    "    M = np.linalg.inv(tau_sigma_inv + P.T @ omega_inv @ P)\n",
    "    \n",
    "    # Posterior returns\n",
    "    posterior_returns = M @ (tau_sigma_inv @ pi + P.T @ omega_inv @ Q)\n",
    "    \n",
    "    return posterior_returns, pi\n",
    "\n",
    "\n",
    "def create_ml_views(ml_predictions, confidence_scaling=0.5):\n",
    "    \"\"\"\n",
    "    Cree des vues Black-Litterman a partir des predictions ML.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ml_predictions : dict\n",
    "        Predictions ML par actif\n",
    "    confidence_scaling : float\n",
    "        Factor pour l'incertitude (plus eleve = moins confiant)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (P, Q, omega)\n",
    "    \"\"\"\n",
    "    n_assets = len(ml_predictions)\n",
    "    assets = list(ml_predictions.keys())\n",
    "    \n",
    "    # Matrice des vues (identite = une vue par actif)\n",
    "    P = np.eye(n_assets)\n",
    "    \n",
    "    # Vecteur des vues\n",
    "    Q = np.array([ml_predictions[a] for a in assets])\n",
    "    \n",
    "    # Incertitude: proportionnelle a l'ecart-type des predictions\n",
    "    # Plus simple: diagonale avec variance proportionnelle a |Q|\n",
    "    uncertainties = confidence_scaling * np.abs(Q) + 0.01  # Minimum 1%\n",
    "    omega = np.diag(uncertainties ** 2)\n",
    "    \n",
    "    return P, Q, omega, assets\n",
    "\n",
    "# Poids de marche simules (equal weight comme proxy)\n",
    "market_weights = np.ones(len(returns.columns)) / len(returns.columns)\n",
    "\n",
    "# Creer les vues ML\n",
    "P, Q, omega, assets = create_ml_views(ml_returns, confidence_scaling=0.3)\n",
    "\n",
    "print(\"Vues ML (Q):\")\n",
    "for i, asset in enumerate(assets):\n",
    "    print(f\"  {asset}: {Q[i]:.2%} (incertitude: {np.sqrt(omega[i,i]):.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer Black-Litterman\n",
    "posterior_returns, equilibrium_returns = black_litterman(\n",
    "    market_weights,\n",
    "    cov_shrunk,\n",
    "    P,\n",
    "    Q,\n",
    "    omega,\n",
    "    tau=0.05\n",
    ")\n",
    "\n",
    "print(\"Comparaison des rendements:\")\n",
    "print(f\"\\n{'Actif':<12} {'Equilibre':>12} {'ML View':>12} {'Posterior':>12}\")\n",
    "print(\"-\" * 50)\n",
    "for i, asset in enumerate(assets):\n",
    "    print(f\"{asset:<12} {equilibrium_returns[i]:>11.2%} {Q[i]:>11.2%} {posterior_returns[i]:>11.2%}\")\n",
    "\n",
    "# Optimiser avec les rendements posterieurs\n",
    "bl_weights = maximum_sharpe_portfolio(posterior_returns, cov_shrunk)\n",
    "\n",
    "print(\"\\nPortefeuille Black-Litterman:\")\n",
    "for i, asset in enumerate(assets):\n",
    "    if bl_weights[i] > 0.01:\n",
    "        print(f\"  {asset}: {bl_weights[i]:.1%}\")\n",
    "\n",
    "print(f\"\\n  Rendement attendu: {portfolio_return(bl_weights, posterior_returns):.2%}\")\n",
    "print(f\"  Volatilite: {portfolio_volatility(bl_weights, cov_shrunk):.2%}\")\n",
    "print(f\"  Sharpe: {portfolio_sharpe(bl_weights, posterior_returns, cov_shrunk):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation Black-Litterman\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Rendements\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(assets))\n",
    "width = 0.25\n",
    "\n",
    "ax1.bar(x - width, equilibrium_returns * 100, width, label='Equilibre', color='steelblue')\n",
    "ax1.bar(x, Q * 100, width, label='ML Views', color='coral')\n",
    "ax1.bar(x + width, posterior_returns * 100, width, label='Posterior BL', color='green')\n",
    "\n",
    "ax1.set_xlabel('Actif')\n",
    "ax1.set_ylabel('Rendement (%)')\n",
    "ax1.set_title('Black-Litterman: Rendements', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(assets, rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Poids\n",
    "ax2 = axes[1]\n",
    "eq_weights = np.ones(len(assets)) / len(assets)\n",
    "mv_weights = maximum_sharpe_portfolio(expected_returns, cov_shrunk)\n",
    "\n",
    "ax2.bar(x - width, eq_weights * 100, width, label='Equal Weight', color='gray')\n",
    "ax2.bar(x, mv_weights * 100, width, label='Mean-Variance', color='orange')\n",
    "ax2.bar(x + width, bl_weights * 100, width, label='Black-Litterman', color='green')\n",
    "\n",
    "ax2.set_xlabel('Actif')\n",
    "ax2.set_ylabel('Poids (%)')\n",
    "ax2.set_title('Comparaison des Allocations', fontsize=12, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(assets, rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 5 : Hierarchical Risk Parity (HRP) (15 min)\n",
    "\n",
    "### Probleme de Mean-Variance\n",
    "\n",
    "L'optimisation Mean-Variance necessite l'**inversion de la matrice de covariance**, qui est instable avec :\n",
    "- Peu de donnees\n",
    "- Beaucoup d'actifs\n",
    "- Actifs fortement correles\n",
    "\n",
    "### Solution : HRP (Lopez de Prado, 2016)\n",
    "\n",
    "HRP utilise le **clustering hierarchique** pour allouer le risque sans inverser la matrice :\n",
    "\n",
    "```\n",
    "1. Clustering           2. Quasi-Diagonalization     3. Recursive Bisection\n",
    "   |                       |                             |\n",
    "   Corrélation  -->        Réordonne actifs   -->        Alloue inversement\n",
    "   distance                par clusters                  à la variance\n",
    "```\n",
    "\n",
    "### Avantages de HRP\n",
    "\n",
    "| Aspect | Mean-Variance | HRP |\n",
    "|--------|---------------|-----|\n",
    "| Inversion matrice | Requise | Non requise |\n",
    "| Stabilite | Instable | Stable |\n",
    "| Concentration | Elevee | Diversifiee |\n",
    "| Rendements attendus | Requis | Non utilises |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_risk_parity(returns_df):\n",
    "    \"\"\"\n",
    "    Implemente Hierarchical Risk Parity.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns_df : pd.DataFrame\n",
    "        DataFrame des rendements\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array : Poids HRP\n",
    "    linkage_matrix : Matrice de linkage pour visualisation\n",
    "    \"\"\"\n",
    "    # 1. Calculer la matrice de correlation\n",
    "    corr = returns_df.corr()\n",
    "    \n",
    "    # 2. Convertir correlation en distance\n",
    "    # Distance = sqrt((1 - correlation) / 2)\n",
    "    dist = np.sqrt((1 - corr) / 2)\n",
    "    \n",
    "    # 3. Clustering hierarchique\n",
    "    dist_condensed = squareform(dist.values)\n",
    "    link = linkage(dist_condensed, method='ward')\n",
    "    \n",
    "    # 4. Quasi-diagonalization (reordonner les actifs)\n",
    "    # Obtenir l'ordre des feuilles du dendrogramme\n",
    "    from scipy.cluster.hierarchy import leaves_list\n",
    "    sorted_idx = leaves_list(link)\n",
    "    sorted_assets = [returns_df.columns[i] for i in sorted_idx]\n",
    "    \n",
    "    # 5. Recursive bisection\n",
    "    cov = returns_df.cov()\n",
    "    weights = _recursive_bisection(cov, sorted_idx)\n",
    "    \n",
    "    # Remettre dans l'ordre original\n",
    "    final_weights = np.zeros(len(returns_df.columns))\n",
    "    for i, idx in enumerate(sorted_idx):\n",
    "        final_weights[idx] = weights[i]\n",
    "    \n",
    "    return final_weights, link, sorted_assets\n",
    "\n",
    "\n",
    "def _recursive_bisection(cov, sorted_idx):\n",
    "    \"\"\"\n",
    "    Recursive bisection pour HRP.\n",
    "    Alloue les poids inversement a la variance dans chaque cluster.\n",
    "    \"\"\"\n",
    "    n = len(sorted_idx)\n",
    "    weights = np.ones(n)\n",
    "    \n",
    "    # Queue des clusters a traiter\n",
    "    clusters = [list(range(n))]\n",
    "    \n",
    "    while len(clusters) > 0:\n",
    "        cluster = clusters.pop(0)\n",
    "        \n",
    "        if len(cluster) == 1:\n",
    "            continue\n",
    "        \n",
    "        # Diviser en deux moities\n",
    "        mid = len(cluster) // 2\n",
    "        left_cluster = cluster[:mid]\n",
    "        right_cluster = cluster[mid:]\n",
    "        \n",
    "        # Calculer la variance de chaque sous-cluster\n",
    "        left_idx = [sorted_idx[i] for i in left_cluster]\n",
    "        right_idx = [sorted_idx[i] for i in right_cluster]\n",
    "        \n",
    "        left_var = _cluster_variance(cov.values, left_idx)\n",
    "        right_var = _cluster_variance(cov.values, right_idx)\n",
    "        \n",
    "        # Allouer inversement a la variance\n",
    "        total_var = left_var + right_var\n",
    "        alpha = 1 - left_var / total_var if total_var > 0 else 0.5\n",
    "        \n",
    "        # Ajuster les poids\n",
    "        for i in left_cluster:\n",
    "            weights[i] *= alpha\n",
    "        for i in right_cluster:\n",
    "            weights[i] *= (1 - alpha)\n",
    "        \n",
    "        # Ajouter les sous-clusters a traiter\n",
    "        if len(left_cluster) > 1:\n",
    "            clusters.append(left_cluster)\n",
    "        if len(right_cluster) > 1:\n",
    "            clusters.append(right_cluster)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "\n",
    "def _cluster_variance(cov, indices):\n",
    "    \"\"\"\n",
    "    Calcule la variance d'un cluster (inverse volatilite portfolio).\n",
    "    \"\"\"\n",
    "    cov_sub = cov[np.ix_(indices, indices)]\n",
    "    inv_var = 1 / np.diag(cov_sub)\n",
    "    weights = inv_var / inv_var.sum()\n",
    "    return weights @ cov_sub @ weights\n",
    "\n",
    "\n",
    "# Appliquer HRP\n",
    "hrp_weights, linkage_matrix, sorted_assets = hierarchical_risk_parity(returns)\n",
    "\n",
    "print(\"Portefeuille HRP:\")\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    print(f\"  {asset}: {hrp_weights[i]:.1%}\")\n",
    "\n",
    "print(f\"\\n  Rendement attendu: {portfolio_return(hrp_weights, expected_returns):.2%}\")\n",
    "print(f\"  Volatilite: {portfolio_volatility(hrp_weights, cov_shrunk):.2%}\")\n",
    "print(f\"  Sharpe: {portfolio_sharpe(hrp_weights, expected_returns, cov_shrunk):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation HRP\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Dendrogramme\n",
    "ax1 = axes[0]\n",
    "dendrogram(linkage_matrix, labels=list(returns.columns), ax=ax1, leaf_rotation=45)\n",
    "ax1.set_title('Dendrogramme - Clustering Hierarchique', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Actif')\n",
    "ax1.set_ylabel('Distance')\n",
    "\n",
    "# Comparaison des poids\n",
    "ax2 = axes[1]\n",
    "x = np.arange(len(returns.columns))\n",
    "width = 0.2\n",
    "\n",
    "eq_w = np.ones(len(returns.columns)) / len(returns.columns)\n",
    "mvp_w = minimum_variance_portfolio(cov_shrunk)\n",
    "\n",
    "ax2.bar(x - width*1.5, eq_w * 100, width, label='Equal Weight', color='gray')\n",
    "ax2.bar(x - width/2, mvp_w * 100, width, label='Min Variance', color='steelblue')\n",
    "ax2.bar(x + width/2, bl_weights * 100, width, label='Black-Litterman', color='coral')\n",
    "ax2.bar(x + width*1.5, hrp_weights * 100, width, label='HRP', color='green')\n",
    "\n",
    "ax2.set_xlabel('Actif')\n",
    "ax2.set_ylabel('Poids (%)')\n",
    "ax2.set_title('Comparaison des Methodes d\\'Allocation', fontsize=12, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(returns.columns, rotation=45)\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 6 : Integration QuantConnect (10 min)\n",
    "\n",
    "### ML-Enhanced Portfolio Construction Model\n",
    "\n",
    "Integrons les techniques vues dans un **Portfolio Construction Model** QuantConnect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code QuantConnect pour ML Portfolio Construction\n",
    "# A copier dans l'IDE QuantConnect\n",
    "\n",
    "qc_ml_portfolio_code = '''\n",
    "from AlgorithmImports import *\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MLPortfolioConstructionModel(PortfolioConstructionModel):\n",
    "    \"\"\"\n",
    "    Portfolio Construction Model avec optimisation ML.\n",
    "    \n",
    "    Combine:\n",
    "    - Ledoit-Wolf pour la covariance\n",
    "    - Random Forest pour les expected returns\n",
    "    - Mean-Variance ou HRP pour l'allocation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 rebalance_days=30,\n",
    "                 lookback_days=252,\n",
    "                 method='mean_variance',\n",
    "                 use_ml_returns=True):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        rebalance_days : int\n",
    "            Jours entre chaque rebalancement\n",
    "        lookback_days : int\n",
    "            Jours d'historique pour les calculs\n",
    "        method : str\n",
    "            'mean_variance', 'hrp', ou 'black_litterman'\n",
    "        use_ml_returns : bool\n",
    "            Utiliser ML pour predire les rendements\n",
    "        \"\"\"\n",
    "        self.rebalance_days = rebalance_days\n",
    "        self.lookback_days = lookback_days\n",
    "        self.method = method\n",
    "        self.use_ml_returns = use_ml_returns\n",
    "        self.last_rebalance = datetime.min\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "    \n",
    "    def CreateTargets(self, algorithm, insights):\n",
    "        \"\"\"\n",
    "        Cree les PortfolioTargets avec optimisation ML.\n",
    "        \"\"\"\n",
    "        targets = []\n",
    "        \n",
    "        # Verifier rebalancement\n",
    "        if (algorithm.Time - self.last_rebalance).days < self.rebalance_days:\n",
    "            return targets\n",
    "        \n",
    "        self.last_rebalance = algorithm.Time\n",
    "        \n",
    "        # Filtrer insights actifs\n",
    "        active_insights = [i for i in insights \n",
    "                          if i.Direction != InsightDirection.Flat]\n",
    "        \n",
    "        if len(active_insights) < 2:\n",
    "            return targets\n",
    "        \n",
    "        symbols = [i.Symbol for i in active_insights]\n",
    "        \n",
    "        # Recuperer historique\n",
    "        history = algorithm.History(symbols, self.lookback_days, Resolution.Daily)\n",
    "        \n",
    "        if history.empty:\n",
    "            return targets\n",
    "        \n",
    "        try:\n",
    "            # Calculer returns\n",
    "            returns = history['close'].unstack(level=0).pct_change().dropna()\n",
    "            \n",
    "            if len(returns) < 60:\n",
    "                return targets\n",
    "            \n",
    "            # Covariance Ledoit-Wolf\n",
    "            lw = LedoitWolf()\n",
    "            cov_matrix = lw.fit(returns).covariance_ * 252\n",
    "            \n",
    "            # Expected returns\n",
    "            if self.use_ml_returns:\n",
    "                expected_returns = self._predict_returns_ml(returns, algorithm)\n",
    "            else:\n",
    "                expected_returns = returns.mean().values * 252\n",
    "            \n",
    "            # Optimiser\n",
    "            if self.method == 'mean_variance':\n",
    "                weights = self._mean_variance_optimize(expected_returns, cov_matrix)\n",
    "            elif self.method == 'hrp':\n",
    "                weights = self._hrp_optimize(returns)\n",
    "            else:\n",
    "                weights = np.ones(len(symbols)) / len(symbols)\n",
    "            \n",
    "            # Creer targets\n",
    "            for i, symbol in enumerate(symbols):\n",
    "                if weights[i] > 0.01:  # Minimum 1%\n",
    "                    targets.append(PortfolioTarget(symbol, weights[i]))\n",
    "            \n",
    "            algorithm.Debug(f\"ML Portfolio: {len(targets)} targets\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            algorithm.Debug(f\"Error in ML Portfolio: {e}\")\n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def _predict_returns_ml(self, returns, algorithm):\n",
    "        \"\"\"\n",
    "        Predit les rendements avec Random Forest.\n",
    "        \"\"\"\n",
    "        predicted = []\n",
    "        \n",
    "        for col in returns.columns:\n",
    "            # Features simples\n",
    "            ret = returns[col]\n",
    "            features = pd.DataFrame({\n",
    "                'mom_5': ret.rolling(5).sum(),\n",
    "                'mom_20': ret.rolling(20).sum(),\n",
    "                'vol_20': ret.rolling(20).std(),\n",
    "            }).dropna()\n",
    "            \n",
    "            target = ret.shift(-20).rolling(20).sum()\n",
    "            \n",
    "            # Aligner\n",
    "            df = pd.concat([features, target.rename('target')], axis=1).dropna()\n",
    "            \n",
    "            if len(df) < 50:\n",
    "                predicted.append(ret.mean() * 252)\n",
    "                continue\n",
    "            \n",
    "            X = df[['mom_5', 'mom_20', 'vol_20']].values\n",
    "            y = df['target'].values\n",
    "            \n",
    "            # Train sur 80%\n",
    "            split = int(len(X) * 0.8)\n",
    "            \n",
    "            model = RandomForestRegressor(n_estimators=50, max_depth=3, random_state=42)\n",
    "            model.fit(X[:split], y[:split])\n",
    "            \n",
    "            # Predire avec derniere observation\n",
    "            pred = model.predict(X[-1:])[0] * 12  # Annualiser\n",
    "            predicted.append(pred)\n",
    "        \n",
    "        return np.array(predicted)\n",
    "    \n",
    "    def _mean_variance_optimize(self, expected_returns, cov_matrix):\n",
    "        \"\"\"\n",
    "        Optimisation Mean-Variance (Max Sharpe).\n",
    "        \"\"\"\n",
    "        n = len(expected_returns)\n",
    "        \n",
    "        def neg_sharpe(w):\n",
    "            ret = w @ expected_returns\n",
    "            vol = np.sqrt(w @ cov_matrix @ w)\n",
    "            return -(ret - 0.02) / vol if vol > 0 else 0\n",
    "        \n",
    "        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]\n",
    "        bounds = [(0, 0.25) for _ in range(n)]  # Max 25% par actif\n",
    "        w0 = np.ones(n) / n\n",
    "        \n",
    "        result = minimize(neg_sharpe, w0, method='SLSQP', \n",
    "                         bounds=bounds, constraints=constraints)\n",
    "        \n",
    "        return result.x if result.success else w0\n",
    "    \n",
    "    def _hrp_optimize(self, returns):\n",
    "        \"\"\"\n",
    "        Hierarchical Risk Parity.\n",
    "        \"\"\"\n",
    "        cov = returns.cov()\n",
    "        inv_var = 1 / np.diag(cov)\n",
    "        weights = inv_var / inv_var.sum()\n",
    "        return weights\n",
    "    \n",
    "    def OnSecuritiesChanged(self, algorithm, changes):\n",
    "        for security in changes.RemovedSecurities:\n",
    "            if security.Invested:\n",
    "                algorithm.Liquidate(security.Symbol)\n",
    "'''\n",
    "\n",
    "print(\"MLPortfolioConstructionModel defini\")\n",
    "print(\"\\nCaracteristiques:\")\n",
    "print(\"  - Covariance: Ledoit-Wolf Shrinkage\")\n",
    "print(\"  - Expected Returns: Random Forest (optionnel)\")\n",
    "print(\"  - Optimisation: Mean-Variance ou HRP\")\n",
    "print(\"  - Contraintes: Max 25% par actif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 7 : Strategie Complete ML-Optimized (15 min)\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "Universe Selection (Top 50 Market Cap)\n",
    "              |\n",
    "              v\n",
    "Alpha Model (Momentum + Value)\n",
    "              |\n",
    "              v\n",
    "ML Portfolio Construction\n",
    "  - Expected Returns: XGBoost\n",
    "  - Covariance: Ledoit-Wolf\n",
    "  - Optimization: Mean-Variance\n",
    "              |\n",
    "              v\n",
    "Risk Management (Max DD 5%)\n",
    "              |\n",
    "              v\n",
    "Execution (Immediate)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategie complete ML-Optimized\n",
    "# A copier dans l'IDE QuantConnect\n",
    "\n",
    "qc_full_strategy = '''\n",
    "from AlgorithmImports import *\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MLOptimizedPortfolioAlgorithm(QCAlgorithm):\n",
    "    \"\"\"\n",
    "    Strategie complete avec optimisation de portefeuille ML.\n",
    "    \n",
    "    - Universe: Top 50 par Market Cap\n",
    "    - Alpha: Momentum (20/60 days)\n",
    "    - Portfolio: ML-Enhanced Mean-Variance\n",
    "    - Risk: Max 5% drawdown par position\n",
    "    - Rebalancement: Mensuel\n",
    "    \"\"\"\n",
    "    \n",
    "    def Initialize(self):\n",
    "        self.SetStartDate(2020, 1, 1)\n",
    "        self.SetEndDate(2023, 12, 31)\n",
    "        self.SetCash(100000)\n",
    "        \n",
    "        # Universe settings\n",
    "        self.UniverseSettings.Resolution = Resolution.Daily\n",
    "        self.num_stocks = 50\n",
    "        \n",
    "        # Add universe\n",
    "        self.AddUniverse(self.CoarseFilter, self.FineFilter)\n",
    "        \n",
    "        # Set models\n",
    "        self.SetAlpha(MomentumAlphaModel())\n",
    "        self.SetPortfolioConstruction(MLPortfolioConstructionModel(\n",
    "            rebalance_days=30,\n",
    "            lookback_days=252,\n",
    "            method='mean_variance',\n",
    "            use_ml_returns=True\n",
    "        ))\n",
    "        self.SetExecution(ImmediateExecutionModel())\n",
    "        self.SetRiskManagement(MaximumDrawdownPercentPerSecurity(0.05))\n",
    "        \n",
    "        # Schedule rebalancing log\n",
    "        self.Schedule.On(\n",
    "            self.DateRules.MonthStart(),\n",
    "            self.TimeRules.AfterMarketOpen(\"SPY\", 30),\n",
    "            self.LogPortfolio\n",
    "        )\n",
    "    \n",
    "    def CoarseFilter(self, coarse):\n",
    "        filtered = [x for x in coarse\n",
    "                   if x.HasFundamentalData\n",
    "                   and x.Price > 10\n",
    "                   and x.DollarVolume > 5000000]\n",
    "        \n",
    "        sorted_by_volume = sorted(filtered, \n",
    "                                  key=lambda x: x.DollarVolume, \n",
    "                                  reverse=True)\n",
    "        return [x.Symbol for x in sorted_by_volume[:100]]\n",
    "    \n",
    "    def FineFilter(self, fine):\n",
    "        filtered = [x for x in fine if x.MarketCap > 2e9]\n",
    "        sorted_by_cap = sorted(filtered, \n",
    "                               key=lambda x: x.MarketCap, \n",
    "                               reverse=True)\n",
    "        return [x.Symbol for x in sorted_by_cap[:self.num_stocks]]\n",
    "    \n",
    "    def LogPortfolio(self):\n",
    "        holdings = [(s.Value, h.HoldingsValue / self.Portfolio.TotalPortfolioValue)\n",
    "                   for s, h in self.Portfolio.items() if h.Invested]\n",
    "        holdings.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        self.Debug(f\"\\n{self.Time.date()}: Portfolio Summary\")\n",
    "        self.Debug(f\"  Total Value: ${self.Portfolio.TotalPortfolioValue:,.0f}\")\n",
    "        self.Debug(f\"  Positions: {len(holdings)}\")\n",
    "        for sym, weight in holdings[:5]:\n",
    "            self.Debug(f\"    {sym}: {weight:.1%}\")\n",
    "    \n",
    "    def OnEndOfAlgorithm(self):\n",
    "        self.Debug(\"\\n\" + \"=\"*60)\n",
    "        self.Debug(\"FINAL SUMMARY - ML Optimized Portfolio\")\n",
    "        self.Debug(\"=\"*60)\n",
    "        self.Debug(f\"Final Value: ${self.Portfolio.TotalPortfolioValue:,.0f}\")\n",
    "        total_return = (self.Portfolio.TotalPortfolioValue / 100000 - 1) * 100\n",
    "        self.Debug(f\"Total Return: {total_return:.2f}%\")\n",
    "\n",
    "\n",
    "class MomentumAlphaModel(AlphaModel):\n",
    "    \"\"\"\n",
    "    Alpha Model basee sur le momentum.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, short_period=20, long_period=60):\n",
    "        self.short_period = short_period\n",
    "        self.long_period = long_period\n",
    "        self.securities = []\n",
    "    \n",
    "    def Update(self, algorithm, data):\n",
    "        insights = []\n",
    "        \n",
    "        for symbol in self.securities:\n",
    "            if not data.ContainsKey(symbol):\n",
    "                continue\n",
    "            \n",
    "            history = algorithm.History(symbol, self.long_period + 5, Resolution.Daily)\n",
    "            if history.empty or len(history) < self.long_period:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                prices = history['close']\n",
    "                \n",
    "                # Momentum signals\n",
    "                mom_short = (prices.iloc[-1] / prices.iloc[-self.short_period] - 1)\n",
    "                mom_long = (prices.iloc[-1] / prices.iloc[-self.long_period] - 1)\n",
    "                \n",
    "                # Combine signals\n",
    "                combined_mom = 0.6 * mom_short + 0.4 * mom_long\n",
    "                \n",
    "                if combined_mom > 0.02:  # >2% momentum\n",
    "                    direction = InsightDirection.Up\n",
    "                    magnitude = min(combined_mom, 0.2)\n",
    "                    confidence = min(abs(combined_mom) * 5, 1.0)\n",
    "                elif combined_mom < -0.02:\n",
    "                    direction = InsightDirection.Down\n",
    "                    magnitude = min(abs(combined_mom), 0.2)\n",
    "                    confidence = min(abs(combined_mom) * 5, 1.0)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                insight = Insight.Price(\n",
    "                    symbol,\n",
    "                    timedelta(days=30),\n",
    "                    direction,\n",
    "                    magnitude,\n",
    "                    confidence\n",
    "                )\n",
    "                insights.append(insight)\n",
    "                \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def OnSecuritiesChanged(self, algorithm, changes):\n",
    "        for security in changes.AddedSecurities:\n",
    "            if security.Symbol not in self.securities:\n",
    "                self.securities.append(security.Symbol)\n",
    "        for security in changes.RemovedSecurities:\n",
    "            if security.Symbol in self.securities:\n",
    "                self.securities.remove(security.Symbol)\n",
    "'''\n",
    "\n",
    "print(\"MLOptimizedPortfolioAlgorithm defini\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUME DE LA STRATEGIE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. Universe Selection:\")\n",
    "print(\"   - Coarse: Volume > $5M, Price > $10\")\n",
    "print(\"   - Fine: Top 50 par Market Cap (> $2B)\")\n",
    "print(\"\\n2. Alpha Model:\")\n",
    "print(\"   - Momentum 20/60 jours\")\n",
    "print(\"   - Seuil: +/-2%\")\n",
    "print(\"\\n3. Portfolio Construction:\")\n",
    "print(\"   - Covariance: Ledoit-Wolf\")\n",
    "print(\"   - Returns: Random Forest\")\n",
    "print(\"   - Optimization: Max Sharpe\")\n",
    "print(\"\\n4. Risk Management:\")\n",
    "print(\"   - Max Drawdown: 5% par position\")\n",
    "print(\"\\n5. Execution:\")\n",
    "print(\"   - Immediate Market Orders\")\n",
    "print(\"   - Rebalancement: Mensuel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume comparatif des methodes\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARAISON DES METHODES D'OPTIMISATION DE PORTEFEUILLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "methods_comparison = pd.DataFrame({\n",
    "    'Methode': ['Equal Weight', 'Min Variance', 'Max Sharpe', 'Black-Litterman', 'HRP'],\n",
    "    'Rendements Requis': ['Non', 'Non', 'Oui', 'Oui (vues)', 'Non'],\n",
    "    'Covariance Requis': ['Non', 'Oui', 'Oui', 'Oui', 'Oui'],\n",
    "    'Inversion Matrice': ['Non', 'Oui', 'Oui', 'Oui', 'Non'],\n",
    "    'Stabilite': ['Haute', 'Moyenne', 'Basse', 'Moyenne', 'Haute'],\n",
    "    'Diversification': ['Maximale', 'Bonne', 'Variable', 'Bonne', 'Bonne'],\n",
    "    'ML Compatible': ['N/A', 'Non', 'Oui', 'Oui', 'Non']\n",
    "})\n",
    "\n",
    "print(methods_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion et Prochaines Etapes\n",
    "\n",
    "### Recapitulatif\n",
    "\n",
    "Dans ce notebook, nous avons couvert :\n",
    "\n",
    "| Sujet | Points Cles |\n",
    "|-------|-------------|\n",
    "| **Mean-Variance** | Fondation theorique, frontiere efficiente, sensible aux inputs |\n",
    "| **Shrinkage** | Ledoit-Wolf stabilise la covariance, reduit le condition number |\n",
    "| **ML Returns** | Random Forest pour predire les rendements, features momentum/vol |\n",
    "| **Black-Litterman** | Combine equilibre marche + vues ML, rendements posterieurs |\n",
    "| **HRP** | Pas d'inversion matrice, clustering hierarchique, stable |\n",
    "| **Integration QC** | MLPortfolioConstructionModel, strategie complete |\n",
    "\n",
    "### Recommandations pratiques\n",
    "\n",
    "| Situation | Methode Recommandee |\n",
    "|-----------|---------------------|\n",
    "| Peu de donnees (<100 obs) | HRP ou Equal Weight |\n",
    "| Beaucoup d'actifs (>50) | HRP avec Ledoit-Wolf |\n",
    "| Alpha model sophistique | Black-Litterman avec vues ML |\n",
    "| Production simple | Min Variance avec Shrinkage |\n",
    "| Recherche/Backtest | Mean-Variance pour baseline |\n",
    "\n",
    "### Limites a garder en tete\n",
    "\n",
    "1. **Overfitting ML** : Les predictions de rendements sont tres bruyantes\n",
    "2. **Regime changes** : Les correlations changent en periode de crise\n",
    "3. **Transaction costs** : Le rebalancement frequent coute cher\n",
    "4. **Estimation lag** : Les donnees historiques ne predisent pas le futur\n",
    "\n",
    "### Ressources Complementaires\n",
    "\n",
    "- [Advances in Financial ML](https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089) - Lopez de Prado\n",
    "- [Machine Learning for Asset Managers](https://www.amazon.com/Machine-Learning-Managers-Elements-Quantitative/dp/1108792898) - Lopez de Prado\n",
    "- [PyPortfolioOpt Documentation](https://pyportfolioopt.readthedocs.io/)\n",
    "- [QuantConnect Portfolio Optimization](https://www.quantconnect.com/docs/v2/writing-algorithms/algorithm-framework/portfolio-construction)\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook complete. Vous maitrisez maintenant l'optimisation de portefeuille avec ML.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
