{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC-Py-20 - Machine Learning Regression pour Price Prediction\n",
    "\n",
    "> **Predire les rendements avec des modeles de regression**\n",
    "> Duree: 75 minutes | Niveau: Intermediaire-Avance | Python + QuantConnect\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous serez capable de :\n",
    "\n",
    "1. Comprendre la difference entre **Regression vs Classification** pour le trading\n",
    "2. Implementer des modeles de **Linear Regression** (Ridge, Lasso, ElasticNet)\n",
    "3. Utiliser des **Ensemble Methods** (Random Forest, Gradient Boosting, XGBoost)\n",
    "4. Appliquer **Support Vector Regression** avec scaling\n",
    "5. Evaluer les modeles avec les **metriques de regression** appropriees\n",
    "6. Convertir les **predictions en signaux de trading**\n",
    "7. Construire une **strategie complete** de prediction de rendements\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Notebooks QC-Py-01 a 18 completes\n",
    "- QC-Py-18 Feature Engineering (features preparees)\n",
    "- Notions de base en Machine Learning\n",
    "- Familiarite avec scikit-learn\n",
    "\n",
    "## Structure du Notebook\n",
    "\n",
    "1. Regression vs Classification (10 min)\n",
    "2. Linear Regression: Ridge, Lasso, ElasticNet (20 min)\n",
    "3. Ensemble Methods: Random Forest, Gradient Boosting (25 min)\n",
    "4. Support Vector Regression (15 min)\n",
    "5. Metriques de Regression (15 min)\n",
    "6. Integration Trading: Prediction to Signal (20 min)\n",
    "7. Strategie Complete: Return Prediction (20 min)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Regression vs Classification (10 min)\n",
    "\n",
    "### Deux approches pour predire le marche\n",
    "\n",
    "En Machine Learning pour le trading, deux approches principales existent :\n",
    "\n",
    "| Approche | Question | Output | Exemple |\n",
    "|----------|----------|--------|--------|\n",
    "| **Classification** | Le prix va-t-il monter ou descendre? | Classe (Up/Down) | Direction du mouvement |\n",
    "| **Regression** | De combien le prix va-t-il changer? | Valeur continue | Rendement attendu (ex: +2.5%) |\n",
    "\n",
    "### Quand utiliser la Regression?\n",
    "\n",
    "```\n",
    "Classification (Direction)\n",
    "   - Objectif: Direction du mouvement\n",
    "   - Output: Up (1), Down (0)\n",
    "   - Avantage: Plus simple, plus robuste\n",
    "   - Limite: Ignore la magnitude\n",
    "\n",
    "Regression (Magnitude)\n",
    "   - Objectif: Rendement exact\n",
    "   - Output: Valeur continue (ex: +2.5%, -1.3%)\n",
    "   - Avantage: Information sur l'amplitude\n",
    "   - Limite: Plus difficile, plus de bruit\n",
    "```\n",
    "\n",
    "### Avantages de la Regression pour le Trading\n",
    "\n",
    "| Avantage | Description |\n",
    "|----------|-------------|\n",
    "| **Position Sizing** | Ajuster la taille selon l'amplitude predite |\n",
    "| **Risk/Reward** | Estimer le ratio risque/rendement |\n",
    "| **Filtering** | Ignorer les petits mouvements non rentables |\n",
    "| **Portfolio Optimization** | Utiliser les predictions comme expected returns |\n",
    "\n",
    "### Pipeline de Regression pour Trading\n",
    "\n",
    "```\n",
    "Features (X)          Modele Regression       Prediction\n",
    "[RSI, MACD, ...]  -->  [Ridge/XGBoost]  -->  y_pred = +1.8%\n",
    "                                                  |\n",
    "                                                  v\n",
    "                                           Signal Trading\n",
    "                                           (Long si > threshold)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Configuration matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Verifier si XGBoost est disponible\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "    print(\"XGBoost disponible\")\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"XGBoost non disponible (pip install xgboost pour l'installer)\")\n",
    "\n",
    "print(\"\\nImports reussis!\")\n",
    "print(\"Ce notebook couvre la Regression ML pour la prediction de prix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des donnees de demonstration avec features et target\n",
    "\n",
    "def generate_regression_data(n_days=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Genere des donnees simulees pour la regression.\n",
    "    Inclut features techniques et target (rendement futur).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_days : int\n",
    "        Nombre de jours de donnees\n",
    "    seed : int\n",
    "        Graine aleatoire\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame avec features et target\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Dates\n",
    "    dates = pd.date_range(start='2019-01-01', periods=n_days, freq='B')\n",
    "    \n",
    "    # Prix simules avec tendance et volatilite\n",
    "    returns = np.random.normal(0.0003, 0.015, n_days)\n",
    "    close = 100 * np.exp(np.cumsum(returns))\n",
    "    \n",
    "    # === FEATURES TECHNIQUES ===\n",
    "    \n",
    "    # Rendements passes\n",
    "    df = pd.DataFrame({'close': close}, index=dates)\n",
    "    df['return_1d'] = df['close'].pct_change(1)\n",
    "    df['return_5d'] = df['close'].pct_change(5)\n",
    "    df['return_20d'] = df['close'].pct_change(20)\n",
    "    \n",
    "    # Volatilite\n",
    "    df['volatility_20d'] = df['return_1d'].rolling(20).std()\n",
    "    \n",
    "    # RSI simule\n",
    "    delta = df['close'].diff()\n",
    "    gain = delta.clip(lower=0).rolling(14).mean()\n",
    "    loss = (-delta.clip(upper=0)).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-10)\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    df['rsi_normalized'] = (df['rsi'] - 50) / 50\n",
    "    \n",
    "    # Moving averages\n",
    "    df['sma_20'] = df['close'].rolling(20).mean()\n",
    "    df['sma_50'] = df['close'].rolling(50).mean()\n",
    "    df['ma_ratio'] = df['sma_20'] / df['sma_50']\n",
    "    df['price_to_sma20'] = df['close'] / df['sma_20']\n",
    "    \n",
    "    # MACD normalise\n",
    "    ema_12 = df['close'].ewm(span=12).mean()\n",
    "    ema_26 = df['close'].ewm(span=26).mean()\n",
    "    df['macd_norm'] = (ema_12 - ema_26) / df['close']\n",
    "    \n",
    "    # Bollinger Bands %B\n",
    "    bb_middle = df['close'].rolling(20).mean()\n",
    "    bb_std = df['close'].rolling(20).std()\n",
    "    bb_upper = bb_middle + 2 * bb_std\n",
    "    bb_lower = bb_middle - 2 * bb_std\n",
    "    df['bb_percent_b'] = (df['close'] - bb_lower) / (bb_upper - bb_lower + 1e-10)\n",
    "    \n",
    "    # Volume ratio (simule)\n",
    "    volume = 1e6 * (1 + np.random.exponential(0.3, n_days))\n",
    "    df['volume_ratio'] = volume / pd.Series(volume).rolling(20).mean().values\n",
    "    \n",
    "    # === TARGET: Rendement futur sur 5 jours ===\n",
    "    horizon = 5\n",
    "    df['target_return'] = df['close'].shift(-horizon) / df['close'] - 1\n",
    "    \n",
    "    # Supprimer les lignes avec NaN\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generer les donnees\n",
    "df = generate_regression_data(n_days=1000)\n",
    "\n",
    "print(\"Donnees generees:\")\n",
    "print(f\"  Periode: {df.index[0].date()} a {df.index[-1].date()}\")\n",
    "print(f\"  Nombre d'echantillons: {len(df)}\")\n",
    "print(f\"\\nFeatures: {[c for c in df.columns if c not in ['close', 'target_return']]}\")\n",
    "print(f\"\\nTarget: 'target_return' (rendement 5 jours)\")\n",
    "print(f\"  Mean: {df['target_return'].mean()*100:.3f}%\")\n",
    "print(f\"  Std: {df['target_return'].std()*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparer les donnees pour ML\n",
    "\n",
    "# Features (X) et Target (y)\n",
    "feature_cols = ['return_1d', 'return_5d', 'return_20d', 'volatility_20d',\n",
    "                'rsi_normalized', 'ma_ratio', 'price_to_sma20', 'macd_norm',\n",
    "                'bb_percent_b', 'volume_ratio']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['target_return']\n",
    "\n",
    "# Split temporel (train/test)\n",
    "train_size = int(len(df) * 0.7)\n",
    "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "print(\"Split Train/Test (temporel):\")\n",
    "print(f\"  Train: {len(X_train)} samples ({X_train.index[0].date()} - {X_train.index[-1].date()})\")\n",
    "print(f\"  Test:  {len(X_test)} samples ({X_test.index[0].date()} - {X_test.index[-1].date()})\")\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=feature_cols, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=feature_cols, index=X_test.index)\n",
    "\n",
    "print(\"\\nStandardisation appliquee (fit sur train, transform sur test)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 2 : Linear Regression - Ridge, Lasso, ElasticNet (20 min)\n",
    "\n",
    "### Regularisation en Regression\n",
    "\n",
    "La regression lineaire simple peut overfitter, surtout avec beaucoup de features. La regularisation penalise les coefficients trop grands.\n",
    "\n",
    "| Modele | Regularisation | Formule Loss | Effet |\n",
    "|--------|---------------|--------------|-------|\n",
    "| **Linear** | Aucune | MSE | Baseline, peut overfitter |\n",
    "| **Ridge (L2)** | L2 (somme carres) | MSE + alpha * sum(coef^2) | Shrinkage, garde toutes les features |\n",
    "| **Lasso (L1)** | L1 (somme absolue) | MSE + alpha * sum(abs(coef)) | Sparse, feature selection |\n",
    "| **ElasticNet** | L1 + L2 | MSE + alpha * (l1_ratio * L1 + (1-l1_ratio) * L2) | Combine les deux |\n",
    "\n",
    "### Quand utiliser chaque modele?\n",
    "\n",
    "```\n",
    "Ridge (L2)\n",
    "  - Quand toutes les features sont utiles\n",
    "  - Features correlees\n",
    "  - Shrinkage uniforme\n",
    "\n",
    "Lasso (L1)\n",
    "  - Quand on veut feature selection automatique\n",
    "  - Beaucoup de features, peu d'utiles\n",
    "  - Coefficients exactement a 0\n",
    "\n",
    "ElasticNet\n",
    "  - Combine les avantages des deux\n",
    "  - Features correlees + sparse solution\n",
    "  - Plus flexible\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression (L2 Regularization)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RIDGE REGRESSION (L2 Regularization)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Tester differentes valeurs de alpha\n",
    "alphas = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "ridge_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = ridge.predict(X_train_scaled)\n",
    "    y_test_pred = ridge.predict(X_test_scaled)\n",
    "    \n",
    "    # Metriques\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    ridge_results.append({\n",
    "        'alpha': alpha,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2,\n",
    "        'coef_norm': np.linalg.norm(ridge.coef_)\n",
    "    })\n",
    "\n",
    "ridge_df = pd.DataFrame(ridge_results)\n",
    "print(\"\\nResultats Ridge pour differents alpha:\")\n",
    "print(ridge_df.to_string(index=False))\n",
    "\n",
    "# Meilleur alpha\n",
    "best_ridge_alpha = ridge_df.loc[ridge_df['test_rmse'].idxmin(), 'alpha']\n",
    "print(f\"\\nMeilleur alpha: {best_ridge_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression (L1 Regularization - Feature Selection)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LASSO REGRESSION (L1 Regularization)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Tester differentes valeurs de alpha\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "lasso_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = lasso.predict(X_train_scaled)\n",
    "    y_test_pred = lasso.predict(X_test_scaled)\n",
    "    \n",
    "    # Metriques\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    n_nonzero = np.sum(lasso.coef_ != 0)\n",
    "    \n",
    "    lasso_results.append({\n",
    "        'alpha': alpha,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2,\n",
    "        'n_features': n_nonzero\n",
    "    })\n",
    "\n",
    "lasso_df = pd.DataFrame(lasso_results)\n",
    "print(\"\\nResultats Lasso pour differents alpha:\")\n",
    "print(lasso_df.to_string(index=False))\n",
    "\n",
    "# Meilleur Lasso\n",
    "best_lasso_alpha = lasso_df.loc[lasso_df['test_rmse'].idxmin(), 'alpha']\n",
    "best_lasso = Lasso(alpha=best_lasso_alpha, max_iter=10000)\n",
    "best_lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nMeilleur alpha: {best_lasso_alpha}\")\n",
    "print(f\"\\nFeatures selectionnees (coef != 0):\")\n",
    "for feat, coef in zip(feature_cols, best_lasso.coef_):\n",
    "    if coef != 0:\n",
    "        print(f\"  {feat}: {coef:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet (L1 + L2 Regularization)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ELASTICNET (L1 + L2 Regularization)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Tester differentes combinaisons\n",
    "params = [\n",
    "    {'alpha': 0.001, 'l1_ratio': 0.2},\n",
    "    {'alpha': 0.001, 'l1_ratio': 0.5},\n",
    "    {'alpha': 0.001, 'l1_ratio': 0.8},\n",
    "    {'alpha': 0.01, 'l1_ratio': 0.5},\n",
    "    {'alpha': 0.1, 'l1_ratio': 0.5},\n",
    "]\n",
    "\n",
    "elastic_results = []\n",
    "\n",
    "for p in params:\n",
    "    elastic = ElasticNet(alpha=p['alpha'], l1_ratio=p['l1_ratio'], max_iter=10000)\n",
    "    elastic.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_test_pred = elastic.predict(X_test_scaled)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    n_nonzero = np.sum(elastic.coef_ != 0)\n",
    "    \n",
    "    elastic_results.append({\n",
    "        'alpha': p['alpha'],\n",
    "        'l1_ratio': p['l1_ratio'],\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2,\n",
    "        'n_features': n_nonzero\n",
    "    })\n",
    "\n",
    "elastic_df = pd.DataFrame(elastic_results)\n",
    "print(\"\\nResultats ElasticNet:\")\n",
    "print(elastic_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nNote:\")\n",
    "print(\"  - l1_ratio=0 -> Ridge (pure L2)\")\n",
    "print(\"  - l1_ratio=1 -> Lasso (pure L1)\")\n",
    "print(\"  - l1_ratio=0.5 -> Mix equilibre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des coefficients\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Ridge\n",
    "ridge_best = Ridge(alpha=best_ridge_alpha)\n",
    "ridge_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "ax1 = axes[0]\n",
    "colors = ['green' if c > 0 else 'red' for c in ridge_best.coef_]\n",
    "ax1.barh(feature_cols, ridge_best.coef_, color=colors)\n",
    "ax1.axvline(0, color='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Coefficient')\n",
    "ax1.set_title(f'Ridge (alpha={best_ridge_alpha})')\n",
    "\n",
    "# Lasso\n",
    "ax2 = axes[1]\n",
    "colors = ['green' if c > 0 else 'red' if c < 0 else 'gray' for c in best_lasso.coef_]\n",
    "ax2.barh(feature_cols, best_lasso.coef_, color=colors)\n",
    "ax2.axvline(0, color='black', linewidth=0.5)\n",
    "ax2.set_xlabel('Coefficient')\n",
    "ax2.set_title(f'Lasso (alpha={best_lasso_alpha})')\n",
    "\n",
    "# ElasticNet\n",
    "elastic_best = ElasticNet(alpha=0.001, l1_ratio=0.5, max_iter=10000)\n",
    "elastic_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "ax3 = axes[2]\n",
    "colors = ['green' if c > 0 else 'red' if c < 0 else 'gray' for c in elastic_best.coef_]\n",
    "ax3.barh(feature_cols, elastic_best.coef_, color=colors)\n",
    "ax3.axvline(0, color='black', linewidth=0.5)\n",
    "ax3.set_xlabel('Coefficient')\n",
    "ax3.set_title('ElasticNet (alpha=0.001, l1=0.5)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"  - Ridge: tous les coefficients non-nuls (shrinkage)\")\n",
    "print(\"  - Lasso: certains coefficients a 0 (feature selection)\")\n",
    "print(\"  - ElasticNet: compromis entre les deux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 3 : Ensemble Methods - Random Forest et Gradient Boosting (25 min)\n",
    "\n",
    "### Ensemble Methods pour la Regression\n",
    "\n",
    "Les methodes d'ensemble combinent plusieurs modeles pour obtenir de meilleures predictions.\n",
    "\n",
    "| Methode | Principe | Avantages | Inconvenients |\n",
    "|---------|----------|-----------|---------------|\n",
    "| **Random Forest** | Moyenne de nombreux arbres | Robuste, peu d'overfitting | Moins precis que boosting |\n",
    "| **Gradient Boosting** | Arbres sequentiels corrigent les erreurs | Tres precis | Risque d'overfitting |\n",
    "| **XGBoost** | GB optimise avec regularisation | Rapide, regularise | Complexe a tuner |\n",
    "\n",
    "### Random Forest Regressor\n",
    "\n",
    "```\n",
    "Donnees\n",
    "   |\n",
    "   +-- Bootstrap sample 1 --> Arbre 1 --> Prediction 1\n",
    "   +-- Bootstrap sample 2 --> Arbre 2 --> Prediction 2\n",
    "   +-- ...                    ...        ...\n",
    "   +-- Bootstrap sample N --> Arbre N --> Prediction N\n",
    "   |\n",
    "   v\n",
    "Prediction finale = Moyenne(Prediction 1, ..., Prediction N)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST REGRESSOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Hyperparametres a tester\n",
    "rf_params = [\n",
    "    {'n_estimators': 50, 'max_depth': 4, 'min_samples_leaf': 20},\n",
    "    {'n_estimators': 100, 'max_depth': 6, 'min_samples_leaf': 20},\n",
    "    {'n_estimators': 100, 'max_depth': 8, 'min_samples_leaf': 10},\n",
    "    {'n_estimators': 200, 'max_depth': 6, 'min_samples_leaf': 20},\n",
    "]\n",
    "\n",
    "rf_results = []\n",
    "\n",
    "for params in rf_params:\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_train_pred = rf.predict(X_train_scaled)\n",
    "    y_test_pred = rf.predict(X_test_scaled)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    rf_results.append({\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'max_depth': params['max_depth'],\n",
    "        'min_samples_leaf': params['min_samples_leaf'],\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2\n",
    "    })\n",
    "\n",
    "rf_df = pd.DataFrame(rf_results)\n",
    "print(\"\\nResultats Random Forest:\")\n",
    "print(rf_df.to_string(index=False))\n",
    "\n",
    "# Meilleur modele\n",
    "best_rf_idx = rf_df['test_rmse'].idxmin()\n",
    "best_rf_params = rf_params[best_rf_idx]\n",
    "print(f\"\\nMeilleurs parametres: {best_rf_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance avec Random Forest\n",
    "\n",
    "# Entrainer le meilleur modele\n",
    "best_rf = RandomForestRegressor(\n",
    "    n_estimators=best_rf_params['n_estimators'],\n",
    "    max_depth=best_rf_params['max_depth'],\n",
    "    min_samples_leaf=best_rf_params['min_samples_leaf'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Random Forest):\")\n",
    "print(importance.to_string(index=False))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(importance)))\n",
    "plt.barh(importance['feature'], importance['importance'], color=colors)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance - Random Forest Regressor')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor (sklearn)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GRADIENT BOOSTING REGRESSOR (sklearn)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Hyperparametres\n",
    "gb_params = [\n",
    "    {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.05},\n",
    "    {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.05},\n",
    "]\n",
    "\n",
    "gb_results = []\n",
    "\n",
    "for params in gb_params:\n",
    "    gb = GradientBoostingRegressor(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        min_samples_leaf=20,\n",
    "        random_state=42\n",
    "    )\n",
    "    gb.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_train_pred = gb.predict(X_train_scaled)\n",
    "    y_test_pred = gb.predict(X_test_scaled)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    gb_results.append({\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'max_depth': params['max_depth'],\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2\n",
    "    })\n",
    "\n",
    "gb_df = pd.DataFrame(gb_results)\n",
    "print(\"\\nResultats Gradient Boosting:\")\n",
    "print(gb_df.to_string(index=False))\n",
    "\n",
    "best_gb_idx = gb_df['test_rmse'].idxmin()\n",
    "best_gb_params = gb_params[best_gb_idx]\n",
    "print(f\"\\nMeilleurs parametres: {best_gb_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor (si disponible)\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST REGRESSOR\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Hyperparametres\n",
    "    xgb_params = [\n",
    "        {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1},\n",
    "        {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.1},\n",
    "        {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.05},\n",
    "        {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.05},\n",
    "    ]\n",
    "    \n",
    "    xgb_results = []\n",
    "    \n",
    "    for params in xgb_params:\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train_scaled)\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        xgb_results.append({\n",
    "            'n_estimators': params['n_estimators'],\n",
    "            'max_depth': params['max_depth'],\n",
    "            'learning_rate': params['learning_rate'],\n",
    "            'train_rmse': train_rmse,\n",
    "            'test_rmse': test_rmse,\n",
    "            'test_r2': test_r2\n",
    "        })\n",
    "    \n",
    "    xgb_df = pd.DataFrame(xgb_results)\n",
    "    print(\"\\nResultats XGBoost:\")\n",
    "    print(xgb_df.to_string(index=False))\n",
    "    \n",
    "    best_xgb_idx = xgb_df['test_rmse'].idxmin()\n",
    "    best_xgb_params = xgb_params[best_xgb_idx]\n",
    "    print(f\"\\nMeilleurs parametres: {best_xgb_params}\")\n",
    "else:\n",
    "    print(\"XGBoost non disponible.\")\n",
    "    print(\"Installer avec: pip install xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 4 : Support Vector Regression (15 min)\n",
    "\n",
    "### SVR - Support Vector Regression\n",
    "\n",
    "Le SVR etend les SVM a la regression. Il cherche a trouver une fonction qui a au plus epsilon deviation des targets.\n",
    "\n",
    "| Kernel | Formule | Usage |\n",
    "|--------|---------|-------|\n",
    "| **Linear** | `x.T @ y` | Relations lineaires |\n",
    "| **RBF** | `exp(-gamma * ||x-y||^2)` | Relations non-lineaires (defaut) |\n",
    "| **Poly** | `(gamma * x.T @ y + coef0)^degree` | Polynomiales |\n",
    "\n",
    "### Parametres importants\n",
    "\n",
    "| Parametre | Description | Effet |\n",
    "|-----------|-------------|-------|\n",
    "| **C** | Regularisation | Plus grand = moins de regularisation |\n",
    "| **epsilon** | Tube insensible | Plus grand = plus de tolerance |\n",
    "| **gamma** | Influence des points (RBF) | Plus grand = plus local |\n",
    "\n",
    "### Importance du Scaling\n",
    "\n",
    "**SVR necessite IMPERATIVEMENT des features standardisees**. Sans scaling, les performances sont tres degradees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SUPPORT VECTOR REGRESSION (SVR)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Demonstration: Sans scaling vs Avec scaling\n",
    "print(\"\\n1. Importance du Scaling:\")\n",
    "\n",
    "# Sans scaling\n",
    "svr_no_scale = SVR(kernel='rbf', C=1.0, epsilon=0.001)\n",
    "svr_no_scale.fit(X_train, y_train)  # Donnees non scalees!\n",
    "y_pred_no_scale = svr_no_scale.predict(X_test)\n",
    "rmse_no_scale = np.sqrt(mean_squared_error(y_test, y_pred_no_scale))\n",
    "\n",
    "# Avec scaling\n",
    "svr_scaled = SVR(kernel='rbf', C=1.0, epsilon=0.001)\n",
    "svr_scaled.fit(X_train_scaled, y_train)  # Donnees scalees\n",
    "y_pred_scaled = svr_scaled.predict(X_test_scaled)\n",
    "rmse_scaled = np.sqrt(mean_squared_error(y_test, y_pred_scaled))\n",
    "\n",
    "print(f\"   RMSE sans scaling: {rmse_no_scale:.6f}\")\n",
    "print(f\"   RMSE avec scaling: {rmse_scaled:.6f}\")\n",
    "print(f\"   Amelioration: {(rmse_no_scale - rmse_scaled) / rmse_no_scale * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester differents kernels et parametres SVR\n",
    "\n",
    "print(\"\\n2. Comparaison des Kernels:\")\n",
    "\n",
    "svr_configs = [\n",
    "    {'kernel': 'linear', 'C': 0.1, 'epsilon': 0.001},\n",
    "    {'kernel': 'linear', 'C': 1.0, 'epsilon': 0.001},\n",
    "    {'kernel': 'rbf', 'C': 0.1, 'epsilon': 0.001},\n",
    "    {'kernel': 'rbf', 'C': 1.0, 'epsilon': 0.001},\n",
    "    {'kernel': 'rbf', 'C': 10.0, 'epsilon': 0.001},\n",
    "    {'kernel': 'poly', 'C': 1.0, 'epsilon': 0.001, 'degree': 2},\n",
    "]\n",
    "\n",
    "svr_results = []\n",
    "\n",
    "for config in svr_configs:\n",
    "    svr = SVR(**config)\n",
    "    svr.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_train_pred = svr.predict(X_train_scaled)\n",
    "    y_test_pred = svr.predict(X_test_scaled)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    result = {\n",
    "        'kernel': config['kernel'],\n",
    "        'C': config['C'],\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2\n",
    "    }\n",
    "    svr_results.append(result)\n",
    "\n",
    "svr_df = pd.DataFrame(svr_results)\n",
    "print(svr_df.to_string(index=False))\n",
    "\n",
    "best_svr_idx = svr_df['test_rmse'].idxmin()\n",
    "best_svr_config = svr_configs[best_svr_idx]\n",
    "print(f\"\\nMeilleure config: {best_svr_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code SVR pour QuantConnect\n",
    "# A adapter dans l'environnement QuantConnect\n",
    "\n",
    "svr_qc_code = '''\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class SVRRegressionModel:\n",
    "    \"\"\"\n",
    "    Wrapper SVR pour QuantConnect.\n",
    "    Inclut le scaler pour normalisation automatique.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel='rbf', C=1.0, epsilon=0.001):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit le scaler et le modele.\"\"\"\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.model.fit(X_scaled, y)\n",
    "        self.is_fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predit avec scaling automatique.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "'''\n",
    "\n",
    "print(\"Code SVR pour QuantConnect:\")\n",
    "print(svr_qc_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 5 : Metriques de Regression (15 min)\n",
    "\n",
    "### Metriques standard\n",
    "\n",
    "| Metrique | Formule | Interpretation |\n",
    "|----------|---------|---------------|\n",
    "| **MSE** | mean((y - y_pred)^2) | Erreur quadratique moyenne |\n",
    "| **RMSE** | sqrt(MSE) | Meme unite que y |\n",
    "| **MAE** | mean(abs(y - y_pred)) | Erreur absolue moyenne |\n",
    "| **R2** | 1 - SS_res / SS_tot | Variance expliquee (0-1) |\n",
    "| **MAPE** | mean(abs((y - y_pred)/y)) | Erreur en pourcentage |\n",
    "\n",
    "### Metriques specifiques au Trading\n",
    "\n",
    "| Metrique | Description | Importance |\n",
    "|----------|-------------|------------|\n",
    "| **Direction Accuracy** | % de predictions avec la bonne direction | Cruciale pour PnL |\n",
    "| **Correlation** | Correlation Pearson/Spearman avec y | Qualite du ranking |\n",
    "| **IC (Information Coefficient)** | Correlation avec les rendements futurs | Standard en quant |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer toutes les metriques\n",
    "\n",
    "def calculate_regression_metrics(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Calcule les metriques de regression standard et trading-specifiques.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        Valeurs reelles\n",
    "    y_pred : array-like\n",
    "        Predictions\n",
    "    model_name : str\n",
    "        Nom du modele\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionnaire de metriques\n",
    "    \"\"\"\n",
    "    # Metriques standard\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Direction Accuracy (CRUCIAL pour trading!)\n",
    "    direction_true = np.sign(y_true)\n",
    "    direction_pred = np.sign(y_pred)\n",
    "    direction_accuracy = np.mean(direction_true == direction_pred)\n",
    "    \n",
    "    # Correlation\n",
    "    correlation = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "    \n",
    "    # Correlation de rang (Spearman)\n",
    "    from scipy.stats import spearmanr\n",
    "    spearman_corr, _ = spearmanr(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'direction_accuracy': direction_accuracy,\n",
    "        'pearson_corr': correlation,\n",
    "        'spearman_corr': spearman_corr\n",
    "    }\n",
    "\n",
    "# Entrainer les meilleurs modeles et calculer les metriques\n",
    "models = {\n",
    "    'Ridge': Ridge(alpha=best_ridge_alpha),\n",
    "    'Lasso': Lasso(alpha=best_lasso_alpha, max_iter=10000),\n",
    "    'Random Forest': RandomForestRegressor(**best_rf_params, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(**best_gb_params, random_state=42),\n",
    "    'SVR': SVR(**best_svr_config)\n",
    "}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    models['XGBoost'] = xgb.XGBRegressor(**best_xgb_params, random_state=42, verbosity=0)\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    metrics = calculate_regression_metrics(y_test.values, y_pred, name)\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARAISON DE TOUS LES MODELES\")\n",
    "print(\"=\"*80)\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des metriques\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# RMSE par modele\n",
    "ax1 = axes[0, 0]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(metrics_df)))\n",
    "bars = ax1.bar(metrics_df['model'], metrics_df['rmse'] * 100, color=colors)\n",
    "ax1.set_ylabel('RMSE (%)')\n",
    "ax1.set_title('RMSE par Modele (plus bas = mieux)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# R2 par modele\n",
    "ax2 = axes[0, 1]\n",
    "bars = ax2.bar(metrics_df['model'], metrics_df['r2'], color=colors)\n",
    "ax2.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.set_ylabel('R2 Score')\n",
    "ax2.set_title('R2 par Modele (plus haut = mieux)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Direction Accuracy (CRUCIAL!)\n",
    "ax3 = axes[1, 0]\n",
    "bars = ax3.bar(metrics_df['model'], metrics_df['direction_accuracy'] * 100, color=colors)\n",
    "ax3.axhline(50, color='red', linestyle='--', label='Random (50%)')\n",
    "ax3.set_ylabel('Direction Accuracy (%)')\n",
    "ax3.set_title('Direction Accuracy (IMPORTANT pour Trading!)')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.legend()\n",
    "\n",
    "# Correlation\n",
    "ax4 = axes[1, 1]\n",
    "x = np.arange(len(metrics_df))\n",
    "width = 0.35\n",
    "ax4.bar(x - width/2, metrics_df['pearson_corr'], width, label='Pearson', color='steelblue')\n",
    "ax4.bar(x + width/2, metrics_df['spearman_corr'], width, label='Spearman', color='coral')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(metrics_df['model'], rotation=45)\n",
    "ax4.set_ylabel('Correlation')\n",
    "ax4.set_title('Correlation avec les vrais rendements')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote importante:\")\n",
    "print(\"  La Direction Accuracy est souvent plus importante que le RMSE pour le trading.\")\n",
    "print(\"  Un modele peut avoir un bon RMSE mais predire la mauvaise direction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions vs Realite pour le meilleur modele\n",
    "\n",
    "# Trouver le meilleur modele selon direction accuracy\n",
    "best_model_name = metrics_df.loc[metrics_df['direction_accuracy'].idxmax(), 'model']\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Meilleur modele (Direction Accuracy): {best_model_name}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot predictions vs reality\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test.values * 100, y_pred_best * 100, alpha=0.5)\n",
    "ax1.plot([-5, 5], [-5, 5], 'r--', label='Perfect prediction')\n",
    "ax1.set_xlabel('Rendement Reel (%)')\n",
    "ax1.set_ylabel('Rendement Predit (%)')\n",
    "ax1.set_title(f'{best_model_name}: Predictions vs Realite')\n",
    "ax1.legend()\n",
    "ax1.set_xlim(-5, 5)\n",
    "ax1.set_ylim(-5, 5)\n",
    "\n",
    "# Distribution des erreurs\n",
    "ax2 = axes[1]\n",
    "errors = (y_test.values - y_pred_best) * 100\n",
    "ax2.hist(errors, bins=50, color='steelblue', edgecolor='white')\n",
    "ax2.axvline(0, color='red', linestyle='--')\n",
    "ax2.axvline(np.mean(errors), color='green', linestyle='--', label=f'Mean: {np.mean(errors):.3f}%')\n",
    "ax2.set_xlabel('Erreur de Prediction (%)')\n",
    "ax2.set_ylabel('Frequence')\n",
    "ax2.set_title('Distribution des Erreurs')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 6 : Integration Trading - Prediction to Signal (20 min)\n",
    "\n",
    "### Convertir les predictions en signaux de trading\n",
    "\n",
    "Une prediction de rendement doit etre convertie en signal actionnable :\n",
    "\n",
    "```\n",
    "Prediction (y_pred)\n",
    "       |\n",
    "       v\n",
    "+-- > +1% ? --> LONG (acheter)\n",
    "+-- < -1% ? --> SHORT (vendre)\n",
    "+-- sinon  --> NEUTRAL (pas de position)\n",
    "       |\n",
    "       v\n",
    "Position Sizing (basee sur magnitude)\n",
    "       |\n",
    "       v\n",
    "Signal Trading\n",
    "```\n",
    "\n",
    "### Strategie de Position Sizing\n",
    "\n",
    "| Methode | Description | Formule |\n",
    "|---------|-------------|--------|\n",
    "| **Fixed** | Meme taille pour tous | size = constant |\n",
    "| **Proportionnel** | Proportionnel a la prediction | size = k * abs(y_pred) |\n",
    "| **Confiance** | Base sur la confiance du modele | size = k * confidence |\n",
    "| **Kelly** | Optimisation Kelly | size = edge / variance |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe RegressionAlphaModel pour QuantConnect\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "qc_regression_alpha_code = '''\n",
    "from AlgorithmImports import *\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class RegressionAlphaModel(AlphaModel):\n",
    "    \"\"\"\n",
    "    Alpha Model utilisant la regression ML pour predire les rendements.\n",
    "    Convertit les predictions en Insights avec magnitude et confiance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lookback=252, retrain_period=30, \n",
    "                 min_return_threshold=0.005, max_confidence=0.02):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        lookback : int\n",
    "            Nombre de jours pour l'entrainement\n",
    "        retrain_period : int\n",
    "            Frequence de re-entrainement (jours)\n",
    "        min_return_threshold : float\n",
    "            Seuil minimum pour generer un signal (ex: 0.5%)\n",
    "        max_confidence : float\n",
    "            Rendement correspondant a 100% confiance (ex: 2%)\n",
    "        \"\"\"\n",
    "        self.lookback = lookback\n",
    "        self.retrain_period = retrain_period\n",
    "        self.min_return_threshold = min_return_threshold\n",
    "        self.max_confidence = max_confidence\n",
    "        \n",
    "        self.symbolData = {}\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.last_train_time = None\n",
    "        self.insight_period = timedelta(days=5)\n",
    "    \n",
    "    def Update(self, algorithm, data):\n",
    "        \"\"\"\n",
    "        Genere des Insights bases sur les predictions du modele.\n",
    "        \"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        # Verifier si on doit re-entrainer\n",
    "        if self._should_retrain(algorithm):\n",
    "            self._train_model(algorithm)\n",
    "        \n",
    "        # Si pas de modele, pas d'insights\n",
    "        if self.model is None:\n",
    "            return insights\n",
    "        \n",
    "        for symbol, sd in self.symbolData.items():\n",
    "            if not sd.IsReady:\n",
    "                continue\n",
    "            \n",
    "            if not data.ContainsKey(symbol):\n",
    "                continue\n",
    "            \n",
    "            # Extraire les features\n",
    "            features = self._extract_features(sd)\n",
    "            if features is None:\n",
    "                continue\n",
    "            \n",
    "            # Prediction\n",
    "            features_scaled = self.scaler.transform([features])\n",
    "            predicted_return = self.model.predict(features_scaled)[0]\n",
    "            \n",
    "            # Filtrer les petites predictions\n",
    "            if abs(predicted_return) < self.min_return_threshold:\n",
    "                continue\n",
    "            \n",
    "            # Convertir en direction\n",
    "            if predicted_return > 0:\n",
    "                direction = InsightDirection.Up\n",
    "            else:\n",
    "                direction = InsightDirection.Down\n",
    "            \n",
    "            # Calculer la confiance (0 a 1)\n",
    "            # Plus la prediction est grande, plus on est confiant\n",
    "            confidence = min(abs(predicted_return) / self.max_confidence, 1.0)\n",
    "            \n",
    "            # Creer l'Insight\n",
    "            insight = Insight.Price(\n",
    "                symbol,\n",
    "                self.insight_period,\n",
    "                direction,\n",
    "                magnitude=abs(predicted_return),\n",
    "                confidence=confidence\n",
    "            )\n",
    "            insights.append(insight)\n",
    "            \n",
    "            algorithm.Debug(f\"{symbol.Value}: Pred={predicted_return:.4f}, Dir={direction}, Conf={confidence:.2f}\")\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def _should_retrain(self, algorithm):\n",
    "        \"\"\"Determine si le modele doit etre re-entraine.\"\"\"\n",
    "        if self.last_train_time is None:\n",
    "            return True\n",
    "        \n",
    "        days_since_train = (algorithm.Time - self.last_train_time).days\n",
    "        return days_since_train >= self.retrain_period\n",
    "    \n",
    "    def _train_model(self, algorithm):\n",
    "        \"\"\"Entraine le modele sur les donnees historiques.\"\"\"\n",
    "        # Collecter les donnees d'entrainement\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        \n",
    "        for symbol, sd in self.symbolData.items():\n",
    "            history = algorithm.History(symbol, self.lookback + 10, Resolution.Daily)\n",
    "            if history.empty:\n",
    "                continue\n",
    "            \n",
    "            # Calculer features et targets\n",
    "            # (implementation simplifiee)\n",
    "            for features, target in self._prepare_training_data(history):\n",
    "                X_train.append(features)\n",
    "                y_train.append(target)\n",
    "        \n",
    "        if len(X_train) < 100:\n",
    "            return  # Pas assez de donnees\n",
    "        \n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "        \n",
    "        # Standardisation\n",
    "        self.scaler = StandardScaler()\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        # Entrainement\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        self.last_train_time = algorithm.Time\n",
    "        algorithm.Debug(f\"Model retrained with {len(X_train)} samples\")\n",
    "    \n",
    "    def _extract_features(self, sd):\n",
    "        \"\"\"Extrait les features du SymbolData.\"\"\"\n",
    "        if not sd.IsReady:\n",
    "            return None\n",
    "        \n",
    "        return [\n",
    "            sd.Return1D,\n",
    "            sd.Return5D,\n",
    "            sd.Volatility,\n",
    "            sd.RSI_Normalized,\n",
    "            sd.MARelative,\n",
    "            sd.MACD_Normalized,\n",
    "            sd.BB_PercentB\n",
    "        ]\n",
    "    \n",
    "    def OnSecuritiesChanged(self, algorithm, changes):\n",
    "        \"\"\"Gere les changements d'univers.\"\"\"\n",
    "        for security in changes.AddedSecurities:\n",
    "            symbol = security.Symbol\n",
    "            if symbol not in self.symbolData:\n",
    "                self.symbolData[symbol] = RegressionSymbolData(algorithm, symbol)\n",
    "        \n",
    "        for security in changes.RemovedSecurities:\n",
    "            symbol = security.Symbol\n",
    "            if symbol in self.symbolData:\n",
    "                del self.symbolData[symbol]\n",
    "'''\n",
    "\n",
    "print(\"RegressionAlphaModel pour QuantConnect:\")\n",
    "print(qc_regression_alpha_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation de trading basee sur les predictions\n",
    "\n",
    "def simulate_trading_strategy(y_true, y_pred, threshold=0.005):\n",
    "    \"\"\"\n",
    "    Simule une strategie de trading basee sur les predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        Rendements reels\n",
    "    y_pred : array-like\n",
    "        Predictions du modele\n",
    "    threshold : float\n",
    "        Seuil minimum pour prendre position\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Metriques de la strategie\n",
    "    \"\"\"\n",
    "    # Signaux\n",
    "    signals = np.where(y_pred > threshold, 1,\n",
    "                       np.where(y_pred < -threshold, -1, 0))\n",
    "    \n",
    "    # Rendements de la strategie\n",
    "    strategy_returns = signals * y_true\n",
    "    \n",
    "    # Metriques\n",
    "    total_return = np.sum(strategy_returns)\n",
    "    n_trades = np.sum(signals != 0)\n",
    "    win_rate = np.mean(strategy_returns[signals != 0] > 0) if n_trades > 0 else 0\n",
    "    avg_win = np.mean(strategy_returns[strategy_returns > 0]) if np.any(strategy_returns > 0) else 0\n",
    "    avg_loss = np.mean(strategy_returns[strategy_returns < 0]) if np.any(strategy_returns < 0) else 0\n",
    "    sharpe = np.mean(strategy_returns) / (np.std(strategy_returns) + 1e-10) * np.sqrt(252)\n",
    "    \n",
    "    # Buy & Hold\n",
    "    bh_return = np.sum(y_true)\n",
    "    \n",
    "    return {\n",
    "        'total_return': total_return,\n",
    "        'n_trades': n_trades,\n",
    "        'win_rate': win_rate,\n",
    "        'avg_win': avg_win,\n",
    "        'avg_loss': avg_loss,\n",
    "        'sharpe': sharpe,\n",
    "        'buy_hold_return': bh_return,\n",
    "        'outperformance': total_return - bh_return\n",
    "    }\n",
    "\n",
    "# Simuler pour chaque modele\n",
    "print(\"=\"*80)\n",
    "print(\"SIMULATION DE TRADING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "trading_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    result = simulate_trading_strategy(y_test.values, y_pred, threshold=0.005)\n",
    "    result['model'] = name\n",
    "    trading_results.append(result)\n",
    "\n",
    "trading_df = pd.DataFrame(trading_results)\n",
    "trading_df = trading_df[['model', 'total_return', 'n_trades', 'win_rate', 'sharpe', 'buy_hold_return', 'outperformance']]\n",
    "\n",
    "# Formatter les pourcentages\n",
    "for col in ['total_return', 'win_rate', 'buy_hold_return', 'outperformance']:\n",
    "    trading_df[col] = trading_df[col].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "\n",
    "print(trading_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equity curves comparees\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Buy & Hold\n",
    "bh_cumulative = (1 + pd.Series(y_test.values)).cumprod()\n",
    "ax.plot(y_test.index, bh_cumulative, label='Buy & Hold', linewidth=2, color='gray', linestyle='--')\n",
    "\n",
    "# Strategies ML\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(models)))\n",
    "\n",
    "for (name, model), color in zip(models.items(), colors):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Signaux\n",
    "    signals = np.where(y_pred > 0.005, 1, np.where(y_pred < -0.005, -1, 0))\n",
    "    strategy_returns = signals * y_test.values\n",
    "    \n",
    "    cumulative = (1 + pd.Series(strategy_returns)).cumprod()\n",
    "    ax.plot(y_test.index, cumulative, label=name, linewidth=1.5, color=color)\n",
    "\n",
    "ax.axhline(1, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Valeur Portfolio (base 1)')\n",
    "ax.set_title('Equity Curves: Strategies ML vs Buy & Hold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 7 : Strategie Complete - Return Prediction (20 min)\n",
    "\n",
    "### Architecture de la strategie\n",
    "\n",
    "```\n",
    "Universe Selection\n",
    "(Top 50 liquid stocks)\n",
    "        |\n",
    "        v\n",
    "Feature Engineering\n",
    "(Technical indicators)\n",
    "        |\n",
    "        v\n",
    "ML Regression Model\n",
    "(XGBoost Regressor)\n",
    "        |\n",
    "        v\n",
    "Prediction Filtering\n",
    "(|pred| > 1% threshold)\n",
    "        |\n",
    "        v\n",
    "Signal Generation\n",
    "(Long if pred > 1%, Short if pred < -1%)\n",
    "        |\n",
    "        v\n",
    "Position Sizing\n",
    "(Proportionnel a magnitude)\n",
    "        |\n",
    "        v\n",
    "Risk Management\n",
    "(5% max drawdown per position)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategie Complete pour QuantConnect\n",
    "\n",
    "qc_strategy_code = '''\n",
    "from AlgorithmImports import *\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "class ReturnPredictionStrategy(QCAlgorithm):\n",
    "    \"\"\"\n",
    "    Strategie complete de prediction de rendements avec ML.\n",
    "    \n",
    "    - Target: Rendement 5 jours\n",
    "    - Model: Gradient Boosting Regressor (ou XGBoost)\n",
    "    - Signal: |predicted return| > 1%\n",
    "    - Position sizing: Proportionnel a la magnitude\n",
    "    \"\"\"\n",
    "    \n",
    "    def Initialize(self):\n",
    "        # Configuration\n",
    "        self.SetStartDate(2020, 1, 1)\n",
    "        self.SetEndDate(2023, 12, 31)\n",
    "        self.SetCash(100000)\n",
    "        \n",
    "        # Parametres\n",
    "        self.lookback = 252  # 1 an d'historique\n",
    "        self.prediction_horizon = 5  # Predire 5 jours\n",
    "        self.retrain_frequency = 30  # Re-entrainer tous les 30 jours\n",
    "        self.min_signal_threshold = 0.01  # 1% minimum\n",
    "        self.max_positions = 10\n",
    "        self.max_position_size = 0.1  # 10% max par position\n",
    "        \n",
    "        # Universe\n",
    "        self.num_stocks = 50\n",
    "        self.AddUniverse(self.CoarseSelection)\n",
    "        self.UniverseSettings.Resolution = Resolution.Daily\n",
    "        \n",
    "        # ML Model\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.last_train_time = None\n",
    "        \n",
    "        # Storage\n",
    "        self.symbolData = {}\n",
    "        \n",
    "        # Schedule rebalancing\n",
    "        self.Schedule.On(\n",
    "            self.DateRules.EveryDay(),\n",
    "            self.TimeRules.AfterMarketOpen(\"SPY\", 30),\n",
    "            self.Rebalance\n",
    "        )\n",
    "        \n",
    "        self.Log(\"Return Prediction Strategy initialized\")\n",
    "    \n",
    "    def CoarseSelection(self, coarse):\n",
    "        \"\"\"Selectionne les top N actions par liquidite.\"\"\"\n",
    "        filtered = [x for x in coarse \n",
    "                    if x.HasFundamentalData \n",
    "                    and x.Price > 5 \n",
    "                    and x.DollarVolume > 10000000]\n",
    "        \n",
    "        sorted_stocks = sorted(filtered, key=lambda x: x.DollarVolume, reverse=True)\n",
    "        return [x.Symbol for x in sorted_stocks[:self.num_stocks]]\n",
    "    \n",
    "    def OnSecuritiesChanged(self, changes):\n",
    "        \"\"\"Initialise les indicateurs pour les nouveaux titres.\"\"\"\n",
    "        for security in changes.AddedSecurities:\n",
    "            symbol = security.Symbol\n",
    "            if symbol not in self.symbolData:\n",
    "                self.symbolData[symbol] = PredictionSymbolData(\n",
    "                    self, symbol, self.lookback\n",
    "                )\n",
    "        \n",
    "        for security in changes.RemovedSecurities:\n",
    "            symbol = security.Symbol\n",
    "            if symbol in self.symbolData:\n",
    "                del self.symbolData[symbol]\n",
    "    \n",
    "    def Rebalance(self):\n",
    "        \"\"\"Logique principale de rebalancement.\"\"\"\n",
    "        # Verifier si on doit re-entrainer\n",
    "        if self._should_retrain():\n",
    "            self._train_model()\n",
    "        \n",
    "        if self.model is None:\n",
    "            return\n",
    "        \n",
    "        # Generer les predictions\n",
    "        predictions = {}\n",
    "        \n",
    "        for symbol, sd in self.symbolData.items():\n",
    "            if not sd.IsReady:\n",
    "                continue\n",
    "            \n",
    "            features = sd.GetFeatures()\n",
    "            if features is None:\n",
    "                continue\n",
    "            \n",
    "            # Prediction\n",
    "            features_scaled = self.scaler.transform([features])\n",
    "            predicted_return = self.model.predict(features_scaled)[0]\n",
    "            \n",
    "            # Filtrer\n",
    "            if abs(predicted_return) >= self.min_signal_threshold:\n",
    "                predictions[symbol] = predicted_return\n",
    "        \n",
    "        # Trier par magnitude (top predictions)\n",
    "        sorted_predictions = sorted(\n",
    "            predictions.items(), \n",
    "            key=lambda x: abs(x[1]), \n",
    "            reverse=True\n",
    "        )[:self.max_positions]\n",
    "        \n",
    "        # Calculer les poids\n",
    "        targets = {}\n",
    "        total_magnitude = sum(abs(p[1]) for p in sorted_predictions)\n",
    "        \n",
    "        for symbol, pred in sorted_predictions:\n",
    "            # Poids proportionnel a la magnitude\n",
    "            weight = abs(pred) / total_magnitude if total_magnitude > 0 else 0\n",
    "            weight = min(weight, self.max_position_size)  # Cap\n",
    "            \n",
    "            # Direction\n",
    "            if pred > 0:\n",
    "                targets[symbol] = weight\n",
    "            else:\n",
    "                targets[symbol] = -weight  # Short\n",
    "        \n",
    "        # Liquider les positions non dans targets\n",
    "        for symbol in self.Portfolio.Keys:\n",
    "            if symbol not in targets and self.Portfolio[symbol].Invested:\n",
    "                self.Liquidate(symbol)\n",
    "        \n",
    "        # Executer les targets\n",
    "        for symbol, weight in targets.items():\n",
    "            self.SetHoldings(symbol, weight)\n",
    "            self.Log(f\"Position: {symbol.Value} = {weight:.2%}\")\n",
    "    \n",
    "    def _should_retrain(self):\n",
    "        \"\"\"Determine si le modele doit etre re-entraine.\"\"\"\n",
    "        if self.last_train_time is None:\n",
    "            return True\n",
    "        return (self.Time - self.last_train_time).days >= self.retrain_frequency\n",
    "    \n",
    "    def _train_model(self):\n",
    "        \"\"\"Entraine le modele ML.\"\"\"\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        \n",
    "        for symbol, sd in self.symbolData.items():\n",
    "            history = self.History(symbol, self.lookback + self.prediction_horizon, Resolution.Daily)\n",
    "            if history.empty or len(history) < self.lookback:\n",
    "                continue\n",
    "            \n",
    "            # Preparer les donnees\n",
    "            features_list, targets_list = sd.PrepareTrainingData(\n",
    "                history, self.prediction_horizon\n",
    "            )\n",
    "            \n",
    "            X_train.extend(features_list)\n",
    "            y_train.extend(targets_list)\n",
    "        \n",
    "        if len(X_train) < 200:\n",
    "            self.Log(f\"Not enough data for training: {len(X_train)} samples\")\n",
    "            return\n",
    "        \n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "        \n",
    "        # Standardiser\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        # Entrainer\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            min_samples_leaf=20,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        self.last_train_time = self.Time\n",
    "        self.Log(f\"Model trained with {len(X_train)} samples\")\n",
    "    \n",
    "    def OnEndOfAlgorithm(self):\n",
    "        \"\"\"Resume final.\"\"\"\n",
    "        self.Log(\"=\"*60)\n",
    "        self.Log(\"RETURN PREDICTION STRATEGY - SUMMARY\")\n",
    "        self.Log(\"=\"*60)\n",
    "        self.Log(f\"Final Value: ${self.Portfolio.TotalPortfolioValue:,.2f}\")\n",
    "        total_return = (self.Portfolio.TotalPortfolioValue - 100000) / 100000\n",
    "        self.Log(f\"Total Return: {total_return:.1%}\")\n",
    "\n",
    "\n",
    "class PredictionSymbolData:\n",
    "    \"\"\"\n",
    "    Stocke les indicateurs et calcule les features pour un symbole.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, algorithm, symbol, lookback):\n",
    "        self.symbol = symbol\n",
    "        self.algorithm = algorithm\n",
    "        \n",
    "        # Indicateurs\n",
    "        self.rsi = algorithm.RSI(symbol, 14, Resolution.Daily)\n",
    "        self.macd = algorithm.MACD(symbol, 12, 26, 9, Resolution.Daily)\n",
    "        self.bb = algorithm.BB(symbol, 20, 2, Resolution.Daily)\n",
    "        self.sma_20 = algorithm.SMA(symbol, 20, Resolution.Daily)\n",
    "        self.sma_50 = algorithm.SMA(symbol, 50, Resolution.Daily)\n",
    "        self.atr = algorithm.ATR(symbol, 14, Resolution.Daily)\n",
    "        \n",
    "        # Rolling windows pour returns\n",
    "        self.price_window = RollingWindow[float](lookback)\n",
    "        \n",
    "        # Warmup\n",
    "        history = algorithm.History(symbol, lookback, Resolution.Daily)\n",
    "        if not history.empty:\n",
    "            for bar in history.itertuples():\n",
    "                self.price_window.Add(bar.close)\n",
    "    \n",
    "    @property\n",
    "    def IsReady(self):\n",
    "        return (self.rsi.IsReady and \n",
    "                self.macd.IsReady and \n",
    "                self.bb.IsReady and\n",
    "                self.sma_50.IsReady and\n",
    "                self.price_window.IsReady)\n",
    "    \n",
    "    def GetFeatures(self):\n",
    "        \"\"\"Retourne le vecteur de features actuel.\"\"\"\n",
    "        if not self.IsReady:\n",
    "            return None\n",
    "        \n",
    "        price = self.price_window[0]\n",
    "        \n",
    "        # Returns\n",
    "        return_1d = (self.price_window[0] - self.price_window[1]) / self.price_window[1]\n",
    "        return_5d = (self.price_window[0] - self.price_window[5]) / self.price_window[5]\n",
    "        return_20d = (self.price_window[0] - self.price_window[20]) / self.price_window[20]\n",
    "        \n",
    "        # Volatility (20d)\n",
    "        prices = [self.price_window[i] for i in range(20)]\n",
    "        returns = np.diff(prices) / prices[:-1]\n",
    "        volatility = np.std(returns)\n",
    "        \n",
    "        # RSI normalized\n",
    "        rsi_norm = (self.rsi.Current.Value - 50) / 50\n",
    "        \n",
    "        # MA ratio\n",
    "        ma_ratio = self.sma_20.Current.Value / self.sma_50.Current.Value\n",
    "        \n",
    "        # Price to SMA\n",
    "        price_to_sma = price / self.sma_20.Current.Value\n",
    "        \n",
    "        # MACD normalized\n",
    "        macd_norm = self.macd.Current.Value / price\n",
    "        \n",
    "        # Bollinger %B\n",
    "        bb_range = self.bb.UpperBand.Current.Value - self.bb.LowerBand.Current.Value\n",
    "        bb_pct_b = (price - self.bb.LowerBand.Current.Value) / bb_range if bb_range > 0 else 0.5\n",
    "        \n",
    "        return [\n",
    "            return_1d, return_5d, return_20d,\n",
    "            volatility, rsi_norm, ma_ratio,\n",
    "            price_to_sma, macd_norm, bb_pct_b\n",
    "        ]\n",
    "    \n",
    "    def PrepareTrainingData(self, history, horizon):\n",
    "        \"\"\"Prepare les donnees d'entrainement depuis l'historique.\"\"\"\n",
    "        features_list = []\n",
    "        targets_list = []\n",
    "        \n",
    "        df = history.close.unstack(level=0)\n",
    "        if df.empty:\n",
    "            return features_list, targets_list\n",
    "        \n",
    "        prices = df.iloc[:, 0].values\n",
    "        \n",
    "        for i in range(50, len(prices) - horizon):\n",
    "            # Features\n",
    "            ret_1d = (prices[i] - prices[i-1]) / prices[i-1]\n",
    "            ret_5d = (prices[i] - prices[i-5]) / prices[i-5]\n",
    "            ret_20d = (prices[i] - prices[i-20]) / prices[i-20]\n",
    "            \n",
    "            vol = np.std(np.diff(prices[i-20:i]) / prices[i-21:i-1])\n",
    "            \n",
    "            # Simplified features\n",
    "            sma_20 = np.mean(prices[i-20:i])\n",
    "            sma_50 = np.mean(prices[i-50:i])\n",
    "            \n",
    "            features = [\n",
    "                ret_1d, ret_5d, ret_20d, vol,\n",
    "                0,  # RSI placeholder\n",
    "                sma_20 / sma_50,\n",
    "                prices[i] / sma_20,\n",
    "                0,  # MACD placeholder\n",
    "                0.5  # BB placeholder\n",
    "            ]\n",
    "            \n",
    "            # Target: future return\n",
    "            target = (prices[i + horizon] - prices[i]) / prices[i]\n",
    "            \n",
    "            features_list.append(features)\n",
    "            targets_list.append(target)\n",
    "        \n",
    "        return features_list, targets_list\n",
    "'''\n",
    "\n",
    "print(\"Strategie Complete pour QuantConnect:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Composants:\")\n",
    "print(\"  1. Universe: Top 50 par liquidite\")\n",
    "print(\"  2. Model: Gradient Boosting Regressor\")\n",
    "print(\"  3. Target: Rendement 5 jours\")\n",
    "print(\"  4. Signal: |prediction| > 1%\")\n",
    "print(\"  5. Position Sizing: Proportionnel a magnitude\")\n",
    "print(\"  6. Retraining: Tous les 30 jours\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume des parametres recommandes\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PARAMETRES RECOMMANDES POUR PRODUCTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "recommendations = pd.DataFrame([\n",
    "    {'Parametre': 'Modele', 'Valeur Recommandee': 'Gradient Boosting ou XGBoost', 'Raison': 'Bon compromis performance/stabilite'},\n",
    "    {'Parametre': 'n_estimators', 'Valeur Recommandee': '100-200', 'Raison': 'Assez pour capturer patterns'},\n",
    "    {'Parametre': 'max_depth', 'Valeur Recommandee': '3-5', 'Raison': 'Eviter overfitting'},\n",
    "    {'Parametre': 'learning_rate', 'Valeur Recommandee': '0.05-0.1', 'Raison': 'Convergence stable'},\n",
    "    {'Parametre': 'min_samples_leaf', 'Valeur Recommandee': '20-50', 'Raison': 'Regularisation'},\n",
    "    {'Parametre': 'Horizon', 'Valeur Recommandee': '5 jours', 'Raison': 'Compromis signal/noise'},\n",
    "    {'Parametre': 'Seuil signal', 'Valeur Recommandee': '0.5-1%', 'Raison': 'Filtrer les petits mouvements'},\n",
    "    {'Parametre': 'Retraining', 'Valeur Recommandee': '30 jours', 'Raison': 'Adaptation au marche'},\n",
    "    {'Parametre': 'Lookback', 'Valeur Recommandee': '252 jours', 'Raison': '1 an de donnees'},\n",
    "])\n",
    "\n",
    "print(recommendations.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion et Prochaines Etapes\n",
    "\n",
    "### Recapitulatif\n",
    "\n",
    "Dans ce notebook, nous avons couvert :\n",
    "\n",
    "1. **Regression vs Classification** :\n",
    "   - Classification predit la direction\n",
    "   - Regression predit la magnitude (rendement exact)\n",
    "   - Regression permet position sizing intelligent\n",
    "\n",
    "2. **Linear Regression Regularisee** :\n",
    "   - Ridge (L2): shrinkage uniforme\n",
    "   - Lasso (L1): feature selection automatique\n",
    "   - ElasticNet: combine L1 + L2\n",
    "\n",
    "3. **Ensemble Methods** :\n",
    "   - Random Forest: robuste, peu d'overfitting\n",
    "   - Gradient Boosting: plus precis mais risque d'overfitting\n",
    "   - XGBoost: optimise avec regularisation\n",
    "\n",
    "4. **Support Vector Regression** :\n",
    "   - Necessite imperativement le scaling\n",
    "   - Kernel RBF pour non-linearites\n",
    "   - Parametres C, epsilon, gamma\n",
    "\n",
    "5. **Metriques** :\n",
    "   - RMSE, MAE, R2 (standard)\n",
    "   - Direction Accuracy (crucial pour trading)\n",
    "   - Correlation (qualite du ranking)\n",
    "\n",
    "6. **Integration Trading** :\n",
    "   - Conversion prediction -> signal\n",
    "   - Position sizing proportionnel\n",
    "   - Filtrage par seuil minimum\n",
    "\n",
    "7. **Strategie Complete** :\n",
    "   - Pipeline end-to-end\n",
    "   - Retraining periodique\n",
    "   - Risk management integre\n",
    "\n",
    "### Points Cles a Retenir\n",
    "\n",
    "| Concept | Point Cle |\n",
    "|---------|----------|\n",
    "| **Regression** | Predit la magnitude, pas juste la direction |\n",
    "| **Regularisation** | Essentielle pour eviter overfitting |\n",
    "| **Scaling** | Obligatoire pour SVR, recommande pour autres |\n",
    "| **Direction Accuracy** | Metrique la plus importante pour PnL |\n",
    "| **Seuil de signal** | Filtrer les petites predictions non rentables |\n",
    "| **Retraining** | Adapter le modele aux changements de marche |\n",
    "\n",
    "### Comparaison des Modeles\n",
    "\n",
    "| Modele | Avantages | Inconvenients | Usage |\n",
    "|--------|-----------|---------------|-------|\n",
    "| **Ridge** | Simple, stable | Lineaire | Baseline |\n",
    "| **Lasso** | Feature selection | Lineaire | Beaucoup de features |\n",
    "| **Random Forest** | Robuste, feature importance | Moins precis | General |\n",
    "| **Gradient Boosting** | Tres precis | Overfitting | Production |\n",
    "| **XGBoost** | Rapide, regularise | Complexe | Production |\n",
    "| **SVR** | Non-lineaire | Lent, scaling | Petits datasets |\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Les marches sont difficiles a predire (efficience)\n",
    "- Les modeles peuvent overfitter l'historique\n",
    "- Les regimes de marche changent\n",
    "- Les couts de transaction impactent les petites predictions\n",
    "\n",
    "### Prochaines Etapes\n",
    "\n",
    "| Notebook | Contenu |\n",
    "|----------|---------|\n",
    "| **QC-Py-21** | Deep Learning (LSTM, Transformers) |\n",
    "| **QC-Py-22** | Reinforcement Learning |\n",
    "| **QC-Py-23** | Model Ensembling et Stacking |\n",
    "| **QC-Py-24** | Hyperparameter Optimization |\n",
    "\n",
    "### Ressources Complementaires\n",
    "\n",
    "- [scikit-learn Regression](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning)\n",
    "- [XGBoost Documentation](https://xgboost.readthedocs.io/)\n",
    "- [Advances in Financial ML](https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089) - Lopez de Prado\n",
    "- [QuantConnect ML Documentation](https://www.quantconnect.com/docs/v2/writing-algorithms/machine-learning)\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook complete. Vous maitrisez maintenant la regression ML pour la prediction de prix.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
