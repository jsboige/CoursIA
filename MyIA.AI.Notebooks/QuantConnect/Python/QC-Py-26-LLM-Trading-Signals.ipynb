{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC-Py-26 - LLM Trading Signals\n",
    "\n",
    "> **Large Language Models pour l'analyse de marche et la generation de signaux**\n",
    "> Duree: 90 minutes | Niveau: Avance | Python + QuantConnect\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous serez capable de :\n",
    "\n",
    "1. Comprendre les **capacites et limites** des LLMs pour le trading\n",
    "2. Maitriser le **prompt engineering** pour l'analyse financiere\n",
    "3. Utiliser l'API **OpenAI** (GPT-4) pour l'analyse de news\n",
    "4. Utiliser l'API **Anthropic** (Claude) pour le raisonnement structure\n",
    "5. Implementer un systeme de **sentiment analysis** base LLM\n",
    "6. Combiner signaux LLM avec **indicateurs techniques**\n",
    "7. Gerer les **couts API** et la **latence**\n",
    "8. Integrer les LLMs dans un **Alpha Model** QuantConnect\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Notebooks QC-Py-01 a 25 completes\n",
    "- Comprehension du sentiment analysis (QC-Py-17)\n",
    "- Cle API OpenAI et/ou Anthropic\n",
    "- Notions de prompt engineering\n",
    "\n",
    "## Structure du Notebook\n",
    "\n",
    "| Partie | Sujet | Duree |\n",
    "|--------|-------|-------|\n",
    "| 1 | LLMs pour la Finance : Opportunites et Limites | 10 min |\n",
    "| 2 | Prompt Engineering pour le Trading | 15 min |\n",
    "| 3 | Analyse de Sentiment avec GPT-4 | 20 min |\n",
    "| 4 | Raisonnement Structure avec Claude | 15 min |\n",
    "| 5 | Systeme Hybride LLM + Indicateurs | 15 min |\n",
    "| 6 | Integration QuantConnect | 15 min |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction : LLMs dans le Trading\n",
    "\n",
    "### Revolution 2023-2026\n",
    "\n",
    "L'emergence des LLMs a transforme l'analyse financiere :\n",
    "\n",
    "| Annee | Developpement | Impact Trading |\n",
    "|-------|---------------|----------------|\n",
    "| 2022 | ChatGPT lance | Debut des experimentations |\n",
    "| 2023 | GPT-4, Claude 2 | Premiers hedgefunds adoptent |\n",
    "| 2024 | Claude 3.5, GPT-4o | Integration production |\n",
    "| 2025 | Claude Opus 4, GPT-5 | Agents trading autonomes |\n",
    "| 2026 | Modeles specialises finance | Mainstream dans quant finance |\n",
    "\n",
    "### Cas d'Usage\n",
    "\n",
    "```\n",
    "                        LLMs en Trading\n",
    "                              |\n",
    "       +----------------------+----------------------+\n",
    "       |                      |                      |\n",
    "  Analyse de News        Interpretation        Generation\n",
    "  - Sentiment            - Earnings calls      - Reports\n",
    "  - Event extraction     - SEC filings         - Strategies\n",
    "  - Summarization        - Economic data       - Code\n",
    "```\n",
    "\n",
    "### Avantages vs Limites\n",
    "\n",
    "| Avantages | Limites |\n",
    "|-----------|---------||\n",
    "| Comprehension du langage naturel | Couts API eleves |\n",
    "| Raisonnement contextuel | Latence (100ms-2s) |\n",
    "| Generalisation zero-shot | Hallucinations possibles |\n",
    "| Mise a jour des connaissances | Knowledge cutoff |\n",
    "| Multi-tache sans retraining | Non deterministe |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports et configuration\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# API clients (installer si necessaire)\n",
    "# pip install openai anthropic\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "    OPENAI_AVAILABLE = True\n",
    "except ImportError:\n",
    "    OPENAI_AVAILABLE = False\n",
    "    print(\"OpenAI not installed. Run: pip install openai\")\n",
    "\n",
    "try:\n",
    "    import anthropic\n",
    "    ANTHROPIC_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ANTHROPIC_AVAILABLE = False\n",
    "    print(\"Anthropic not installed. Run: pip install anthropic\")\n",
    "\n",
    "# Configuration matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"OpenAI disponible: {OPENAI_AVAILABLE}\")\n",
    "print(f\"Anthropic disponible: {ANTHROPIC_AVAILABLE}\")\n",
    "print(\"\\nNote: Ce notebook necessite des cles API valides pour les appels reels.\")\n",
    "print(\"Les exemples utilisent des reponses simulees si les APIs ne sont pas configurees.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des APIs (utiliser .env en production)\n",
    "\n",
    "@dataclass\n",
    "class LLMConfig:\n",
    "    \"\"\"Configuration pour les LLMs.\"\"\"\n",
    "    openai_api_key: Optional[str] = None\n",
    "    anthropic_api_key: Optional[str] = None\n",
    "    openai_model: str = \"gpt-4o-mini\"  # Economique pour tests\n",
    "    claude_model: str = \"claude-3-5-sonnet-20241022\"  # Equilibre cout/performance\n",
    "    max_tokens: int = 1000\n",
    "    temperature: float = 0.3  # Faible pour coherence\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # Charger depuis environnement si non specifie\n",
    "        if self.openai_api_key is None:\n",
    "            self.openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "        if self.anthropic_api_key is None:\n",
    "            self.anthropic_api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "\n",
    "\n",
    "# Initialiser configuration\n",
    "config = LLMConfig()\n",
    "\n",
    "print(\"Configuration LLM:\")\n",
    "print(f\"  OpenAI Key: {'***' + config.openai_api_key[-4:] if config.openai_api_key else 'Non configuree'}\")\n",
    "print(f\"  Anthropic Key: {'***' + config.anthropic_api_key[-4:] if config.anthropic_api_key else 'Non configuree'}\")\n",
    "print(f\"  OpenAI Model: {config.openai_model}\")\n",
    "print(f\"  Claude Model: {config.claude_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 1 : Couts et Gestion des APIs (10 min)\n",
    "\n",
    "### Tarification (Janvier 2026)\n",
    "\n",
    "| Modele | Input (1M tokens) | Output (1M tokens) | Latence |\n",
    "|--------|-------------------|--------------------|---------|\n",
    "| GPT-4o | $2.50 | $10.00 | 500ms |\n",
    "| GPT-4o-mini | $0.15 | $0.60 | 200ms |\n",
    "| Claude 3.5 Sonnet | $3.00 | $15.00 | 400ms |\n",
    "| Claude 3 Haiku | $0.25 | $1.25 | 150ms |\n",
    "\n",
    "### Estimation des Couts\n",
    "\n",
    "Pour une strategie quotidienne analysant 10 articles par actif, 50 actifs :\n",
    "\n",
    "```\n",
    "Tokens par analyse: ~500 input + ~200 output\n",
    "Analyses par jour: 10 * 50 = 500\n",
    "Tokens par jour: 500 * 700 = 350,000\n",
    "\n",
    "Cout mensuel (GPT-4o-mini):\n",
    "  Input: 350K * 30 * $0.15/1M = $1.58\n",
    "  Output: 100K * 30 * $0.60/1M = $1.80\n",
    "  Total: ~$3.40/mois\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestionnaire de couts et rate limiting\n",
    "\n",
    "@dataclass\n",
    "class CostTracker:\n",
    "    \"\"\"\n",
    "    Suivi des couts et usage des APIs LLM.\n",
    "    \"\"\"\n",
    "    daily_budget: float = 1.0  # $1/jour par defaut\n",
    "    input_tokens_used: int = 0\n",
    "    output_tokens_used: int = 0\n",
    "    requests_made: int = 0\n",
    "    \n",
    "    # Tarification (a jour janvier 2026)\n",
    "    PRICING = {\n",
    "        'gpt-4o': {'input': 2.50 / 1_000_000, 'output': 10.00 / 1_000_000},\n",
    "        'gpt-4o-mini': {'input': 0.15 / 1_000_000, 'output': 0.60 / 1_000_000},\n",
    "        'claude-3-5-sonnet-20241022': {'input': 3.00 / 1_000_000, 'output': 15.00 / 1_000_000},\n",
    "        'claude-3-haiku-20240307': {'input': 0.25 / 1_000_000, 'output': 1.25 / 1_000_000},\n",
    "    }\n",
    "    \n",
    "    def estimate_cost(self, model: str, input_tokens: int, output_tokens: int) -> float:\n",
    "        \"\"\"Estime le cout d'une requete.\"\"\"\n",
    "        if model not in self.PRICING:\n",
    "            return 0.0\n",
    "        \n",
    "        pricing = self.PRICING[model]\n",
    "        return (input_tokens * pricing['input'] + output_tokens * pricing['output'])\n",
    "    \n",
    "    def record_usage(self, model: str, input_tokens: int, output_tokens: int):\n",
    "        \"\"\"Enregistre l'usage.\"\"\"\n",
    "        self.input_tokens_used += input_tokens\n",
    "        self.output_tokens_used += output_tokens\n",
    "        self.requests_made += 1\n",
    "    \n",
    "    def get_total_cost(self, model: str) -> float:\n",
    "        \"\"\"Calcule le cout total.\"\"\"\n",
    "        return self.estimate_cost(model, self.input_tokens_used, self.output_tokens_used)\n",
    "    \n",
    "    def within_budget(self, model: str) -> bool:\n",
    "        \"\"\"Verifie si dans le budget.\"\"\"\n",
    "        return self.get_total_cost(model) < self.daily_budget\n",
    "    \n",
    "    def report(self, model: str) -> str:\n",
    "        \"\"\"Genere un rapport d'usage.\"\"\"\n",
    "        cost = self.get_total_cost(model)\n",
    "        return (\n",
    "            f\"Usage Report:\\n\"\n",
    "            f\"  Requests: {self.requests_made}\\n\"\n",
    "            f\"  Input tokens: {self.input_tokens_used:,}\\n\"\n",
    "            f\"  Output tokens: {self.output_tokens_used:,}\\n\"\n",
    "            f\"  Estimated cost: ${cost:.4f}\\n\"\n",
    "            f\"  Budget remaining: ${self.daily_budget - cost:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Demonstration\n",
    "tracker = CostTracker(daily_budget=5.0)\n",
    "\n",
    "# Simuler quelques requetes\n",
    "for i in range(10):\n",
    "    tracker.record_usage('gpt-4o-mini', input_tokens=500, output_tokens=200)\n",
    "\n",
    "print(tracker.report('gpt-4o-mini'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 2 : Prompt Engineering pour le Trading (15 min)\n",
    "\n",
    "### Principes Cles\n",
    "\n",
    "| Principe | Description | Exemple |\n",
    "|----------|-------------|--------|\n",
    "| **Specificite** | Instructions precises | \"Analyse le sentiment: BULLISH, BEARISH, ou NEUTRAL\" |\n",
    "| **Structure** | Format de sortie defini | JSON avec champs obligatoires |\n",
    "| **Contexte** | Information de fond | \"Tu es un analyste quantitatif senior\" |\n",
    "| **Exemples** | Few-shot learning | 2-3 exemples annotes |\n",
    "| **Contraintes** | Limites claires | \"Reponds en moins de 100 mots\" |\n",
    "\n",
    "### Template de Prompt\n",
    "\n",
    "```\n",
    "[ROLE]\n",
    "Tu es un analyste financier quantitatif...\n",
    "\n",
    "[TASK]\n",
    "Analyse le texte suivant et determine...\n",
    "\n",
    "[FORMAT]\n",
    "Reponds en JSON avec les champs:\n",
    "- sentiment: BULLISH | BEARISH | NEUTRAL\n",
    "- confidence: 0.0 a 1.0\n",
    "- reasoning: explication breve\n",
    "\n",
    "[EXAMPLES]\n",
    "Exemple 1: \"...\" -> {...}\n",
    "\n",
    "[INPUT]\n",
    "{texte a analyser}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Templates de prompts pour le trading\n",
    "\n",
    "class TradingPrompts:\n",
    "    \"\"\"\n",
    "    Collection de prompts optimises pour l'analyse de trading.\n",
    "    \"\"\"\n",
    "    \n",
    "    SENTIMENT_ANALYSIS = \"\"\"\n",
    "You are a senior quantitative analyst at a hedge fund. Your task is to analyze \n",
    "financial news and determine the market sentiment for a specific stock.\n",
    "\n",
    "RULES:\n",
    "1. Focus on facts that could impact stock price in the next 1-5 days\n",
    "2. Ignore general market commentary unless directly relevant\n",
    "3. Weight recent information more heavily\n",
    "4. Consider both explicit statements and implicit implications\n",
    "\n",
    "OUTPUT FORMAT (JSON only, no other text):\n",
    "{{\n",
    "    \"sentiment\": \"BULLISH\" | \"BEARISH\" | \"NEUTRAL\",\n",
    "    \"confidence\": <float 0.0-1.0>,\n",
    "    \"key_factors\": [\"factor1\", \"factor2\"],\n",
    "    \"price_impact\": \"HIGH\" | \"MEDIUM\" | \"LOW\",\n",
    "    \"time_horizon\": \"<number> days\"\n",
    "}}\n",
    "\n",
    "STOCK: {symbol}\n",
    "NEWS:\n",
    "{news_text}\n",
    "\"\"\"\n",
    "\n",
    "    EARNINGS_ANALYSIS = \"\"\"\n",
    "You are analyzing an earnings report for trading signals.\n",
    "\n",
    "Focus on:\n",
    "1. EPS vs expectations (beat/miss magnitude)\n",
    "2. Revenue growth and guidance\n",
    "3. Margin trends\n",
    "4. Forward guidance tone\n",
    "5. Key business metrics mentioned\n",
    "\n",
    "OUTPUT FORMAT (JSON only):\n",
    "{{\n",
    "    \"overall_signal\": \"BUY\" | \"SELL\" | \"HOLD\",\n",
    "    \"earnings_surprise\": <percentage>,\n",
    "    \"guidance_tone\": \"POSITIVE\" | \"NEGATIVE\" | \"NEUTRAL\",\n",
    "    \"key_metrics\": {{}},\n",
    "    \"risk_factors\": [],\n",
    "    \"confidence\": <float 0.0-1.0>\n",
    "}}\n",
    "\n",
    "COMPANY: {symbol}\n",
    "EARNINGS REPORT:\n",
    "{earnings_text}\n",
    "\"\"\"\n",
    "\n",
    "    MULTI_ASSET_SUMMARY = \"\"\"\n",
    "You are summarizing market conditions for portfolio management.\n",
    "\n",
    "Analyze the following market data and news across multiple assets.\n",
    "Identify:\n",
    "1. Overall market sentiment\n",
    "2. Sector rotations or themes\n",
    "3. Risk-on vs risk-off indicators\n",
    "4. Key events in next 7 days\n",
    "\n",
    "OUTPUT FORMAT (JSON only):\n",
    "{{\n",
    "    \"market_regime\": \"RISK_ON\" | \"RISK_OFF\" | \"NEUTRAL\",\n",
    "    \"sector_preferences\": [\"sector1\", \"sector2\"],\n",
    "    \"sectors_to_avoid\": [\"sector3\"],\n",
    "    \"key_events\": [{\"date\": \"...\", \"event\": \"...\", \"impact\": \"...\"}],\n",
    "    \"overall_confidence\": <float 0.0-1.0>\n",
    "}}\n",
    "\n",
    "MARKET DATA:\n",
    "{market_data}\n",
    "\"\"\"\n",
    "\n",
    "    TECHNICAL_INTERPRETATION = \"\"\"\n",
    "You are interpreting technical indicators for trading decisions.\n",
    "\n",
    "Given the following technical data, provide a trading recommendation.\n",
    "Consider indicator confluence and potential false signals.\n",
    "\n",
    "OUTPUT FORMAT (JSON only):\n",
    "{{\n",
    "    \"direction\": \"LONG\" | \"SHORT\" | \"FLAT\",\n",
    "    \"strength\": \"STRONG\" | \"MODERATE\" | \"WEAK\",\n",
    "    \"entry_condition\": \"description\",\n",
    "    \"stop_loss\": \"description or price\",\n",
    "    \"take_profit\": \"description or price\",\n",
    "    \"timeframe\": \"INTRADAY\" | \"SWING\" | \"POSITION\",\n",
    "    \"confidence\": <float 0.0-1.0>\n",
    "}}\n",
    "\n",
    "SYMBOL: {symbol}\n",
    "TECHNICAL DATA:\n",
    "{technical_data}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Demonstration\n",
    "print(\"Templates de Prompts Disponibles:\")\n",
    "print(\"  1. SENTIMENT_ANALYSIS - Analyse de sentiment de news\")\n",
    "print(\"  2. EARNINGS_ANALYSIS - Analyse de resultats\")\n",
    "print(\"  3. MULTI_ASSET_SUMMARY - Resume multi-actifs\")\n",
    "print(\"  4. TECHNICAL_INTERPRETATION - Interpretation technique\")\n",
    "\n",
    "# Exemple de formatage\n",
    "example_prompt = TradingPrompts.SENTIMENT_ANALYSIS.format(\n",
    "    symbol=\"AAPL\",\n",
    "    news_text=\"Apple announces record iPhone sales in Q4, beating analyst expectations by 15%...\"\n",
    ")\n",
    "print(f\"\\nExemple de prompt formate ({len(example_prompt)} caracteres):\")\n",
    "print(example_prompt[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 3 : Analyse de Sentiment avec GPT-4 (20 min)\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "News Feed\n",
    "    |\n",
    "    v\n",
    "Preprocessing\n",
    "  - Filtrage\n",
    "  - Chunking\n",
    "    |\n",
    "    v\n",
    "GPT-4 API\n",
    "  - Prompt template\n",
    "  - JSON parsing\n",
    "    |\n",
    "    v\n",
    "Signal Processing\n",
    "  - Aggregation\n",
    "  - Confidence weighting\n",
    "    |\n",
    "    v\n",
    "Trading Signal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client LLM avec fallback simule\n",
    "\n",
    "class LLMClient:\n",
    "    \"\"\"\n",
    "    Client unifie pour OpenAI et Anthropic avec fallback simule.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: LLMConfig):\n",
    "        self.config = config\n",
    "        self.cost_tracker = CostTracker()\n",
    "        \n",
    "        # Initialiser clients si disponibles\n",
    "        self.openai_client = None\n",
    "        self.anthropic_client = None\n",
    "        \n",
    "        if OPENAI_AVAILABLE and config.openai_api_key:\n",
    "            self.openai_client = openai.OpenAI(api_key=config.openai_api_key)\n",
    "        \n",
    "        if ANTHROPIC_AVAILABLE and config.anthropic_api_key:\n",
    "            self.anthropic_client = anthropic.Anthropic(api_key=config.anthropic_api_key)\n",
    "    \n",
    "    def _simulate_response(self, prompt: str, task_type: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Simule une reponse LLM pour demonstration.\n",
    "        \"\"\"\n",
    "        # Analyser le prompt pour determiner le sentiment simule\n",
    "        positive_words = ['beat', 'record', 'growth', 'exceed', 'strong', 'bullish']\n",
    "        negative_words = ['miss', 'decline', 'weak', 'loss', 'bearish', 'warning']\n",
    "        \n",
    "        prompt_lower = prompt.lower()\n",
    "        pos_count = sum(1 for w in positive_words if w in prompt_lower)\n",
    "        neg_count = sum(1 for w in negative_words if w in prompt_lower)\n",
    "        \n",
    "        if pos_count > neg_count:\n",
    "            sentiment = \"BULLISH\"\n",
    "            confidence = min(0.5 + pos_count * 0.1, 0.9)\n",
    "        elif neg_count > pos_count:\n",
    "            sentiment = \"BEARISH\"\n",
    "            confidence = min(0.5 + neg_count * 0.1, 0.9)\n",
    "        else:\n",
    "            sentiment = \"NEUTRAL\"\n",
    "            confidence = 0.5\n",
    "        \n",
    "        return {\n",
    "            \"sentiment\": sentiment,\n",
    "            \"confidence\": confidence,\n",
    "            \"key_factors\": [\"simulated_factor_1\", \"simulated_factor_2\"],\n",
    "            \"price_impact\": \"MEDIUM\",\n",
    "            \"time_horizon\": \"5 days\",\n",
    "            \"_simulated\": True\n",
    "        }\n",
    "    \n",
    "    def analyze_with_openai(self, prompt: str) -> Tuple[Dict, Dict]:\n",
    "        \"\"\"\n",
    "        Analyse avec OpenAI GPT-4.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (result_dict, usage_dict)\n",
    "        \"\"\"\n",
    "        if self.openai_client is None:\n",
    "            result = self._simulate_response(prompt, \"sentiment\")\n",
    "            usage = {\"input_tokens\": len(prompt) // 4, \"output_tokens\": 100, \"simulated\": True}\n",
    "            return result, usage\n",
    "        \n",
    "        try:\n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=self.config.openai_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a financial analyst. Always respond with valid JSON.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=self.config.max_tokens,\n",
    "                temperature=self.config.temperature,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            content = response.choices[0].message.content\n",
    "            result = json.loads(content)\n",
    "            \n",
    "            usage = {\n",
    "                \"input_tokens\": response.usage.prompt_tokens,\n",
    "                \"output_tokens\": response.usage.completion_tokens,\n",
    "                \"simulated\": False\n",
    "            }\n",
    "            \n",
    "            self.cost_tracker.record_usage(\n",
    "                self.config.openai_model,\n",
    "                usage[\"input_tokens\"],\n",
    "                usage[\"output_tokens\"]\n",
    "            )\n",
    "            \n",
    "            return result, usage\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"OpenAI error: {e}\")\n",
    "            result = self._simulate_response(prompt, \"sentiment\")\n",
    "            result[\"_error\"] = str(e)\n",
    "            return result, {\"simulated\": True, \"error\": str(e)}\n",
    "    \n",
    "    def analyze_with_claude(self, prompt: str) -> Tuple[Dict, Dict]:\n",
    "        \"\"\"\n",
    "        Analyse avec Anthropic Claude.\n",
    "        \"\"\"\n",
    "        if self.anthropic_client is None:\n",
    "            result = self._simulate_response(prompt, \"sentiment\")\n",
    "            usage = {\"input_tokens\": len(prompt) // 4, \"output_tokens\": 100, \"simulated\": True}\n",
    "            return result, usage\n",
    "        \n",
    "        try:\n",
    "            response = self.anthropic_client.messages.create(\n",
    "                model=self.config.claude_model,\n",
    "                max_tokens=self.config.max_tokens,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            content = response.content[0].text\n",
    "            \n",
    "            # Extraire JSON du contenu\n",
    "            try:\n",
    "                # Chercher JSON dans la reponse\n",
    "                start = content.find('{')\n",
    "                end = content.rfind('}') + 1\n",
    "                if start != -1 and end > start:\n",
    "                    result = json.loads(content[start:end])\n",
    "                else:\n",
    "                    result = {\"raw_response\": content}\n",
    "            except json.JSONDecodeError:\n",
    "                result = {\"raw_response\": content}\n",
    "            \n",
    "            usage = {\n",
    "                \"input_tokens\": response.usage.input_tokens,\n",
    "                \"output_tokens\": response.usage.output_tokens,\n",
    "                \"simulated\": False\n",
    "            }\n",
    "            \n",
    "            self.cost_tracker.record_usage(\n",
    "                self.config.claude_model,\n",
    "                usage[\"input_tokens\"],\n",
    "                usage[\"output_tokens\"]\n",
    "            )\n",
    "            \n",
    "            return result, usage\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Claude error: {e}\")\n",
    "            result = self._simulate_response(prompt, \"sentiment\")\n",
    "            result[\"_error\"] = str(e)\n",
    "            return result, {\"simulated\": True, \"error\": str(e)}\n",
    "\n",
    "\n",
    "# Initialiser client\n",
    "llm_client = LLMClient(config)\n",
    "print(\"LLM Client initialise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyseur de sentiment complet\n",
    "\n",
    "@dataclass\n",
    "class SentimentResult:\n",
    "    \"\"\"Resultat d'analyse de sentiment.\"\"\"\n",
    "    symbol: str\n",
    "    sentiment: str  # BULLISH, BEARISH, NEUTRAL\n",
    "    confidence: float\n",
    "    key_factors: List[str]\n",
    "    price_impact: str\n",
    "    time_horizon: str\n",
    "    source: str  # openai, claude, simulated\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    \n",
    "    def to_signal(self) -> float:\n",
    "        \"\"\"Convertit en signal numerique [-1, 1].\"\"\"\n",
    "        base = {\n",
    "            \"BULLISH\": 1.0,\n",
    "            \"BEARISH\": -1.0,\n",
    "            \"NEUTRAL\": 0.0\n",
    "        }.get(self.sentiment, 0.0)\n",
    "        \n",
    "        return base * self.confidence\n",
    "\n",
    "\n",
    "class NewsSentimentAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyseur de sentiment pour news financieres.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client: LLMClient, provider: str = \"openai\"):\n",
    "        self.client = llm_client\n",
    "        self.provider = provider\n",
    "        self.results_cache = {}\n",
    "    \n",
    "    def analyze(self, symbol: str, news_text: str) -> SentimentResult:\n",
    "        \"\"\"\n",
    "        Analyse le sentiment d'un texte de news.\n",
    "        \"\"\"\n",
    "        # Construire prompt\n",
    "        prompt = TradingPrompts.SENTIMENT_ANALYSIS.format(\n",
    "            symbol=symbol,\n",
    "            news_text=news_text[:2000]  # Limiter la taille\n",
    "        )\n",
    "        \n",
    "        # Appeler LLM\n",
    "        if self.provider == \"openai\":\n",
    "            result, usage = self.client.analyze_with_openai(prompt)\n",
    "        else:\n",
    "            result, usage = self.client.analyze_with_claude(prompt)\n",
    "        \n",
    "        # Parser resultat\n",
    "        sentiment_result = SentimentResult(\n",
    "            symbol=symbol,\n",
    "            sentiment=result.get(\"sentiment\", \"NEUTRAL\"),\n",
    "            confidence=result.get(\"confidence\", 0.5),\n",
    "            key_factors=result.get(\"key_factors\", []),\n",
    "            price_impact=result.get(\"price_impact\", \"MEDIUM\"),\n",
    "            time_horizon=result.get(\"time_horizon\", \"5 days\"),\n",
    "            source=\"simulated\" if usage.get(\"simulated\") else self.provider\n",
    "        )\n",
    "        \n",
    "        return sentiment_result\n",
    "    \n",
    "    def analyze_batch(self, symbol: str, news_list: List[str]) -> List[SentimentResult]:\n",
    "        \"\"\"\n",
    "        Analyse un batch de news.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for news in news_list:\n",
    "            result = self.analyze(symbol, news)\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def aggregate_signals(self, results: List[SentimentResult]) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Agrege plusieurs signaux en un signal unique.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (signal_aggrege, confiance_moyenne)\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        signals = [r.to_signal() for r in results]\n",
    "        confidences = [r.confidence for r in results]\n",
    "        \n",
    "        # Moyenne ponderee par confiance\n",
    "        total_weight = sum(confidences)\n",
    "        if total_weight == 0:\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        weighted_signal = sum(s * c for s, c in zip(signals, confidences)) / total_weight\n",
    "        avg_confidence = np.mean(confidences)\n",
    "        \n",
    "        return weighted_signal, avg_confidence\n",
    "\n",
    "\n",
    "# Demonstration\n",
    "analyzer = NewsSentimentAnalyzer(llm_client, provider=\"openai\")\n",
    "\n",
    "# Exemples de news\n",
    "sample_news = [\n",
    "    \"Apple reported record Q4 revenue of $95 billion, beating analyst expectations by 8%. iPhone sales grew 15% year-over-year.\",\n",
    "    \"Apple faces supply chain challenges in China, potentially impacting holiday quarter shipments.\",\n",
    "    \"Goldman Sachs upgrades Apple to Buy, citing strong services growth and AI opportunities.\"\n",
    "]\n",
    "\n",
    "print(\"Analyse de Sentiment - AAPL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "for i, news in enumerate(sample_news):\n",
    "    result = analyzer.analyze(\"AAPL\", news)\n",
    "    results.append(result)\n",
    "    print(f\"\\nNews {i+1}:\")\n",
    "    print(f\"  Sentiment: {result.sentiment}\")\n",
    "    print(f\"  Confidence: {result.confidence:.2f}\")\n",
    "    print(f\"  Signal: {result.to_signal():.2f}\")\n",
    "    print(f\"  Source: {result.source}\")\n",
    "\n",
    "# Aggreger\n",
    "agg_signal, agg_conf = analyzer.aggregate_signals(results)\n",
    "print(f\"\\nSignal Agrege: {agg_signal:.2f} (confiance: {agg_conf:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 4 : Raisonnement Structure avec Claude (15 min)\n",
    "\n",
    "### Avantages de Claude pour l'Analyse\n",
    "\n",
    "| Aspect | GPT-4 | Claude |\n",
    "|--------|-------|--------|\n",
    "| **Raisonnement** | Bon | Excellent |\n",
    "| **Instructions longues** | Bon | Excellent |\n",
    "| **Coherence JSON** | Excellent | Bon |\n",
    "| **Cout** | Moyen | Similaire |\n",
    "| **Contexte** | 128K | 200K |\n",
    "\n",
    "### Chain-of-Thought pour Decisions Complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyseur avec Chain-of-Thought\n",
    "\n",
    "class ChainOfThoughtAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyseur utilisant le raisonnement en chaine.\n",
    "    \"\"\"\n",
    "    \n",
    "    COT_PROMPT = \"\"\"\n",
    "You are a senior portfolio manager making trading decisions.\n",
    "\n",
    "THINK STEP BY STEP:\n",
    "\n",
    "Step 1: Identify the key facts\n",
    "- List the most important data points\n",
    "- Note any conflicting information\n",
    "\n",
    "Step 2: Assess market context\n",
    "- Current market regime (risk-on/risk-off)\n",
    "- Sector trends\n",
    "- Macro factors\n",
    "\n",
    "Step 3: Evaluate technical setup\n",
    "- Trend direction\n",
    "- Support/resistance levels\n",
    "- Momentum indicators\n",
    "\n",
    "Step 4: Consider risks\n",
    "- What could go wrong?\n",
    "- Position sizing implications\n",
    "\n",
    "Step 5: Make decision\n",
    "- Clear action (BUY/SELL/HOLD)\n",
    "- Entry/exit criteria\n",
    "- Position size recommendation\n",
    "\n",
    "FINAL OUTPUT (JSON):\n",
    "{{\n",
    "    \"reasoning_steps\": [\n",
    "        {{\"step\": 1, \"title\": \"Key Facts\", \"content\": \"...\"}},\n",
    "        {{\"step\": 2, \"title\": \"Market Context\", \"content\": \"...\"}},\n",
    "        {{\"step\": 3, \"title\": \"Technical Setup\", \"content\": \"...\"}},\n",
    "        {{\"step\": 4, \"title\": \"Risk Assessment\", \"content\": \"...\"}},\n",
    "        {{\"step\": 5, \"title\": \"Decision\", \"content\": \"...\"}}\n",
    "    ],\n",
    "    \"final_decision\": {{\n",
    "        \"action\": \"BUY\" | \"SELL\" | \"HOLD\",\n",
    "        \"conviction\": \"HIGH\" | \"MEDIUM\" | \"LOW\",\n",
    "        \"position_size\": \"percentage of portfolio\",\n",
    "        \"stop_loss\": \"description\",\n",
    "        \"take_profit\": \"description\",\n",
    "        \"time_horizon\": \"days/weeks\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "ANALYSIS CONTEXT:\n",
    "Symbol: {symbol}\n",
    "\n",
    "NEWS:\n",
    "{news}\n",
    "\n",
    "TECHNICAL DATA:\n",
    "{technical}\n",
    "\n",
    "PORTFOLIO CONTEXT:\n",
    "{portfolio}\n",
    "\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client: LLMClient):\n",
    "        self.client = llm_client\n",
    "    \n",
    "    def analyze(self, symbol: str, news: str, technical: Dict, portfolio: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyse complete avec raisonnement structure.\n",
    "        \"\"\"\n",
    "        prompt = self.COT_PROMPT.format(\n",
    "            symbol=symbol,\n",
    "            news=news,\n",
    "            technical=json.dumps(technical, indent=2),\n",
    "            portfolio=json.dumps(portfolio, indent=2)\n",
    "        )\n",
    "        \n",
    "        # Utiliser Claude pour meilleur raisonnement\n",
    "        result, usage = self.client.analyze_with_claude(prompt)\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# Demonstration\n",
    "cot_analyzer = ChainOfThoughtAnalyzer(llm_client)\n",
    "\n",
    "# Donnees d'exemple\n",
    "sample_technical = {\n",
    "    \"price\": 185.50,\n",
    "    \"sma_20\": 182.30,\n",
    "    \"sma_50\": 178.90,\n",
    "    \"rsi_14\": 62,\n",
    "    \"macd\": {\"macd\": 2.1, \"signal\": 1.8, \"histogram\": 0.3},\n",
    "    \"volume_ratio\": 1.2,\n",
    "    \"support\": 180.00,\n",
    "    \"resistance\": 190.00\n",
    "}\n",
    "\n",
    "sample_portfolio = {\n",
    "    \"current_position\": \"0%\",\n",
    "    \"sector_exposure\": {\"technology\": \"25%\"},\n",
    "    \"cash_available\": \"15%\",\n",
    "    \"risk_budget\": \"moderate\"\n",
    "}\n",
    "\n",
    "combined_news = \"\\n\".join(sample_news)\n",
    "\n",
    "print(\"Chain-of-Thought Analysis - AAPL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cot_result = cot_analyzer.analyze(\n",
    "    \"AAPL\",\n",
    "    combined_news,\n",
    "    sample_technical,\n",
    "    sample_portfolio\n",
    ")\n",
    "\n",
    "if \"reasoning_steps\" in cot_result:\n",
    "    print(\"\\nRaisonnement:\")\n",
    "    for step in cot_result.get(\"reasoning_steps\", []):\n",
    "        print(f\"  Step {step.get('step', '?')}: {step.get('title', 'N/A')}\")\n",
    "        print(f\"    {step.get('content', '')[:100]}...\")\n",
    "\n",
    "if \"final_decision\" in cot_result:\n",
    "    decision = cot_result[\"final_decision\"]\n",
    "    print(f\"\\nDecision Finale:\")\n",
    "    print(f\"  Action: {decision.get('action', 'N/A')}\")\n",
    "    print(f\"  Conviction: {decision.get('conviction', 'N/A')}\")\n",
    "    print(f\"  Position Size: {decision.get('position_size', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"\\nResultat brut: {json.dumps(cot_result, indent=2)[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 5 : Systeme Hybride LLM + Indicateurs (15 min)\n",
    "\n",
    "### Architecture Hybride\n",
    "\n",
    "```\n",
    "             +----------------+\n",
    "             |   LLM Signal   |\n",
    "             | (Sentiment)    |\n",
    "             +-------+--------+\n",
    "                     |  0.4\n",
    "                     v\n",
    "+------------+  +----+----+  +------------+\n",
    "| Technical  |  | Signal  |  | Risk       |\n",
    "| Indicators +->| Fusion  |<-+ Filters    |\n",
    "|   0.4      |  +---------+  |            |\n",
    "+------------+       |       +------------+\n",
    "                     v\n",
    "             +-------+--------+\n",
    "             | Final Signal   |\n",
    "             | + Position     |\n",
    "             +----------------+\n",
    "```\n",
    "\n",
    "### Avantages du Systeme Hybride\n",
    "\n",
    "| Aspect | LLM Seul | Technique Seul | Hybride |\n",
    "|--------|----------|----------------|-------|\n",
    "| Comprehension news | Excellent | Aucune | Excellent |\n",
    "| Objectivite | Moyenne | Excellente | Bonne |\n",
    "| Latence | Haute | Faible | Moyenne |\n",
    "| Cout | Eleve | Faible | Modere |\n",
    "| Robustesse | Moyenne | Moyenne | Haute |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systeme de fusion de signaux hybride\n",
    "\n",
    "@dataclass\n",
    "class HybridSignal:\n",
    "    \"\"\"Signal de trading hybride.\"\"\"\n",
    "    symbol: str\n",
    "    llm_signal: float  # [-1, 1]\n",
    "    llm_confidence: float\n",
    "    technical_signal: float  # [-1, 1]\n",
    "    technical_confidence: float\n",
    "    fused_signal: float\n",
    "    final_direction: str  # BUY, SELL, HOLD\n",
    "    position_size: float  # 0 to 1\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "\n",
    "class HybridSignalSystem:\n",
    "    \"\"\"\n",
    "    Systeme hybride combinant LLM et indicateurs techniques.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_weight: float = 0.4,\n",
    "        technical_weight: float = 0.4,\n",
    "        agreement_bonus: float = 0.2,\n",
    "        signal_threshold: float = 0.3\n",
    "    ):\n",
    "        self.llm_weight = llm_weight\n",
    "        self.technical_weight = technical_weight\n",
    "        self.agreement_bonus = agreement_bonus\n",
    "        self.signal_threshold = signal_threshold\n",
    "    \n",
    "    def compute_technical_signal(self, data: Dict) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Calcule le signal technique a partir des indicateurs.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (signal, confidence)\n",
    "        \"\"\"\n",
    "        signals = []\n",
    "        \n",
    "        # Trend (SMA)\n",
    "        if 'sma_20' in data and 'sma_50' in data and 'price' in data:\n",
    "            price = data['price']\n",
    "            sma20 = data['sma_20']\n",
    "            sma50 = data['sma_50']\n",
    "            \n",
    "            # Price above both SMAs = bullish\n",
    "            if price > sma20 > sma50:\n",
    "                signals.append(1.0)\n",
    "            elif price < sma20 < sma50:\n",
    "                signals.append(-1.0)\n",
    "            else:\n",
    "                signals.append(0.0)\n",
    "        \n",
    "        # RSI\n",
    "        if 'rsi_14' in data:\n",
    "            rsi = data['rsi_14']\n",
    "            if rsi > 70:\n",
    "                signals.append(-0.5)  # Overbought\n",
    "            elif rsi < 30:\n",
    "                signals.append(0.5)   # Oversold\n",
    "            elif rsi > 50:\n",
    "                signals.append(0.25)\n",
    "            else:\n",
    "                signals.append(-0.25)\n",
    "        \n",
    "        # MACD\n",
    "        if 'macd' in data:\n",
    "            macd = data['macd']\n",
    "            if isinstance(macd, dict):\n",
    "                histogram = macd.get('histogram', 0)\n",
    "                if histogram > 0:\n",
    "                    signals.append(0.5)\n",
    "                else:\n",
    "                    signals.append(-0.5)\n",
    "        \n",
    "        # Volume\n",
    "        if 'volume_ratio' in data:\n",
    "            vol_ratio = data['volume_ratio']\n",
    "            if vol_ratio > 1.5:\n",
    "                # High volume confirms the move\n",
    "                signals.append(0.25 if np.mean(signals) > 0 else -0.25)\n",
    "        \n",
    "        if not signals:\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        signal = np.clip(np.mean(signals), -1, 1)\n",
    "        \n",
    "        # Confidence based on signal agreement\n",
    "        signs = [np.sign(s) for s in signals if s != 0]\n",
    "        if signs:\n",
    "            agreement = abs(sum(signs)) / len(signs)\n",
    "            confidence = 0.5 + 0.5 * agreement\n",
    "        else:\n",
    "            confidence = 0.5\n",
    "        \n",
    "        return signal, confidence\n",
    "    \n",
    "    def fuse_signals(\n",
    "        self,\n",
    "        llm_signal: float,\n",
    "        llm_confidence: float,\n",
    "        technical_signal: float,\n",
    "        technical_confidence: float\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Fusionne les signaux LLM et technique.\n",
    "        \"\"\"\n",
    "        # Ponderation de base\n",
    "        base_signal = (\n",
    "            self.llm_weight * llm_signal * llm_confidence +\n",
    "            self.technical_weight * technical_signal * technical_confidence\n",
    "        )\n",
    "        \n",
    "        # Bonus si les deux signaux sont d'accord\n",
    "        same_direction = np.sign(llm_signal) == np.sign(technical_signal)\n",
    "        if same_direction and llm_signal != 0 and technical_signal != 0:\n",
    "            agreement_strength = min(abs(llm_signal), abs(technical_signal))\n",
    "            bonus = self.agreement_bonus * agreement_strength * np.sign(llm_signal)\n",
    "            base_signal += bonus\n",
    "        \n",
    "        # Penalite si en desaccord fort\n",
    "        if not same_direction:\n",
    "            # Reduire le signal si desaccord\n",
    "            base_signal *= 0.7\n",
    "        \n",
    "        return np.clip(base_signal, -1, 1)\n",
    "    \n",
    "    def compute_position_size(self, signal: float, confidence: float) -> float:\n",
    "        \"\"\"\n",
    "        Calcule la taille de position basee sur le signal.\n",
    "        \"\"\"\n",
    "        if abs(signal) < self.signal_threshold:\n",
    "            return 0.0\n",
    "        \n",
    "        # Position size proportionnelle au signal et a la confiance\n",
    "        base_size = abs(signal) * confidence\n",
    "        \n",
    "        # Scaling non-lineaire pour reduire les positions extremes\n",
    "        scaled_size = np.tanh(base_size * 2) * 0.5  # Max 50% of portfolio\n",
    "        \n",
    "        return scaled_size\n",
    "    \n",
    "    def generate_signal(\n",
    "        self,\n",
    "        symbol: str,\n",
    "        llm_signal: float,\n",
    "        llm_confidence: float,\n",
    "        technical_data: Dict\n",
    "    ) -> HybridSignal:\n",
    "        \"\"\"\n",
    "        Genere un signal hybride complet.\n",
    "        \"\"\"\n",
    "        # Signal technique\n",
    "        tech_signal, tech_confidence = self.compute_technical_signal(technical_data)\n",
    "        \n",
    "        # Fusion\n",
    "        fused = self.fuse_signals(\n",
    "            llm_signal, llm_confidence,\n",
    "            tech_signal, tech_confidence\n",
    "        )\n",
    "        \n",
    "        # Direction\n",
    "        if fused > self.signal_threshold:\n",
    "            direction = \"BUY\"\n",
    "        elif fused < -self.signal_threshold:\n",
    "            direction = \"SELL\"\n",
    "        else:\n",
    "            direction = \"HOLD\"\n",
    "        \n",
    "        # Position size\n",
    "        avg_confidence = (llm_confidence + tech_confidence) / 2\n",
    "        position_size = self.compute_position_size(fused, avg_confidence)\n",
    "        \n",
    "        return HybridSignal(\n",
    "            symbol=symbol,\n",
    "            llm_signal=llm_signal,\n",
    "            llm_confidence=llm_confidence,\n",
    "            technical_signal=tech_signal,\n",
    "            technical_confidence=tech_confidence,\n",
    "            fused_signal=fused,\n",
    "            final_direction=direction,\n",
    "            position_size=position_size\n",
    "        )\n",
    "\n",
    "\n",
    "# Demonstration\n",
    "hybrid_system = HybridSignalSystem()\n",
    "\n",
    "# Utiliser les resultats precedents\n",
    "print(\"Systeme Hybride LLM + Technique\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "hybrid_signal = hybrid_system.generate_signal(\n",
    "    symbol=\"AAPL\",\n",
    "    llm_signal=agg_signal,\n",
    "    llm_confidence=agg_conf,\n",
    "    technical_data=sample_technical\n",
    ")\n",
    "\n",
    "print(f\"\\nSignaux d'entree:\")\n",
    "print(f\"  LLM Signal: {hybrid_signal.llm_signal:.2f} (conf: {hybrid_signal.llm_confidence:.2f})\")\n",
    "print(f\"  Technical Signal: {hybrid_signal.technical_signal:.2f} (conf: {hybrid_signal.technical_confidence:.2f})\")\n",
    "\n",
    "print(f\"\\nSignal Fusionne:\")\n",
    "print(f\"  Fused Signal: {hybrid_signal.fused_signal:.2f}\")\n",
    "print(f\"  Direction: {hybrid_signal.final_direction}\")\n",
    "print(f\"  Position Size: {hybrid_signal.position_size:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du systeme hybride\n",
    "\n",
    "def visualize_hybrid_signals(signals: List[HybridSignal]):\n",
    "    \"\"\"\n",
    "    Visualise les signaux hybrides.\n",
    "    \"\"\"\n",
    "    if not signals:\n",
    "        print(\"Pas de signaux a visualiser\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Signal comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    symbols = [s.symbol for s in signals]\n",
    "    llm_signals = [s.llm_signal for s in signals]\n",
    "    tech_signals = [s.technical_signal for s in signals]\n",
    "    fused_signals = [s.fused_signal for s in signals]\n",
    "    \n",
    "    x = np.arange(len(symbols))\n",
    "    width = 0.25\n",
    "    \n",
    "    ax1.bar(x - width, llm_signals, width, label='LLM', color='blue', alpha=0.7)\n",
    "    ax1.bar(x, tech_signals, width, label='Technical', color='green', alpha=0.7)\n",
    "    ax1.bar(x + width, fused_signals, width, label='Fused', color='red', alpha=0.7)\n",
    "    \n",
    "    ax1.set_xlabel('Symbol')\n",
    "    ax1.set_ylabel('Signal Strength')\n",
    "    ax1.set_title('Signal Comparison', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(symbols)\n",
    "    ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Confidence levels\n",
    "    ax2 = axes[0, 1]\n",
    "    llm_conf = [s.llm_confidence for s in signals]\n",
    "    tech_conf = [s.technical_confidence for s in signals]\n",
    "    \n",
    "    ax2.bar(x - width/2, llm_conf, width, label='LLM Confidence', color='blue', alpha=0.7)\n",
    "    ax2.bar(x + width/2, tech_conf, width, label='Technical Confidence', color='green', alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlabel('Symbol')\n",
    "    ax2.set_ylabel('Confidence')\n",
    "    ax2.set_title('Confidence Levels', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(symbols)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Position sizes\n",
    "    ax3 = axes[1, 0]\n",
    "    positions = [s.position_size * 100 for s in signals]\n",
    "    colors = ['green' if s.final_direction == 'BUY' else 'red' if s.final_direction == 'SELL' else 'gray' \n",
    "              for s in signals]\n",
    "    \n",
    "    ax3.bar(symbols, positions, color=colors, alpha=0.7)\n",
    "    ax3.set_xlabel('Symbol')\n",
    "    ax3.set_ylabel('Position Size (%)')\n",
    "    ax3.set_title('Recommended Position Sizes', fontsize=12, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Signal scatter\n",
    "    ax4 = axes[1, 1]\n",
    "    for s in signals:\n",
    "        color = 'green' if s.final_direction == 'BUY' else 'red' if s.final_direction == 'SELL' else 'gray'\n",
    "        ax4.scatter(s.llm_signal, s.technical_signal, s=200, c=color, alpha=0.7, \n",
    "                   label=f\"{s.symbol} ({s.final_direction})\")\n",
    "    \n",
    "    ax4.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax4.axvline(x=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax4.set_xlabel('LLM Signal')\n",
    "    ax4.set_ylabel('Technical Signal')\n",
    "    ax4.set_title('Signal Agreement', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xlim(-1.2, 1.2)\n",
    "    ax4.set_ylim(-1.2, 1.2)\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Generer quelques signaux de demonstration\n",
    "demo_symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN']\n",
    "demo_signals = []\n",
    "\n",
    "# Donnees simulees\n",
    "demo_data = {\n",
    "    'AAPL': {'price': 185, 'sma_20': 182, 'sma_50': 178, 'rsi_14': 62, 'macd': {'histogram': 0.3}, 'volume_ratio': 1.2},\n",
    "    'MSFT': {'price': 380, 'sma_20': 385, 'sma_50': 375, 'rsi_14': 55, 'macd': {'histogram': -0.2}, 'volume_ratio': 0.9},\n",
    "    'GOOGL': {'price': 140, 'sma_20': 138, 'sma_50': 142, 'rsi_14': 48, 'macd': {'histogram': 0.1}, 'volume_ratio': 1.0},\n",
    "    'AMZN': {'price': 175, 'sma_20': 172, 'sma_50': 168, 'rsi_14': 72, 'macd': {'histogram': 0.5}, 'volume_ratio': 1.4},\n",
    "}\n",
    "\n",
    "demo_llm = {\n",
    "    'AAPL': (0.6, 0.75),\n",
    "    'MSFT': (0.2, 0.6),\n",
    "    'GOOGL': (-0.3, 0.55),\n",
    "    'AMZN': (0.5, 0.8),\n",
    "}\n",
    "\n",
    "for symbol in demo_symbols:\n",
    "    llm_sig, llm_conf = demo_llm[symbol]\n",
    "    signal = hybrid_system.generate_signal(\n",
    "        symbol=symbol,\n",
    "        llm_signal=llm_sig,\n",
    "        llm_confidence=llm_conf,\n",
    "        technical_data=demo_data[symbol]\n",
    "    )\n",
    "    demo_signals.append(signal)\n",
    "\n",
    "visualize_hybrid_signals(demo_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 6 : Integration QuantConnect (15 min)\n",
    "\n",
    "### Architecture pour Production\n",
    "\n",
    "```\n",
    "EXTERNE (API Keys secrets)\n",
    "        |\n",
    "        v\n",
    "QuantConnect Scheduled Event (Daily)\n",
    "        |\n",
    "        v\n",
    "Fetch News (NewsAPI, TiingoNews)\n",
    "        |\n",
    "        v\n",
    "LLM Analysis (OpenAI/Anthropic)\n",
    "        |\n",
    "        v\n",
    "Signal Fusion\n",
    "        |\n",
    "        v\n",
    "Alpha Model Insights\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code QuantConnect pour LLM Alpha Model\n",
    "\n",
    "qc_llm_code = '''\n",
    "from AlgorithmImports import *\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class LLMTradingAlphaModel(AlphaModel):\n",
    "    \"\"\"\n",
    "    Alpha Model utilisant les LLMs pour l'analyse de sentiment.\n",
    "    \n",
    "    Features:\n",
    "    - Analyse quotidienne des news\n",
    "    - Fusion avec indicateurs techniques\n",
    "    - Gestion des couts API\n",
    "    - Caching des resultats\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prompt template\n",
    "    SENTIMENT_PROMPT = \"\"\"\n",
    "Analyze the following news for {symbol} and provide a trading signal.\n",
    "\n",
    "NEWS:\n",
    "{news}\n",
    "\n",
    "Respond in JSON format only:\n",
    "{{\"sentiment\": \"BULLISH\"|\"BEARISH\"|\"NEUTRAL\", \"confidence\": 0.0-1.0, \"reasoning\": \"brief explanation\"}}\n",
    "\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        openai_api_key: str,\n",
    "        model: str = \"gpt-4o-mini\",\n",
    "        max_daily_cost: float = 1.0,\n",
    "        technical_weight: float = 0.4,\n",
    "        llm_weight: float = 0.4\n",
    "    ):\n",
    "        self.api_key = openai_api_key\n",
    "        self.model = model\n",
    "        self.max_daily_cost = max_daily_cost\n",
    "        self.technical_weight = technical_weight\n",
    "        self.llm_weight = llm_weight\n",
    "        \n",
    "        # Tracking\n",
    "        self.symbols = []\n",
    "        self.last_analysis = {}\n",
    "        self.daily_cost = 0.0\n",
    "        self.last_cost_reset = datetime.min\n",
    "        \n",
    "        # Technical indicators\n",
    "        self.indicators = {}\n",
    "        \n",
    "        # Initialize OpenAI client\n",
    "        openai.api_key = self.api_key\n",
    "    \n",
    "    def Update(self, algorithm: QCAlgorithm, data: Slice) -> List[Insight]:\n",
    "        insights = []\n",
    "        \n",
    "        # Reset daily cost\n",
    "        if algorithm.Time.date() > self.last_cost_reset.date():\n",
    "            self.daily_cost = 0.0\n",
    "            self.last_cost_reset = algorithm.Time\n",
    "        \n",
    "        # Only run once per day\n",
    "        if algorithm.Time.hour != 10:  # 10 AM\n",
    "            return insights\n",
    "        \n",
    "        for symbol in self.symbols:\n",
    "            if not data.ContainsKey(symbol):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Get news (using TiingoNews or custom data)\n",
    "                news = self._get_news(algorithm, symbol)\n",
    "                \n",
    "                # Get LLM signal (if within budget)\n",
    "                llm_signal, llm_confidence = self._get_llm_signal(\n",
    "                    algorithm, symbol, news\n",
    "                )\n",
    "                \n",
    "                # Get technical signal\n",
    "                tech_signal, tech_confidence = self._get_technical_signal(\n",
    "                    algorithm, symbol\n",
    "                )\n",
    "                \n",
    "                # Fuse signals\n",
    "                fused_signal = self._fuse_signals(\n",
    "                    llm_signal, llm_confidence,\n",
    "                    tech_signal, tech_confidence\n",
    "                )\n",
    "                \n",
    "                # Generate insight if signal is strong enough\n",
    "                if abs(fused_signal) > 0.3:\n",
    "                    direction = InsightDirection.Up if fused_signal > 0 else InsightDirection.Down\n",
    "                    confidence = min(abs(fused_signal), 1.0)\n",
    "                    \n",
    "                    insight = Insight.Price(\n",
    "                        symbol,\n",
    "                        timedelta(days=5),\n",
    "                        direction,\n",
    "                        magnitude=abs(fused_signal) * 0.02,\n",
    "                        confidence=confidence,\n",
    "                        sourceModel=\"LLM-Hybrid\"\n",
    "                    )\n",
    "                    insights.append(insight)\n",
    "                    \n",
    "                    algorithm.Debug(\n",
    "                        f\"LLM Insight: {symbol} {direction.name} \"\n",
    "                        f\"(signal: {fused_signal:.2f}, conf: {confidence:.2f})\"\n",
    "                    )\n",
    "                    \n",
    "            except Exception as e:\n",
    "                algorithm.Debug(f\"Error analyzing {symbol}: {e}\")\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def _get_news(self, algorithm: QCAlgorithm, symbol: Symbol) -> str:\n",
    "        \"\"\"\n",
    "        Recupere les news recentes pour un symbole.\n",
    "        \"\"\"\n",
    "        # Option 1: TiingoNews (premium)\n",
    "        # news_data = algorithm.AddData(TiingoNews, symbol)\n",
    "        \n",
    "        # Option 2: Custom data source\n",
    "        # Implementer selon votre source de donnees\n",
    "        \n",
    "        # Placeholder pour demonstration\n",
    "        return f\"Recent news about {symbol.Value}...\"\n",
    "    \n",
    "    def _get_llm_signal(self, algorithm: QCAlgorithm, symbol: Symbol, news: str) -> tuple:\n",
    "        \"\"\"\n",
    "        Obtient le signal LLM.\n",
    "        \"\"\"\n",
    "        # Check budget\n",
    "        estimated_cost = 0.001  # ~$0.001 per request for gpt-4o-mini\n",
    "        if self.daily_cost + estimated_cost > self.max_daily_cost:\n",
    "            algorithm.Debug(\"LLM budget exceeded, using cached/default\")\n",
    "            cached = self.last_analysis.get(str(symbol))\n",
    "            if cached:\n",
    "                return cached\n",
    "            return 0.0, 0.5\n",
    "        \n",
    "        try:\n",
    "            prompt = self.SENTIMENT_PROMPT.format(\n",
    "                symbol=symbol.Value,\n",
    "                news=news[:2000]\n",
    "            )\n",
    "            \n",
    "            response = openai.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=200,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            content = response.choices[0].message.content\n",
    "            result = json.loads(content)\n",
    "            \n",
    "            # Update cost tracking\n",
    "            self.daily_cost += estimated_cost\n",
    "            \n",
    "            # Parse result\n",
    "            sentiment = result.get(\"sentiment\", \"NEUTRAL\")\n",
    "            confidence = result.get(\"confidence\", 0.5)\n",
    "            \n",
    "            signal = {\n",
    "                \"BULLISH\": 1.0,\n",
    "                \"BEARISH\": -1.0,\n",
    "                \"NEUTRAL\": 0.0\n",
    "            }.get(sentiment, 0.0)\n",
    "            \n",
    "            # Cache result\n",
    "            self.last_analysis[str(symbol)] = (signal * confidence, confidence)\n",
    "            \n",
    "            return signal * confidence, confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            algorithm.Debug(f\"LLM error: {e}\")\n",
    "            return 0.0, 0.5\n",
    "    \n",
    "    def _get_technical_signal(self, algorithm: QCAlgorithm, symbol: Symbol) -> tuple:\n",
    "        \"\"\"\n",
    "        Calcule le signal technique.\n",
    "        \"\"\"\n",
    "        if symbol not in self.indicators:\n",
    "            return 0.0, 0.5\n",
    "        \n",
    "        ind = self.indicators[symbol]\n",
    "        signals = []\n",
    "        \n",
    "        # SMA trend\n",
    "        if ind['sma_fast'].IsReady and ind['sma_slow'].IsReady:\n",
    "            if ind['sma_fast'].Current.Value > ind['sma_slow'].Current.Value:\n",
    "                signals.append(1.0)\n",
    "            else:\n",
    "                signals.append(-1.0)\n",
    "        \n",
    "        # RSI\n",
    "        if ind['rsi'].IsReady:\n",
    "            rsi = ind['rsi'].Current.Value\n",
    "            if rsi > 70:\n",
    "                signals.append(-0.5)\n",
    "            elif rsi < 30:\n",
    "                signals.append(0.5)\n",
    "        \n",
    "        if not signals:\n",
    "            return 0.0, 0.5\n",
    "        \n",
    "        signal = sum(signals) / len(signals)\n",
    "        confidence = 0.6 + 0.2 * (len([s for s in signals if abs(s) > 0.3]) / len(signals))\n",
    "        \n",
    "        return signal, confidence\n",
    "    \n",
    "    def _fuse_signals(self, llm_signal, llm_conf, tech_signal, tech_conf) -> float:\n",
    "        \"\"\"\n",
    "        Fusionne les signaux.\n",
    "        \"\"\"\n",
    "        fused = (\n",
    "            self.llm_weight * llm_signal * llm_conf +\n",
    "            self.technical_weight * tech_signal * tech_conf\n",
    "        )\n",
    "        \n",
    "        # Bonus for agreement\n",
    "        if llm_signal * tech_signal > 0:\n",
    "            fused *= 1.2\n",
    "        \n",
    "        return max(-1, min(1, fused))\n",
    "    \n",
    "    def OnSecuritiesChanged(self, algorithm: QCAlgorithm, changes: SecurityChanges):\n",
    "        for security in changes.AddedSecurities:\n",
    "            symbol = security.Symbol\n",
    "            if symbol not in self.symbols:\n",
    "                self.symbols.append(symbol)\n",
    "                \n",
    "                # Setup indicators\n",
    "                self.indicators[symbol] = {\n",
    "                    'sma_fast': algorithm.SMA(symbol, 20, Resolution.Daily),\n",
    "                    'sma_slow': algorithm.SMA(symbol, 50, Resolution.Daily),\n",
    "                    'rsi': algorithm.RSI(symbol, 14, Resolution.Daily)\n",
    "                }\n",
    "        \n",
    "        for security in changes.RemovedSecurities:\n",
    "            symbol = security.Symbol\n",
    "            if symbol in self.symbols:\n",
    "                self.symbols.remove(symbol)\n",
    "\n",
    "\n",
    "class LLMTradingAlgorithm(QCAlgorithm):\n",
    "    \"\"\"\n",
    "    Algorithme de trading utilisant les LLMs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def Initialize(self):\n",
    "        self.SetStartDate(2024, 1, 1)\n",
    "        self.SetEndDate(2024, 12, 31)\n",
    "        self.SetCash(100000)\n",
    "        \n",
    "        # API key from secrets\n",
    "        openai_key = self.GetParameter(\"openai_api_key\")\n",
    "        \n",
    "        # Universe\n",
    "        self.AddUniverse(self.CoarseFilter)\n",
    "        \n",
    "        # Models\n",
    "        self.SetAlpha(LLMTradingAlphaModel(\n",
    "            openai_api_key=openai_key,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_daily_cost=1.0\n",
    "        ))\n",
    "        \n",
    "        self.SetPortfolioConstruction(EqualWeightingPortfolioConstructionModel())\n",
    "        self.SetExecution(ImmediateExecutionModel())\n",
    "        self.SetRiskManagement(MaximumDrawdownPercentPerSecurity(0.05))\n",
    "    \n",
    "    def CoarseFilter(self, coarse):\n",
    "        filtered = [x for x in coarse\n",
    "                   if x.HasFundamentalData\n",
    "                   and x.Price > 10\n",
    "                   and x.DollarVolume > 10000000]\n",
    "        return [x.Symbol for x in sorted(filtered, key=lambda x: x.DollarVolume, reverse=True)[:20]]\n",
    "'''\n",
    "\n",
    "print(\"LLMTradingAlgorithm code genere\")\n",
    "print(\"\\nCaracteristiques:\")\n",
    "print(\"  - Analyse quotidienne avec GPT-4o-mini\")\n",
    "print(\"  - Budget API: $1/jour\")\n",
    "print(\"  - Fusion LLM + Technical\")\n",
    "print(\"  - Caching des resultats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume et meilleures pratiques\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RESUME : LLM TRADING SIGNALS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_practices = \"\"\"\n",
    "1. PROMPT ENGINEERING\n",
    "   - Instructions specifiques et structurees\n",
    "   - Format de sortie JSON\n",
    "   - Exemples few-shot si necessaire\n",
    "   - Temperature basse (0.2-0.4) pour coherence\n",
    "\n",
    "2. GESTION DES COUTS\n",
    "   - Budget quotidien strict\n",
    "   - Modeles economiques (gpt-4o-mini, haiku)\n",
    "   - Caching des resultats\n",
    "   - Batching des requetes\n",
    "\n",
    "3. ROBUSTESSE\n",
    "   - Fallback vers signaux techniques\n",
    "   - Validation du JSON\n",
    "   - Retry avec backoff\n",
    "   - Logging complet\n",
    "\n",
    "4. SYSTEME HYBRIDE\n",
    "   - Ne jamais se fier au LLM seul\n",
    "   - Fusion avec indicateurs objectifs\n",
    "   - Bonus pour accord LLM/technique\n",
    "   - Penalite pour desaccord\n",
    "\n",
    "5. PRODUCTION\n",
    "   - API keys en secrets QuantConnect\n",
    "   - Scheduled events quotidiens\n",
    "   - Monitoring des couts en temps reel\n",
    "   - Alertes sur erreurs API\n",
    "\"\"\"\n",
    "\n",
    "print(best_practices)\n",
    "\n",
    "print(\"\\nESTIMATION DES COUTS MENSUELS:\")\n",
    "print(\"  - 20 actifs x 1 analyse/jour x 30 jours = 600 requetes\")\n",
    "print(\"  - GPT-4o-mini: ~$3-5/mois\")\n",
    "print(\"  - GPT-4o: ~$15-25/mois\")\n",
    "print(\"  - Claude 3.5 Sonnet: ~$20-30/mois\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion et Prochaines Etapes\n",
    "\n",
    "### Recapitulatif\n",
    "\n",
    "| Sujet | Points Cles |\n",
    "|-------|-------------|\n",
    "| **LLMs Finance** | Sentiment analysis, news interpretation, reasoning |\n",
    "| **Prompt Engineering** | Structure, JSON output, few-shot, temperature |\n",
    "| **GPT-4** | Excellent JSON, rapide, cout modere |\n",
    "| **Claude** | Meilleur raisonnement, contexte long |\n",
    "| **Systeme Hybride** | LLM + technique, fusion ponderee, robustesse |\n",
    "| **Production** | Budget, caching, secrets, monitoring |\n",
    "\n",
    "### Limitations et Risques\n",
    "\n",
    "| Risque | Mitigation |\n",
    "|--------|------------|\n",
    "| **Hallucinations** | Validation croisee, signaux techniques |\n",
    "| **Latence** | Caching, batch processing |\n",
    "| **Couts** | Budget strict, modeles economiques |\n",
    "| **Rate limits** | Retry, backoff, quotas |\n",
    "\n",
    "### Ressources Complementaires\n",
    "\n",
    "- [OpenAI API Documentation](https://platform.openai.com/docs)\n",
    "- [Anthropic Claude API](https://docs.anthropic.com/)\n",
    "- [Prompt Engineering Guide](https://www.promptingguide.ai/)\n",
    "- [QuantConnect Alternative Data](https://www.quantconnect.com/docs/v2/writing-algorithms/datasets/alternative-data)\n",
    "\n",
    "### Prochain Notebook\n",
    "\n",
    "**QC-Py-27 - Production Deployment** : Paper trading, live trading, monitoring, et deploiement en production.\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook complete. Vous maitrisez maintenant l'integration des LLMs pour le trading.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
