{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Workflow Orchestration - Cha√Ænage Multi-Mod√®les\n",
    "\n",
    "**Module :** 03-Images-Orchestration  \n",
    "**Niveau :** Expert  \n",
    "**Dur√©e estim√©e :** 60 minutes  \n",
    "\n",
    "## Introduction\n",
    "\n",
    "L'orchestration de workflows permet de combiner plusieurs mod√®les et op√©rations pour cr√©er des pipelines de g√©n√©ration d'images sophistiqu√©s. Ce notebook couvre:\n",
    "\n",
    "- **Cha√Ænage s√©quentiel**: Text ‚Üí Image ‚Üí Edit ‚Üí Upscale\n",
    "- **Ex√©cution parall√®le**: G√©n√©ration simultan√©e multi-mod√®les\n",
    "- **Workflows conditionnels**: Branchement selon qualit√©/contenu\n",
    "- **Gestion des erreurs**: Retry, fallback, timeouts\n",
    "\n",
    "### Architecture d'Orchestration\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ               Workflow Orchestrator                      ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                          ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ\n",
    "‚îÇ   ‚îÇ Prompt  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Model A ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Model B ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ Output ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ\n",
    "‚îÇ                        ‚îÇ                                 ‚îÇ\n",
    "‚îÇ                        ‚ñº                                 ‚îÇ\n",
    "‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îÇ\n",
    "‚îÇ                  ‚îÇ Model C ‚îÇ (parallel)                 ‚îÇ\n",
    "‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ\n",
    "‚îÇ                                                          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "## Pr√©requis\n",
    "\n",
    "- Modules 01 et 02 compl√©t√©s\n",
    "- Acc√®s aux services ComfyUI et/ou APIs cloud\n",
    "- Compr√©hension des diff√©rents mod√®les (Qwen, FLUX, SD3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. CONFIGURATION ET IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "import hashlib\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, List, Tuple, Any, Callable, Union\n",
    "from enum import Enum\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# Chargement variables d'environnement\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "load_dotenv(\"../00-GenAI-Environment/.env\")\n",
    "\n",
    "# Configuration\n",
    "COMFYUI_URL = os.getenv(\"COMFYUI_API_URL\", \"http://localhost:8188\")\n",
    "COMFYUI_TOKEN = os.getenv(\"COMFYUI_AUTH_TOKEN\")\n",
    "\n",
    "print(\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\")\n",
    "print(\"‚ïë   Workflow Orchestration - Multi-Model Pipelines  ‚ïë\")\n",
    "print(\"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\")\n",
    "print(f\"\\nüìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. TYPES ET STRUCTURES DE DONN√âES\n",
    "# =============================================================================\n",
    "\n",
    "class TaskStatus(Enum):\n",
    "    PENDING = \"pending\"\n",
    "    RUNNING = \"running\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    SKIPPED = \"skipped\"\n",
    "\n",
    "@dataclass\n",
    "class TaskResult:\n",
    "    \"\"\"R√©sultat d'une t√¢che d'orchestration.\"\"\"\n",
    "    task_id: str\n",
    "    status: TaskStatus\n",
    "    output: Any = None\n",
    "    error: str = None\n",
    "    duration: float = 0.0\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class WorkflowStep:\n",
    "    \"\"\"√âtape d'un workflow.\"\"\"\n",
    "    name: str\n",
    "    func: Callable\n",
    "    inputs: Dict = field(default_factory=dict)\n",
    "    depends_on: List[str] = field(default_factory=list)\n",
    "    retry_count: int = 3\n",
    "    timeout: float = 120.0\n",
    "    condition: Callable = None  # Ex√©cuter si condition() retourne True\n",
    "\n",
    "print(\"‚úÖ Types et structures d√©finis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. ORCHESTRATEUR DE WORKFLOWS\n",
    "# =============================================================================\n",
    "\n",
    "class WorkflowOrchestrator:\n",
    "    \"\"\"\n",
    "    Orchestrateur pour pipelines de g√©n√©ration d'images.\n",
    "    \n",
    "    Fonctionnalit√©s:\n",
    "    - Ex√©cution s√©quentielle et parall√®le\n",
    "    - Gestion des d√©pendances entre √©tapes\n",
    "    - Retry automatique avec backoff\n",
    "    - Timeouts configurables\n",
    "    - Caching des r√©sultats interm√©diaires\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = 4):\n",
    "        self.max_workers = max_workers\n",
    "        self.results: Dict[str, TaskResult] = {}\n",
    "        self.cache: Dict[str, Any] = {}\n",
    "        self.execution_log: List[Dict] = []\n",
    "    \n",
    "    def _generate_cache_key(self, step_name: str, inputs: Dict) -> str:\n",
    "        \"\"\"G√©n√®re une cl√© de cache unique.\"\"\"\n",
    "        content = f\"{step_name}:{json.dumps(inputs, sort_keys=True)}\"\n",
    "        return hashlib.md5(content.encode()).hexdigest()\n",
    "    \n",
    "    def _execute_with_retry(self, step: WorkflowStep, inputs: Dict) -> TaskResult:\n",
    "        \"\"\"Ex√©cute une √©tape avec retry et timeout.\"\"\"\n",
    "        task_id = f\"{step.name}_{int(time.time()*1000)}\"\n",
    "        \n",
    "        # V√©rifier le cache\n",
    "        cache_key = self._generate_cache_key(step.name, inputs)\n",
    "        if cache_key in self.cache:\n",
    "            print(f\"   üì¶ Cache hit pour {step.name}\")\n",
    "            return TaskResult(\n",
    "                task_id=task_id,\n",
    "                status=TaskStatus.COMPLETED,\n",
    "                output=self.cache[cache_key],\n",
    "                metadata={\"cached\": True}\n",
    "            )\n",
    "        \n",
    "        # V√©rifier la condition\n",
    "        if step.condition and not step.condition(inputs):\n",
    "            print(f\"   ‚è≠Ô∏è Skipping {step.name} (condition non remplie)\")\n",
    "            return TaskResult(task_id=task_id, status=TaskStatus.SKIPPED)\n",
    "        \n",
    "        # Ex√©cution avec retry\n",
    "        last_error = None\n",
    "        for attempt in range(step.retry_count):\n",
    "            try:\n",
    "                start = time.time()\n",
    "                print(f\"   üîÑ {step.name} (attempt {attempt + 1}/{step.retry_count})\")\n",
    "                \n",
    "                output = step.func(**inputs)\n",
    "                duration = time.time() - start\n",
    "                \n",
    "                # Mise en cache\n",
    "                self.cache[cache_key] = output\n",
    "                \n",
    "                return TaskResult(\n",
    "                    task_id=task_id,\n",
    "                    status=TaskStatus.COMPLETED,\n",
    "                    output=output,\n",
    "                    duration=duration\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                last_error = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è Erreur: {last_error}\")\n",
    "                if attempt < step.retry_count - 1:\n",
    "                    wait_time = 2 ** attempt  # Exponential backoff\n",
    "                    print(f\"   ‚è≥ Retry dans {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "        \n",
    "        return TaskResult(\n",
    "            task_id=task_id,\n",
    "            status=TaskStatus.FAILED,\n",
    "            error=last_error\n",
    "        )\n",
    "    \n",
    "    def run_sequential(self, steps: List[WorkflowStep], initial_input: Dict = None) -> Dict[str, TaskResult]:\n",
    "        \"\"\"\n",
    "        Ex√©cute les √©tapes s√©quentiellement.\n",
    "        Le r√©sultat de chaque √©tape est pass√© √† la suivante.\n",
    "        \"\"\"\n",
    "        print(\"\\nüîó Ex√©cution S√©quentielle\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        self.results = {}\n",
    "        current_input = initial_input or {}\n",
    "        \n",
    "        for i, step in enumerate(steps):\n",
    "            print(f\"\\n[{i+1}/{len(steps)}] {step.name}\")\n",
    "            \n",
    "            # Merge inputs\n",
    "            merged_inputs = {**current_input, **step.inputs}\n",
    "            \n",
    "            result = self._execute_with_retry(step, merged_inputs)\n",
    "            self.results[step.name] = result\n",
    "            \n",
    "            if result.status == TaskStatus.FAILED:\n",
    "                print(f\"   ‚ùå Pipeline arr√™t√© sur {step.name}\")\n",
    "                break\n",
    "            elif result.status == TaskStatus.COMPLETED:\n",
    "                print(f\"   ‚úÖ Compl√©t√© en {result.duration:.2f}s\")\n",
    "                # Passer le r√©sultat √† l'√©tape suivante\n",
    "                if result.output is not None:\n",
    "                    if isinstance(result.output, dict):\n",
    "                        current_input.update(result.output)\n",
    "                    else:\n",
    "                        current_input[\"previous_output\"] = result.output\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def run_parallel(self, steps: List[WorkflowStep], shared_input: Dict = None) -> Dict[str, TaskResult]:\n",
    "        \"\"\"\n",
    "        Ex√©cute les √©tapes en parall√®le.\n",
    "        Toutes les √©tapes re√ßoivent le m√™me input.\n",
    "        \"\"\"\n",
    "        print(\"\\n‚ö° Ex√©cution Parall√®le\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        self.results = {}\n",
    "        shared_input = shared_input or {}\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            futures = {}\n",
    "            \n",
    "            for step in steps:\n",
    "                merged_inputs = {**shared_input, **step.inputs}\n",
    "                future = executor.submit(self._execute_with_retry, step, merged_inputs)\n",
    "                futures[future] = step.name\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                step_name = futures[future]\n",
    "                result = future.result()\n",
    "                self.results[step_name] = result\n",
    "                \n",
    "                status_icon = \"‚úÖ\" if result.status == TaskStatus.COMPLETED else \"‚ùå\"\n",
    "                print(f\"   {status_icon} {step_name}: {result.status.value}\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def get_summary(self) -> Dict:\n",
    "        \"\"\"Retourne un r√©sum√© de l'ex√©cution.\"\"\"\n",
    "        completed = sum(1 for r in self.results.values() if r.status == TaskStatus.COMPLETED)\n",
    "        failed = sum(1 for r in self.results.values() if r.status == TaskStatus.FAILED)\n",
    "        total_time = sum(r.duration for r in self.results.values())\n",
    "        \n",
    "        return {\n",
    "            \"total_steps\": len(self.results),\n",
    "            \"completed\": completed,\n",
    "            \"failed\": failed,\n",
    "            \"total_time\": total_time,\n",
    "            \"cache_hits\": sum(1 for r in self.results.values() if r.metadata.get(\"cached\"))\n",
    "        }\n",
    "\n",
    "# Instanciation\n",
    "orchestrator = WorkflowOrchestrator(max_workers=4)\n",
    "print(\"\\n‚úÖ WorkflowOrchestrator initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 4. Fonctions de G√©n√©ration (Simul√©es)\n",
    "\n",
    "Pour la d√©monstration, nous utilisons des fonctions simul√©es. En production, remplacez par les vrais appels aux mod√®les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. FONCTIONS DE G√âN√âRATION (SIMUL√âES)\n",
    "# =============================================================================\n",
    "\n",
    "def generate_prompt_variations(base_prompt: str, count: int = 3) -> Dict:\n",
    "    \"\"\"G√©n√®re des variations d'un prompt (simul√©).\"\"\"\n",
    "    time.sleep(0.5)  # Simule un appel API\n",
    "    \n",
    "    variations = [\n",
    "        f\"{base_prompt}, photorealistic, 8k\",\n",
    "        f\"{base_prompt}, digital art, vibrant colors\",\n",
    "        f\"{base_prompt}, oil painting, classic style\"\n",
    "    ][:count]\n",
    "    \n",
    "    return {\"prompts\": variations}\n",
    "\n",
    "def generate_image_placeholder(prompt: str, model: str = \"default\", **kwargs) -> Dict:\n",
    "    \"\"\"Simule une g√©n√©ration d'image.\"\"\"\n",
    "    time.sleep(1 + np.random.random())  # Simule la g√©n√©ration\n",
    "    \n",
    "    # Cr√©er une image placeholder color√©e\n",
    "    color = np.random.randint(50, 200, 3)\n",
    "    img = Image.new('RGB', (512, 512), tuple(color))\n",
    "    \n",
    "    return {\n",
    "        \"image\": img,\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"seed\": kwargs.get(\"seed\", np.random.randint(0, 1000000))\n",
    "    }\n",
    "\n",
    "def upscale_image(image: Image.Image, scale: int = 2) -> Dict:\n",
    "    \"\"\"Simule un upscaling.\"\"\"\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    new_size = (image.width * scale, image.height * scale)\n",
    "    upscaled = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    return {\"image\": upscaled, \"scale\": scale}\n",
    "\n",
    "def apply_style_transfer(image: Image.Image, style: str) -> Dict:\n",
    "    \"\"\"Simule un transfert de style.\"\"\"\n",
    "    time.sleep(0.8)\n",
    "    \n",
    "    # Simuler un effet de style (juste modifier les couleurs)\n",
    "    arr = np.array(image).astype(float)\n",
    "    \n",
    "    if style == \"warm\":\n",
    "        arr[:,:,0] = np.clip(arr[:,:,0] * 1.2, 0, 255)  # Plus de rouge\n",
    "    elif style == \"cool\":\n",
    "        arr[:,:,2] = np.clip(arr[:,:,2] * 1.2, 0, 255)  # Plus de bleu\n",
    "    elif style == \"vintage\":\n",
    "        arr = np.clip(arr * 0.9 + 20, 0, 255)  # D√©lav√©\n",
    "    \n",
    "    styled = Image.fromarray(arr.astype(np.uint8))\n",
    "    return {\"image\": styled, \"style\": style}\n",
    "\n",
    "def evaluate_quality(image: Image.Image) -> Dict:\n",
    "    \"\"\"Simule une √©valuation de qualit√©.\"\"\"\n",
    "    time.sleep(0.3)\n",
    "    \n",
    "    # Score al√©atoire entre 0.5 et 1.0\n",
    "    score = 0.5 + np.random.random() * 0.5\n",
    "    \n",
    "    return {\n",
    "        \"quality_score\": score,\n",
    "        \"passed\": score > 0.7,\n",
    "        \"feedback\": \"Good quality\" if score > 0.7 else \"Needs improvement\"\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Fonctions de g√©n√©ration d√©finies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 5. Pipeline S√©quentiel: Text ‚Üí Image ‚Üí Style ‚Üí Upscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. PIPELINE S√âQUENTIEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã Pipeline S√©quentiel: Text ‚Üí Image ‚Üí Style ‚Üí Upscale\")\n",
    "\n",
    "# D√©finir les √©tapes\n",
    "sequential_steps = [\n",
    "    WorkflowStep(\n",
    "        name=\"generate_image\",\n",
    "        func=generate_image_placeholder,\n",
    "        inputs={\"prompt\": \"A serene mountain landscape at sunset\", \"model\": \"sd35\"}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        name=\"apply_style\",\n",
    "        func=lambda previous_output, **kw: apply_style_transfer(\n",
    "            previous_output[\"image\"], style=\"warm\"\n",
    "        ),\n",
    "        inputs={}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        name=\"upscale\",\n",
    "        func=lambda previous_output, **kw: upscale_image(\n",
    "            previous_output[\"image\"], scale=2\n",
    "        ),\n",
    "        inputs={}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        name=\"evaluate\",\n",
    "        func=lambda previous_output, **kw: evaluate_quality(previous_output[\"image\"]),\n",
    "        inputs={}\n",
    "    )\n",
    "]\n",
    "\n",
    "# Ex√©cuter\n",
    "results = orchestrator.run_sequential(sequential_steps)\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "print(\"\\nüìä R√©sum√©:\")\n",
    "summary = orchestrator.get_summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Visualiser si succ√®s\n",
    "if \"upscale\" in results and results[\"upscale\"].status == TaskStatus.COMPLETED:\n",
    "    final_image = results[\"upscale\"].output[\"image\"]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    if \"generate_image\" in results:\n",
    "        axes[0].imshow(results[\"generate_image\"].output[\"image\"])\n",
    "        axes[0].set_title(\"1. Generated\")\n",
    "        axes[0].axis('off')\n",
    "    \n",
    "    if \"apply_style\" in results:\n",
    "        axes[1].imshow(results[\"apply_style\"].output[\"image\"])\n",
    "        axes[1].set_title(\"2. Styled\")\n",
    "        axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(final_image)\n",
    "    axes[2].set_title(f\"3. Upscaled ({final_image.size})\")\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Pipeline S√©quentiel\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 6. Pipeline Parall√®le: G√©n√©ration Multi-Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. PIPELINE PARALL√àLE - MULTI-MOD√àLES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n‚ö° Pipeline Parall√®le: Comparaison Multi-Mod√®les\")\n",
    "\n",
    "shared_prompt = \"A futuristic city with flying cars and neon lights\"\n",
    "\n",
    "parallel_steps = [\n",
    "    WorkflowStep(\n",
    "        name=\"qwen_generation\",\n",
    "        func=generate_image_placeholder,\n",
    "        inputs={\"prompt\": shared_prompt, \"model\": \"qwen\", \"seed\": 42}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        name=\"flux_generation\",\n",
    "        func=generate_image_placeholder,\n",
    "        inputs={\"prompt\": shared_prompt, \"model\": \"flux\", \"seed\": 42}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        name=\"sd35_generation\",\n",
    "        func=generate_image_placeholder,\n",
    "        inputs={\"prompt\": shared_prompt, \"model\": \"sd35\", \"seed\": 42}\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Ex√©cuter en parall√®le\n",
    "parallel_results = orchestrator.run_parallel(parallel_steps)\n",
    "\n",
    "# Affichage\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, (name, result) in enumerate(parallel_results.items()):\n",
    "    if result.status == TaskStatus.COMPLETED:\n",
    "        axes[i].imshow(result.output[\"image\"])\n",
    "        model = result.output[\"model\"]\n",
    "        axes[i].set_title(f\"{model.upper()}\\n({result.duration:.2f}s)\")\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, \"Failed\", ha='center', va='center')\n",
    "        axes[i].set_title(name)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Comparaison Multi-Mod√®les\\n'{shared_prompt[:50]}...'\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Temps total: {orchestrator.get_summary()['total_time']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 7. Pipeline Conditionnel: Qualit√©-Based Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. PIPELINE CONDITIONNEL\n",
    "# =============================================================================\n",
    "\n",
    "class ConditionalPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline avec branchement conditionnel bas√© sur la qualit√©.\n",
    "    Si qualit√© < seuil: r√©g√©n√®re avec param√®tres am√©lior√©s.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, quality_threshold: float = 0.7):\n",
    "        self.quality_threshold = quality_threshold\n",
    "        self.history = []\n",
    "    \n",
    "    def run(self, prompt: str, max_attempts: int = 3) -> Dict:\n",
    "        \"\"\"Ex√©cute avec am√©lioration it√©rative.\"\"\"\n",
    "        print(f\"\\nüîÑ Pipeline Conditionnel (seuil: {self.quality_threshold})\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        best_result = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for attempt in range(max_attempts):\n",
    "            print(f\"\\n[Attempt {attempt + 1}/{max_attempts}]\")\n",
    "            \n",
    "            # G√©n√©rer\n",
    "            gen_result = generate_image_placeholder(\n",
    "                prompt=prompt,\n",
    "                model=\"sd35\",\n",
    "                steps=20 + attempt * 10  # Plus de steps √† chaque tentative\n",
    "            )\n",
    "            print(f\"   üñºÔ∏è Image g√©n√©r√©e\")\n",
    "            \n",
    "            # √âvaluer\n",
    "            eval_result = evaluate_quality(gen_result[\"image\"])\n",
    "            score = eval_result[\"quality_score\"]\n",
    "            print(f\"   üìä Score: {score:.2f}\")\n",
    "            \n",
    "            self.history.append({\n",
    "                \"attempt\": attempt + 1,\n",
    "                \"score\": score,\n",
    "                \"passed\": eval_result[\"passed\"]\n",
    "            })\n",
    "            \n",
    "            # Garder le meilleur\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_result = gen_result\n",
    "            \n",
    "            # Condition d'arr√™t\n",
    "            if score >= self.quality_threshold:\n",
    "                print(f\"   ‚úÖ Qualit√© suffisante atteinte!\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Qualit√© insuffisante, retry...\")\n",
    "        \n",
    "        return {\n",
    "            \"result\": best_result,\n",
    "            \"final_score\": best_score,\n",
    "            \"attempts\": len(self.history),\n",
    "            \"history\": self.history\n",
    "        }\n",
    "\n",
    "# Test\n",
    "conditional = ConditionalPipeline(quality_threshold=0.75)\n",
    "cond_result = conditional.run(\"A magical forest with glowing mushrooms\")\n",
    "\n",
    "print(f\"\\nüìã R√©sultat Final:\")\n",
    "print(f\"   Tentatives: {cond_result['attempts']}\")\n",
    "print(f\"   Score final: {cond_result['final_score']:.2f}\")\n",
    "\n",
    "# Visualiser l'historique\n",
    "if cond_result[\"history\"]:\n",
    "    attempts = [h[\"attempt\"] for h in cond_result[\"history\"]]\n",
    "    scores = [h[\"score\"] for h in cond_result[\"history\"]]\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(attempts, scores, color=['green' if s >= 0.75 else 'orange' for s in scores])\n",
    "    plt.axhline(y=0.75, color='red', linestyle='--', label='Seuil')\n",
    "    plt.xlabel('Tentative')\n",
    "    plt.ylabel('Score Qualit√©')\n",
    "    plt.title('Pipeline Conditionnel - √âvolution de la Qualit√©')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 8. Pipeline Avanc√©: G√©n√©ration Multi-Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. PIPELINE MULTI-VARIATIONS\n",
    "# =============================================================================\n",
    "\n",
    "class MultiVariationPipeline:\n",
    "    \"\"\"Pipeline pour g√©n√©rer et comparer plusieurs variations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.orchestrator = WorkflowOrchestrator(max_workers=4)\n",
    "    \n",
    "    def generate_variations(self, base_prompt: str, \n",
    "                           styles: List[str] = None,\n",
    "                           models: List[str] = None) -> Dict:\n",
    "        \"\"\"G√©n√®re des variations par style et/ou mod√®le.\"\"\"\n",
    "        \n",
    "        styles = styles or [\"photorealistic\", \"digital art\", \"oil painting\"]\n",
    "        models = models or [\"sd35\"]\n",
    "        \n",
    "        print(f\"\\nüé® G√©n√©ration Multi-Variations\")\n",
    "        print(f\"   Base: '{base_prompt[:40]}...'\")\n",
    "        print(f\"   Styles: {styles}\")\n",
    "        print(f\"   Models: {models}\")\n",
    "        \n",
    "        # Cr√©er les √©tapes\n",
    "        steps = []\n",
    "        for model in models:\n",
    "            for style in styles:\n",
    "                styled_prompt = f\"{base_prompt}, {style}\"\n",
    "                steps.append(WorkflowStep(\n",
    "                    name=f\"{model}_{style.replace(' ', '_')}\",\n",
    "                    func=generate_image_placeholder,\n",
    "                    inputs={\"prompt\": styled_prompt, \"model\": model}\n",
    "                ))\n",
    "        \n",
    "        # Ex√©cuter en parall√®le\n",
    "        results = self.orchestrator.run_parallel(steps)\n",
    "        \n",
    "        return {\n",
    "            \"variations\": results,\n",
    "            \"summary\": self.orchestrator.get_summary()\n",
    "        }\n",
    "    \n",
    "    def select_best(self, results: Dict) -> Tuple[str, Any]:\n",
    "        \"\"\"S√©lectionne la meilleure variation bas√©e sur l'√©valuation.\"\"\"\n",
    "        best_name = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for name, result in results[\"variations\"].items():\n",
    "            if result.status == TaskStatus.COMPLETED:\n",
    "                eval_result = evaluate_quality(result.output[\"image\"])\n",
    "                if eval_result[\"quality_score\"] > best_score:\n",
    "                    best_score = eval_result[\"quality_score\"]\n",
    "                    best_name = name\n",
    "        \n",
    "        return best_name, best_score\n",
    "\n",
    "# Test\n",
    "multi_pipeline = MultiVariationPipeline()\n",
    "variations_result = multi_pipeline.generate_variations(\n",
    "    \"A cozy cabin in the snowy mountains\",\n",
    "    styles=[\"photorealistic\", \"watercolor\", \"anime\"],\n",
    "    models=[\"sd35\"]\n",
    ")\n",
    "\n",
    "# Affichage grille\n",
    "completed = {k: v for k, v in variations_result[\"variations\"].items() \n",
    "             if v.status == TaskStatus.COMPLETED}\n",
    "\n",
    "if completed:\n",
    "    n = len(completed)\n",
    "    cols = min(3, n)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "    axes = np.array(axes).flatten() if n > 1 else [axes]\n",
    "    \n",
    "    for i, (name, result) in enumerate(completed.items()):\n",
    "        axes[i].imshow(result.output[\"image\"])\n",
    "        axes[i].set_title(name.replace('_', ' '), fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    for i in range(len(completed), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Multi-Variations\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# S√©lectionner la meilleure\n",
    "best_name, best_score = multi_pipeline.select_best(variations_result)\n",
    "print(f\"\\nüèÜ Meilleure variation: {best_name} (score: {best_score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 9. Exercices Pratiques\n",
    "\n",
    "### Exercice 1: Pipeline Personnalis√©\n",
    "Cr√©ez un pipeline qui g√©n√®re une image, applique 3 styles diff√©rents, et s√©lectionne le meilleur.\n",
    "\n",
    "### Exercice 2: Retry Intelligent\n",
    "Modifiez `ConditionalPipeline` pour utiliser des param√®tres diff√©rents √† chaque retry.\n",
    "\n",
    "### Exercice 3: M√©triques\n",
    "Ajoutez des m√©triques de performance (temps par mod√®le, taux de succ√®s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 9. ESPACE D'EXERCICES\n",
    "# =============================================================================\n",
    "\n",
    "# Exercice 1: D√©commentez et compl√©tez\n",
    "\n",
    "# custom_steps = [\n",
    "#     WorkflowStep(name=\"generate\", func=generate_image_placeholder, \n",
    "#                  inputs={\"prompt\": \"votre prompt\"}),\n",
    "#     # Ajoutez vos √©tapes...\n",
    "# ]\n",
    "# \n",
    "# custom_orchestrator = WorkflowOrchestrator()\n",
    "# custom_results = custom_orchestrator.run_sequential(custom_steps)\n",
    "\n",
    "print(\"üìù Espace d'exercices - D√©commentez pour commencer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 10. R√©capitulatif\n",
    "\n",
    "### Patterns d'Orchestration\n",
    "\n",
    "| Pattern | Cas d'Usage | Avantages |\n",
    "|---------|-------------|----------|\n",
    "| **S√©quentiel** | Cha√Ænage d√©pendant | Simple, pr√©visible |\n",
    "| **Parall√®le** | Comparaison mod√®les | Rapide, efficace |\n",
    "| **Conditionnel** | Qualit√© garantie | Adaptif, robuste |\n",
    "| **Multi-Variations** | Exploration | Diversit√©, choix |\n",
    "\n",
    "### Bonnes Pratiques\n",
    "\n",
    "1. **Retry avec backoff** pour la r√©silience\n",
    "2. **Caching** pour les r√©sultats interm√©diaires\n",
    "3. **Timeouts** pour √©viter les blocages\n",
    "4. **Logging** pour le debugging\n",
    "5. **√âvaluation automatique** pour la s√©lection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIN DU NOTEBOOK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"   ‚úÖ Notebook Workflow Orchestration Compl√©t√©\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìÖ Termin√©: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nüìö Concepts couverts:\")\n",
    "print(\"   ‚Ä¢ WorkflowOrchestrator pour pipelines\")\n",
    "print(\"   ‚Ä¢ Ex√©cution s√©quentielle et parall√®le\")\n",
    "print(\"   ‚Ä¢ Pipelines conditionnels\")\n",
    "print(\"   ‚Ä¢ Multi-variations et s√©lection\")\n",
    "print(\"   ‚Ä¢ Retry et gestion d'erreurs\")\n",
    "print(\"\\n‚û°Ô∏è  Prochain notebook: 03-3-Performance-Optimization.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
