{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Workflow Orchestration - Cha\u00eenage Multi-Mod\u00e8les\n",
        "\n",
        "**Module :** 03-Images-Orchestration  \n",
        "**Niveau :** Expert  \n",
        "**Dur\u00e9e estim\u00e9e :** 60 minutes  \n",
        "\n",
        "## Introduction\n",
        "\n",
        "L'orchestration de workflows permet de combiner plusieurs mod\u00e8les et op\u00e9rations pour cr\u00e9er des pipelines de g\u00e9n\u00e9ration d'images sophistiqu\u00e9s. Ce notebook couvre:\n",
        "\n",
        "- **Cha\u00eenage s\u00e9quentiel**: Text \u2192 Image \u2192 Edit \u2192 Upscale\n",
        "- **Ex\u00e9cution parall\u00e8le**: G\u00e9n\u00e9ration simultan\u00e9e multi-mod\u00e8les\n",
        "- **Workflows conditionnels**: Branchement selon qualit\u00e9/contenu\n",
        "- **Gestion des erreurs**: Retry, fallback, timeouts\n",
        "\n",
        "### Architecture d'Orchestration\n",
        "\n",
        "```\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502               Workflow Orchestrator                      \u2502\n",
        "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
        "\u2502                                                          \u2502\n",
        "\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n",
        "\u2502   \u2502 Prompt  \u2502\u2500\u2500\u2500\u25b6\u2502 Model A \u2502\u2500\u2500\u2500\u25b6\u2502 Model B \u2502\u2500\u2500\u2500\u25b6 Output \u2502\n",
        "\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n",
        "\u2502                        \u2502                                 \u2502\n",
        "\u2502                        \u25bc                                 \u2502\n",
        "\u2502                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                            \u2502\n",
        "\u2502                  \u2502 Model C \u2502 (parallel)                 \u2502\n",
        "\u2502                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                            \u2502\n",
        "\u2502                                                          \u2502\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "```\n",
        "\n",
        "## Pr\u00e9requis\n",
        "\n",
        "- Modules 01 et 02 compl\u00e9t\u00e9s\n",
        "- Acc\u00e8s aux services ComfyUI et/ou APIs cloud\n",
        "- Compr\u00e9hension des diff\u00e9rents mod\u00e8les (Qwen, FLUX, SD3.5)"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 1. CONFIGURATION ET IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import asyncio\n",
        "import hashlib\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional, Dict, List, Tuple, Any, Callable, Union\n",
        "from enum import Enum\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "# Chargement variables d'environnement\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"../.env\")\n",
        "load_dotenv(\"../00-GenAI-Environment/.env\")\n",
        "\n",
        "# Configuration\n",
        "COMFYUI_URL = os.getenv(\"COMFYUI_API_URL\", \"http://localhost:8188\")\n",
        "COMFYUI_TOKEN = os.getenv(\"COMFYUI_AUTH_TOKEN\")\n",
        "\n",
        "print(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\")\n",
        "print(\"\u2551   Workflow Orchestration - Multi-Model Pipelines  \u2551\")\n",
        "print(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\")\n",
        "print(f\"\\n\ud83d\udcc5 Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 2. TYPES ET STRUCTURES DE DONN\u00c9ES\n",
        "# =============================================================================\n",
        "\n",
        "class TaskStatus(Enum):\n",
        "    PENDING = \"pending\"\n",
        "    RUNNING = \"running\"\n",
        "    COMPLETED = \"completed\"\n",
        "    FAILED = \"failed\"\n",
        "    SKIPPED = \"skipped\"\n",
        "\n",
        "@dataclass\n",
        "class TaskResult:\n",
        "    \"\"\"R\u00e9sultat d'une t\u00e2che d'orchestration.\"\"\"\n",
        "    task_id: str\n",
        "    status: TaskStatus\n",
        "    output: Any = None\n",
        "    error: str = None\n",
        "    duration: float = 0.0\n",
        "    metadata: Dict = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class WorkflowStep:\n",
        "    \"\"\"\u00c9tape d'un workflow.\"\"\"\n",
        "    name: str\n",
        "    func: Callable\n",
        "    inputs: Dict = field(default_factory=dict)\n",
        "    depends_on: List[str] = field(default_factory=list)\n",
        "    retry_count: int = 3\n",
        "    timeout: float = 120.0\n",
        "    condition: Callable = None  # Ex\u00e9cuter si condition() retourne True\n",
        "\n",
        "print(\"\u2705 Types et structures d\u00e9finis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
            "\u2551   Workflow Orchestration - Multi-Model Pipelines  \u2551\n",
            "\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
            "\n",
            "\ud83d\udcc5 Date: 2026-02-18 10:05:01\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 3. ORCHESTRATEUR DE WORKFLOWS\n",
        "# =============================================================================\n",
        "\n",
        "class WorkflowOrchestrator:\n",
        "    \"\"\"\n",
        "    Orchestrateur pour pipelines de g\u00e9n\u00e9ration d'images.\n",
        "    \n",
        "    Fonctionnalit\u00e9s:\n",
        "    - Ex\u00e9cution s\u00e9quentielle et parall\u00e8le\n",
        "    - Gestion des d\u00e9pendances entre \u00e9tapes\n",
        "    - Retry automatique avec backoff\n",
        "    - Timeouts configurables\n",
        "    - Caching des r\u00e9sultats interm\u00e9diaires\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, max_workers: int = 4):\n",
        "        self.max_workers = max_workers\n",
        "        self.results: Dict[str, TaskResult] = {}\n",
        "        self.cache: Dict[str, Any] = {}\n",
        "        self.execution_log: List[Dict] = []\n",
        "    \n",
        "    def _generate_cache_key(self, step_name: str, inputs: Dict) -> str:\n",
        "        \"\"\"G\u00e9n\u00e8re une cl\u00e9 de cache unique.\"\"\"\n",
        "        content = f\"{step_name}:{json.dumps(inputs, sort_keys=True)}\"\n",
        "        return hashlib.md5(content.encode()).hexdigest()\n",
        "    \n",
        "    def _execute_with_retry(self, step: WorkflowStep, inputs: Dict) -> TaskResult:\n",
        "        \"\"\"Ex\u00e9cute une \u00e9tape avec retry et timeout.\"\"\"\n",
        "        task_id = f\"{step.name}_{int(time.time()*1000)}\"\n",
        "        \n",
        "        # V\u00e9rifier le cache\n",
        "        cache_key = self._generate_cache_key(step.name, inputs)\n",
        "        if cache_key in self.cache:\n",
        "            print(f\"   \ud83d\udce6 Cache hit pour {step.name}\")\n",
        "            return TaskResult(\n",
        "                task_id=task_id,\n",
        "                status=TaskStatus.COMPLETED,\n",
        "                output=self.cache[cache_key],\n",
        "                metadata={\"cached\": True}\n",
        "            )\n",
        "        \n",
        "        # V\u00e9rifier la condition\n",
        "        if step.condition and not step.condition(inputs):\n",
        "            print(f\"   \u23ed\ufe0f Skipping {step.name} (condition non remplie)\")\n",
        "            return TaskResult(task_id=task_id, status=TaskStatus.SKIPPED)\n",
        "        \n",
        "        # Ex\u00e9cution avec retry\n",
        "        last_error = None\n",
        "        for attempt in range(step.retry_count):\n",
        "            try:\n",
        "                start = time.time()\n",
        "                print(f\"   \ud83d\udd04 {step.name} (attempt {attempt + 1}/{step.retry_count})\")\n",
        "                \n",
        "                output = step.func(**inputs)\n",
        "                duration = time.time() - start\n",
        "                \n",
        "                # Mise en cache\n",
        "                self.cache[cache_key] = output\n",
        "                \n",
        "                return TaskResult(\n",
        "                    task_id=task_id,\n",
        "                    status=TaskStatus.COMPLETED,\n",
        "                    output=output,\n",
        "                    duration=duration\n",
        "                )\n",
        "                \n",
        "            except Exception as e:\n",
        "                last_error = str(e)\n",
        "                print(f\"   \u26a0\ufe0f Erreur: {last_error}\")\n",
        "                if attempt < step.retry_count - 1:\n",
        "                    wait_time = 2 ** attempt  # Exponential backoff\n",
        "                    print(f\"   \u23f3 Retry dans {wait_time}s...\")\n",
        "                    time.sleep(wait_time)\n",
        "        \n",
        "        return TaskResult(\n",
        "            task_id=task_id,\n",
        "            status=TaskStatus.FAILED,\n",
        "            error=last_error\n",
        "        )\n",
        "    \n",
        "    def run_sequential(self, steps: List[WorkflowStep], initial_input: Dict = None) -> Dict[str, TaskResult]:\n",
        "        \"\"\"\n",
        "        Ex\u00e9cute les \u00e9tapes s\u00e9quentiellement.\n",
        "        Le r\u00e9sultat de chaque \u00e9tape est pass\u00e9 \u00e0 la suivante.\n",
        "        \"\"\"\n",
        "        print(\"\\n\ud83d\udd17 Ex\u00e9cution S\u00e9quentielle\")\n",
        "        print(\"=\" * 40)\n",
        "        \n",
        "        self.results = {}\n",
        "        current_input = initial_input or {}\n",
        "        \n",
        "        for i, step in enumerate(steps):\n",
        "            print(f\"\\n[{i+1}/{len(steps)}] {step.name}\")\n",
        "            \n",
        "            # Merge inputs\n",
        "            merged_inputs = {**current_input, **step.inputs}\n",
        "            \n",
        "            result = self._execute_with_retry(step, merged_inputs)\n",
        "            self.results[step.name] = result\n",
        "            \n",
        "            if result.status == TaskStatus.FAILED:\n",
        "                print(f\"   \u274c Pipeline arr\u00eat\u00e9 sur {step.name}\")\n",
        "                break\n",
        "            elif result.status == TaskStatus.COMPLETED:\n",
        "                print(f\"   \u2705 Compl\u00e9t\u00e9 en {result.duration:.2f}s\")\n",
        "                # Passer le r\u00e9sultat \u00e0 l'\u00e9tape suivante\n",
        "                if result.output is not None:\n",
        "                    if isinstance(result.output, dict):\n",
        "                        current_input.update(result.output)\n",
        "                    else:\n",
        "                        current_input[\"previous_output\"] = result.output\n",
        "        \n",
        "        return self.results\n",
        "    \n",
        "    def run_parallel(self, steps: List[WorkflowStep], shared_input: Dict = None) -> Dict[str, TaskResult]:\n",
        "        \"\"\"\n",
        "        Ex\u00e9cute les \u00e9tapes en parall\u00e8le.\n",
        "        Toutes les \u00e9tapes re\u00e7oivent le m\u00eame input.\n",
        "        \"\"\"\n",
        "        print(\"\\n\u26a1 Ex\u00e9cution Parall\u00e8le\")\n",
        "        print(\"=\" * 40)\n",
        "        \n",
        "        self.results = {}\n",
        "        shared_input = shared_input or {}\n",
        "        \n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            futures = {}\n",
        "            \n",
        "            for step in steps:\n",
        "                merged_inputs = {**shared_input, **step.inputs}\n",
        "                future = executor.submit(self._execute_with_retry, step, merged_inputs)\n",
        "                futures[future] = step.name\n",
        "            \n",
        "            for future in as_completed(futures):\n",
        "                step_name = futures[future]\n",
        "                result = future.result()\n",
        "                self.results[step_name] = result\n",
        "                \n",
        "                status_icon = \"\u2705\" if result.status == TaskStatus.COMPLETED else \"\u274c\"\n",
        "                print(f\"   {status_icon} {step_name}: {result.status.value}\")\n",
        "        \n",
        "        return self.results\n",
        "    \n",
        "    def get_summary(self) -> Dict:\n",
        "        \"\"\"Retourne un r\u00e9sum\u00e9 de l'ex\u00e9cution.\"\"\"\n",
        "        completed = sum(1 for r in self.results.values() if r.status == TaskStatus.COMPLETED)\n",
        "        failed = sum(1 for r in self.results.values() if r.status == TaskStatus.FAILED)\n",
        "        total_time = sum(r.duration for r in self.results.values())\n",
        "        \n",
        "        return {\n",
        "            \"total_steps\": len(self.results),\n",
        "            \"completed\": completed,\n",
        "            \"failed\": failed,\n",
        "            \"total_time\": total_time,\n",
        "            \"cache_hits\": sum(1 for r in self.results.values() if r.metadata.get(\"cached\"))\n",
        "        }\n",
        "\n",
        "# Instanciation\n",
        "orchestrator = WorkflowOrchestrator(max_workers=4)\n",
        "print(\"\\n\u2705 WorkflowOrchestrator initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-4",
      "metadata": {},
      "source": [
        "## 4. Fonctions de G\u00e9n\u00e9ration (Simul\u00e9es)\n",
        "\n",
        "Pour la d\u00e9monstration, nous utilisons des fonctions simul\u00e9es. En production, remplacez par les vrais appels aux mod\u00e8les."
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Types et structures d\u00e9finis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u2705 WorkflowOrchestrator initialis\u00e9\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 4. FONCTIONS DE G\u00c9N\u00c9RATION (SIMUL\u00c9ES)\n",
        "# =============================================================================\n",
        "\n",
        "def generate_prompt_variations(base_prompt: str, count: int = 3) -> Dict:\n",
        "    \"\"\"G\u00e9n\u00e8re des variations d'un prompt (simul\u00e9).\"\"\"\n",
        "    time.sleep(0.5)  # Simule un appel API\n",
        "    \n",
        "    variations = [\n",
        "        f\"{base_prompt}, photorealistic, 8k\",\n",
        "        f\"{base_prompt}, digital art, vibrant colors\",\n",
        "        f\"{base_prompt}, oil painting, classic style\"\n",
        "    ][:count]\n",
        "    \n",
        "    return {\"prompts\": variations}\n",
        "\n",
        "def generate_image_placeholder(prompt: str, model: str = \"default\", **kwargs) -> Dict:\n",
        "    \"\"\"Simule une g\u00e9n\u00e9ration d'image.\"\"\"\n",
        "    time.sleep(1 + np.random.random())  # Simule la g\u00e9n\u00e9ration\n",
        "    \n",
        "    # Cr\u00e9er une image placeholder color\u00e9e\n",
        "    color = np.random.randint(50, 200, 3)\n",
        "    img = Image.new('RGB', (512, 512), tuple(color))\n",
        "    \n",
        "    return {\n",
        "        \"image\": img,\n",
        "        \"model\": model,\n",
        "        \"prompt\": prompt,\n",
        "        \"seed\": kwargs.get(\"seed\", np.random.randint(0, 1000000))\n",
        "    }\n",
        "\n",
        "def upscale_image(image: Image.Image, scale: int = 2) -> Dict:\n",
        "    \"\"\"Simule un upscaling.\"\"\"\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    new_size = (image.width * scale, image.height * scale)\n",
        "    upscaled = image.resize(new_size, Image.Resampling.LANCZOS)\n",
        "    \n",
        "    return {\"image\": upscaled, \"scale\": scale}\n",
        "\n",
        "def apply_style_transfer(image: Image.Image, style: str) -> Dict:\n",
        "    \"\"\"Simule un transfert de style.\"\"\"\n",
        "    time.sleep(0.8)\n",
        "    \n",
        "    # Simuler un effet de style (juste modifier les couleurs)\n",
        "    arr = np.array(image).astype(float)\n",
        "    \n",
        "    if style == \"warm\":\n",
        "        arr[:,:,0] = np.clip(arr[:,:,0] * 1.2, 0, 255)  # Plus de rouge\n",
        "    elif style == \"cool\":\n",
        "        arr[:,:,2] = np.clip(arr[:,:,2] * 1.2, 0, 255)  # Plus de bleu\n",
        "    elif style == \"vintage\":\n",
        "        arr = np.clip(arr * 0.9 + 20, 0, 255)  # D\u00e9lav\u00e9\n",
        "    \n",
        "    styled = Image.fromarray(arr.astype(np.uint8))\n",
        "    return {\"image\": styled, \"style\": style}\n",
        "\n",
        "def evaluate_quality(image: Image.Image) -> Dict:\n",
        "    \"\"\"Simule une \u00e9valuation de qualit\u00e9.\"\"\"\n",
        "    time.sleep(0.3)\n",
        "    \n",
        "    # Score al\u00e9atoire entre 0.5 et 1.0\n",
        "    score = 0.5 + np.random.random() * 0.5\n",
        "    \n",
        "    return {\n",
        "        \"quality_score\": score,\n",
        "        \"passed\": score > 0.7,\n",
        "        \"feedback\": \"Good quality\" if score > 0.7 else \"Needs improvement\"\n",
        "    }\n",
        "\n",
        "print(\"\u2705 Fonctions de g\u00e9n\u00e9ration d\u00e9finies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-6",
      "metadata": {},
      "source": [
        "## 5. Pipeline S\u00e9quentiel: Text \u2192 Image \u2192 Style \u2192 Upscale"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Fonctions de g\u00e9n\u00e9ration d\u00e9finies\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 5. PIPELINE S\u00c9QUENTIEL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\ud83d\udccb Pipeline S\u00e9quentiel: Text \u2192 Image \u2192 Style \u2192 Upscale\")\n",
        "\n",
        "# D\u00e9finir les \u00e9tapes\n",
        "sequential_steps = [\n",
        "    WorkflowStep(\n",
        "        name=\"generate_image\",\n",
        "        func=generate_image_placeholder,\n",
        "        inputs={\"prompt\": \"A serene mountain landscape at sunset\", \"model\": \"sd35\"}\n",
        "    ),\n",
        "    WorkflowStep(\n",
        "        name=\"apply_style\",\n",
        "        func=lambda previous_output, **kw: apply_style_transfer(\n",
        "            previous_output[\"image\"], style=\"warm\"\n",
        "        ),\n",
        "        inputs={}\n",
        "    ),\n",
        "    WorkflowStep(\n",
        "        name=\"upscale\",\n",
        "        func=lambda previous_output, **kw: upscale_image(\n",
        "            previous_output[\"image\"], scale=2\n",
        "        ),\n",
        "        inputs={}\n",
        "    ),\n",
        "    WorkflowStep(\n",
        "        name=\"evaluate\",\n",
        "        func=lambda previous_output, **kw: evaluate_quality(previous_output[\"image\"]),\n",
        "        inputs={}\n",
        "    )\n",
        "]\n",
        "\n",
        "# Ex\u00e9cuter\n",
        "results = orchestrator.run_sequential(sequential_steps)\n",
        "\n",
        "# Afficher les r\u00e9sultats\n",
        "print(\"\\n\ud83d\udcca R\u00e9sum\u00e9:\")\n",
        "summary = orchestrator.get_summary()\n",
        "for key, value in summary.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# Visualiser si succ\u00e8s\n",
        "if \"upscale\" in results and results[\"upscale\"].status == TaskStatus.COMPLETED:\n",
        "    final_image = results[\"upscale\"].output[\"image\"]\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    if \"generate_image\" in results:\n",
        "        axes[0].imshow(results[\"generate_image\"].output[\"image\"])\n",
        "        axes[0].set_title(\"1. Generated\")\n",
        "        axes[0].axis('off')\n",
        "    \n",
        "    if \"apply_style\" in results:\n",
        "        axes[1].imshow(results[\"apply_style\"].output[\"image\"])\n",
        "        axes[1].set_title(\"2. Styled\")\n",
        "        axes[1].axis('off')\n",
        "    \n",
        "    axes[2].imshow(final_image)\n",
        "    axes[2].set_title(f\"3. Upscaled ({final_image.size})\")\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.suptitle(\"Pipeline S\u00e9quentiel\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-8",
      "metadata": {},
      "source": [
        "## 6. Pipeline Parall\u00e8le: G\u00e9n\u00e9ration Multi-Mod\u00e8les"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 6. PIPELINE PARALL\u00c8LE - MULTI-MOD\u00c8LES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\u26a1 Pipeline Parall\u00e8le: Comparaison Multi-Mod\u00e8les\")\n",
        "\n",
        "shared_prompt = \"A futuristic city with flying cars and neon lights\"\n",
        "\n",
        "parallel_steps = [\n",
        "    WorkflowStep(\n",
        "        name=\"qwen_generation\",\n",
        "        func=generate_image_placeholder,\n",
        "        inputs={\"prompt\": shared_prompt, \"model\": \"qwen\", \"seed\": 42}\n",
        "    ),\n",
        "    WorkflowStep(\n",
        "        name=\"flux_generation\",\n",
        "        func=generate_image_placeholder,\n",
        "        inputs={\"prompt\": shared_prompt, \"model\": \"flux\", \"seed\": 42}\n",
        "    ),\n",
        "    WorkflowStep(\n",
        "        name=\"sd35_generation\",\n",
        "        func=generate_image_placeholder,\n",
        "        inputs={\"prompt\": shared_prompt, \"model\": \"sd35\", \"seed\": 42}\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Ex\u00e9cuter en parall\u00e8le\n",
        "parallel_results = orchestrator.run_parallel(parallel_steps)\n",
        "\n",
        "# Affichage\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for i, (name, result) in enumerate(parallel_results.items()):\n",
        "    if result.status == TaskStatus.COMPLETED:\n",
        "        axes[i].imshow(result.output[\"image\"])\n",
        "        model = result.output[\"model\"]\n",
        "        axes[i].set_title(f\"{model.upper()}\\n({result.duration:.2f}s)\")\n",
        "    else:\n",
        "        axes[i].text(0.5, 0.5, \"Failed\", ha='center', va='center')\n",
        "        axes[i].set_title(name)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle(f\"Comparaison Multi-Mod\u00e8les\\n'{shared_prompt[:50]}...'\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n\u23f1\ufe0f Temps total: {orchestrator.get_summary()['total_time']:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "## 7. Pipeline Conditionnel: Qualit\u00e9-Based Routing"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\ud83d\udccb Pipeline S\u00e9quentiel: Text \u2192 Image \u2192 Style \u2192 Upscale\n",
            "\n",
            "\ud83d\udd17 Ex\u00e9cution S\u00e9quentielle\n",
            "========================================\n",
            "\n",
            "[1/4] generate_image\n",
            "   \ud83d\udd04 generate_image (attempt 1/3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   \u2705 Compl\u00e9t\u00e9 en 1.82s\n",
            "\n",
            "[2/4] apply_style\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Object of type Image is not JSON serializable",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m      8\u001b[39m sequential_steps = [\n\u001b[32m      9\u001b[39m     WorkflowStep(\n\u001b[32m     10\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mgenerate_image\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     )\n\u001b[32m     33\u001b[39m ]\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Ex\u00e9cuter\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m results = \u001b[43morchestrator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequential_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Afficher les r\u00e9sultats\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\ud83d\udcca R\u00e9sum\u00e9:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mWorkflowOrchestrator.run_sequential\u001b[39m\u001b[34m(self, steps, initial_input)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Merge inputs\u001b[39;00m\n\u001b[32m     97\u001b[39m merged_inputs = {**current_input, **step.inputs}\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28mself\u001b[39m.results[step.name] = result\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.status == TaskStatus.FAILED:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mWorkflowOrchestrator._execute_with_retry\u001b[39m\u001b[34m(self, step, inputs)\u001b[39m\n\u001b[32m     30\u001b[39m task_id = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(time.time()*\u001b[32m1000\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# V\u00e9rifier le cache\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m cache_key = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_cache_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   \ud83d\udce6 Cache hit pour \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mWorkflowOrchestrator._generate_cache_key\u001b[39m\u001b[34m(self, step_name, inputs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_cache_key\u001b[39m(\u001b[38;5;28mself\u001b[39m, step_name: \u001b[38;5;28mstr\u001b[39m, inputs: Dict) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"G\u00e9n\u00e8re une cl\u00e9 de cache unique.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     content = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hashlib.md5(content.encode()).hexdigest()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\json\\__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\json\\encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\json\\encoder.py:261\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    258\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, indent, floatstr,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\json\\encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mTypeError\u001b[39m: Object of type Image is not JSON serializable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 7. PIPELINE CONDITIONNEL\n",
        "# =============================================================================\n",
        "\n",
        "class ConditionalPipeline:\n",
        "    \"\"\"\n",
        "    Pipeline avec branchement conditionnel bas\u00e9 sur la qualit\u00e9.\n",
        "    Si qualit\u00e9 < seuil: r\u00e9g\u00e9n\u00e8re avec param\u00e8tres am\u00e9lior\u00e9s.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, quality_threshold: float = 0.7):\n",
        "        self.quality_threshold = quality_threshold\n",
        "        self.history = []\n",
        "    \n",
        "    def run(self, prompt: str, max_attempts: int = 3) -> Dict:\n",
        "        \"\"\"Ex\u00e9cute avec am\u00e9lioration it\u00e9rative.\"\"\"\n",
        "        print(f\"\\n\ud83d\udd04 Pipeline Conditionnel (seuil: {self.quality_threshold})\")\n",
        "        print(\"=\" * 40)\n",
        "        \n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "        \n",
        "        for attempt in range(max_attempts):\n",
        "            print(f\"\\n[Attempt {attempt + 1}/{max_attempts}]\")\n",
        "            \n",
        "            # G\u00e9n\u00e9rer\n",
        "            gen_result = generate_image_placeholder(\n",
        "                prompt=prompt,\n",
        "                model=\"sd35\",\n",
        "                steps=20 + attempt * 10  # Plus de steps \u00e0 chaque tentative\n",
        "            )\n",
        "            print(f\"   \ud83d\uddbc\ufe0f Image g\u00e9n\u00e9r\u00e9e\")\n",
        "            \n",
        "            # \u00c9valuer\n",
        "            eval_result = evaluate_quality(gen_result[\"image\"])\n",
        "            score = eval_result[\"quality_score\"]\n",
        "            print(f\"   \ud83d\udcca Score: {score:.2f}\")\n",
        "            \n",
        "            self.history.append({\n",
        "                \"attempt\": attempt + 1,\n",
        "                \"score\": score,\n",
        "                \"passed\": eval_result[\"passed\"]\n",
        "            })\n",
        "            \n",
        "            # Garder le meilleur\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_result = gen_result\n",
        "            \n",
        "            # Condition d'arr\u00eat\n",
        "            if score >= self.quality_threshold:\n",
        "                print(f\"   \u2705 Qualit\u00e9 suffisante atteinte!\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"   \u26a0\ufe0f Qualit\u00e9 insuffisante, retry...\")\n",
        "        \n",
        "        return {\n",
        "            \"result\": best_result,\n",
        "            \"final_score\": best_score,\n",
        "            \"attempts\": len(self.history),\n",
        "            \"history\": self.history\n",
        "        }\n",
        "\n",
        "# Test\n",
        "conditional = ConditionalPipeline(quality_threshold=0.75)\n",
        "cond_result = conditional.run(\"A magical forest with glowing mushrooms\")\n",
        "\n",
        "print(f\"\\n\ud83d\udccb R\u00e9sultat Final:\")\n",
        "print(f\"   Tentatives: {cond_result['attempts']}\")\n",
        "print(f\"   Score final: {cond_result['final_score']:.2f}\")\n",
        "\n",
        "# Visualiser l'historique\n",
        "if cond_result[\"history\"]:\n",
        "    attempts = [h[\"attempt\"] for h in cond_result[\"history\"]]\n",
        "    scores = [h[\"score\"] for h in cond_result[\"history\"]]\n",
        "    \n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(attempts, scores, color=['green' if s >= 0.75 else 'orange' for s in scores])\n",
        "    plt.axhline(y=0.75, color='red', linestyle='--', label='Seuil')\n",
        "    plt.xlabel('Tentative')\n",
        "    plt.ylabel('Score Qualit\u00e9')\n",
        "    plt.title('Pipeline Conditionnel - \u00c9volution de la Qualit\u00e9')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-12",
      "metadata": {},
      "source": [
        "## 8. Pipeline Avanc\u00e9: G\u00e9n\u00e9ration Multi-Variations"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 8. PIPELINE MULTI-VARIATIONS\n",
        "# =============================================================================\n",
        "\n",
        "class MultiVariationPipeline:\n",
        "    \"\"\"Pipeline pour g\u00e9n\u00e9rer et comparer plusieurs variations.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.orchestrator = WorkflowOrchestrator(max_workers=4)\n",
        "    \n",
        "    def generate_variations(self, base_prompt: str, \n",
        "                           styles: List[str] = None,\n",
        "                           models: List[str] = None) -> Dict:\n",
        "        \"\"\"G\u00e9n\u00e8re des variations par style et/ou mod\u00e8le.\"\"\"\n",
        "        \n",
        "        styles = styles or [\"photorealistic\", \"digital art\", \"oil painting\"]\n",
        "        models = models or [\"sd35\"]\n",
        "        \n",
        "        print(f\"\\n\ud83c\udfa8 G\u00e9n\u00e9ration Multi-Variations\")\n",
        "        print(f\"   Base: '{base_prompt[:40]}...'\")\n",
        "        print(f\"   Styles: {styles}\")\n",
        "        print(f\"   Models: {models}\")\n",
        "        \n",
        "        # Cr\u00e9er les \u00e9tapes\n",
        "        steps = []\n",
        "        for model in models:\n",
        "            for style in styles:\n",
        "                styled_prompt = f\"{base_prompt}, {style}\"\n",
        "                steps.append(WorkflowStep(\n",
        "                    name=f\"{model}_{style.replace(' ', '_')}\",\n",
        "                    func=generate_image_placeholder,\n",
        "                    inputs={\"prompt\": styled_prompt, \"model\": model}\n",
        "                ))\n",
        "        \n",
        "        # Ex\u00e9cuter en parall\u00e8le\n",
        "        results = self.orchestrator.run_parallel(steps)\n",
        "        \n",
        "        return {\n",
        "            \"variations\": results,\n",
        "            \"summary\": self.orchestrator.get_summary()\n",
        "        }\n",
        "    \n",
        "    def select_best(self, results: Dict) -> Tuple[str, Any]:\n",
        "        \"\"\"S\u00e9lectionne la meilleure variation bas\u00e9e sur l'\u00e9valuation.\"\"\"\n",
        "        best_name = None\n",
        "        best_score = 0\n",
        "        \n",
        "        for name, result in results[\"variations\"].items():\n",
        "            if result.status == TaskStatus.COMPLETED:\n",
        "                eval_result = evaluate_quality(result.output[\"image\"])\n",
        "                if eval_result[\"quality_score\"] > best_score:\n",
        "                    best_score = eval_result[\"quality_score\"]\n",
        "                    best_name = name\n",
        "        \n",
        "        return best_name, best_score\n",
        "\n",
        "# Test\n",
        "multi_pipeline = MultiVariationPipeline()\n",
        "variations_result = multi_pipeline.generate_variations(\n",
        "    \"A cozy cabin in the snowy mountains\",\n",
        "    styles=[\"photorealistic\", \"watercolor\", \"anime\"],\n",
        "    models=[\"sd35\"]\n",
        ")\n",
        "\n",
        "# Affichage grille\n",
        "completed = {k: v for k, v in variations_result[\"variations\"].items() \n",
        "             if v.status == TaskStatus.COMPLETED}\n",
        "\n",
        "if completed:\n",
        "    n = len(completed)\n",
        "    cols = min(3, n)\n",
        "    rows = (n + cols - 1) // cols\n",
        "    \n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
        "    axes = np.array(axes).flatten() if n > 1 else [axes]\n",
        "    \n",
        "    for i, (name, result) in enumerate(completed.items()):\n",
        "        axes[i].imshow(result.output[\"image\"])\n",
        "        axes[i].set_title(name.replace('_', ' '), fontsize=10)\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    for i in range(len(completed), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.suptitle(\"Multi-Variations\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# S\u00e9lectionner la meilleure\n",
        "best_name, best_score = multi_pipeline.select_best(variations_result)\n",
        "print(f\"\\n\ud83c\udfc6 Meilleure variation: {best_name} (score: {best_score:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {},
      "source": [
        "## 9. Exercices Pratiques\n",
        "\n",
        "### Exercice 1: Pipeline Personnalis\u00e9\n",
        "Cr\u00e9ez un pipeline qui g\u00e9n\u00e8re une image, applique 3 styles diff\u00e9rents, et s\u00e9lectionne le meilleur.\n",
        "\n",
        "### Exercice 2: Retry Intelligent\n",
        "Modifiez `ConditionalPipeline` pour utiliser des param\u00e8tres diff\u00e9rents \u00e0 chaque retry.\n",
        "\n",
        "### Exercice 3: M\u00e9triques\n",
        "Ajoutez des m\u00e9triques de performance (temps par mod\u00e8le, taux de succ\u00e8s)."
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 9. ESPACE D'EXERCICES\n",
        "# =============================================================================\n",
        "\n",
        "# Exercice 1: D\u00e9commentez et compl\u00e9tez\n",
        "\n",
        "# custom_steps = [\n",
        "#     WorkflowStep(name=\"generate\", func=generate_image_placeholder, \n",
        "#                  inputs={\"prompt\": \"votre prompt\"}),\n",
        "#     # Ajoutez vos \u00e9tapes...\n",
        "# ]\n",
        "# \n",
        "# custom_orchestrator = WorkflowOrchestrator()\n",
        "# custom_results = custom_orchestrator.run_sequential(custom_steps)\n",
        "\n",
        "print(\"\ud83d\udcdd Espace d'exercices - D\u00e9commentez pour commencer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## 10. R\u00e9capitulatif\n",
        "\n",
        "### Patterns d'Orchestration\n",
        "\n",
        "| Pattern | Cas d'Usage | Avantages |\n",
        "|---------|-------------|----------|\n",
        "| **S\u00e9quentiel** | Cha\u00eenage d\u00e9pendant | Simple, pr\u00e9visible |\n",
        "| **Parall\u00e8le** | Comparaison mod\u00e8les | Rapide, efficace |\n",
        "| **Conditionnel** | Qualit\u00e9 garantie | Adaptif, robuste |\n",
        "| **Multi-Variations** | Exploration | Diversit\u00e9, choix |\n",
        "\n",
        "### Bonnes Pratiques\n",
        "\n",
        "1. **Retry avec backoff** pour la r\u00e9silience\n",
        "2. **Caching** pour les r\u00e9sultats interm\u00e9diaires\n",
        "3. **Timeouts** pour \u00e9viter les blocages\n",
        "4. **Logging** pour le debugging\n",
        "5. **\u00c9valuation automatique** pour la s\u00e9lection"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FIN DU NOTEBOOK\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"   \u2705 Notebook Workflow Orchestration Compl\u00e9t\u00e9\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n\ud83d\udcc5 Termin\u00e9: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"\\n\ud83d\udcda Concepts couverts:\")\n",
        "print(\"   \u2022 WorkflowOrchestrator pour pipelines\")\n",
        "print(\"   \u2022 Ex\u00e9cution s\u00e9quentielle et parall\u00e8le\")\n",
        "print(\"   \u2022 Pipelines conditionnels\")\n",
        "print(\"   \u2022 Multi-variations et s\u00e9lection\")\n",
        "print(\"   \u2022 Retry et gestion d'erreurs\")\n",
        "print(\"\\n\u27a1\ufe0f  Prochain notebook: 03-3-Performance-Optimization.ipynb\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}