{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89109c32",
   "metadata": {
    "papermill": {
     "duration": 0.003056,
     "end_time": "2026-02-18T08:59:12.637598",
     "exception": false,
     "start_time": "2026-02-18T08:59:12.634542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ğŸ¤– GPT-5 Multimodal - Analyse et GÃ©nÃ©ration d'Images\n",
    "\n",
    "**Module :** 01-Images-Foundation  \n",
    "**Niveau :** ğŸŸ¢ DÃ©butant  \n",
    "**Technologies :** GPT-5, OpenRouter API, Vision AI  \n",
    "**DurÃ©e estimÃ©e :** 30 minutes  \n",
    "\n",
    "## ğŸ¯ Objectifs d'Apprentissage\n",
    "\n",
    "- [ ] Configurer GPT-5 via OpenRouter pour analyse d'images\n",
    "- [ ] MaÃ®triser les conversations multimodales texte + image\n",
    "- [ ] Analyser et dÃ©crire des images avec prÃ©cision\n",
    "- [ ] CrÃ©er des prompts optimisÃ©s pour l'analyse visuelle\n",
    "- [ ] IntÃ©grer GPT-5 dans des cas d'usage pÃ©dagogiques\n",
    "\n",
    "## ğŸ“š PrÃ©requis\n",
    "\n",
    "- Environment Setup (module 00) complÃ©tÃ©\n",
    "- ClÃ© API OpenRouter configurÃ©e\n",
    "- Connaissances de base en IA multimodale\n",
    "\n",
    "## âš¡ CapacitÃ©s GPT-5\n",
    "\n",
    "- **Vision avancÃ©e** : Analyse dÃ©taillÃ©e d'images\n",
    "- **Multimodal** : Conversation texte + image simultanÃ©e\n",
    "- **Contexte Ã©tendu** : Jusqu'Ã  200K tokens\n",
    "- **Raisonnement** : Analyse complexe et dÃ©ductive\n",
    "- **Ã‰ducatif** : Parfait pour l'enseignement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923ff0b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T08:59:12.642831Z",
     "iopub.status.busy": "2026-02-18T08:59:12.642634Z",
     "iopub.status.idle": "2026-02-18T08:59:12.647035Z",
     "shell.execute_reply": "2026-02-18T08:59:12.646382Z"
    },
    "papermill": {
     "duration": 0.007802,
     "end_time": "2026-02-18T08:59:12.648134",
     "exception": false,
     "start_time": "2026-02-18T08:59:12.640332",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parametres Papermill - JAMAIS modifier ce commentaire\n",
    "\n",
    "# Configuration conversation\n",
    "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
    "skip_widgets = False               # True pour mode batch MCP\n",
    "debug_level = \"INFO\"               \n",
    "\n",
    "# Parametres GPT-5\n",
    "model_name = \"openai/gpt-5\"        # Modele via OpenRouter\n",
    "max_tokens = 4000                  # Tokens de reponse max\n",
    "temperature = 0.7                  # Creativite (0.0-1.0)\n",
    "top_p = 0.9                        # Diversite sampling\n",
    "\n",
    "# Configuration analyse\n",
    "analyze_images = True              # Analyser les images (False pour validation structurelle seule)\n",
    "analysis_mode = \"detailed\"         # \"quick\", \"detailed\", \"educational\"\n",
    "include_technical_details = True   # Details techniques images\n",
    "export_analysis = True             # Sauvegarder analyses\n",
    "generate_alt_text = True           # Generer descriptions accessibilite\n",
    "\n",
    "# Parametres pedagogiques\n",
    "educational_level = \"university\"   # \"elementary\", \"secondary\", \"university\"\n",
    "language = \"francais\"              # Langue des explications\n",
    "include_examples = True            # Inclure exemples pratiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf2a7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T08:59:12.653102Z",
     "iopub.status.busy": "2026-02-18T08:59:12.652891Z",
     "iopub.status.idle": "2026-02-18T08:59:12.656359Z",
     "shell.execute_reply": "2026-02-18T08:59:12.655622Z"
    },
    "papermill": {
     "duration": 0.007407,
     "end_time": "2026-02-18T08:59:12.657544",
     "exception": false,
     "start_time": "2026-02-18T08:59:12.650137",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "notebook_mode = \"batch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5749c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T08:59:12.662744Z",
     "iopub.status.busy": "2026-02-18T08:59:12.662541Z",
     "iopub.status.idle": "2026-02-18T08:59:13.422378Z",
     "shell.execute_reply": "2026-02-18T08:59:13.421551Z"
    },
    "papermill": {
     "duration": 0.763463,
     "end_time": "2026-02-18T08:59:13.423493",
     "exception": false,
     "start_time": "2026-02-18T08:59:12.660030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helpers GenAI importÃ©s\n",
      "ğŸ¤– GPT-5 Multimodal - Analyse et GÃ©nÃ©ration d'Images\n",
      "ğŸ“… 2026-02-18 09:59:13\n",
      "ğŸ”§ Mode: batch, Analyse: detailed, Niveau: university\n",
      "ğŸŒ Langue: francais, Max tokens: 4000\n"
     ]
    }
   ],
   "source": [
    "# Setup environnement et imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Import helpers GenAI\n",
    "GENAI_ROOT = Path.cwd()\n",
    "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
    "    GENAI_ROOT = GENAI_ROOT.parent\n",
    "\n",
    "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
    "if HELPERS_PATH.exists():\n",
    "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
    "    try:\n",
    "        from helpers.genai_helpers import setup_genai_logging, load_genai_config\n",
    "        print(\"âœ… Helpers GenAI importÃ©s\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸  Helpers GenAI non disponibles - mode autonome\")\n",
    "\n",
    "# Configuration logging\n",
    "logging.basicConfig(level=getattr(logging, debug_level))\n",
    "logger = logging.getLogger('gpt5_multimodal')\n",
    "\n",
    "print(f\"ğŸ¤– GPT-5 Multimodal - Analyse et GÃ©nÃ©ration d'Images\")\n",
    "print(f\"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ”§ Mode: {notebook_mode}, Analyse: {analysis_mode}, Niveau: {educational_level}\")\n",
    "print(f\"ğŸŒ Langue: {language}, Max tokens: {max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68c0943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T08:59:13.428716Z",
     "iopub.status.busy": "2026-02-18T08:59:13.428467Z",
     "iopub.status.idle": "2026-02-18T08:59:13.553567Z",
     "shell.execute_reply": "2026-02-18T08:59:13.552951Z"
    },
    "papermill": {
     "duration": 0.128423,
     "end_time": "2026-02-18T08:59:13.554367",
     "exception": false,
     "start_time": "2026-02-18T08:59:13.425944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”‘ CONFIGURATION GPT-5 MULTIMODAL\n",
      "==========================================\n",
      "âœ… Fichier .env chargÃ© depuis: D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\.env\n",
      "âœ… ClÃ© API OpenRouter configurÃ©e\n",
      "âœ… Connexion rÃ©ussie - 17 modÃ¨les GPT-5 disponibles\n",
      "  ğŸ§  openai/gpt-5.2-codex - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5.2-chat - Contexte: 128000 tokens\n",
      "  ğŸ§  openai/gpt-5.2-pro - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5.2 - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5.1-codex-max - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5.1 - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5.1-chat - Contexte: 128000 tokens\n",
      "  ğŸ§  openai/gpt-5.1-codex - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5.1-codex-mini - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5-image-mini - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5-image - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5-pro - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5-codex - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5-chat - Contexte: 128000 tokens\n",
      "  ğŸ§  openai/gpt-5 - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5-mini - Contexte: 400000 tokens\n",
      "  ğŸ§  openai/gpt-5-nano - Contexte: 400000 tokens\n",
      "\n",
      "ğŸ¯ ModÃ¨le sÃ©lectionnÃ©: openai/gpt-5\n",
      "âš™ï¸  ParamÃ¨tres: Temperature=0.7, Max tokens=4000\n",
      "ğŸ“Š Mode d'analyse: detailed\n"
     ]
    }
   ],
   "source": [
    "# Configuration API OpenRouter pour GPT-5\n",
    "print(\"\\nğŸ”‘ CONFIGURATION GPT-5 MULTIMODAL\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Chargement explicite du .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Recherche du .env dans les parents\n",
    "current_path = Path.cwd()\n",
    "found_env = False\n",
    "for _ in range(4):  # Remonter jusqu'Ã  4 niveaux\n",
    "    env_path = current_path / '.env'\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"âœ… Fichier .env chargÃ© depuis: {env_path}\")\n",
    "        found_env = True\n",
    "        break\n",
    "    current_path = current_path.parent\n",
    "\n",
    "if not found_env:\n",
    "    print(\"âš ï¸  Aucun fichier .env trouvÃ© dans l'arborescence\")\n",
    "\n",
    "# VÃ©rification clÃ© API\n",
    "openrouter_key = os.getenv('OPENROUTER_API_KEY')\n",
    "if not openrouter_key:\n",
    "    # Fallback pour validation structurelle sans clÃ©\n",
    "    if notebook_mode == \"batch\" and not analyze_images:\n",
    "        print(\"âš ï¸  Mode batch sans analyse : ClÃ© API ignorÃ©e\")\n",
    "        openrouter_key = \"dummy_key_for_validation\"\n",
    "    else:\n",
    "        raise ValueError(\"âŒ OPENROUTER_API_KEY manquante dans .env\")\n",
    "\n",
    "print(f\"âœ… ClÃ© API OpenRouter configurÃ©e\")\n",
    "\n",
    "# Configuration headers et endpoint\n",
    "api_base_url = \"https://openrouter.ai/api/v1\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openrouter_key}\",\n",
    "    \"HTTP-Referer\": \"https://coursia.myia.io\",\n",
    "    \"X-Title\": \"CoursIA GenAI Images - GPT-5 Multimodal\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Test connexion et vÃ©rification modÃ¨le GPT-5\n",
    "if openrouter_key != \"dummy_key_for_validation\":\n",
    "    try:\n",
    "        response = requests.get(f\"{api_base_url}/models\", headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            models_data = response.json()\n",
    "            gpt5_models = [m for m in models_data.get('data', []) if 'gpt-5' in m.get('id', '').lower()]\n",
    "            \n",
    "            if gpt5_models:\n",
    "                print(f\"âœ… Connexion rÃ©ussie - {len(gpt5_models)} modÃ¨les GPT-5 disponibles\")\n",
    "                \n",
    "                for model in gpt5_models:\n",
    "                    print(f\"  ğŸ§  {model['id']} - Contexte: {model.get('context_length', 'N/A')} tokens\")\n",
    "                    if 'vision' in model.get('capabilities', []):\n",
    "                        print(f\"     ğŸ‘ï¸  CapacitÃ©s vision activÃ©es\")\n",
    "            else:\n",
    "                print(f\"âš ï¸  Aucun modÃ¨le GPT-5 dÃ©tectÃ© - vÃ©rifiez votre accÃ¨s\")\n",
    "                print(f\"ğŸ” ModÃ¨les disponibles avec 'gpt' : {len([m for m in models_data.get('data', []) if 'gpt' in m.get('id', '').lower()])}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  Connexion API: HTTP {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur connexion: {str(e)[:100]}...\")\n",
    "else:\n",
    "    print(\"â­ï¸  Test connexion API sautÃ© (dummy key)\")\n",
    "    \n",
    "print(f\"\\nğŸ¯ ModÃ¨le sÃ©lectionnÃ©: {model_name}\")\n",
    "print(f\"âš™ï¸  ParamÃ¨tres: Temperature={temperature}, Max tokens={max_tokens}\")\n",
    "print(f\"ğŸ“Š Mode d'analyse: {analysis_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e35d0ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T08:59:13.559746Z",
     "iopub.status.busy": "2026-02-18T08:59:13.559523Z",
     "iopub.status.idle": "2026-02-18T08:59:13.565786Z",
     "shell.execute_reply": "2026-02-18T08:59:13.565207Z"
    },
    "papermill": {
     "duration": 0.010088,
     "end_time": "2026-02-18T08:59:13.566638",
     "exception": false,
     "start_time": "2026-02-18T08:59:13.556550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fonctions utilitaires images prÃªtes\n"
     ]
    }
   ],
   "source": [
    "# Fonctions utilitaires pour traitement d'images\n",
    "def encode_image_base64(image_path: Union[str, Path]) -> str:\n",
    "    \"\"\"\n",
    "    Encode une image locale en base64 pour GPT-5.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Chemin vers l'image locale\n",
    "        \n",
    "    Returns:\n",
    "        String base64 de l'image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Erreur lecture image {image_path}: {str(e)}\")\n",
    "\n",
    "def download_and_encode_image(image_url: str) -> str:\n",
    "    \"\"\"\n",
    "    TÃ©lÃ©charge et encode une image depuis URL.\n",
    "    \n",
    "    Args:\n",
    "        image_url: URL de l'image\n",
    "        \n",
    "    Returns:\n",
    "        String base64 de l'image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(image_url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return base64.b64encode(response.content).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Erreur tÃ©lÃ©chargement {image_url}: {str(e)}\")\n",
    "\n",
    "def prepare_image_for_gpt5(image_source: Union[str, Path]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    PrÃ©pare une image pour GPT-5 (locale ou URL).\n",
    "    \n",
    "    Args:\n",
    "        image_source: Chemin local ou URL de l'image\n",
    "        \n",
    "    Returns:\n",
    "        Dict avec format attendu par GPT-5\n",
    "    \"\"\"\n",
    "    if isinstance(image_source, (str, Path)):\n",
    "        str_source = str(image_source)\n",
    "        \n",
    "        # VÃ©rification URL\n",
    "        if str_source.startswith(('http://', 'https://')):\n",
    "            try:\n",
    "                # Pour les URLs, GPT-5 peut les traiter directement\n",
    "                return {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": str_source\n",
    "                    }\n",
    "                }\n",
    "            except:\n",
    "                # Fallback : tÃ©lÃ©charger et encoder\n",
    "                base64_image = download_and_encode_image(str_source)\n",
    "                return {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "        else:\n",
    "            # Image locale\n",
    "            if Path(str_source).exists():\n",
    "                base64_image = encode_image_base64(str_source)\n",
    "                return {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Image non trouvÃ©e: {str_source}\")\n",
    "    \n",
    "    raise ValueError(f\"Format d'image non supportÃ©: {type(image_source)}\")\n",
    "\n",
    "print(\"âœ… Fonctions utilitaires images prÃªtes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d7158b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T08:59:13.572012Z",
     "iopub.status.busy": "2026-02-18T08:59:13.571714Z",
     "iopub.status.idle": "2026-02-18T08:59:13.579936Z",
     "shell.execute_reply": "2026-02-18T08:59:13.579035Z"
    },
    "papermill": {
     "duration": 0.012268,
     "end_time": "2026-02-18T08:59:13.580966",
     "exception": false,
     "start_time": "2026-02-18T08:59:13.568698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fonction d'analyse GPT-5 prÃªte\n"
     ]
    }
   ],
   "source": [
    "# Fonction principale d'analyse d'image avec GPT-5\n",
    "def analyze_image_with_gpt5(image_source: Union[str, Path], \n",
    "                           prompt: str = None,\n",
    "                           analysis_type: str = \"detailed\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyse une image avec GPT-5 multimodal.\n",
    "    \n",
    "    Args:\n",
    "        image_source: Chemin local ou URL de l'image\n",
    "        prompt: Prompt personnalisÃ© (optionnel)\n",
    "        analysis_type: Type d'analyse (\"quick\", \"detailed\", \"educational\")\n",
    "        \n",
    "    Returns:\n",
    "        Dict avec analyse complÃ¨te\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prompts prÃ©dÃ©finis selon le type d'analyse\n",
    "    analysis_prompts = {\n",
    "        \"quick\": f\"DÃ©cris briÃ¨vement cette image en {language}. Sois concis mais prÃ©cis.\",\n",
    "        \n",
    "        \"detailed\": f\"\"\"Analyse cette image en dÃ©tail en {language}. Inclus :\n",
    "        \n",
    "1. **Description gÃ©nÃ©rale** : Que voit-on dans l'image ?\n",
    "2. **Ã‰lÃ©ments visuels** : Couleurs, composition, style artistique\n",
    "3. **Contexte** : Ã‰poque, lieu, situation probable\n",
    "4. **DÃ©tails techniques** : QualitÃ©, rÃ©solution apparente, type de photo/illustration\n",
    "5. **Ã‰motions/AtmosphÃ¨re** : Quelle ambiance dÃ©gage l'image ?\n",
    "6. **InterprÃ©tation** : Signification possible, message artistique\n",
    "\n",
    "Sois prÃ©cis et pÃ©dagogique dans tes explications.\"\"\",\n",
    "        \n",
    "        \"educational\": f\"\"\"Tu es un professeur expert analysant cette image pour des Ã©tudiants de niveau {educational_level}. En {language}, fournis :\n",
    "\n",
    "ğŸ¯ **ANALYSE PÃ‰DAGOGIQUE**\n",
    "\n",
    "**1. Description accessible**\n",
    "- Que montre cette image de faÃ§on simple et claire ?\n",
    "\n",
    "**2. Ã‰lÃ©ments Ã  observer**\n",
    "- Quels dÃ©tails importants les Ã©tudiants doivent-ils remarquer ?\n",
    "- Techniques artistiques ou photographiques utilisÃ©es\n",
    "\n",
    "**3. Contexte Ã©ducatif**\n",
    "- Dans quel domaine d'Ã©tude cette image serait-elle utile ?\n",
    "- Quelles disciplines acadÃ©miques peuvent l'utiliser ?\n",
    "\n",
    "**4. Questions pour rÃ©flexion**\n",
    "- 3 questions que tu poserais aux Ã©tudiants sur cette image\n",
    "\n",
    "**5. Connexions interdisciplinaires**\n",
    "- Comment cette image se connecte-t-elle Ã  d'autres sujets ?\n",
    "\n",
    "Adapte ton vocabulaire au niveau {educational_level}.\"\"\"\n",
    "    }\n",
    "    \n",
    "    # SÃ©lection du prompt\n",
    "    if prompt is None:\n",
    "        prompt = analysis_prompts.get(analysis_type, analysis_prompts[\"detailed\"])\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nğŸ” Analyse en cours...\")\n",
    "        print(f\"ğŸ“ Type: {analysis_type}\")\n",
    "        print(f\"ğŸ–¼ï¸  Source: {str(image_source)[:100]}{'...' if len(str(image_source)) > 100 else ''}\")\n",
    "        \n",
    "        # PrÃ©paration de l'image\n",
    "        image_data = prepare_image_for_gpt5(image_source)\n",
    "        \n",
    "        # Construction du message multimodal\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    },\n",
    "                    image_data\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Payload de la requÃªte\n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"messages\": messages,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p\n",
    "        }\n",
    "        \n",
    "        # RequÃªte API\n",
    "        start_time = datetime.now()\n",
    "        response = requests.post(\n",
    "            f\"{api_base_url}/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=120\n",
    "        )\n",
    "        response_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            analysis_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "            \n",
    "            # MÃ©tadonnÃ©es de l'analyse\n",
    "            metadata = {\n",
    "                \"model\": model_name,\n",
    "                \"analysis_type\": analysis_type,\n",
    "                \"educational_level\": educational_level,\n",
    "                \"language\": language,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"response_time\": response_time,\n",
    "                \"tokens_used\": result.get(\"usage\", {}),\n",
    "                \"image_source\": str(image_source),\n",
    "                \"prompt_length\": len(prompt)\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"analysis\": analysis_text,\n",
    "                \"metadata\": metadata,\n",
    "                \"image_source\": image_source,\n",
    "                \"analysis_type\": analysis_type\n",
    "            }\n",
    "        else:\n",
    "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else {}\n",
    "            error_msg = error_data.get(\"error\", {}).get(\"message\", f\"HTTP {response.status_code}\")\n",
    "            \n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": error_msg,\n",
    "                \"image_source\": image_source,\n",
    "                \"status_code\": response.status_code\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"image_source\": image_source\n",
    "        }\n",
    "\n",
    "print(\"âœ… Fonction d'analyse GPT-5 prÃªte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d27b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T08:59:13.587250Z",
     "iopub.status.busy": "2026-02-18T08:59:13.586937Z",
     "iopub.status.idle": "2026-02-18T08:59:13.592279Z",
     "shell.execute_reply": "2026-02-18T08:59:13.591563Z"
    },
    "papermill": {
     "duration": 0.009926,
     "end_time": "2026-02-18T08:59:13.593374",
     "exception": false,
     "start_time": "2026-02-18T08:59:13.583448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ–¼ï¸  EXEMPLES D'ANALYSE GPT-5\n",
      "========================================\n",
      "\n",
      "1. ğŸ›ï¸ Architecture Historique\n",
      "   ğŸ“‚ CatÃ©gorie: Histoire/Architecture\n",
      "   ğŸ“ Monument historique romain - idÃ©al pour analyse architecturale\n",
      "   ğŸ”— URL: https://images.unsplash.com/photo-1539037116277-4db20889f2d4...\n",
      "\n",
      "2. ğŸ”¬ Science et Technologie\n",
      "   ğŸ“‚ CatÃ©gorie: Science/Technologie\n",
      "   ğŸ“ Environnement scientifique - parfait pour analyse technique\n",
      "   ğŸ”— URL: https://images.unsplash.com/photo-1532094349884-543bc11b234d...\n",
      "\n",
      "3. ğŸ¨ Art et Culture\n",
      "   ğŸ“‚ CatÃ©gorie: Art/Culture\n",
      "   ğŸ“ Å’uvre artistique - excellent pour analyse esthÃ©tique\n",
      "   ğŸ”— URL: https://images.unsplash.com/photo-1541961017774-22349e4a1262...\n",
      "\n",
      "4. ğŸŒ Nature et Environnement\n",
      "   ğŸ“‚ CatÃ©gorie: GÃ©ographie/Environnement\n",
      "   ğŸ“ Paysage naturel - parfait pour analyse gÃ©ographique\n",
      "   ğŸ”— URL: https://images.unsplash.com/photo-1506905925346-21bda4d32df4...\n",
      "\n",
      "ğŸ’¡ Conseils pour l'analyse avec GPT-5:\n",
      "â€¢ Utilisez des images de haute qualitÃ©\n",
      "â€¢ Posez des questions spÃ©cifiques\n",
      "â€¢ Exploitez le contexte Ã©ducatif\n",
      "â€¢ Combinez analyse textuelle et visuelle\n",
      "â€¢ Adaptez le niveau de complexitÃ©\n"
     ]
    }
   ],
   "source": [
    "# Exemples d'images pour dÃ©monstration\n",
    "print(\"\\nğŸ–¼ï¸  EXEMPLES D'ANALYSE GPT-5\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Images d'exemple (URLs publiques pour tests)\n",
    "example_images = [\n",
    "    {\n",
    "        \"title\": \"ğŸ›ï¸ Architecture Historique\",\n",
    "        \"url\": \"https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\",  # ColisÃ©e Rome\n",
    "        \"description\": \"Monument historique romain - idÃ©al pour analyse architecturale\",\n",
    "        \"category\": \"Histoire/Architecture\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸ”¬ Science et Technologie\",\n",
    "        \"url\": \"https://images.unsplash.com/photo-1532094349884-543bc11b234d?w=800\",  # Laboratoire\n",
    "        \"description\": \"Environnement scientifique - parfait pour analyse technique\",\n",
    "        \"category\": \"Science/Technologie\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸ¨ Art et Culture\",\n",
    "        \"url\": \"https://images.unsplash.com/photo-1541961017774-22349e4a1262?w=800\",  # Peinture\n",
    "        \"description\": \"Å’uvre artistique - excellent pour analyse esthÃ©tique\",\n",
    "        \"category\": \"Art/Culture\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸŒ Nature et Environnement\",\n",
    "        \"url\": \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800\",  # Paysage naturel\n",
    "        \"description\": \"Paysage naturel - parfait pour analyse gÃ©ographique\",\n",
    "        \"category\": \"GÃ©ographie/Environnement\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Affichage des exemples\n",
    "for i, example in enumerate(example_images, 1):\n",
    "    print(f\"\\n{i}. {example['title']}\")\n",
    "    print(f\"   ğŸ“‚ CatÃ©gorie: {example['category']}\")\n",
    "    print(f\"   ğŸ“ {example['description']}\")\n",
    "    print(f\"   ğŸ”— URL: {example['url'][:60]}...\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Conseils pour l'analyse avec GPT-5:\")\n",
    "print(f\"â€¢ Utilisez des images de haute qualitÃ©\")\n",
    "print(f\"â€¢ Posez des questions spÃ©cifiques\")\n",
    "print(f\"â€¢ Exploitez le contexte Ã©ducatif\")\n",
    "print(f\"â€¢ Combinez analyse textuelle et visuelle\")\n",
    "print(f\"â€¢ Adaptez le niveau de complexitÃ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc59d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T08:59:13.599535Z",
     "iopub.status.busy": "2026-02-18T08:59:13.599022Z",
     "iopub.status.idle": "2026-02-18T09:01:20.427952Z",
     "shell.execute_reply": "2026-02-18T09:01:20.427408Z"
    },
    "papermill": {
     "duration": 126.834486,
     "end_time": "2026-02-18T09:01:20.430192",
     "exception": false,
     "start_time": "2026-02-18T08:59:13.595706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ANALYSE DE DÃ‰MONSTRATION - GPT-5\n",
      "==================================================\n",
      "ğŸ¯ Analyse: ğŸ›ï¸ Architecture Historique\n",
      "ğŸ“‚ CatÃ©gorie: Histoire/Architecture\n",
      "\n",
      "ğŸ” Mode d'analyse: QUICK\n",
      "------------------------------\n",
      "\n",
      "ğŸ” Analyse en cours...\n",
      "ğŸ“ Type: quick\n",
      "ğŸ–¼ï¸  Source: https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analyse quick rÃ©ussie\n",
      "â±ï¸  Temps: 10.95s\n",
      "ğŸ”¢ Tokens: {'prompt_tokens': 653, 'completion_tokens': 253, 'total_tokens': 906, 'cost': 0, 'is_byok': True, 'prompt_tokens_details': {'cached_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.00334625, 'upstream_inference_prompt_cost': 0.00081625, 'upstream_inference_completions_cost': 0.00253}, 'completion_tokens_details': {'reasoning_tokens': 192, 'image_tokens': 0}}\n",
      "\n",
      "ğŸ“ **AperÃ§u de l'analyse quick:**\n",
      "Vue au coucher du soleil sur la Gran VÃ­a Ã  Madrid : bÃ¢timents historiques Ã©clairÃ©s, circulation sur lâ€™avenue, ciel orangÃ© et montagnes au loin, avec le dÃ´me noir et dorÃ© du bÃ¢timent MetrÃ³polis au premier plan.\n",
      "\n",
      "\n",
      "ğŸ” Mode d'analyse: DETAILED\n",
      "------------------------------\n",
      "\n",
      "ğŸ” Analyse en cours...\n",
      "ğŸ“ Type: detailed\n",
      "ğŸ–¼ï¸  Source: https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analyse detailed rÃ©ussie\n",
      "â±ï¸  Temps: 42.89s\n",
      "ğŸ”¢ Tokens: {'prompt_tokens': 758, 'completion_tokens': 1548, 'total_tokens': 2306, 'cost': 0, 'is_byok': True, 'prompt_tokens_details': {'cached_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.0164275, 'upstream_inference_prompt_cost': 0.0009475, 'upstream_inference_completions_cost': 0.01548}, 'completion_tokens_details': {'reasoning_tokens': 576, 'image_tokens': 0}}\n",
      "\n",
      "ğŸ“ **AperÃ§u de l'analyse detailed:**\n",
      "1) Description gÃ©nÃ©rale\n",
      "- Vue aÃ©rienne/Ã©levÃ©e dâ€™une grande avenue urbaine au crÃ©puscule. \n",
      "- Au premier plan Ã  gauche, un immeuble dâ€™angle ornÃ© dâ€™un dÃ´me sombre surmontÃ© dâ€™une statue; lâ€™enseigne lumineuse â€œMetropolisâ€ est visible.\n",
      "- Lâ€™avenue sâ€™Ã©tire en diagonale, bordÃ©e dâ€™immeubles Ã©lÃ©gants aux faÃ§ad...\n",
      "\n",
      "\n",
      "ğŸ” Mode d'analyse: EDUCATIONAL\n",
      "------------------------------\n",
      "\n",
      "ğŸ” Analyse en cours...\n",
      "ğŸ“ Type: educational\n",
      "ğŸ–¼ï¸  Source: https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analyse educational rÃ©ussie\n",
      "â±ï¸  Temps: 72.98s\n",
      "ğŸ”¢ Tokens: {'prompt_tokens': 804, 'completion_tokens': 1825, 'total_tokens': 2629, 'cost': 0, 'is_byok': True, 'prompt_tokens_details': {'cached_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.019255, 'upstream_inference_prompt_cost': 0.001005, 'upstream_inference_completions_cost': 0.01825}, 'completion_tokens_details': {'reasoning_tokens': 960, 'image_tokens': 0}}\n",
      "\n",
      "ğŸ“ **AperÃ§u de l'analyse educational:**\n",
      "ğŸ¯ ANALYSE PÃ‰DAGOGIQUE\n",
      "\n",
      "1) Description accessible\n",
      "- Vue aÃ©rienne/Ã©levÃ©e dâ€™un centre-ville au coucher du soleil.\n",
      "- Une large avenue traverse lâ€™image, bordÃ©e dâ€™immeubles historiques Ã©clairÃ©s.\n",
      "- Circulation modÃ©rÃ©e de voitures, piÃ©tons discrets, enseignes lumineuses.\n",
      "- Ã€ lâ€™horizon, chaÃ®ne de montagnes s...\n",
      "\n",
      "\n",
      "ğŸ“Š COMPARAISON DES MODES D'ANALYSE\n",
      "=============================================\n",
      "Quick        |  209 chars |    906 tokens | 10.95s\n",
      "Detailed     | 3611 chars |   2306 tokens | 42.89s\n",
      "Educational  | 3322 chars |   2629 tokens | 72.98s\n",
      "\n",
      "ğŸ’¡ Observations:\n",
      "â€¢ Mode 'quick': RÃ©ponses concises et rapides\n",
      "â€¢ Mode 'detailed': Analyse approfondie et structurÃ©e\n",
      "â€¢ Mode 'educational': AdaptÃ© Ã  l'enseignement avec questions\n"
     ]
    }
   ],
   "source": [
    "# Analyse d'une image de dÃ©monstration\n",
    "print(\"\\nğŸš€ ANALYSE DE DÃ‰MONSTRATION - GPT-5\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# SÃ©lection d'une image pour la dÃ©monstration\n",
    "selected_example = example_images[0]  # Architecture historique\n",
    "print(f\"ğŸ¯ Analyse: {selected_example['title']}\")\n",
    "print(f\"ğŸ“‚ CatÃ©gorie: {selected_example['category']}\")\n",
    "\n",
    "# Test de l'analyse avec les diffÃ©rents modes\n",
    "analysis_results = []\n",
    "\n",
    "for mode in ['quick', 'detailed', 'educational']:\n",
    "    print(f\"\\nğŸ” Mode d'analyse: {mode.upper()}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Analyse de l'image\n",
    "    result = analyze_image_with_gpt5(\n",
    "        image_source=selected_example['url'],\n",
    "        analysis_type=mode\n",
    "    )\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"âœ… Analyse {mode} rÃ©ussie\")\n",
    "        print(f\"â±ï¸  Temps: {result['metadata']['response_time']:.2f}s\")\n",
    "        print(f\"ğŸ”¢ Tokens: {result['metadata']['tokens_used']}\")\n",
    "        \n",
    "        # Affichage de l'analyse (tronquÃ©e pour la dÃ©mo)\n",
    "        analysis_preview = result['analysis'][:300] + \"...\" if len(result['analysis']) > 300 else result['analysis']\n",
    "        print(f\"\\nğŸ“ **AperÃ§u de l'analyse {mode}:**\")\n",
    "        print(analysis_preview)\n",
    "        \n",
    "        analysis_results.append(result)\n",
    "    else:\n",
    "        print(f\"âŒ Ã‰chec analyse {mode}: {result['error']}\")\n",
    "    \n",
    "    print()  # SÃ©paration\n",
    "\n",
    "# Comparaison des rÃ©sultats\n",
    "if analysis_results:\n",
    "    print(f\"\\nğŸ“Š COMPARAISON DES MODES D'ANALYSE\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    for result in analysis_results:\n",
    "        mode = result['analysis_type']\n",
    "        length = len(result['analysis'])\n",
    "        tokens = result['metadata'].get('tokens_used', {}).get('total_tokens', 'N/A')\n",
    "        time = result['metadata']['response_time']\n",
    "        \n",
    "        print(f\"{mode.capitalize():12} | {length:4d} chars | {tokens:>6} tokens | {time:5.2f}s\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Observations:\")\n",
    "    print(f\"â€¢ Mode 'quick': RÃ©ponses concises et rapides\")\n",
    "    print(f\"â€¢ Mode 'detailed': Analyse approfondie et structurÃ©e\")\n",
    "    print(f\"â€¢ Mode 'educational': AdaptÃ© Ã  l'enseignement avec questions\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Aucune analyse rÃ©ussie - vÃ©rifiez votre configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5044e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:01:20.436304Z",
     "iopub.status.busy": "2026-02-18T09:01:20.436084Z",
     "iopub.status.idle": "2026-02-18T09:01:46.611063Z",
     "shell.execute_reply": "2026-02-18T09:01:46.610633Z"
    },
    "papermill": {
     "duration": 26.179153,
     "end_time": "2026-02-18T09:01:46.611926",
     "exception": false,
     "start_time": "2026-02-18T09:01:20.432773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â™¿ GÃ‰NÃ‰RATION DE DESCRIPTIONS D'ACCESSIBILITÃ‰\n",
      "=======================================================\n",
      "\n",
      "ğŸ” Analyse en cours...\n",
      "ğŸ“ Type: detailed\n",
      "ğŸ–¼ï¸  Source: https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Description d'accessibilitÃ© gÃ©nÃ©rÃ©e\n",
      "ğŸ“ Alt text (110 caractÃ¨res) :\n",
      "   \"Vue sur la Gran VÃ­a Ã  Madrid au coucher du soleil, avec le bÃ¢timent Metropolis et la circulation sur lâ€™avenue.\"\n",
      "âœ… Longueur optimale (110/125 chars)\n"
     ]
    }
   ],
   "source": [
    "# GÃ©nÃ©ration de descriptions d'accessibilitÃ© (Alt text)\n",
    "if generate_alt_text and analysis_results:\n",
    "    print(\"\\nâ™¿ GÃ‰NÃ‰RATION DE DESCRIPTIONS D'ACCESSIBILITÃ‰\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Prompt spÃ©cialisÃ© pour l'accessibilitÃ©\n",
    "    accessibility_prompt = f\"\"\"GÃ©nÃ¨re une description d'accessibilitÃ© (alt text) pour cette image en {language}.\n",
    "    \n",
    "CritÃ¨res :\n",
    "- Maximum 125 caractÃ¨res\n",
    "- Description factuelle et objective\n",
    "- Inclut les Ã©lÃ©ments essentiels pour la comprÃ©hension\n",
    "- Ã‰vite les interprÃ©tations subjectives\n",
    "- AdaptÃ© aux lecteurs d'Ã©cran\n",
    "\n",
    "Format : Fournis UNIQUEMENT la description, sans formatage supplÃ©mentaire.\"\"\"\n",
    "    \n",
    "    # GÃ©nÃ©ration de l'alt text\n",
    "    alt_result = analyze_image_with_gpt5(\n",
    "        image_source=selected_example['url'],\n",
    "        prompt=accessibility_prompt\n",
    "    )\n",
    "    \n",
    "    if alt_result['success']:\n",
    "        alt_text = alt_result['analysis'].strip()\n",
    "        \n",
    "        print(f\"âœ… Description d'accessibilitÃ© gÃ©nÃ©rÃ©e\")\n",
    "        print(f\"ğŸ“ Alt text ({len(alt_text)} caractÃ¨res) :\")\n",
    "        print(f'   \"{alt_text}\"')\n",
    "        \n",
    "        if len(alt_text) > 125:\n",
    "            print(f\"âš ï¸  Longueur dÃ©passÃ©e ({len(alt_text)}/125 chars) - considÃ©rez une version plus courte\")\n",
    "        else:\n",
    "            print(f\"âœ… Longueur optimale ({len(alt_text)}/125 chars)\")\n",
    "    else:\n",
    "        print(f\"âŒ Erreur gÃ©nÃ©ration alt text: {alt_result['error']}\")\n",
    "else:\n",
    "    print(f\"\\nâ­ï¸  GÃ©nÃ©ration alt text dÃ©sactivÃ©e ou pas d'analyse disponible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819fc808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:01:46.618669Z",
     "iopub.status.busy": "2026-02-18T09:01:46.618336Z",
     "iopub.status.idle": "2026-02-18T09:01:46.624838Z",
     "shell.execute_reply": "2026-02-18T09:01:46.624321Z"
    },
    "papermill": {
     "duration": 0.010409,
     "end_time": "2026-02-18T09:01:46.625659",
     "exception": false,
     "start_time": "2026-02-18T09:01:46.615250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¤– Mode batch - Interface interactive dÃ©sactivÃ©e\n",
      "ğŸ’¡ Pour mode interactif: notebook_mode = 'interactive'\n"
     ]
    }
   ],
   "source": [
    "# Mode interactif - Analyse d'image personnalisÃ©e\n",
    "if notebook_mode == \"interactive\" and not skip_widgets:\n",
    "    print(\"\\nğŸ¨ MODE INTERACTIF - ANALYSE PERSONNALISÃ‰E\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Analysez votre propre image avec GPT-5:\")\n",
    "    print(\"Formats supportÃ©s: URL https:// ou chemin local\")\n",
    "    print(\"(Laissez vide pour passer Ã  la suite)\")\n",
    "    \n",
    "    try:\n",
    "        user_image = input(\"\\nğŸ–¼ï¸  URL ou chemin de votre image: \").strip()\n",
    "\n",
    "        if user_image:\n",
    "            # ParamÃ¨tres d'analyse personnalisÃ©s\n",
    "            print(\"\\nâš™ï¸  ParamÃ¨tres d'analyse (appuyez EntrÃ©e pour dÃ©faut):\")\n",
    "            custom_mode = input(f\"ğŸ“Š Mode [{analysis_mode}]: \").strip() or analysis_mode\n",
    "            custom_prompt = input(\"ğŸ“ Prompt personnalisÃ© (optionnel): \").strip()\n",
    "\n",
    "            print(f\"\\nğŸ” Analyse de votre image en cours...\")\n",
    "\n",
    "            # Analyse personnalisÃ©e\n",
    "            if custom_prompt:\n",
    "                user_result = analyze_image_with_gpt5(\n",
    "                    image_source=user_image,\n",
    "                    prompt=custom_prompt\n",
    "                )\n",
    "            else:\n",
    "                user_result = analyze_image_with_gpt5(\n",
    "                    image_source=user_image,\n",
    "                    analysis_type=custom_mode\n",
    "                )\n",
    "\n",
    "            if user_result['success']:\n",
    "                print(f\"\\nğŸ‰ Analyse rÃ©ussie!\")\n",
    "                print(f\"â±ï¸  Temps: {user_result['metadata']['response_time']:.2f}s\")\n",
    "                print(f\"\\nğŸ“ **Analyse GPT-5:**\")\n",
    "                print(user_result['analysis'])\n",
    "\n",
    "                # Option de sauvegarde\n",
    "                if export_analysis:\n",
    "                    try:\n",
    "                        save_choice = input(\"\\nğŸ’¾ Sauvegarder cette analyse ? (o/N): \").strip().lower()\n",
    "                        if save_choice in ['o', 'oui', 'y', 'yes']:\n",
    "                            output_dir = GENAI_ROOT / 'outputs' / 'gpt5_analysis'\n",
    "                            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                            analysis_file = output_dir / f\"gpt5_analysis_{timestamp}.json\"\n",
    "\n",
    "                            with open(analysis_file, 'w', encoding='utf-8') as f:\n",
    "                                json.dump(user_result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "                            print(f\"ğŸ’¾ Analyse sauvegardÃ©e: {analysis_file}\")\n",
    "                    except Exception as save_err:\n",
    "                        if \"StdinNotImplemented\" in type(save_err).__name__:\n",
    "                            print(\"\\nâ­ï¸  Sauvegarde automatique ignorÃ©e en mode batch\")\n",
    "                        else:\n",
    "                            raise\n",
    "            else:\n",
    "                print(f\"\\nâŒ Erreur: {user_result['error']}\")\n",
    "                print(f\"ğŸ” Source: {user_result['image_source']}\")\n",
    "        else:\n",
    "            print(\"\\nâ­ï¸  Mode interactif ignorÃ©\")\n",
    "\n",
    "    except (KeyboardInterrupt, EOFError) as e:\n",
    "        # Gestion interruption normale\n",
    "        print(f\"\\nâ­ï¸  Mode interactif interrompu ({type(e).__name__})\")\n",
    "    except Exception as e:\n",
    "        # Gestion des erreurs d'input en mode non-interactif (Papermill, etc.)\n",
    "        error_type = type(e).__name__\n",
    "        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n",
    "            print(\"\\nâ­ï¸  Mode interactif non disponible (exÃ©cution automatisÃ©e)\")\n",
    "        else:\n",
    "            # Autre erreur inattendue - afficher pour dÃ©bogage\n",
    "            print(f\"\\nâš ï¸  Erreur inattendue: {error_type} - {str(e)[:100]}\")\n",
    "            print(\"â­ï¸  Passage Ã  la suite du notebook\")\n",
    "else:\n",
    "    print(\"\\nğŸ¤– Mode batch - Interface interactive dÃ©sactivÃ©e\")\n",
    "    print(\"ğŸ’¡ Pour mode interactif: notebook_mode = 'interactive'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ae9272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:01:46.631161Z",
     "iopub.status.busy": "2026-02-18T09:01:46.630943Z",
     "iopub.status.idle": "2026-02-18T09:01:46.636415Z",
     "shell.execute_reply": "2026-02-18T09:01:46.635927Z"
    },
    "papermill": {
     "duration": 0.009263,
     "end_time": "2026-02-18T09:01:46.637254",
     "exception": false,
     "start_time": "2026-02-18T09:01:46.627991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ CAS D'USAGE PÃ‰DAGOGIQUES GPT-5\n",
      "=============================================\n",
      "\n",
      "ğŸ“š **Histoire**\n",
      "   ğŸ“‹ Analyse de documents historiques, Å“uvres d'art, monuments\n",
      "   ğŸ’¡ Exemple: Analyser une fresque renaissance pour comprendre le contexte social\n",
      "   ğŸ“ Template de prompt disponible\n",
      "\n",
      "ğŸ“š **Sciences**\n",
      "   ğŸ“‹ Analyse d'expÃ©riences, schÃ©mas scientifiques, phÃ©nomÃ¨nes naturels\n",
      "   ğŸ’¡ Exemple: Expliquer un diagramme de cellule ou une rÃ©action chimique\n",
      "   ğŸ“ Template de prompt disponible\n",
      "\n",
      "ğŸ“š **GÃ©ographie**\n",
      "   ğŸ“‹ Ã‰tude de paysages, cartes, phÃ©nomÃ¨nes gÃ©ologiques\n",
      "   ğŸ’¡ Exemple: Analyser une photo satellite ou un paysage gÃ©ographique\n",
      "   ğŸ“ Template de prompt disponible\n",
      "\n",
      "ğŸ“š **Art et Culture**\n",
      "   ğŸ“‹ Critique artistique, analyse stylistique, histoire de l'art\n",
      "   ğŸ’¡ Exemple: Comprendre les techniques d'un tableau impressionniste\n",
      "   ğŸ“ Template de prompt disponible\n",
      "\n",
      "ğŸ“š **MÃ©decine**\n",
      "   ğŸ“‹ Analyse d'imagerie mÃ©dicale, anatomie, cas cliniques\n",
      "   ğŸ’¡ Exemple: Expliquer une radiographie ou un schÃ©ma anatomique\n",
      "   ğŸ“ Template de prompt disponible\n",
      "\n",
      "ğŸ¯ Avantages GPT-5 pour l'Ã©ducation:\n",
      "â€¢ **Multimodal** : Analyse texte + image simultanÃ©e\n",
      "â€¢ **Contextuel** : Comprend le niveau Ã©ducatif\n",
      "â€¢ **Adaptable** : Ajuste le vocabulaire selon l'audience\n",
      "â€¢ **Interactif** : Permet les questions de suivi\n",
      "â€¢ **PrÃ©cis** : Analyse dÃ©taillÃ©e et factuelle\n",
      "\n",
      "ğŸ“ Exemple de workflow pÃ©dagogique:\n",
      "1. SÃ©lection d'image pertinente au cours\n",
      "2. Analyse GPT-5 avec prompt Ã©ducatif\n",
      "3. GÃ©nÃ©ration de questions pour les Ã©tudiants\n",
      "4. Discussion interactive basÃ©e sur l'analyse\n",
      "5. Ã‰valuation de la comprÃ©hension\n"
     ]
    }
   ],
   "source": [
    "# Cas d'usage pÃ©dagogiques avec GPT-5\n",
    "print(\"\\nğŸ“ CAS D'USAGE PÃ‰DAGOGIQUES GPT-5\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Exemples d'applications Ã©ducatives\n",
    "educational_use_cases = {\n",
    "    \"Histoire\": {\n",
    "        \"description\": \"Analyse de documents historiques, Å“uvres d'art, monuments\",\n",
    "        \"exemple\": \"Analyser une fresque renaissance pour comprendre le contexte social\",\n",
    "        \"prompt_template\": \"Analyse cette image historique pour des Ã©tudiants en histoire. Explique le contexte historique, les Ã©lÃ©ments symboliques, et l'importance culturelle.\"\n",
    "    },\n",
    "    \n",
    "    \"Sciences\": {\n",
    "        \"description\": \"Analyse d'expÃ©riences, schÃ©mas scientifiques, phÃ©nomÃ¨nes naturels\",\n",
    "        \"exemple\": \"Expliquer un diagramme de cellule ou une rÃ©action chimique\",\n",
    "        \"prompt_template\": \"En tant qu'enseignant de sciences, explique cette image scientifique. Identifie les Ã©lÃ©ments techniques et leur fonctionnement.\"\n",
    "    },\n",
    "    \n",
    "    \"GÃ©ographie\": {\n",
    "        \"description\": \"Ã‰tude de paysages, cartes, phÃ©nomÃ¨nes gÃ©ologiques\",\n",
    "        \"exemple\": \"Analyser une photo satellite ou un paysage gÃ©ographique\",\n",
    "        \"prompt_template\": \"Analyse cette image gÃ©ographique pour des Ã©tudiants. Explique les formations gÃ©ologiques, le climat, et l'impact humain visible.\"\n",
    "    },\n",
    "    \n",
    "    \"Art et Culture\": {\n",
    "        \"description\": \"Critique artistique, analyse stylistique, histoire de l'art\",\n",
    "        \"exemple\": \"Comprendre les techniques d'un tableau impressionniste\",\n",
    "        \"prompt_template\": \"Fais une analyse artistique de cette Å“uvre pour des Ã©tudiants en art. Inclus style, techniques, et signification culturelle.\"\n",
    "    },\n",
    "    \n",
    "    \"MÃ©decine\": {\n",
    "        \"description\": \"Analyse d'imagerie mÃ©dicale, anatomie, cas cliniques\",\n",
    "        \"exemple\": \"Expliquer une radiographie ou un schÃ©ma anatomique\",\n",
    "        \"prompt_template\": \"Analyse cette image mÃ©dicale pour des Ã©tudiants en mÃ©decine. Explique l'anatomie visible et les points d'intÃ©rÃªt clinique.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Affichage des cas d'usage\n",
    "for domain, info in educational_use_cases.items():\n",
    "    print(f\"\\nğŸ“š **{domain}**\")\n",
    "    print(f\"   ğŸ“‹ {info['description']}\")\n",
    "    print(f\"   ğŸ’¡ Exemple: {info['exemple']}\")\n",
    "    print(f\"   ğŸ“ Template de prompt disponible\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Avantages GPT-5 pour l'Ã©ducation:\")\n",
    "print(f\"â€¢ **Multimodal** : Analyse texte + image simultanÃ©e\")\n",
    "print(f\"â€¢ **Contextuel** : Comprend le niveau Ã©ducatif\")\n",
    "print(f\"â€¢ **Adaptable** : Ajuste le vocabulaire selon l'audience\")\n",
    "print(f\"â€¢ **Interactif** : Permet les questions de suivi\")\n",
    "print(f\"â€¢ **PrÃ©cis** : Analyse dÃ©taillÃ©e et factuelle\")\n",
    "\n",
    "print(f\"\\nğŸ“ Exemple de workflow pÃ©dagogique:\")\n",
    "print(f\"1. SÃ©lection d'image pertinente au cours\")\n",
    "print(f\"2. Analyse GPT-5 avec prompt Ã©ducatif\")\n",
    "print(f\"3. GÃ©nÃ©ration de questions pour les Ã©tudiants\")\n",
    "print(f\"4. Discussion interactive basÃ©e sur l'analyse\")\n",
    "print(f\"5. Ã‰valuation de la comprÃ©hension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba3abd",
   "metadata": {
    "papermill": {
     "duration": 0.002141,
     "end_time": "2026-02-18T09:01:46.641803",
     "exception": false,
     "start_time": "2026-02-18T09:01:46.639662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ğŸ¯ RÃ©sumÃ© et Bonnes Pratiques\n",
    "\n",
    "### âœ… Ce que vous avez appris\n",
    "\n",
    "- [ ] **Configuration GPT-5** : OpenRouter API et paramÃ¨tres optimaux\n",
    "- [ ] **Analyse multimodale** : Combinaison texte + image\n",
    "- [ ] **Prompts Ã©ducatifs** : Adaptation au niveau d'enseignement\n",
    "- [ ] **Cas d'usage pÃ©dagogiques** : Applications concrÃ¨tes par domaine\n",
    "- [ ] **Optimisation** : ParamÃ¨tres de qualitÃ© et performance\n",
    "\n",
    "### ğŸš€ Prochaines Ã©tapes\n",
    "\n",
    "1. **ExpÃ©rimentez** avec vos propres images Ã©ducatives\n",
    "2. **Testez** diffÃ©rents niveaux d'analyse selon votre public\n",
    "3. **IntÃ©grez** GPT-5 dans vos workflows pÃ©dagogiques\n",
    "4. **Combinez** avec DALL-E 3 pour gÃ©nÃ©ration + analyse\n",
    "5. **Explorez** les notebooks avancÃ©s (Module 02)\n",
    "\n",
    "### ğŸ’¡ Conseils pour l'utilisation\n",
    "\n",
    "**âœ… Bonnes pratiques:**\n",
    "- Utilisez des images de haute qualitÃ©\n",
    "- Adaptez le prompt au niveau Ã©ducatif\n",
    "- Combinez analyse visuelle et contextuelle\n",
    "- GÃ©nÃ©rez des questions pÃ©dagogiques\n",
    "- Sauvegardez les analyses rÃ©ussies\n",
    "\n",
    "**âŒ Ã‰vitez:**\n",
    "- Images trop petites ou de mauvaise qualitÃ©\n",
    "- Prompts vagues ou gÃ©nÃ©riques\n",
    "- Oublier le contexte Ã©ducatif\n",
    "- Ignorer les limitations du modÃ¨le\n",
    "- Ne pas vÃ©rifier la factualitÃ©\n",
    "\n",
    "### ğŸ”— Ressources complÃ©mentaires\n",
    "\n",
    "- **Documentation OpenRouter** : [openrouter.ai](https://openrouter.ai)\n",
    "- **Guide GPT-5** : CapacitÃ©s multimodales\n",
    "- **Templates Ã©ducatifs** : `docs/genai-phase2-templates.md`\n",
    "- **Standards CoursIA** : `docs/genai-images-development-standards.md`"
   ]
  }
 ],
 "metadata": {
  "genai": {
   "dependencies": [
    "openai",
    "requests",
    "pillow",
    "matplotlib",
    "base64"
   ],
   "difficulty": "beginner",
   "enabled": true,
   "estimated_duration_minutes": 30,
   "learning_outcomes": [
    "Utiliser GPT-5 pour analyse et description d'images",
    "MaÃ®triser les conversations multimodales",
    "Comprendre les capacitÃ©s visuelles de GPT-5",
    "IntÃ©grer GPT-5 dans workflows pÃ©dagogiques",
    "Optimiser les prompts pour l'analyse visuelle"
   ],
   "level": "foundation",
   "module": "01-Images-Foundation"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 156.059152,
   "end_time": "2026-02-18T09:01:46.991528",
   "environment_variables": {},
   "exception": null,
   "input_path": "01-2-GPT-5-Image-Generation.ipynb",
   "output_path": "01-2-GPT-5-Image-Generation_output.ipynb",
   "parameters": {
    "notebook_mode": "batch"
   },
   "start_time": "2026-02-18T08:59:10.932376",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}