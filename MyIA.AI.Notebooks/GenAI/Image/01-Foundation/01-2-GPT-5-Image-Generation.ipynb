{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ GPT-5 Multimodal - Analyse et G√©n√©ration d'Images\n",
    "\n",
    "**Module :** 01-Images-Foundation  \n",
    "**Niveau :** üü¢ D√©butant  \n",
    "**Technologies :** GPT-5, OpenRouter API, Vision AI  \n",
    "**Dur√©e estim√©e :** 30 minutes  \n",
    "\n",
    "## üéØ Objectifs d'Apprentissage\n",
    "\n",
    "- [ ] Configurer GPT-5 via OpenRouter pour analyse d'images\n",
    "- [ ] Ma√Ætriser les conversations multimodales texte + image\n",
    "- [ ] Analyser et d√©crire des images avec pr√©cision\n",
    "- [ ] Cr√©er des prompts optimis√©s pour l'analyse visuelle\n",
    "- [ ] Int√©grer GPT-5 dans des cas d'usage p√©dagogiques\n",
    "\n",
    "## üìö Pr√©requis\n",
    "\n",
    "- Environment Setup (module 00) compl√©t√©\n",
    "- Cl√© API OpenRouter configur√©e\n",
    "- Connaissances de base en IA multimodale\n",
    "\n",
    "## ‚ö° Capacit√©s GPT-5\n",
    "\n",
    "- **Vision avanc√©e** : Analyse d√©taill√©e d'images\n",
    "- **Multimodal** : Conversation texte + image simultan√©e\n",
    "- **Contexte √©tendu** : Jusqu'√† 200K tokens\n",
    "- **Raisonnement** : Analyse complexe et d√©ductive\n",
    "- **√âducatif** : Parfait pour l'enseignement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Param√®tres Papermill - JAMAIS modifier ce commentaire\n",
    "\n",
    "# Configuration conversation\n",
    "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
    "skip_widgets = False               # True pour mode batch MCP\n",
    "debug_level = \"INFO\"               \n",
    "\n",
    "# Param√®tres GPT-5\n",
    "model_name = \"openai/gpt-5\"        # Mod√®le via OpenRouter\n",
    "max_tokens = 4000                  # Tokens de r√©ponse max\n",
    "temperature = 0.7                  # Cr√©ativit√© (0.0-1.0)\n",
    "top_p = 0.9                        # Diversit√© sampling\n",
    "\n",
    "# Configuration analyse\n",
    "analysis_mode = \"detailed\"         # \"quick\", \"detailed\", \"educational\"\n",
    "include_technical_details = True   # D√©tails techniques images\n",
    "export_analysis = True             # Sauvegarder analyses\n",
    "generate_alt_text = True           # G√©n√©rer descriptions accessibilit√©\n",
    "\n",
    "# Param√®tres p√©dagogiques\n",
    "educational_level = \"university\"   # \"elementary\", \"secondary\", \"university\"\n",
    "language = \"fran√ßais\"              # Langue des explications\n",
    "include_examples = True            # Inclure exemples pratiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environnement et imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Import helpers GenAI\n",
    "GENAI_ROOT = Path.cwd()\n",
    "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
    "    GENAI_ROOT = GENAI_ROOT.parent\n",
    "\n",
    "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
    "if HELPERS_PATH.exists():\n",
    "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
    "    try:\n",
    "        from helpers.genai_helpers import setup_genai_logging, load_genai_config\n",
    "        print(\"‚úÖ Helpers GenAI import√©s\")\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  Helpers GenAI non disponibles - mode autonome\")\n",
    "\n",
    "# Configuration logging\n",
    "logging.basicConfig(level=getattr(logging, debug_level))\n",
    "logger = logging.getLogger('gpt5_multimodal')\n",
    "\n",
    "print(f\"ü§ñ GPT-5 Multimodal - Analyse et G√©n√©ration d'Images\")\n",
    "print(f\"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üîß Mode: {notebook_mode}, Analyse: {analysis_mode}, Niveau: {educational_level}\")\n",
    "print(f\"üåç Langue: {language}, Max tokens: {max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration API OpenRouter pour GPT-5\n",
    "print(\"\\nüîë CONFIGURATION GPT-5 MULTIMODAL\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Chargement explicite du .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Recherche du .env dans les parents\n",
    "current_path = Path.cwd()\n",
    "found_env = False\n",
    "for _ in range(4):  # Remonter jusqu'√† 4 niveaux\n",
    "    env_path = current_path / '.env'\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"‚úÖ Fichier .env charg√© depuis: {env_path}\")\n",
    "        found_env = True\n",
    "        break\n",
    "    current_path = current_path.parent\n",
    "\n",
    "if not found_env:\n",
    "    print(\"‚ö†Ô∏è  Aucun fichier .env trouv√© dans l'arborescence\")\n",
    "\n",
    "# V√©rification cl√© API\n",
    "openrouter_key = os.getenv('OPENROUTER_API_KEY')\n",
    "if not openrouter_key:\n",
    "    # Fallback pour validation structurelle sans cl√©\n",
    "    if notebook_mode == \"batch\" and not analyze_images:\n",
    "        print(\"‚ö†Ô∏è  Mode batch sans analyse : Cl√© API ignor√©e\")\n",
    "        openrouter_key = \"dummy_key_for_validation\"\n",
    "    else:\n",
    "        raise ValueError(\"‚ùå OPENROUTER_API_KEY manquante dans .env\")\n",
    "\n",
    "print(f\"‚úÖ Cl√© API OpenRouter configur√©e\")\n",
    "\n",
    "# Configuration headers et endpoint\n",
    "api_base_url = \"https://openrouter.ai/api/v1\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openrouter_key}\",\n",
    "    \"HTTP-Referer\": \"https://coursia.myia.io\",\n",
    "    \"X-Title\": \"CoursIA GenAI Images - GPT-5 Multimodal\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Test connexion et v√©rification mod√®le GPT-5\n",
    "if openrouter_key != \"dummy_key_for_validation\":\n",
    "    try:\n",
    "        response = requests.get(f\"{api_base_url}/models\", headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            models_data = response.json()\n",
    "            gpt5_models = [m for m in models_data.get('data', []) if 'gpt-5' in m.get('id', '').lower()]\n",
    "            \n",
    "            if gpt5_models:\n",
    "                print(f\"‚úÖ Connexion r√©ussie - {len(gpt5_models)} mod√®les GPT-5 disponibles\")\n",
    "                \n",
    "                for model in gpt5_models:\n",
    "                    print(f\"  üß† {model['id']} - Contexte: {model.get('context_length', 'N/A')} tokens\")\n",
    "                    if 'vision' in model.get('capabilities', []):\n",
    "                        print(f\"     üëÅÔ∏è  Capacit√©s vision activ√©es\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Aucun mod√®le GPT-5 d√©tect√© - v√©rifiez votre acc√®s\")\n",
    "                print(f\"üîç Mod√®les disponibles avec 'gpt' : {len([m for m in models_data.get('data', []) if 'gpt' in m.get('id', '').lower()])}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Connexion API: HTTP {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur connexion: {str(e)[:100]}...\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Test connexion API saut√© (dummy key)\")\n",
    "    \n",
    "print(f\"\\nüéØ Mod√®le s√©lectionn√©: {model_name}\")\n",
    "print(f\"‚öôÔ∏è  Param√®tres: Temperature={temperature}, Max tokens={max_tokens}\")\n",
    "print(f\"üìä Mode d'analyse: {analysis_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions utilitaires pour traitement d'images\n",
    "def encode_image_base64(image_path: Union[str, Path]) -> str:\n",
    "    \"\"\"\n",
    "    Encode une image locale en base64 pour GPT-5.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Chemin vers l'image locale\n",
    "        \n",
    "    Returns:\n",
    "        String base64 de l'image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Erreur lecture image {image_path}: {str(e)}\")\n",
    "\n",
    "def download_and_encode_image(image_url: str) -> str:\n",
    "    \"\"\"\n",
    "    T√©l√©charge et encode une image depuis URL.\n",
    "    \n",
    "    Args:\n",
    "        image_url: URL de l'image\n",
    "        \n",
    "    Returns:\n",
    "        String base64 de l'image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(image_url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return base64.b64encode(response.content).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Erreur t√©l√©chargement {image_url}: {str(e)}\")\n",
    "\n",
    "def prepare_image_for_gpt5(image_source: Union[str, Path]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Pr√©pare une image pour GPT-5 (locale ou URL).\n",
    "    \n",
    "    Args:\n",
    "        image_source: Chemin local ou URL de l'image\n",
    "        \n",
    "    Returns:\n",
    "        Dict avec format attendu par GPT-5\n",
    "    \"\"\"\n",
    "    if isinstance(image_source, (str, Path)):\n",
    "        str_source = str(image_source)\n",
    "        \n",
    "        # V√©rification URL\n",
    "        if str_source.startswith(('http://', 'https://')):\n",
    "            try:\n",
    "                # Pour les URLs, GPT-5 peut les traiter directement\n",
    "                return {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": str_source\n",
    "                    }\n",
    "                }\n",
    "            except:\n",
    "                # Fallback : t√©l√©charger et encoder\n",
    "                base64_image = download_and_encode_image(str_source)\n",
    "                return {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "        else:\n",
    "            # Image locale\n",
    "            if Path(str_source).exists():\n",
    "                base64_image = encode_image_base64(str_source)\n",
    "                return {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Image non trouv√©e: {str_source}\")\n",
    "    \n",
    "    raise ValueError(f\"Format d'image non support√©: {type(image_source)}\")\n",
    "\n",
    "print(\"‚úÖ Fonctions utilitaires images pr√™tes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction principale d'analyse d'image avec GPT-5\n",
    "def analyze_image_with_gpt5(image_source: Union[str, Path], \n",
    "                           prompt: str = None,\n",
    "                           analysis_type: str = \"detailed\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyse une image avec GPT-5 multimodal.\n",
    "    \n",
    "    Args:\n",
    "        image_source: Chemin local ou URL de l'image\n",
    "        prompt: Prompt personnalis√© (optionnel)\n",
    "        analysis_type: Type d'analyse (\"quick\", \"detailed\", \"educational\")\n",
    "        \n",
    "    Returns:\n",
    "        Dict avec analyse compl√®te\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prompts pr√©d√©finis selon le type d'analyse\n",
    "    analysis_prompts = {\n",
    "        \"quick\": f\"D√©cris bri√®vement cette image en {language}. Sois concis mais pr√©cis.\",\n",
    "        \n",
    "        \"detailed\": f\"\"\"Analyse cette image en d√©tail en {language}. Inclus :\n",
    "        \n",
    "1. **Description g√©n√©rale** : Que voit-on dans l'image ?\n",
    "2. **√âl√©ments visuels** : Couleurs, composition, style artistique\n",
    "3. **Contexte** : √âpoque, lieu, situation probable\n",
    "4. **D√©tails techniques** : Qualit√©, r√©solution apparente, type de photo/illustration\n",
    "5. **√âmotions/Atmosph√®re** : Quelle ambiance d√©gage l'image ?\n",
    "6. **Interpr√©tation** : Signification possible, message artistique\n",
    "\n",
    "Sois pr√©cis et p√©dagogique dans tes explications.\"\"\",\n",
    "        \n",
    "        \"educational\": f\"\"\"Tu es un professeur expert analysant cette image pour des √©tudiants de niveau {educational_level}. En {language}, fournis :\n",
    "\n",
    "üéØ **ANALYSE P√âDAGOGIQUE**\n",
    "\n",
    "**1. Description accessible**\n",
    "- Que montre cette image de fa√ßon simple et claire ?\n",
    "\n",
    "**2. √âl√©ments √† observer**\n",
    "- Quels d√©tails importants les √©tudiants doivent-ils remarquer ?\n",
    "- Techniques artistiques ou photographiques utilis√©es\n",
    "\n",
    "**3. Contexte √©ducatif**\n",
    "- Dans quel domaine d'√©tude cette image serait-elle utile ?\n",
    "- Quelles disciplines acad√©miques peuvent l'utiliser ?\n",
    "\n",
    "**4. Questions pour r√©flexion**\n",
    "- 3 questions que tu poserais aux √©tudiants sur cette image\n",
    "\n",
    "**5. Connexions interdisciplinaires**\n",
    "- Comment cette image se connecte-t-elle √† d'autres sujets ?\n",
    "\n",
    "Adapte ton vocabulaire au niveau {educational_level}.\"\"\"\n",
    "    }\n",
    "    \n",
    "    # S√©lection du prompt\n",
    "    if prompt is None:\n",
    "        prompt = analysis_prompts.get(analysis_type, analysis_prompts[\"detailed\"])\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nüîç Analyse en cours...\")\n",
    "        print(f\"üìù Type: {analysis_type}\")\n",
    "        print(f\"üñºÔ∏è  Source: {str(image_source)[:100]}{'...' if len(str(image_source)) > 100 else ''}\")\n",
    "        \n",
    "        # Pr√©paration de l'image\n",
    "        image_data = prepare_image_for_gpt5(image_source)\n",
    "        \n",
    "        # Construction du message multimodal\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    },\n",
    "                    image_data\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Payload de la requ√™te\n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"messages\": messages,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p\n",
    "        }\n",
    "        \n",
    "        # Requ√™te API\n",
    "        start_time = datetime.now()\n",
    "        response = requests.post(\n",
    "            f\"{api_base_url}/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=120\n",
    "        )\n",
    "        response_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            analysis_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "            \n",
    "            # M√©tadonn√©es de l'analyse\n",
    "            metadata = {\n",
    "                \"model\": model_name,\n",
    "                \"analysis_type\": analysis_type,\n",
    "                \"educational_level\": educational_level,\n",
    "                \"language\": language,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"response_time\": response_time,\n",
    "                \"tokens_used\": result.get(\"usage\", {}),\n",
    "                \"image_source\": str(image_source),\n",
    "                \"prompt_length\": len(prompt)\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"analysis\": analysis_text,\n",
    "                \"metadata\": metadata,\n",
    "                \"image_source\": image_source,\n",
    "                \"analysis_type\": analysis_type\n",
    "            }\n",
    "        else:\n",
    "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else {}\n",
    "            error_msg = error_data.get(\"error\", {}).get(\"message\", f\"HTTP {response.status_code}\")\n",
    "            \n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": error_msg,\n",
    "                \"image_source\": image_source,\n",
    "                \"status_code\": response.status_code\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"image_source\": image_source\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Fonction d'analyse GPT-5 pr√™te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples d'images pour d√©monstration\n",
    "print(\"\\nüñºÔ∏è  EXEMPLES D'ANALYSE GPT-5\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Images d'exemple (URLs publiques pour tests)\n",
    "example_images = [\n",
    "    {\n",
    "        \"title\": \"üèõÔ∏è Architecture Historique\",\n",
    "        \"url\": \"https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\",  # Colis√©e Rome\n",
    "        \"description\": \"Monument historique romain - id√©al pour analyse architecturale\",\n",
    "        \"category\": \"Histoire/Architecture\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üî¨ Science et Technologie\",\n",
    "        \"url\": \"https://images.unsplash.com/photo-1532094349884-543bc11b234d?w=800\",  # Laboratoire\n",
    "        \"description\": \"Environnement scientifique - parfait pour analyse technique\",\n",
    "        \"category\": \"Science/Technologie\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üé® Art et Culture\",\n",
    "        \"url\": \"https://images.unsplash.com/photo-1541961017774-22349e4a1262?w=800\",  # Peinture\n",
    "        \"description\": \"≈íuvre artistique - excellent pour analyse esth√©tique\",\n",
    "        \"category\": \"Art/Culture\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üåç Nature et Environnement\",\n",
    "        \"url\": \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800\",  # Paysage naturel\n",
    "        \"description\": \"Paysage naturel - parfait pour analyse g√©ographique\",\n",
    "        \"category\": \"G√©ographie/Environnement\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Affichage des exemples\n",
    "for i, example in enumerate(example_images, 1):\n",
    "    print(f\"\\n{i}. {example['title']}\")\n",
    "    print(f\"   üìÇ Cat√©gorie: {example['category']}\")\n",
    "    print(f\"   üìù {example['description']}\")\n",
    "    print(f\"   üîó URL: {example['url'][:60]}...\")\n",
    "\n",
    "print(f\"\\nüí° Conseils pour l'analyse avec GPT-5:\")\n",
    "print(f\"‚Ä¢ Utilisez des images de haute qualit√©\")\n",
    "print(f\"‚Ä¢ Posez des questions sp√©cifiques\")\n",
    "print(f\"‚Ä¢ Exploitez le contexte √©ducatif\")\n",
    "print(f\"‚Ä¢ Combinez analyse textuelle et visuelle\")\n",
    "print(f\"‚Ä¢ Adaptez le niveau de complexit√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse d'une image de d√©monstration\n",
    "print(\"\\nüöÄ ANALYSE DE D√âMONSTRATION - GPT-5\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# S√©lection d'une image pour la d√©monstration\n",
    "selected_example = example_images[0]  # Architecture historique\n",
    "print(f\"üéØ Analyse: {selected_example['title']}\")\n",
    "print(f\"üìÇ Cat√©gorie: {selected_example['category']}\")\n",
    "\n",
    "# Test de l'analyse avec les diff√©rents modes\n",
    "analysis_results = []\n",
    "\n",
    "for mode in ['quick', 'detailed', 'educational']:\n",
    "    print(f\"\\nüîç Mode d'analyse: {mode.upper()}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Analyse de l'image\n",
    "    result = analyze_image_with_gpt5(\n",
    "        image_source=selected_example['url'],\n",
    "        analysis_type=mode\n",
    "    )\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"‚úÖ Analyse {mode} r√©ussie\")\n",
    "        print(f\"‚è±Ô∏è  Temps: {result['metadata']['response_time']:.2f}s\")\n",
    "        print(f\"üî¢ Tokens: {result['metadata']['tokens_used']}\")\n",
    "        \n",
    "        # Affichage de l'analyse (tronqu√©e pour la d√©mo)\n",
    "        analysis_preview = result['analysis'][:300] + \"...\" if len(result['analysis']) > 300 else result['analysis']\n",
    "        print(f\"\\nüìù **Aper√ßu de l'analyse {mode}:**\")\n",
    "        print(analysis_preview)\n",
    "        \n",
    "        analysis_results.append(result)\n",
    "    else:\n",
    "        print(f\"‚ùå √âchec analyse {mode}: {result['error']}\")\n",
    "    \n",
    "    print()  # S√©paration\n",
    "\n",
    "# Comparaison des r√©sultats\n",
    "if analysis_results:\n",
    "    print(f\"\\nüìä COMPARAISON DES MODES D'ANALYSE\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    for result in analysis_results:\n",
    "        mode = result['analysis_type']\n",
    "        length = len(result['analysis'])\n",
    "        tokens = result['metadata'].get('tokens_used', {}).get('total_tokens', 'N/A')\n",
    "        time = result['metadata']['response_time']\n",
    "        \n",
    "        print(f\"{mode.capitalize():12} | {length:4d} chars | {tokens:>6} tokens | {time:5.2f}s\")\n",
    "    \n",
    "    print(f\"\\nüí° Observations:\")\n",
    "    print(f\"‚Ä¢ Mode 'quick': R√©ponses concises et rapides\")\n",
    "    print(f\"‚Ä¢ Mode 'detailed': Analyse approfondie et structur√©e\")\n",
    "    print(f\"‚Ä¢ Mode 'educational': Adapt√© √† l'enseignement avec questions\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Aucune analyse r√©ussie - v√©rifiez votre configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©ration de descriptions d'accessibilit√© (Alt text)\n",
    "if generate_alt_text and analysis_results:\n",
    "    print(\"\\n‚ôø G√âN√âRATION DE DESCRIPTIONS D'ACCESSIBILIT√â\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Prompt sp√©cialis√© pour l'accessibilit√©\n",
    "    accessibility_prompt = f\"\"\"G√©n√®re une description d'accessibilit√© (alt text) pour cette image en {language}.\n",
    "    \n",
    "Crit√®res :\n",
    "- Maximum 125 caract√®res\n",
    "- Description factuelle et objective\n",
    "- Inclut les √©l√©ments essentiels pour la compr√©hension\n",
    "- √âvite les interpr√©tations subjectives\n",
    "- Adapt√© aux lecteurs d'√©cran\n",
    "\n",
    "Format : Fournis UNIQUEMENT la description, sans formatage suppl√©mentaire.\"\"\"\n",
    "    \n",
    "    # G√©n√©ration de l'alt text\n",
    "    alt_result = analyze_image_with_gpt5(\n",
    "        image_source=selected_example['url'],\n",
    "        prompt=accessibility_prompt\n",
    "    )\n",
    "    \n",
    "    if alt_result['success']:\n",
    "        alt_text = alt_result['analysis'].strip()\n",
    "        \n",
    "        print(f\"‚úÖ Description d'accessibilit√© g√©n√©r√©e\")\n",
    "        print(f\"üìù Alt text ({len(alt_text)} caract√®res) :\")\n",
    "        print(f'   \"{alt_text}\"')\n",
    "        \n",
    "        if len(alt_text) > 125:\n",
    "            print(f\"‚ö†Ô∏è  Longueur d√©pass√©e ({len(alt_text)}/125 chars) - consid√©rez une version plus courte\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Longueur optimale ({len(alt_text)}/125 chars)\")\n",
    "    else:\n",
    "        print(f\"‚ùå Erreur g√©n√©ration alt text: {alt_result['error']}\")\n",
    "else:\n",
    "    print(f\"\\n‚è≠Ô∏è  G√©n√©ration alt text d√©sactiv√©e ou pas d'analyse disponible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode interactif - Analyse d'image personnalis√©e\n",
    "if notebook_mode == \"interactive\" and not skip_widgets:\n",
    "    print(\"\\nüé® MODE INTERACTIF - ANALYSE PERSONNALIS√âE\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    print(\"\\nüí° Analysez votre propre image avec GPT-5:\")\n",
    "    print(\"Formats support√©s: URL https:// ou chemin local\")\n",
    "    print(\"(Laissez vide pour passer √† la suite)\")\n",
    "    \n",
    "    try:\n",
    "        user_image = input(\"\\nüñºÔ∏è  URL ou chemin de votre image: \").strip()\n",
    "        \n",
    "        if user_image:\n",
    "            # Param√®tres d'analyse personnalis√©s\n",
    "            print(\"\\n‚öôÔ∏è  Param√®tres d'analyse (appuyez Entr√©e pour d√©faut):\")\n",
    "            custom_mode = input(f\"üìä Mode [{analysis_mode}]: \").strip() or analysis_mode\n",
    "            custom_prompt = input(\"üìù Prompt personnalis√© (optionnel): \").strip()\n",
    "            \n",
    "            print(f\"\\nüîç Analyse de votre image en cours...\")\n",
    "            \n",
    "            # Analyse personnalis√©e\n",
    "            if custom_prompt:\n",
    "                user_result = analyze_image_with_gpt5(\n",
    "                    image_source=user_image,\n",
    "                    prompt=custom_prompt\n",
    "                )\n",
    "            else:\n",
    "                user_result = analyze_image_with_gpt5(\n",
    "                    image_source=user_image,\n",
    "                    analysis_type=custom_mode\n",
    "                )\n",
    "            \n",
    "            if user_result['success']:\n",
    "                print(f\"\\nüéâ Analyse r√©ussie!\")\n",
    "                print(f\"‚è±Ô∏è  Temps: {user_result['metadata']['response_time']:.2f}s\")\n",
    "                print(f\"\\nüìù **Analyse GPT-5:**\")\n",
    "                print(user_result['analysis'])\n",
    "                \n",
    "                # Option de sauvegarde\n",
    "                if export_analysis:\n",
    "                    save_choice = input(\"\\nüíæ Sauvegarder cette analyse ? (o/N): \").strip().lower()\n",
    "                    if save_choice in ['o', 'oui', 'y', 'yes']:\n",
    "                        output_dir = GENAI_ROOT / 'outputs' / 'gpt5_analysis'\n",
    "                        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        \n",
    "                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                        analysis_file = output_dir / f\"gpt5_analysis_{timestamp}.json\"\n",
    "                        \n",
    "                        with open(analysis_file, 'w', encoding='utf-8') as f:\n",
    "                            json.dump(user_result, f, indent=2, ensure_ascii=False)\n",
    "                        \n",
    "                        print(f\"üíæ Analyse sauvegard√©e: {analysis_file}\")\n",
    "            else:\n",
    "                print(f\"\\n‚ùå Erreur: {user_result['error']}\")\n",
    "                print(f\"üîç Source: {user_result['image_source']}\")\n",
    "        else:\n",
    "            print(\"\\n‚è≠Ô∏è  Mode interactif ignor√©\")\n",
    "            \n",
    "    except (KeyboardInterrupt, EOFError):\n",
    "        print(\"\\n‚è≠Ô∏è  Mode interactif interrompu\")\n",
    "else:\n",
    "    print(\"\\nü§ñ Mode batch - Interface interactive d√©sactiv√©e\")\n",
    "    print(\"üí° Pour mode interactif: notebook_mode = 'interactive'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cas d'usage p√©dagogiques avec GPT-5\n",
    "print(\"\\nüéì CAS D'USAGE P√âDAGOGIQUES GPT-5\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Exemples d'applications √©ducatives\n",
    "educational_use_cases = {\n",
    "    \"Histoire\": {\n",
    "        \"description\": \"Analyse de documents historiques, ≈ìuvres d'art, monuments\",\n",
    "        \"exemple\": \"Analyser une fresque renaissance pour comprendre le contexte social\",\n",
    "        \"prompt_template\": \"Analyse cette image historique pour des √©tudiants en histoire. Explique le contexte historique, les √©l√©ments symboliques, et l'importance culturelle.\"\n",
    "    },\n",
    "    \n",
    "    \"Sciences\": {\n",
    "        \"description\": \"Analyse d'exp√©riences, sch√©mas scientifiques, ph√©nom√®nes naturels\",\n",
    "        \"exemple\": \"Expliquer un diagramme de cellule ou une r√©action chimique\",\n",
    "        \"prompt_template\": \"En tant qu'enseignant de sciences, explique cette image scientifique. Identifie les √©l√©ments techniques et leur fonctionnement.\"\n",
    "    },\n",
    "    \n",
    "    \"G√©ographie\": {\n",
    "        \"description\": \"√âtude de paysages, cartes, ph√©nom√®nes g√©ologiques\",\n",
    "        \"exemple\": \"Analyser une photo satellite ou un paysage g√©ographique\",\n",
    "        \"prompt_template\": \"Analyse cette image g√©ographique pour des √©tudiants. Explique les formations g√©ologiques, le climat, et l'impact humain visible.\"\n",
    "    },\n",
    "    \n",
    "    \"Art et Culture\": {\n",
    "        \"description\": \"Critique artistique, analyse stylistique, histoire de l'art\",\n",
    "        \"exemple\": \"Comprendre les techniques d'un tableau impressionniste\",\n",
    "        \"prompt_template\": \"Fais une analyse artistique de cette ≈ìuvre pour des √©tudiants en art. Inclus style, techniques, et signification culturelle.\"\n",
    "    },\n",
    "    \n",
    "    \"M√©decine\": {\n",
    "        \"description\": \"Analyse d'imagerie m√©dicale, anatomie, cas cliniques\",\n",
    "        \"exemple\": \"Expliquer une radiographie ou un sch√©ma anatomique\",\n",
    "        \"prompt_template\": \"Analyse cette image m√©dicale pour des √©tudiants en m√©decine. Explique l'anatomie visible et les points d'int√©r√™t clinique.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Affichage des cas d'usage\n",
    "for domain, info in educational_use_cases.items():\n",
    "    print(f\"\\nüìö **{domain}**\")\n",
    "    print(f\"   üìã {info['description']}\")\n",
    "    print(f\"   üí° Exemple: {info['exemple']}\")\n",
    "    print(f\"   üìù Template de prompt disponible\")\n",
    "\n",
    "print(f\"\\nüéØ Avantages GPT-5 pour l'√©ducation:\")\n",
    "print(f\"‚Ä¢ **Multimodal** : Analyse texte + image simultan√©e\")\n",
    "print(f\"‚Ä¢ **Contextuel** : Comprend le niveau √©ducatif\")\n",
    "print(f\"‚Ä¢ **Adaptable** : Ajuste le vocabulaire selon l'audience\")\n",
    "print(f\"‚Ä¢ **Interactif** : Permet les questions de suivi\")\n",
    "print(f\"‚Ä¢ **Pr√©cis** : Analyse d√©taill√©e et factuelle\")\n",
    "\n",
    "print(f\"\\nüìù Exemple de workflow p√©dagogique:\")\n",
    "print(f\"1. S√©lection d'image pertinente au cours\")\n",
    "print(f\"2. Analyse GPT-5 avec prompt √©ducatif\")\n",
    "print(f\"3. G√©n√©ration de questions pour les √©tudiants\")\n",
    "print(f\"4. Discussion interactive bas√©e sur l'analyse\")\n",
    "print(f\"5. √âvaluation de la compr√©hension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ R√©sum√© et Bonnes Pratiques\n",
    "\n",
    "### ‚úÖ Ce que vous avez appris\n",
    "\n",
    "- [ ] **Configuration GPT-5** : OpenRouter API et param√®tres optimaux\n",
    "- [ ] **Analyse multimodale** : Combinaison texte + image\n",
    "- [ ] **Prompts √©ducatifs** : Adaptation au niveau d'enseignement\n",
    "- [ ] **Cas d'usage p√©dagogiques** : Applications concr√®tes par domaine\n",
    "- [ ] **Optimisation** : Param√®tres de qualit√© et performance\n",
    "\n",
    "### üöÄ Prochaines √©tapes\n",
    "\n",
    "1. **Exp√©rimentez** avec vos propres images √©ducatives\n",
    "2. **Testez** diff√©rents niveaux d'analyse selon votre public\n",
    "3. **Int√©grez** GPT-5 dans vos workflows p√©dagogiques\n",
    "4. **Combinez** avec DALL-E 3 pour g√©n√©ration + analyse\n",
    "5. **Explorez** les notebooks avanc√©s (Module 02)\n",
    "\n",
    "### üí° Conseils pour l'utilisation\n",
    "\n",
    "**‚úÖ Bonnes pratiques:**\n",
    "- Utilisez des images de haute qualit√©\n",
    "- Adaptez le prompt au niveau √©ducatif\n",
    "- Combinez analyse visuelle et contextuelle\n",
    "- G√©n√©rez des questions p√©dagogiques\n",
    "- Sauvegardez les analyses r√©ussies\n",
    "\n",
    "**‚ùå √âvitez:**\n",
    "- Images trop petites ou de mauvaise qualit√©\n",
    "- Prompts vagues ou g√©n√©riques\n",
    "- Oublier le contexte √©ducatif\n",
    "- Ignorer les limitations du mod√®le\n",
    "- Ne pas v√©rifier la factualit√©\n",
    "\n",
    "### üîó Ressources compl√©mentaires\n",
    "\n",
    "- **Documentation OpenRouter** : [openrouter.ai](https://openrouter.ai)\n",
    "- **Guide GPT-5** : Capacit√©s multimodales\n",
    "- **Templates √©ducatifs** : `docs/genai-phase2-templates.md`\n",
    "- **Standards CoursIA** : `docs/genai-images-development-standards.md`"
   ]
  }
 ],
 "metadata": {
  "genai": {
   "dependencies": [
    "openai",
    "requests",
    "pillow",
    "matplotlib",
    "base64"
   ],
   "difficulty": "beginner",
   "enabled": true,
   "estimated_duration_minutes": 30,
   "learning_outcomes": [
    "Utiliser GPT-5 pour analyse et description d'images",
    "Ma√Ætriser les conversations multimodales",
    "Comprendre les capacit√©s visuelles de GPT-5",
    "Int√©grer GPT-5 dans workflows p√©dagogiques",
    "Optimiser les prompts pour l'analyse visuelle"
   ],
   "level": "foundation",
   "module": "01-Images-Foundation"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
