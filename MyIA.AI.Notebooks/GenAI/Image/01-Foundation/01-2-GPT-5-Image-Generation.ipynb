{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udd16 GPT-5 Multimodal - Analyse et G\u00e9n\u00e9ration d'Images\n",
        "\n",
        "**Module :** 01-Images-Foundation  \n",
        "**Niveau :** \ud83d\udfe2 D\u00e9butant  \n",
        "**Technologies :** GPT-5, OpenRouter API, Vision AI  \n",
        "**Dur\u00e9e estim\u00e9e :** 30 minutes  \n",
        "\n",
        "## \ud83c\udfaf Objectifs d'Apprentissage\n",
        "\n",
        "- [ ] Configurer GPT-5 via OpenRouter pour analyse d'images\n",
        "- [ ] Ma\u00eetriser les conversations multimodales texte + image\n",
        "- [ ] Analyser et d\u00e9crire des images avec pr\u00e9cision\n",
        "- [ ] Cr\u00e9er des prompts optimis\u00e9s pour l'analyse visuelle\n",
        "- [ ] Int\u00e9grer GPT-5 dans des cas d'usage p\u00e9dagogiques\n",
        "\n",
        "## \ud83d\udcda Pr\u00e9requis\n",
        "\n",
        "- Environment Setup (module 00) compl\u00e9t\u00e9\n",
        "- Cl\u00e9 API OpenRouter configur\u00e9e\n",
        "- Connaissances de base en IA multimodale\n",
        "\n",
        "## \u26a1 Capacit\u00e9s GPT-5\n",
        "\n",
        "- **Vision avanc\u00e9e** : Analyse d\u00e9taill\u00e9e d'images\n",
        "- **Multimodal** : Conversation texte + image simultan\u00e9e\n",
        "- **Contexte \u00e9tendu** : Jusqu'\u00e0 200K tokens\n",
        "- **Raisonnement** : Analyse complexe et d\u00e9ductive\n",
        "- **\u00c9ducatif** : Parfait pour l'enseignement"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": "# Parametres Papermill - JAMAIS modifier ce commentaire\n\n# Configuration conversation\nnotebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\nskip_widgets = False               # True pour mode batch MCP\ndebug_level = \"INFO\"               \n\n# Parametres GPT-5\nmodel_name = \"openai/gpt-5\"        # Modele via OpenRouter\nmax_tokens = 4000                  # Tokens de reponse max\ntemperature = 0.7                  # Creativite (0.0-1.0)\ntop_p = 0.9                        # Diversite sampling\n\n# Configuration analyse\nanalyze_images = True              # Analyser les images (False pour validation structurelle seule)\nanalysis_mode = \"detailed\"         # \"quick\", \"detailed\", \"educational\"\ninclude_technical_details = True   # Details techniques images\nexport_analysis = True             # Sauvegarder analyses\ngenerate_alt_text = True           # Generer descriptions accessibilite\n\n# Parametres pedagogiques\neducational_level = \"university\"   # \"elementary\", \"secondary\", \"university\"\nlanguage = \"francais\"              # Langue des explications\ninclude_examples = True            # Inclure exemples pratiques"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup environnement et imports\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Union\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Import helpers GenAI\n",
        "GENAI_ROOT = Path.cwd()\n",
        "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
        "    GENAI_ROOT = GENAI_ROOT.parent\n",
        "\n",
        "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
        "if HELPERS_PATH.exists():\n",
        "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
        "    try:\n",
        "        from helpers.genai_helpers import setup_genai_logging, load_genai_config\n",
        "        print(\"\u2705 Helpers GenAI import\u00e9s\")\n",
        "    except ImportError:\n",
        "        print(\"\u26a0\ufe0f  Helpers GenAI non disponibles - mode autonome\")\n",
        "\n",
        "# Configuration logging\n",
        "logging.basicConfig(level=getattr(logging, debug_level))\n",
        "logger = logging.getLogger('gpt5_multimodal')\n",
        "\n",
        "print(f\"\ud83e\udd16 GPT-5 Multimodal - Analyse et G\u00e9n\u00e9ration d'Images\")\n",
        "print(f\"\ud83d\udcc5 {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"\ud83d\udd27 Mode: {notebook_mode}, Analyse: {analysis_mode}, Niveau: {educational_level}\")\n",
        "print(f\"\ud83c\udf0d Langue: {language}, Max tokens: {max_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Helpers GenAI import\u00e9s\n",
            "\ud83e\udd16 GPT-5 Multimodal - Analyse et G\u00e9n\u00e9ration d'Images\n",
            "\ud83d\udcc5 2026-02-18 09:59:13\n",
            "\ud83d\udd27 Mode: batch, Analyse: detailed, Niveau: university\n",
            "\ud83c\udf0d Langue: francais, Max tokens: 4000\n"
          ]
        }
      ],
      "source": [
        "# Configuration API OpenRouter pour GPT-5\n",
        "print(\"\\n\ud83d\udd11 CONFIGURATION GPT-5 MULTIMODAL\")\n",
        "print(\"=\" * 42)\n",
        "\n",
        "# Chargement explicite du .env\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Recherche du .env dans les parents\n",
        "current_path = Path.cwd()\n",
        "found_env = False\n",
        "for _ in range(4):  # Remonter jusqu'\u00e0 4 niveaux\n",
        "    env_path = current_path / '.env'\n",
        "    if env_path.exists():\n",
        "        load_dotenv(env_path)\n",
        "        print(f\"\u2705 Fichier .env charg\u00e9 depuis: {env_path}\")\n",
        "        found_env = True\n",
        "        break\n",
        "    current_path = current_path.parent\n",
        "\n",
        "if not found_env:\n",
        "    print(\"\u26a0\ufe0f  Aucun fichier .env trouv\u00e9 dans l'arborescence\")\n",
        "\n",
        "# V\u00e9rification cl\u00e9 API\n",
        "openrouter_key = os.getenv('OPENROUTER_API_KEY')\n",
        "if not openrouter_key:\n",
        "    # Fallback pour validation structurelle sans cl\u00e9\n",
        "    if notebook_mode == \"batch\" and not analyze_images:\n",
        "        print(\"\u26a0\ufe0f  Mode batch sans analyse : Cl\u00e9 API ignor\u00e9e\")\n",
        "        openrouter_key = \"dummy_key_for_validation\"\n",
        "    else:\n",
        "        raise ValueError(\"\u274c OPENROUTER_API_KEY manquante dans .env\")\n",
        "\n",
        "print(f\"\u2705 Cl\u00e9 API OpenRouter configur\u00e9e\")\n",
        "\n",
        "# Configuration headers et endpoint\n",
        "api_base_url = \"https://openrouter.ai/api/v1\"\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {openrouter_key}\",\n",
        "    \"HTTP-Referer\": \"https://coursia.myia.io\",\n",
        "    \"X-Title\": \"CoursIA GenAI Images - GPT-5 Multimodal\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# Test connexion et v\u00e9rification mod\u00e8le GPT-5\n",
        "if openrouter_key != \"dummy_key_for_validation\":\n",
        "    try:\n",
        "        response = requests.get(f\"{api_base_url}/models\", headers=headers, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            models_data = response.json()\n",
        "            gpt5_models = [m for m in models_data.get('data', []) if 'gpt-5' in m.get('id', '').lower()]\n",
        "            \n",
        "            if gpt5_models:\n",
        "                print(f\"\u2705 Connexion r\u00e9ussie - {len(gpt5_models)} mod\u00e8les GPT-5 disponibles\")\n",
        "                \n",
        "                for model in gpt5_models:\n",
        "                    print(f\"  \ud83e\udde0 {model['id']} - Contexte: {model.get('context_length', 'N/A')} tokens\")\n",
        "                    if 'vision' in model.get('capabilities', []):\n",
        "                        print(f\"     \ud83d\udc41\ufe0f  Capacit\u00e9s vision activ\u00e9es\")\n",
        "            else:\n",
        "                print(f\"\u26a0\ufe0f  Aucun mod\u00e8le GPT-5 d\u00e9tect\u00e9 - v\u00e9rifiez votre acc\u00e8s\")\n",
        "                print(f\"\ud83d\udd0d Mod\u00e8les disponibles avec 'gpt' : {len([m for m in models_data.get('data', []) if 'gpt' in m.get('id', '').lower()])}\")\n",
        "        else:\n",
        "            print(f\"\u26a0\ufe0f  Connexion API: HTTP {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Erreur connexion: {str(e)[:100]}...\")\n",
        "else:\n",
        "    print(\"\u23ed\ufe0f  Test connexion API saut\u00e9 (dummy key)\")\n",
        "    \n",
        "print(f\"\\n\ud83c\udfaf Mod\u00e8le s\u00e9lectionn\u00e9: {model_name}\")\n",
        "print(f\"\u2699\ufe0f  Param\u00e8tres: Temperature={temperature}, Max tokens={max_tokens}\")\n",
        "print(f\"\ud83d\udcca Mode d'analyse: {analysis_mode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\ud83d\udd11 CONFIGURATION GPT-5 MULTIMODAL\n",
            "==========================================\n",
            "\u2705 Fichier .env charg\u00e9 depuis: D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\.env\n",
            "\u2705 Cl\u00e9 API OpenRouter configur\u00e9e\n",
            "\u2705 Connexion r\u00e9ussie - 17 mod\u00e8les GPT-5 disponibles\n",
            "  \ud83e\udde0 openai/gpt-5.2-codex - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5.2-chat - Contexte: 128000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5.2-pro - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5.2 - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5.1-codex-max - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5.1 - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5.1-chat - Contexte: 128000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5.1-codex - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5.1-codex-mini - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5-image-mini - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5-image - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5-pro - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5-codex - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5-chat - Contexte: 128000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5 - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5-mini - Contexte: 400000 tokens\n",
            "  \ud83e\udde0 openai/gpt-5-nano - Contexte: 400000 tokens\n",
            "\n",
            "\ud83c\udfaf Mod\u00e8le s\u00e9lectionn\u00e9: openai/gpt-5\n",
            "\u2699\ufe0f  Param\u00e8tres: Temperature=0.7, Max tokens=4000\n",
            "\ud83d\udcca Mode d'analyse: detailed\n"
          ]
        }
      ],
      "source": [
        "# Fonctions utilitaires pour traitement d'images\n",
        "def encode_image_base64(image_path: Union[str, Path]) -> str:\n",
        "    \"\"\"\n",
        "    Encode une image locale en base64 pour GPT-5.\n",
        "    \n",
        "    Args:\n",
        "        image_path: Chemin vers l'image locale\n",
        "        \n",
        "    Returns:\n",
        "        String base64 de l'image\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Erreur lecture image {image_path}: {str(e)}\")\n",
        "\n",
        "def download_and_encode_image(image_url: str) -> str:\n",
        "    \"\"\"\n",
        "    T\u00e9l\u00e9charge et encode une image depuis URL.\n",
        "    \n",
        "    Args:\n",
        "        image_url: URL de l'image\n",
        "        \n",
        "    Returns:\n",
        "        String base64 de l'image\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(image_url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        return base64.b64encode(response.content).decode('utf-8')\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Erreur t\u00e9l\u00e9chargement {image_url}: {str(e)}\")\n",
        "\n",
        "def prepare_image_for_gpt5(image_source: Union[str, Path]) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Pr\u00e9pare une image pour GPT-5 (locale ou URL).\n",
        "    \n",
        "    Args:\n",
        "        image_source: Chemin local ou URL de l'image\n",
        "        \n",
        "    Returns:\n",
        "        Dict avec format attendu par GPT-5\n",
        "    \"\"\"\n",
        "    if isinstance(image_source, (str, Path)):\n",
        "        str_source = str(image_source)\n",
        "        \n",
        "        # V\u00e9rification URL\n",
        "        if str_source.startswith(('http://', 'https://')):\n",
        "            try:\n",
        "                # Pour les URLs, GPT-5 peut les traiter directement\n",
        "                return {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": str_source\n",
        "                    }\n",
        "                }\n",
        "            except:\n",
        "                # Fallback : t\u00e9l\u00e9charger et encoder\n",
        "                base64_image = download_and_encode_image(str_source)\n",
        "                return {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                    }\n",
        "                }\n",
        "        else:\n",
        "            # Image locale\n",
        "            if Path(str_source).exists():\n",
        "                base64_image = encode_image_base64(str_source)\n",
        "                return {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                    }\n",
        "                }\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"Image non trouv\u00e9e: {str_source}\")\n",
        "    \n",
        "    raise ValueError(f\"Format d'image non support\u00e9: {type(image_source)}\")\n",
        "\n",
        "print(\"\u2705 Fonctions utilitaires images pr\u00eates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Fonctions utilitaires images pr\u00eates\n"
          ]
        }
      ],
      "source": [
        "# Fonction principale d'analyse d'image avec GPT-5\n",
        "def analyze_image_with_gpt5(image_source: Union[str, Path], \n",
        "                           prompt: str = None,\n",
        "                           analysis_type: str = \"detailed\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Analyse une image avec GPT-5 multimodal.\n",
        "    \n",
        "    Args:\n",
        "        image_source: Chemin local ou URL de l'image\n",
        "        prompt: Prompt personnalis\u00e9 (optionnel)\n",
        "        analysis_type: Type d'analyse (\"quick\", \"detailed\", \"educational\")\n",
        "        \n",
        "    Returns:\n",
        "        Dict avec analyse compl\u00e8te\n",
        "    \"\"\"\n",
        "    \n",
        "    # Prompts pr\u00e9d\u00e9finis selon le type d'analyse\n",
        "    analysis_prompts = {\n",
        "        \"quick\": f\"D\u00e9cris bri\u00e8vement cette image en {language}. Sois concis mais pr\u00e9cis.\",\n",
        "        \n",
        "        \"detailed\": f\"\"\"Analyse cette image en d\u00e9tail en {language}. Inclus :\n",
        "        \n",
        "1. **Description g\u00e9n\u00e9rale** : Que voit-on dans l'image ?\n",
        "2. **\u00c9l\u00e9ments visuels** : Couleurs, composition, style artistique\n",
        "3. **Contexte** : \u00c9poque, lieu, situation probable\n",
        "4. **D\u00e9tails techniques** : Qualit\u00e9, r\u00e9solution apparente, type de photo/illustration\n",
        "5. **\u00c9motions/Atmosph\u00e8re** : Quelle ambiance d\u00e9gage l'image ?\n",
        "6. **Interpr\u00e9tation** : Signification possible, message artistique\n",
        "\n",
        "Sois pr\u00e9cis et p\u00e9dagogique dans tes explications.\"\"\",\n",
        "        \n",
        "        \"educational\": f\"\"\"Tu es un professeur expert analysant cette image pour des \u00e9tudiants de niveau {educational_level}. En {language}, fournis :\n",
        "\n",
        "\ud83c\udfaf **ANALYSE P\u00c9DAGOGIQUE**\n",
        "\n",
        "**1. Description accessible**\n",
        "- Que montre cette image de fa\u00e7on simple et claire ?\n",
        "\n",
        "**2. \u00c9l\u00e9ments \u00e0 observer**\n",
        "- Quels d\u00e9tails importants les \u00e9tudiants doivent-ils remarquer ?\n",
        "- Techniques artistiques ou photographiques utilis\u00e9es\n",
        "\n",
        "**3. Contexte \u00e9ducatif**\n",
        "- Dans quel domaine d'\u00e9tude cette image serait-elle utile ?\n",
        "- Quelles disciplines acad\u00e9miques peuvent l'utiliser ?\n",
        "\n",
        "**4. Questions pour r\u00e9flexion**\n",
        "- 3 questions que tu poserais aux \u00e9tudiants sur cette image\n",
        "\n",
        "**5. Connexions interdisciplinaires**\n",
        "- Comment cette image se connecte-t-elle \u00e0 d'autres sujets ?\n",
        "\n",
        "Adapte ton vocabulaire au niveau {educational_level}.\"\"\"\n",
        "    }\n",
        "    \n",
        "    # S\u00e9lection du prompt\n",
        "    if prompt is None:\n",
        "        prompt = analysis_prompts.get(analysis_type, analysis_prompts[\"detailed\"])\n",
        "    \n",
        "    try:\n",
        "        print(f\"\\n\ud83d\udd0d Analyse en cours...\")\n",
        "        print(f\"\ud83d\udcdd Type: {analysis_type}\")\n",
        "        print(f\"\ud83d\uddbc\ufe0f  Source: {str(image_source)[:100]}{'...' if len(str(image_source)) > 100 else ''}\")\n",
        "        \n",
        "        # Pr\u00e9paration de l'image\n",
        "        image_data = prepare_image_for_gpt5(image_source)\n",
        "        \n",
        "        # Construction du message multimodal\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": prompt\n",
        "                    },\n",
        "                    image_data\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "        \n",
        "        # Payload de la requ\u00eate\n",
        "        payload = {\n",
        "            \"model\": model_name,\n",
        "            \"messages\": messages,\n",
        "            \"max_tokens\": max_tokens,\n",
        "            \"temperature\": temperature,\n",
        "            \"top_p\": top_p\n",
        "        }\n",
        "        \n",
        "        # Requ\u00eate API\n",
        "        start_time = datetime.now()\n",
        "        response = requests.post(\n",
        "            f\"{api_base_url}/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            timeout=120\n",
        "        )\n",
        "        response_time = (datetime.now() - start_time).total_seconds()\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            \n",
        "            analysis_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "            \n",
        "            # M\u00e9tadonn\u00e9es de l'analyse\n",
        "            metadata = {\n",
        "                \"model\": model_name,\n",
        "                \"analysis_type\": analysis_type,\n",
        "                \"educational_level\": educational_level,\n",
        "                \"language\": language,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"response_time\": response_time,\n",
        "                \"tokens_used\": result.get(\"usage\", {}),\n",
        "                \"image_source\": str(image_source),\n",
        "                \"prompt_length\": len(prompt)\n",
        "            }\n",
        "            \n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"analysis\": analysis_text,\n",
        "                \"metadata\": metadata,\n",
        "                \"image_source\": image_source,\n",
        "                \"analysis_type\": analysis_type\n",
        "            }\n",
        "        else:\n",
        "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else {}\n",
        "            error_msg = error_data.get(\"error\", {}).get(\"message\", f\"HTTP {response.status_code}\")\n",
        "            \n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"error\": error_msg,\n",
        "                \"image_source\": image_source,\n",
        "                \"status_code\": response.status_code\n",
        "            }\n",
        "            \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"error\": str(e),\n",
        "            \"image_source\": image_source\n",
        "        }\n",
        "\n",
        "print(\"\u2705 Fonction d'analyse GPT-5 pr\u00eate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Fonction d'analyse GPT-5 pr\u00eate\n"
          ]
        }
      ],
      "source": [
        "# Exemples d'images pour d\u00e9monstration\n",
        "print(\"\\n\ud83d\uddbc\ufe0f  EXEMPLES D'ANALYSE GPT-5\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Images d'exemple (URLs publiques pour tests)\n",
        "example_images = [\n",
        "    {\n",
        "        \"title\": \"\ud83c\udfdb\ufe0f Architecture Historique\",\n",
        "        \"url\": \"https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\",  # Colis\u00e9e Rome\n",
        "        \"description\": \"Monument historique romain - id\u00e9al pour analyse architecturale\",\n",
        "        \"category\": \"Histoire/Architecture\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"\ud83d\udd2c Science et Technologie\",\n",
        "        \"url\": \"https://images.unsplash.com/photo-1532094349884-543bc11b234d?w=800\",  # Laboratoire\n",
        "        \"description\": \"Environnement scientifique - parfait pour analyse technique\",\n",
        "        \"category\": \"Science/Technologie\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"\ud83c\udfa8 Art et Culture\",\n",
        "        \"url\": \"https://images.unsplash.com/photo-1541961017774-22349e4a1262?w=800\",  # Peinture\n",
        "        \"description\": \"\u0152uvre artistique - excellent pour analyse esth\u00e9tique\",\n",
        "        \"category\": \"Art/Culture\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"\ud83c\udf0d Nature et Environnement\",\n",
        "        \"url\": \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800\",  # Paysage naturel\n",
        "        \"description\": \"Paysage naturel - parfait pour analyse g\u00e9ographique\",\n",
        "        \"category\": \"G\u00e9ographie/Environnement\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Affichage des exemples\n",
        "for i, example in enumerate(example_images, 1):\n",
        "    print(f\"\\n{i}. {example['title']}\")\n",
        "    print(f\"   \ud83d\udcc2 Cat\u00e9gorie: {example['category']}\")\n",
        "    print(f\"   \ud83d\udcdd {example['description']}\")\n",
        "    print(f\"   \ud83d\udd17 URL: {example['url'][:60]}...\")\n",
        "\n",
        "print(f\"\\n\ud83d\udca1 Conseils pour l'analyse avec GPT-5:\")\n",
        "print(f\"\u2022 Utilisez des images de haute qualit\u00e9\")\n",
        "print(f\"\u2022 Posez des questions sp\u00e9cifiques\")\n",
        "print(f\"\u2022 Exploitez le contexte \u00e9ducatif\")\n",
        "print(f\"\u2022 Combinez analyse textuelle et visuelle\")\n",
        "print(f\"\u2022 Adaptez le niveau de complexit\u00e9\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\ud83d\uddbc\ufe0f  EXEMPLES D'ANALYSE GPT-5\n",
            "========================================\n",
            "\n",
            "1. \ud83c\udfdb\ufe0f Architecture Historique\n",
            "   \ud83d\udcc2 Cat\u00e9gorie: Histoire/Architecture\n",
            "   \ud83d\udcdd Monument historique romain - id\u00e9al pour analyse architecturale\n",
            "   \ud83d\udd17 URL: https://images.unsplash.com/photo-1539037116277-4db20889f2d4...\n",
            "\n",
            "2. \ud83d\udd2c Science et Technologie\n",
            "   \ud83d\udcc2 Cat\u00e9gorie: Science/Technologie\n",
            "   \ud83d\udcdd Environnement scientifique - parfait pour analyse technique\n",
            "   \ud83d\udd17 URL: https://images.unsplash.com/photo-1532094349884-543bc11b234d...\n",
            "\n",
            "3. \ud83c\udfa8 Art et Culture\n",
            "   \ud83d\udcc2 Cat\u00e9gorie: Art/Culture\n",
            "   \ud83d\udcdd \u0152uvre artistique - excellent pour analyse esth\u00e9tique\n",
            "   \ud83d\udd17 URL: https://images.unsplash.com/photo-1541961017774-22349e4a1262...\n",
            "\n",
            "4. \ud83c\udf0d Nature et Environnement\n",
            "   \ud83d\udcc2 Cat\u00e9gorie: G\u00e9ographie/Environnement\n",
            "   \ud83d\udcdd Paysage naturel - parfait pour analyse g\u00e9ographique\n",
            "   \ud83d\udd17 URL: https://images.unsplash.com/photo-1506905925346-21bda4d32df4...\n",
            "\n",
            "\ud83d\udca1 Conseils pour l'analyse avec GPT-5:\n",
            "\u2022 Utilisez des images de haute qualit\u00e9\n",
            "\u2022 Posez des questions sp\u00e9cifiques\n",
            "\u2022 Exploitez le contexte \u00e9ducatif\n",
            "\u2022 Combinez analyse textuelle et visuelle\n",
            "\u2022 Adaptez le niveau de complexit\u00e9\n"
          ]
        }
      ],
      "source": [
        "# Analyse d'une image de d\u00e9monstration\n",
        "print(\"\\n\ud83d\ude80 ANALYSE DE D\u00c9MONSTRATION - GPT-5\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# S\u00e9lection d'une image pour la d\u00e9monstration\n",
        "selected_example = example_images[0]  # Architecture historique\n",
        "print(f\"\ud83c\udfaf Analyse: {selected_example['title']}\")\n",
        "print(f\"\ud83d\udcc2 Cat\u00e9gorie: {selected_example['category']}\")\n",
        "\n",
        "# Test de l'analyse avec les diff\u00e9rents modes\n",
        "analysis_results = []\n",
        "\n",
        "for mode in ['quick', 'detailed', 'educational']:\n",
        "    print(f\"\\n\ud83d\udd0d Mode d'analyse: {mode.upper()}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # Analyse de l'image\n",
        "    result = analyze_image_with_gpt5(\n",
        "        image_source=selected_example['url'],\n",
        "        analysis_type=mode\n",
        "    )\n",
        "    \n",
        "    if result['success']:\n",
        "        print(f\"\u2705 Analyse {mode} r\u00e9ussie\")\n",
        "        print(f\"\u23f1\ufe0f  Temps: {result['metadata']['response_time']:.2f}s\")\n",
        "        print(f\"\ud83d\udd22 Tokens: {result['metadata']['tokens_used']}\")\n",
        "        \n",
        "        # Affichage de l'analyse (tronqu\u00e9e pour la d\u00e9mo)\n",
        "        analysis_preview = result['analysis'][:300] + \"...\" if len(result['analysis']) > 300 else result['analysis']\n",
        "        print(f\"\\n\ud83d\udcdd **Aper\u00e7u de l'analyse {mode}:**\")\n",
        "        print(analysis_preview)\n",
        "        \n",
        "        analysis_results.append(result)\n",
        "    else:\n",
        "        print(f\"\u274c \u00c9chec analyse {mode}: {result['error']}\")\n",
        "    \n",
        "    print()  # S\u00e9paration\n",
        "\n",
        "# Comparaison des r\u00e9sultats\n",
        "if analysis_results:\n",
        "    print(f\"\\n\ud83d\udcca COMPARAISON DES MODES D'ANALYSE\")\n",
        "    print(\"=\" * 45)\n",
        "    \n",
        "    for result in analysis_results:\n",
        "        mode = result['analysis_type']\n",
        "        length = len(result['analysis'])\n",
        "        tokens = result['metadata'].get('tokens_used', {}).get('total_tokens', 'N/A')\n",
        "        time = result['metadata']['response_time']\n",
        "        \n",
        "        print(f\"{mode.capitalize():12} | {length:4d} chars | {tokens:>6} tokens | {time:5.2f}s\")\n",
        "    \n",
        "    print(f\"\\n\ud83d\udca1 Observations:\")\n",
        "    print(f\"\u2022 Mode 'quick': R\u00e9ponses concises et rapides\")\n",
        "    print(f\"\u2022 Mode 'detailed': Analyse approfondie et structur\u00e9e\")\n",
        "    print(f\"\u2022 Mode 'educational': Adapt\u00e9 \u00e0 l'enseignement avec questions\")\n",
        "else:\n",
        "    print(f\"\\n\u26a0\ufe0f  Aucune analyse r\u00e9ussie - v\u00e9rifiez votre configuration\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\ud83d\ude80 ANALYSE DE D\u00c9MONSTRATION - GPT-5\n",
            "==================================================\n",
            "\ud83c\udfaf Analyse: \ud83c\udfdb\ufe0f Architecture Historique\n",
            "\ud83d\udcc2 Cat\u00e9gorie: Histoire/Architecture\n",
            "\n",
            "\ud83d\udd0d Mode d'analyse: QUICK\n",
            "------------------------------\n",
            "\n",
            "\ud83d\udd0d Analyse en cours...\n",
            "\ud83d\udcdd Type: quick\n",
            "\ud83d\uddbc\ufe0f  Source: https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Analyse quick r\u00e9ussie\n",
            "\u23f1\ufe0f  Temps: 10.95s\n",
            "\ud83d\udd22 Tokens: {'prompt_tokens': 653, 'completion_tokens': 253, 'total_tokens': 906, 'cost': 0, 'is_byok': True, 'prompt_tokens_details': {'cached_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.00334625, 'upstream_inference_prompt_cost': 0.00081625, 'upstream_inference_completions_cost': 0.00253}, 'completion_tokens_details': {'reasoning_tokens': 192, 'image_tokens': 0}}\n",
            "\n",
            "\ud83d\udcdd **Aper\u00e7u de l'analyse quick:**\n",
            "Vue au coucher du soleil sur la Gran V\u00eda \u00e0 Madrid : b\u00e2timents historiques \u00e9clair\u00e9s, circulation sur l\u2019avenue, ciel orang\u00e9 et montagnes au loin, avec le d\u00f4me noir et dor\u00e9 du b\u00e2timent Metr\u00f3polis au premier plan.\n",
            "\n",
            "\n",
            "\ud83d\udd0d Mode d'analyse: DETAILED\n",
            "------------------------------\n",
            "\n",
            "\ud83d\udd0d Analyse en cours...\n",
            "\ud83d\udcdd Type: detailed\n",
            "\ud83d\uddbc\ufe0f  Source: https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Analyse detailed r\u00e9ussie\n",
            "\u23f1\ufe0f  Temps: 42.89s\n",
            "\ud83d\udd22 Tokens: {'prompt_tokens': 758, 'completion_tokens': 1548, 'total_tokens': 2306, 'cost': 0, 'is_byok': True, 'prompt_tokens_details': {'cached_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.0164275, 'upstream_inference_prompt_cost': 0.0009475, 'upstream_inference_completions_cost': 0.01548}, 'completion_tokens_details': {'reasoning_tokens': 576, 'image_tokens': 0}}\n",
            "\n",
            "\ud83d\udcdd **Aper\u00e7u de l'analyse detailed:**\n",
            "1) Description g\u00e9n\u00e9rale\n",
            "- Vue a\u00e9rienne/\u00e9lev\u00e9e d\u2019une grande avenue urbaine au cr\u00e9puscule. \n",
            "- Au premier plan \u00e0 gauche, un immeuble d\u2019angle orn\u00e9 d\u2019un d\u00f4me sombre surmont\u00e9 d\u2019une statue; l\u2019enseigne lumineuse \u201cMetropolis\u201d est visible.\n",
            "- L\u2019avenue s\u2019\u00e9tire en diagonale, bord\u00e9e d\u2019immeubles \u00e9l\u00e9gants aux fa\u00e7ad...\n",
            "\n",
            "\n",
            "\ud83d\udd0d Mode d'analyse: EDUCATIONAL\n",
            "------------------------------\n",
            "\n",
            "\ud83d\udd0d Analyse en cours...\n",
            "\ud83d\udcdd Type: educational\n",
            "\ud83d\uddbc\ufe0f  Source: https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Analyse educational r\u00e9ussie\n",
            "\u23f1\ufe0f  Temps: 72.98s\n",
            "\ud83d\udd22 Tokens: {'prompt_tokens': 804, 'completion_tokens': 1825, 'total_tokens': 2629, 'cost': 0, 'is_byok': True, 'prompt_tokens_details': {'cached_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.019255, 'upstream_inference_prompt_cost': 0.001005, 'upstream_inference_completions_cost': 0.01825}, 'completion_tokens_details': {'reasoning_tokens': 960, 'image_tokens': 0}}\n",
            "\n",
            "\ud83d\udcdd **Aper\u00e7u de l'analyse educational:**\n",
            "\ud83c\udfaf ANALYSE P\u00c9DAGOGIQUE\n",
            "\n",
            "1) Description accessible\n",
            "- Vue a\u00e9rienne/\u00e9lev\u00e9e d\u2019un centre-ville au coucher du soleil.\n",
            "- Une large avenue traverse l\u2019image, bord\u00e9e d\u2019immeubles historiques \u00e9clair\u00e9s.\n",
            "- Circulation mod\u00e9r\u00e9e de voitures, pi\u00e9tons discrets, enseignes lumineuses.\n",
            "- \u00c0 l\u2019horizon, cha\u00eene de montagnes s...\n",
            "\n",
            "\n",
            "\ud83d\udcca COMPARAISON DES MODES D'ANALYSE\n",
            "=============================================\n",
            "Quick        |  209 chars |    906 tokens | 10.95s\n",
            "Detailed     | 3611 chars |   2306 tokens | 42.89s\n",
            "Educational  | 3322 chars |   2629 tokens | 72.98s\n",
            "\n",
            "\ud83d\udca1 Observations:\n",
            "\u2022 Mode 'quick': R\u00e9ponses concises et rapides\n",
            "\u2022 Mode 'detailed': Analyse approfondie et structur\u00e9e\n",
            "\u2022 Mode 'educational': Adapt\u00e9 \u00e0 l'enseignement avec questions\n"
          ]
        }
      ],
      "source": [
        "# G\u00e9n\u00e9ration de descriptions d'accessibilit\u00e9 (Alt text)\n",
        "if generate_alt_text and analysis_results:\n",
        "    print(\"\\n\u267f G\u00c9N\u00c9RATION DE DESCRIPTIONS D'ACCESSIBILIT\u00c9\")\n",
        "    print(\"=\" * 55)\n",
        "    \n",
        "    # Prompt sp\u00e9cialis\u00e9 pour l'accessibilit\u00e9\n",
        "    accessibility_prompt = f\"\"\"G\u00e9n\u00e8re une description d'accessibilit\u00e9 (alt text) pour cette image en {language}.\n",
        "    \n",
        "Crit\u00e8res :\n",
        "- Maximum 125 caract\u00e8res\n",
        "- Description factuelle et objective\n",
        "- Inclut les \u00e9l\u00e9ments essentiels pour la compr\u00e9hension\n",
        "- \u00c9vite les interpr\u00e9tations subjectives\n",
        "- Adapt\u00e9 aux lecteurs d'\u00e9cran\n",
        "\n",
        "Format : Fournis UNIQUEMENT la description, sans formatage suppl\u00e9mentaire.\"\"\"\n",
        "    \n",
        "    # G\u00e9n\u00e9ration de l'alt text\n",
        "    alt_result = analyze_image_with_gpt5(\n",
        "        image_source=selected_example['url'],\n",
        "        prompt=accessibility_prompt\n",
        "    )\n",
        "    \n",
        "    if alt_result['success']:\n",
        "        alt_text = alt_result['analysis'].strip()\n",
        "        \n",
        "        print(f\"\u2705 Description d'accessibilit\u00e9 g\u00e9n\u00e9r\u00e9e\")\n",
        "        print(f\"\ud83d\udcdd Alt text ({len(alt_text)} caract\u00e8res) :\")\n",
        "        print(f'   \"{alt_text}\"')\n",
        "        \n",
        "        if len(alt_text) > 125:\n",
        "            print(f\"\u26a0\ufe0f  Longueur d\u00e9pass\u00e9e ({len(alt_text)}/125 chars) - consid\u00e9rez une version plus courte\")\n",
        "        else:\n",
        "            print(f\"\u2705 Longueur optimale ({len(alt_text)}/125 chars)\")\n",
        "    else:\n",
        "        print(f\"\u274c Erreur g\u00e9n\u00e9ration alt text: {alt_result['error']}\")\n",
        "else:\n",
        "    print(f\"\\n\u23ed\ufe0f  G\u00e9n\u00e9ration alt text d\u00e9sactiv\u00e9e ou pas d'analyse disponible\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u267f G\u00c9N\u00c9RATION DE DESCRIPTIONS D'ACCESSIBILIT\u00c9\n",
            "=======================================================\n",
            "\n",
            "\ud83d\udd0d Analyse en cours...\n",
            "\ud83d\udcdd Type: detailed\n",
            "\ud83d\uddbc\ufe0f  Source: https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Description d'accessibilit\u00e9 g\u00e9n\u00e9r\u00e9e\n",
            "\ud83d\udcdd Alt text (110 caract\u00e8res) :\n",
            "   \"Vue sur la Gran V\u00eda \u00e0 Madrid au coucher du soleil, avec le b\u00e2timent Metropolis et la circulation sur l\u2019avenue.\"\n",
            "\u2705 Longueur optimale (110/125 chars)\n"
          ]
        }
      ],
      "source": "# Mode interactif - Analyse d'image personnalis\u00e9e\nif notebook_mode == \"interactive\" and not skip_widgets:\n    print(\"\\n\ud83c\udfa8 MODE INTERACTIF - ANALYSE PERSONNALIS\u00c9E\")\n    print(\"=\" * 55)\n    \n    print(\"\\n\ud83d\udca1 Analysez votre propre image avec GPT-5:\")\n    print(\"Formats support\u00e9s: URL https:// ou chemin local\")\n    print(\"(Laissez vide pour passer \u00e0 la suite)\")\n    \n    try:\n        user_image = input(\"\\n\ud83d\uddbc\ufe0f  URL ou chemin de votre image: \").strip()\n\n        if user_image:\n            # Param\u00e8tres d'analyse personnalis\u00e9s\n            print(\"\\n\u2699\ufe0f  Param\u00e8tres d'analyse (appuyez Entr\u00e9e pour d\u00e9faut):\")\n            custom_mode = input(f\"\ud83d\udcca Mode [{analysis_mode}]: \").strip() or analysis_mode\n            custom_prompt = input(\"\ud83d\udcdd Prompt personnalis\u00e9 (optionnel): \").strip()\n\n            print(f\"\\n\ud83d\udd0d Analyse de votre image en cours...\")\n\n            # Analyse personnalis\u00e9e\n            if custom_prompt:\n                user_result = analyze_image_with_gpt5(\n                    image_source=user_image,\n                    prompt=custom_prompt\n                )\n            else:\n                user_result = analyze_image_with_gpt5(\n                    image_source=user_image,\n                    analysis_type=custom_mode\n                )\n\n            if user_result['success']:\n                print(f\"\\n\ud83c\udf89 Analyse r\u00e9ussie!\")\n                print(f\"\u23f1\ufe0f  Temps: {user_result['metadata']['response_time']:.2f}s\")\n                print(f\"\\n\ud83d\udcdd **Analyse GPT-5:**\")\n                print(user_result['analysis'])\n\n                # Option de sauvegarde\n                if export_analysis:\n                    try:\n                        save_choice = input(\"\\n\ud83d\udcbe Sauvegarder cette analyse ? (o/N): \").strip().lower()\n                        if save_choice in ['o', 'oui', 'y', 'yes']:\n                            output_dir = GENAI_ROOT / 'outputs' / 'gpt5_analysis'\n                            output_dir.mkdir(parents=True, exist_ok=True)\n\n                            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n                            analysis_file = output_dir / f\"gpt5_analysis_{timestamp}.json\"\n\n                            with open(analysis_file, 'w', encoding='utf-8') as f:\n                                json.dump(user_result, f, indent=2, ensure_ascii=False)\n\n                            print(f\"\ud83d\udcbe Analyse sauvegard\u00e9e: {analysis_file}\")\n                    except Exception as save_err:\n                        if \"StdinNotImplemented\" in type(save_err).__name__:\n                            print(\"\\n\u23ed\ufe0f  Sauvegarde automatique ignor\u00e9e en mode batch\")\n                        else:\n                            raise\n            else:\n                print(f\"\\n\u274c Erreur: {user_result['error']}\")\n                print(f\"\ud83d\udd0d Source: {user_result['image_source']}\")\n        else:\n            print(\"\\n\u23ed\ufe0f  Mode interactif ignor\u00e9\")\n\n    except (KeyboardInterrupt, EOFError) as e:\n        # Gestion interruption normale\n        print(f\"\\n\u23ed\ufe0f  Mode interactif interrompu ({type(e).__name__})\")\n    except Exception as e:\n        # Gestion des erreurs d'input en mode non-interactif (Papermill, etc.)\n        error_type = type(e).__name__\n        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n            print(\"\\n\u23ed\ufe0f  Mode interactif non disponible (ex\u00e9cution automatis\u00e9e)\")\n        else:\n            # Autre erreur inattendue - afficher pour d\u00e9bogage\n            print(f\"\\n\u26a0\ufe0f  Erreur inattendue: {error_type} - {str(e)[:100]}\")\n            print(\"\u23ed\ufe0f  Passage \u00e0 la suite du notebook\")\nelse:\n    print(\"\\n\ud83e\udd16 Mode batch - Interface interactive d\u00e9sactiv\u00e9e\")\n    print(\"\ud83d\udca1 Pour mode interactif: notebook_mode = 'interactive'\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\ud83e\udd16 Mode batch - Interface interactive d\u00e9sactiv\u00e9e\n",
            "\ud83d\udca1 Pour mode interactif: notebook_mode = 'interactive'\n"
          ]
        }
      ],
      "source": [
        "# Cas d'usage p\u00e9dagogiques avec GPT-5\n",
        "print(\"\\n\ud83c\udf93 CAS D'USAGE P\u00c9DAGOGIQUES GPT-5\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Exemples d'applications \u00e9ducatives\n",
        "educational_use_cases = {\n",
        "    \"Histoire\": {\n",
        "        \"description\": \"Analyse de documents historiques, \u0153uvres d'art, monuments\",\n",
        "        \"exemple\": \"Analyser une fresque renaissance pour comprendre le contexte social\",\n",
        "        \"prompt_template\": \"Analyse cette image historique pour des \u00e9tudiants en histoire. Explique le contexte historique, les \u00e9l\u00e9ments symboliques, et l'importance culturelle.\"\n",
        "    },\n",
        "    \n",
        "    \"Sciences\": {\n",
        "        \"description\": \"Analyse d'exp\u00e9riences, sch\u00e9mas scientifiques, ph\u00e9nom\u00e8nes naturels\",\n",
        "        \"exemple\": \"Expliquer un diagramme de cellule ou une r\u00e9action chimique\",\n",
        "        \"prompt_template\": \"En tant qu'enseignant de sciences, explique cette image scientifique. Identifie les \u00e9l\u00e9ments techniques et leur fonctionnement.\"\n",
        "    },\n",
        "    \n",
        "    \"G\u00e9ographie\": {\n",
        "        \"description\": \"\u00c9tude de paysages, cartes, ph\u00e9nom\u00e8nes g\u00e9ologiques\",\n",
        "        \"exemple\": \"Analyser une photo satellite ou un paysage g\u00e9ographique\",\n",
        "        \"prompt_template\": \"Analyse cette image g\u00e9ographique pour des \u00e9tudiants. Explique les formations g\u00e9ologiques, le climat, et l'impact humain visible.\"\n",
        "    },\n",
        "    \n",
        "    \"Art et Culture\": {\n",
        "        \"description\": \"Critique artistique, analyse stylistique, histoire de l'art\",\n",
        "        \"exemple\": \"Comprendre les techniques d'un tableau impressionniste\",\n",
        "        \"prompt_template\": \"Fais une analyse artistique de cette \u0153uvre pour des \u00e9tudiants en art. Inclus style, techniques, et signification culturelle.\"\n",
        "    },\n",
        "    \n",
        "    \"M\u00e9decine\": {\n",
        "        \"description\": \"Analyse d'imagerie m\u00e9dicale, anatomie, cas cliniques\",\n",
        "        \"exemple\": \"Expliquer une radiographie ou un sch\u00e9ma anatomique\",\n",
        "        \"prompt_template\": \"Analyse cette image m\u00e9dicale pour des \u00e9tudiants en m\u00e9decine. Explique l'anatomie visible et les points d'int\u00e9r\u00eat clinique.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Affichage des cas d'usage\n",
        "for domain, info in educational_use_cases.items():\n",
        "    print(f\"\\n\ud83d\udcda **{domain}**\")\n",
        "    print(f\"   \ud83d\udccb {info['description']}\")\n",
        "    print(f\"   \ud83d\udca1 Exemple: {info['exemple']}\")\n",
        "    print(f\"   \ud83d\udcdd Template de prompt disponible\")\n",
        "\n",
        "print(f\"\\n\ud83c\udfaf Avantages GPT-5 pour l'\u00e9ducation:\")\n",
        "print(f\"\u2022 **Multimodal** : Analyse texte + image simultan\u00e9e\")\n",
        "print(f\"\u2022 **Contextuel** : Comprend le niveau \u00e9ducatif\")\n",
        "print(f\"\u2022 **Adaptable** : Ajuste le vocabulaire selon l'audience\")\n",
        "print(f\"\u2022 **Interactif** : Permet les questions de suivi\")\n",
        "print(f\"\u2022 **Pr\u00e9cis** : Analyse d\u00e9taill\u00e9e et factuelle\")\n",
        "\n",
        "print(f\"\\n\ud83d\udcdd Exemple de workflow p\u00e9dagogique:\")\n",
        "print(f\"1. S\u00e9lection d'image pertinente au cours\")\n",
        "print(f\"2. Analyse GPT-5 avec prompt \u00e9ducatif\")\n",
        "print(f\"3. G\u00e9n\u00e9ration de questions pour les \u00e9tudiants\")\n",
        "print(f\"4. Discussion interactive bas\u00e9e sur l'analyse\")\n",
        "print(f\"5. \u00c9valuation de la compr\u00e9hension\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf R\u00e9sum\u00e9 et Bonnes Pratiques\n",
        "\n",
        "### \u2705 Ce que vous avez appris\n",
        "\n",
        "- [ ] **Configuration GPT-5** : OpenRouter API et param\u00e8tres optimaux\n",
        "- [ ] **Analyse multimodale** : Combinaison texte + image\n",
        "- [ ] **Prompts \u00e9ducatifs** : Adaptation au niveau d'enseignement\n",
        "- [ ] **Cas d'usage p\u00e9dagogiques** : Applications concr\u00e8tes par domaine\n",
        "- [ ] **Optimisation** : Param\u00e8tres de qualit\u00e9 et performance\n",
        "\n",
        "### \ud83d\ude80 Prochaines \u00e9tapes\n",
        "\n",
        "1. **Exp\u00e9rimentez** avec vos propres images \u00e9ducatives\n",
        "2. **Testez** diff\u00e9rents niveaux d'analyse selon votre public\n",
        "3. **Int\u00e9grez** GPT-5 dans vos workflows p\u00e9dagogiques\n",
        "4. **Combinez** avec DALL-E 3 pour g\u00e9n\u00e9ration + analyse\n",
        "5. **Explorez** les notebooks avanc\u00e9s (Module 02)\n",
        "\n",
        "### \ud83d\udca1 Conseils pour l'utilisation\n",
        "\n",
        "**\u2705 Bonnes pratiques:**\n",
        "- Utilisez des images de haute qualit\u00e9\n",
        "- Adaptez le prompt au niveau \u00e9ducatif\n",
        "- Combinez analyse visuelle et contextuelle\n",
        "- G\u00e9n\u00e9rez des questions p\u00e9dagogiques\n",
        "- Sauvegardez les analyses r\u00e9ussies\n",
        "\n",
        "**\u274c \u00c9vitez:**\n",
        "- Images trop petites ou de mauvaise qualit\u00e9\n",
        "- Prompts vagues ou g\u00e9n\u00e9riques\n",
        "- Oublier le contexte \u00e9ducatif\n",
        "- Ignorer les limitations du mod\u00e8le\n",
        "- Ne pas v\u00e9rifier la factualit\u00e9\n",
        "\n",
        "### \ud83d\udd17 Ressources compl\u00e9mentaires\n",
        "\n",
        "- **Documentation OpenRouter** : [openrouter.ai](https://openrouter.ai)\n",
        "- **Guide GPT-5** : Capacit\u00e9s multimodales\n",
        "- **Templates \u00e9ducatifs** : `docs/genai-phase2-templates.md`\n",
        "- **Standards CoursIA** : `docs/genai-images-development-standards.md`"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\ud83c\udf93 CAS D'USAGE P\u00c9DAGOGIQUES GPT-5\n",
            "=============================================\n",
            "\n",
            "\ud83d\udcda **Histoire**\n",
            "   \ud83d\udccb Analyse de documents historiques, \u0153uvres d'art, monuments\n",
            "   \ud83d\udca1 Exemple: Analyser une fresque renaissance pour comprendre le contexte social\n",
            "   \ud83d\udcdd Template de prompt disponible\n",
            "\n",
            "\ud83d\udcda **Sciences**\n",
            "   \ud83d\udccb Analyse d'exp\u00e9riences, sch\u00e9mas scientifiques, ph\u00e9nom\u00e8nes naturels\n",
            "   \ud83d\udca1 Exemple: Expliquer un diagramme de cellule ou une r\u00e9action chimique\n",
            "   \ud83d\udcdd Template de prompt disponible\n",
            "\n",
            "\ud83d\udcda **G\u00e9ographie**\n",
            "   \ud83d\udccb \u00c9tude de paysages, cartes, ph\u00e9nom\u00e8nes g\u00e9ologiques\n",
            "   \ud83d\udca1 Exemple: Analyser une photo satellite ou un paysage g\u00e9ographique\n",
            "   \ud83d\udcdd Template de prompt disponible\n",
            "\n",
            "\ud83d\udcda **Art et Culture**\n",
            "   \ud83d\udccb Critique artistique, analyse stylistique, histoire de l'art\n",
            "   \ud83d\udca1 Exemple: Comprendre les techniques d'un tableau impressionniste\n",
            "   \ud83d\udcdd Template de prompt disponible\n",
            "\n",
            "\ud83d\udcda **M\u00e9decine**\n",
            "   \ud83d\udccb Analyse d'imagerie m\u00e9dicale, anatomie, cas cliniques\n",
            "   \ud83d\udca1 Exemple: Expliquer une radiographie ou un sch\u00e9ma anatomique\n",
            "   \ud83d\udcdd Template de prompt disponible\n",
            "\n",
            "\ud83c\udfaf Avantages GPT-5 pour l'\u00e9ducation:\n",
            "\u2022 **Multimodal** : Analyse texte + image simultan\u00e9e\n",
            "\u2022 **Contextuel** : Comprend le niveau \u00e9ducatif\n",
            "\u2022 **Adaptable** : Ajuste le vocabulaire selon l'audience\n",
            "\u2022 **Interactif** : Permet les questions de suivi\n",
            "\u2022 **Pr\u00e9cis** : Analyse d\u00e9taill\u00e9e et factuelle\n",
            "\n",
            "\ud83d\udcdd Exemple de workflow p\u00e9dagogique:\n",
            "1. S\u00e9lection d'image pertinente au cours\n",
            "2. Analyse GPT-5 avec prompt \u00e9ducatif\n",
            "3. G\u00e9n\u00e9ration de questions pour les \u00e9tudiants\n",
            "4. Discussion interactive bas\u00e9e sur l'analyse\n",
            "5. \u00c9valuation de la compr\u00e9hension\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "genai": {
      "dependencies": [
        "openai",
        "requests",
        "pillow",
        "matplotlib",
        "base64"
      ],
      "difficulty": "beginner",
      "enabled": true,
      "estimated_duration_minutes": 30,
      "learning_outcomes": [
        "Utiliser GPT-5 pour analyse et description d'images",
        "Ma\u00eetriser les conversations multimodales",
        "Comprendre les capacit\u00e9s visuelles de GPT-5",
        "Int\u00e9grer GPT-5 dans workflows p\u00e9dagogiques",
        "Optimiser les prompts pour l'analyse visuelle"
      ],
      "level": "foundation",
      "module": "01-Images-Foundation"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}