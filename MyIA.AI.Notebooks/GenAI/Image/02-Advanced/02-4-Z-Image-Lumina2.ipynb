{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Z-Image (Lumina-2) : Generation Avancee avec ComfyUI\n\n**Module :** 02-Images-Advanced\n**Niveau :** Avance\n**Duree estimee :** 30 minutes\n**Statut :** FONCTIONNEL\n\n## Introduction\n\nZ-Image utilise l'architecture **Lumina-Next-SFT** via le wrapper Diffusers pour la generation d'images haute qualite. Ce notebook utilise le node `LuminaDiffusersNode` qui integre le pipeline HuggingFace Diffusers directement dans ComfyUI.\n\n### Architecture\n\n| Composant | Details |\n|-----------|---------|\n| **Pipeline** | LuminaPipeline (diffusers 0.34+) |\n| **Modele** | Alpha-VLLM/Lumina-Next-SFT-diffusers (~10GB) |\n| **VAE** | SDXL VAE (sdxl_vae.safetensors) |\n| **Resolution** | 1024x1024 (natif) |\n\n### Note sur l'approche GGUF\n\nL'approche GGUF (z_image_turbo + gemma CLIP) a ete abandonnee en raison d'incompatibilites dimensionnelles (2560 vs 2304 entre RecurrentGemma et Gemma-2).\n\n## Prerequis\n- Service `comfyui-qwen` actif\n- Node installe : LuminaDiffusersNode (ComfyUI-Lumina-Next-SFT-DiffusersWrapper)\n- VAE : sdxl_vae.safetensors dans models/vae/",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 1. Configuration de l'environnement\nimport os\nimport requests\nimport json\nimport time\nfrom PIL import Image\nfrom io import BytesIO\nfrom dotenv import load_dotenv\nimport matplotlib.pyplot as plt\n\n# Chargement des variables d'environnement\n# Cherche le .env dans plusieurs emplacements possibles\nload_dotenv()  # Charge .env du repertoire courant\nload_dotenv(\"../../.env\")  # Charge le .env racine GenAI\nload_dotenv(\"../00-GenAI-Environment/.env\")  # Fallback ancien chemin\n\n# URL du serveur ComfyUI (par defaut: service myia.io pour etudiants)\nCOMFYUI_URL = os.getenv(\"COMFYUI_API_URL\", \"https://qwen-image-edit.myia.io\")\nCOMFYUI_TOKEN = os.getenv(\"COMFYUI_AUTH_TOKEN\") or os.getenv(\"COMFYUI_API_TOKEN\")\n\nif not COMFYUI_TOKEN:\n    raise ValueError(\"Token COMFYUI_AUTH_TOKEN ou COMFYUI_API_TOKEN manquant dans le fichier .env\")\n\nHEADERS = {\"Authorization\": f\"Bearer {COMFYUI_TOKEN}\"}\n\nprint(\"Configuration chargee\")\nprint(f\"Target URL: {COMFYUI_URL}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration chargee\n",
            "Target URL: https://qwen-image-edit.myia.io\n"
          ]
        }
      ],
      "source": "# 2. Definition du Workflow Z-Image (Diffusers)\n# Ce workflow utilise LuminaDiffusersNode qui telecharge automatiquement\n# le modele depuis HuggingFace (Alpha-VLLM/Lumina-Next-SFT-diffusers)\n\ndef create_zimage_workflow(prompt: str, \n                           negative_prompt: str = \"blurry, low quality, text, watermark\",\n                           width: int = 1024, \n                           height: int = 1024,\n                           steps: int = 30,\n                           guidance: float = 4.0,\n                           seed: int = None) -> dict:\n    \"\"\"\n    Cree un workflow Z-Image avec le wrapper Diffusers.\n    \n    Args:\n        prompt: Description de l'image a generer\n        negative_prompt: Elements a eviter\n        width/height: Dimensions (1024x1024 recommande)\n        steps: Etapes de diffusion (20-40 optimal)\n        guidance: Guidance scale (3-5 optimal pour Lumina)\n        seed: Graine pour reproductibilite (-1 = aleatoire)\n    \n    Returns:\n        Workflow JSON pret pour ComfyUI\n    \"\"\"\n    if seed is None:\n        seed = -1  # -1 = random dans LuminaDiffusersNode\n    \n    return {\n        # LuminaDiffusersNode - Le coeur de la generation\n        # Note: Le node gere en interne la resolution via le scheduler\n        \"1\": {\n            \"class_type\": \"LuminaDiffusersNode\",\n            \"inputs\": {\n                \"model_path\": \"Alpha-VLLM/Lumina-Next-SFT-diffusers\",\n                \"prompt\": prompt,\n                \"negative_prompt\": negative_prompt,\n                \"num_inference_steps\": steps,\n                \"guidance_scale\": guidance,\n                \"seed\": seed,\n                \"batch_size\": 1,\n                \"scaling_watershed\": 0.3,\n                \"proportional_attn\": True,\n                \"clean_caption\": True,\n                \"max_sequence_length\": 256,\n                \"use_time_shift\": False,\n                \"t_shift\": 4,\n                \"strength\": 1.0\n            }\n        },\n        # VAELoader - SDXL VAE pour le decodage\n        \"2\": {\n            \"class_type\": \"VAELoader\",\n            \"inputs\": {\n                \"vae_name\": \"sdxl_vae.safetensors\"\n            }\n        },\n        # VAEDecode - Conversion latent vers image\n        \"3\": {\n            \"class_type\": \"VAEDecode\",\n            \"inputs\": {\n                \"samples\": [\"1\", 0],\n                \"vae\": [\"2\", 0]\n            }\n        },\n        # SaveImage - Sauvegarde du resultat\n        \"4\": {\n            \"class_type\": \"SaveImage\",\n            \"inputs\": {\n                \"filename_prefix\": \"Z-Image-Lumina\",\n                \"images\": [\"3\", 0]\n            }\n        }\n    }\n\n# Workflow de test basique\nz_image_workflow = create_zimage_workflow(\n    prompt=\"A vibrant sunset over a mountain lake, reflection in water, photorealistic\",\n    steps=20,\n    guidance=4.0,\n    seed=42\n)\n\nprint(\"Workflow Z-Image (Diffusers) defini\")\nprint(\"  - Node principal: LuminaDiffusersNode\")\nprint(\"  - Modele: Alpha-VLLM/Lumina-Next-SFT-diffusers\")\nprint(\"  - VAE: SDXL\")\nprint(\"  - Output node: '4'\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workflow Z-Image (Diffusers) defini\n",
            "  - Node principal: LuminaDiffusersNode\n",
            "  - Modele: Alpha-VLLM/Lumina-Next-SFT-diffusers\n",
            "  - VAE: SDXL\n",
            "  - Output node: '4'\n"
          ]
        }
      ],
      "source": "# 3. Fonction de Generation Helper\ndef generate_z_image(prompt, seed=None, steps=20, guidance=4.0, width=1024, height=1024):\n    \"\"\"\n    Genere une image avec Z-Image (Lumina Diffusers).\n    \n    Args:\n        prompt: Description de l'image\n        seed: Graine pour reproductibilite (None/-1 = aleatoire)\n        steps: Nombre d'etapes (20-40 recommande)\n        guidance: Guidance scale (3-5 recommande)\n        width/height: Dimensions\n    \n    Returns:\n        PIL.Image ou None en cas d'erreur\n    \"\"\"\n    if seed is None:\n        seed = -1\n    \n    # Creer le workflow\n    workflow = create_zimage_workflow(\n        prompt=prompt,\n        seed=seed,\n        steps=steps,\n        guidance=guidance,\n        width=width,\n        height=height\n    )\n    \n    payload = {\"prompt\": workflow}\n    \n    print(f\"Envoi de la requete... (Seed: {seed})\")\n    resp = requests.post(f\"{COMFYUI_URL}/prompt\", json=payload, headers=HEADERS)\n    \n    if resp.status_code != 200:\n        print(f\"Erreur API: {resp.text}\")\n        return None\n        \n    prompt_id = resp.json()[\"prompt_id\"]\n    print(f\"Tache ID: {prompt_id}\")\n    print(\"Generation en cours (premiere execution peut prendre plusieurs minutes pour telecharger le modele)...\")\n    \n    # Polling avec timeout etendu (premier run telecharge ~10GB)\n    max_wait = 600  # 10 minutes pour le premier run\n    start_time = time.time()\n    \n    while time.time() - start_time < max_wait:\n        history_resp = requests.get(f\"{COMFYUI_URL}/history/{prompt_id}\", headers=HEADERS)\n        if history_resp.status_code == 200:\n            history_data = history_resp.json()\n            if prompt_id in history_data:\n                prompt_data = history_data[prompt_id]\n                status = prompt_data.get('status', {})\n                \n                if status.get('completed'):\n                    elapsed = time.time() - start_time\n                    print(f\"Generation terminee en {elapsed:.1f}s\")\n                    \n                    # Recuperation image (node 4 = SaveImage)\n                    outputs = prompt_data.get('outputs', {})\n                    if '4' in outputs and 'images' in outputs['4']:\n                        output_data = outputs['4']['images'][0]\n                        filename = output_data['filename']\n                        subfolder = output_data.get('subfolder', '')\n                        img_type = output_data.get('type', 'output')\n                        \n                        img_url = f\"{COMFYUI_URL}/view?filename={filename}&subfolder={subfolder}&type={img_type}\"\n                        img_resp = requests.get(img_url, headers=HEADERS)\n                        \n                        if img_resp.status_code == 200:\n                            return Image.open(BytesIO(img_resp.content))\n                    \n                    print(\"Pas d'image dans les outputs\")\n                    return None\n                    \n                if status.get('status_str') == 'error':\n                    print(f\"Erreur: {status.get('messages', 'Unknown')}\")\n                    return None\n        \n        time.sleep(2)\n    \n    print(f\"Timeout apres {max_wait}s\")\n    return None"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 4. Test de Generation\n# Note: La premiere execution telecharge le modele (~10GB), prevoir 5-10 minutes\n\nprompt = \"Cinematic photography of a samurai robot in a neon cyberpunk city, raining, reflections, 8k, highly detailed\"\n\nprint(\"Lancement de la generation Z-Image (Lumina Diffusers)...\")\nprint(f\"Prompt: {prompt}\")\nprint(\"\\nNote: Le premier lancement telecharge le modele (~10GB)\")\n\nimage = generate_z_image(prompt, seed=42, steps=20, guidance=4.0)\n\nif image:\n    plt.figure(figsize=(10, 10))\n    plt.imshow(image)\n    plt.title(f\"Z-Image: {prompt[:50]}...\", fontsize=10)\n    plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nImage generee: {image.size[0]}x{image.size[1]}\")\nelse:\n    print(\"\\nEchec de la generation. Verifiez:\")\n    print(\"  1. Le service ComfyUI est actif\")\n    print(\"  2. Le node LuminaDiffusersNode est installe\")\n    print(\"  3. Le VAE SDXL est present dans models/vae/\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Exercices\n\n### Exercice 1: Exploration des parametres\nTestez differentes valeurs de guidance (2.0, 4.0, 6.0) avec le meme prompt et seed pour observer l'impact sur la fidelite au prompt.\n\n### Exercice 2: Comparaison de styles\nGenerez des images avec des styles differents:\n- \"A peaceful mountain lake at sunrise, photorealistic\"\n- \"A peaceful mountain lake at sunrise, watercolor painting style\"\n- \"A peaceful mountain lake at sunrise, anime style\"\n\n### Exercice 3: Resolution\nTestez differentes resolutions (512x512, 768x768, 1024x1024) et observez l'impact sur la qualite et le temps de generation.\n\n## Notes Techniques\n\n### Parametres recommandes\n| Parametre | Plage | Recommande | Impact |\n|-----------|-------|------------|--------|\n| steps | 15-50 | 20-30 | Qualite vs vitesse |\n| guidance | 2-7 | 3-5 | Fidelite au prompt |\n| scaling_watershed | 0.0-1.0 | 0.3 | Reduction saturation |\n\n### Differences avec Qwen\n- **Lumina/Z-Image**: Generation text-to-image de haute qualite, meilleur pour scenes complexes\n- **Qwen**: Specialise dans l'edition d'images existantes, image-to-image\n- Lumina utilise un VAE 4-channel SDXL, Qwen utilise un VAE 16-channel\n\n### Premier lancement\nLe premier lancement telecharge automatiquement le modele (~10GB) depuis HuggingFace.\nCela peut prendre 5-10 minutes selon votre connexion.\n\n### Fix technique (Janvier 2025)\nLe node `LuminaDiffusersNode` a ete mis a jour pour utiliser `LuminaPipeline` au lieu de\n`LuminaText2ImgPipeline` (renomme dans diffusers 0.34+).",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lancement de la generation Z-Image (Lumina Diffusers)...\n",
            "Prompt: Cinematic photography of a samurai robot in a neon cyberpunk city, raining, reflections, 8k, highly detailed\n",
            "\n",
            "Note: Le premier lancement telecharge le modele (~10GB)\n",
            "Envoi de la requete... (Seed: 42)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Erreur API: <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\"> \n",
            "<html xmlns=\"http://www.w3.org/1999/xhtml\"> \n",
            "<head> \n",
            "<title>IIS 10.0 Detailed Error - 502.3 - Bad Gateway</title> \n",
            "<style type=\"text/css\"> \n",
            "<!-- \n",
            "body{margin:0;font-size:.7em;font-family:Verdana,Arial,Helvetica,sans-serif;} \n",
            "code{margin:0;color:#006600;font-size:1.1em;font-weight:bold;} \n",
            ".config_source code{font-size:.8em;color:#000000;} \n",
            "pre{margin:0;font-size:1.4em;word-wrap:break-word;} \n",
            "ul,ol{margin:10px 0 10px 5px;} \n",
            "ul.first,ol.first{margin-top:5px;} \n",
            "fieldset{padding:0 15px 10px 15px;word-break:break-all;} \n",
            ".summary-container fieldset{padding-bottom:5px;margin-top:4px;} \n",
            "legend.no-expand-all{padding:2px 15px 4px 10px;margin:0 0 0 -12px;} \n",
            "legend{color:#333333;;margin:4px 0 8px -12px;_margin-top:0px; \n",
            "font-weight:bold;font-size:1em;} \n",
            "a:link,a:visited{color:#007EFF;font-weight:bold;} \n",
            "a:hover{text-decoration:none;} \n",
            "h1{font-size:2.4em;margin:0;color:#FFF;} \n",
            "h2{font-size:1.7em;margin:0;color:#CC0000;} \n",
            "h3{font-size:1.4em;margin:10px 0 0 0;color:#CC0000;} \n",
            "h4{font-size:1.2em;margin:10px 0 5px 0; \n",
            "}#header{width:96%;margin:0 0 0 0;padding:6px 2% 6px 2%;font-family:\"trebuchet MS\",Verdana,sans-serif; \n",
            " color:#FFF;background-color:#5C87B2; \n",
            "}#content{margin:0 0 0 2%;position:relative;} \n",
            ".summary-container,.content-container{background:#FFF;width:96%;margin-top:8px;padding:10px;position:relative;} \n",
            ".content-container p{margin:0 0 10px 0; \n",
            "}#details-left{width:35%;float:left;margin-right:2%; \n",
            "}#details-right{width:63%;float:left;overflow:hidden; \n",
            "}#server_version{width:96%;_height:1px;min-height:1px;margin:0 0 5px 0;padding:11px 2% 8px 2%;color:#FFFFFF; \n",
            " background-color:#5A7FA5;border-bottom:1px solid #C1CFDD;border-top:1px solid #4A6C8E;font-weight:normal; \n",
            " font-size:1em;color:#FFF;text-align:right; \n",
            "}#server_version p{margin:5px 0;} \n",
            "table{margin:4px 0 4px 0;width:100%;border:none;} \n",
            "td,th{vertical-align:top;padding:3px 0;text-align:left;font-weight:normal;border:none;} \n",
            "th{width:30%;text-align:right;padding-right:2%;font-weight:bold;} \n",
            "thead th{background-color:#ebebeb;width:25%; \n",
            "}#details-right th{width:20%;} \n",
            "table tr.alt td,table tr.alt th{} \n",
            ".highlight-code{color:#CC0000;font-weight:bold;font-style:italic;} \n",
            ".clear{clear:both;} \n",
            ".preferred{padding:0 5px 2px 5px;font-weight:normal;background:#006633;color:#FFF;font-size:.8em;} \n",
            "--> \n",
            "</style> \n",
            " \n",
            "</head> \n",
            "<body> \n",
            "<div id=\"content\"> \n",
            "<div class=\"content-container\"> \n",
            "  <h3>HTTP Error 502.3 - Bad Gateway</h3> \n",
            "  <h4>Impossible d\u2019\u00e9tablir une connexion avec le serveur\r\n",
            "</h4> \n",
            "</div> \n",
            "<div class=\"content-container\"> \n",
            " <fieldset><h4>Most likely causes:</h4> \n",
            "  <ul> \t<li>The CGI application did not return a valid set of HTTP errors.</li> \t<li>A server acting as a proxy or gateway was unable to process the request due to an error in a parent gateway.</li> </ul> \n",
            " </fieldset> \n",
            "</div> \n",
            "<div class=\"content-container\"> \n",
            " <fieldset><h4>Things you can try:</h4> \n",
            "  <ul> \t<li>Use DebugDiag to troubleshoot the CGI application.</li> \t<li>Determine if a proxy or gateway is responsible for this error.</li> </ul> \n",
            " </fieldset> \n",
            "</div> \n",
            " \n",
            "<div class=\"content-container\"> \n",
            " <fieldset><h4>Detailed Error Information:</h4> \n",
            "  <div id=\"details-left\"> \n",
            "   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\"> \n",
            "    <tr class=\"alt\"><th>Module</th><td>&nbsp;&nbsp;&nbsp;ApplicationRequestRouting</td></tr> \n",
            "    <tr><th>Notification</th><td>&nbsp;&nbsp;&nbsp;ExecuteRequestHandler</td></tr> \n",
            "    <tr class=\"alt\"><th>Handler</th><td>&nbsp;&nbsp;&nbsp;ApplicationRequestRoutingHandler</td></tr> \n",
            "    <tr><th>Error Code</th><td>&nbsp;&nbsp;&nbsp;0x80072efd</td></tr> \n",
            "     \n",
            "   </table> \n",
            "  </div> \n",
            "  <div id=\"details-right\"> \n",
            "   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\"> \n",
            "    <tr class=\"alt\"><th>Requested URL</th><td>&nbsp;&nbsp;&nbsp;https://qwen-image-edit.myia.io:443/prompt</td></tr> \n",
            "    <tr><th>Physical Path</th><td>&nbsp;&nbsp;&nbsp;D:\\Production\\qwen-image-edit.myia.io\\prompt</td></tr> \n",
            "    <tr class=\"alt\"><th>Logon Method</th><td>&nbsp;&nbsp;&nbsp;Anonymous</td></tr> \n",
            "    <tr><th>Logon User</th><td>&nbsp;&nbsp;&nbsp;Anonymous</td></tr> \n",
            "     \n",
            "   </table> \n",
            "   <div class=\"clear\"></div> \n",
            "  </div> \n",
            " </fieldset> \n",
            "</div> \n",
            " \n",
            "<div class=\"content-container\"> \n",
            " <fieldset><h4>More Information:</h4> \n",
            "  This error occurs when a CGI application does not return a valid set of HTTP headers, or when a proxy or gateway was unable to send the request to a parent gateway. You may need to get a network trace or contact the proxy server administrator, if it is not a CGI problem. \n",
            "  <p><a href=\"https://go.microsoft.com/fwlink/?LinkID=62293&amp;IIS70Error=502,3,0x80072efd,26100\">View more information &raquo;</a></p> \n",
            "   \n",
            " </fieldset> \n",
            "</div> \n",
            "</div> \n",
            "</body> \n",
            "</html> \n",
            "\n",
            "\n",
            "Echec de la generation. Verifiez:\n",
            "  1. Le service ComfyUI est actif\n",
            "  2. Le node LuminaDiffusersNode est installe\n",
            "  3. Le VAE SDXL est present dans models/vae/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}