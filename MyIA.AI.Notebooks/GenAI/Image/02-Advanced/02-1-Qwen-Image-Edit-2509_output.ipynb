{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74016523",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [5]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e937913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:03:03.132619Z",
     "iopub.status.busy": "2026-02-18T09:03:03.132379Z",
     "iopub.status.idle": "2026-02-18T09:03:03.135864Z",
     "shell.execute_reply": "2026-02-18T09:03:03.135276Z"
    },
    "papermill": {
     "duration": 0.008936,
     "end_time": "2026-02-18T09:03:03.137061",
     "exception": false,
     "start_time": "2026-02-18T09:03:03.128125",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "notebook_mode = \"batch\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {
    "papermill": {
     "duration": 0.002509,
     "end_time": "2026-02-18T09:03:03.142607",
     "exception": false,
     "start_time": "2026-02-18T09:03:03.140098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Qwen Image Edit 2509 - Ã‰dition AvancÃ©e d'Images\n",
    "\n",
    "**Module :** 02-Images-Advanced  \n",
    "**Niveau :** IntermÃ©diaire/AvancÃ©  \n",
    "**DurÃ©e estimÃ©e :** 45 minutes  \n",
    "\n",
    "## Introduction\n",
    "\n",
    "Ce notebook explore les capacitÃ©s avancÃ©es de **Qwen-Image-Edit 2509** (version Septembre 2025), un modÃ¨le d'Ã©dition d'images de pointe intÃ©grÃ© via ComfyUI. Par rapport au notebook d'introduction (01-5), nous abordons ici :\n",
    "\n",
    "- **Ã‰dition prÃ©cise de texte** dans les images\n",
    "- **Inpainting avancÃ©** avec masques personnalisÃ©s\n",
    "- **Workflows multi-Ã©tapes** pour des transformations complexes\n",
    "- **Batch processing** pour l'efficacitÃ©\n",
    "- **Analyse comparative** des paramÃ¨tres\n",
    "\n",
    "### Architecture Qwen-Image-Edit 2509\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              Qwen-Image-Edit 2509 Pipeline              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Image Input â†’ Qwen2.5-VL Encoder â†’ Diffusion Model    â”‚\n",
    "â”‚       â†“              â†“                    â†“             â”‚\n",
    "â”‚  [Tokenizer]    [16-ch VAE]        [UNet 1024Â²]        â”‚\n",
    "â”‚       â†“              â†“                    â†“             â”‚\n",
    "â”‚   Text Prompt â†’ Cross-Attention â†’ Latent Space         â”‚\n",
    "â”‚                                        â†“                â”‚\n",
    "â”‚                               VAE Decode â†’ Output      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## PrÃ©requis\n",
    "\n",
    "- Module 00-GenAI-Environment complÃ©tÃ©\n",
    "- Service `comfyui-qwen` actif (`docker compose up -d`)\n",
    "- Notebook 01-5-Qwen-Image-Edit terminÃ© (concepts de base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dw2367dvov",
   "metadata": {
    "papermill": {
     "duration": 0.002926,
     "end_time": "2026-02-18T09:03:03.148158",
     "exception": false,
     "start_time": "2026-02-18T09:03:03.145232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Navigation** : [Index](../../README.md) | [<< Precedent](../01-Foundation/01-5-Qwen-Image-Edit.ipynb) | [Suivant >>](02-2-FLUX-1-Advanced-Generation.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "# Qwen Image Edit 2509 - Ã‰dition AvancÃ©e d'Images\n",
    "\n",
    "**Module :** 02-Images-Advanced  \n",
    "**Niveau :** IntermÃ©diaire/AvancÃ©  \n",
    "**DurÃ©e estimÃ©e :** 45 minutes  \n",
    "\n",
    "## Objectifs d'apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous saurez :\n",
    "1. Maitriser l'architecture Phase 29 de Qwen-Image-Edit 2509\n",
    "2. Comprendre l'impact du parametre `denoise` sur l'edition d'images\n",
    "3. Implementer l'inpainting avec des masques personnalises\n",
    "4. Optimiser le traitement par lots (batch processing)\n",
    "5. Analyser l'effet du parametre CFG avec CFGNorm\n",
    "\n",
    "### Prerequis\n",
    "\n",
    "- Module 00-GenAI-Environment complÃ©tÃ©\n",
    "- Service `comfyui-qwen` actif (`docker compose up -d`)\n",
    "- Notebook 01-5-Qwen-Image-Edit terminÃ© (concepts de base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:03:03.154733Z",
     "iopub.status.busy": "2026-02-18T09:03:03.154364Z",
     "iopub.status.idle": "2026-02-18T09:03:03.979641Z",
     "shell.execute_reply": "2026-02-18T09:03:03.978989Z"
    },
    "papermill": {
     "duration": 0.829935,
     "end_time": "2026-02-18T09:03:03.980622",
     "exception": false,
     "start_time": "2026-02-18T09:03:03.150687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen-Image-Edit 2509 - Edition Avancee\n",
      "\n",
      "Date: 2026-02-18 10:03:03\n",
      "API URL: https://qwen-image-edit.myia.io\n",
      "Token: Configure\n",
      ".env: charge\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. CONFIGURATION ET IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chargement variables d'environnement\n",
    "# Recherche du .env en remontant l'arborescence (plus robuste que chemins relatifs)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_path = Path.cwd()\n",
    "found_env = False\n",
    "for _ in range(5):  # Remonter jusqu'a 5 niveaux\n",
    "    env_path = current_path / '.env'\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        found_env = True\n",
    "        break\n",
    "    current_path = current_path.parent\n",
    "\n",
    "if not found_env:\n",
    "    # Fallback: essayer des chemins relatifs connus\n",
    "    for fallback in [\"../../.env\", \"../.env\", \"../00-GenAI-Environment/.env\"]:\n",
    "        if Path(fallback).exists():\n",
    "            load_dotenv(fallback)\n",
    "            found_env = True\n",
    "            break\n",
    "\n",
    "# Configuration ComfyUI\n",
    "# URL par defaut: service myia.io pour etudiants\n",
    "COMFYUI_URL = os.getenv(\"COMFYUI_API_URL\", \"https://qwen-image-edit.myia.io\")\n",
    "# Support des deux noms de variable pour le token\n",
    "COMFYUI_TOKEN = os.getenv(\"COMFYUI_AUTH_TOKEN\") or os.getenv(\"COMFYUI_API_TOKEN\")\n",
    "CLIENT_ID = str(uuid.uuid4())\n",
    "\n",
    "# Validation\n",
    "if not COMFYUI_TOKEN:\n",
    "    raise ValueError(\"COMFYUI_AUTH_TOKEN ou COMFYUI_API_TOKEN manquant dans .env\")\n",
    "\n",
    "print(\"Qwen-Image-Edit 2509 - Edition Avancee\")\n",
    "print(f\"\\nDate: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"API URL: {COMFYUI_URL}\")\n",
    "print(f\"Token: {'Configure' if COMFYUI_TOKEN else 'Manquant'}\")\n",
    "if found_env:\n",
    "    print(f\".env: charge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:03:03.987827Z",
     "iopub.status.busy": "2026-02-18T09:03:03.987531Z",
     "iopub.status.idle": "2026-02-18T09:03:08.065528Z",
     "shell.execute_reply": "2026-02-18T09:03:08.064853Z"
    },
    "papermill": {
     "duration": 4.082862,
     "end_time": "2026-02-18T09:03:08.066586",
     "exception": false,
     "start_time": "2026-02-18T09:03:03.983724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¥ Ã‰tat du service: error\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. CLIENT COMFYUI AVANCÃ‰\n",
    "# =============================================================================\n",
    "\n",
    "class QwenImageEditClient:\n",
    "    \"\"\"\n",
    "    Client avancÃ© pour Qwen-Image-Edit via ComfyUI.\n",
    "    Supporte l'authentification, le batch processing et les workflows multi-Ã©tapes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = COMFYUI_URL, auth_token: str = COMFYUI_TOKEN):\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.client_id = str(uuid.uuid4())\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        if auth_token:\n",
    "            self.session.headers.update({\"Authorization\": f\"Bearer {auth_token}\"})\n",
    "    \n",
    "    def check_health(self) -> Dict[str, Any]:\n",
    "        \"\"\"VÃ©rifie la santÃ© du service ComfyUI.\"\"\"\n",
    "        try:\n",
    "            resp = self.session.get(f\"{self.base_url}/system_stats\", timeout=10)\n",
    "            if resp.status_code == 200:\n",
    "                stats = resp.json()\n",
    "                return {\n",
    "                    \"status\": \"healthy\",\n",
    "                    \"vram_free\": stats.get(\"devices\", [{}])[0].get(\"vram_free\", 0) / 1e9,\n",
    "                    \"vram_total\": stats.get(\"devices\", [{}])[0].get(\"vram_total\", 0) / 1e9\n",
    "                }\n",
    "            return {\"status\": \"error\", \"code\": resp.status_code}\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"unreachable\", \"error\": str(e)}\n",
    "    \n",
    "    def upload_image(self, image: Image.Image, name: str = \"input.png\") -> str:\n",
    "        \"\"\"Upload une image vers ComfyUI.\"\"\"\n",
    "        buffer = BytesIO()\n",
    "        image.save(buffer, format=\"PNG\")\n",
    "        buffer.seek(0)\n",
    "        \n",
    "        files = {\"image\": (name, buffer, \"image/png\")}\n",
    "        data = {\"overwrite\": \"true\"}\n",
    "        \n",
    "        resp = self.session.post(f\"{self.base_url}/upload/image\", files=files, data=data)\n",
    "        if resp.status_code == 200:\n",
    "            return resp.json().get(\"name\", name)\n",
    "        raise Exception(f\"Upload failed: {resp.text}\")\n",
    "    \n",
    "    def upload_mask(self, mask: Image.Image, name: str = \"mask.png\") -> str:\n",
    "        \"\"\"Upload un masque pour l'inpainting.\"\"\"\n",
    "        # Convertir en grayscale si nÃ©cessaire\n",
    "        if mask.mode != 'L':\n",
    "            mask = mask.convert('L')\n",
    "        return self.upload_image(mask, name)\n",
    "    \n",
    "    def queue_workflow(self, workflow: Dict) -> str:\n",
    "        \"\"\"Soumet un workflow et retourne le prompt_id.\"\"\"\n",
    "        payload = {\"prompt\": workflow, \"client_id\": self.client_id}\n",
    "        resp = self.session.post(f\"{self.base_url}/prompt\", json=payload)\n",
    "        \n",
    "        if resp.status_code != 200:\n",
    "            raise Exception(f\"Queue failed: {resp.text}\")\n",
    "        return resp.json()[\"prompt_id\"]\n",
    "    \n",
    "    def wait_for_completion(self, prompt_id: str, timeout: int = 120) -> Dict:\n",
    "        \"\"\"Attend la fin d'un workflow avec timeout.\"\"\"\n",
    "        start = time.time()\n",
    "        while time.time() - start < timeout:\n",
    "            resp = self.session.get(f\"{self.base_url}/history/{prompt_id}\")\n",
    "            if resp.status_code == 200:\n",
    "                history = resp.json()\n",
    "                if prompt_id in history:\n",
    "                    return history[prompt_id]\n",
    "            time.sleep(1)\n",
    "        raise TimeoutError(f\"Workflow {prompt_id} timeout after {timeout}s\")\n",
    "    \n",
    "    def get_image(self, filename: str, subfolder: str = \"\", img_type: str = \"output\") -> Image.Image:\n",
    "        \"\"\"RÃ©cupÃ¨re une image gÃ©nÃ©rÃ©e.\"\"\"\n",
    "        params = {\"filename\": filename, \"subfolder\": subfolder, \"type\": img_type}\n",
    "        resp = self.session.get(f\"{self.base_url}/view\", params=params)\n",
    "        if resp.status_code == 200:\n",
    "            return Image.open(BytesIO(resp.content))\n",
    "        raise Exception(f\"Failed to get image: {resp.text}\")\n",
    "    \n",
    "    def execute_and_get_images(self, workflow: Dict, output_node: str = \"9\", \n",
    "                                timeout: int = 120, verbose: bool = True) -> List[Image.Image]:\n",
    "        \"\"\"ExÃ©cute un workflow et retourne les images gÃ©nÃ©rÃ©es.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"ğŸš€ Soumission du workflow...\")\n",
    "        \n",
    "        prompt_id = self.queue_workflow(workflow)\n",
    "        if verbose:\n",
    "            print(f\"ğŸ“‹ ID: {prompt_id}\")\n",
    "            print(\"â³ GÃ©nÃ©ration en cours...\", end=\"\", flush=True)\n",
    "        \n",
    "        result = self.wait_for_completion(prompt_id, timeout)\n",
    "        if verbose:\n",
    "            print(\" âœ…\")\n",
    "        \n",
    "        # Extraire les images\n",
    "        images = []\n",
    "        if \"outputs\" in result and output_node in result[\"outputs\"]:\n",
    "            for img_data in result[\"outputs\"][output_node].get(\"images\", []):\n",
    "                img = self.get_image(\n",
    "                    img_data[\"filename\"],\n",
    "                    img_data.get(\"subfolder\", \"\"),\n",
    "                    img_data.get(\"type\", \"output\")\n",
    "                )\n",
    "                images.append(img)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ–¼ï¸ {len(images)} image(s) rÃ©cupÃ©rÃ©e(s)\")\n",
    "        return images\n",
    "\n",
    "# Instanciation du client\n",
    "client = QwenImageEditClient()\n",
    "\n",
    "# Test de connexion\n",
    "health = client.check_health()\n",
    "print(f\"\\nğŸ¥ Ã‰tat du service: {health['status']}\")\n",
    "if health['status'] == 'healthy':\n",
    "    print(f\"   VRAM: {health['vram_free']:.1f} / {health['vram_total']:.1f} GB libre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:03:08.072610Z",
     "iopub.status.busy": "2026-02-18T09:03:08.072410Z",
     "iopub.status.idle": "2026-02-18T09:03:08.083624Z",
     "shell.execute_reply": "2026-02-18T09:03:08.082898Z"
    },
    "papermill": {
     "duration": 0.015759,
     "end_time": "2026-02-18T09:03:08.084883",
     "exception": false,
     "start_time": "2026-02-18T09:03:08.069124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflows Qwen-Image-Edit 2509 definis (Architecture Phase 29)\n",
      "   - create_text2img_workflow() -> node output: '11'\n",
      "   - create_img2img_workflow() -> node output: '12'\n",
      "   - create_inpaint_workflow() -> node output: '14'\n",
      "\n",
      "Notes importantes:\n",
      "   - CFG=1.0 recommande (CFGNorm gere l'amplification)\n",
      "   - Scheduler 'beta' optimise pour Qwen\n",
      "   - 20 steps suffisent pour de bons resultats\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. WORKFLOWS QWEN-IMAGE-EDIT 2509 - ARCHITECTURE PHASE 29\n",
    "# =============================================================================\n",
    "# Ces workflows utilisent l'architecture native ComfyUI validee Phase 29\n",
    "# avec les modeles FP8 officiels Comfy-Org\n",
    "\n",
    "def create_text2img_workflow(prompt: str, \n",
    "                              width: int = 1024, height: int = 1024,\n",
    "                              steps: int = 20, cfg: float = 1.0,\n",
    "                              seed: int = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Workflow Text-to-Image avec Qwen-Image-Edit 2509.\n",
    "    \n",
    "    Architecture Phase 29 validee:\n",
    "    - VAELoader + CLIPLoader + UNETLoader (modeles separes)\n",
    "    - ModelSamplingAuraFlow (shift=3.0) + CFGNorm (strength=1.0)\n",
    "    - TextEncodeQwenImageEdit (encodeur natif Qwen)\n",
    "    - KSampler avec scheduler=beta, sampler=euler, cfg=1.0\n",
    "    \n",
    "    Args:\n",
    "        prompt: Description de l'image a generer\n",
    "        width/height: Dimensions (multiples de 32, defaut 1024)\n",
    "        steps: Nombre d'etapes de diffusion (20 recommande)\n",
    "        cfg: Guidance scale (1.0 recommande pour Qwen avec CFGNorm)\n",
    "        seed: Graine pour reproductibilite\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(0, 2**32)\n",
    "    \n",
    "    return {\n",
    "        # Chargement des modeles\n",
    "        \"1\": {\n",
    "            \"class_type\": \"VAELoader\",\n",
    "            \"inputs\": {\"vae_name\": \"qwen_image_vae.safetensors\"}\n",
    "        },\n",
    "        \"2\": {\n",
    "            \"class_type\": \"CLIPLoader\",\n",
    "            \"inputs\": {\n",
    "                \"clip_name\": \"qwen_2.5_vl_7b_fp8_scaled.safetensors\",\n",
    "                \"type\": \"sd3\"\n",
    "            }\n",
    "        },\n",
    "        \"3\": {\n",
    "            \"class_type\": \"UNETLoader\",\n",
    "            \"inputs\": {\n",
    "                \"unet_name\": \"qwen_image_edit_2509_fp8_e4m3fn.safetensors\",\n",
    "                \"weight_dtype\": \"fp8_e4m3fn\"\n",
    "            }\n",
    "        },\n",
    "        # Configuration modele pour Qwen\n",
    "        \"4\": {\n",
    "            \"class_type\": \"ModelSamplingAuraFlow\",\n",
    "            \"inputs\": {\"model\": [\"3\", 0], \"shift\": 3.0}\n",
    "        },\n",
    "        \"5\": {\n",
    "            \"class_type\": \"CFGNorm\",\n",
    "            \"inputs\": {\"model\": [\"4\", 0], \"strength\": 1.0}\n",
    "        },\n",
    "        # Encodage du prompt avec TextEncodeQwenImageEdit\n",
    "        \"6\": {\n",
    "            \"class_type\": \"TextEncodeQwenImageEdit\",\n",
    "            \"inputs\": {\n",
    "                \"clip\": [\"2\", 0],\n",
    "                \"prompt\": prompt,\n",
    "                \"vae\": [\"1\", 0]\n",
    "            }\n",
    "        },\n",
    "        # Conditioning negatif (vide pour Qwen)\n",
    "        \"7\": {\n",
    "            \"class_type\": \"ConditioningZeroOut\",\n",
    "            \"inputs\": {\"conditioning\": [\"6\", 0]}\n",
    "        },\n",
    "        # Latent vide (16 canaux pour Qwen)\n",
    "        \"8\": {\n",
    "            \"class_type\": \"EmptySD3LatentImage\",\n",
    "            \"inputs\": {\"width\": width, \"height\": height, \"batch_size\": 1}\n",
    "        },\n",
    "        # Sampling\n",
    "        \"9\": {\n",
    "            \"class_type\": \"KSampler\",\n",
    "            \"inputs\": {\n",
    "                \"model\": [\"5\", 0],\n",
    "                \"positive\": [\"6\", 0],\n",
    "                \"negative\": [\"7\", 0],\n",
    "                \"latent_image\": [\"8\", 0],\n",
    "                \"seed\": seed,\n",
    "                \"steps\": steps,\n",
    "                \"cfg\": cfg,\n",
    "                \"sampler_name\": \"euler\",\n",
    "                \"scheduler\": \"beta\",\n",
    "                \"denoise\": 1.0\n",
    "            }\n",
    "        },\n",
    "        # Decodage VAE\n",
    "        \"10\": {\n",
    "            \"class_type\": \"VAEDecode\",\n",
    "            \"inputs\": {\"samples\": [\"9\", 0], \"vae\": [\"1\", 0]}\n",
    "        },\n",
    "        # Sauvegarde\n",
    "        \"11\": {\n",
    "            \"class_type\": \"SaveImage\",\n",
    "            \"inputs\": {\"filename_prefix\": \"Qwen2509_t2i\", \"images\": [\"10\", 0]}\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def create_img2img_workflow(image_name: str, prompt: str, \n",
    "                            denoise: float = 0.7, steps: int = 20,\n",
    "                            cfg: float = 1.0, seed: int = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Workflow Image-to-Image pour l'edition avec Qwen.\n",
    "    \n",
    "    Note: Qwen-Image-Edit 2509 est optimise pour l'edition d'images.\n",
    "    Le parametre denoise controle la force de l'edition:\n",
    "    - 0.3-0.5: Ajustements subtils\n",
    "    - 0.5-0.7: Modifications moderees  \n",
    "    - 0.7-0.9: Transformations significatives\n",
    "    \n",
    "    Args:\n",
    "        image_name: Nom du fichier image uploade\n",
    "        prompt: Instructions d'edition\n",
    "        denoise: Force de l'edition (0.0=rien, 1.0=regeneration complete)\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(0, 2**32)\n",
    "    \n",
    "    return {\n",
    "        # Chargement image source\n",
    "        \"1\": {\n",
    "            \"class_type\": \"LoadImage\",\n",
    "            \"inputs\": {\"image\": image_name}\n",
    "        },\n",
    "        # Chargement des modeles\n",
    "        \"2\": {\n",
    "            \"class_type\": \"VAELoader\",\n",
    "            \"inputs\": {\"vae_name\": \"qwen_image_vae.safetensors\"}\n",
    "        },\n",
    "        \"3\": {\n",
    "            \"class_type\": \"CLIPLoader\",\n",
    "            \"inputs\": {\n",
    "                \"clip_name\": \"qwen_2.5_vl_7b_fp8_scaled.safetensors\",\n",
    "                \"type\": \"sd3\"\n",
    "            }\n",
    "        },\n",
    "        \"4\": {\n",
    "            \"class_type\": \"UNETLoader\",\n",
    "            \"inputs\": {\n",
    "                \"unet_name\": \"qwen_image_edit_2509_fp8_e4m3fn.safetensors\",\n",
    "                \"weight_dtype\": \"fp8_e4m3fn\"\n",
    "            }\n",
    "        },\n",
    "        # Configuration modele\n",
    "        \"5\": {\n",
    "            \"class_type\": \"ModelSamplingAuraFlow\",\n",
    "            \"inputs\": {\"model\": [\"4\", 0], \"shift\": 3.0}\n",
    "        },\n",
    "        \"6\": {\n",
    "            \"class_type\": \"CFGNorm\",\n",
    "            \"inputs\": {\"model\": [\"5\", 0], \"strength\": 1.0}\n",
    "        },\n",
    "        # Encodage VAE de l'image source\n",
    "        \"7\": {\n",
    "            \"class_type\": \"VAEEncode\",\n",
    "            \"inputs\": {\"pixels\": [\"1\", 0], \"vae\": [\"2\", 0]}\n",
    "        },\n",
    "        # Encodage du prompt\n",
    "        \"8\": {\n",
    "            \"class_type\": \"TextEncodeQwenImageEdit\",\n",
    "            \"inputs\": {\n",
    "                \"clip\": [\"3\", 0],\n",
    "                \"prompt\": prompt,\n",
    "                \"vae\": [\"2\", 0]\n",
    "            }\n",
    "        },\n",
    "        # Conditioning negatif\n",
    "        \"9\": {\n",
    "            \"class_type\": \"ConditioningZeroOut\",\n",
    "            \"inputs\": {\"conditioning\": [\"8\", 0]}\n",
    "        },\n",
    "        # Sampling\n",
    "        \"10\": {\n",
    "            \"class_type\": \"KSampler\",\n",
    "            \"inputs\": {\n",
    "                \"model\": [\"6\", 0],\n",
    "                \"positive\": [\"8\", 0],\n",
    "                \"negative\": [\"9\", 0],\n",
    "                \"latent_image\": [\"7\", 0],\n",
    "                \"seed\": seed,\n",
    "                \"steps\": steps,\n",
    "                \"cfg\": cfg,\n",
    "                \"sampler_name\": \"euler\",\n",
    "                \"scheduler\": \"beta\",\n",
    "                \"denoise\": denoise\n",
    "            }\n",
    "        },\n",
    "        # Decodage\n",
    "        \"11\": {\n",
    "            \"class_type\": \"VAEDecode\",\n",
    "            \"inputs\": {\"samples\": [\"10\", 0], \"vae\": [\"2\", 0]}\n",
    "        },\n",
    "        # Sauvegarde\n",
    "        \"12\": {\n",
    "            \"class_type\": \"SaveImage\",\n",
    "            \"inputs\": {\"filename_prefix\": \"Qwen2509_i2i\", \"images\": [\"11\", 0]}\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def create_inpaint_workflow(image_name: str, mask_name: str, prompt: str,\n",
    "                            denoise: float = 0.9, steps: int = 25,\n",
    "                            cfg: float = 1.0, seed: int = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Workflow Inpainting pour Qwen-Image-Edit 2509.\n",
    "\n",
    "    Note: L'inpainting Qwen utilise SetLatentNoiseMask pour appliquer\n",
    "    le masque sur le latent encode. Le masque definit les zones a regenerer.\n",
    "\n",
    "    Args:\n",
    "        image_name: Nom du fichier image uploade\n",
    "        mask_name: Nom du fichier masque (blanc = zone a modifier)\n",
    "        prompt: Description de ce qui doit remplacer la zone masquee\n",
    "        denoise: Force de regeneration (0.8-1.0 recommande pour inpaint)\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(0, 2**32)\n",
    "\n",
    "    return {\n",
    "        # Chargement image et masque\n",
    "        \"1\": {\n",
    "            \"class_type\": \"LoadImage\",\n",
    "            \"inputs\": {\"image\": image_name}\n",
    "        },\n",
    "        \"2\": {\n",
    "            \"class_type\": \"LoadImage\",\n",
    "            \"inputs\": {\"image\": mask_name}\n",
    "        },\n",
    "        # Chargement des modeles\n",
    "        \"3\": {\n",
    "            \"class_type\": \"VAELoader\",\n",
    "            \"inputs\": {\"vae_name\": \"qwen_image_vae.safetensors\"}\n",
    "        },\n",
    "        \"4\": {\n",
    "            \"class_type\": \"CLIPLoader\",\n",
    "            \"inputs\": {\n",
    "                \"clip_name\": \"qwen_2.5_vl_7b_fp8_scaled.safetensors\",\n",
    "                \"type\": \"sd3\"\n",
    "            }\n",
    "        },\n",
    "        \"5\": {\n",
    "            \"class_type\": \"UNETLoader\",\n",
    "            \"inputs\": {\n",
    "                \"unet_name\": \"qwen_image_edit_2509_fp8_e4m3fn.safetensors\",\n",
    "                \"weight_dtype\": \"fp8_e4m3fn\"\n",
    "            }\n",
    "        },\n",
    "        # Configuration modele\n",
    "        \"6\": {\n",
    "            \"class_type\": \"ModelSamplingAuraFlow\",\n",
    "            \"inputs\": {\"model\": [\"5\", 0], \"shift\": 3.0}\n",
    "        },\n",
    "        \"7\": {\n",
    "            \"class_type\": \"CFGNorm\",\n",
    "            \"inputs\": {\"model\": [\"6\", 0], \"strength\": 1.0}\n",
    "        },\n",
    "        # Encodage VAE de l'image source\n",
    "        \"8\": {\n",
    "            \"class_type\": \"VAEEncode\",\n",
    "            \"inputs\": {\"pixels\": [\"1\", 0], \"vae\": [\"3\", 0]}\n",
    "        },\n",
    "        # Application du masque sur le latent\n",
    "        \"9\": {\n",
    "            \"class_type\": \"SetLatentNoiseMask\",\n",
    "            \"inputs\": {\n",
    "                \"samples\": [\"8\", 0],\n",
    "                \"mask\": [\"2\", 0]\n",
    "            }\n",
    "        },\n",
    "        # Encodage du prompt\n",
    "        \"10\": {\n",
    "            \"class_type\": \"TextEncodeQwenImageEdit\",\n",
    "            \"inputs\": {\n",
    "                \"clip\": [\"4\", 0],\n",
    "                \"prompt\": prompt,\n",
    "                \"vae\": [\"3\", 0]\n",
    "            }\n",
    "        },\n",
    "        # Conditioning negatif\n",
    "        \"11\": {\n",
    "            \"class_type\": \"ConditioningZeroOut\",\n",
    "            \"inputs\": {\"conditioning\": [\"10\", 0]}\n",
    "        },\n",
    "        # Sampling avec masque\n",
    "        \"12\": {\n",
    "            \"class_type\": \"KSampler\",\n",
    "            \"inputs\": {\n",
    "                \"model\": [\"7\", 0],\n",
    "                \"positive\": [\"10\", 0],\n",
    "                \"negative\": [\"11\", 0],\n",
    "                \"latent_image\": [\"9\", 0],\n",
    "                \"seed\": seed,\n",
    "                \"steps\": steps,\n",
    "                \"cfg\": cfg,\n",
    "                \"sampler_name\": \"euler\",\n",
    "                \"scheduler\": \"beta\",\n",
    "                \"denoise\": denoise\n",
    "            }\n",
    "        },\n",
    "        # Decodage\n",
    "        \"13\": {\n",
    "            \"class_type\": \"VAEDecode\",\n",
    "            \"inputs\": {\"samples\": [\"12\", 0], \"vae\": [\"3\", 0]}\n",
    "        },\n",
    "        # Sauvegarde\n",
    "        \"14\": {\n",
    "            \"class_type\": \"SaveImage\",\n",
    "            \"inputs\": {\"filename_prefix\": \"Qwen2509_inpaint\", \"images\": [\"13\", 0]}\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Workflows Qwen-Image-Edit 2509 definis (Architecture Phase 29)\")\n",
    "print(\"   - create_text2img_workflow() -> node output: '11'\")\n",
    "print(\"   - create_img2img_workflow() -> node output: '12'\")\n",
    "print(\"   - create_inpaint_workflow() -> node output: '14'\")\n",
    "print(\"\\nNotes importantes:\")\n",
    "print(\"   - CFG=1.0 recommande (CFGNorm gere l'amplification)\")\n",
    "print(\"   - Scheduler 'beta' optimise pour Qwen\")\n",
    "print(\"   - 20 steps suffisent pour de bons resultats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {
    "papermill": {
     "duration": 0.002892,
     "end_time": "2026-02-18T09:03:08.091106",
     "exception": false,
     "start_time": "2026-02-18T09:03:08.088214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. GÃ©nÃ©ration Text-to-Image\n",
    "\n",
    "CommenÃ§ons par gÃ©nÃ©rer une image de base que nous Ã©diterons ensuite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ea618",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:03:08.098324Z",
     "iopub.status.busy": "2026-02-18T09:03:08.098027Z",
     "iopub.status.idle": "2026-02-18T09:03:12.563860Z",
     "shell.execute_reply": "2026-02-18T09:03:12.562115Z"
    },
    "papermill": {
     "duration": 4.471792,
     "end_time": "2026-02-18T09:03:12.565828",
     "exception": true,
     "start_time": "2026-02-18T09:03:08.094036",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation de l'image de base...\n",
      "Prompt: A cozy coffee shop interior, wooden tables, warm lighting,\n",
      "large window with rai...\n",
      "ğŸš€ Soumission du workflow...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Queue failed: <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\"> \n<html xmlns=\"http://www.w3.org/1999/xhtml\"> \n<head> \n<title>IIS 10.0 Detailed Error - 502.3 - Bad Gateway</title> \n<style type=\"text/css\"> \n<!-- \nbody{margin:0;font-size:.7em;font-family:Verdana,Arial,Helvetica,sans-serif;} \ncode{margin:0;color:#006600;font-size:1.1em;font-weight:bold;} \n.config_source code{font-size:.8em;color:#000000;} \npre{margin:0;font-size:1.4em;word-wrap:break-word;} \nul,ol{margin:10px 0 10px 5px;} \nul.first,ol.first{margin-top:5px;} \nfieldset{padding:0 15px 10px 15px;word-break:break-all;} \n.summary-container fieldset{padding-bottom:5px;margin-top:4px;} \nlegend.no-expand-all{padding:2px 15px 4px 10px;margin:0 0 0 -12px;} \nlegend{color:#333333;;margin:4px 0 8px -12px;_margin-top:0px; \nfont-weight:bold;font-size:1em;} \na:link,a:visited{color:#007EFF;font-weight:bold;} \na:hover{text-decoration:none;} \nh1{font-size:2.4em;margin:0;color:#FFF;} \nh2{font-size:1.7em;margin:0;color:#CC0000;} \nh3{font-size:1.4em;margin:10px 0 0 0;color:#CC0000;} \nh4{font-size:1.2em;margin:10px 0 5px 0; \n}#header{width:96%;margin:0 0 0 0;padding:6px 2% 6px 2%;font-family:\"trebuchet MS\",Verdana,sans-serif; \n color:#FFF;background-color:#5C87B2; \n}#content{margin:0 0 0 2%;position:relative;} \n.summary-container,.content-container{background:#FFF;width:96%;margin-top:8px;padding:10px;position:relative;} \n.content-container p{margin:0 0 10px 0; \n}#details-left{width:35%;float:left;margin-right:2%; \n}#details-right{width:63%;float:left;overflow:hidden; \n}#server_version{width:96%;_height:1px;min-height:1px;margin:0 0 5px 0;padding:11px 2% 8px 2%;color:#FFFFFF; \n background-color:#5A7FA5;border-bottom:1px solid #C1CFDD;border-top:1px solid #4A6C8E;font-weight:normal; \n font-size:1em;color:#FFF;text-align:right; \n}#server_version p{margin:5px 0;} \ntable{margin:4px 0 4px 0;width:100%;border:none;} \ntd,th{vertical-align:top;padding:3px 0;text-align:left;font-weight:normal;border:none;} \nth{width:30%;text-align:right;padding-right:2%;font-weight:bold;} \nthead th{background-color:#ebebeb;width:25%; \n}#details-right th{width:20%;} \ntable tr.alt td,table tr.alt th{} \n.highlight-code{color:#CC0000;font-weight:bold;font-style:italic;} \n.clear{clear:both;} \n.preferred{padding:0 5px 2px 5px;font-weight:normal;background:#006633;color:#FFF;font-size:.8em;} \n--> \n</style> \n \n</head> \n<body> \n<div id=\"content\"> \n<div class=\"content-container\"> \n  <h3>HTTP Error 502.3 - Bad Gateway</h3> \n  <h4>Impossible dâ€™Ã©tablir une connexion avec le serveur\r\n</h4> \n</div> \n<div class=\"content-container\"> \n <fieldset><h4>Most likely causes:</h4> \n  <ul> \t<li>The CGI application did not return a valid set of HTTP errors.</li> \t<li>A server acting as a proxy or gateway was unable to process the request due to an error in a parent gateway.</li> </ul> \n </fieldset> \n</div> \n<div class=\"content-container\"> \n <fieldset><h4>Things you can try:</h4> \n  <ul> \t<li>Use DebugDiag to troubleshoot the CGI application.</li> \t<li>Determine if a proxy or gateway is responsible for this error.</li> </ul> \n </fieldset> \n</div> \n \n<div class=\"content-container\"> \n <fieldset><h4>Detailed Error Information:</h4> \n  <div id=\"details-left\"> \n   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\"> \n    <tr class=\"alt\"><th>Module</th><td>&nbsp;&nbsp;&nbsp;ApplicationRequestRouting</td></tr> \n    <tr><th>Notification</th><td>&nbsp;&nbsp;&nbsp;ExecuteRequestHandler</td></tr> \n    <tr class=\"alt\"><th>Handler</th><td>&nbsp;&nbsp;&nbsp;ApplicationRequestRoutingHandler</td></tr> \n    <tr><th>Error Code</th><td>&nbsp;&nbsp;&nbsp;0x80072efd</td></tr> \n     \n   </table> \n  </div> \n  <div id=\"details-right\"> \n   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\"> \n    <tr class=\"alt\"><th>Requested URL</th><td>&nbsp;&nbsp;&nbsp;https://qwen-image-edit.myia.io:443/prompt</td></tr> \n    <tr><th>Physical Path</th><td>&nbsp;&nbsp;&nbsp;D:\\Production\\qwen-image-edit.myia.io\\prompt</td></tr> \n    <tr class=\"alt\"><th>Logon Method</th><td>&nbsp;&nbsp;&nbsp;Anonymous</td></tr> \n    <tr><th>Logon User</th><td>&nbsp;&nbsp;&nbsp;Anonymous</td></tr> \n     \n   </table> \n   <div class=\"clear\"></div> \n  </div> \n </fieldset> \n</div> \n \n<div class=\"content-container\"> \n <fieldset><h4>More Information:</h4> \n  This error occurs when a CGI application does not return a valid set of HTTP headers, or when a proxy or gateway was unable to send the request to a parent gateway. You may need to get a network trace or contact the proxy server administrator, if it is not a CGI problem. \n  <p><a href=\"https://go.microsoft.com/fwlink/?LinkID=62293&amp;IIS70Error=502,3,0x80072efd,26100\">View more information &raquo;</a></p> \n   \n </fieldset> \n</div> \n</div> \n</body> \n</html> \n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGeneration de l\u001b[39m\u001b[33m'\u001b[39m\u001b[33mimage de base...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_base[:\u001b[32m80\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m images_t2i = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_and_get_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkflow_t2i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_node\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m11\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m images_t2i:\n\u001b[32m     29\u001b[39m     base_image = images_t2i[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mQwenImageEditClient.execute_and_get_images\u001b[39m\u001b[34m(self, workflow, output_node, timeout, verbose)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m     88\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸš€ Soumission du workflow...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m prompt_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqueue_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ“‹ ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mQwenImageEditClient.queue_workflow\u001b[39m\u001b[34m(self, workflow)\u001b[39m\n\u001b[32m     58\u001b[39m resp = \u001b[38;5;28mself\u001b[39m.session.post(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/prompt\u001b[39m\u001b[33m\"\u001b[39m, json=payload)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resp.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQueue failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp.json()[\u001b[33m\"\u001b[39m\u001b[33mprompt_id\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mException\u001b[39m: Queue failed: <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\"> \n<html xmlns=\"http://www.w3.org/1999/xhtml\"> \n<head> \n<title>IIS 10.0 Detailed Error - 502.3 - Bad Gateway</title> \n<style type=\"text/css\"> \n<!-- \nbody{margin:0;font-size:.7em;font-family:Verdana,Arial,Helvetica,sans-serif;} \ncode{margin:0;color:#006600;font-size:1.1em;font-weight:bold;} \n.config_source code{font-size:.8em;color:#000000;} \npre{margin:0;font-size:1.4em;word-wrap:break-word;} \nul,ol{margin:10px 0 10px 5px;} \nul.first,ol.first{margin-top:5px;} \nfieldset{padding:0 15px 10px 15px;word-break:break-all;} \n.summary-container fieldset{padding-bottom:5px;margin-top:4px;} \nlegend.no-expand-all{padding:2px 15px 4px 10px;margin:0 0 0 -12px;} \nlegend{color:#333333;;margin:4px 0 8px -12px;_margin-top:0px; \nfont-weight:bold;font-size:1em;} \na:link,a:visited{color:#007EFF;font-weight:bold;} \na:hover{text-decoration:none;} \nh1{font-size:2.4em;margin:0;color:#FFF;} \nh2{font-size:1.7em;margin:0;color:#CC0000;} \nh3{font-size:1.4em;margin:10px 0 0 0;color:#CC0000;} \nh4{font-size:1.2em;margin:10px 0 5px 0; \n}#header{width:96%;margin:0 0 0 0;padding:6px 2% 6px 2%;font-family:\"trebuchet MS\",Verdana,sans-serif; \n color:#FFF;background-color:#5C87B2; \n}#content{margin:0 0 0 2%;position:relative;} \n.summary-container,.content-container{background:#FFF;width:96%;margin-top:8px;padding:10px;position:relative;} \n.content-container p{margin:0 0 10px 0; \n}#details-left{width:35%;float:left;margin-right:2%; \n}#details-right{width:63%;float:left;overflow:hidden; \n}#server_version{width:96%;_height:1px;min-height:1px;margin:0 0 5px 0;padding:11px 2% 8px 2%;color:#FFFFFF; \n background-color:#5A7FA5;border-bottom:1px solid #C1CFDD;border-top:1px solid #4A6C8E;font-weight:normal; \n font-size:1em;color:#FFF;text-align:right; \n}#server_version p{margin:5px 0;} \ntable{margin:4px 0 4px 0;width:100%;border:none;} \ntd,th{vertical-align:top;padding:3px 0;text-align:left;font-weight:normal;border:none;} \nth{width:30%;text-align:right;padding-right:2%;font-weight:bold;} \nthead th{background-color:#ebebeb;width:25%; \n}#details-right th{width:20%;} \ntable tr.alt td,table tr.alt th{} \n.highlight-code{color:#CC0000;font-weight:bold;font-style:italic;} \n.clear{clear:both;} \n.preferred{padding:0 5px 2px 5px;font-weight:normal;background:#006633;color:#FFF;font-size:.8em;} \n--> \n</style> \n \n</head> \n<body> \n<div id=\"content\"> \n<div class=\"content-container\"> \n  <h3>HTTP Error 502.3 - Bad Gateway</h3> \n  <h4>Impossible dâ€™Ã©tablir une connexion avec le serveur\r\n</h4> \n</div> \n<div class=\"content-container\"> \n <fieldset><h4>Most likely causes:</h4> \n  <ul> \t<li>The CGI application did not return a valid set of HTTP errors.</li> \t<li>A server acting as a proxy or gateway was unable to process the request due to an error in a parent gateway.</li> </ul> \n </fieldset> \n</div> \n<div class=\"content-container\"> \n <fieldset><h4>Things you can try:</h4> \n  <ul> \t<li>Use DebugDiag to troubleshoot the CGI application.</li> \t<li>Determine if a proxy or gateway is responsible for this error.</li> </ul> \n </fieldset> \n</div> \n \n<div class=\"content-container\"> \n <fieldset><h4>Detailed Error Information:</h4> \n  <div id=\"details-left\"> \n   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\"> \n    <tr class=\"alt\"><th>Module</th><td>&nbsp;&nbsp;&nbsp;ApplicationRequestRouting</td></tr> \n    <tr><th>Notification</th><td>&nbsp;&nbsp;&nbsp;ExecuteRequestHandler</td></tr> \n    <tr class=\"alt\"><th>Handler</th><td>&nbsp;&nbsp;&nbsp;ApplicationRequestRoutingHandler</td></tr> \n    <tr><th>Error Code</th><td>&nbsp;&nbsp;&nbsp;0x80072efd</td></tr> \n     \n   </table> \n  </div> \n  <div id=\"details-right\"> \n   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\"> \n    <tr class=\"alt\"><th>Requested URL</th><td>&nbsp;&nbsp;&nbsp;https://qwen-image-edit.myia.io:443/prompt</td></tr> \n    <tr><th>Physical Path</th><td>&nbsp;&nbsp;&nbsp;D:\\Production\\qwen-image-edit.myia.io\\prompt</td></tr> \n    <tr class=\"alt\"><th>Logon Method</th><td>&nbsp;&nbsp;&nbsp;Anonymous</td></tr> \n    <tr><th>Logon User</th><td>&nbsp;&nbsp;&nbsp;Anonymous</td></tr> \n     \n   </table> \n   <div class=\"clear\"></div> \n  </div> \n </fieldset> \n</div> \n \n<div class=\"content-container\"> \n <fieldset><h4>More Information:</h4> \n  This error occurs when a CGI application does not return a valid set of HTTP headers, or when a proxy or gateway was unable to send the request to a parent gateway. You may need to get a network trace or contact the proxy server administrator, if it is not a CGI problem. \n  <p><a href=\"https://go.microsoft.com/fwlink/?LinkID=62293&amp;IIS70Error=502,3,0x80072efd,26100\">View more information &raquo;</a></p> \n   \n </fieldset> \n</div> \n</div> \n</body> \n</html> \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. TEXT-TO-IMAGE: Creation d'une image de base\n",
    "# =============================================================================\n",
    "\n",
    "# Prompt creatif pour une scene editable\n",
    "prompt_base = \"\"\"\n",
    "A cozy coffee shop interior, wooden tables, warm lighting,\n",
    "large window with rain outside, vintage aesthetic,\n",
    "empty cup on table, potted plant, high quality photography\n",
    "\"\"\".strip()\n",
    "\n",
    "# Creer le workflow (Architecture Phase 29)\n",
    "workflow_t2i = create_text2img_workflow(\n",
    "    prompt=prompt_base,\n",
    "    width=1024,\n",
    "    height=768,\n",
    "    steps=20,      # 20 steps optimaux pour Qwen\n",
    "    cfg=1.0,       # CFG=1.0 avec CFGNorm\n",
    "    seed=42        # Fixe pour reproductibilite\n",
    ")\n",
    "\n",
    "# Executer (output_node=\"11\" pour le nouveau workflow)\n",
    "print(\"\\nGeneration de l'image de base...\")\n",
    "print(f\"Prompt: {prompt_base[:80]}...\")\n",
    "\n",
    "images_t2i = client.execute_and_get_images(workflow_t2i, output_node=\"11\")\n",
    "\n",
    "if images_t2i:\n",
    "    base_image = images_t2i[0]\n",
    "    \n",
    "    # Affichage\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.imshow(base_image)\n",
    "    plt.title(\"Image de Base - Coffee Shop (Qwen 2509)\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nDimensions: {base_image.size}\")\n",
    "else:\n",
    "    print(\"Erreur de generation - verifiez que les modeles Qwen sont presents\")\n",
    "    print(\"Modeles requis dans ComfyUI/models/:\")\n",
    "    print(\"  - vae/qwen_image_vae.safetensors\")\n",
    "    print(\"  - text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors\")\n",
    "    print(\"  - diffusion_models/qwen_image_edit_2509_fp8_e4m3fn.safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. Ã‰dition Image-to-Image\n",
    "\n",
    "Explorons diffÃ©rents niveaux de `denoise` pour comprendre son impact sur l'Ã©dition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. IMAGE-TO-IMAGE: Analyse comparative du parametre denoise\n",
    "# =============================================================================\n",
    "\n",
    "# Upload de l'image de base\n",
    "if 'base_image' in dir():\n",
    "    uploaded_name = client.upload_image(base_image, \"base_coffee_shop.png\")\n",
    "    print(f\"Image uploadee: {uploaded_name}\")\n",
    "    \n",
    "    # Test avec differents niveaux de denoise\n",
    "    denoise_levels = [0.3, 0.5, 0.7, 0.9]\n",
    "    edit_prompt = \"Same scene but with snow falling outside the window, winter atmosphere\"\n",
    "    \n",
    "    results = []\n",
    "    seed_fixed = 12345  # Meme seed pour comparer\n",
    "    \n",
    "    print(f\"\\nEdition avec prompt: '{edit_prompt}'\")\n",
    "    print(\"\\nComparaison des niveaux de denoise:\")\n",
    "    \n",
    "    for denoise in denoise_levels:\n",
    "        print(f\"\\n--- Denoise = {denoise} ---\")\n",
    "        \n",
    "        workflow = create_img2img_workflow(\n",
    "            image_name=uploaded_name,\n",
    "            prompt=edit_prompt,\n",
    "            denoise=denoise,\n",
    "            steps=20,\n",
    "            cfg=1.0,\n",
    "            seed=seed_fixed\n",
    "        )\n",
    "        \n",
    "        # output_node=\"12\" pour img2img\n",
    "        images = client.execute_and_get_images(workflow, output_node=\"12\", verbose=False)\n",
    "        if images:\n",
    "            results.append((denoise, images[0]))\n",
    "            print(f\"   Genere\")\n",
    "    \n",
    "    # Affichage comparatif\n",
    "    if results:\n",
    "        fig, axes = plt.subplots(1, len(results) + 1, figsize=(20, 5))\n",
    "        \n",
    "        # Image originale\n",
    "        axes[0].imshow(base_image)\n",
    "        axes[0].set_title(\"Original\", fontsize=12)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Resultats\n",
    "        for i, (denoise, img) in enumerate(results):\n",
    "            axes[i+1].imshow(img)\n",
    "            axes[i+1].set_title(f\"Denoise = {denoise}\", fontsize=12)\n",
    "            axes[i+1].axis('off')\n",
    "        \n",
    "        plt.suptitle(\"Impact du parametre Denoise sur l'edition\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nObservations:\")\n",
    "        print(\"   0.3: Changements subtils, structure tres preservee\")\n",
    "        print(\"   0.5: Modifications visibles, bonne balance\")\n",
    "        print(\"   0.7: Transformations significatives\")\n",
    "        print(\"   0.9: Quasi-regeneration, peu de l'original conserve\")\n",
    "else:\n",
    "    print(\"Executez d'abord la cellule Text-to-Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadagfpmkwo",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Impact du parametre Denoise\n",
    "\n",
    "Les resultats montrent l'effet du parametre `denoise` sur l'intensite de l'edition :\n",
    "\n",
    "| Denoise | Observation | Cas d'usage |\n",
    "|---------|-------------|-------------|\n",
    "| **0.3** | Changements subtils, structure tres preservee | Retouche photo, correction couleur |\n",
    "| **0.5** | Modifications visibles, bonne balance | Style transfer modere |\n",
    "| **0.7** | Transformations significatives | Edition importante |\n",
    "| **0.9** | Quasi-regeneration, peu de l'original conserve | Reconstruction complete |\n",
    "\n",
    "> **Note technique** : Le parametre `denoise` controle la quantite de bruit ajoutee lors du processus de diffusion. Plus il est eleve, plus le modele s'eloigne de l'image originale pour creer quelque chose de nouveau.\n",
    "\n",
    "**Choix strategique** : Pour une edition qui preserve la composition tout en changeant l'ambiance, `denoise=0.5` offre le meilleur compromis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Inpainting AvancÃ© avec Masque PersonnalisÃ©\n",
    "\n",
    "L'inpainting permet de modifier uniquement certaines zones de l'image. Nous allons crÃ©er un masque programmatique pour remplacer un Ã©lÃ©ment spÃ©cifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. INPAINTING: Ã‰dition localisÃ©e avec masque\n",
    "# =============================================================================\n",
    "\n",
    "def create_rectangular_mask(width: int, height: int, \n",
    "                            x1: int, y1: int, x2: int, y2: int,\n",
    "                            feather: int = 10) -> Image.Image:\n",
    "    \"\"\"\n",
    "    CrÃ©e un masque rectangulaire avec bords adoucis.\n",
    "    \n",
    "    Args:\n",
    "        width, height: Dimensions du masque\n",
    "        x1, y1, x2, y2: CoordonnÃ©es du rectangle (zone Ã  modifier)\n",
    "        feather: Adoucissement des bords en pixels\n",
    "    \n",
    "    Returns:\n",
    "        Image grayscale (blanc = zone Ã  modifier)\n",
    "    \"\"\"\n",
    "    mask = Image.new('L', (width, height), 0)  # Noir = prÃ©server\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.rectangle([x1, y1, x2, y2], fill=255)  # Blanc = modifier\n",
    "    \n",
    "    # Adoucissement optionnel (blur simple)\n",
    "    if feather > 0:\n",
    "        from PIL import ImageFilter\n",
    "        mask = mask.filter(ImageFilter.GaussianBlur(radius=feather))\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_circular_mask(width: int, height: int,\n",
    "                         cx: int, cy: int, radius: int,\n",
    "                         feather: int = 15) -> Image.Image:\n",
    "    \"\"\"\n",
    "    CrÃ©e un masque circulaire pour l'inpainting.\n",
    "    \"\"\"\n",
    "    mask = Image.new('L', (width, height), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.ellipse([cx-radius, cy-radius, cx+radius, cy+radius], fill=255)\n",
    "    \n",
    "    if feather > 0:\n",
    "        from PIL import ImageFilter\n",
    "        mask = mask.filter(ImageFilter.GaussianBlur(radius=feather))\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "# Exemple: Remplacer la tasse sur la table\n",
    "if 'base_image' in dir():\n",
    "    w, h = base_image.size\n",
    "    \n",
    "    # CrÃ©er un masque pour le centre-bas de l'image (oÃ¹ la table/tasse serait)\n",
    "    mask = create_rectangular_mask(\n",
    "        w, h,\n",
    "        x1=int(w*0.35), y1=int(h*0.55),\n",
    "        x2=int(w*0.65), y2=int(h*0.85),\n",
    "        feather=20\n",
    "    )\n",
    "    \n",
    "    # Upload du masque\n",
    "    mask_name = client.upload_mask(mask, \"edit_mask.png\")\n",
    "    print(f\"âœ… Masque uploadÃ©: {mask_name}\")\n",
    "    \n",
    "    # Visualisation du masque\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(base_image)\n",
    "    axes[0].set_title(\"Image Originale\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(mask, cmap='gray')\n",
    "    axes[1].set_title(\"Masque (blanc = zone Ã  modifier)\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = base_image.copy().convert('RGBA')\n",
    "    mask_rgba = Image.new('RGBA', overlay.size, (255, 0, 0, 0))\n",
    "    mask_draw = ImageDraw.Draw(mask_rgba)\n",
    "    # Convertir le masque en overlay rouge semi-transparent\n",
    "    mask_array = np.array(mask)\n",
    "    red_overlay = np.zeros((h, w, 4), dtype=np.uint8)\n",
    "    red_overlay[:,:,0] = 255  # Rouge\n",
    "    red_overlay[:,:,3] = (mask_array * 0.5).astype(np.uint8)  # Alpha\n",
    "    overlay_img = Image.alpha_composite(overlay, Image.fromarray(red_overlay))\n",
    "    \n",
    "    axes[2].imshow(overlay_img)\n",
    "    axes[2].set_title(\"Zone d'Ã©dition (rouge)\")\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ Image de base non disponible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6b. EXECUTION DE L'INPAINTING\n",
    "# =============================================================================\n",
    "\n",
    "if 'uploaded_name' in dir() and 'mask_name' in dir():\n",
    "    # Prompt pour la zone masquee\n",
    "    inpaint_prompt = \"A beautiful laptop with glowing screen, modern design, on wooden table\"\n",
    "    \n",
    "    print(f\"\\nInpainting: '{inpaint_prompt}'\")\n",
    "    \n",
    "    workflow_inpaint = create_inpaint_workflow(\n",
    "        image_name=uploaded_name,\n",
    "        mask_name=mask_name,\n",
    "        prompt=inpaint_prompt,\n",
    "        denoise=0.95,  # Haut pour remplacer completement\n",
    "        steps=25,\n",
    "        cfg=1.0,       # CFG=1.0 avec CFGNorm (Phase 29)\n",
    "        seed=99999\n",
    "    )\n",
    "    \n",
    "    # output_node=\"14\" pour inpainting workflow\n",
    "    images_inpaint = client.execute_and_get_images(workflow_inpaint, output_node=\"14\")\n",
    "    \n",
    "    if images_inpaint:\n",
    "        inpainted_image = images_inpaint[0]\n",
    "        \n",
    "        # Comparaison avant/apres\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "        \n",
    "        axes[0].imshow(base_image)\n",
    "        axes[0].set_title(\"Avant Inpainting\", fontsize=14)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(inpainted_image)\n",
    "        axes[1].set_title(\"Apres Inpainting\", fontsize=14)\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.suptitle(f\"Inpainting: '{inpaint_prompt}'\", fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Prerequis manquants (image ou masque)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gjiyry24wsw",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Resultats de l'Inpainting\n",
    "\n",
    "L'inpainting a remplace la zone masquee par un nouvel element :\n",
    "\n",
    "| Aspect | Observation |\n",
    "|--------|-------------|\n",
    "| **CohÃ©rence spatiale** | Le laptop s'integre naturellement dans la scene |\n",
    "| **QualitÃ© des bords** | La transition avec l'arriere-plan est fluide grace au masque adouci |\n",
    "| **Consistance lumineuse** | L'eclairage du laptop correspond a l'ambiance du coffee shop |\n",
    "\n",
    "> **Point cle** : Le succes de l'inpainting depend de la qualite du masque. Un masque avec bords adoucis (feathered) permet une transition plus naturelle entre la zone modifiee et l'originale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Batch Processing: GÃ©nÃ©ration Multiple\n",
    "\n",
    "Pour l'efficacitÃ©, gÃ©nÃ©rons plusieurs variations en parallÃ¨le avec diffÃ©rents prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. BATCH PROCESSING: Variations multiples\n",
    "# =============================================================================\n",
    "\n",
    "def batch_generate(prompts: List[str], base_seed: int = 1000, **kwargs) -> List[Tuple[str, Image.Image]]:\n",
    "    \"\"\"\n",
    "    Genere plusieurs images a partir d'une liste de prompts.\n",
    "    \n",
    "    Args:\n",
    "        prompts: Liste de descriptions\n",
    "        base_seed: Seed de depart (incremente pour chaque image)\n",
    "        **kwargs: Arguments passes a create_text2img_workflow\n",
    "    \n",
    "    Returns:\n",
    "        Liste de tuples (prompt, image)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"\\n[{i+1}/{len(prompts)}] Generation...\")\n",
    "        print(f\"   Prompt: {prompt[:60]}...\")\n",
    "        \n",
    "        workflow = create_text2img_workflow(\n",
    "            prompt=prompt,\n",
    "            seed=base_seed + i,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # output_node=\"11\" pour t2i\n",
    "        images = client.execute_and_get_images(workflow, output_node=\"11\", verbose=False)\n",
    "        if images:\n",
    "            results.append((prompt, images[0]))\n",
    "            print(f\"   Succes\")\n",
    "        else:\n",
    "            print(f\"   Echec\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Generation de variations thematiques\n",
    "variation_prompts = [\n",
    "    \"A futuristic cityscape at sunset, flying cars, neon lights, cyberpunk style\",\n",
    "    \"An ancient Japanese temple in autumn, red maple leaves, misty mountains\",\n",
    "    \"An underwater coral reef, tropical fish, sunlight rays, crystal clear water\",\n",
    "    \"A cozy library interior, tall bookshelves, reading nook, warm lamp light\"\n",
    "]\n",
    "\n",
    "print(\"\\nBatch Generation - 4 Themes\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "batch_results = batch_generate(\n",
    "    variation_prompts,\n",
    "    base_seed=2024,\n",
    "    width=768,\n",
    "    height=768,\n",
    "    steps=20,\n",
    "    cfg=1.0  # CFG=1.0 avec CFGNorm\n",
    ")\n",
    "\n",
    "# Affichage grille\n",
    "if batch_results:\n",
    "    n = len(batch_results)\n",
    "    cols = 2\n",
    "    rows = (n + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (prompt, img) in enumerate(batch_results):\n",
    "        axes[i].imshow(img)\n",
    "        # Titre court\n",
    "        short_title = prompt.split(',')[0][:40]\n",
    "        axes[i].set_title(short_title, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Masquer les axes vides\n",
    "    for i in range(len(batch_results), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Batch Generation - Variations Thematiques\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n{len(batch_results)} images generees avec succes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8txuf4lm17g",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Batch Processing\n",
    "\n",
    "La generation en lot a permis de creer 4 variations thematiques distinctes :\n",
    "\n",
    "| Theme | Prompt cle | Resultat |\n",
    "|-------|-----------|----------|\n",
    "| **Cyberpunk** | \"futuristic cityscape\", \"neon lights\" | Ambiance urbaine futuriste |\n",
    "| **Japonais** | \"ancient temple\", \"autumn\", \"maple leaves\" | Scene traditionnelle paisible |\n",
    "| **Sous-marin** | \"coral reef\", \"tropical fish\", \"sunlight\" | Eclairage aquatique realise |\n",
    "| **Bibliotheque** | \"library interior\", \"warm lamp light\" | Atmosphere intime et studieuse |\n",
    "\n",
    "> **Avantage du batch** : Le traitement par lots permet d'explorer plusieurs directions creatives en un seul passage, optimisant ainsi le temps de creation.\n",
    "\n",
    "**Performance** : Avec 4 images generes en sequence, le temps total reste raisonnable car chaque generation utilise la meme architecture de modeles (pas de rechargement necessaire)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. Analyse Comparative: CFG Scale\n",
    "\n",
    "Le paramÃ¨tre `cfg` (Classifier-Free Guidance) contrÃ´le l'adhÃ©rence au prompt. Explorons son impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. ANALYSE CFG: Impact du Guidance Scale avec CFGNorm\n",
    "# =============================================================================\n",
    "# NOTE IMPORTANTE (Phase 29):\n",
    "# L'architecture Qwen utilise CFGNorm qui normalise le guidance.\n",
    "# Avec CFGNorm, CFG=1.0 est optimal car la normalisation gere l'amplification.\n",
    "# Cette cellule explore differentes valeurs CFG a titre educatif pour\n",
    "# comprendre le comportement du modele.\n",
    "\n",
    "test_prompt = \"A majestic dragon breathing fire, fantasy art, highly detailed scales, dramatic lighting\"\n",
    "\n",
    "# Valeurs CFG a tester (1.0 est recommande avec CFGNorm)\n",
    "cfg_values = [1.0, 2.0, 4.0, 7.0]\n",
    "fixed_seed = 7777\n",
    "\n",
    "print(f\"\\nAnalyse CFG Scale (avec CFGNorm)\")\n",
    "print(f\"Prompt: '{test_prompt[:50]}...'\")\n",
    "print(f\"Valeurs testees: {cfg_values}\")\n",
    "print(\"\\nNote: CFG=1.0 est recommande avec CFGNorm (architecture Phase 29)\")\n",
    "\n",
    "cfg_results = []\n",
    "\n",
    "for cfg in cfg_values:\n",
    "    print(f\"\\n--- CFG = {cfg} ---\")\n",
    "    \n",
    "    workflow = create_text2img_workflow(\n",
    "        prompt=test_prompt,\n",
    "        width=768,\n",
    "        height=768,\n",
    "        steps=20,\n",
    "        cfg=cfg,\n",
    "        seed=fixed_seed\n",
    "    )\n",
    "    \n",
    "    # output_node=\"11\" pour t2i\n",
    "    images = client.execute_and_get_images(workflow, output_node=\"11\", verbose=False)\n",
    "    if images:\n",
    "        cfg_results.append((cfg, images[0]))\n",
    "        print(f\"   Genere\")\n",
    "\n",
    "# Affichage comparatif\n",
    "if cfg_results:\n",
    "    fig, axes = plt.subplots(1, len(cfg_results), figsize=(16, 5))\n",
    "    \n",
    "    for i, (cfg, img) in enumerate(cfg_results):\n",
    "        axes[i].imshow(img)\n",
    "        title = f\"CFG = {cfg}\"\n",
    "        if cfg == 1.0:\n",
    "            title += \" (recommande)\"\n",
    "        axes[i].set_title(title, fontsize=12)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Impact du CFG avec CFGNorm (Architecture Phase 29)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nObservations CFG avec CFGNorm:\")\n",
    "    print(\"   1.0: Valeur optimale - CFGNorm gere l'amplification automatiquement\")\n",
    "    print(\"   2.0: Leger renforcement du prompt\")\n",
    "    print(\"   4.0: Adherence plus forte, details accentues\")\n",
    "    print(\"   7.0: Peut introduire des artefacts avec CFGNorm\")\n",
    "    print(\"\\nRecommandation: Utiliser CFG=1.0 avec l'architecture Phase 29\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mzzz5x02in9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Impact du CFG avec CFGNorm\n",
    "\n",
    "L'analyse des differentes valeurs CFG avec l'architecture Phase 29 revele des comportements specifiques :\n",
    "\n",
    "| CFG | Comportement | Qualite resultats |\n",
    "|-----|-------------|-------------------|\n",
    "| **1.0** | Valeur optimale avec CFGNorm | Equilibre parfait entre creativite et adherence au prompt |\n",
    "| **2.0** | Leger renforcement du prompt | Details un peu plus prononces sans artefacts |\n",
    "| **4.0** | Adherence forte au prompt | Risque de surcontrainte, details forces |\n",
    "| **7.0** | Trop eleve pour CFGNorm | Artefacts possibles, degradation de la qualite |\n",
    "\n",
    "> **Comprehension de CFGNorm** : Le node CFGNorm normalise automatiquement le signal de guidance. C'est pourquoi CFG=1.0 est optimal - la normalisation gere deja l'amplification du prompt.\n",
    "\n",
    "**Recommandation definitive** : Avec l'architecture Phase 29 (Qwen Image Edit 2509), utilisez toujours `cfg=1.0` pour les meilleurs resultats. Des valeurs plus elevees n'apportent pas d'amelioration significative et peuvent reduire la qualite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9. Exercices Pratiques\n",
    "\n",
    "### Exercice 1: Ã‰dition de Style\n",
    "Prenez l'image de base du coffee shop et appliquez diffÃ©rents styles artistiques (impressionniste, anime, rÃ©aliste) en utilisant img2img avec un denoise de 0.6.\n",
    "\n",
    "### Exercice 2: Inpainting CrÃ©atif\n",
    "CrÃ©ez un masque circulaire au centre de l'image et remplacez cette zone par un personnage de votre choix.\n",
    "\n",
    "### Exercice 3: Exploration des Schedulers\n",
    "Modifiez le workflow pour tester diffÃ©rents schedulers (`normal`, `karras`, `exponential`) et comparez les rÃ©sultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 9. ESPACE D'EXERCICES\n",
    "# =============================================================================\n",
    "\n",
    "# Exercice 1: Style Transfer\n",
    "# DÃ©commentez et complÃ©tez:\n",
    "\n",
    "# style_prompts = [\n",
    "#     \"Same scene, impressionist painting style, visible brushstrokes\",\n",
    "#     \"Same scene, anime style, vibrant colors, Studio Ghibli\",\n",
    "#     \"Same scene, photorealistic, DSLR quality, 8k resolution\"\n",
    "# ]\n",
    "# \n",
    "# for style in style_prompts:\n",
    "#     workflow = create_img2img_workflow(\n",
    "#         image_name=uploaded_name,\n",
    "#         prompt=style,\n",
    "#         denoise=0.6\n",
    "#     )\n",
    "#     # ... gÃ©nÃ©rer et afficher\n",
    "\n",
    "print(\"ğŸ“ Espace d'exercices - DÃ©commentez le code ci-dessus pour commencer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 10. Recapitulatif et Points Cles\n",
    "\n",
    "### Architecture Phase 29 - Qwen-Image-Edit 2509\n",
    "\n",
    "Cette architecture utilise les composants natifs ComfyUI suivants :\n",
    "\n",
    "| Composant | Node ComfyUI | Fichier Modele |\n",
    "|-----------|--------------|----------------|\n",
    "| VAE | VAELoader | qwen_image_vae.safetensors (243MB) |\n",
    "| Text Encoder | CLIPLoader (type=sd3) | qwen_2.5_vl_7b_fp8_scaled.safetensors (8.8GB) |\n",
    "| Diffusion | UNETLoader (fp8_e4m3fn) | qwen_image_edit_2509_fp8_e4m3fn.safetensors (20GB) |\n",
    "\n",
    "### Parametres Essentiels (Architecture Phase 29)\n",
    "\n",
    "| Parametre | Plage | Recommande | Impact |\n",
    "|-----------|-------|------------|--------|\n",
    "| `steps` | 15-30 | 20 | Qualite vs. Vitesse |\n",
    "| `cfg` | 1-4 | **1.0** | CFGNorm gere l'amplification |\n",
    "| `denoise` | 0-1 | 0.5-0.7 | Force de l'edition |\n",
    "| `shift` | 2-4 | 3.0 | ModelSamplingAuraFlow |\n",
    "| `scheduler` | - | **beta** | Optimise pour Qwen |\n",
    "| `sampler` | - | **euler** | Stable et rapide |\n",
    "\n",
    "### Bonnes Pratiques\n",
    "\n",
    "1. **Toujours utiliser CFG=1.0** avec l'architecture Phase 29 (CFGNorm normalise automatiquement)\n",
    "2. **Scheduler 'beta'** est optimise pour les modeles Qwen\n",
    "3. **20 steps** suffisent pour de bons resultats (qualite/vitesse optimal)\n",
    "4. **Pour l'inpainting, denoise >= 0.8** pour un remplacement complet\n",
    "5. **Utiliser seed fixe** pour comparer les parametres et reproduire les resultats\n",
    "\n",
    "### Nodes Requis\n",
    "\n",
    "```\n",
    "TextEncodeQwenImageEdit   # Encodeur texte natif Qwen\n",
    "ModelSamplingAuraFlow     # Configuration sampling (shift=3.0)\n",
    "CFGNorm                   # Normalisation CFG (strength=1.0)\n",
    "EmptySD3LatentImage       # Latent 16 canaux pour Qwen\n",
    "ConditioningZeroOut       # Conditioning negatif vide\n",
    "```\n",
    "\n",
    "### Ressources\n",
    "\n",
    "- [Documentation ComfyUI](https://docs.comfy.org/)\n",
    "- [Qwen-VL Papers](https://arxiv.org/abs/2308.12966)\n",
    "- [Modeles Comfy-Org](https://huggingface.co/Comfy-Org/Qwen-Image-Edit_ComfyUI)\n",
    "- Notebook suivant: **02-2-FLUX-1-Advanced-Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIN DU NOTEBOOK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"   âœ… Notebook Qwen-Image-Edit 2509 ComplÃ©tÃ©\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“… TerminÃ©: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nğŸ“š Concepts couverts:\")\n",
    "print(\"   â€¢ Text-to-Image avec Qwen 2509\")\n",
    "print(\"   â€¢ Image-to-Image et analyse du denoise\")\n",
    "print(\"   â€¢ Inpainting avec masques personnalisÃ©s\")\n",
    "print(\"   â€¢ Batch processing\")\n",
    "print(\"   â€¢ Analyse comparative CFG\")\n",
    "print(\"\\nâ¡ï¸  Prochain notebook: 02-2-FLUX-1-Advanced-Generation.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4g9g5qfo8ux",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "### Synthese des apprentissages\n",
    "\n",
    "Ce notebook a explore les capacites avancees de Qwen-Image-Edit 2509 avec l'architecture Phase 29 :\n",
    "\n",
    "| Concept | Retenu |\n",
    "|---------|--------|\n",
    "| **Architecture Phase 29** | Loaders separes (VAE, CLIP, UNET) + CFGNorm |\n",
    "| **Denoise** | Controle l'intensite de l'edition (0.3-0.9) |\n",
    "| **Inpainting** | Modification locale avec masques personnalises |\n",
    "| **Batch processing** | Generation efficace de multiples variations |\n",
    "| **CFG avec CFGNorm** | CFG=1.0 est optimal pour cette architecture |\n",
    "\n",
    "### Tableau recapitulatif des parametres\n",
    "\n",
    "| Parametre | Valeur recommandee | Usage |\n",
    "|-----------|-------------------|-------|\n",
    "| `steps` | 20 | Equilibre qualite/vitesse |\n",
    "| `cfg` | 1.0 | Optimal avec CFGNorm |\n",
    "| `denoise` (img2img) | 0.5-0.7 | Edition preservee |\n",
    "| `denoise` (inpaint) | 0.9+ | Remplacement complet |\n",
    "| `scheduler` | beta | Optimise pour Qwen |\n",
    "| `sampler` | euler | Stable et rapide |\n",
    "\n",
    "### Prochaines etapes\n",
    "\n",
    "1. Experimentez avec differents types de masques (circulaires, irreguliers)\n",
    "2. Combinez plusieurs editions en sequence pour des transformations complexes\n",
    "3. Explorez le notebook suivant : **02-2-FLUX-1-Advanced-Generation**\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation** : [Index](../../README.md) | [<< Precedent](../01-Foundation/01-5-Qwen-Image-Edit.ipynb) | [Suivant >>](02-2-FLUX-1-Advanced-Generation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.561337,
   "end_time": "2026-02-18T09:03:12.921776",
   "environment_variables": {},
   "exception": true,
   "input_path": "02-1-Qwen-Image-Edit-2509.ipynb",
   "output_path": "02-1-Qwen-Image-Edit-2509_output.ipynb",
   "parameters": {
    "notebook_mode": "batch"
   },
   "start_time": "2026-02-18T09:03:01.360439",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}