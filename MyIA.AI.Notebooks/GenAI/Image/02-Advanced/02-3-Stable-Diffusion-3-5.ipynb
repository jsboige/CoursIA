{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Stable Diffusion 3.5 - G\u00e9n\u00e9ration de Pointe\n",
        "\n",
        "**Module :** 02-Images-Advanced  \n",
        "**Niveau :** Interm\u00e9diaire/Avanc\u00e9  \n",
        "**Dur\u00e9e estim\u00e9e :** 50 minutes  \n",
        "\n",
        "## Introduction\n",
        "\n",
        "**Stable Diffusion 3.5** repr\u00e9sente la derni\u00e8re g\u00e9n\u00e9ration de mod\u00e8les de Stability AI, combinant une architecture MMDiT (Multimodal Diffusion Transformer) avec des encodeurs de texte avanc\u00e9s.\n",
        "\n",
        "### Variantes SD 3.5\n",
        "\n",
        "| Variante | Params | VRAM | Caract\u00e9ristiques |\n",
        "|----------|--------|------|------------------|\n",
        "| **SD 3.5 Large** | 8B | 16GB+ | Meilleure qualit\u00e9 |\n",
        "| **SD 3.5 Large Turbo** | 8B | 16GB+ | 4 steps, rapide |\n",
        "| **SD 3.5 Medium** | 2.5B | 8GB+ | Balance qualit\u00e9/vitesse |\n",
        "\n",
        "### Architecture MMDiT\n",
        "\n",
        "```\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502            Stable Diffusion 3.5 Architecture            \u2502\n",
        "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
        "\u2502   Text Prompt \u2192 [CLIP-L] + [CLIP-G] + [T5-XXL]         \u2502\n",
        "\u2502       \u2193                                                 \u2502\n",
        "\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n",
        "\u2502   \u2502    MMDiT (Multimodal Diffusion    \u2502                \u2502\n",
        "\u2502   \u2502    Transformer)                    \u2502                \u2502\n",
        "\u2502   \u2502    - Joint attention text+image   \u2502                \u2502\n",
        "\u2502   \u2502    - Flow Matching objective      \u2502                \u2502\n",
        "\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n",
        "\u2502       \u2193                                                 \u2502\n",
        "\u2502   [16-ch VAE] \u2192 Output Image (1024x1024)               \u2502\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "```\n",
        "\n",
        "## Pr\u00e9requis\n",
        "\n",
        "- Module 00-GenAI-Environment compl\u00e9t\u00e9\n",
        "- GPU avec 8GB+ VRAM (Medium) ou 16GB+ (Large)\n",
        "- Token HuggingFace avec acceptation licence SD 3.5"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 1. CONFIGURATION ET IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import gc\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Optional, Dict, List, Tuple, Any\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Chargement variables d'environnement\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"../.env\")\n",
        "load_dotenv(\"../00-GenAI-Environment/.env\")\n",
        "\n",
        "# Configuration\n",
        "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\") or os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "print(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\")\n",
        "print(\"\u2551   Stable Diffusion 3.5 - G\u00e9n\u00e9ration de Pointe     \u2551\")\n",
        "print(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\")\n",
        "print(f\"\\n\ud83d\udcc5 Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"\\n\ud83d\udd11 HuggingFace: {'\u2705 Token configur\u00e9' if HF_TOKEN else '\u274c Token manquant'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 2. D\u00c9TECTION GPU ET CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "\n",
        "def get_gpu_info():\n",
        "    \"\"\"D\u00e9tecte et retourne les informations GPU.\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        return None, 0, \"cpu\"\n",
        "    \n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    return gpu_name, gpu_memory, \"cuda\"\n",
        "\n",
        "def recommend_model(gpu_memory: float) -> str:\n",
        "    \"\"\"Recommande la variante SD3.5 selon la VRAM.\"\"\"\n",
        "    if gpu_memory >= 24:\n",
        "        return \"stabilityai/stable-diffusion-3.5-large\"\n",
        "    elif gpu_memory >= 16:\n",
        "        return \"stabilityai/stable-diffusion-3.5-large-turbo\"\n",
        "    elif gpu_memory >= 8:\n",
        "        return \"stabilityai/stable-diffusion-3.5-medium\"\n",
        "    return None\n",
        "\n",
        "GPU_NAME, GPU_MEMORY, DEVICE = get_gpu_info()\n",
        "RECOMMENDED_MODEL = recommend_model(GPU_MEMORY) if GPU_MEMORY else None\n",
        "DTYPE = torch.float16 if GPU_MEMORY and GPU_MEMORY >= 16 else torch.bfloat16\n",
        "\n",
        "if GPU_NAME:\n",
        "    print(f\"\\n\ud83c\udfae GPU: {GPU_NAME}\")\n",
        "    print(f\"   VRAM: {GPU_MEMORY:.1f} GB\")\n",
        "    if RECOMMENDED_MODEL:\n",
        "        print(f\"   \u2705 Recommandation: {RECOMMENDED_MODEL.split('/')[-1]}\")\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f Pas de GPU CUDA d\u00e9tect\u00e9\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
            "\u2551   Stable Diffusion 3.5 - G\u00e9n\u00e9ration de Pointe     \u2551\n",
            "\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
            "\n",
            "\ud83d\udcc5 Date: 2026-02-18 10:03:33\n",
            "\n",
            "\ud83d\udd11 HuggingFace: \u274c Token manquant\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 3. CLIENT SD 3.5\n",
        "# =============================================================================\n",
        "\n",
        "from diffusers import StableDiffusion3Pipeline\n",
        "\n",
        "class SD35Client:\n",
        "    \"\"\"Client pour Stable Diffusion 3.5 avec optimisations m\u00e9moire.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_id: str = None):\n",
        "        self.model_id = model_id or RECOMMENDED_MODEL\n",
        "        self.pipeline = None\n",
        "        self.is_turbo = \"turbo\" in (self.model_id or \"\").lower()\n",
        "        \n",
        "        if not self.model_id:\n",
        "            raise ValueError(\"Pas assez de VRAM pour SD3.5 local.\")\n",
        "        \n",
        "        print(f\"\ud83d\udd27 SD35Client: {self.model_id.split('/')[-1]}\")\n",
        "        print(f\"   Turbo: {'Oui' if self.is_turbo else 'Non'}\")\n",
        "    \n",
        "    def load(self):\n",
        "        \"\"\"Charge le pipeline.\"\"\"\n",
        "        if self.pipeline:\n",
        "            return\n",
        "        \n",
        "        print(f\"\\n\ud83d\udce5 Chargement du mod\u00e8le...\")\n",
        "        start = time.time()\n",
        "        \n",
        "        self.pipeline = StableDiffusion3Pipeline.from_pretrained(\n",
        "            self.model_id,\n",
        "            torch_dtype=DTYPE,\n",
        "            token=HF_TOKEN,\n",
        "            use_safetensors=True\n",
        "        )\n",
        "        self.pipeline.enable_model_cpu_offload()\n",
        "        self.pipeline.enable_attention_slicing()\n",
        "        \n",
        "        print(f\"   \u2705 Charg\u00e9 en {time.time()-start:.1f}s\")\n",
        "    \n",
        "    def generate(self, prompt: str, negative_prompt: str = \"\",\n",
        "                 width: int = 1024, height: int = 1024,\n",
        "                 num_inference_steps: int = None,\n",
        "                 guidance_scale: float = None,\n",
        "                 seed: int = None) -> List[Image.Image]:\n",
        "        \"\"\"G\u00e9n\u00e8re des images.\"\"\"\n",
        "        self.load()\n",
        "        \n",
        "        if num_inference_steps is None:\n",
        "            num_inference_steps = 4 if self.is_turbo else 28\n",
        "        if guidance_scale is None:\n",
        "            guidance_scale = 0.0 if self.is_turbo else 4.5\n",
        "        if seed is None:\n",
        "            seed = np.random.randint(0, 2**32)\n",
        "        if not negative_prompt:\n",
        "            negative_prompt = \"blurry, low quality, distorted, deformed\"\n",
        "        \n",
        "        generator = torch.Generator(device=DEVICE).manual_seed(seed)\n",
        "        \n",
        "        print(f\"\\n\ud83c\udfa8 G\u00e9n\u00e9ration (seed: {seed}, steps: {num_inference_steps})...\")\n",
        "        start = time.time()\n",
        "        \n",
        "        result = self.pipeline(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            width=width,\n",
        "            height=height,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            generator=generator\n",
        "        )\n",
        "        \n",
        "        print(f\"   \u2705 G\u00e9n\u00e9r\u00e9 en {time.time()-start:.1f}s\")\n",
        "        return result.images\n",
        "    \n",
        "    def unload(self):\n",
        "        \"\"\"Lib\u00e8re la m\u00e9moire.\"\"\"\n",
        "        if self.pipeline:\n",
        "            del self.pipeline\n",
        "            self.pipeline = None\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            print(\"\u2705 M\u00e9moire lib\u00e9r\u00e9e\")\n",
        "\n",
        "# Instanciation\n",
        "try:\n",
        "    sd35 = SD35Client()\n",
        "except ValueError as e:\n",
        "    print(f\"\u26a0\ufe0f {e}\")\n",
        "    sd35 = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-4",
      "metadata": {},
      "source": [
        "## 4. G\u00e9n\u00e9ration de Base"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u26a0\ufe0f Pas de GPU CUDA d\u00e9tect\u00e9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 4. G\u00c9N\u00c9RATION DE BASE\n",
        "# =============================================================================\n",
        "\n",
        "if sd35:\n",
        "    base_prompt = \"\"\"\n",
        "    A majestic phoenix rising from flames, \n",
        "    intricate feather details, golden and crimson colors,\n",
        "    magical sparks, dark fantasy background,\n",
        "    highly detailed digital art, 8k resolution\n",
        "    \"\"\".strip()\n",
        "    \n",
        "    print(f\"\ud83d\udcdd Prompt: {base_prompt[:60]}...\")\n",
        "    \n",
        "    images = sd35.generate(prompt=base_prompt, seed=42)\n",
        "    \n",
        "    if images:\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(images[0])\n",
        "        plt.title(f\"SD 3.5 - {sd35.model_id.split('/')[-1]}\", fontsize=14)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f SD35 non initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-6",
      "metadata": {},
      "source": [
        "## 5. Analyse CFG Scale"
      ],
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import diffusers.pipelines.stable_diffusion_3.pipeline_stable_diffusion_3 because of the following error (look up to see its traceback):\nhuggingface-hub>=0.30.0,<1.0 is required for a normal functioning of this module, but found huggingface-hub==1.4.1.\nTry: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\diffusers\\utils\\import_utils.py:1016\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1016\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1026\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\diffusers\\pipelines\\stable_diffusion_3\\pipeline_stable_diffusion_3.py:19\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     CLIPTextModelWithProjection,\n\u001b[32m     21\u001b[39m     CLIPTokenizer,\n\u001b[32m     22\u001b[39m     SiglipImageProcessor,\n\u001b[32m     23\u001b[39m     SiglipVisionModel,\n\u001b[32m     24\u001b[39m     T5EncoderModel,\n\u001b[32m     25\u001b[39m     T5TokenizerFast,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiPipelineCallbacks, PipelineCallback\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\__init__.py:26\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     29\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     logging,\n\u001b[32m     49\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\dependency_versions_check.py:57\u001b[39m\n\u001b[32m     55\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# not required, check version only if installed\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[43mrequire_version_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\utils\\versions.py:117\u001b[39m, in \u001b[36mrequire_version_core\u001b[39m\u001b[34m(requirement)\u001b[39m\n\u001b[32m    116\u001b[39m hint = \u001b[33m\"\u001b[39m\u001b[33mTry: `pip install transformers -U` or `pip install -e \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.[dev]\u001b[39m\u001b[33m'\u001b[39m\u001b[33m` if you\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre working with git main\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequire_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\utils\\versions.py:111\u001b[39m, in \u001b[36mrequire_version\u001b[39m\u001b[34m(requirement, hint)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m op, want_ver \u001b[38;5;129;01min\u001b[39;00m wanted.items():\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[43m_compare_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgot_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwant_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\utils\\versions.py:44\u001b[39m, in \u001b[36m_compare_versions\u001b[39m\u001b[34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops[op](version.parse(got_ver), version.parse(want_ver)):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     45\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is required for a normal functioning of this module, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m     )\n",
            "\u001b[31mImportError\u001b[39m: huggingface-hub>=0.30.0,<1.0 is required for a normal functioning of this module, but found huggingface-hub==1.4.1.\nTry: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 3. CLIENT SD 3.5\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdiffusers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StableDiffusion3Pipeline\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSD35Client\u001b[39;00m:\n\u001b[32m      8\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Client pour Stable Diffusion 3.5 avec optimisations m\u00e9moire.\"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\diffusers\\utils\\import_utils.py:1007\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m   1006\u001b[39m     module = \u001b[38;5;28mself\u001b[39m._get_module(\u001b[38;5;28mself\u001b[39m._class_to_module[name])\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     value = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\diffusers\\utils\\import_utils.py:1007\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m   1006\u001b[39m     module = \u001b[38;5;28mself\u001b[39m._get_module(\u001b[38;5;28mself\u001b[39m._class_to_module[name])\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     value = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\diffusers\\utils\\import_utils.py:1006\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1004\u001b[39m     value = \u001b[38;5;28mself\u001b[39m._get_module(name)\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1007\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\diffusers\\utils\\import_utils.py:1018\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + module_name, \u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1018\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1019\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m because of the following error (look up to see its\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: Failed to import diffusers.pipelines.stable_diffusion_3.pipeline_stable_diffusion_3 because of the following error (look up to see its traceback):\nhuggingface-hub>=0.30.0,<1.0 is required for a normal functioning of this module, but found huggingface-hub==1.4.1.\nTry: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 5. ANALYSE CFG SCALE\n",
        "# =============================================================================\n",
        "\n",
        "if sd35 and not sd35.is_turbo:\n",
        "    cfg_prompt = \"A serene lake reflecting mountains, sunset, photorealistic\"\n",
        "    cfg_values = [2.0, 4.5, 7.0, 10.0]\n",
        "    \n",
        "    print(f\"\\n\ud83d\udcca Analyse CFG Scale\")\n",
        "    cfg_results = []\n",
        "    \n",
        "    for cfg in cfg_values:\n",
        "        print(f\"--- CFG = {cfg} ---\")\n",
        "        images = sd35.generate(cfg_prompt, width=768, height=768,\n",
        "                               num_inference_steps=20, guidance_scale=cfg, seed=12345)\n",
        "        if images:\n",
        "            cfg_results.append((cfg, images[0]))\n",
        "    \n",
        "    if cfg_results:\n",
        "        fig, axes = plt.subplots(1, len(cfg_results), figsize=(16, 5))\n",
        "        for i, (cfg, img) in enumerate(cfg_results):\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(f\"CFG = {cfg}\")\n",
        "            axes[i].axis('off')\n",
        "        plt.suptitle(\"Impact du Guidance Scale (CFG)\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "elif sd35:\n",
        "    print(\"Mode Turbo: CFG fix\u00e9 \u00e0 0\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f SD35 non initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-8",
      "metadata": {},
      "source": [
        "## 6. Comparaison Inference Steps"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 6. ANALYSE INFERENCE STEPS\n",
        "# =============================================================================\n",
        "\n",
        "if sd35:\n",
        "    steps_prompt = \"A cyberpunk city at night, neon lights, rain, cinematic\"\n",
        "    step_values = [1, 2, 4, 8] if sd35.is_turbo else [10, 20, 28, 40]\n",
        "    \n",
        "    print(f\"\\n\u23f1\ufe0f Analyse Steps ({'Turbo' if sd35.is_turbo else 'Standard'})\")\n",
        "    steps_results = []\n",
        "    \n",
        "    for steps in step_values:\n",
        "        print(f\"--- Steps = {steps} ---\")\n",
        "        start = time.time()\n",
        "        images = sd35.generate(steps_prompt, width=768, height=768,\n",
        "                               num_inference_steps=steps, seed=7777)\n",
        "        elapsed = time.time() - start\n",
        "        if images:\n",
        "            steps_results.append((steps, elapsed, images[0]))\n",
        "    \n",
        "    if steps_results:\n",
        "        fig, axes = plt.subplots(1, len(steps_results), figsize=(16, 5))\n",
        "        for i, (steps, t, img) in enumerate(steps_results):\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(f\"Steps={steps}\\n({t:.1f}s)\")\n",
        "            axes[i].axis('off')\n",
        "        plt.suptitle(\"Impact des Inference Steps\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f SD35 non initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "## 7. Styles Artistiques"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 7. STYLES ARTISTIQUES\n",
        "# =============================================================================\n",
        "\n",
        "if sd35:\n",
        "    base_subject = \"a ancient tree in a mystical forest\"\n",
        "    \n",
        "    styles = {\n",
        "        \"Photorealistic\": f\"{base_subject}, photorealistic, natural lighting, 8k\",\n",
        "        \"Oil Painting\": f\"{base_subject}, oil painting, impressionist, brushstrokes\",\n",
        "        \"Anime\": f\"{base_subject}, anime style, Studio Ghibli, vibrant colors\",\n",
        "        \"Watercolor\": f\"{base_subject}, watercolor painting, soft edges, pastel\",\n",
        "    }\n",
        "    \n",
        "    print(\"\\n\ud83c\udfa8 Styles Artistiques\")\n",
        "    style_results = []\n",
        "    \n",
        "    for style_name, prompt in styles.items():\n",
        "        print(f\"--- {style_name} ---\")\n",
        "        images = sd35.generate(prompt, width=768, height=768, seed=5555)\n",
        "        if images:\n",
        "            style_results.append((style_name, images[0]))\n",
        "    \n",
        "    if style_results:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "        axes = axes.flatten()\n",
        "        for i, (style, img) in enumerate(style_results):\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(style, fontsize=12)\n",
        "            axes[i].axis('off')\n",
        "        plt.suptitle(\"Comparaison des Styles\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f SD35 non initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-12",
      "metadata": {},
      "source": [
        "## 8. Exercices Pratiques\n",
        "\n",
        "### Exercice 1: Portrait Artistique\n",
        "Cr\u00e9ez un portrait avec le style \"Oil Painting\" et diff\u00e9rentes valeurs CFG.\n",
        "\n",
        "### Exercice 2: Comparaison Negative Prompts\n",
        "Testez l'impact de diff\u00e9rents negative prompts sur la qualit\u00e9.\n",
        "\n",
        "### Exercice 3: Exploration Ratios\n",
        "G\u00e9n\u00e9rez la m\u00eame sc\u00e8ne en 1:1, 16:9 et 9:16."
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 8. ESPACE D'EXERCICES\n",
        "# =============================================================================\n",
        "\n",
        "# D\u00e9commentez pour tester:\n",
        "\n",
        "# portrait_prompt = \"Portrait of a wise elderly man, oil painting style, Rembrandt lighting\"\n",
        "# if sd35:\n",
        "#     for cfg in [3.0, 5.0, 7.0]:\n",
        "#         images = sd35.generate(portrait_prompt, guidance_scale=cfg, seed=42)\n",
        "#         plt.imshow(images[0])\n",
        "#         plt.title(f\"CFG={cfg}\")\n",
        "#         plt.show()\n",
        "\n",
        "print(\"\ud83d\udcdd D\u00e9commentez le code pour commencer les exercices\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {},
      "source": [
        "## 9. Nettoyage M\u00e9moire"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 9. NETTOYAGE\n",
        "# =============================================================================\n",
        "\n",
        "if sd35:\n",
        "    print(\"\ud83e\uddf9 Lib\u00e9ration m\u00e9moire...\")\n",
        "    if torch.cuda.is_available():\n",
        "        vram_before = torch.cuda.memory_allocated() / 1e9\n",
        "    sd35.unload()\n",
        "    if torch.cuda.is_available():\n",
        "        vram_after = torch.cuda.memory_allocated() / 1e9\n",
        "        print(f\"   Lib\u00e9r\u00e9: {vram_before - vram_after:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## 10. R\u00e9capitulatif\n",
        "\n",
        "### Param\u00e8tres SD 3.5\n",
        "\n",
        "| Param\u00e8tre | Standard | Turbo |\n",
        "|-----------|----------|-------|\n",
        "| `steps` | 28-50 | 4 |\n",
        "| `guidance_scale` | 4.0-7.5 | 0.0 |\n",
        "| `width/height` | 1024 | 1024 |\n",
        "\n",
        "### Points Cl\u00e9s\n",
        "\n",
        "1. **MMDiT** pour meilleure coh\u00e9rence\n",
        "2. **Triple encodeur** (CLIP-L, CLIP-G, T5)\n",
        "3. **Turbo** pour g\u00e9n\u00e9ration rapide\n",
        "4. **Toujours lib\u00e9rer** la m\u00e9moire apr\u00e8s usage"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FIN DU NOTEBOOK\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"   \u2705 Notebook Stable Diffusion 3.5 Compl\u00e9t\u00e9\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n\ud83d\udcc5 Termin\u00e9: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"\\n\ud83d\udcda Concepts couverts:\")\n",
        "print(\"   \u2022 Architecture MMDiT\")\n",
        "print(\"   \u2022 Variantes (Large, Turbo, Medium)\")\n",
        "print(\"   \u2022 CFG et Inference Steps\")\n",
        "print(\"   \u2022 Styles artistiques\")\n",
        "print(\"\\n\u27a1\ufe0f  Prochain module: 03-Images-Orchestration/\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}