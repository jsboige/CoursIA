{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# FLUX.1 - G\u00e9n\u00e9ration d'Images Avanc\u00e9e\n",
        "\n",
        "**Module :** 02-Images-Advanced  \n",
        "**Niveau :** Interm\u00e9diaire/Avanc\u00e9  \n",
        "**Dur\u00e9e estim\u00e9e :** 45 minutes  \n",
        "\n",
        "## Introduction\n",
        "\n",
        "**FLUX.1** est un mod\u00e8le de g\u00e9n\u00e9ration d'images de pointe d\u00e9velopp\u00e9 par Black Forest Labs (\u00e9quipe fondatrice de Stable Diffusion). Il repr\u00e9sente une avanc\u00e9e significative en termes de qualit\u00e9 et de fid\u00e9lit\u00e9 au prompt.\n",
        "\n",
        "### Variantes FLUX.1\n",
        "\n",
        "| Variante | Licence | Caract\u00e9ristiques | Utilisation |\n",
        "|----------|---------|------------------|-------------|\n",
        "| **FLUX.1-pro** | Propri\u00e9taire | Meilleure qualit\u00e9, API uniquement | Production |\n",
        "| **FLUX.1-dev** | Non-commercial | Haute qualit\u00e9, LoRA support\u00e9 | Recherche |\n",
        "| **FLUX.1-schnell** | Apache 2.0 | Ultra-rapide (4 steps), local | Prototypage |\n",
        "\n",
        "### Architecture\n",
        "\n",
        "```\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502                    FLUX.1 Architecture                  \u2502\n",
        "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
        "\u2502   Text Prompt                                           \u2502\n",
        "\u2502       \u2193                                                 \u2502\n",
        "\u2502   [T5-XXL Encoder] + [CLIP-L Encoder]                  \u2502\n",
        "\u2502       \u2193              \u2193                                  \u2502\n",
        "\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n",
        "\u2502   \u2502   Multimodal DiT (Diffusion       \u2502                \u2502\n",
        "\u2502   \u2502   Transformer with Flow Matching) \u2502                \u2502\n",
        "\u2502   \u2502   - 12B parameters                \u2502                \u2502\n",
        "\u2502   \u2502   - Rotary Position Embeddings    \u2502                \u2502\n",
        "\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n",
        "\u2502       \u2193                                                 \u2502\n",
        "\u2502   [VAE Decoder] \u2192 Output Image                         \u2502\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "```\n",
        "\n",
        "## Pr\u00e9requis\n",
        "\n",
        "- Module 00-GenAI-Environment compl\u00e9t\u00e9\n",
        "- GPU avec 12GB+ VRAM (pour ex\u00e9cution locale)\n",
        "- Ou cl\u00e9 API pour services cloud (fal.ai, Replicate)"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 1. CONFIGURATION ET IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import base64\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Optional, Dict, List, Tuple, Any, Union\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Chargement variables d'environnement\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"../.env\")\n",
        "load_dotenv(\"../00-GenAI-Environment/.env\")\n",
        "\n",
        "# Configuration\n",
        "FAL_API_KEY = os.getenv(\"FAL_API_KEY\")\n",
        "REPLICATE_API_KEY = os.getenv(\"REPLICATE_API_TOKEN\")\n",
        "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\") or os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "# D\u00e9tection du mode d'ex\u00e9cution\n",
        "USE_LOCAL = False  # Chang\u00e9 dynamiquement si GPU disponible\n",
        "USE_API = bool(FAL_API_KEY or REPLICATE_API_KEY)\n",
        "\n",
        "print(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\")\n",
        "print(\"\u2551   FLUX.1 - G\u00e9n\u00e9ration d'Images Avanc\u00e9e            \u2551\")\n",
        "print(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\")\n",
        "print(f\"\\n\ud83d\udcc5 Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"\\n\ud83d\udd11 Configuration API:\")\n",
        "print(f\"   FAL.ai: {'\u2705 Configur\u00e9' if FAL_API_KEY else '\u274c Non configur\u00e9'}\")\n",
        "print(f\"   Replicate: {'\u2705 Configur\u00e9' if REPLICATE_API_KEY else '\u274c Non configur\u00e9'}\")\n",
        "print(f\"   HuggingFace: {'\u2705 Configur\u00e9' if HF_TOKEN else '\u274c Non configur\u00e9'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
            "\u2551   FLUX.1 - G\u00e9n\u00e9ration d'Images Avanc\u00e9e            \u2551\n",
            "\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
            "\n",
            "\ud83d\udcc5 Date: 2026-02-18 10:03:21\n",
            "\n",
            "\ud83d\udd11 Configuration API:\n",
            "   FAL.ai: \u274c Non configur\u00e9\n",
            "   Replicate: \u274c Non configur\u00e9\n",
            "   HuggingFace: \u274c Non configur\u00e9\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 2. D\u00c9TECTION GPU ET CHARGEMENT DIFFUSERS (LOCAL)\n",
        "# =============================================================================\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        print(f\"\\n\ud83c\udfae GPU D\u00e9tect\u00e9: {gpu_name}\")\n",
        "        print(f\"   VRAM: {gpu_memory:.1f} GB\")\n",
        "        \n",
        "        # FLUX.1-schnell requiert ~12GB, dev ~24GB\n",
        "        if gpu_memory >= 12:\n",
        "            USE_LOCAL = True\n",
        "            print(f\"   \u2705 Suffisant pour FLUX.1-schnell en local\")\n",
        "        else:\n",
        "            print(f\"   \u26a0\ufe0f VRAM insuffisant pour FLUX local, utilisation API\")\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "        print(\"\\n\u26a0\ufe0f Pas de GPU CUDA d\u00e9tect\u00e9 - Mode API recommand\u00e9\")\n",
        "except ImportError:\n",
        "    device = \"cpu\"\n",
        "    print(\"\\n\u26a0\ufe0f PyTorch non install\u00e9 - Mode API uniquement\")\n",
        "\n",
        "# Tentative de chargement diffusers\n",
        "flux_pipeline = None\n",
        "\n",
        "if USE_LOCAL:\n",
        "    try:\n",
        "        from diffusers import FluxPipeline\n",
        "        print(\"\\n\ud83d\udce6 Diffusers disponible pour FLUX local\")\n",
        "    except ImportError:\n",
        "        print(\"\\n\u26a0\ufe0f diffusers non install\u00e9: pip install diffusers transformers accelerate\")\n",
        "        USE_LOCAL = False\n",
        "\n",
        "print(f\"\\n\ud83d\udd27 Mode d'ex\u00e9cution: {'Local (GPU)' if USE_LOCAL else 'API Cloud'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u26a0\ufe0f Pas de GPU CUDA d\u00e9tect\u00e9 - Mode API recommand\u00e9\n",
            "\n",
            "\ud83d\udd27 Mode d'ex\u00e9cution: API Cloud\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 3. CLIENT FLUX.1 UNIFI\u00c9 (Local + API)\n",
        "# =============================================================================\n",
        "\n",
        "class FluxClient:\n",
        "    \"\"\"\n",
        "    Client unifi\u00e9 pour FLUX.1 supportant:\n",
        "    - Ex\u00e9cution locale via diffusers\n",
        "    - API fal.ai\n",
        "    - API Replicate\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, mode: str = \"auto\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            mode: \"local\", \"fal\", \"replicate\", ou \"auto\" (d\u00e9tection automatique)\n",
        "        \"\"\"\n",
        "        self.mode = mode\n",
        "        self.pipeline = None\n",
        "        \n",
        "        if mode == \"auto\":\n",
        "            if USE_LOCAL:\n",
        "                self.mode = \"local\"\n",
        "            elif FAL_API_KEY:\n",
        "                self.mode = \"fal\"\n",
        "            elif REPLICATE_API_KEY:\n",
        "                self.mode = \"replicate\"\n",
        "            else:\n",
        "                raise ValueError(\"Aucun backend disponible. Configurez une API ou installez diffusers.\")\n",
        "        \n",
        "        print(f\"\ud83d\udd0c FluxClient initialis\u00e9 en mode: {self.mode}\")\n",
        "    \n",
        "    def load_local_model(self, model_id: str = \"black-forest-labs/FLUX.1-schnell\"):\n",
        "        \"\"\"Charge le mod\u00e8le FLUX localement (GPU requis).\"\"\"\n",
        "        if self.mode != \"local\":\n",
        "            print(\"\u26a0\ufe0f Mode local non disponible\")\n",
        "            return\n",
        "        \n",
        "        from diffusers import FluxPipeline\n",
        "        import torch\n",
        "        \n",
        "        print(f\"\\n\ud83d\udce5 Chargement de {model_id}...\")\n",
        "        print(\"   (Cela peut prendre plusieurs minutes au premier lancement)\")\n",
        "        \n",
        "        self.pipeline = FluxPipeline.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            token=HF_TOKEN\n",
        "        )\n",
        "        self.pipeline.to(\"cuda\")\n",
        "        \n",
        "        # Optimisations m\u00e9moire\n",
        "        self.pipeline.enable_model_cpu_offload()\n",
        "        \n",
        "        print(\"   \u2705 Mod\u00e8le charg\u00e9\")\n",
        "    \n",
        "    def generate(self, prompt: str, \n",
        "                 width: int = 1024, height: int = 1024,\n",
        "                 num_inference_steps: int = 4,\n",
        "                 guidance_scale: float = 0.0,\n",
        "                 seed: int = None,\n",
        "                 num_images: int = 1) -> List[Image.Image]:\n",
        "        \"\"\"\n",
        "        G\u00e9n\u00e8re des images avec FLUX.1.\n",
        "        \n",
        "        Args:\n",
        "            prompt: Description de l'image\n",
        "            width, height: Dimensions (multiples de 8)\n",
        "            num_inference_steps: Nombre d'\u00e9tapes (schnell: 1-4, dev: 20-50)\n",
        "            guidance_scale: CFG (0 pour schnell, 3.5 pour dev)\n",
        "            seed: Graine pour reproductibilit\u00e9\n",
        "            num_images: Nombre d'images \u00e0 g\u00e9n\u00e9rer\n",
        "        \n",
        "        Returns:\n",
        "            Liste d'images PIL\n",
        "        \"\"\"\n",
        "        if seed is None:\n",
        "            seed = np.random.randint(0, 2**32)\n",
        "        \n",
        "        if self.mode == \"local\":\n",
        "            return self._generate_local(prompt, width, height, num_inference_steps, \n",
        "                                        guidance_scale, seed, num_images)\n",
        "        elif self.mode == \"fal\":\n",
        "            return self._generate_fal(prompt, width, height, num_inference_steps,\n",
        "                                      guidance_scale, seed, num_images)\n",
        "        elif self.mode == \"replicate\":\n",
        "            return self._generate_replicate(prompt, width, height, num_inference_steps,\n",
        "                                            guidance_scale, seed, num_images)\n",
        "        else:\n",
        "            raise ValueError(f\"Mode inconnu: {self.mode}\")\n",
        "    \n",
        "    def _generate_local(self, prompt, width, height, steps, guidance, seed, num_images):\n",
        "        \"\"\"G\u00e9n\u00e9ration locale avec diffusers.\"\"\"\n",
        "        import torch\n",
        "        \n",
        "        if self.pipeline is None:\n",
        "            self.load_local_model()\n",
        "        \n",
        "        generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "        \n",
        "        print(f\"\\n\ud83c\udfa8 G\u00e9n\u00e9ration locale (seed: {seed})...\")\n",
        "        start = time.time()\n",
        "        \n",
        "        result = self.pipeline(\n",
        "            prompt=prompt,\n",
        "            width=width,\n",
        "            height=height,\n",
        "            num_inference_steps=steps,\n",
        "            guidance_scale=guidance,\n",
        "            generator=generator,\n",
        "            num_images_per_prompt=num_images\n",
        "        )\n",
        "        \n",
        "        elapsed = time.time() - start\n",
        "        print(f\"   \u2705 G\u00e9n\u00e9r\u00e9 en {elapsed:.1f}s\")\n",
        "        \n",
        "        return result.images\n",
        "    \n",
        "    def _generate_fal(self, prompt, width, height, steps, guidance, seed, num_images):\n",
        "        \"\"\"G\u00e9n\u00e9ration via fal.ai API.\"\"\"\n",
        "        print(f\"\\n\ud83c\udf10 G\u00e9n\u00e9ration via fal.ai (seed: {seed})...\")\n",
        "        \n",
        "        headers = {\n",
        "            \"Authorization\": f\"Key {FAL_API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        \n",
        "        # Endpoint pour FLUX.1-schnell\n",
        "        url = \"https://fal.run/fal-ai/flux/schnell\"\n",
        "        \n",
        "        payload = {\n",
        "            \"prompt\": prompt,\n",
        "            \"image_size\": {\"width\": width, \"height\": height},\n",
        "            \"num_inference_steps\": steps,\n",
        "            \"seed\": seed,\n",
        "            \"num_images\": num_images\n",
        "        }\n",
        "        \n",
        "        start = time.time()\n",
        "        resp = requests.post(url, headers=headers, json=payload, timeout=120)\n",
        "        \n",
        "        if resp.status_code != 200:\n",
        "            raise Exception(f\"fal.ai error: {resp.text}\")\n",
        "        \n",
        "        result = resp.json()\n",
        "        elapsed = time.time() - start\n",
        "        \n",
        "        # T\u00e9l\u00e9charger les images\n",
        "        images = []\n",
        "        for img_data in result.get(\"images\", []):\n",
        "            img_url = img_data.get(\"url\")\n",
        "            if img_url:\n",
        "                img_resp = requests.get(img_url)\n",
        "                images.append(Image.open(BytesIO(img_resp.content)))\n",
        "        \n",
        "        print(f\"   \u2705 G\u00e9n\u00e9r\u00e9 en {elapsed:.1f}s ({len(images)} images)\")\n",
        "        return images\n",
        "    \n",
        "    def _generate_replicate(self, prompt, width, height, steps, guidance, seed, num_images):\n",
        "        \"\"\"G\u00e9n\u00e9ration via Replicate API.\"\"\"\n",
        "        print(f\"\\n\ud83c\udf10 G\u00e9n\u00e9ration via Replicate (seed: {seed})...\")\n",
        "        \n",
        "        headers = {\n",
        "            \"Authorization\": f\"Token {REPLICATE_API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        \n",
        "        # Cr\u00e9er la pr\u00e9diction\n",
        "        url = \"https://api.replicate.com/v1/predictions\"\n",
        "        \n",
        "        payload = {\n",
        "            \"version\": \"schnell\",  # ou \"dev\" pour FLUX.1-dev\n",
        "            \"input\": {\n",
        "                \"prompt\": prompt,\n",
        "                \"width\": width,\n",
        "                \"height\": height,\n",
        "                \"num_inference_steps\": steps,\n",
        "                \"guidance_scale\": guidance,\n",
        "                \"seed\": seed,\n",
        "                \"num_outputs\": num_images\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        start = time.time()\n",
        "        resp = requests.post(url, headers=headers, json=payload)\n",
        "        \n",
        "        if resp.status_code not in [200, 201]:\n",
        "            raise Exception(f\"Replicate error: {resp.text}\")\n",
        "        \n",
        "        prediction = resp.json()\n",
        "        prediction_id = prediction[\"id\"]\n",
        "        \n",
        "        # Polling pour attendre le r\u00e9sultat\n",
        "        status_url = f\"https://api.replicate.com/v1/predictions/{prediction_id}\"\n",
        "        while True:\n",
        "            status_resp = requests.get(status_url, headers=headers)\n",
        "            status = status_resp.json()\n",
        "            \n",
        "            if status[\"status\"] == \"succeeded\":\n",
        "                break\n",
        "            elif status[\"status\"] == \"failed\":\n",
        "                raise Exception(f\"Generation failed: {status.get('error')}\")\n",
        "            \n",
        "            time.sleep(1)\n",
        "        \n",
        "        elapsed = time.time() - start\n",
        "        \n",
        "        # T\u00e9l\u00e9charger les images\n",
        "        images = []\n",
        "        for img_url in status.get(\"output\", []):\n",
        "            img_resp = requests.get(img_url)\n",
        "            images.append(Image.open(BytesIO(img_resp.content)))\n",
        "        \n",
        "        print(f\"   \u2705 G\u00e9n\u00e9r\u00e9 en {elapsed:.1f}s ({len(images)} images)\")\n",
        "        return images\n",
        "\n",
        "\n",
        "# Instanciation du client\n",
        "try:\n",
        "    flux = FluxClient(mode=\"auto\")\n",
        "except ValueError as e:\n",
        "    print(f\"\\n\u26a0\ufe0f {e}\")\n",
        "    print(\"\\nPour utiliser ce notebook, configurez:\")\n",
        "    print(\"  - FAL_API_KEY dans .env (recommand\u00e9)\")\n",
        "    print(\"  - Ou REPLICATE_API_TOKEN dans .env\")\n",
        "    print(\"  - Ou installez diffusers avec un GPU 12GB+\")\n",
        "    flux = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-4",
      "metadata": {},
      "source": [
        "## 4. G\u00e9n\u00e9ration de Base avec FLUX.1-schnell\n",
        "\n",
        "FLUX.1-schnell est optimis\u00e9 pour la rapidit\u00e9 (1-4 steps) tout en maintenant une bonne qualit\u00e9."
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u26a0\ufe0f Aucun backend disponible. Configurez une API ou installez diffusers.\n",
            "\n",
            "Pour utiliser ce notebook, configurez:\n",
            "  - FAL_API_KEY dans .env (recommand\u00e9)\n",
            "  - Ou REPLICATE_API_TOKEN dans .env\n",
            "  - Ou installez diffusers avec un GPU 12GB+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 4. G\u00c9N\u00c9RATION DE BASE\n",
        "# =============================================================================\n",
        "\n",
        "if flux:\n",
        "    # Prompt de d\u00e9monstration\n",
        "    demo_prompt = \"\"\"\n",
        "    A serene Japanese zen garden at golden hour, \n",
        "    carefully raked sand patterns, moss-covered stones, \n",
        "    a small wooden bridge over a koi pond, \n",
        "    cherry blossoms falling gently, \n",
        "    photorealistic, 8k, masterpiece\n",
        "    \"\"\".strip()\n",
        "    \n",
        "    print(f\"\\n\ud83d\udcdd Prompt: {demo_prompt[:80]}...\")\n",
        "    \n",
        "    # G\u00e9n\u00e9ration avec FLUX.1-schnell (4 steps)\n",
        "    images = flux.generate(\n",
        "        prompt=demo_prompt,\n",
        "        width=1024,\n",
        "        height=1024,\n",
        "        num_inference_steps=4,  # schnell: 1-4 steps\n",
        "        guidance_scale=0.0,     # schnell: pas de guidance\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    if images:\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(images[0])\n",
        "        plt.title(\"FLUX.1-schnell (4 steps)\", fontsize=14)\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        demo_image = images[0]\n",
        "        print(f\"\\n\ud83d\udcd0 Dimensions: {demo_image.size}\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f Client FLUX non initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-6",
      "metadata": {},
      "source": [
        "## 5. Analyse du Nombre d'\u00c9tapes (Inference Steps)\n",
        "\n",
        "Comparons l'impact du nombre d'\u00e9tapes sur la qualit\u00e9 de g\u00e9n\u00e9ration."
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u26a0\ufe0f Client FLUX non initialis\u00e9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 5. ANALYSE DES INFERENCE STEPS\n",
        "# =============================================================================\n",
        "\n",
        "if flux:\n",
        "    test_prompt = \"A majestic wolf standing on a snowy mountain peak, aurora borealis in the sky, cinematic lighting\"\n",
        "    step_values = [1, 2, 4, 8]  # Pour schnell\n",
        "    fixed_seed = 12345\n",
        "    \n",
        "    print(f\"\\n\ud83d\udcca Analyse Inference Steps\")\n",
        "    print(f\"Prompt: '{test_prompt[:50]}...'\")\n",
        "    print(f\"Valeurs test\u00e9es: {step_values}\")\n",
        "    \n",
        "    step_results = []\n",
        "    \n",
        "    for steps in step_values:\n",
        "        print(f\"\\n--- Steps = {steps} ---\")\n",
        "        \n",
        "        images = flux.generate(\n",
        "            prompt=test_prompt,\n",
        "            width=768,\n",
        "            height=768,\n",
        "            num_inference_steps=steps,\n",
        "            guidance_scale=0.0,\n",
        "            seed=fixed_seed\n",
        "        )\n",
        "        \n",
        "        if images:\n",
        "            step_results.append((steps, images[0]))\n",
        "    \n",
        "    # Affichage comparatif\n",
        "    if step_results:\n",
        "        fig, axes = plt.subplots(1, len(step_results), figsize=(16, 5))\n",
        "        \n",
        "        for i, (steps, img) in enumerate(step_results):\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(f\"Steps = {steps}\", fontsize=12)\n",
        "            axes[i].axis('off')\n",
        "        \n",
        "        plt.suptitle(\"Impact du nombre d'\u00e9tapes (FLUX.1-schnell)\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"\\n\ud83d\udcc8 Observations:\")\n",
        "        print(\"   1 step:  Tr\u00e8s rapide, structure de base\")\n",
        "        print(\"   2 steps: Bon compromis vitesse/qualit\u00e9\")\n",
        "        print(\"   4 steps: Qualit\u00e9 optimale pour schnell\")\n",
        "        print(\"   8 steps: Diminishing returns, peu d'am\u00e9lioration\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f Client FLUX non initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-8",
      "metadata": {},
      "source": [
        "## 6. Exploration des Ratios d'Aspect\n",
        "\n",
        "FLUX.1 supporte diff\u00e9rents ratios d'aspect pour des compositions vari\u00e9es."
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u26a0\ufe0f Client FLUX non initialis\u00e9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 6. RATIOS D'ASPECT\n",
        "# =============================================================================\n",
        "\n",
        "if flux:\n",
        "    # Diff\u00e9rents ratios\n",
        "    aspect_ratios = [\n",
        "        (\"1:1 (Carr\u00e9)\", 1024, 1024),\n",
        "        (\"16:9 (Paysage)\", 1024, 576),\n",
        "        (\"9:16 (Portrait)\", 576, 1024),\n",
        "        (\"4:3 (Standard)\", 1024, 768),\n",
        "    ]\n",
        "    \n",
        "    aspect_prompt = \"A stunning sunset over the ocean, vibrant orange and purple sky, silhouette of palm trees, photorealistic\"\n",
        "    \n",
        "    print(f\"\\n\ud83d\uddbc\ufe0f Exploration des Ratios d'Aspect\")\n",
        "    print(f\"Prompt: '{aspect_prompt[:50]}...'\")\n",
        "    \n",
        "    aspect_results = []\n",
        "    \n",
        "    for name, w, h in aspect_ratios:\n",
        "        print(f\"\\n--- {name} ({w}x{h}) ---\")\n",
        "        \n",
        "        images = flux.generate(\n",
        "            prompt=aspect_prompt,\n",
        "            width=w,\n",
        "            height=h,\n",
        "            num_inference_steps=4,\n",
        "            seed=7777\n",
        "        )\n",
        "        \n",
        "        if images:\n",
        "            aspect_results.append((name, images[0]))\n",
        "    \n",
        "    # Affichage\n",
        "    if aspect_results:\n",
        "        fig = plt.figure(figsize=(16, 8))\n",
        "        \n",
        "        for i, (name, img) in enumerate(aspect_results):\n",
        "            ax = fig.add_subplot(2, 2, i+1)\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(name, fontsize=11)\n",
        "            ax.axis('off')\n",
        "        \n",
        "        plt.suptitle(\"Comparaison des Ratios d'Aspect\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f Client FLUX non initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "## 7. Batch Generation: Variations d'un M\u00eame Prompt\n",
        "\n",
        "G\u00e9n\u00e9rons plusieurs variations en changeant uniquement la seed."
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u26a0\ufe0f Client FLUX non initialis\u00e9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 7. BATCH GENERATION - VARIATIONS\n",
        "# =============================================================================\n",
        "\n",
        "if flux:\n",
        "    variation_prompt = \"\"\"\n",
        "    A mystical forest with bioluminescent plants, \n",
        "    glowing mushrooms, fireflies, magical atmosphere, \n",
        "    fantasy art style, highly detailed\n",
        "    \"\"\".strip()\n",
        "    \n",
        "    num_variations = 4\n",
        "    base_seed = 1000\n",
        "    \n",
        "    print(f\"\\n\ud83c\udfb2 G\u00e9n\u00e9ration de {num_variations} variations\")\n",
        "    print(f\"Prompt: '{variation_prompt[:50]}...'\")\n",
        "    \n",
        "    variations = []\n",
        "    \n",
        "    for i in range(num_variations):\n",
        "        seed = base_seed + i * 1000\n",
        "        print(f\"\\n[{i+1}/{num_variations}] Seed: {seed}\")\n",
        "        \n",
        "        images = flux.generate(\n",
        "            prompt=variation_prompt,\n",
        "            width=768,\n",
        "            height=768,\n",
        "            num_inference_steps=4,\n",
        "            seed=seed\n",
        "        )\n",
        "        \n",
        "        if images:\n",
        "            variations.append((seed, images[0]))\n",
        "    \n",
        "    # Affichage grille\n",
        "    if variations:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "        axes = axes.flatten()\n",
        "        \n",
        "        for i, (seed, img) in enumerate(variations):\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(f\"Seed: {seed}\", fontsize=11)\n",
        "            axes[i].axis('off')\n",
        "        \n",
        "        plt.suptitle(\"Variations avec diff\u00e9rentes seeds\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"\\n\u2705 {len(variations)} variations g\u00e9n\u00e9r\u00e9es\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f Client FLUX non initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-12",
      "metadata": {},
      "source": [
        "## 8. Techniques de Prompt Engineering pour FLUX\n",
        "\n",
        "FLUX.1 r\u00e9pond particuli\u00e8rement bien \u00e0 certains styles de prompts."
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u26a0\ufe0f Client FLUX non initialis\u00e9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 8. PROMPT ENGINEERING AVANC\u00c9\n",
        "# =============================================================================\n",
        "\n",
        "# Templates de prompts efficaces pour FLUX\n",
        "prompt_templates = {\n",
        "    \"photorealistic\": {\n",
        "        \"prefix\": \"A photorealistic image of\",\n",
        "        \"suffix\": \", shot with a Canon EOS R5, 85mm f/1.4, natural lighting, 8k resolution\",\n",
        "        \"example\": \"a woman in a red dress walking through autumn leaves\"\n",
        "    },\n",
        "    \"cinematic\": {\n",
        "        \"prefix\": \"Cinematic still from a movie,\",\n",
        "        \"suffix\": \", dramatic lighting, anamorphic lens, film grain, color graded\",\n",
        "        \"example\": \"a detective in a noir city at night under rain\"\n",
        "    },\n",
        "    \"illustration\": {\n",
        "        \"prefix\": \"Digital illustration of\",\n",
        "        \"suffix\": \", artstation trending, vibrant colors, highly detailed, concept art\",\n",
        "        \"example\": \"a steampunk airship flying over a Victorian city\"\n",
        "    },\n",
        "    \"anime\": {\n",
        "        \"prefix\": \"Anime artwork of\",\n",
        "        \"suffix\": \", Studio Ghibli style, beautiful scenery, soft colors, detailed\",\n",
        "        \"example\": \"a young adventurer discovering a hidden temple in the forest\"\n",
        "    }\n",
        "}\n",
        "\n",
        "if flux:\n",
        "    print(\"\\n\ud83c\udfa8 Comparaison des Styles de Prompts\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    style_results = []\n",
        "    fixed_seed = 9999\n",
        "    \n",
        "    for style_name, template in prompt_templates.items():\n",
        "        full_prompt = f\"{template['prefix']} {template['example']}{template['suffix']}\"\n",
        "        \n",
        "        print(f\"\\n--- Style: {style_name.upper()} ---\")\n",
        "        print(f\"   Prompt: {full_prompt[:60]}...\")\n",
        "        \n",
        "        images = flux.generate(\n",
        "            prompt=full_prompt,\n",
        "            width=768,\n",
        "            height=768,\n",
        "            num_inference_steps=4,\n",
        "            seed=fixed_seed\n",
        "        )\n",
        "        \n",
        "        if images:\n",
        "            style_results.append((style_name, images[0]))\n",
        "    \n",
        "    # Affichage\n",
        "    if style_results:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 14))\n",
        "        axes = axes.flatten()\n",
        "        \n",
        "        for i, (style, img) in enumerate(style_results):\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(f\"Style: {style.capitalize()}\", fontsize=12)\n",
        "            axes[i].axis('off')\n",
        "        \n",
        "        plt.suptitle(\"Comparaison des Styles de Prompt\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f Client FLUX non initialis\u00e9\")\n",
        "    print(\"\\nVoici les templates de prompt recommand\u00e9s pour FLUX:\")\n",
        "    for style, template in prompt_templates.items():\n",
        "        print(f\"\\n{style.upper()}:\")\n",
        "        print(f\"  Pr\u00e9fixe: {template['prefix']}\")\n",
        "        print(f\"  Suffixe: {template['suffix']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {},
      "source": [
        "## 9. G\u00e9n\u00e9ration de Texte dans les Images\n",
        "\n",
        "FLUX.1 excelle particuli\u00e8rement dans le rendu de texte lisible dans les images."
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u26a0\ufe0f Client FLUX non initialis\u00e9\n",
            "\n",
            "Voici les templates de prompt recommand\u00e9s pour FLUX:\n",
            "\n",
            "PHOTOREALISTIC:\n",
            "  Pr\u00e9fixe: A photorealistic image of\n",
            "  Suffixe: , shot with a Canon EOS R5, 85mm f/1.4, natural lighting, 8k resolution\n",
            "\n",
            "CINEMATIC:\n",
            "  Pr\u00e9fixe: Cinematic still from a movie,\n",
            "  Suffixe: , dramatic lighting, anamorphic lens, film grain, color graded\n",
            "\n",
            "ILLUSTRATION:\n",
            "  Pr\u00e9fixe: Digital illustration of\n",
            "  Suffixe: , artstation trending, vibrant colors, highly detailed, concept art\n",
            "\n",
            "ANIME:\n",
            "  Pr\u00e9fixe: Anime artwork of\n",
            "  Suffixe: , Studio Ghibli style, beautiful scenery, soft colors, detailed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 9. G\u00c9N\u00c9RATION DE TEXTE DANS LES IMAGES\n",
        "# =============================================================================\n",
        "\n",
        "if flux:\n",
        "    text_prompts = [\n",
        "        'A vintage neon sign that says \"OPEN 24 HOURS\" glowing in the night, realistic',\n",
        "        'A birthday cake with elegant cursive text reading \"Happy Birthday Sarah\" in icing',\n",
        "        'A wooden street sign pointing right with the text \"Adventure Awaits\" carved into it',\n",
        "        'A coffee cup with \"Good Morning!\" written in latte art'\n",
        "    ]\n",
        "    \n",
        "    print(\"\\n\u270d\ufe0f Test de G\u00e9n\u00e9ration de Texte\")\n",
        "    print(\"FLUX.1 est reconnu pour sa capacit\u00e9 \u00e0 g\u00e9n\u00e9rer du texte lisible.\")\n",
        "    \n",
        "    text_results = []\n",
        "    \n",
        "    for i, prompt in enumerate(text_prompts):\n",
        "        print(f\"\\n[{i+1}/{len(text_prompts)}] {prompt[:50]}...\")\n",
        "        \n",
        "        images = flux.generate(\n",
        "            prompt=prompt,\n",
        "            width=768,\n",
        "            height=768,\n",
        "            num_inference_steps=4,\n",
        "            seed=2024 + i\n",
        "        )\n",
        "        \n",
        "        if images:\n",
        "            text_results.append((prompt.split('\"')[1] if '\"' in prompt else prompt[:20], images[0]))\n",
        "    \n",
        "    # Affichage\n",
        "    if text_results:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "        axes = axes.flatten()\n",
        "        \n",
        "        for i, (text, img) in enumerate(text_results):\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(f'Texte: \"{text}\"', fontsize=10)\n",
        "            axes[i].axis('off')\n",
        "        \n",
        "        plt.suptitle(\"Capacit\u00e9 de G\u00e9n\u00e9ration de Texte\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f Client FLUX non initialis\u00e9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## 10. Exercices Pratiques\n",
        "\n",
        "### Exercice 1: Portrait Professionnel\n",
        "Utilisez le template \"photorealistic\" pour g\u00e9n\u00e9rer un portrait professionnel d'une personne de votre choix.\n",
        "\n",
        "### Exercice 2: Exploration des Seeds\n",
        "Gardez le m\u00eame prompt et g\u00e9n\u00e9rez 6 variations en changeant la seed. Identifiez celle qui correspond le mieux \u00e0 votre vision.\n",
        "\n",
        "### Exercice 3: Texte Cr\u00e9atif\n",
        "Cr\u00e9ez une image contenant un message personnalis\u00e9 (ex: affiche de film, couverture de livre)."
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u26a0\ufe0f Client FLUX non initialis\u00e9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 10. ESPACE D'EXERCICES\n",
        "# =============================================================================\n",
        "\n",
        "# Exercice 1: Portrait Professionnel\n",
        "# D\u00e9commentez et personnalisez:\n",
        "\n",
        "# portrait_prompt = \"\"\"\n",
        "# A photorealistic portrait of a professional woman in her 30s,\n",
        "# wearing a navy blue blazer, confident smile,\n",
        "# shot with a Canon EOS R5, 85mm f/1.4, studio lighting,\n",
        "# clean white background, corporate headshot\n",
        "# \"\"\"\n",
        "# \n",
        "# if flux:\n",
        "#     images = flux.generate(portrait_prompt, width=768, height=1024, seed=42)\n",
        "#     if images:\n",
        "#         plt.imshow(images[0])\n",
        "#         plt.axis('off')\n",
        "#         plt.show()\n",
        "\n",
        "print(\"\ud83d\udcdd Espace d'exercices - D\u00e9commentez le code ci-dessus pour commencer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-18",
      "metadata": {},
      "source": [
        "## 11. R\u00e9capitulatif et Points Cl\u00e9s\n",
        "\n",
        "### Param\u00e8tres FLUX.1\n",
        "\n",
        "| Param\u00e8tre | Schnell | Dev | Description |\n",
        "|-----------|---------|-----|-------------|\n",
        "| `num_inference_steps` | 1-4 | 20-50 | Nombre d'it\u00e9rations |\n",
        "| `guidance_scale` | 0.0 | 3.0-7.0 | Adh\u00e9rence au prompt |\n",
        "| `width/height` | 512-2048 | 512-2048 | Multiples de 8 |\n",
        "\n",
        "### Points Forts de FLUX.1\n",
        "\n",
        "1. **G\u00e9n\u00e9ration de texte** exceptionnelle\n",
        "2. **Rapidit\u00e9** avec schnell (1-4 steps)\n",
        "3. **Qualit\u00e9 photo-r\u00e9aliste** sup\u00e9rieure\n",
        "4. **Compr\u00e9hension des prompts** avanc\u00e9e\n",
        "5. **Support LoRA** (dev uniquement)\n",
        "\n",
        "### Bonnes Pratiques\n",
        "\n",
        "- Utilisez **schnell** pour le prototypage rapide\n",
        "- Passez \u00e0 **dev** pour la qualit\u00e9 finale\n",
        "- Sp\u00e9cifiez le style photographique/artistique dans le prompt\n",
        "- Pour le texte, encadrez-le avec des guillemets dans le prompt\n",
        "\n",
        "### Ressources\n",
        "\n",
        "- [FLUX.1 on HuggingFace](https://huggingface.co/black-forest-labs)\n",
        "- [fal.ai Documentation](https://fal.ai/models/fal-ai/flux)\n",
        "- Notebook suivant: **02-3-Stable-Diffusion-3-5**"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udcdd Espace d'exercices - D\u00e9commentez le code ci-dessus pour commencer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-19",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FIN DU NOTEBOOK\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"   \u2705 Notebook FLUX.1 Advanced Generation Compl\u00e9t\u00e9\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n\ud83d\udcc5 Termin\u00e9: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"\\n\ud83d\udcda Concepts couverts:\")\n",
        "print(\"   \u2022 Architecture FLUX.1 (schnell, dev, pro)\")\n",
        "print(\"   \u2022 Client unifi\u00e9 (local + API)\")\n",
        "print(\"   \u2022 Analyse des inference steps\")\n",
        "print(\"   \u2022 Ratios d'aspect\")\n",
        "print(\"   \u2022 Prompt engineering avanc\u00e9\")\n",
        "print(\"   \u2022 G\u00e9n\u00e9ration de texte dans les images\")\n",
        "print(\"\\n\u27a1\ufe0f  Prochain notebook: 02-3-Stable-Diffusion-3-5.ipynb\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}