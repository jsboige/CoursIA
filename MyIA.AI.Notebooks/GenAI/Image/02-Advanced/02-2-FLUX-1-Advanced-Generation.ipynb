{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {
    "papermill": {
     "duration": 0.009948,
     "end_time": "2026-02-25T19:52:25.737033",
     "exception": false,
     "start_time": "2026-02-25T19:52:25.727085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FLUX.1 - G√©n√©ration d'Images Avanc√©e\n",
    "\n",
    "**Module :** 02-Images-Advanced  \n",
    "**Niveau :** Interm√©diaire/Avanc√©  \n",
    "**Dur√©e estim√©e :** 45 minutes  \n",
    "\n",
    "## Introduction\n",
    "\n",
    "**FLUX.1** est un mod√®le de g√©n√©ration d'images de pointe d√©velopp√© par Black Forest Labs (√©quipe fondatrice de Stable Diffusion). Il repr√©sente une avanc√©e significative en termes de qualit√© et de fid√©lit√© au prompt.\n",
    "\n",
    "### Variantes FLUX.1\n",
    "\n",
    "| Variante | Licence | Caract√©ristiques | Utilisation |\n",
    "|----------|---------|------------------|-------------|\n",
    "| **FLUX.1-pro** | Propri√©taire | Meilleure qualit√©, API uniquement | Production |\n",
    "| **FLUX.1-dev** | Non-commercial | Haute qualit√©, LoRA support√© | Recherche |\n",
    "| **FLUX.1-schnell** | Apache 2.0 | Ultra-rapide (4 steps), local | Prototypage |\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    FLUX.1 Architecture                  ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ   Text Prompt                                           ‚îÇ\n",
    "‚îÇ       ‚Üì                                                 ‚îÇ\n",
    "‚îÇ   [T5-XXL Encoder] + [CLIP-L Encoder]                  ‚îÇ\n",
    "‚îÇ       ‚Üì              ‚Üì                                  ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ\n",
    "‚îÇ   ‚îÇ   Multimodal DiT (Diffusion       ‚îÇ                ‚îÇ\n",
    "‚îÇ   ‚îÇ   Transformer with Flow Matching) ‚îÇ                ‚îÇ\n",
    "‚îÇ   ‚îÇ   - 12B parameters                ‚îÇ                ‚îÇ\n",
    "‚îÇ   ‚îÇ   - Rotary Position Embeddings    ‚îÇ                ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ\n",
    "‚îÇ       ‚Üì                                                 ‚îÇ\n",
    "‚îÇ   [VAE Decoder] ‚Üí Output Image                         ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "## Pr√©requis\n",
    "\n",
    "- Module 00-GenAI-Environment compl√©t√©\n",
    "- GPU avec 12GB+ VRAM (pour ex√©cution locale)\n",
    "- Ou cl√© API pour services cloud (fal.ai, Replicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:25.746064Z",
     "iopub.status.busy": "2026-02-25T19:52:25.745867Z",
     "iopub.status.idle": "2026-02-25T19:52:26.356064Z",
     "shell.execute_reply": "2026-02-25T19:52:26.355592Z"
    },
    "papermill": {
     "duration": 0.615815,
     "end_time": "2026-02-25T19:52:26.357245",
     "exception": false,
     "start_time": "2026-02-25T19:52:25.741430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë   FLUX.1 - G√©n√©ration d'Images Avanc√©e            ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n",
      "üìÖ Date: 2026-02-25 20:52:26\n",
      "\n",
      "üîë Configuration API:\n",
      "   FAL.ai: ‚ùå Non configur√©\n",
      "   Replicate: ‚ùå Non configur√©\n",
      "   HuggingFace: ‚ùå Non configur√©\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. CONFIGURATION ET IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, List, Tuple, Any, Union\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chargement variables d'environnement\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "load_dotenv(\"../00-GenAI-Environment/.env\")\n",
    "\n",
    "# Configuration\n",
    "FAL_API_KEY = os.getenv(\"FAL_API_KEY\")\n",
    "REPLICATE_API_KEY = os.getenv(\"REPLICATE_API_TOKEN\")\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\") or os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# D√©tection du mode d'ex√©cution\n",
    "USE_LOCAL = False  # Chang√© dynamiquement si GPU disponible\n",
    "USE_API = bool(FAL_API_KEY or REPLICATE_API_KEY)\n",
    "\n",
    "print(\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\")\n",
    "print(\"‚ïë   FLUX.1 - G√©n√©ration d'Images Avanc√©e            ‚ïë\")\n",
    "print(\"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\")\n",
    "print(f\"\\nüìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nüîë Configuration API:\")\n",
    "print(f\"   FAL.ai: {'‚úÖ Configur√©' if FAL_API_KEY else '‚ùå Non configur√©'}\")\n",
    "print(f\"   Replicate: {'‚úÖ Configur√©' if REPLICATE_API_KEY else '‚ùå Non configur√©'}\")\n",
    "print(f\"   HuggingFace: {'‚úÖ Configur√©' if HF_TOKEN else '‚ùå Non configur√©'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:26.363505Z",
     "iopub.status.busy": "2026-02-25T19:52:26.363247Z",
     "iopub.status.idle": "2026-02-25T19:52:27.675246Z",
     "shell.execute_reply": "2026-02-25T19:52:27.674853Z"
    },
    "papermill": {
     "duration": 1.316002,
     "end_time": "2026-02-25T19:52:27.676063",
     "exception": false,
     "start_time": "2026-02-25T19:52:26.360061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Pas de GPU CUDA d√©tect√© - Mode API recommand√©\n",
      "\n",
      "üîß Mode d'ex√©cution: API Cloud\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. D√âTECTION GPU ET CHARGEMENT DIFFUSERS (LOCAL)\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"\\nüéÆ GPU D√©tect√©: {gpu_name}\")\n",
    "        print(f\"   VRAM: {gpu_memory:.1f} GB\")\n",
    "        \n",
    "        # FLUX.1-schnell requiert ~12GB, dev ~24GB\n",
    "        if gpu_memory >= 12:\n",
    "            USE_LOCAL = True\n",
    "            print(f\"   ‚úÖ Suffisant pour FLUX.1-schnell en local\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è VRAM insuffisant pour FLUX local, utilisation API\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(\"\\n‚ö†Ô∏è Pas de GPU CUDA d√©tect√© - Mode API recommand√©\")\n",
    "except ImportError:\n",
    "    device = \"cpu\"\n",
    "    print(\"\\n‚ö†Ô∏è PyTorch non install√© - Mode API uniquement\")\n",
    "\n",
    "# Tentative de chargement diffusers\n",
    "flux_pipeline = None\n",
    "\n",
    "if USE_LOCAL:\n",
    "    try:\n",
    "        from diffusers import FluxPipeline\n",
    "        print(\"\\nüì¶ Diffusers disponible pour FLUX local\")\n",
    "    except ImportError:\n",
    "        print(\"\\n‚ö†Ô∏è diffusers non install√©: pip install diffusers transformers accelerate\")\n",
    "        USE_LOCAL = False\n",
    "\n",
    "print(f\"\\nüîß Mode d'ex√©cution: {'Local (GPU)' if USE_LOCAL else 'API Cloud'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:27.682533Z",
     "iopub.status.busy": "2026-02-25T19:52:27.682234Z",
     "iopub.status.idle": "2026-02-25T19:52:27.693058Z",
     "shell.execute_reply": "2026-02-25T19:52:27.692603Z"
    },
    "papermill": {
     "duration": 0.014858,
     "end_time": "2026-02-25T19:52:27.693791",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.678933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Aucun backend disponible. Configurez une API ou installez diffusers.\n",
      "\n",
      "Pour utiliser ce notebook, configurez:\n",
      "  - FAL_API_KEY dans .env (recommand√©)\n",
      "  - Ou REPLICATE_API_TOKEN dans .env\n",
      "  - Ou installez diffusers avec un GPU 12GB+\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. CLIENT FLUX.1 UNIFI√â (Local + API)\n",
    "# =============================================================================\n",
    "\n",
    "class FluxClient:\n",
    "    \"\"\"\n",
    "    Client unifi√© pour FLUX.1 supportant:\n",
    "    - Ex√©cution locale via diffusers\n",
    "    - API fal.ai\n",
    "    - API Replicate\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mode: str = \"auto\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mode: \"local\", \"fal\", \"replicate\", ou \"auto\" (d√©tection automatique)\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.pipeline = None\n",
    "        \n",
    "        if mode == \"auto\":\n",
    "            if USE_LOCAL:\n",
    "                self.mode = \"local\"\n",
    "            elif FAL_API_KEY:\n",
    "                self.mode = \"fal\"\n",
    "            elif REPLICATE_API_KEY:\n",
    "                self.mode = \"replicate\"\n",
    "            else:\n",
    "                raise ValueError(\"Aucun backend disponible. Configurez une API ou installez diffusers.\")\n",
    "        \n",
    "        print(f\"üîå FluxClient initialis√© en mode: {self.mode}\")\n",
    "    \n",
    "    def load_local_model(self, model_id: str = \"black-forest-labs/FLUX.1-schnell\"):\n",
    "        \"\"\"Charge le mod√®le FLUX localement (GPU requis).\"\"\"\n",
    "        if self.mode != \"local\":\n",
    "            print(\"‚ö†Ô∏è Mode local non disponible\")\n",
    "            return\n",
    "        \n",
    "        from diffusers import FluxPipeline\n",
    "        import torch\n",
    "        \n",
    "        print(f\"\\nüì• Chargement de {model_id}...\")\n",
    "        print(\"   (Cela peut prendre plusieurs minutes au premier lancement)\")\n",
    "        \n",
    "        self.pipeline = FluxPipeline.from_pretrained(\n",
    "            model_id,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            token=HF_TOKEN\n",
    "        )\n",
    "        self.pipeline.to(\"cuda\")\n",
    "        \n",
    "        # Optimisations m√©moire\n",
    "        self.pipeline.enable_model_cpu_offload()\n",
    "        \n",
    "        print(\"   ‚úÖ Mod√®le charg√©\")\n",
    "    \n",
    "    def generate(self, prompt: str, \n",
    "                 width: int = 1024, height: int = 1024,\n",
    "                 num_inference_steps: int = 4,\n",
    "                 guidance_scale: float = 0.0,\n",
    "                 seed: int = None,\n",
    "                 num_images: int = 1) -> List[Image.Image]:\n",
    "        \"\"\"\n",
    "        G√©n√®re des images avec FLUX.1.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Description de l'image\n",
    "            width, height: Dimensions (multiples de 8)\n",
    "            num_inference_steps: Nombre d'√©tapes (schnell: 1-4, dev: 20-50)\n",
    "            guidance_scale: CFG (0 pour schnell, 3.5 pour dev)\n",
    "            seed: Graine pour reproductibilit√©\n",
    "            num_images: Nombre d'images √† g√©n√©rer\n",
    "        \n",
    "        Returns:\n",
    "            Liste d'images PIL\n",
    "        \"\"\"\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(0, 2**32)\n",
    "        \n",
    "        if self.mode == \"local\":\n",
    "            return self._generate_local(prompt, width, height, num_inference_steps, \n",
    "                                        guidance_scale, seed, num_images)\n",
    "        elif self.mode == \"fal\":\n",
    "            return self._generate_fal(prompt, width, height, num_inference_steps,\n",
    "                                      guidance_scale, seed, num_images)\n",
    "        elif self.mode == \"replicate\":\n",
    "            return self._generate_replicate(prompt, width, height, num_inference_steps,\n",
    "                                            guidance_scale, seed, num_images)\n",
    "        else:\n",
    "            raise ValueError(f\"Mode inconnu: {self.mode}\")\n",
    "    \n",
    "    def _generate_local(self, prompt, width, height, steps, guidance, seed, num_images):\n",
    "        \"\"\"G√©n√©ration locale avec diffusers.\"\"\"\n",
    "        import torch\n",
    "        \n",
    "        if self.pipeline is None:\n",
    "            self.load_local_model()\n",
    "        \n",
    "        generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "        \n",
    "        print(f\"\\nüé® G√©n√©ration locale (seed: {seed})...\")\n",
    "        start = time.time()\n",
    "        \n",
    "        result = self.pipeline(\n",
    "            prompt=prompt,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=guidance,\n",
    "            generator=generator,\n",
    "            num_images_per_prompt=num_images\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        print(f\"   ‚úÖ G√©n√©r√© en {elapsed:.1f}s\")\n",
    "        \n",
    "        return result.images\n",
    "    \n",
    "    def _generate_fal(self, prompt, width, height, steps, guidance, seed, num_images):\n",
    "        \"\"\"G√©n√©ration via fal.ai API.\"\"\"\n",
    "        print(f\"\\nüåê G√©n√©ration via fal.ai (seed: {seed})...\")\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Key {FAL_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        # Endpoint pour FLUX.1-schnell\n",
    "        url = \"https://fal.run/fal-ai/flux/schnell\"\n",
    "        \n",
    "        payload = {\n",
    "            \"prompt\": prompt,\n",
    "            \"image_size\": {\"width\": width, \"height\": height},\n",
    "            \"num_inference_steps\": steps,\n",
    "            \"seed\": seed,\n",
    "            \"num_images\": num_images\n",
    "        }\n",
    "        \n",
    "        start = time.time()\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=120)\n",
    "        \n",
    "        if resp.status_code != 200:\n",
    "            raise Exception(f\"fal.ai error: {resp.text}\")\n",
    "        \n",
    "        result = resp.json()\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        # T√©l√©charger les images\n",
    "        images = []\n",
    "        for img_data in result.get(\"images\", []):\n",
    "            img_url = img_data.get(\"url\")\n",
    "            if img_url:\n",
    "                img_resp = requests.get(img_url)\n",
    "                images.append(Image.open(BytesIO(img_resp.content)))\n",
    "        \n",
    "        print(f\"   ‚úÖ G√©n√©r√© en {elapsed:.1f}s ({len(images)} images)\")\n",
    "        return images\n",
    "    \n",
    "    def _generate_replicate(self, prompt, width, height, steps, guidance, seed, num_images):\n",
    "        \"\"\"G√©n√©ration via Replicate API.\"\"\"\n",
    "        print(f\"\\nüåê G√©n√©ration via Replicate (seed: {seed})...\")\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Token {REPLICATE_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        # Cr√©er la pr√©diction\n",
    "        url = \"https://api.replicate.com/v1/predictions\"\n",
    "        \n",
    "        payload = {\n",
    "            \"version\": \"schnell\",  # ou \"dev\" pour FLUX.1-dev\n",
    "            \"input\": {\n",
    "                \"prompt\": prompt,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"num_inference_steps\": steps,\n",
    "                \"guidance_scale\": guidance,\n",
    "                \"seed\": seed,\n",
    "                \"num_outputs\": num_images\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        start = time.time()\n",
    "        resp = requests.post(url, headers=headers, json=payload)\n",
    "        \n",
    "        if resp.status_code not in [200, 201]:\n",
    "            raise Exception(f\"Replicate error: {resp.text}\")\n",
    "        \n",
    "        prediction = resp.json()\n",
    "        prediction_id = prediction[\"id\"]\n",
    "        \n",
    "        # Polling pour attendre le r√©sultat\n",
    "        status_url = f\"https://api.replicate.com/v1/predictions/{prediction_id}\"\n",
    "        while True:\n",
    "            status_resp = requests.get(status_url, headers=headers)\n",
    "            status = status_resp.json()\n",
    "            \n",
    "            if status[\"status\"] == \"succeeded\":\n",
    "                break\n",
    "            elif status[\"status\"] == \"failed\":\n",
    "                raise Exception(f\"Generation failed: {status.get('error')}\")\n",
    "            \n",
    "            time.sleep(1)\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        # T√©l√©charger les images\n",
    "        images = []\n",
    "        for img_url in status.get(\"output\", []):\n",
    "            img_resp = requests.get(img_url)\n",
    "            images.append(Image.open(BytesIO(img_resp.content)))\n",
    "        \n",
    "        print(f\"   ‚úÖ G√©n√©r√© en {elapsed:.1f}s ({len(images)} images)\")\n",
    "        return images\n",
    "\n",
    "\n",
    "# Instanciation du client\n",
    "try:\n",
    "    flux = FluxClient(mode=\"auto\")\n",
    "except ValueError as e:\n",
    "    print(f\"\\n‚ö†Ô∏è {e}\")\n",
    "    print(\"\\nPour utiliser ce notebook, configurez:\")\n",
    "    print(\"  - FAL_API_KEY dans .env (recommand√©)\")\n",
    "    print(\"  - Ou REPLICATE_API_TOKEN dans .env\")\n",
    "    print(\"  - Ou installez diffusers avec un GPU 12GB+\")\n",
    "    flux = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {
    "papermill": {
     "duration": 0.002793,
     "end_time": "2026-02-25T19:52:27.699370",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.696577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Aucun backend disponible. Configurez une API ou installez diffusers.\n",
      "\n",
      "Pour utiliser ce notebook, configurez:\n",
      "  - FAL_API_KEY dans .env (recommand√©)\n",
      "  - Ou REPLICATE_API_TOKEN dans .env\n",
      "  - Ou installez diffusers avec un GPU 12GB+\n"
     ]
    }
   ],
   "source": [
    "## 4. G√©n√©ration de Base avec FLUX.1-schnell\n",
    "\n",
    "FLUX.1-schnell est optimis√© pour la rapidit√© (1-4 steps) tout en maintenant une bonne qualit√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:27.705524Z",
     "iopub.status.busy": "2026-02-25T19:52:27.705331Z",
     "iopub.status.idle": "2026-02-25T19:52:27.709846Z",
     "shell.execute_reply": "2026-02-25T19:52:27.709375Z"
    },
    "papermill": {
     "duration": 0.008539,
     "end_time": "2026-02-25T19:52:27.710550",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.702011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. G√âN√âRATION DE BASE\n",
    "# =============================================================================\n",
    "\n",
    "if flux:\n",
    "    # Prompt de d√©monstration\n",
    "    demo_prompt = \"\"\"\n",
    "    A serene Japanese zen garden at golden hour, \n",
    "    carefully raked sand patterns, moss-covered stones, \n",
    "    a small wooden bridge over a koi pond, \n",
    "    cherry blossoms falling gently, \n",
    "    photorealistic, 8k, masterpiece\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    print(f\"\\nüìù Prompt: {demo_prompt[:80]}...\")\n",
    "    \n",
    "    # G√©n√©ration avec FLUX.1-schnell (4 steps)\n",
    "    images = flux.generate(\n",
    "        prompt=demo_prompt,\n",
    "        width=1024,\n",
    "        height=1024,\n",
    "        num_inference_steps=4,  # schnell: 1-4 steps\n",
    "        guidance_scale=0.0,     # schnell: pas de guidance\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    if images:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(images[0])\n",
    "        plt.title(\"FLUX.1-schnell (4 steps)\", fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        demo_image = images[0]\n",
    "        print(f\"\\nüìê Dimensions: {demo_image.size}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Client FLUX non initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {
    "papermill": {
     "duration": 0.002471,
     "end_time": "2026-02-25T19:52:27.715640",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.713169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "## 5. Analyse du Nombre d'√âtapes (Inference Steps)\n",
    "\n",
    "Comparons l'impact du nombre d'√©tapes sur la qualit√© de g√©n√©ration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:27.721870Z",
     "iopub.status.busy": "2026-02-25T19:52:27.721642Z",
     "iopub.status.idle": "2026-02-25T19:52:27.726253Z",
     "shell.execute_reply": "2026-02-25T19:52:27.725891Z"
    },
    "papermill": {
     "duration": 0.008879,
     "end_time": "2026-02-25T19:52:27.726942",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.718063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. ANALYSE DES INFERENCE STEPS\n",
    "# =============================================================================\n",
    "\n",
    "if flux:\n",
    "    test_prompt = \"A majestic wolf standing on a snowy mountain peak, aurora borealis in the sky, cinematic lighting\"\n",
    "    step_values = [1, 2, 4, 8]  # Pour schnell\n",
    "    fixed_seed = 12345\n",
    "    \n",
    "    print(f\"\\nüìä Analyse Inference Steps\")\n",
    "    print(f\"Prompt: '{test_prompt[:50]}...'\")\n",
    "    print(f\"Valeurs test√©es: {step_values}\")\n",
    "    \n",
    "    step_results = []\n",
    "    \n",
    "    for steps in step_values:\n",
    "        print(f\"\\n--- Steps = {steps} ---\")\n",
    "        \n",
    "        images = flux.generate(\n",
    "            prompt=test_prompt,\n",
    "            width=768,\n",
    "            height=768,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=0.0,\n",
    "            seed=fixed_seed\n",
    "        )\n",
    "        \n",
    "        if images:\n",
    "            step_results.append((steps, images[0]))\n",
    "    \n",
    "    # Affichage comparatif\n",
    "    if step_results:\n",
    "        fig, axes = plt.subplots(1, len(step_results), figsize=(16, 5))\n",
    "        \n",
    "        for i, (steps, img) in enumerate(step_results):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Steps = {steps}\", fontsize=12)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle(\"Impact du nombre d'√©tapes (FLUX.1-schnell)\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nüìà Observations:\")\n",
    "        print(\"   1 step:  Tr√®s rapide, structure de base\")\n",
    "        print(\"   2 steps: Bon compromis vitesse/qualit√©\")\n",
    "        print(\"   4 steps: Qualit√© optimale pour schnell\")\n",
    "        print(\"   8 steps: Diminishing returns, peu d'am√©lioration\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Client FLUX non initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {
    "papermill": {
     "duration": 0.002793,
     "end_time": "2026-02-25T19:52:27.732355",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.729562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "## 6. Exploration des Ratios d'Aspect\n",
    "\n",
    "FLUX.1 supporte diff√©rents ratios d'aspect pour des compositions vari√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:27.738775Z",
     "iopub.status.busy": "2026-02-25T19:52:27.738415Z",
     "iopub.status.idle": "2026-02-25T19:52:27.743319Z",
     "shell.execute_reply": "2026-02-25T19:52:27.742825Z"
    },
    "papermill": {
     "duration": 0.008912,
     "end_time": "2026-02-25T19:52:27.743962",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.735050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. RATIOS D'ASPECT\n",
    "# =============================================================================\n",
    "\n",
    "if flux:\n",
    "    # Diff√©rents ratios\n",
    "    aspect_ratios = [\n",
    "        (\"1:1 (Carr√©)\", 1024, 1024),\n",
    "        (\"16:9 (Paysage)\", 1024, 576),\n",
    "        (\"9:16 (Portrait)\", 576, 1024),\n",
    "        (\"4:3 (Standard)\", 1024, 768),\n",
    "    ]\n",
    "    \n",
    "    aspect_prompt = \"A stunning sunset over the ocean, vibrant orange and purple sky, silhouette of palm trees, photorealistic\"\n",
    "    \n",
    "    print(f\"\\nüñºÔ∏è Exploration des Ratios d'Aspect\")\n",
    "    print(f\"Prompt: '{aspect_prompt[:50]}...'\")\n",
    "    \n",
    "    aspect_results = []\n",
    "    \n",
    "    for name, w, h in aspect_ratios:\n",
    "        print(f\"\\n--- {name} ({w}x{h}) ---\")\n",
    "        \n",
    "        images = flux.generate(\n",
    "            prompt=aspect_prompt,\n",
    "            width=w,\n",
    "            height=h,\n",
    "            num_inference_steps=4,\n",
    "            seed=7777\n",
    "        )\n",
    "        \n",
    "        if images:\n",
    "            aspect_results.append((name, images[0]))\n",
    "    \n",
    "    # Affichage\n",
    "    if aspect_results:\n",
    "        fig = plt.figure(figsize=(16, 8))\n",
    "        \n",
    "        for i, (name, img) in enumerate(aspect_results):\n",
    "            ax = fig.add_subplot(2, 2, i+1)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(name, fontsize=11)\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.suptitle(\"Comparaison des Ratios d'Aspect\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Client FLUX non initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {
    "papermill": {
     "duration": 0.004458,
     "end_time": "2026-02-25T19:52:27.750963",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.746505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "## 7. Batch Generation: Variations d'un M√™me Prompt\n",
    "\n",
    "G√©n√©rons plusieurs variations en changeant uniquement la seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:27.757000Z",
     "iopub.status.busy": "2026-02-25T19:52:27.756768Z",
     "iopub.status.idle": "2026-02-25T19:52:27.761139Z",
     "shell.execute_reply": "2026-02-25T19:52:27.760762Z"
    },
    "papermill": {
     "duration": 0.008209,
     "end_time": "2026-02-25T19:52:27.761799",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.753590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7. BATCH GENERATION - VARIATIONS\n",
    "# =============================================================================\n",
    "\n",
    "if flux:\n",
    "    variation_prompt = \"\"\"\n",
    "    A mystical forest with bioluminescent plants, \n",
    "    glowing mushrooms, fireflies, magical atmosphere, \n",
    "    fantasy art style, highly detailed\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    num_variations = 4\n",
    "    base_seed = 1000\n",
    "    \n",
    "    print(f\"\\nüé≤ G√©n√©ration de {num_variations} variations\")\n",
    "    print(f\"Prompt: '{variation_prompt[:50]}...'\")\n",
    "    \n",
    "    variations = []\n",
    "    \n",
    "    for i in range(num_variations):\n",
    "        seed = base_seed + i * 1000\n",
    "        print(f\"\\n[{i+1}/{num_variations}] Seed: {seed}\")\n",
    "        \n",
    "        images = flux.generate(\n",
    "            prompt=variation_prompt,\n",
    "            width=768,\n",
    "            height=768,\n",
    "            num_inference_steps=4,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        if images:\n",
    "            variations.append((seed, images[0]))\n",
    "    \n",
    "    # Affichage grille\n",
    "    if variations:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (seed, img) in enumerate(variations):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Seed: {seed}\", fontsize=11)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle(\"Variations avec diff√©rentes seeds\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n‚úÖ {len(variations)} variations g√©n√©r√©es\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Client FLUX non initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {
    "papermill": {
     "duration": 0.002675,
     "end_time": "2026-02-25T19:52:27.767225",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.764550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "## 8. Techniques de Prompt Engineering pour FLUX\n",
    "\n",
    "FLUX.1 r√©pond particuli√®rement bien √† certains styles de prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:27.773113Z",
     "iopub.status.busy": "2026-02-25T19:52:27.772918Z",
     "iopub.status.idle": "2026-02-25T19:52:27.778820Z",
     "shell.execute_reply": "2026-02-25T19:52:27.778422Z"
    },
    "papermill": {
     "duration": 0.009774,
     "end_time": "2026-02-25T19:52:27.779545",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.769771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n",
      "\n",
      "Voici les templates de prompt recommand√©s pour FLUX:\n",
      "\n",
      "PHOTOREALISTIC:\n",
      "  Pr√©fixe: A photorealistic image of\n",
      "  Suffixe: , shot with a Canon EOS R5, 85mm f/1.4, natural lighting, 8k resolution\n",
      "\n",
      "CINEMATIC:\n",
      "  Pr√©fixe: Cinematic still from a movie,\n",
      "  Suffixe: , dramatic lighting, anamorphic lens, film grain, color graded\n",
      "\n",
      "ILLUSTRATION:\n",
      "  Pr√©fixe: Digital illustration of\n",
      "  Suffixe: , artstation trending, vibrant colors, highly detailed, concept art\n",
      "\n",
      "ANIME:\n",
      "  Pr√©fixe: Anime artwork of\n",
      "  Suffixe: , Studio Ghibli style, beautiful scenery, soft colors, detailed\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. PROMPT ENGINEERING AVANC√â\n",
    "# =============================================================================\n",
    "\n",
    "# Templates de prompts efficaces pour FLUX\n",
    "prompt_templates = {\n",
    "    \"photorealistic\": {\n",
    "        \"prefix\": \"A photorealistic image of\",\n",
    "        \"suffix\": \", shot with a Canon EOS R5, 85mm f/1.4, natural lighting, 8k resolution\",\n",
    "        \"example\": \"a woman in a red dress walking through autumn leaves\"\n",
    "    },\n",
    "    \"cinematic\": {\n",
    "        \"prefix\": \"Cinematic still from a movie,\",\n",
    "        \"suffix\": \", dramatic lighting, anamorphic lens, film grain, color graded\",\n",
    "        \"example\": \"a detective in a noir city at night under rain\"\n",
    "    },\n",
    "    \"illustration\": {\n",
    "        \"prefix\": \"Digital illustration of\",\n",
    "        \"suffix\": \", artstation trending, vibrant colors, highly detailed, concept art\",\n",
    "        \"example\": \"a steampunk airship flying over a Victorian city\"\n",
    "    },\n",
    "    \"anime\": {\n",
    "        \"prefix\": \"Anime artwork of\",\n",
    "        \"suffix\": \", Studio Ghibli style, beautiful scenery, soft colors, detailed\",\n",
    "        \"example\": \"a young adventurer discovering a hidden temple in the forest\"\n",
    "    }\n",
    "}\n",
    "\n",
    "if flux:\n",
    "    print(\"\\nüé® Comparaison des Styles de Prompts\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    style_results = []\n",
    "    fixed_seed = 9999\n",
    "    \n",
    "    for style_name, template in prompt_templates.items():\n",
    "        full_prompt = f\"{template['prefix']} {template['example']}{template['suffix']}\"\n",
    "        \n",
    "        print(f\"\\n--- Style: {style_name.upper()} ---\")\n",
    "        print(f\"   Prompt: {full_prompt[:60]}...\")\n",
    "        \n",
    "        images = flux.generate(\n",
    "            prompt=full_prompt,\n",
    "            width=768,\n",
    "            height=768,\n",
    "            num_inference_steps=4,\n",
    "            seed=fixed_seed\n",
    "        )\n",
    "        \n",
    "        if images:\n",
    "            style_results.append((style_name, images[0]))\n",
    "    \n",
    "    # Affichage\n",
    "    if style_results:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 14))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (style, img) in enumerate(style_results):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Style: {style.capitalize()}\", fontsize=12)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle(\"Comparaison des Styles de Prompt\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Client FLUX non initialis√©\")\n",
    "    print(\"\\nVoici les templates de prompt recommand√©s pour FLUX:\")\n",
    "    for style, template in prompt_templates.items():\n",
    "        print(f\"\\n{style.upper()}:\")\n",
    "        print(f\"  Pr√©fixe: {template['prefix']}\")\n",
    "        print(f\"  Suffixe: {template['suffix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {
    "papermill": {
     "duration": 0.002858,
     "end_time": "2026-02-25T19:52:27.785238",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.782380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n",
      "\n",
      "Voici les templates de prompt recommand√©s pour FLUX:\n",
      "\n",
      "PHOTOREALISTIC:\n",
      "  Pr√©fixe: A photorealistic image of\n",
      "  Suffixe: , shot with a Canon EOS R5, 85mm f/1.4, natural lighting, 8k resolution\n",
      "\n",
      "CINEMATIC:\n",
      "  Pr√©fixe: Cinematic still from a movie,\n",
      "  Suffixe: , dramatic lighting, anamorphic lens, film grain, color graded\n",
      "\n",
      "ILLUSTRATION:\n",
      "  Pr√©fixe: Digital illustration of\n",
      "  Suffixe: , artstation trending, vibrant colors, highly detailed, concept art\n",
      "\n",
      "ANIME:\n",
      "  Pr√©fixe: Anime artwork of\n",
      "  Suffixe: , Studio Ghibli style, beautiful scenery, soft colors, detailed\n"
     ]
    }
   ],
   "source": [
    "## 9. G√©n√©ration de Texte dans les Images\n",
    "\n",
    "FLUX.1 excelle particuli√®rement dans le rendu de texte lisible dans les images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:27.792148Z",
     "iopub.status.busy": "2026-02-25T19:52:27.791824Z",
     "iopub.status.idle": "2026-02-25T19:52:27.796920Z",
     "shell.execute_reply": "2026-02-25T19:52:27.796399Z"
    },
    "papermill": {
     "duration": 0.009733,
     "end_time": "2026-02-25T19:52:27.797809",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.788076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 9. G√âN√âRATION DE TEXTE DANS LES IMAGES\n",
    "# =============================================================================\n",
    "\n",
    "if flux:\n",
    "    text_prompts = [\n",
    "        'A vintage neon sign that says \"OPEN 24 HOURS\" glowing in the night, realistic',\n",
    "        'A birthday cake with elegant cursive text reading \"Happy Birthday Sarah\" in icing',\n",
    "        'A wooden street sign pointing right with the text \"Adventure Awaits\" carved into it',\n",
    "        'A coffee cup with \"Good Morning!\" written in latte art'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n‚úçÔ∏è Test de G√©n√©ration de Texte\")\n",
    "    print(\"FLUX.1 est reconnu pour sa capacit√© √† g√©n√©rer du texte lisible.\")\n",
    "    \n",
    "    text_results = []\n",
    "    \n",
    "    for i, prompt in enumerate(text_prompts):\n",
    "        print(f\"\\n[{i+1}/{len(text_prompts)}] {prompt[:50]}...\")\n",
    "        \n",
    "        images = flux.generate(\n",
    "            prompt=prompt,\n",
    "            width=768,\n",
    "            height=768,\n",
    "            num_inference_steps=4,\n",
    "            seed=2024 + i\n",
    "        )\n",
    "        \n",
    "        if images:\n",
    "            text_results.append((prompt.split('\"')[1] if '\"' in prompt else prompt[:20], images[0]))\n",
    "    \n",
    "    # Affichage\n",
    "    if text_results:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (text, img) in enumerate(text_results):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f'Texte: \"{text}\"', fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle(\"Capacit√© de G√©n√©ration de Texte\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Client FLUX non initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {
    "papermill": {
     "duration": 0.003128,
     "end_time": "2026-02-25T19:52:27.805504",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.802376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Client FLUX non initialis√©\n"
     ]
    }
   ],
   "source": [
    "## 10. Exercices Pratiques\n",
    "\n",
    "### Exercice 1: Portrait Professionnel\n",
    "Utilisez le template \"photorealistic\" pour g√©n√©rer un portrait professionnel d'une personne de votre choix.\n",
    "\n",
    "### Exercice 2: Exploration des Seeds\n",
    "Gardez le m√™me prompt et g√©n√©rez 6 variations en changeant la seed. Identifiez celle qui correspond le mieux √† votre vision.\n",
    "\n",
    "### Exercice 3: Texte Cr√©atif\n",
    "Cr√©ez une image contenant un message personnalis√© (ex: affiche de film, couverture de livre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:27.812477Z",
     "iopub.status.busy": "2026-02-25T19:52:27.812262Z",
     "iopub.status.idle": "2026-02-25T19:52:27.815956Z",
     "shell.execute_reply": "2026-02-25T19:52:27.815430Z"
    },
    "papermill": {
     "duration": 0.00842,
     "end_time": "2026-02-25T19:52:27.816880",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.808460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Espace d'exercices - D√©commentez le code ci-dessus pour commencer\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 10. ESPACE D'EXERCICES\n",
    "# =============================================================================\n",
    "\n",
    "# Exercice 1: Portrait Professionnel\n",
    "# D√©commentez et personnalisez:\n",
    "\n",
    "# portrait_prompt = \"\"\"\n",
    "# A photorealistic portrait of a professional woman in her 30s,\n",
    "# wearing a navy blue blazer, confident smile,\n",
    "# shot with a Canon EOS R5, 85mm f/1.4, studio lighting,\n",
    "# clean white background, corporate headshot\n",
    "# \"\"\"\n",
    "# \n",
    "# if flux:\n",
    "#     images = flux.generate(portrait_prompt, width=768, height=1024, seed=42)\n",
    "#     if images:\n",
    "#         plt.imshow(images[0])\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "\n",
    "print(\"üìù Espace d'exercices - D√©commentez le code ci-dessus pour commencer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {
    "papermill": {
     "duration": 0.003007,
     "end_time": "2026-02-25T19:52:27.822954",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.819947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Espace d'exercices - D√©commentez le code ci-dessus pour commencer\n"
     ]
    }
   ],
   "source": [
    "## 11. R√©capitulatif et Points Cl√©s\n",
    "\n",
    "### Param√®tres FLUX.1\n",
    "\n",
    "| Param√®tre | Schnell | Dev | Description |\n",
    "|-----------|---------|-----|-------------|\n",
    "| `num_inference_steps` | 1-4 | 20-50 | Nombre d'it√©rations |\n",
    "| `guidance_scale` | 0.0 | 3.0-7.0 | Adh√©rence au prompt |\n",
    "| `width/height` | 512-2048 | 512-2048 | Multiples de 8 |\n",
    "\n",
    "### Points Forts de FLUX.1\n",
    "\n",
    "1. **G√©n√©ration de texte** exceptionnelle\n",
    "2. **Rapidit√©** avec schnell (1-4 steps)\n",
    "3. **Qualit√© photo-r√©aliste** sup√©rieure\n",
    "4. **Compr√©hension des prompts** avanc√©e\n",
    "5. **Support LoRA** (dev uniquement)\n",
    "\n",
    "### Bonnes Pratiques\n",
    "\n",
    "- Utilisez **schnell** pour le prototypage rapide\n",
    "- Passez √† **dev** pour la qualit√© finale\n",
    "- Sp√©cifiez le style photographique/artistique dans le prompt\n",
    "- Pour le texte, encadrez-le avec des guillemets dans le prompt\n",
    "\n",
    "### Ressources\n",
    "\n",
    "- [FLUX.1 on HuggingFace](https://huggingface.co/black-forest-labs)\n",
    "- [fal.ai Documentation](https://fal.ai/models/fal-ai/flux)\n",
    "- Notebook suivant: **02-3-Stable-Diffusion-3-5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T19:52:27.830506Z",
     "iopub.status.busy": "2026-02-25T19:52:27.830257Z",
     "iopub.status.idle": "2026-02-25T19:52:27.834702Z",
     "shell.execute_reply": "2026-02-25T19:52:27.833918Z"
    },
    "papermill": {
     "duration": 0.009313,
     "end_time": "2026-02-25T19:52:27.835511",
     "exception": false,
     "start_time": "2026-02-25T19:52:27.826198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "   ‚úÖ Notebook FLUX.1 Advanced Generation Compl√©t√©\n",
      "============================================================\n",
      "\n",
      "üìÖ Termin√©: 2026-02-25 20:52:27\n",
      "\n",
      "üìö Concepts couverts:\n",
      "   ‚Ä¢ Architecture FLUX.1 (schnell, dev, pro)\n",
      "   ‚Ä¢ Client unifi√© (local + API)\n",
      "   ‚Ä¢ Analyse des inference steps\n",
      "   ‚Ä¢ Ratios d'aspect\n",
      "   ‚Ä¢ Prompt engineering avanc√©\n",
      "   ‚Ä¢ G√©n√©ration de texte dans les images\n",
      "\n",
      "‚û°Ô∏è  Prochain notebook: 02-3-Stable-Diffusion-3-5.ipynb\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FIN DU NOTEBOOK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"   ‚úÖ Notebook FLUX.1 Advanced Generation Compl√©t√©\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìÖ Termin√©: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nüìö Concepts couverts:\")\n",
    "print(\"   ‚Ä¢ Architecture FLUX.1 (schnell, dev, pro)\")\n",
    "print(\"   ‚Ä¢ Client unifi√© (local + API)\")\n",
    "print(\"   ‚Ä¢ Analyse des inference steps\")\n",
    "print(\"   ‚Ä¢ Ratios d'aspect\")\n",
    "print(\"   ‚Ä¢ Prompt engineering avanc√©\")\n",
    "print(\"   ‚Ä¢ G√©n√©ration de texte dans les images\")\n",
    "print(\"\\n‚û°Ô∏è  Prochain notebook: 02-3-Stable-Diffusion-3-5.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.362831,
   "end_time": "2026-02-25T19:52:28.396767",
   "environment_variables": {},
   "exception": null,
   "input_path": "MyIA.AI.Notebooks\\GenAI\\Image\\02-Advanced\\02-2-FLUX-1-Advanced-Generation.ipynb",
   "output_path": "MyIA.AI.Notebooks\\GenAI\\Image\\02-Advanced\\02-2-FLUX-1-Advanced-Generation.ipynb",
   "parameters": {},
   "start_time": "2026-02-25T19:52:24.033936",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}