# üîß TROUBLESHOOTING GUIDE - GenAI Images CoursIA

> **Guide complet de r√©solution des probl√®mes courants**  
> Solutions √©tape par √©tape | Scripts diagnostiques | Support production

---

## üìë Table des Mati√®res

1. [Probl√®mes APIs Externes](#probl√®mes-apis-externes)
2. [Erreurs Configuration](#erreurs-configuration)
3. [Issues MCP/Papermill](#issues-mcppapermill)
4. [Probl√®mes Performance](#probl√®mes-performance)
5. [Quality Issues](#quality-issues)
6. [Gestion des Co√ªts](#gestion-des-co√ªts)
7. [Probl√®mes Int√©gration](#probl√®mes-int√©gration)
8. [Scripts Diagnostiques](#scripts-diagnostiques)
9. [Support & Escalation](#support--escalation)

---

## üåê Probl√®mes APIs Externes

### 1. ‚ùå API Key Invalid (OpenAI)

#### Sympt√¥mes
```python
openai.AuthenticationError: Incorrect API key provided: sk-****
```

#### Diagnostic
```python
import os
from dotenv import load_dotenv

# V√©rifier chargement .env
load_dotenv()

# Afficher d√©but cl√© (s√©curis√©)
api_key = os.getenv("OPENAI_API_KEY")
if api_key:
    print(f"‚úÖ Cl√© trouv√©e: {api_key[:10]}...{api_key[-4:]}")
else:
    print("‚ùå Variable OPENAI_API_KEY non d√©finie")
```

#### Solutions

**Solution 1: V√©rifier fichier .env**
```bash
# 1. V√©rifier .env existe
ls -la .env  # Linux/Mac
dir .env     # Windows

# 2. Contenu attendu
cat .env
# Output: OPENAI_API_KEY=sk-proj-...
```

**Solution 2: Recharger environnement**
```python
# Dans Jupyter, red√©marrer kernel
# Kernel > Restart Kernel

# Puis recharger
from dotenv import load_dotenv
load_dotenv(override=True)  # Force reload
```

**Solution 3: V√©rifier cl√© sur plateforme**
```bash
# 1. Aller sur https://platform.openai.com/api-keys
# 2. Cr√©er nouvelle cl√© si n√©cessaire
# 3. Copier dans .env (sans espaces)
OPENAI_API_KEY=sk-proj-abcd1234...
```

**Solution 4: Tester connexion**
```python
from openai import OpenAI
import os

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

try:
    # Test minimal
    models = client.models.list()
    print("‚úÖ Connexion OpenAI OK")
except Exception as e:
    print(f"‚ùå Erreur: {e}")
```

---

### 2. ‚ö†Ô∏è Rate Limit Exceeded

#### Sympt√¥mes
```python
openai.RateLimitError: Rate limit reached for requests
```

#### Causes Fr√©quentes
- Trop de requ√™tes simultan√©es
- D√©passement quota tier gratuit
- Boucles mal contr√¥l√©es

#### Solution 1: Retry avec Backoff Exponentiel
```python
import time
from openai import RateLimitError, OpenAI

def generate_with_retry(client, prompt, max_retries=5):
    """G√©n√©ration avec retry automatique"""
    for attempt in range(max_retries):
        try:
            response = client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                size="1024x1024"
            )
            return response
        except RateLimitError as e:
            if attempt == max_retries - 1:
                raise
            wait_time = 2 ** attempt  # Backoff: 1s, 2s, 4s, 8s, 16s
            print(f"‚è≥ Rate limit, attente {wait_time}s... (tentative {attempt+1}/{max_retries})")
            time.sleep(wait_time)
```

#### Solution 2: Throttling Manuel
```python
import time
from datetime import datetime

class RateLimiter:
    """Limiteur de taux configurable"""
    def __init__(self, requests_per_minute=50):
        self.requests_per_minute = requests_per_minute
        self.min_interval = 60.0 / requests_per_minute
        self.last_request = 0
    
    def wait(self):
        """Attend le temps n√©cessaire avant prochaine requ√™te"""
        now = time.time()
        time_since_last = now - self.last_request
        
        if time_since_last < self.min_interval:
            sleep_time = self.min_interval - time_since_last
            print(f"‚è∏Ô∏è Throttling: {sleep_time:.2f}s")
            time.sleep(sleep_time)
        
        self.last_request = time.time()

# Usage
limiter = RateLimiter(requests_per_minute=30)

for prompt in prompts:
    limiter.wait()
    response = client.images.generate(...)
```

#### Solution 3: Batch avec D√©lais
```python
import asyncio

async def generate_batch_with_delay(prompts, delay_seconds=2):
    """Batch processing avec d√©lais"""
    results = []
    
    for i, prompt in enumerate(prompts):
        print(f"üé® G√©n√©ration {i+1}/{len(prompts)}")
        
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size="1024x1024"
        )
        results.append(response)
        
        if i < len(prompts) - 1:
            await asyncio.sleep(delay_seconds)
    
    return results
```

#### Solution 4: Upgrade Tier
```bash
# Si usage fr√©quent, passer √† tier payant
# https://platform.openai.com/account/billing/overview

# Limites par tier:
# Free: 3 images/min
# Tier 1 ($5+): 50 images/min
# Tier 2 ($50+): 100 images/min
```

---

### 3. üîí OpenRouter API Issues

#### Sympt√¥mes
```python
openai.APIError: OpenRouter API error: Invalid model specified
```

#### Solution 1: V√©rifier Format Mod√®le
```python
from openai import OpenAI
import os

# ‚ùå Incorrect
client = OpenAI(
    api_key=os.getenv("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1"
)
response = client.chat.completions.create(
    model="gpt-5-preview",  # ‚ùå Format incorrect
    ...
)

# ‚úÖ Correct
response = client.chat.completions.create(
    model="openai/gpt-5-preview",  # ‚úÖ Avec provider prefix
    ...
)
```

#### Solution 2: Tester Disponibilit√© Mod√®le
```python
def check_model_availability(model_id):
    """V√©rifie si mod√®le disponible sur OpenRouter"""
    import requests
    
    headers = {
        "Authorization": f"Bearer {os.getenv('OPENROUTER_API_KEY')}"
    }
    
    response = requests.get(
        "https://openrouter.ai/api/v1/models",
        headers=headers
    )
    
    models = response.json()
    available = [m['id'] for m in models.get('data', [])]
    
    if model_id in available:
        print(f"‚úÖ {model_id} disponible")
        return True
    else:
        print(f"‚ùå {model_id} non disponible")
        print(f"Mod√®les similaires: {[m for m in available if model_id.split('/')[-1] in m]}")
        return False

# Test
check_model_availability("openai/gpt-5-preview")
```

#### Solution 3: Headers Additionnels
```python
# Pour tracking et features avanc√©es
client = OpenAI(
    api_key=os.getenv("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1",
    default_headers={
        "HTTP-Referer": "https://coursia.ai",  # Optional
        "X-Title": "CoursIA GenAI Images"      # Optional
    }
)
```

---

### 4. üí∏ Budget Exceeded

#### Sympt√¥mes
```python
openai.APIError: You exceeded your current quota
```

#### Diagnostic Budget
```python
import requests
import os

def check_openai_usage():
    """V√©rifie usage et limites OpenAI"""
    headers = {
        "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}"
    }
    
    # Note: API usage endpoint deprecated, v√©rifier sur dashboard
    print("üìä V√©rifier usage sur: https://platform.openai.com/usage")
    print("üí≥ V√©rifier limites sur: https://platform.openai.com/account/billing/limits")

check_openai_usage()
```

#### Solutions

**Solution 1: Configurer Limites Budg√©taires**
```bash
# Dans dashboard OpenAI:
# 1. Account > Billing > Usage limits
# 2. Set monthly budget cap
# 3. Enable email alerts at 75%, 90%
```

**Solution 2: Local Cost Tracking**
```python
class CostTracker:
    """Suivi co√ªts local"""
    def __init__(self):
        self.costs = {
            'dalle-3-standard': 0.040,
            'dalle-3-hd': 0.080,
            'gpt-5-preview-input': 0.00001,  # per token
            'gpt-5-preview-output': 0.00003
        }
        self.usage = []
    
    def log_dalle_generation(self, size, quality='standard'):
        """Log g√©n√©ration DALL-E"""
        key = f'dalle-3-{quality}'
        cost = self.costs[key]
        self.usage.append({
            'type': 'dalle-3',
            'cost': cost,
            'size': size,
            'quality': quality
        })
        return cost
    
    def get_total_cost(self):
        """Calcule co√ªt total"""
        return sum(item['cost'] for item in self.usage)
    
    def get_report(self):
        """Rapport d√©taill√©"""
        total = self.get_total_cost()
        return {
            'total_cost': total,
            'num_requests': len(self.usage),
            'average_cost': total / len(self.usage) if self.usage else 0
        }

# Usage
tracker = CostTracker()

# Apr√®s chaque g√©n√©ration
cost = tracker.log_dalle_generation('1024x1024', 'standard')
print(f"üí∞ Co√ªt: ${cost:.4f}")

# Rapport final
report = tracker.get_report()
print(f"üìä Total session: ${report['total_cost']:.2f}")
```

**Solution 3: Ajouter Cr√©dits**
```bash
# https://platform.openai.com/account/billing/overview
# Add payment method -> Add to balance
```

---

## ‚öôÔ∏è Erreurs Configuration

### 5. üìù .env File Not Found

#### Sympt√¥mes
```python
# Variables d'environnement None
os.getenv("OPENAI_API_KEY") returns None
```

#### Solution 1: Cr√©er .env
```bash
# Cr√©er depuis template
cp .env.example .env

# √âditer avec cl√©s r√©elles
nano .env  # Linux/Mac
notepad .env  # Windows
```

#### Solution 2: V√©rifier Emplacement
```python
import os
from pathlib import Path

# Afficher working directory
print(f"Working dir: {os.getcwd()}")

# V√©rifier .env existe
env_path = Path(".env")
if env_path.exists():
    print(f"‚úÖ .env trouv√©: {env_path.absolute()}")
else:
    print(f"‚ùå .env manquant dans: {env_path.absolute()}")
    
# Lister fichiers .env* dans r√©pertoire
env_files = list(Path(".").glob(".env*"))
print(f"Fichiers .env trouv√©s: {env_files}")
```

#### Solution 3: Load Explicite
```python
from dotenv import load_dotenv
from pathlib import Path

# Chemin explicite
env_path = Path("MyIA.AI.Notebooks/GenAI/.env")
load_dotenv(dotenv_path=env_path)

# V√©rification
api_key = os.getenv("OPENAI_API_KEY")
print(f"Cl√© charg√©e: {api_key is not None}")
```

---

### 6. üîê Invalid Characters in API Key

#### Sympt√¥mes
```python
# Erreur parsing ou authentication
ValueError: Invalid API key format
```

#### Solution: Nettoyage Cl√©
```python
import os

def clean_api_key(raw_key):
    """Nettoie cl√© API (espaces, newlines)"""
    if not raw_key:
        return None
    
    # Supprimer whitespace
    cleaned = raw_key.strip()
    
    # V√©rifier format attendu
    if cleaned.startswith("sk-"):
        return cleaned
    else:
        print(f"‚ö†Ô∏è Format suspect: {cleaned[:10]}...")
        return cleaned

# Usage
raw_key = os.getenv("OPENAI_API_KEY")
api_key = clean_api_key(raw_key)

# Tester
client = OpenAI(api_key=api_key)
```

---

### 7. üì¶ Missing Dependencies

#### Sympt√¥mes
```python
ModuleNotFoundError: No module named 'openai'
```

#### Solution 1: Installation Compl√®te
```bash
# Activer environnement
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Installer depuis requirements
pip install -r requirements.txt

# V√©rifier installation
pip list | grep openai
```

#### Solution 2: Installation Individuelle
```bash
# D√©pendances core
pip install openai>=1.3.0
pip install Pillow>=10.0.0
pip install requests>=2.31.0
pip install python-dotenv>=1.0.0

# Jupyter
pip install jupyter>=1.0.0
pip install notebook>=7.0.0
```

#### Solution 3: Kernel Jupyter
```bash
# Enregistrer kernel avec environnement
python -m ipykernel install --user --name=genai-env --display-name="Python (GenAI)"

# Dans Jupyter, s√©lectionner kernel "Python (GenAI)"
```

---

## üêç Issues MCP/Papermill

### 8. üî§ BOM UTF-8 in Notebooks

#### Sympt√¥mes
```python
# MCP Papermill erreur parsing
json.JSONDecodeError: Unexpected UTF-8 BOM
```

#### Diagnostic
```python
def check_bom(file_path):
    """D√©tecte BOM UTF-8 dans fichier"""
    with open(file_path, 'rb') as f:
        start = f.read(3)
        has_bom = (start == b'\xef\xbb\xbf')
        
    if has_bom:
        print(f"‚ö†Ô∏è BOM d√©tect√©: {file_path}")
    else:
        print(f"‚úÖ Pas de BOM: {file_path}")
    
    return has_bom

# Tester notebook
check_bom("01-1-OpenAI-DALL-E-3.ipynb")
```

#### Solution Automatique: Script PowerShell
```powershell
# Script: scripts/37-fix-genai-bom-utf8-20251008.ps1
$notebooks = Get-ChildItem -Path "MyIA.AI.Notebooks/GenAI" -Filter "*.ipynb" -Recurse

foreach ($notebook in $notebooks) {
    # Lire contenu
    $content = Get-Content $notebook.FullName -Raw -Encoding UTF8
    
    # R√©√©crire sans BOM
    [System.IO.File]::WriteAllLines($notebook.FullName, $content, [System.Text.UTF8Encoding]::new($false))
    
    Write-Host "‚úÖ Fixed: $($notebook.Name)"
}
```

#### Solution Manuelle Python
```python
def remove_bom(file_path):
    """Supprime BOM UTF-8 d'un notebook"""
    import json
    
    # Lire avec gestion BOM
    with open(file_path, 'r', encoding='utf-8-sig') as f:
        content = json.load(f)
    
    # R√©√©crire sans BOM
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(content, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ BOM supprim√©: {file_path}")

# Usage
remove_bom("01-1-OpenAI-DALL-E-3.ipynb")
```

---

### 9. üö´ Papermill Execution Timeout

#### Sympt√¥mes
```python
papermill.exceptions.PapermillExecutionError: Execution timeout after 300s
```

#### Solution 1: Augmenter Timeout
```python
import papermill as pm

pm.execute_notebook(
    '01-1-OpenAI-DALL-E-3.ipynb',
    'output.ipynb',
    timeout=600,  # 10 minutes au lieu de 5
    kernel_name='python3'
)
```

#### Solution 2: MCP Async Execution
```python
# Via MCP Papermill Server
# Tool: start_notebook_async

{
    "notebook_path": "01-1-OpenAI-DALL-E-3.ipynb",
    "timeout_seconds": 1200,  # 20 minutes
    "output_path": "output.ipynb"
}

# Puis polling status
# Tool: get_execution_status_async
```

#### Solution 3: Optimiser Notebook
```python
# Identifier cellules lentes
%time  # En d√©but de cellule

# Cacher r√©sultats lourds
import pickle

# Sauvegarder
with open('cache.pkl', 'wb') as f:
    pickle.dump(results, f)

# Recharger
with open('cache.pkl', 'rb') as f:
    results = pickle.load(f)
```

---

### 10. üìÇ Path Issues (Windows vs Linux)

#### Sympt√¥mes
```python
FileNotFoundError: [Errno 2] No such file or directory: 'outputs\image.png'
```

#### Solution: Path Agnostique
```python
from pathlib import Path

# ‚ùå √âviter strings hardcod√©s
output_path = "outputs\image.png"  # Windows uniquement

# ‚úÖ Utiliser pathlib
output_path = Path("outputs") / "image.png"  # Cross-platform

# Cr√©er r√©pertoires si n√©cessaire
output_path.parent.mkdir(parents=True, exist_ok=True)

# Convertir en string pour APIs
image_path_str = str(output_path)
```

---

## ‚ö° Probl√®mes Performance

### 11. üêå Slow Image Generation

#### Diagnostic
```python
import time

def measure_generation_time(prompt):
    """Mesure temps g√©n√©ration"""
    start = time.time()
    
    response = client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024"
    )
    
    elapsed = time.time() - start
    print(f"‚è±Ô∏è Temps g√©n√©ration: {elapsed:.2f}s")
    
    return response, elapsed

# Test
response, timing = measure_generation_time("Test prompt")
```

#### Solutions

**Solution 1: Optimiser Taille Images**
```python
# Si possible, utiliser r√©solution inf√©rieure
response = client.images.generate(
    model="dall-e-3",
    prompt=prompt,
    size="1024x1024",  # Au lieu de 1792x1024
    quality="standard"  # Au lieu de 'hd'
)
# Standard: ~30-40s vs HD: ~60-90s
```

**Solution 2: Parallel Processing**
```python
from concurrent.futures import ThreadPoolExecutor

def generate_parallel(prompts, max_workers=3):
    """G√©n√©ration parall√®le (attention rate limits)"""
    results = []
    
    def generate_one(prompt):
        return client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size="1024x1024"
        )
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(generate_one, prompts))
    
    return results

# Usage
results = generate_parallel(prompts[:5], max_workers=2)
```

---

### 12. üíæ Out of Memory (Large Images)

#### Sympt√¥mes
```python
MemoryError: Unable to allocate array
```

#### Solution 1: Lib√©ration M√©moire
```python
from PIL import Image
import gc

# Apr√®s traitement
image = Image.open('large.png')
# ... op√©rations ...
image.close()
del image
gc.collect()
```

#### Solution 2: Streaming Downloads
```python
import requests
from PIL import Image
from io import BytesIO

def download_and_resize(url, max_size=(1024, 1024)):
    """T√©l√©charge et redimensionne directement"""
    response = requests.get(url, stream=True)
    
    # Charger en m√©moire minimale
    img = Image.open(BytesIO(response.content))
    
    # Redimensionner imm√©diatement
    img.thumbnail(max_size, Image.Resampling.LANCZOS)
    
    return img
```

#### Solution 3: Processing par Batch
```python
def process_images_batched(image_paths, batch_size=10):
    """Traite images par petits lots"""
    for i in range(0, len(image_paths), batch_size):
        batch = image_paths[i:i+batch_size]
        
        # Traiter batch
        for path in batch:
            img = Image.open(path)
            # ... op√©rations ...
            img.close()
        
        # Lib√©rer m√©moire
        gc.collect()
        print(f"‚úÖ Batch {i//batch_size + 1} termin√©")
```

---

### 13. üî• High CPU Usage

#### Solution: Limiter Threads PIL
```python
from PIL import Image

# Limiter threads pour op√©rations image
Image.MAX_IMAGE_PIXELS = 100000000  # Limite pixels

# Pour OpenCV
import cv2
cv2.setNumThreads(2)  # Limiter √† 2 threads
```

---

## üé® Quality Issues

### 14. üòû Unsatisfactory Results

#### Diagnostic: Analyse Systematic
```python
def analyze_generation_quality(prompt, num_iterations=3):
    """G√©n√®re plusieurs versions pour comparaison"""
    results = []
    
    for i in range(num_iterations):
        print(f"üé® It√©ration {i+1}/{num_iterations}")
        
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size="1024x1024"
        )
        
        results.append({
            'url': response.data[0].url,
            'revised_prompt': response.data[0].revised_prompt,
            'iteration': i+1
        })
    
    return results
```

#### Solution 1: Am√©liorer Prompts
```python
# ‚ùå Prompt vague
prompt = "Cellule v√©g√©tale"

# ‚úÖ Prompt d√©taill√©
prompt = """Diagramme scientifique d√©taill√© d'une cellule v√©g√©tale, 
vue en coupe transversale, montrant clairement:
- Noyau au centre avec nucl√©ole
- Chloroplastes verts r√©partis dans cytoplasme
- Vacuole centrale large
- Paroi cellulaire √©paisse externe
- Membrane plasmique
- Mitochondries
Labels fran√ßais pour chaque organite, 
style manuel biologie √©ducatif,
fond blanc, haute clart√©"""
```

#### Solution 2: Style Modifiers
```python
# Ajouter style sp√©cifique
STYLE_MODIFIERS = {
    'educational': 'style manuel √©ducatif, diagramme p√©dagogique, labels clairs',
    'realistic': 'photor√©aliste, haute d√©finition, √©clairage naturel',
    'illustration': 'illustration artistique, couleurs vives, style dessin√©',
    'scientific': 'sch√©ma scientifique pr√©cis, annotations techniques'
}

enhanced_prompt = f"{base_prompt}, {STYLE_MODIFIERS['educational']}"
```

---

### 15. üîç GPT-5 Vision Errors

#### Sympt√¥mes
```python
# Analyse impr√©cise ou erreurs
"Unable to analyze image" ou descriptions vagues
```

#### Solution 1: Optimiser Prompt Vision
```python
def create_detailed_analysis_prompt(context):
    """Cr√©e prompt structur√© pour GPT-5"""
    prompt = f"""Analyse cette image en d√©tail pour un contexte {context}.

Structure ta r√©ponse ainsi:
1. DESCRIPTION G√âN√âRALE (2-3 phrases)
2. √âL√âMENTS PRINCIPAUX (liste d√©taill√©e)
3. D√âTAILS TECHNIQUES (couleurs, composition, style)
4. PERTINENCE P√âDAGOGIQUE (si applicable)
5. SUGGESTIONS AM√âLIORATION (si n√©cessaire)

Sois pr√©cis, factuel, et exhaustif."""
    
    return prompt

# Usage
analysis_prompt = create_detailed_analysis_prompt("√©ducation sciences")
```

#### Solution 2: V√©rifier Qualit√© Image
```python
from PIL import Image

def check_image_quality(image_path):
    """V√©rifie que l'image est acceptable pour GPT-5"""
    img = Image.open(image_path)
    
    # Dimensions
    width, height = img.size
    pixels = width * height
    
    checks = {
        'dimensions_ok': width >= 256 and height >= 256,
        'not_too_large': pixels <= 4096 * 4096,
        'format_supported': img.format in ['PNG', 'JPEG', 'WEBP', 'GIF']
    }
    
    if all(checks.values()):
        print(f"‚úÖ Image OK: {width}x{height}, {img.format}")
        return True
    else:
        print(f"‚ö†Ô∏è Issues d√©tect√©s:")
        for check, passed in checks.items():
            if not passed:
                print(f"  - {check}: ‚ùå")
        return False
```

---

## üí∞ Gestion des Co√ªts

### 16. üìà Cost Overrun

#### Monitoring Costs
```python
class DetailedCostTracker:
    """Tracker co√ªts avec alertes"""
    def __init__(self, daily_budget=10.0):
        self.daily_budget = daily_budget
        self.costs = []
        self.alerts = []
    
    def log_request(self, model, cost, metadata=None):
        """Log requ√™te avec co√ªt"""
        entry = {
            'timestamp': datetime.now(),
            'model': model,
            'cost': cost,
            'metadata': metadata or {}
        }
        self.costs.append(entry)
        
        # V√©rifier budget
        daily_total = self.get_daily_total()
        if daily_total > self.daily_budget * 0.8:
            self.alerts.append(f"‚ö†Ô∏è 80% budget quotidien atteint: ${daily_total:.2f}")
    
    def get_daily_total(self):
        """Calcule total journ√©e en cours"""
        today = datetime.now().date()
        return sum(
            c['cost'] for c in self.costs 
            if c['timestamp'].date() == today
        )
    
    def get_report(self):
        """Rapport d√©taill√©"""
        total = sum(c['cost'] for c in self.costs)
        by_model = {}
        
        for cost in self.costs:
            model = cost['model']
            by_model[model] = by_model.get(model, 0) + cost['cost']
        
        return {
            'total': total,
            'daily': self.get_daily_total(),
            'by_model': by_model,
            'alerts': self.alerts
        }

# Usage
tracker = DetailedCostTracker(daily_budget=5.0)

# Log chaque requ√™te
tracker.log_request('dalle-3-standard', 0.040, {'size': '1024x1024'})

# Rapport
report = tracker.get_report()
print(f"üí∞ Co√ªt total: ${report['total']:.2f}")
print(f"üìä Par mod√®le: {report['by_model']}")
```

---

### 17. üí° Cost Optimization Strategies

#### Strat√©gie 1: Caching Intelligent
```python
import hashlib
import json
from pathlib import Path

class ImageCache:
    """Cache images g√©n√©r√©es pour √©viter reg√©n√©ration"""
    def __init__(self, cache_dir="cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def get_cache_key(self, prompt, size, quality):
        """G√©n√®re cl√© cache unique"""
        content = f"{prompt}|{size}|{quality}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def get(self, prompt, size, quality):
        """R√©cup√®re depuis cache si existe"""
        key = self.get_cache_key(prompt, size, quality)
        cache_file = self.cache_dir / f"{key}.json"
        
        if cache_file.exists():
            with open(cache_file) as f:
                data = json.load(f)
            print(f"‚úÖ Cache hit: {key[:8]}...")
            return data
        
        return None
    
    def set(self, prompt, size, quality, response_data):
        """Sauvegarde dans cache"""
        key = self.get_cache_key(prompt, size, quality)
        cache_file = self.cache_dir / f"{key}.json"
        
        with open(cache_file, 'w') as f:
            json.dump(response_data, f)
        
        print(f"üíæ Cached: {key[:8]}...")

# Usage
cache = ImageCache()

# V√©rifier cache avant g√©n√©ration
cached = cache.get(prompt, '1024x1024', 'standard')
if cached:
    image_url = cached['url']
else:
    response = client.images.generate(...)
    cache.set(prompt, '1024x1024', 'standard', {
        'url': response.data[0].url,
        'revised_prompt': response.data[0].revised_prompt
    })
```

---

## üîå Probl√®mes Int√©gration

### 18. üêã Docker Services Not Starting

#### Diagnostic
```bash
# V√©rifier status services
docker-compose ps

# Logs services
docker-compose logs

# V√©rifier ressources
docker system df
```

#### Solutions

**Solution 1: Restart Clean**
```bash
# Arr√™ter tout
docker-compose down

# Nettoyer
docker system prune -a --volumes

# Red√©marrer
docker-compose up -d
```

**Solution 2: V√©rifier Ports**
```bash
# V√©rifier ports disponibles
netstat -tuln | grep 8188  # ComfyUI
netstat -tuln | grep 8000  # Qwen

# Si port occup√©, modifier docker-compose.yml
ports:
  - "8189:8188"  # Port alternatif
```

---

### 19. üîó Integration avec Syst√®mes Externes

#### Issue: CORS Errors
```javascript
// Si appel depuis browser
Access-Control-Allow-Origin error
```

#### Solution: Proxy Backend
```python
from flask import Flask, request, jsonify
from flask_cors import CORS
import requests

app = Flask(__name__)
CORS(app)

@app.route('/api/generate', methods=['POST'])
def generate_image():
    """Proxy pour √©viter CORS"""
    data = request.json
    
    # Call OpenAI
    response = client.images.generate(
        model="dall-e-3",
        prompt=data['prompt'],
        size=data.get('size', '1024x1024')
    )
    
    return jsonify({
        'url': response.data[0].url,
        'revised_prompt': response.data[0].revised_prompt
    })

if __name__ == '__main__':
    app.run(port=5000)
```

---

## üõ†Ô∏è Scripts Diagnostiques

### Script 1: Health Check Complet

```python
#!/usr/bin/env python3
"""
health_check.py - Diagnostic complet √©cosyst√®me GenAI
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv
import requests

def check_environment():
    """V√©rifie configuration environnement"""
    print("üîç V√©rification Environnement...")
    
    checks = {
        '.env exists': Path('.env').exists(),
        'Python >= 3.10': sys.version_info >= (3, 10),
        'OpenAI key set': bool(os.getenv('OPENAI_API_KEY')),
        'OpenRouter key set': bool(os.getenv('OPENROUTER_API_KEY'))
    }
    
    for check, passed in checks.items():
        status = "‚úÖ" if passed else "‚ùå"
        print(f"  {status} {check}")
    
    return all(checks.values())

def check_apis():
    """Teste connectivit√© APIs"""
    print("\nüåê Test APIs...")
    
    results = {}
    
    # OpenAI
    try:
        from openai import OpenAI
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        models = client.models.list()
        results['OpenAI'] = True
        print("  ‚úÖ OpenAI API")
    except Exception as e:
        results['OpenAI'] = False
        print(f"  ‚ùå OpenAI API: {e}")
    
    # OpenRouter
    try:
        client = OpenAI(
            api_key=os.getenv("OPENROUTER_API_KEY"),
            base_url="https://openrouter.ai/api/v1"
        )
        response = client.chat.completions.create(
            model="openai/gpt-4-turbo",
            messages=[{"role": "user", "content": "test"}],
            max_tokens=5
        )
        results['OpenRouter'] = True
        print("  ‚úÖ OpenRouter API")
    except Exception as e:
        results['OpenRouter'] = False
        print(f"  ‚ùå OpenRouter API: {e}")
    
    return results

def check_dependencies():
    """V√©rifie d√©pendances Python"""
    print("\nüì¶ V√©rification D√©pendances...")
    
    required = {
        'openai': '1.3.0',
        'Pillow': '10.0.0',
        'requests': '2.31.0',
        'jupyter': '1.0.0'
    }
    
    results = {}
    for package, min_version in required.items():
        try:
            __import__(package)
            results[package] = True
            print(f"  ‚úÖ {package}")
        except ImportError:
            results[package] = False
            print(f"  ‚ùå {package} (requis: >={min_version})")
    
    return results

def main():
    """Ex√©cution diagnostic complet"""
    print("=" * 60)
    print("üè• DIAGNOSTIC COMPLET - GenAI Images CoursIA")
    print("=" * 60)
    
    # Load environment
    load_dotenv()
    
    # Run checks
    env_ok = check_environment()
    api_results = check_apis()
    dep_results = check_dependencies()
    
    # Summary
    print("\n" + "=" * 60)
    print("üìä R√âSUM√â")
    print("=" * 60)
    
    all_ok = (
        env_ok and
        all(api_results.values()) and
        all(dep_results.values())
    )
    
    if all_ok:
        print("‚úÖ Tous les tests pass√©s ! Syst√®me pr√™t.")
        sys.exit(0)
    else:
        print("‚ùå Certains tests ont √©chou√©. Voir d√©tails ci-dessus.")
        sys.exit(1)

if __name__ == '__main__':
    main()
```

**Usage** :
```bash
python scripts/health_check.py
```

---

### Script 2: Cost Calculator

```python
#!/usr/bin/env python3
"""
cost_calculator.py - Estimateur co√ªts GenAI
"""

def calculate_project_cost(num_images, size='1024x1024', quality='standard'):
    """Estime co√ªt projet"""
    
    costs = {
        ('1024x1024', 'standard'): 0.040,
        ('1024x1024', 'hd'): 0.080,
        ('1024x1792', 'standard'): 0.080,
        ('1024x1792', 'hd'): 0.120,
        ('1792x1024', 'standard'): 0.080,
        ('1792x1024', 'hd'): 0.120
    }
    
    cost_per_image = costs.get((size, quality), 0.040)
    total = num_images * cost_per_image
    
    print(f"üí∞ Estimation Co√ªts Projet")
    print(f"=" * 40)
    print(f"Images: {num_images}")
    print(f"Taille: {size}")
    print(f"Qualit√©: {quality}")
    print(f"Co√ªt unitaire: ${cost_per_image:.3f}")
    print(f"=" * 40)
    print(f"TOTAL: ${total:.2f}")
    
    return total

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python cost_calculator.py <num_images> [size] [quality]")
        sys.exit(1)
    
    num_images = int(sys.argv[1])
    size = sys.argv[2] if len(sys.argv) > 2 else '1024x1024'
    quality = sys.argv[3] if len(sys.argv) > 3 else 'standard'
    
    calculate_project_cost(num_images, size, quality)
```

**Usage** :
```bash
# Estimer 50 images standard
python scripts/cost_calculator.py 50

# Estimer 20 images HD landscape
python scripts/cost_calculator.py 20 1792x1024 hd
```

---

## üìû Support & Escalation

### Niveaux de Support

#### Niveau 1: Auto-diagnostic
1. Consulter ce guide TROUBLESHOOTING
2. Ex√©cuter scripts diagnostiques
3. Rechercher dans FAQ ([INDEX.md](INDEX.md))

#### Niveau 2: Documentation
1. Consulter tutoriels complets ([`tutorials/`](tutorials/))
2. V√©rifier exemples sectoriels ([`examples/`](examples/))
3. Lire docs techniques ([`docs/genai/`](../../docs/genai/))

#### Niveau 3: Community Support
- üí¨ **Discord**: [CoursIA Community](https://discord.gg/coursia)
- üìß **Forum**: [forum.coursia.ai/genai](https://forum.coursia.ai/genai)
- üìö **Stack Overflow**: Tag `coursia-genai`

#### Niveau 4: Technical Support
- üìß **Email**: support@coursia.ai
- üé´ **Tickets**: [support.coursia.ai](https://support.coursia.ai)
- ‚è∞ **Horaires**: Lun-Ven 9h-18h CET

---

### Informations √† Fournir pour Support

#### Template Ticket Support

```markdown
**Environnement**
- OS: [Windows 11 / macOS 13 / Ubuntu 22.04]
- Python: [3.11.5]
- Notebook: [01-1-OpenAI-DALL-E-3.ipynb]

**Probl√®me**
[Description d√©taill√©e du probl√®me]

**Erreur**
```
[Copier-coller message d'erreur complet avec stack trace]
```

**√âtapes pour Reproduire**
1. [√âtape 1]
2. [√âtape 2]
3. [R√©sultat observ√©]

**Comportement Attendu**
[Ce qui devrait se passer]

**Tentatives de R√©solution**
- [ ] V√©rifi√© .env configuration
- [ ] Ex√©cut√© health_check.py
- [ ] Consult√© TROUBLESHOOTING.md
- [ ] Test√© avec autre notebook

**Logs/Screenshots**
[Joindre fichiers pertinents]
```

---

### Escalation Proc√©dure

**Probl√®mes Critiques (P0)** :
- Services compl√®tement indisponibles
- Perte de donn√©es
- Failles s√©curit√©

**Action** : Email imm√©diat √† emergency@coursia.ai

**Probl√®mes Majeurs (P1)** :
- Fonctionnalit√©s principales cass√©es
- Blocage d√©veloppement
- Erreurs APIs persistantes

**Action** : Ticket support avec priorit√© haute

**Probl√®mes Mineurs (P2)** :
- Bugs non-bloquants
- Probl√®mes performance
- Questions usage

**Action** : Ticket support standard ou community

---

## üìö Ressources Additionnelles

### Documentation Officielle
- [OpenAI API Docs](https://platform.openai.com/docs)
- [OpenRouter Documentation](https://openrouter.ai/docs)
- [Pillow Documentation](https://pillow.readthedocs.io/)
- [Papermill Guide](https://papermill.readthedocs.io/)

### Guides CoursIA
- [INDEX Complet](INDEX.md)
- [DEPLOYMENT Guide](DEPLOYMENT.md)
- [Tutorials Complets](tutorials/)

### Communaut√©
- [Discord CoursIA](https://discord.gg/coursia)
- [GitHub Discussions](https://github.com/coursia/genai/discussions)
- [Twitter @CoursIA](https://twitter.com/coursia)

---

**Version** : 1.0.0  
**Derni√®re mise √† jour** : 2025-10-08  
**Maintainers** : √âquipe Support CoursIA

---

üí° **Probl√®me non r√©solu ?** Contactez-nous sur support@coursia.ai