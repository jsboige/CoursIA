{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude CLI - Automatisation Avancee\n",
    "\n",
    "**Module :** Vibe-Coding / Claude Code / Notebooks CLI  \n",
    "**Niveau :** Avance  \n",
    "**Duree :** 30 min  \n",
    "**Prerequis :** Notebooks 01-04 completes\n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "- [ ] Creer des pipelines d'automatisation avec subprocess\n",
    "- [ ] Integrer Claude dans des scripts Bash/PowerShell\n",
    "- [ ] Comprendre les slash commands (/commit, /review)\n",
    "- [ ] Decouvrir les hooks (PreToolUse, PostToolUse)\n",
    "- [ ] Construire un script de revue de code automatise\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, 'helpers')\n",
    "from claude_cli import run_claude, verify_installation, print_response\n",
    "\n",
    "EXAMPLES_DIR = Path('examples/sample_project')\n",
    "print(f\"Claude CLI pret: {verify_installation()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipelines avec Subprocess\n",
    "\n",
    "Les pipelines permettent de chainer des operations Claude pour des workflows complexes :\n",
    "\n",
    "```\n",
    "Input → [Claude: Analyse] → [Claude: Correction] → [Claude: Review] → Output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(*steps):\n",
    "    \"\"\"\n",
    "    Cree un pipeline de prompts Claude.\n",
    "    \n",
    "    Args:\n",
    "        steps: Liste de tuples (nom, prompt_template)\n",
    "        \n",
    "    Returns:\n",
    "        Fonction qui execute le pipeline.\n",
    "    \"\"\"\n",
    "    def execute(initial_input):\n",
    "        current_data = initial_input\n",
    "        results = []\n",
    "        \n",
    "        for step_name, prompt_template in steps:\n",
    "            prompt = prompt_template.format(input=current_data)\n",
    "            stdout, stderr, code = run_claude(prompt, model=\"haiku\")\n",
    "            \n",
    "            if code != 0:\n",
    "                return {\"error\": f\"Etape '{step_name}' echouee\", \"stderr\": stderr}\n",
    "            \n",
    "            results.append({\"step\": step_name, \"output\": stdout})\n",
    "            current_data = stdout\n",
    "        \n",
    "        return {\"success\": True, \"results\": results, \"final_output\": current_data}\n",
    "    \n",
    "    return execute\n",
    "\n",
    "print(\"Fonction create_pipeline definie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de pipeline : Analyse → Resume → Ameliorations\n",
    "code_review_pipeline = create_pipeline(\n",
    "    (\"analyse\", \"Analyse ce code et liste ses caracteristiques principales:\\n{input}\"),\n",
    "    (\"resume\", \"Resume cette analyse en 3 points cles:\\n{input}\"),\n",
    "    (\"ameliorations\", \"Propose 2 ameliorations basees sur ce resume:\\n{input}\")\n",
    ")\n",
    "\n",
    "print(\"Pipeline de revue de code defini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du pipeline (ATTENTION: 3 appels API)\n",
    "sample_code = '''\n",
    "def process_data(items):\n",
    "    result = []\n",
    "    for item in items:\n",
    "        if item > 0:\n",
    "            result.append(item * 2)\n",
    "    return result\n",
    "'''\n",
    "\n",
    "# Decommentez pour executer\n",
    "# output = code_review_pipeline(sample_code)\n",
    "# if output.get(\"success\"):\n",
    "#     for r in output[\"results\"]:\n",
    "#         print(f\"\\n=== {r['step'].upper()} ===\")\n",
    "#         print(r['output'][:300])\n",
    "\n",
    "print(\"(Pipeline non execute - decommentez pour tester)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integration Scripts Shell\n",
    "\n",
    "Claude Code peut etre integre dans des scripts Bash ou PowerShell.\n",
    "\n",
    "### Exemple Bash\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# Script de revue automatique\n",
    "\n",
    "FILE=$1\n",
    "REVIEW=$(claude -p \"Revue de code pour: $(cat $FILE)\")\n",
    "echo \"$REVIEW\" > \"${FILE}.review.md\"\n",
    "```\n",
    "\n",
    "### Exemple PowerShell\n",
    "```powershell\n",
    "# Analyse de tous les fichiers Python\n",
    "Get-ChildItem -Filter *.py | ForEach-Object {\n",
    "    $content = Get-Content $_.FullName -Raw\n",
    "    claude -p \"Resume ce fichier: $content\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer un script de revue automatique\n",
    "bash_script = '''#!/bin/bash\n",
    "# Script de revue de code automatique avec Claude\n",
    "\n",
    "FILE=\"$1\"\n",
    "\n",
    "if [ -z \"$FILE\" ]; then\n",
    "    echo \"Usage: $0 <fichier.py>\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "if [ ! -f \"$FILE\" ]; then\n",
    "    echo \"Fichier non trouve: $FILE\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"Analyse de $FILE...\"\n",
    "CONTENT=$(cat \"$FILE\")\n",
    "\n",
    "REVIEW=$(claude -p \"Effectue une revue de code pour ce fichier Python. \n",
    "Identifie: bugs potentiels, problemes de style, ameliorations possibles.\n",
    "\n",
    "Code:\n",
    "$CONTENT\")\n",
    "\n",
    "OUTPUT=\"${FILE%.py}.review.md\"\n",
    "echo \"# Code Review: $FILE\" > \"$OUTPUT\"\n",
    "echo \"\" >> \"$OUTPUT\"\n",
    "echo \"$REVIEW\" >> \"$OUTPUT\"\n",
    "\n",
    "echo \"Revue sauvegardee dans: $OUTPUT\"\n",
    "'''\n",
    "\n",
    "print(bash_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version Python equivalente\n",
    "def auto_review(filepath):\n",
    "    \"\"\"Effectue une revue de code automatique.\"\"\"\n",
    "    path = Path(filepath)\n",
    "    \n",
    "    if not path.exists():\n",
    "        return {\"error\": f\"Fichier non trouve: {filepath}\"}\n",
    "    \n",
    "    content = path.read_text()\n",
    "    \n",
    "    stdout, stderr, code = run_claude(\n",
    "        f\"\"\"Effectue une revue de code pour ce fichier Python.\n",
    "Identifie:\n",
    "1. Bugs potentiels\n",
    "2. Problemes de style (PEP 8)\n",
    "3. Ameliorations possibles\n",
    "4. Securite\n",
    "\n",
    "Format: sections avec titres markdown.\n",
    "\n",
    "Code:\n",
    "{content}\"\"\",\n",
    "        model=\"sonnet\"\n",
    "    )\n",
    "    \n",
    "    if code == 0:\n",
    "        output_path = path.with_suffix('.review.md')\n",
    "        output_path.write_text(f\"# Code Review: {path.name}\\n\\n{stdout}\")\n",
    "        return {\"success\": True, \"review\": stdout, \"output_file\": str(output_path)}\n",
    "    else:\n",
    "        return {\"error\": stderr}\n",
    "\n",
    "print(\"Fonction auto_review definie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Slash Commands\n",
    "\n",
    "Claude Code propose des commandes integrees accessibles avec `/` :\n",
    "\n",
    "| Commande | Description |\n",
    "|----------|-------------|\n",
    "| `/init` | Genere un CLAUDE.md pour le projet |\n",
    "| `/commit` | Cree un commit avec message genere |\n",
    "| `/review` | Revue des changements en cours |\n",
    "| `/status` | Statut de connexion |\n",
    "| `/mcp` | Statut des serveurs MCP |\n",
    "\n",
    "Ces commandes sont utilisees en mode interactif (`claude` sans `-p`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuler /commit : generer un message de commit\n",
    "def generate_commit_message(diff_content):\n",
    "    \"\"\"Genere un message de commit a partir d'un diff.\"\"\"\n",
    "    stdout, stderr, code = run_claude(\n",
    "        f\"\"\"Genere un message de commit conventionnel pour ces changements.\n",
    "\n",
    "Format attendu:\n",
    "type(scope): description courte\n",
    "\n",
    "Description detaillee si necessaire.\n",
    "\n",
    "Types: feat, fix, docs, style, refactor, test, chore\n",
    "\n",
    "Diff:\n",
    "{diff_content}\"\"\",\n",
    "        model=\"haiku\"\n",
    "    )\n",
    "    return stdout if code == 0 else f\"Erreur: {stderr}\"\n",
    "\n",
    "# Exemple de diff\n",
    "example_diff = '''\n",
    "--- a/utils.py\n",
    "+++ b/utils.py\n",
    "@@ -15,6 +15,10 @@ def calculate_statistics(data):\n",
    "+    if not data:\n",
    "+        raise ValueError(\"Empty data\")\n",
    "+\n",
    "     mean = sum(data) / len(data)\n",
    "'''\n",
    "\n",
    "# Decommentez pour tester\n",
    "# message = generate_commit_message(example_diff)\n",
    "# print(message)\n",
    "\n",
    "print(\"Fonction generate_commit_message definie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hooks (Concept)\n",
    "\n",
    "Les **hooks** permettent d'intercepter les actions de Claude pour les modifier ou les valider.\n",
    "\n",
    "Types de hooks :\n",
    "- **PreToolUse** : Avant l'utilisation d'un outil (Write, Bash, etc.)\n",
    "- **PostToolUse** : Apres l'utilisation\n",
    "- **Notification** : Sur certains evenements\n",
    "\n",
    "Configuration dans `.claude/settings.json` :\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"hooks\": {\n",
    "    \"PreToolUse\": {\n",
    "      \"Write\": \"python validate_write.py\"\n",
    "    },\n",
    "    \"PostToolUse\": {\n",
    "      \"Bash\": \"python log_bash.py\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de hook de validation\n",
    "def validate_write_hook(filepath, content):\n",
    "    \"\"\"Hook qui valide le contenu avant ecriture.\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Verifications de securite\n",
    "    if 'password' in content.lower() and '=' in content:\n",
    "        issues.append(\"Possible mot de passe en clair detecte\")\n",
    "    \n",
    "    if 'api_key' in content.lower():\n",
    "        issues.append(\"Possible cle API detectee\")\n",
    "    \n",
    "    # Verifications de style\n",
    "    if filepath.endswith('.py'):\n",
    "        if 'import *' in content:\n",
    "            issues.append(\"Import wildcard detecte (mauvaise pratique)\")\n",
    "    \n",
    "    return {\n",
    "        \"approved\": len(issues) == 0,\n",
    "        \"issues\": issues\n",
    "    }\n",
    "\n",
    "# Test\n",
    "test_content = '''\n",
    "from utils import *\n",
    "api_key = \"sk-1234\"\n",
    "'''\n",
    "\n",
    "result = validate_write_hook(\"config.py\", test_content)\n",
    "print(f\"Approuve: {result['approved']}\")\n",
    "print(f\"Problemes: {result['issues']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Script de Revue Automatise Complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeReviewer:\n",
    "    \"\"\"Revue de code automatisee avec Claude.\"\"\"\n",
    "    \n",
    "    def __init__(self, model=\"sonnet\"):\n",
    "        self.model = model\n",
    "        self.checks = [\n",
    "            (\"bugs\", \"Identifie les bugs potentiels\"),\n",
    "            (\"style\", \"Verifie le style PEP 8\"),\n",
    "            (\"security\", \"Analyse les problemes de securite\"),\n",
    "            (\"performance\", \"Identifie les optimisations possibles\"),\n",
    "        ]\n",
    "    \n",
    "    def review_file(self, filepath):\n",
    "        \"\"\"Effectue une revue complete d'un fichier.\"\"\"\n",
    "        path = Path(filepath)\n",
    "        if not path.exists():\n",
    "            return {\"error\": \"Fichier non trouve\"}\n",
    "        \n",
    "        content = path.read_text()\n",
    "        results = {\"file\": str(path), \"checks\": {}}\n",
    "        \n",
    "        for check_name, check_desc in self.checks:\n",
    "            stdout, stderr, code = run_claude(\n",
    "                f\"{check_desc} dans ce code (reponse courte):\\n\\n{content}\",\n",
    "                model=\"haiku\"  # Rapide pour chaque check\n",
    "            )\n",
    "            results[\"checks\"][check_name] = stdout if code == 0 else f\"Erreur: {stderr}\"\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def review_project(self, directory, pattern=\"*.py\"):\n",
    "        \"\"\"Revue tous les fichiers d'un projet.\"\"\"\n",
    "        path = Path(directory)\n",
    "        files = list(path.rglob(pattern))\n",
    "        \n",
    "        return {\n",
    "            \"directory\": str(path),\n",
    "            \"files_count\": len(files),\n",
    "            \"files\": [str(f) for f in files]\n",
    "            # En production, on appellerait review_file pour chaque fichier\n",
    "        }\n",
    "    \n",
    "    def generate_report(self, results):\n",
    "        \"\"\"Genere un rapport markdown.\"\"\"\n",
    "        lines = [f\"# Code Review: {results['file']}\\n\"]\n",
    "        \n",
    "        for check, output in results.get(\"checks\", {}).items():\n",
    "            lines.append(f\"## {check.title()}\\n\")\n",
    "            lines.append(output + \"\\n\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "print(\"CodeReviewer defini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du reviewer (ATTENTION: multiple appels API)\n",
    "reviewer = CodeReviewer()\n",
    "\n",
    "# Voir les fichiers disponibles\n",
    "project_info = reviewer.review_project(EXAMPLES_DIR)\n",
    "print(f\"Fichiers dans le projet: {project_info['files_count']}\")\n",
    "for f in project_info['files']:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revue d'un fichier (decommentez pour executer - 4 appels API)\n",
    "# results = reviewer.review_file(EXAMPLES_DIR / \"utils.py\")\n",
    "# report = reviewer.generate_report(results)\n",
    "# print(report)\n",
    "\n",
    "print(\"(Revue non executee - decommentez pour tester)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exercices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 1 : Creez un pipeline qui:\n",
    "# 1. Lit un fichier Python\n",
    "# 2. Identifie les fonctions sans docstring\n",
    "# 3. Genere les docstrings manquantes\n",
    "\n",
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 2 : Creez un hook qui verifie\n",
    "# que tout fichier Python a au moins un test associe\n",
    "\n",
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 3 : Etendez CodeReviewer avec un check supplementaire\n",
    "# de votre choix (ex: documentation, tests, complexite)\n",
    "\n",
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resume Final\n",
    "\n",
    "Dans cette serie de notebooks, nous avons appris :\n",
    "\n",
    "| Notebook | Competences acquises |\n",
    "|----------|---------------------|\n",
    "| **01-Bases** | `claude -p`, modeles, formats de sortie |\n",
    "| **02-Sessions** | `-c`, sessions, conversations multi-tours |\n",
    "| **03-References** | @fichier, plages de lignes, CLAUDE.md |\n",
    "| **04-Agents** | Explore, Plan, subagents, parallelisation |\n",
    "| **05-Automatisation** | Pipelines, scripts, hooks, revue automatisee |\n",
    "\n",
    "### Pour aller plus loin\n",
    "\n",
    "- **Documentation officielle** : [docs.claude.com/code](https://docs.claude.com/code)\n",
    "- **Concepts avances** : [CONCEPTS-AVANCES.md](../../docs/claude-code/CONCEPTS-AVANCES.md)\n",
    "- **Modeles alternatifs** : [OPENROUTER-MODELES-ALTERNATIFS.md](../../docs/claude-code/OPENROUTER-MODELES-ALTERNATIFS.md)\n",
    "\n",
    "### Ressources communautaires\n",
    "\n",
    "- [Awesome Claude Code](https://github.com/hesreallyhim/awesome-claude-code)\n",
    "- [SkillsMP Marketplace](https://skillsmp.com/)\n",
    "\n",
    "---\n",
    "\n",
    "**Felicitations !** Vous avez complete la serie de notebooks Claude CLI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
