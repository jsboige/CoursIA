{
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "genai": {
      "enabled": true,
      "level": "foundation", 
      "module": "01-Images-Foundation",
      "dependencies": [
        "openai",
        "requests", 
        "pillow",
        "matplotlib",
        "base64"
      ],
      "estimated_duration_minutes": 30,
      "difficulty": "beginner",
      "learning_outcomes": [
        "Utiliser GPT-5 pour analyse et description d'images",
        "MaÃ®triser les conversations multimodales",
        "Comprendre les capacitÃ©s visuelles de GPT-5",
        "IntÃ©grer GPT-5 dans workflows pÃ©dagogiques",
        "Optimiser les prompts pour l'analyse visuelle"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# ğŸ¤– GPT-5 Multimodal - Analyse et GÃ©nÃ©ration d'Images\n\n**Module :** 01-Images-Foundation  \n**Niveau :** ğŸŸ¢ DÃ©butant  \n**Technologies :** GPT-5, OpenRouter API, Vision AI  \n**DurÃ©e estimÃ©e :** 30 minutes  \n\n## ğŸ¯ Objectifs d'Apprentissage\n\n- [ ] Configurer GPT-5 via OpenRouter pour analyse d'images\n- [ ] MaÃ®triser les conversations multimodales texte + image\n- [ ] Analyser et dÃ©crire des images avec prÃ©cision\n- [ ] CrÃ©er des prompts optimisÃ©s pour l'analyse visuelle\n- [ ] IntÃ©grer GPT-5 dans des cas d'usage pÃ©dagogiques\n\n## ğŸ“š PrÃ©requis\n\n- Environment Setup (module 00) complÃ©tÃ©\n- ClÃ© API OpenRouter configurÃ©e\n- Connaissances de base en IA multimodale\n\n## âš¡ CapacitÃ©s GPT-5\n\n- **Vision avancÃ©e** : Analyse dÃ©taillÃ©e d'images\n- **Multimodal** : Conversation texte + image simultanÃ©e\n- **Contexte Ã©tendu** : Jusqu'Ã  200K tokens\n- **Raisonnement** : Analyse complexe et dÃ©ductive\n- **Ã‰ducatif** : Parfait pour l'enseignement",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# ParamÃ¨tres Papermill - JAMAIS modifier ce commentaire\n\n# Configuration conversation\nnotebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\nskip_widgets = False               # True pour mode batch MCP\ndebug_level = \"INFO\"               \n\n# ParamÃ¨tres GPT-5\nmodel_name = \"openai/gpt-5\"        # ModÃ¨le via OpenRouter\nmax_tokens = 4000                  # Tokens de rÃ©ponse max\ntemperature = 0.7                  # CrÃ©ativitÃ© (0.0-1.0)\ntop_p = 0.9                        # DiversitÃ© sampling\n\n# Configuration analyse\nanalysis_mode = \"detailed\"         # \"quick\", \"detailed\", \"educational\"\ninclude_technical_details = True   # DÃ©tails techniques images\nexport_analysis = True             # Sauvegarder analyses\ngenerate_alt_text = True           # GÃ©nÃ©rer descriptions accessibilitÃ©\n\n# ParamÃ¨tres pÃ©dagogiques\neducational_level = \"university\"   # \"elementary\", \"secondary\", \"university\"\nlanguage = \"franÃ§ais\"              # Langue des explications\ninclude_examples = True            # Inclure exemples pratiques",
      "metadata": {
        "tags": ["parameters"]
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Setup environnement et imports\nimport os\nimport sys\nimport json\nimport requests\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional, Union\nimport base64\nfrom io import BytesIO\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport logging\nfrom urllib.parse import urlparse\n\n# Import helpers GenAI\nGENAI_ROOT = Path.cwd()\nwhile GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n    GENAI_ROOT = GENAI_ROOT.parent\n\nHELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\nif HELPERS_PATH.exists():\n    sys.path.insert(0, str(HELPERS_PATH.parent))\n    try:\n        from helpers.genai_helpers import setup_genai_logging, load_genai_config\n        print(\"âœ… Helpers GenAI importÃ©s\")\n    except ImportError:\n        print(\"âš ï¸  Helpers GenAI non disponibles - mode autonome\")\n\n# Configuration logging\nlogging.basicConfig(level=getattr(logging, debug_level))\nlogger = logging.getLogger('gpt5_multimodal')\n\nprint(f\"ğŸ¤– GPT-5 Multimodal - Analyse et GÃ©nÃ©ration d'Images\")\nprint(f\"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"ğŸ”§ Mode: {notebook_mode}, Analyse: {analysis_mode}, Niveau: {educational_level}\")\nprint(f\"ğŸŒ Langue: {language}, Max tokens: {max_tokens}\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Configuration API OpenRouter pour GPT-5\nprint(\"\\nğŸ”‘ CONFIGURATION GPT-5 MULTIMODAL\")\nprint(\"=\" * 42)\n\n# VÃ©rification clÃ© API\nopenrouter_key = os.getenv('OPENROUTER_API_KEY')\nif not openrouter_key:\n    raise ValueError(\"âŒ OPENROUTER_API_KEY manquante dans .env\")\n\nprint(f\"âœ… ClÃ© API OpenRouter configurÃ©e\")\n\n# Configuration headers et endpoint\napi_base_url = \"https://openrouter.ai/api/v1\"\nheaders = {\n    \"Authorization\": f\"Bearer {openrouter_key}\",\n    \"HTTP-Referer\": \"https://coursia.myia.io\",\n    \"X-Title\": \"CoursIA GenAI Images - GPT-5 Multimodal\",\n    \"Content-Type\": \"application/json\"\n}\n\n# Test connexion et vÃ©rification modÃ¨le GPT-5\ntry:\n    response = requests.get(f\"{api_base_url}/models\", headers=headers, timeout=10)\n    if response.status_code == 200:\n        models_data = response.json()\n        gpt5_models = [m for m in models_data.get('data', []) if 'gpt-5' in m.get('id', '').lower()]\n        \n        if gpt5_models:\n            print(f\"âœ… Connexion rÃ©ussie - {len(gpt5_models)} modÃ¨les GPT-5 disponibles\")\n            \n            for model in gpt5_models:\n                print(f\"  ğŸ§  {model['id']} - Contexte: {model.get('context_length', 'N/A')} tokens\")\n                if 'vision' in model.get('capabilities', []):\n                    print(f\"     ğŸ‘ï¸  CapacitÃ©s vision activÃ©es\")\n        else:\n            print(f\"âš ï¸  Aucun modÃ¨le GPT-5 dÃ©tectÃ© - vÃ©rifiez votre accÃ¨s\")\n            print(f\"ğŸ” ModÃ¨les disponibles avec 'gpt' : {len([m for m in models_data.get('data', []) if 'gpt' in m.get('id', '').lower()])}\")\n    else:\n        print(f\"âš ï¸  Connexion API: HTTP {response.status_code}\")\nexcept Exception as e:\n    print(f\"âŒ Erreur connexion: {str(e)[:100]}...\")\n    \nprint(f\"\\nğŸ¯ ModÃ¨le sÃ©lectionnÃ©: {model_name}\")\nprint(f\"âš™ï¸  ParamÃ¨tres: Temperature={temperature}, Max tokens={max_tokens}\")\nprint(f\"ğŸ“Š Mode d'analyse: {analysis_mode}\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Fonctions utilitaires pour traitement d'images\ndef encode_image_base64(image_path: Union[str, Path]) -> str:\n    \"\"\"\n    Encode une image locale en base64 pour GPT-5.\n    \n    Args:\n        image_path: Chemin vers l'image locale\n        \n    Returns:\n        String base64 de l'image\n    \"\"\"\n    try:\n        with open(image_path, \"rb\") as image_file:\n            return base64.b64encode(image_file.read()).decode('utf-8')\n    except Exception as e:\n        raise ValueError(f\"Erreur lecture image {image_path}: {str(e)}\")\n\ndef download_and_encode_image(image_url: str) -> str:\n    \"\"\"\n    TÃ©lÃ©charge et encode une image depuis URL.\n    \n    Args:\n        image_url: URL de l'image\n        \n    Returns:\n        String base64 de l'image\n    \"\"\"\n    try:\n        response = requests.get(image_url, timeout=30)\n        response.raise_for_status()\n        return base64.b64encode(response.content).decode('utf-8')\n    except Exception as e:\n        raise ValueError(f\"Erreur tÃ©lÃ©chargement {image_url}: {str(e)}\")\n\ndef prepare_image_for_gpt5(image_source: Union[str, Path]) -> Dict[str, str]:\n    \"\"\"\n    PrÃ©pare une image pour GPT-5 (locale ou URL).\n    \n    Args:\n        image_source: Chemin local ou URL de l'image\n        \n    Returns:\n        Dict avec format attendu par GPT-5\n    \"\"\"\n    if isinstance(image_source, (str, Path)):\n        str_source = str(image_source)\n        \n        # VÃ©rification URL\n        if str_source.startswith(('http://', 'https://')):\n            try:\n                # Pour les URLs, GPT-5 peut les traiter directement\n                return {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": str_source\n                    }\n                }\n            except:\n                # Fallback : tÃ©lÃ©charger et encoder\n                base64_image = download_and_encode_image(str_source)\n                return {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n                    }\n                }\n        else:\n            # Image locale\n            if Path(str_source).exists():\n                base64_image = encode_image_base64(str_source)\n                return {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n                    }\n                }\n            else:\n                raise FileNotFoundError(f\"Image non trouvÃ©e: {str_source}\")\n    \n    raise ValueError(f\"Format d'image non supportÃ©: {type(image_source)}\")\n\nprint(\"âœ… Fonctions utilitaires images prÃªtes\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Fonction principale d'analyse d'image avec GPT-5\ndef analyze_image_with_gpt5(image_source: Union[str, Path], \n                           prompt: str = None,\n                           analysis_type: str = \"detailed\") -> Dict[str, Any]:\n    \"\"\"\n    Analyse une image avec GPT-5 multimodal.\n    \n    Args:\n        image_source: Chemin local ou URL de l'image\n        prompt: Prompt personnalisÃ© (optionnel)\n        analysis_type: Type d'analyse (\"quick\", \"detailed\", \"educational\")\n        \n    Returns:\n        Dict avec analyse complÃ¨te\n    \"\"\"\n    \n    # Prompts prÃ©dÃ©finis selon le type d'analyse\n    analysis_prompts = {\n        \"quick\": f\"DÃ©cris briÃ¨vement cette image en {language}. Sois concis mais prÃ©cis.\",\n        \n        \"detailed\": f\"\"\"Analyse cette image en dÃ©tail en {language}. Inclus :\n        \n1. **Description gÃ©nÃ©rale** : Que voit-on dans l'image ?\n2. **Ã‰lÃ©ments visuels** : Couleurs, composition, style artistique\n3. **Contexte** : Ã‰poque, lieu, situation probable\n4. **DÃ©tails techniques** : QualitÃ©, rÃ©solution apparente, type de photo/illustration\n5. **Ã‰motions/AtmosphÃ¨re** : Quelle ambiance dÃ©gage l'image ?\n6. **InterprÃ©tation** : Signification possible, message artistique\n\nSois prÃ©cis et pÃ©dagogique dans tes explications.\"\"\",\n        \n        \"educational\": f\"\"\"Tu es un professeur expert analysant cette image pour des Ã©tudiants de niveau {educational_level}. En {language}, fournis :\n\nğŸ¯ **ANALYSE PÃ‰DAGOGIQUE**\n\n**1. Description accessible**\n- Que montre cette image de faÃ§on simple et claire ?\n\n**2. Ã‰lÃ©ments Ã  observer**\n- Quels dÃ©tails importants les Ã©tudiants doivent-ils remarquer ?\n- Techniques artistiques ou photographiques utilisÃ©es\n\n**3. Contexte Ã©ducatif**\n- Dans quel domaine d'Ã©tude cette image serait-elle utile ?\n- Quelles disciplines acadÃ©miques peuvent l'utiliser ?\n\n**4. Questions pour rÃ©flexion**\n- 3 questions que tu poserais aux Ã©tudiants sur cette image\n\n**5. Connexions interdisciplinaires**\n- Comment cette image se connecte-t-elle Ã  d'autres sujets ?\n\nAdapte ton vocabulaire au niveau {educational_level}.\"\"\"\n    }\n    \n    # SÃ©lection du prompt\n    if prompt is None:\n        prompt = analysis_prompts.get(analysis_type, analysis_prompts[\"detailed\"])\n    \n    try:\n        print(f\"\\nğŸ” Analyse en cours...\")\n        print(f\"ğŸ“ Type: {analysis_type}\")\n        print(f\"ğŸ–¼ï¸  Source: {str(image_source)[:100]}{'...' if len(str(image_source)) > 100 else ''}\")\n        \n        # PrÃ©paration de l'image\n        image_data = prepare_image_for_gpt5(image_source)\n        \n        # Construction du message multimodal\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": prompt\n                    },\n                    image_data\n                ]\n            }\n        ]\n        \n        # Payload de la requÃªte\n        payload = {\n            \"model\": model_name,\n            \"messages\": messages,\n            \"max_tokens\": max_tokens,\n            \"temperature\": temperature,\n            \"top_p\": top_p\n        }\n        \n        # RequÃªte API\n        start_time = datetime.now()\n        response = requests.post(\n            f\"{api_base_url}/chat/completions\",\n            headers=headers,\n            json=payload,\n            timeout=120\n        )\n        response_time = (datetime.now() - start_time).total_seconds()\n        \n        if response.status_code == 200:\n            result = response.json()\n            \n            analysis_text = result[\"choices\"][0][\"message\"][\"content\"]\n            \n            # MÃ©tadonnÃ©es de l'analyse\n            metadata = {\n                \"model\": model_name,\n                \"analysis_type\": analysis_type,\n                \"educational_level\": educational_level,\n                \"language\": language,\n                \"timestamp\": datetime.now().isoformat(),\n                \"response_time\": response_time,\n                \"tokens_used\": result.get(\"usage\", {}),\n                \"image_source\": str(image_source),\n                \"prompt_length\": len(prompt)\n            }\n            \n            return {\n                \"success\": True,\n                \"analysis\": analysis_text,\n                \"metadata\": metadata,\n                \"image_source\": image_source,\n                \"analysis_type\": analysis_type\n            }\n        else:\n            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else {}\n            error_msg = error_data.get(\"error\", {}).get(\"message\", f\"HTTP {response.status_code}\")\n            \n            return {\n                \"success\": False,\n                \"error\": error_msg,\n                \"image_source\": image_source,\n                \"status_code\": response.status_code\n            }\n            \n    except Exception as e:\n        return {\n            \"success\": False,\n            \"error\": str(e),\n            \"image_source\": image_source\n        }\n\nprint(\"âœ… Fonction d'analyse GPT-5 prÃªte\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Exemples d'images pour dÃ©monstration\nprint(\"\\nğŸ–¼ï¸  EXEMPLES D'ANALYSE GPT-5\")\nprint(\"=\" * 40)\n\n# Images d'exemple (URLs publiques pour tests)\nexample_images = [\n    {\n        \"title\": \"ğŸ›ï¸ Architecture Historique\",\n        \"url\": \"https://images.unsplash.com/photo-1539037116277-4db20889f2d4?w=800\",  # ColisÃ©e Rome\n        \"description\": \"Monument historique romain - idÃ©al pour analyse architecturale\",\n        \"category\": \"Histoire/Architecture\"\n    },\n    {\n        \"title\": \"ğŸ”¬ Science et Technologie\",\n        \"url\": \"https://images.unsplash.com/photo-1532094349884-543bc11b234d?w=800\",  # Laboratoire\n        \"description\": \"Environnement scientifique - parfait pour analyse technique\",\n        \"category\": \"Science/Technologie\"\n    },\n    {\n        \"title\": \"ğŸ¨ Art et Culture\",\n        \"url\": \"https://images.unsplash.com/photo-1541961017774-22349e4a1262?w=800\",  # Peinture\n        \"description\": \"Å’uvre artistique - excellent pour analyse esthÃ©tique\",\n        \"category\": \"Art/Culture\"\n    },\n    {\n        \"title\": \"ğŸŒ Nature et Environnement\",\n        \"url\": \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800\",  # Paysage naturel\n        \"description\": \"Paysage naturel - parfait pour analyse gÃ©ographique\",\n        \"category\": \"GÃ©ographie/Environnement\"\n    }\n]\n\n# Affichage des exemples\nfor i, example in enumerate(example_images, 1):\n    print(f\"\\n{i}. {example['title']}\")\n    print(f\"   ğŸ“‚ CatÃ©gorie: {example['category']}\")\n    print(f\"   ğŸ“ {example['description']}\")\n    print(f\"   ğŸ”— URL: {example['url'][:60]}...\")\n\nprint(f\"\\nğŸ’¡ Conseils pour l'analyse avec GPT-5:\")\nprint(f\"â€¢ Utilisez des images de haute qualitÃ©\")\nprint(f\"â€¢ Posez des questions spÃ©cifiques\")\nprint(f\"â€¢ Exploitez le contexte Ã©ducatif\")\nprint(f\"â€¢ Combinez analyse textuelle et visuelle\")\nprint(f\"â€¢ Adaptez le niveau de complexitÃ©\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Analyse d'une image de dÃ©monstration\nprint(\"\\nğŸš€ ANALYSE DE DÃ‰MONSTRATION - GPT-5\")\nprint(\"=\" * 50)\n\n# SÃ©lection d'une image pour la dÃ©monstration\nselected_example = example_images[0]  # Architecture historique\nprint(f\"ğŸ¯ Analyse: {selected_example['title']}\")\nprint(f\"ğŸ“‚ CatÃ©gorie: {selected_example['category']}\")\n\n# Test de l'analyse avec les diffÃ©rents modes\nanalysis_results = []\n\nfor mode in ['quick', 'detailed', 'educational']:\n    print(f\"\\nğŸ” Mode d'analyse: {mode.upper()}\")\n    print(\"-\" * 30)\n    \n    # Analyse de l'image\n    result = analyze_image_with_gpt5(\n        image_source=selected_example['url'],\n        analysis_type=mode\n    )\n    \n    if result['success']:\n        print(f\"âœ… Analyse {mode} rÃ©ussie\")\n        print(f\"â±ï¸  Temps: {result['metadata']['response_time']:.2f}s\")\n        print(f\"ğŸ”¢ Tokens: {result['metadata']['tokens_used']}\")\n        \n        # Affichage de l'analyse (tronquÃ©e pour la dÃ©mo)\n        analysis_preview = result['analysis'][:300] + \"...\" if len(result['analysis']) > 300 else result['analysis']\n        print(f\"\\nğŸ“ **AperÃ§u de l'analyse {mode}:**\")\n        print(analysis_preview)\n        \n        analysis_results.append(result)\n    else:\n        print(f\"âŒ Ã‰chec analyse {mode}: {result['error']}\")\n    \n    print()  # SÃ©paration\n\n# Comparaison des rÃ©sultats\nif analysis_results:\n    print(f\"\\nğŸ“Š COMPARAISON DES MODES D'ANALYSE\")\n    print(\"=\" * 45)\n    \n    for result in analysis_results:\n        mode = result['analysis_type']\n        length = len(result['analysis'])\n        tokens = result['metadata'].get('tokens_used', {}).get('total_tokens', 'N/A')\n        time = result['metadata']['response_time']\n        \n        print(f\"{mode.capitalize():12} | {length:4d} chars | {tokens:>6} tokens | {time:5.2f}s\")\n    \n    print(f\"\\nğŸ’¡ Observations:\")\n    print(f\"â€¢ Mode 'quick': RÃ©ponses concises et rapides\")\n    print(f\"â€¢ Mode 'detailed': Analyse approfondie et structurÃ©e\")\n    print(f\"â€¢ Mode 'educational': AdaptÃ© Ã  l'enseignement avec questions\")\nelse:\n    print(f\"\\nâš ï¸  Aucune analyse rÃ©ussie - vÃ©rifiez votre configuration\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# GÃ©nÃ©ration de descriptions d'accessibilitÃ© (Alt text)\nif generate_alt_text and analysis_results:\n    print(\"\\nâ™¿ GÃ‰NÃ‰RATION DE DESCRIPTIONS D'ACCESSIBILITÃ‰\")\n    print(\"=\" * 55)\n    \n    # Prompt spÃ©cialisÃ© pour l'accessibilitÃ©\n    accessibility_prompt = f\"\"\"GÃ©nÃ¨re une description d'accessibilitÃ© (alt text) pour cette image en {language}.\n    \nCritÃ¨res :\n- Maximum 125 caractÃ¨res\n- Description factuelle et objective\n- Inclut les Ã©lÃ©ments essentiels pour la comprÃ©hension\n- Ã‰vite les interprÃ©tations subjectives\n- AdaptÃ© aux lecteurs d'Ã©cran\n\nFormat : Fournis UNIQUEMENT la description, sans formatage supplÃ©mentaire.\"\"\"\n    \n    # GÃ©nÃ©ration de l'alt text\n    alt_result = analyze_image_with_gpt5(\n        image_source=selected_example['url'],\n        prompt=accessibility_prompt\n    )\n    \n    if alt_result['success']:\n        alt_text = alt_result['analysis'].strip()\n        \n        print(f\"âœ… Description d'accessibilitÃ© gÃ©nÃ©rÃ©e\")\n        print(f\"ğŸ“ Alt text ({len(alt_text)} caractÃ¨res) :\")\n        print(f'   \"{alt_text}\"')\n        \n        if len(alt_text) > 125:\n            print(f\"âš ï¸  Longueur dÃ©passÃ©e ({len(alt_text)}/125 chars) - considÃ©rez une version plus courte\")\n        else:\n            print(f\"âœ… Longueur optimale ({len(alt_text)}/125 chars)\")\n    else:\n        print(f\"âŒ Erreur gÃ©nÃ©ration alt text: {alt_result['error']}\")\nelse:\n    print(f\"\\nâ­ï¸  GÃ©nÃ©ration alt text dÃ©sactivÃ©e ou pas d'analyse disponible\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Mode interactif - Analyse d'image personnalisÃ©e\nif notebook_mode == \"interactive\" and not skip_widgets:\n    print(\"\\nğŸ¨ MODE INTERACTIF - ANALYSE PERSONNALISÃ‰E\")\n    print(\"=\" * 55)\n    \n    print(\"\\nğŸ’¡ Analysez votre propre image avec GPT-5:\")\n    print(\"Formats supportÃ©s: URL https:// ou chemin local\")\n    print(\"(Laissez vide pour passer Ã  la suite)\")\n    \n    try:\n        user_image = input(\"\\nğŸ–¼ï¸  URL ou chemin de votre image: \").strip()\n        \n        if user_image:\n            # ParamÃ¨tres d'analyse personnalisÃ©s\n            print(\"\\nâš™ï¸  ParamÃ¨tres d'analyse (appuyez EntrÃ©e pour dÃ©faut):\")\n            custom_mode = input(f\"ğŸ“Š Mode [{analysis_mode}]: \").strip() or analysis_mode\n            custom_prompt = input(\"ğŸ“ Prompt personnalisÃ© (optionnel): \").strip()\n            \n            print(f\"\\nğŸ” Analyse de votre image en cours...\")\n            \n            # Analyse personnalisÃ©e\n            if custom_prompt:\n                user_result = analyze_image_with_gpt5(\n                    image_source=user_image,\n                    prompt=custom_prompt\n                )\n            else:\n                user_result = analyze_image_with_gpt5(\n                    image_source=user_image,\n                    analysis_type=custom_mode\n                )\n            \n            if user_result['success']:\n                print(f\"\\nğŸ‰ Analyse rÃ©ussie!\")\n                print(f\"â±ï¸  Temps: {user_result['metadata']['response_time']:.2f}s\")\n                print(f\"\\nğŸ“ **Analyse GPT-5:**\")\n                print(user_result['analysis'])\n                \n                # Option de sauvegarde\n                if export_analysis:\n                    save_choice = input(\"\\nğŸ’¾ Sauvegarder cette analyse ? (o/N): \").strip().lower()\n                    if save_choice in ['o', 'oui', 'y', 'yes']:\n                        output_dir = GENAI_ROOT / 'outputs' / 'gpt5_analysis'\n                        output_dir.mkdir(parents=True, exist_ok=True)\n                        \n                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n                        analysis_file = output_dir / f\"gpt5_analysis_{timestamp}.json\"\n                        \n                        with open(analysis_file, 'w', encoding='utf-8') as f:\n                            json.dump(user_result, f, indent=2, ensure_ascii=False)\n                        \n                        print(f\"ğŸ’¾ Analyse sauvegardÃ©e: {analysis_file}\")\n            else:\n                print(f\"\\nâŒ Erreur: {user_result['error']}\")\n                print(f\"ğŸ” Source: {user_result['image_source']}\")\n        else:\n            print(\"\\nâ­ï¸  Mode interactif ignorÃ©\")\n            \n    except (KeyboardInterrupt, EOFError):\n        print(\"\\nâ­ï¸  Mode interactif interrompu\")\nelse:\n    print(\"\\nğŸ¤– Mode batch - Interface interactive dÃ©sactivÃ©e\")\n    print(\"ğŸ’¡ Pour mode interactif: notebook_mode = 'interactive'\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Cas d'usage pÃ©dagogiques avec GPT-5\nprint(\"\\nğŸ“ CAS D'USAGE PÃ‰DAGOGIQUES GPT-5\")\nprint(\"=\" * 45)\n\n# Exemples d'applications Ã©ducatives\neducational_use_cases = {\n    \"Histoire\": {\n        \"description\": \"Analyse de documents historiques, Å“uvres d'art, monuments\",\n        \"exemple\": \"Analyser une fresque renaissance pour comprendre le contexte social\",\n        \"prompt_template\": \"Analyse cette image historique pour des Ã©tudiants en histoire. Explique le contexte historique, les Ã©lÃ©ments symboliques, et l'importance culturelle.\"\n    },\n    \n    \"Sciences\": {\n        \"description\": \"Analyse d'expÃ©riences, schÃ©mas scientifiques, phÃ©nomÃ¨nes naturels\",\n        \"exemple\": \"Expliquer un diagramme de cellule ou une rÃ©action chimique\",\n        \"prompt_template\": \"En tant qu'enseignant de sciences, explique cette image scientifique. Identifie les Ã©lÃ©ments techniques et leur fonctionnement.\"\n    },\n    \n    \"GÃ©ographie\": {\n        \"description\": \"Ã‰tude de paysages, cartes, phÃ©nomÃ¨nes gÃ©ologiques\",\n        \"exemple\": \"Analyser une photo satellite ou un paysage gÃ©ographique\",\n        \"prompt_template\": \"Analyse cette image gÃ©ographique pour des Ã©tudiants. Explique les formations gÃ©ologiques, le climat, et l'impact humain visible.\"\n    },\n    \n    \"Art et Culture\": {\n        \"description\": \"Critique artistique, analyse stylistique, histoire de l'art\",\n        \"exemple\": \"Comprendre les techniques d'un tableau impressionniste\",\n        \"prompt_template\": \"Fais une analyse artistique de cette Å“uvre pour des Ã©tudiants en art. Inclus style, techniques, et signification culturelle.\"\n    },\n    \n    \"MÃ©decine\": {\n        \"description\": \"Analyse d'imagerie mÃ©dicale, anatomie, cas cliniques\",\n        \"exemple\": \"Expliquer une radiographie ou un schÃ©ma anatomique\",\n        \"prompt_template\": \"Analyse cette image mÃ©dicale pour des Ã©tudiants en mÃ©decine. Explique l'anatomie visible et les points d'intÃ©rÃªt clinique.\"\n    }\n}\n\n# Affichage des cas d'usage\nfor domain, info in educational_use_cases.items():\n    print(f\"\\nğŸ“š **{domain}**\")\n    print(f\"   ğŸ“‹ {info['description']}\")\n    print(f\"   ğŸ’¡ Exemple: {info['exemple']}\")\n    print(f\"   ğŸ“ Template de prompt disponible\")\n\nprint(f\"\\nğŸ¯ Avantages GPT-5 pour l'Ã©ducation:\")\nprint(f\"â€¢ **Multimodal** : Analyse texte + image simultanÃ©e\")\nprint(f\"â€¢ **Contextuel** : Comprend le niveau Ã©ducatif\")\nprint(f\"â€¢ **Adaptable** : Ajuste le vocabulaire selon l'audience\")\nprint(f\"â€¢ **Interactif** : Permet les questions de suivi\")\nprint(f\"â€¢ **PrÃ©cis** : Analyse dÃ©taillÃ©e et factuelle\")\n\nprint(f\"\\nğŸ“ Exemple de workflow pÃ©dagogique:\")\nprint(f\"1. SÃ©lection d'image pertinente au cours\")\nprint(f\"2. Analyse GPT-5 avec prompt Ã©ducatif\")\nprint(f\"3. GÃ©nÃ©ration de questions pour les Ã©tudiants\")\nprint(f\"4. Discussion interactive basÃ©e sur l'analyse\")\nprint(f\"5. Ã‰valuation de la comprÃ©hension\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## ğŸ¯ RÃ©sumÃ© et Bonnes Pratiques\n\n### âœ… Ce que vous avez appris\n\n- [ ] **Configuration GPT-5** : OpenRouter API et paramÃ¨tres optimaux\n- [ ] **Analyse multimodale** : Combinaison texte + image\n- [ ] **Prompts Ã©ducatifs** : Adaptation au niveau d'enseignement\n- [ ] **Cas d'usage pÃ©dagogiques** : Applications concrÃ¨tes par domaine\n- [ ] **Optimisation** : ParamÃ¨tres de qualitÃ© et performance\n\n### ğŸš€ Prochaines Ã©tapes\n\n1. **ExpÃ©rimentez** avec vos propres images Ã©ducatives\n2. **Testez** diffÃ©rents niveaux d'analyse selon votre public\n3. **IntÃ©grez** GPT-5 dans vos workflows pÃ©dagogiques\n4. **Combinez** avec DALL-E 3 pour gÃ©nÃ©ration + analyse\n5. **Explorez** les notebooks avancÃ©s (Module 02)\n\n### ğŸ’¡ Conseils pour l'utilisation\n\n**âœ… Bonnes pratiques:**\n- Utilisez des images de haute qualitÃ©\n- Adaptez le prompt au niveau Ã©ducatif\n- Combinez analyse visuelle et contextuelle\n- GÃ©nÃ©rez des questions pÃ©dagogiques\n- Sauvegardez les analyses rÃ©ussies\n\n**âŒ Ã‰vitez:**\n- Images trop petites ou de mauvaise qualitÃ©\n- Prompts vagues ou gÃ©nÃ©riques\n- Oublier le contexte Ã©ducatif\n- Ignorer les limitations du modÃ¨le\n- Ne pas vÃ©rifier la factualitÃ©\n\n### ğŸ”— Ressources complÃ©mentaires\n\n- **Documentation OpenRouter** : [openrouter.ai](https://openrouter.ai)\n- **Guide GPT-5** : CapacitÃ©s multimodales\n- **Templates Ã©ducatifs** : `docs/genai-phase2-templates.md`\n- **Standards CoursIA** : `docs/genai-images-development-standards.md`",
      "metadata": {}
    }
  ]
}
