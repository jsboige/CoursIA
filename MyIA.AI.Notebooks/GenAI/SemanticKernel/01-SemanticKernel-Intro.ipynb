{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe765e5",
   "metadata": {
    "papermill": {
     "duration": 0.00299,
     "end_time": "2026-02-04T07:05:41.560989",
     "exception": false,
     "start_time": "2026-02-04T07:05:41.557999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SK-1-Fundamentals : Introduction a Semantic Kernel\n",
    "\n",
    "**Navigation** : [Index](README.md) | [02-Functions >>](02-SemanticKernel-Advanced.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs d'apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous saurez :\n",
    "1. Installer et configurer **Semantic Kernel** pour Python\n",
    "2. Comprendre le role du **Kernel** comme orchestrateur central\n",
    "3. Ajouter des **services LLM** (OpenAI, Azure, Hugging Face)\n",
    "4. Charger et utiliser des **plugins** (prompts templates)\n",
    "5. Creer des **fonctions semantiques inline**\n",
    "6. Gerer un **chat conversationnel** avec historique\n",
    "\n",
    "### Prerequis\n",
    "\n",
    "- Python 3.10+\n",
    "- Cle API OpenAI (ou Azure OpenAI)\n",
    "- Fichier `.env` configure\n",
    "\n",
    "### Duree estimee : 45 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Sommaire\n",
    "\n",
    "| Section | Contenu | Concepts cles |\n",
    "|---------|---------|---------------|\n",
    "| 1 | Installation | pip install semantic-kernel |\n",
    "| 2 | Configuration | .env, Kernel, Services |\n",
    "| 3 | Premier Kernel | Initialisation, service LLM |\n",
    "| 4 | Plugins | Chargement depuis fichiers |\n",
    "| 5 | Fonctions inline | Prompts dynamiques |\n",
    "| 6 | Chat | Historique, KernelArguments |\n",
    "\n",
    "> **Qu'est-ce que Semantic Kernel ?** Un SDK Microsoft open-source pour integrer des LLMs dans vos applications. Il orchestre les appels aux modeles, gere les plugins, et permet de creer des agents intelligents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f2073a",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "execution": {
     "iopub.execute_input": "2026-02-04T07:05:41.568177Z",
     "iopub.status.busy": "2026-02-04T07:05:41.567887Z",
     "iopub.status.idle": "2026-02-04T07:05:44.010618Z",
     "shell.execute_reply": "2026-02-04T07:05:44.009876Z"
    },
    "papermill": {
     "duration": 2.445918,
     "end_time": "2026-02-04T07:05:44.011144",
     "exception": false,
     "start_time": "2026-02-04T07:05:41.565226",
     "status": "completed"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.39.3)\n",
      "Requirement already satisfied: azure-ai-projects~=1.0.0b12 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.0.0)\n",
      "Requirement already satisfied: azure-ai-agents>=1.2.0b3 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.2.0b6)\n",
      "Requirement already satisfied: aiohttp~=3.8 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (3.13.3)\n",
      "Requirement already satisfied: cloudevents~=1.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.12.0)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (2.11.10)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (2.11.0)\n",
      "Requirement already satisfied: defusedxml~=0.7 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: azure-identity>=1.13 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.25.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (2.3.4)\n",
      "Requirement already satisfied: openai<2,>=1.98.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.109.1)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (0.19.5)\n",
      "Requirement already satisfied: websockets<16,>=13 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (15.0.1)\n",
      "Requirement already satisfied: aiortc>=1.9.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.14.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.39.1)\n",
      "Requirement already satisfied: prance<25.4.9,>=23.6.21 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (25.4.8.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.15.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (1.17.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (6.33.0)\n",
      "Requirement already satisfied: typing-extensions>=4.13 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from semantic-kernel) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.22.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (1.36.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (12.28.0)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from deprecation<3.0,>=2.0->cloudevents~=1.0->semantic-kernel) (25.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2~=3.1->semantic-kernel) (3.0.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (0.13.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2,>=1.98.0->semantic-kernel) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2,>=1.98.0->semantic-kernel) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2,>=1.98.0->semantic-kernel) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2,>=1.98.0->semantic-kernel) (0.16.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.25.1)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.8.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: parse in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug<3.1.2 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.27.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.3)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (2.32.5)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.12.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.60b1)\n",
      "Requirement already satisfied: chardet>=5.2 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.18.10 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (0.19.1)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic-settings~=2.0->semantic-kernel) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (2.5.0)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.10.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (0.10.2)\n",
      "Requirement already satisfied: av<17.0.0,>=14.0.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (16.1.0)\n",
      "Requirement already satisfied: cryptography>=44.0.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (46.0.3)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (1.8.0)\n",
      "Requirement already satisfied: pyee>=13.0.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (13.0.0)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (1.0.0)\n",
      "Requirement already satisfied: pyopenssl>=25.0.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (25.3.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel) (2.8.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel) (0.2.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from azure-identity>=1.13->semantic-kernel) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from azure-identity>=1.13->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cryptography>=44.0.0->aiortc>=1.9.0->semantic-kernel) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=2.0.0->cryptography>=44.0.0->aiortc>=1.9.0->semantic-kernel) (2.23)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity>=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai<2,>=1.98.0->semantic-kernel) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rfc3339-validator->openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\jsboi\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Kernel version : 1.39.3\n"
     ]
    }
   ],
   "source": [
    "# Installation de Semantic Kernel (si n√©cessaire)\n",
    "%pip install semantic-kernel\n",
    "\n",
    "# V√©rification de la version install√©e\n",
    "from semantic_kernel import __version__\n",
    "print(f\"Semantic Kernel version : {__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40a140",
   "metadata": {
    "papermill": {
     "duration": 0.002042,
     "end_time": "2026-02-04T07:05:44.015502",
     "exception": false,
     "start_time": "2026-02-04T07:05:44.013460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### üìå **Importation des biblioth√®ques n√©cessaires**\n",
    "Dans cette cellule, nous allons importer les modules principaux.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df070673",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "execution": {
     "iopub.execute_input": "2026-02-04T07:05:44.020216Z",
     "iopub.status.busy": "2026-02-04T07:05:44.019953Z",
     "iopub.status.idle": "2026-02-04T07:06:16.364812Z",
     "shell.execute_reply": "2026-02-04T07:06:16.364153Z"
    },
    "papermill": {
     "duration": 32.348075,
     "end_time": "2026-02-04T07:06:16.365413",
     "exception": false,
     "start_time": "2026-02-04T07:05:44.017338",
     "status": "completed"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import KernelArguments  # Correction de l'import\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7549dc0",
   "metadata": {
    "papermill": {
     "duration": 0.002031,
     "end_time": "2026-02-04T07:06:16.369755",
     "exception": false,
     "start_time": "2026-02-04T07:06:16.367724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **üìÅ 2. Chargement des param√®tres de configuration**\n",
    "### üìå **Lecture des param√®tres depuis un fichier `.env` ou JSON**\n",
    "Le fichier de configuration `.env` doit contenir les cl√©s n√©cessaires pour acc√©der aux services OpenAI/Azure OpenAI.\n",
    "\n",
    "üí° **V√©rifiez que vous avez bien cr√©√© un fichier `.env`** dans le m√™me dossier que ce notebook avec ces valeurs :\n",
    "\n",
    "```plaintext\n",
    "GLOBAL_LLM_SERVICE=\"OpenAI\"\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_CHAT_MODEL_ID=\"gpt-4o-mini\"\n",
    "```\n",
    "\n",
    "üëâ Nous allons maintenant **charger ces param√®tres en Python** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132601a1",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "execution": {
     "iopub.execute_input": "2026-02-04T07:06:16.374726Z",
     "iopub.status.busy": "2026-02-04T07:06:16.374471Z",
     "iopub.status.idle": "2026-02-04T07:06:16.379101Z",
     "shell.execute_reply": "2026-02-04T07:06:16.378613Z"
    },
    "papermill": {
     "duration": 0.008035,
     "end_time": "2026-02-04T07:06:16.379617",
     "exception": false,
     "start_time": "2026-02-04T07:06:16.371582",
     "status": "completed"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service s√©lectionn√© : OpenAI\n",
      "Mod√®le utilis√© : gpt-4o\n"
     ]
    }
   ],
   "source": [
    "# Chargement du fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# R√©cup√©ration des cl√©s API et du mod√®le\n",
    "llm_service = os.getenv(\"GLOBAL_LLM_SERVICE\", \"OpenAI\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_id = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-4o-mini\")\n",
    "\n",
    "# V√©rification\n",
    "print(f\"Service s√©lectionn√© : {llm_service}\")\n",
    "print(f\"Mod√®le utilis√© : {model_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "788431b1",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "execution": {
     "iopub.execute_input": "2026-02-04T07:06:16.384476Z",
     "iopub.status.busy": "2026-02-04T07:06:16.384236Z",
     "iopub.status.idle": "2026-02-04T07:06:16.386871Z",
     "shell.execute_reply": "2026-02-04T07:06:16.386367Z"
    },
    "papermill": {
     "duration": 0.005722,
     "end_time": "2026-02-04T07:06:16.387331",
     "exception": false,
     "start_time": "2026-02-04T07:06:16.381609",
     "status": "completed"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel initialis√© avec succ√®s.\n"
     ]
    }
   ],
   "source": [
    "# Importer le Kernel depuis Semantic Kernel\n",
    "from semantic_kernel import Kernel\n",
    "\n",
    "# Cr√©er une instance du Kernel\n",
    "kernel = Kernel()\n",
    "print(\"Kernel initialis√© avec succ√®s.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92121b71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:06:16.392849Z",
     "iopub.status.busy": "2026-02-04T07:06:16.392668Z",
     "iopub.status.idle": "2026-02-04T07:06:17.454793Z",
     "shell.execute_reply": "2026-02-04T07:06:17.454136Z"
    },
    "papermill": {
     "duration": 1.065583,
     "end_time": "2026-02-04T07:06:17.455436",
     "exception": false,
     "start_time": "2026-02-04T07:06:16.389853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de l'URL par d√©faut : https://api.openai.com/v1\n",
      "Utilisation du mod√®le : gpt-4o\n",
      "Cl√© API utilis√©e : Oui\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion r√©ussie !\n",
      "R√©ponse : Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# R√©cup√®re la valeur du .env et nettoie les espaces\n",
    "base_url_from_env = os.getenv(\"OPENAI_BASE_URL\", \"\").strip()\n",
    "\n",
    "# D√©termine explicitement l'URL finale\n",
    "if base_url_from_env:\n",
    "    final_base_url = base_url_from_env\n",
    "    print(f\"Utilisation de l'URL du .env : {final_base_url}\")\n",
    "else:\n",
    "    final_base_url = \"https://api.openai.com/v1\" # <<< URL par d√©faut explicite\n",
    "    print(f\"Utilisation de l'URL par d√©faut : {final_base_url}\")\n",
    "\n",
    "model_id = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-4o-mini\")\n",
    "print(f\"Utilisation du mod√®le : {model_id}\")\n",
    "print(f\"Cl√© API utilis√©e : {'Oui' if api_key else 'Non'}\")\n",
    "\n",
    "async def test_connection():\n",
    "    try:\n",
    "        if not api_key:\n",
    "            print(\"ERREUR : Cl√© API non d√©finie.\")\n",
    "            return\n",
    "\n",
    "        # Utilise final_base_url d√©termin√© ci-dessus\n",
    "        client = AsyncOpenAI(api_key=api_key, base_url=final_base_url)\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model_id,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Say hello!\"}],\n",
    "            max_tokens=10,\n",
    "            timeout=20\n",
    "        )\n",
    "        print(\"Connexion r√©ussie !\")\n",
    "        print(\"R√©ponse :\", response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR lors du test de connexion : {type(e).__name__} - {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Ex√©cuter le test\n",
    "await test_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81395a",
   "metadata": {
    "papermill": {
     "duration": 0.002543,
     "end_time": "2026-02-04T07:06:17.460724",
     "exception": false,
     "start_time": "2026-02-04T07:06:17.458181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration du service LLM\n",
    "\n",
    "Nous devons connecter notre Kernel √† un service de Chat Completion.  \n",
    "Pour cet exemple, nous allons utiliser OpenAI. Si vous pr√©f√©rez Azure OpenAI, adaptez le code en cons√©quence (voir la documentation).\n",
    "\n",
    "La configuration se fait via l'ajout d'un service au Kernel.  \n",
    "Assurez-vous que votre fichier `.env` contient votre cl√© API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799cc66f",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "execution": {
     "iopub.execute_input": "2026-02-04T07:06:17.466475Z",
     "iopub.status.busy": "2026-02-04T07:06:17.466191Z",
     "iopub.status.idle": "2026-02-04T07:06:17.674372Z",
     "shell.execute_reply": "2026-02-04T07:06:17.673685Z"
    },
    "papermill": {
     "duration": 0.211499,
     "end_time": "2026-02-04T07:06:17.674924",
     "exception": false,
     "start_time": "2026-02-04T07:06:17.463425",
     "status": "completed"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service OpenAI ajout√© au Kernel.\n"
     ]
    }
   ],
   "source": [
    "# Importation du service OpenAI pour le Chat Completion\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "# Ajout du service \"default\" au Kernel\n",
    "kernel.add_service(OpenAIChatCompletion(service_id=\"default\"))\n",
    "print(\"Service OpenAI ajout√© au Kernel.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932eec0b",
   "metadata": {
    "papermill": {
     "duration": 0.002232,
     "end_time": "2026-02-04T07:06:17.679729",
     "exception": false,
     "start_time": "2026-02-04T07:06:17.677497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Architecture du Kernel\n",
    "\n",
    "Le Kernel est le **coeur** de Semantic Kernel. Il orchestre :\n",
    "\n",
    "| Composant | Role | Exemple |\n",
    "|-----------|------|---------|\n",
    "| **Services** | Connexions aux LLMs | OpenAIChatCompletion, AzureChatCompletion |\n",
    "| **Plugins** | Collections de fonctions | FunPlugin, WriterPlugin |\n",
    "| **Fonctions** | Unites d'execution | Joke, Summarize, Chat |\n",
    "| **Arguments** | Parametres dynamiques | KernelArguments(input=...) |\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                 Kernel                  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ  Services   ‚îÇ  ‚îÇ    Plugins      ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  (LLMs)     ‚îÇ  ‚îÇ  (Functions)    ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ           ‚Üì              ‚Üì              ‚îÇ\n",
    "‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
    "‚îÇ       ‚îÇ     invoke(func, args)  ‚îÇ      ‚îÇ\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "> **Service ID** : Chaque service a un identifiant unique. \"default\" est utilise si non specifie lors de l'invocation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ea841",
   "metadata": {
    "papermill": {
     "duration": 0.001938,
     "end_time": "2026-02-04T07:06:17.684046",
     "exception": false,
     "start_time": "2026-02-04T07:06:17.682108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utiliser un Plugin de Prompt\n",
    "\n",
    "Semantic Kernel permet de charger des **prompt plugins** stock√©s sur disque.  \n",
    "Dans cet exemple, nous chargerons le plugin \"FunPlugin\" qui contient, par exemple, une fonction pour g√©n√©rer une blague.\n",
    "\n",
    "Les fichiers du plugin (le prompt et sa configuration) sont stock√©s dans le r√©pertoire `prompt_template_samples/`.  \n",
    "Nous allons charger ce plugin et invoquer la fonction \"Joke\" pour g√©n√©rer une blague sur un sujet donn√©.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7302508",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "execution": {
     "iopub.execute_input": "2026-02-04T07:06:17.689439Z",
     "iopub.status.busy": "2026-02-04T07:06:17.689140Z",
     "iopub.status.idle": "2026-02-04T07:06:20.209203Z",
     "shell.execute_reply": "2026-02-04T07:06:20.208527Z"
    },
    "papermill": {
     "duration": 2.523676,
     "end_time": "2026-02-04T07:06:20.209825",
     "exception": false,
     "start_time": "2026-02-04T07:06:17.686149",
     "status": "completed"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plugin charg√© avec succ√®s.\n",
      "metadata=KernelFunctionMetadata(name='Joke', plugin_name='FunPlugin', description='Generate a funny joke', parameters=[KernelParameterMetadata(name='input', description='Joke subject', default_value='', type_='', is_required=True, type_object=None, schema_data={'type': 'object', 'description': 'Joke subject'}, include_in_function_choices=True), KernelParameterMetadata(name='style', description='Give a hint about the desired joke style', default_value='', type_='', is_required=True, type_object=None, schema_data={'type': 'object', 'description': 'Give a hint about the desired joke style'}, include_in_function_choices=True)], is_prompt=True, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='The completion result', default_value=None, type_='FunctionResult', is_required=True, type_object=None, schema_data=None, include_in_function_choices=True), additional_properties=None) invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x0000023753D6A710> streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x0000023753A9A3F0> prompt_template=KernelPromptTemplate(prompt_template_config=PromptTemplateConfig(name='Joke', description='Generate a funny joke', template=\"WRITE EXACTLY ONE JOKE or HUMOROUS STORY ABOUT THE TOPIC BELOW\\n\\nJOKE MUST BE:\\n- G RATED\\n- WORKPLACE/FAMILY SAFE\\nNO SEXISM, RACISM OR OTHER BIAS/BIGOTRY\\nAVOID Daddy's jokes and puns, be funny, be deep, provocative, for real !\\n\\nBE CREATIVE AND FUNNY. I WANT TO LAUGH.\\nIncorporate the style suggestion, if provided: {{$style}}\\n+++++\\n\\n{{$input}}\\n+++++\\n\", template_format='semantic-kernel', input_variables=[InputVariable(name='input', description='Joke subject', default='', is_required=True, json_schema='', allow_dangerously_set_content=False), InputVariable(name='style', description='Give a hint about the desired joke style', default='', is_required=True, json_schema='', allow_dangerously_set_content=False)], allow_dangerously_set_content=False, execution_settings={'default': PromptExecutionSettings(service_id=None, extension_data={'max_tokens': 1000, 'temperature': 0.9, 'top_p': 0.0, 'presence_penalty': 0.0, 'frequency_penalty': 0.0}, function_choice_behavior=None)}), allow_dangerously_set_content=False) prompt_execution_settings={'default': PromptExecutionSettings(service_id=None, extension_data={'max_tokens': 1000, 'temperature': 0.9, 'top_p': 0.0, 'presence_penalty': 0.0, 'frequency_penalty': 0.0}, function_choice_behavior=None)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blague g√©n√©r√©e : Why did the time traveler bring a suitcase full of sandwiches to the dinosaur age?\n",
      "\n",
      "Because he heard the T-Rex had a \"roaring\" appetite, and he didn't want to be the main course! So, he figured he'd distract it with a prehistoric picnic. But when he got there, the T-Rex just looked at the sandwiches, then at him, and said, \"I‚Äôm on a paleo diet, but thanks for the offer!\"\n"
     ]
    }
   ],
   "source": [
    "# Chemin correct vers les plugins\n",
    "plugins_directory = \"./prompt_template_samples/\"\n",
    "\n",
    "# V√©rifier si le dossier du plugin existe avant de charger\n",
    "if os.path.exists(os.path.join(plugins_directory, \"FunPlugin\")):\n",
    "    fun_plugin = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"FunPlugin\")\n",
    "    joke_function = fun_plugin[\"Joke\"]\n",
    "    print(\"Plugin charg√© avec succ√®s.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Le plugin FunPlugin est introuvable. V√©rifiez le chemin et assurez-vous qu'il est bien pr√©sent.\")\n",
    "\n",
    "\n",
    "# Invoquer la fonction pour g√©n√©rer une blague sur un th√®me donn√©\n",
    "# Pour ce faire, nous utilisons des KernelArguments (ici, seul l'input est n√©cessaire)\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "print(joke_function)\n",
    "\n",
    "# Exemple : g√©n√©rer une blague sur \"time travel to dinosaur age\" avec un style \"super silly\"\n",
    "joke_response = await kernel.invoke(joke_function, KernelArguments(input=\"time travel to dinosaur age\", style=\"super silly\"))\n",
    "print(\"Blague g√©n√©r√©e :\", joke_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2509cdf0",
   "metadata": {
    "papermill": {
     "duration": 0.00571,
     "end_time": "2026-02-04T07:06:20.218430",
     "exception": false,
     "start_time": "2026-02-04T07:06:20.212720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## D√©finir une fonction s√©mantique en ligne\n",
    "\n",
    "Outre l'utilisation de plugins stock√©s sur disque, il est possible de d√©finir des fonctions s√©mantiques directement dans votre code Python.  \n",
    "Cette approche est particuli√®rement utile pour :\n",
    "- G√©n√©rer dynamiquement des prompts en fonction du contexte\n",
    "- Prototyper rapidement des id√©es sans cr√©er de fichiers s√©par√©s\n",
    "\n",
    "Dans cet exemple, nous allons cr√©er une fonction qui r√©sume un texte donn√© en quelques mots (TL;DR).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb5042b",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "execution": {
     "iopub.execute_input": "2026-02-04T07:06:20.223863Z",
     "iopub.status.busy": "2026-02-04T07:06:20.223686Z",
     "iopub.status.idle": "2026-02-04T07:06:20.805229Z",
     "shell.execute_reply": "2026-02-04T07:06:20.804485Z"
    },
    "papermill": {
     "duration": 0.585144,
     "end_time": "2026-02-04T07:06:20.805929",
     "exception": false,
     "start_time": "2026-02-04T07:06:20.220785",
     "status": "completed"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©sum√© (TL;DR) : Po√©tesse grecque, unique po√®me grav√©.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "\n",
    "# D√©finition du prompt\n",
    "tldr_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Donne-moi un r√©sum√© en 5 mots ou moins.\n",
    "\"\"\"\n",
    "\n",
    "# Configuration de l'ex√©cution\n",
    "execution_settings = OpenAIChatPromptExecutionSettings(\n",
    "    service_id=\"default\",\n",
    "    ai_model_id=model_id,\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Configuration du prompt template\n",
    "tldr_template_config = PromptTemplateConfig(\n",
    "    template=tldr_prompt,\n",
    "    name=\"tldr\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[InputVariable(name=\"input\", description=\"Texte √† r√©sumer\", is_required=True)],\n",
    "    execution_settings=execution_settings,\n",
    ")\n",
    "\n",
    "# Ajout de la fonction au Kernel\n",
    "tldr_function = kernel.add_function(function_name=\"tldrFunction\", plugin_name=\"tldrPlugin\", prompt_template_config=tldr_template_config)\n",
    "\n",
    "# Ex√©cution de la fonction\n",
    "async def run_tldr():\n",
    "    input_text = \"Demo √©tait une po√©tesse grecque ancienne connue pour un unique po√®me grav√© sur le Colosse de Memnon.\"\n",
    "    tldr_summary = await kernel.invoke(tldr_function, KernelArguments(input=input_text))\n",
    "    print(\"R√©sum√© (TL;DR) :\", tldr_summary)\n",
    "\n",
    "# Lancer la fonction\n",
    "await run_tldr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324147e2",
   "metadata": {
    "papermill": {
     "duration": 0.002558,
     "end_time": "2026-02-04T07:06:20.811221",
     "exception": false,
     "start_time": "2026-02-04T07:06:20.808663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Chat interactif avec le Kernel\n",
    "\n",
    "Semantic Kernel offre √©galement la possibilit√© de cr√©er des interactions de type chatbot.  \n",
    "Nous allons configurer une fonction de chat qui utilise des **Kernel Arguments** pour conserver l'historique de la conversation.\n",
    "\n",
    "L'objectif est de simuler une conversation o√π l'utilisateur envoie un message, le bot y r√©pond, et l'historique est mis √† jour √† chaque √©change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3f6f22",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "execution": {
     "iopub.execute_input": "2026-02-04T07:06:20.816260Z",
     "iopub.status.busy": "2026-02-04T07:06:20.816092Z",
     "iopub.status.idle": "2026-02-04T07:06:33.940030Z",
     "shell.execute_reply": "2026-02-04T07:06:33.939487Z"
    },
    "papermill": {
     "duration": 13.127312,
     "end_time": "2026-02-04T07:06:33.940636",
     "exception": false,
     "start_time": "2026-02-04T07:06:20.813324",
     "status": "completed"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisateur : Salut, je cherche des suggestions de livres sur la philosophie antique.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot : Salut ! La philosophie antique est un domaine fascinant, et il y a plusieurs ouvrages qui pourraient t'int√©resser :\n",
      "\n",
      "1. **\"La R√©publique\" de Platon** - Un dialogue sur la justice, la politique et l'organisation de la soci√©t√©. C'est l'une des ≈ìuvres les plus c√©l√®bres de Platon.\n",
      "\n",
      "2. **\"√âthique √† Nicomaque\" d'Aristote** - Un trait√© sur la vertu et le chemin vers une vie √©thique et √©panouie.\n",
      "\n",
      "3. **\"Les M√©ditations\" de Marc Aur√®le** - Des r√©flexions personnelles de l'empereur romain sto√Øque, offrant des conseils sur la r√©silience et la sagesse.\n",
      "\n",
      "4. **\"Enn√©ades\" de Plotin** - Une collection de six groupes de neuf trait√©s qui explore la m√©taphysique, l'√©thique et la th√©ologie.\n",
      "\n",
      "5. **\"Les Pens√©es\" d'√âpict√®te** (souvent publi√©es sous le titre \"Manuel d'√âpict√®te\") - Un guide pratique pour mener une vie sto√Øque.\n",
      "\n",
      "6. **\"Les Discours\" de Plutarque** - Bien que Plutarque soit plus connu pour ses \"Vies parall√®les\", ses essais philosophiques sont √©galement tr√®s influents.\n",
      "\n",
      "Chacun de ces livres offre une perspective unique sur la philosophie antique et peut enrichir ta compr√©hension de la pens√©e classique. Bonne lecture !\n",
      "Utilisateur : Peux-tu m'en recommander quelques-uns ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot : Bien s√ªr ! Voici quelques recommandations suppl√©mentaires sur la philosophie antique qui pourraient t'int√©resser :\n",
      "\n",
      "1. **\"Le Banquet\" de Platon** - Un dialogue centr√© sur le th√®me de l'amour, o√π diff√©rents personnages discutent de sa nature et de son r√¥le dans la vie humaine.\n",
      "\n",
      "2. **\"Penseurs grecs avant Socrate\" de G.S. Kirk, J.E. Raven et M. Schofield** - Un recueil qui explore les id√©es des premiers philosophes grecs, souvent appel√©s les pr√©socratiques.\n",
      "\n",
      "3. **\"Les Sto√Øciens\" de Pierre Hadot** - Une introduction accessible √† la philosophie sto√Øque, mettant en lumi√®re ses concepts cl√©s et son influence durable.\n",
      "\n",
      "4. **\"Les Lettres √† Lucilius\" de S√©n√®que** - Une s√©rie de lettres philosophiques qui abordent divers sujets, allant de l'√©thique personnelle √† la gestion des √©motions.\n",
      "\n",
      "5. **\"Le Ph√©don\" de Platon** - Un dialogue qui traite de l'√¢me et de l'immortalit√©, racontant les derniers moments de Socrate avant sa mort.\n",
      "\n",
      "6. **\"Fragments\" d'H√©raclite** - Bien que peu de ses √©crits aient surv√©cu, les fragments d'H√©raclite offrent un aper√ßu fascinant de sa vision du monde et de la nature du changement.\n",
      "\n",
      "Ces livres peuvent t'offrir une perspective plus large sur la philosophie antique et enrichir ta compr√©hension des id√©es qui ont fa√ßonn√© la pens√©e occidentale. Bonne lecture !\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "# Initialiser l'historique\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_system_message(\"Vous √™tes un chatbot utile et vous fournissez des recommandations de livres.\")\n",
    "\n",
    "# D√©finition du prompt de chat\n",
    "chat_prompt = \"\"\"\n",
    "{{$history}}\n",
    "User: {{$user_input}}\n",
    "ChatBot:\n",
    "\"\"\"\n",
    "\n",
    "# Configuration de l'ex√©cution\n",
    "chat_exec_settings = OpenAIChatPromptExecutionSettings(\n",
    "    service_id=\"default\",\n",
    "    ai_model_id=model_id,\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Configuration du chat template\n",
    "chat_template_config = PromptTemplateConfig(\n",
    "    template=chat_prompt,\n",
    "    name=\"chat\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"user_input\", description=\"Message de l'utilisateur\", is_required=True),\n",
    "        InputVariable(name=\"history\", description=\"Historique de la conversation\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=chat_exec_settings,\n",
    ")\n",
    "\n",
    "# Ajout au Kernel\n",
    "chat_function = kernel.add_function(function_name=\"chat\", plugin_name=\"chatPlugin\", prompt_template_config=chat_template_config)\n",
    "\n",
    "# Fonction asynchrone pour le chat\n",
    "async def chat(input_text: str):\n",
    "    print(f\"Utilisateur : {input_text}\")\n",
    "    response = await kernel.invoke(chat_function, KernelArguments(\n",
    "        user_input=input_text, \n",
    "        history=str(chat_history),\n",
    "        allow_dangerously_set_content=True\n",
    "    ))\n",
    "    print(f\"ChatBot : {response}\")\n",
    "    chat_history.add_user_message(input_text)\n",
    "    chat_history.add_assistant_message(str(response))\n",
    "\n",
    "# Ex√©cution des exemples\n",
    "await chat(\"Salut, je cherche des suggestions de livres sur la philosophie antique.\")\n",
    "await chat(\"Peux-tu m'en recommander quelques-uns ?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760d187",
   "metadata": {
    "papermill": {
     "duration": 0.003676,
     "end_time": "2026-02-04T07:06:33.946980",
     "exception": false,
     "start_time": "2026-02-04T07:06:33.943304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "## Resume des concepts\n",
    "\n",
    "| Concept | Description | Code cle |\n",
    "|---------|-------------|----------|\n",
    "| **Kernel** | Orchestrateur central SK | `Kernel()` |\n",
    "| **Service** | Connexion LLM | `kernel.add_service(OpenAIChatCompletion(...))` |\n",
    "| **Plugin** | Collection de fonctions | `kernel.add_plugin(parent_directory=..., plugin_name=...)` |\n",
    "| **Fonction semantique** | Prompt template execute | `kernel.add_function(prompt_template_config=...)` |\n",
    "| **KernelArguments** | Parametres dynamiques | `KernelArguments(input=..., style=...)` |\n",
    "| **ChatHistory** | Historique conversation | `ChatHistory()` + `add_user_message()` |\n",
    "\n",
    "## Points cles a retenir\n",
    "\n",
    "1. **Le Kernel est le coeur de SK** - Il orchestre services, plugins et fonctions\n",
    "2. **Les plugins sont modulaires** - Chargeables depuis fichiers ou definis inline\n",
    "3. **KernelArguments permet le passage dynamique** - Variables injectees dans les templates\n",
    "4. **ChatHistory preserve le contexte** - Essentiel pour les conversations multi-tours\n",
    "\n",
    "## Pour aller plus loin\n",
    "\n",
    "| Notebook suivant | Contenu |\n",
    "|-----------------|---------|\n",
    "| [02-Functions](02-SemanticKernel-Advanced.ipynb) | Function Calling moderne, Memory, Groundedness |\n",
    "| [03-Agents](03-SemanticKernel-Agents.ipynb) | ChatCompletionAgent, AgentGroupChat |\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation** : [Index](README.md) | [02-Functions >>](02-SemanticKernel-Advanced.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 54.465151,
   "end_time": "2026-02-04T07:06:34.296336",
   "environment_variables": {},
   "exception": null,
   "input_path": "01-SemanticKernel-Intro.ipynb",
   "output_path": "01-SemanticKernel-Intro.ipynb",
   "parameters": {},
   "start_time": "2026-02-04T07:05:39.831185",
   "version": "2.6.0"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}