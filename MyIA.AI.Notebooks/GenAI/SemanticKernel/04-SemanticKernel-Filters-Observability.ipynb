{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d2d9ae",
   "metadata": {
    "papermill": {
     "duration": 0.002455,
     "end_time": "2026-02-04T07:07:51.561344",
     "exception": false,
     "start_time": "2026-02-04T07:07:51.558889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SK-4-Filters : Filtres et Observabilite\n",
    "\n",
    "**Navigation** : [<< 03-Agents](03-SemanticKernel-Agents.ipynb) | [Index](README.md) | [05-VectorStores >>](05-SemanticKernel-VectorStores.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs d'apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous saurez :\n",
    "1. Intercepter les appels de **fonctions** avec des filtres\n",
    "2. Modifier les **prompts** avant envoi au LLM\n",
    "3. Controler le **Function Calling automatique**\n",
    "4. Configurer le **logging** pour le debugging\n",
    "5. Comprendre l'integration **OpenTelemetry** pour le monitoring\n",
    "\n",
    "### Prerequis\n",
    "\n",
    "- Python 3.10+\n",
    "- Notebooks 01-03 completes\n",
    "- Cle API OpenAI configuree (`.env`)\n",
    "\n",
    "### Duree estimee : 45 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Sommaire\n",
    "\n",
    "| Section | Contenu | Concepts cles |\n",
    "|---------|---------|---------------|\n",
    "| 1 | Introduction | Pourquoi les filtres ? |\n",
    "| 2 | Function Filters | Avant/apres invocation |\n",
    "| 3 | Prompt Filters | Modification du prompt |\n",
    "| 4 | Auto-Invoke Filters | Controle du function calling |\n",
    "| 5 | Logging | Configuration, niveaux |\n",
    "| 6 | OpenTelemetry | Tracing, metriques |\n",
    "| 7 | Conclusion | Resume, exercices |\n",
    "\n",
    "> **Pourquoi les filtres ?** Les filtres permettent d'intercepter et modifier les appels a tous les niveaux de SK : avant/apres les fonctions, avant/apres les prompts, et lors du function calling automatique. C'est essentiel pour le logging, la securite, et le monitoring en production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0002df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:51.566112Z",
     "iopub.status.busy": "2026-02-04T07:07:51.565908Z",
     "iopub.status.idle": "2026-02-04T07:07:53.977212Z",
     "shell.execute_reply": "2026-02-04T07:07:53.976554Z"
    },
    "papermill": {
     "duration": 2.414439,
     "end_time": "2026-02-04T07:07:53.977759",
     "exception": false,
     "start_time": "2026-02-04T07:07:51.563320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\jsboi\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: API Key OK\n",
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "# Installation et imports\n",
    "%pip install semantic-kernel python-dotenv --quiet\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function, KernelArguments\n",
    "from semantic_kernel.filters import FilterTypes\n",
    "from semantic_kernel.exceptions import KernelInvokeException\n",
    "\n",
    "# Chargement du fichier .env (cles API)\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"Configuration: API Key {'OK' if api_key else 'MANQUANTE'}\")\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763cbc4",
   "metadata": {
    "papermill": {
     "duration": 0.001696,
     "end_time": "2026-02-04T07:07:53.981559",
     "exception": false,
     "start_time": "2026-02-04T07:07:53.979863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Introduction aux Filtres\n",
    "\n",
    "Semantic Kernel propose un systeme de filtres inspire des middlewares web :\n",
    "\n",
    "| Type de Filtre | Point d'interception | Cas d'usage |\n",
    "|----------------|---------------------|-------------|\n",
    "| **Function Invocation** | Avant/apres chaque fonction | Logging, validation, timing |\n",
    "| **Prompt Rendering** | Avant envoi au LLM | Injection de regles, anonymisation |\n",
    "| **Auto Function Invocation** | Lors du function calling | Rate limiting, approbation |\n",
    "\n",
    "### Architecture des filtres\n",
    "\n",
    "```\n",
    "User Request\n",
    "    |\n",
    "    v\n",
    "[Prompt Filter] --> Modifie le prompt\n",
    "    |\n",
    "    v\n",
    "LLM Call\n",
    "    |\n",
    "    v\n",
    "[Auto-Invoke Filter] --> Controle les appels de fonction\n",
    "    |\n",
    "    v\n",
    "[Function Filter] --> Avant/apres chaque fonction\n",
    "    |\n",
    "    v\n",
    "Response\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59627e0",
   "metadata": {
    "papermill": {
     "duration": 0.001671,
     "end_time": "2026-02-04T07:07:53.984835",
     "exception": false,
     "start_time": "2026-02-04T07:07:53.983164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Function Invocation Filters\n",
    "\n",
    "Les filtres de fonction permettent d'intercepter chaque appel de fonction du kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f249b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:53.989100Z",
     "iopub.status.busy": "2026-02-04T07:07:53.988686Z",
     "iopub.status.idle": "2026-02-04T07:07:54.225739Z",
     "shell.execute_reply": "2026-02-04T07:07:54.225059Z"
    },
    "papermill": {
     "duration": 0.239876,
     "end_time": "2026-02-04T07:07:54.226247",
     "exception": false,
     "start_time": "2026-02-04T07:07:53.986371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AVANT] Appel de math.add\n",
      "  Arguments: {'a': 5, 'b': 3}\n",
      "[APRES] math.add termine en 0.0001s\n",
      "  Resultat: 8\n",
      "\n",
      "Resultat final: 8\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.filters.functions.function_invocation_context import FunctionInvocationContext\n",
    "from typing import Callable, Coroutine, Any\n",
    "import time\n",
    "\n",
    "# Creation du kernel\n",
    "kernel = Kernel()\n",
    "kernel.add_service(OpenAIChatCompletion(service_id=\"default\"))\n",
    "\n",
    "# Plugin de demonstration\n",
    "class MathPlugin:\n",
    "    @kernel_function(description=\"Additionne deux nombres\")\n",
    "    def add(self, a: int, b: int) -> int:\n",
    "        return a + b\n",
    "    \n",
    "    @kernel_function(description=\"Multiplie deux nombres\")\n",
    "    def multiply(self, a: int, b: int) -> int:\n",
    "        return a * b\n",
    "\n",
    "kernel.add_plugin(MathPlugin(), plugin_name=\"math\")\n",
    "\n",
    "# Filtre de logging avec timing\n",
    "@kernel.filter(FilterTypes.FUNCTION_INVOCATION)\n",
    "async def logging_filter(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Coroutine[Any, Any, None]]\n",
    "):\n",
    "    \"\"\"Filtre qui log les appels de fonction avec leur duree.\"\"\"\n",
    "    func_name = f\"{context.function.plugin_name}.{context.function.name}\"\n",
    "    print(f\"[AVANT] Appel de {func_name}\")\n",
    "    print(f\"  Arguments: {context.arguments}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Appel de la fonction (ou du filtre suivant)\n",
    "    await next(context)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    print(f\"[APRES] {func_name} termine en {duration:.4f}s\")\n",
    "    print(f\"  Resultat: {context.result}\")\n",
    "\n",
    "# Test du filtre\n",
    "result = await kernel.invoke(kernel.get_function(\"math\", \"add\"), KernelArguments(a=5, b=3))\n",
    "print(f\"\\nResultat final: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410b33d",
   "metadata": {
    "papermill": {
     "duration": 0.001656,
     "end_time": "2026-02-04T07:07:54.229697",
     "exception": false,
     "start_time": "2026-02-04T07:07:54.228041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Function Invocation Filter\n",
    "\n",
    "Le filtre ci-dessus illustre le pattern **middleware** :\n",
    "\n",
    "1. **Avant l'appel** : On log le nom de la fonction et ses arguments\n",
    "2. **`await next(context)`** : On execute la fonction (ou le filtre suivant)\n",
    "3. **Apres l'appel** : On log le resultat et la duree\n",
    "\n",
    "**Points cles** :\n",
    "- `context.function` : Metadata de la fonction (nom, plugin, description)\n",
    "- `context.arguments` : Arguments passes a la fonction\n",
    "- `context.result` : Resultat apres execution\n",
    "- `next(context)` : Appelle le filtre suivant ou la fonction elle-meme\n",
    "\n",
    "> **Attention** : Oublier `await next(context)` bloquera l'execution de la fonction !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ca421d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:54.234043Z",
     "iopub.status.busy": "2026-02-04T07:07:54.233825Z",
     "iopub.status.idle": "2026-02-04T07:07:54.239616Z",
     "shell.execute_reply": "2026-02-04T07:07:54.239019Z"
    },
    "papermill": {
     "duration": 0.008802,
     "end_time": "2026-02-04T07:07:54.240027",
     "exception": false,
     "start_time": "2026-02-04T07:07:54.231225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function failed. Error: Les nombres negatifs ne sont pas autorises: a=-3, b=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Something went wrong in function invocation. During function invocation: 'math-multiply'. Error description: 'Les nombres negatifs ne sont pas autorises: a=-3, b=5'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AVANT] Appel de math.multiply\n",
      "  Arguments: {'a': 4, 'b': 5}\n",
      "[APRES] math.multiply termine en 0.0000s\n",
      "  Resultat: 20\n",
      "Resultat: 20\n",
      "[AVANT] Appel de math.multiply\n",
      "  Arguments: {'a': -3, 'b': 5}\n",
      "Erreur de validation (KernelInvokeException): nombres negatifs bloques\n"
     ]
    }
   ],
   "source": [
    "# Exemple de filtre de validation\n",
    "@kernel.filter(FilterTypes.FUNCTION_INVOCATION)\n",
    "async def validation_filter(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Coroutine[Any, Any, None]]\n",
    "):\n",
    "    \"\"\"Filtre qui valide les arguments avant execution.\"\"\"\n",
    "    # Validation specifique pour les fonctions math\n",
    "    if context.function.plugin_name == \"math\":\n",
    "        a = context.arguments.get(\"a\", 0)\n",
    "        b = context.arguments.get(\"b\", 0)\n",
    "        \n",
    "        # Exemple : bloquer les nombres negatifs\n",
    "        if a < 0 or b < 0:\n",
    "            raise ValueError(f\"Les nombres negatifs ne sont pas autorises: a={a}, b={b}\")\n",
    "    \n",
    "    await next(context)\n",
    "\n",
    "# Test avec nombres valides\n",
    "try:\n",
    "    result = await kernel.invoke(kernel.get_function(\"math\", \"multiply\"), KernelArguments(a=4, b=5))\n",
    "    print(f\"Resultat: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur: {e}\")\n",
    "\n",
    "# Test avec nombre negatif (devrait echouer)\n",
    "try:\n",
    "    result = await kernel.invoke(kernel.get_function(\"math\", \"multiply\"), KernelArguments(a=-3, b=5))\n",
    "    print(f\"Resultat: {result}\")\n",
    "except KernelInvokeException as e:\n",
    "    # L'exception ValueError est encapsulee dans KernelInvokeException\n",
    "    print(f\"Erreur de validation (KernelInvokeException): nombres negatifs bloques\")\n",
    "except ValueError as e:\n",
    "    print(f\"Erreur de validation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qjl4vgibshj",
   "source": "### Interprétation : Validation Filter avec Exception Handling\n\n**Sortie obtenue** : \n- Premier appel (4 × 5) : Succès avec résultat 20\n- Second appel (-3 × 5) : Blocage avec KernelInvokeException\n\n| Aspect | Comportement | Explication |\n|--------|--------------|-------------|\n| **Exception wrapping** | ValueError → KernelInvokeException | SK encapsule les exceptions des filtres |\n| **Ordre d'exécution** | Validation → Logging → Fonction | Les filtres sont chaînés dans l'ordre d'enregistrement |\n| **Blocage précoce** | Avant calcul | Le filtre de validation empêche l'exécution de la fonction |\n\n**Points clés** :\n1. **Chaînage des filtres** : Le filtre de validation s'exécute AVANT le filtre de logging (voir les logs)\n2. **Exception handling** : Les exceptions levées dans les filtres sont automatiquement wrappées dans `KernelInvokeException`\n3. **Validation métier** : Pattern idéal pour valider les inputs avant traitement coûteux (LLM, DB, etc.)\n4. **Court-circuit** : Si on lève une exception, `next(context)` n'est jamais appelé → fonction non exécutée\n\n**Note technique** : Pour capturer l'exception originale, utiliser `try/except KernelInvokeException as e` et inspecter `e.__cause__`.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "77b8207e",
   "metadata": {
    "papermill": {
     "duration": 0.00163,
     "end_time": "2026-02-04T07:07:54.243316",
     "exception": false,
     "start_time": "2026-02-04T07:07:54.241686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Prompt Rendering Filters\n",
    "\n",
    "Les filtres de prompt permettent de modifier le prompt avant son envoi au LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ac35e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:54.247661Z",
     "iopub.status.busy": "2026-02-04T07:07:54.247500Z",
     "iopub.status.idle": "2026-02-04T07:07:55.356953Z",
     "shell.execute_reply": "2026-02-04T07:07:55.356370Z"
    },
    "papermill": {
     "duration": 1.112564,
     "end_time": "2026-02-04T07:07:55.357455",
     "exception": false,
     "start_time": "2026-02-04T07:07:54.244891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prompt Filter] Regles de securite ajoutees\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reponse: Bonjour! Je vais bien, merci. Comment puis-je vous aider aujourd'hui?\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.filters.prompts.prompt_render_context import PromptRenderContext\n",
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "\n",
    "# Nouveau kernel pour les filtres de prompt\n",
    "kernel_prompt = Kernel()\n",
    "kernel_prompt.add_service(OpenAIChatCompletion(service_id=\"default\"))\n",
    "\n",
    "# Filtre qui ajoute des instructions de securite\n",
    "@kernel_prompt.filter(FilterTypes.PROMPT_RENDERING)\n",
    "async def security_prompt_filter(\n",
    "    context: PromptRenderContext,\n",
    "    next: Callable[[PromptRenderContext], Coroutine[Any, Any, None]]\n",
    "):\n",
    "    \"\"\"Ajoute des regles de securite au prompt.\"\"\"\n",
    "    # Executer le rendu du template d'abord\n",
    "    await next(context)\n",
    "    \n",
    "    # Ajouter des instructions de securite apres le rendu\n",
    "    security_rules = \"\"\"\n",
    "\n",
    "REGLES DE SECURITE:\n",
    "- Ne jamais reveler d'informations personnelles\n",
    "- Ne pas generer de contenu offensant\n",
    "- Refuser les demandes de code malveillant\n",
    "\"\"\"\n",
    "    context.rendered_prompt = context.rendered_prompt + security_rules\n",
    "    print(f\"[Prompt Filter] Regles de securite ajoutees\")\n",
    "\n",
    "# Creation d'une fonction avec template\n",
    "prompt_config = PromptTemplateConfig(\n",
    "    template=\"Tu es un assistant. Reponds a: {{$input}}\",\n",
    "    name=\"secure_chat\",\n",
    "    template_format=\"semantic-kernel\"\n",
    ")\n",
    "\n",
    "chat_function = kernel_prompt.add_function(\n",
    "    function_name=\"chat\",\n",
    "    plugin_name=\"demo\",\n",
    "    prompt_template_config=prompt_config\n",
    ")\n",
    "\n",
    "# Test\n",
    "response = await kernel_prompt.invoke(chat_function, KernelArguments(input=\"Bonjour, comment ca va?\"))\n",
    "print(f\"\\nReponse: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4gqygvpo5o",
   "source": "### Interprétation : Prompt Filter avec Injection de Règles\n\n**Sortie obtenue** : Le message \"[Prompt Filter] Regles de securite ajoutees\" confirme que le filtre s'est exécuté, et le LLM a bien reçu le prompt modifié.\n\n| Étape | Contenu | Rôle |\n|-------|---------|------|\n| **Template original** | \"Tu es un assistant. Reponds a: {{$input}}\" | Défini par le développeur |\n| **Rendu** | \"Tu es un assistant. Reponds a: Bonjour...\" | Variables remplacées |\n| **Après filtre** | Prompt + REGLES DE SECURITE | Instructions système ajoutées |\n| **Envoyé au LLM** | Prompt complet avec règles | Le LLM \"voit\" les règles |\n\n**Points clés** :\n1. **Ordre d'exécution** : D'abord `await next(context)` (rendu du template), PUIS modification du `rendered_prompt`\n2. **Injection transparente** : Le développeur qui appelle la fonction ne sait pas que des règles sont ajoutées\n3. **Sécurité systémique** : Toutes les fonctions du kernel héritent automatiquement des règles\n4. **Visibilité** : Le LLM \"voit\" les règles dans son prompt (contrairement aux system messages cachés)\n\n**Cas d'usage production** :\n- Ajout de contraintes légales (RGPD, conformité)\n- Injection de contexte d'entreprise (brand guidelines)\n- Rate limiting explicite (\"Tu as droit à 3 appels de fonction max\")\n- Instructions de formatage (JSON, Markdown, etc.)\n\n**Note** : Pour voir le prompt complet envoyé au LLM, activer le logging en mode DEBUG (voir section 5).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "832e30f9",
   "metadata": {
    "papermill": {
     "duration": 0.001792,
     "end_time": "2026-02-04T07:07:55.365390",
     "exception": false,
     "start_time": "2026-02-04T07:07:55.363598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Auto Function Invocation Filters\n",
    "\n",
    "Ces filtres controlent le comportement du function calling automatique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb93d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:55.369958Z",
     "iopub.status.busy": "2026-02-04T07:07:55.369716Z",
     "iopub.status.idle": "2026-02-04T07:07:55.582875Z",
     "shell.execute_reply": "2026-02-04T07:07:55.582280Z"
    },
    "papermill": {
     "duration": 0.216199,
     "end_time": "2026-02-04T07:07:55.583446",
     "exception": false,
     "start_time": "2026-02-04T07:07:55.367247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtre auto-invoke configure. Voir section 5 pour un exemple complet.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.filters.auto_function_invocation.auto_function_invocation_context import AutoFunctionInvocationContext\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "\n",
    "# Nouveau kernel pour les filtres auto-invoke\n",
    "kernel_auto = Kernel()\n",
    "kernel_auto.add_service(OpenAIChatCompletion(service_id=\"default\"))\n",
    "\n",
    "# Plugin sensible\n",
    "class DatabasePlugin:\n",
    "    @kernel_function(description=\"Execute une requete SQL\")\n",
    "    def execute_sql(self, query: str) -> str:\n",
    "        print(f\"  [DB] Execution: {query}\")\n",
    "        return f\"Resultats pour: {query}\"\n",
    "    \n",
    "    @kernel_function(description=\"Supprime des donnees\")\n",
    "    def delete_data(self, table: str) -> str:\n",
    "        print(f\"  [DB] DELETE FROM {table}\")\n",
    "        return f\"Donnees supprimees de {table}\"\n",
    "\n",
    "kernel_auto.add_plugin(DatabasePlugin(), plugin_name=\"database\")\n",
    "\n",
    "# Compteur d'appels pour rate limiting\n",
    "call_count = {\"total\": 0}\n",
    "\n",
    "@kernel_auto.filter(FilterTypes.AUTO_FUNCTION_INVOCATION)\n",
    "async def rate_limit_filter(\n",
    "    context: AutoFunctionInvocationContext,\n",
    "    next: Callable[[AutoFunctionInvocationContext], Coroutine[Any, Any, None]]\n",
    "):\n",
    "    \"\"\"Limite le nombre d'appels de fonction automatiques.\"\"\"\n",
    "    MAX_CALLS = 3\n",
    "    \n",
    "    call_count[\"total\"] += 1\n",
    "    \n",
    "    if call_count[\"total\"] > MAX_CALLS:\n",
    "        print(f\"[Rate Limit] Limite atteinte ({MAX_CALLS} appels max)\")\n",
    "        context.terminate = True  # Stoppe le function calling\n",
    "        return\n",
    "    \n",
    "    func_name = context.function.name\n",
    "    print(f\"[Auto-Invoke] Appel #{call_count['total']}: {func_name}\")\n",
    "    \n",
    "    # Bloquer les operations dangereuses\n",
    "    if \"delete\" in func_name.lower():\n",
    "        print(f\"[Auto-Invoke] BLOQUE: Operation de suppression non autorisee\")\n",
    "        context.terminate = True\n",
    "        return\n",
    "    \n",
    "    await next(context)\n",
    "\n",
    "print(\"Filtre auto-invoke configure. Voir section 5 pour un exemple complet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s2ivokko2nn",
   "source": "### Interprétation : Auto Function Invocation Filter avec Rate Limiting\n\n**Architecture du contrôle** : Ce filtre intercepte les décisions du LLM AVANT l'exécution des fonctions.\n\n| Mécanisme | Implémentation | Effet |\n|-----------|----------------|-------|\n| **Rate limiting** | Compteur global `call_count` | Maximum 3 appels de fonction |\n| **Blacklist** | Check sur `\"delete\" in func_name` | Bloque les opérations dangereuses |\n| **Terminaison** | `context.terminate = True` | Stoppe le function calling loop |\n| **Court-circuit** | Return sans `await next(context)` | Fonction non exécutée |\n\n**Points clés** :\n1. **Function calling loop** : Quand le LLM appelle une fonction, SK peut automatiquement exécuter la fonction et renvoyer le résultat au LLM (qui peut ensuite appeler une autre fonction, etc.)\n2. **`terminate = True`** : Indique à SK d'arrêter le loop et de retourner la réponse actuelle du LLM\n3. **Sécurité critique** : Sans ce filtre, un LLM pourrait décider d'appeler `delete_data()` sans supervision\n4. **Audit trail** : Chaque tentative d'appel est loggée, même si bloquée\n\n**Workflow complet** :\n```\nUser: \"Supprime les anciennes données\"\n    ↓\nLLM decide: database.delete_data(table=\"old_data\")\n    ↓\n[Auto-Invoke Filter] BLOQUE: Operation de suppression\n    ↓\nLLM reçoit: \"Opération refusée\"\n    ↓\nResponse finale\n```\n\n**Note technique** : Ce filtre est complémentaire aux Function Filters (section 2). L'Auto-Invoke Filter contrôle les appels **automatiques** du LLM, tandis que les Function Filters interceptent **tous** les appels (manuels ou auto).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "0062c7f5",
   "metadata": {
    "papermill": {
     "duration": 0.001795,
     "end_time": "2026-02-04T07:07:55.591049",
     "exception": false,
     "start_time": "2026-02-04T07:07:55.589254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Logging et Debugging\n",
    "\n",
    "SK utilise le module `logging` standard de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1869a0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:55.595716Z",
     "iopub.status.busy": "2026-02-04T07:07:55.595500Z",
     "iopub.status.idle": "2026-02-04T07:07:55.599128Z",
     "shell.execute_reply": "2026-02-04T07:07:55.598655Z"
    },
    "papermill": {
     "duration": 0.006677,
     "end_time": "2026-02-04T07:07:55.599625",
     "exception": false,
     "start_time": "2026-02-04T07:07:55.592948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niveaux de logging disponibles:\n",
      "| Niveau   | Valeur | Description                              |\n",
      "|----------|--------|------------------------------------------|\n",
      "| DEBUG    | 10     | Details tres fins (prompts complets)     |\n",
      "| INFO     | 20     | Informations generales                   |\n",
      "| WARNING  | 30     | Avertissements                           |\n",
      "| ERROR    | 40     | Erreurs                                  |\n",
      "| CRITICAL | 50     | Erreurs critiques                        |\n",
      "\n",
      "Logging configure en mode DEBUG\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configuration du logging pour SK\n",
    "def configure_sk_logging(level=logging.INFO):\n",
    "    \"\"\"Configure le logging pour Semantic Kernel.\"\"\"\n",
    "    # Handler pour la console\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(level)\n",
    "    \n",
    "    # Format detaille\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    \n",
    "    # Configurer le logger SK\n",
    "    sk_logger = logging.getLogger(\"semantic_kernel\")\n",
    "    sk_logger.setLevel(level)\n",
    "    sk_logger.addHandler(handler)\n",
    "    \n",
    "    return sk_logger\n",
    "\n",
    "# Niveaux de logging disponibles\n",
    "print(\"Niveaux de logging disponibles:\")\n",
    "print(\"| Niveau   | Valeur | Description                              |\")\n",
    "print(\"|----------|--------|------------------------------------------|\")\n",
    "print(\"| DEBUG    | 10     | Details tres fins (prompts complets)     |\")\n",
    "print(\"| INFO     | 20     | Informations generales                   |\")\n",
    "print(\"| WARNING  | 30     | Avertissements                           |\")\n",
    "print(\"| ERROR    | 40     | Erreurs                                  |\")\n",
    "print(\"| CRITICAL | 50     | Erreurs critiques                        |\")\n",
    "\n",
    "# Activer le logging DEBUG pour voir les details\n",
    "logger = configure_sk_logging(logging.DEBUG)\n",
    "print(\"\\nLogging configure en mode DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e3bf7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:55.604474Z",
     "iopub.status.busy": "2026-02-04T07:07:55.604251Z",
     "iopub.status.idle": "2026-02-04T07:07:56.219666Z",
     "shell.execute_reply": "2026-02-04T07:07:56.218939Z"
    },
    "papermill": {
     "duration": 0.618617,
     "end_time": "2026-02-04T07:07:56.220217",
     "exception": false,
     "start_time": "2026-02-04T07:07:55.601600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 08:07:55,813 - semantic_kernel.prompt_template.kernel_prompt_template - DEBUG - Extracting blocks from template: Dis bonjour a {{$name}} en francais.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Execution avec logging actif:\n",
      "==================================================\n",
      "2026-02-04 08:07:55,814 - semantic_kernel.functions.kernel_function - INFO - Function demo-greet invoking.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 08:07:55,815 - semantic_kernel.functions.kernel_function - DEBUG - Function arguments: {'name': 'Alice'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 08:07:55,815 - semantic_kernel.prompt_template.kernel_prompt_template - DEBUG - Rendering list of 3 blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 08:07:55,816 - semantic_kernel.prompt_template.kernel_prompt_template - DEBUG - Rendered prompt: Dis bonjour a Alice en francais.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 08:07:56,214 - semantic_kernel.connectors.ai.open_ai.services.open_ai_handler - INFO - OpenAI usage: CompletionUsage(completion_tokens=3, prompt_tokens=16, total_tokens=19, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 08:07:56,215 - semantic_kernel.functions.kernel_function - INFO - Function demo-greet succeeded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 08:07:56,216 - semantic_kernel.functions.kernel_function - DEBUG - Function result: Bonjour Alice !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 08:07:56,216 - semantic_kernel.functions.kernel_function - INFO - Function completed. Duration: 0.400880s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reponse finale: Bonjour Alice !\n"
     ]
    }
   ],
   "source": [
    "# Exemple avec logging actif\n",
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "\n",
    "kernel_log = Kernel()\n",
    "kernel_log.add_service(OpenAIChatCompletion(service_id=\"default\"))\n",
    "\n",
    "# Fonction simple\n",
    "simple_config = PromptTemplateConfig(\n",
    "    template=\"Dis bonjour a {{$name}} en francais.\",\n",
    "    name=\"greet\"\n",
    ")\n",
    "\n",
    "greet_function = kernel_log.add_function(\n",
    "    function_name=\"greet\",\n",
    "    plugin_name=\"demo\",\n",
    "    prompt_template_config=simple_config\n",
    ")\n",
    "\n",
    "# Execution avec logging\n",
    "print(\"=\" * 50)\n",
    "print(\"Execution avec logging actif:\")\n",
    "print(\"=\" * 50)\n",
    "response = await kernel_log.invoke(greet_function, KernelArguments(name=\"Alice\"))\n",
    "print(f\"\\nReponse finale: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wwfrmlsdpn",
   "source": "### Interprétation : Logging DEBUG - Anatomie d'une Invocation\n\n**Sortie obtenue** : Les logs DEBUG révèlent chaque étape interne de SK lors de l'exécution d'une fonction.\n\n| Timestamp | Logger | Message clé | Signification |\n|-----------|--------|-------------|---------------|\n| 08:07:55.813 | kernel_prompt_template | \"Extracting blocks from template\" | Parsing du template Jinja |\n| 08:07:55.814 | kernel_function | \"Function demo-greet invoking\" | Début de l'invocation |\n| 08:07:55.815 | kernel_function | \"Function arguments: {...}\" | Arguments reçus |\n| 08:07:55.815 | kernel_prompt_template | \"Rendering list of 3 blocks\" | Rendu du template (3 blocs détectés) |\n| 08:07:55.816 | kernel_prompt_template | \"Rendered prompt: Dis bonjour...\" | Prompt final avant envoi |\n| 08:07:56.214 | open_ai_handler | \"OpenAI usage: CompletionUsage(...)\" | Tokens consommés (16 prompt + 3 completion) |\n| 08:07:56.215 | kernel_function | \"Function demo-greet succeeded\" | Succès |\n| 08:07:56.216 | kernel_function | \"Function completed. Duration: 0.400880s\" | Durée totale |\n\n**Points clés** :\n1. **3 blocs dans le template** : SK découpe le template en blocs (texte statique + variables)\n2. **Tokens consommés** : 16 tokens prompt + 3 tokens completion = 19 tokens total (~0.00038$ avec GPT-4o)\n3. **Latence** : 400ms totale dont ~398ms pour l'appel OpenAI (réseau + génération)\n4. **Pas de cache** : `cached_tokens=0` → prompt non mis en cache par OpenAI\n\n**Utilisation en production** :\n- **Debugging** : Identifier où une fonction échoue (template, LLM, post-processing)\n- **Optimisation** : Mesurer la latence de chaque composant\n- **Cost tracking** : Tracker les tokens consommés par fonction\n- **Audit** : Logger tous les prompts envoyés (compliance RGPD)\n\n**Niveaux de logging recommandés** :\n- **Development** : DEBUG (tout voir)\n- **Staging** : INFO (invocations + erreurs)\n- **Production** : WARNING (erreurs seulement) + OpenTelemetry pour les métriques",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "264b179e",
   "metadata": {
    "papermill": {
     "duration": 0.004003,
     "end_time": "2026-02-04T07:07:56.226587",
     "exception": false,
     "start_time": "2026-02-04T07:07:56.222584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. OpenTelemetry (Apercu)\n",
    "\n",
    "Pour le monitoring en production, SK supporte OpenTelemetry.\n",
    "\n",
    "### Architecture OpenTelemetry\n",
    "\n",
    "```\n",
    "Semantic Kernel\n",
    "    |\n",
    "    v\n",
    "OpenTelemetry SDK\n",
    "    |\n",
    "    +-- Traces (appels, latence)\n",
    "    |\n",
    "    +-- Metrics (compteurs, histogrammes)\n",
    "    |\n",
    "    +-- Logs (evenements)\n",
    "    |\n",
    "    v\n",
    "Exporters\n",
    "    |\n",
    "    +-- Azure Monitor\n",
    "    +-- Jaeger\n",
    "    +-- Prometheus\n",
    "    +-- Console (debug)\n",
    "```\n",
    "\n",
    "### Exemple conceptuel (non execute)\n",
    "\n",
    "```python\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor\n",
    "\n",
    "# Configuration OpenTelemetry\n",
    "provider = TracerProvider()\n",
    "processor = SimpleSpanProcessor(ConsoleSpanExporter())\n",
    "provider.add_span_processor(processor)\n",
    "trace.set_tracer_provider(provider)\n",
    "\n",
    "# SK detecte automatiquement OpenTelemetry\n",
    "kernel = Kernel()\n",
    "# Les traces sont emises automatiquement pour:\n",
    "# - Chaque invocation de fonction\n",
    "# - Chaque appel au LLM\n",
    "# - Les erreurs et exceptions\n",
    "```\n",
    "\n",
    "### Metriques disponibles\n",
    "\n",
    "| Metrique | Type | Description |\n",
    "|----------|------|-------------|\n",
    "| `semantic_kernel.function.invocations` | Counter | Nombre d'invocations |\n",
    "| `semantic_kernel.function.duration` | Histogram | Duree des appels |\n",
    "| `semantic_kernel.llm.tokens` | Counter | Tokens consommes |\n",
    "| `semantic_kernel.llm.latency` | Histogram | Latence LLM |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe37a29",
   "metadata": {
    "papermill": {
     "duration": 0.001989,
     "end_time": "2026-02-04T07:07:56.230510",
     "exception": false,
     "start_time": "2026-02-04T07:07:56.228521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "## Resume des concepts\n",
    "\n",
    "| Concept | Description | Code cle |\n",
    "|---------|-------------|----------|\n",
    "| **Function Filter** | Intercepte avant/apres fonctions | `@kernel.filter(FilterTypes.FUNCTION_INVOCATION)` |\n",
    "| **Prompt Filter** | Modifie le prompt | `@kernel.filter(FilterTypes.PROMPT_RENDERING)` |\n",
    "| **Auto-Invoke Filter** | Controle function calling | `@kernel.filter(FilterTypes.AUTO_FUNCTION_INVOCATION)` |\n",
    "| **Logging** | Debug avec logging standard | `logging.getLogger(\"semantic_kernel\")` |\n",
    "| **OpenTelemetry** | Monitoring production | Traces, metriques, logs |\n",
    "\n",
    "## Points cles a retenir\n",
    "\n",
    "1. **Les filtres suivent le pattern middleware** - `await next(context)` passe au suivant\n",
    "2. **Plusieurs filtres peuvent etre chaines** - Ordre d'enregistrement = ordre d'execution\n",
    "3. **Le contexte est mutable** - On peut modifier arguments, resultats, prompts\n",
    "4. **`terminate = True`** - Stoppe l'execution (utile pour le rate limiting)\n",
    "5. **OpenTelemetry pour la production** - Traces et metriques automatiques\n",
    "\n",
    "## Exercices suggeres\n",
    "\n",
    "1. **Filtre de cache** : Creer un filtre qui cache les resultats de fonctions\n",
    "2. **Filtre d'anonymisation** : Masquer les emails/numeros dans les prompts\n",
    "3. **Filtre d'approbation** : Demander confirmation avant les operations sensibles\n",
    "\n",
    "## Pour aller plus loin\n",
    "\n",
    "| Notebook | Contenu |\n",
    "|----------|--------|\n",
    "| [05-VectorStores](05-SemanticKernel-VectorStores.ipynb) | RAG avec Qdrant |\n",
    "| [06-ProcessFramework](06-SemanticKernel-ProcessFramework.ipynb) | Workflows orchestres |\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation** : [<< 03-Agents](03-SemanticKernel-Agents.ipynb) | [Index](README.md) | [05-VectorStores >>](05-SemanticKernel-VectorStores.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.347894,
   "end_time": "2026-02-04T07:07:58.868062",
   "environment_variables": {},
   "exception": null,
   "input_path": "04-SemanticKernel-Filters-Observability.ipynb",
   "output_path": "04-SemanticKernel-Filters-Observability.ipynb",
   "parameters": {},
   "start_time": "2026-02-04T07:07:50.520168",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}