{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb171a6",
   "metadata": {
    "papermill": {
     "duration": 0.003189,
     "end_time": "2026-02-04T07:07:31.960139",
     "exception": false,
     "start_time": "2026-02-04T07:07:31.956950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SK-3-Agents : Agent Framework Semantic Kernel\n",
    "\n",
    "**Navigation** : [<< 02-Functions](02-SemanticKernel-Advanced.ipynb) | [Index](README.md) | [04-Filters >>](04-SemanticKernel-Filters-Observability.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs d'apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous saurez :\n",
    "1. Creer un **ChatCompletionAgent** simple avec instructions\n",
    "2. Integrer des **plugins** avec Function Calling automatique\n",
    "3. Orchestrer plusieurs agents via **AgentGroupChat**\n",
    "4. Definir des **strategies de terminaison** personnalisees\n",
    "5. Comprendre les bases d'**OpenAIAssistantAgent** (Code Interpreter, File Search)\n",
    "\n",
    "### Prerequis\n",
    "\n",
    "- Python 3.10+\n",
    "- Notebooks 01 et 02 completes\n",
    "- Cle API OpenAI configuree (`.env`)\n",
    "\n",
    "### Duree estimee : 55 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Sommaire\n",
    "\n",
    "| Section | Contenu | Concepts cles |\n",
    "|---------|---------|---------------|\n",
    "| 1 | Installation | semantic-kernel, imports |\n",
    "| 2 | Agent Simple | ChatCompletionAgent, instructions, invoke |\n",
    "| 3 | Agent + Plugins | MenuPlugin, FunctionChoiceBehavior.Auto() |\n",
    "| 4 | Group Chat | AgentGroupChat, TerminationStrategy |\n",
    "| 5 | OpenAIAssistantAgent | Code Interpreter, File Search, Threads |\n",
    "| 6 | Conclusion | Resume, exercices, navigation |\n",
    "\n",
    "> **Qu'est-ce que l'Agent Framework ?** Introduit avec SK 1.0, il permet de creer des agents autonomes capables de raisonner, utiliser des outils, et collaborer entre eux. C'est l'evolution naturelle des plugins vers des entites plus intelligentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c8e9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:31.965044Z",
     "iopub.status.busy": "2026-02-04T07:07:31.964641Z",
     "iopub.status.idle": "2026-02-04T07:07:33.081010Z",
     "shell.execute_reply": "2026-02-04T07:07:33.080547Z"
    },
    "papermill": {
     "duration": 1.119647,
     "end_time": "2026-02-04T07:07:33.081657",
     "exception": false,
     "start_time": "2026-02-04T07:07:31.962010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Configuration chargee:\n",
      "  - API Key: OK\n",
      "  - Modele: gpt-4o\n",
      "semantic-kernel installe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\jsboi\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Bloc 1 : Installation semantic-kernel et imports\n",
    "# ============================\n",
    "\n",
    "# A n'executer qu'une fois\n",
    "%pip install semantic-kernel python-dotenv --quiet\n",
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Chargement du fichier .env (cles API)\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Verification de la configuration\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_id = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-4o\")\n",
    "print(f\"Configuration chargee:\")\n",
    "print(f\"  - API Key: {'OK' if api_key else 'MANQUANTE'}\")\n",
    "print(f\"  - Modele: {model_id}\")\n",
    "print(\"semantic-kernel installe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w26cdtzp6e",
   "metadata": {
    "papermill": {
     "duration": 0.001784,
     "end_time": "2026-02-04T07:07:33.085290",
     "exception": false,
     "start_time": "2026-02-04T07:07:33.083506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Installation et imports\n",
    "\n",
    "Cette cellule installe le SDK Semantic Kernel et importe les modules necessaires pour creer des agents conversationnels.\n",
    "\n",
    "**Concepts cles** :\n",
    "- `ChatCompletionAgent` : Un agent base sur un modele de chat completion\n",
    "- `AgentGroupChat` : Orchestrateur pour faire collaborer plusieurs agents\n",
    "- `ChatHistory` : Historique de conversation partage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cefe0",
   "metadata": {
    "papermill": {
     "duration": 0.001605,
     "end_time": "2026-02-04T07:07:33.088420",
     "exception": false,
     "start_time": "2026-02-04T07:07:33.086815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bloc 2 : Simple Agent (Parrot)\n",
    "\n",
    "Nous créons un agent tout simple, qui répète le message de l’utilisateur sur le ton d’un pirate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd991043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:33.092525Z",
     "iopub.status.busy": "2026-02-04T07:07:33.092316Z",
     "iopub.status.idle": "2026-02-04T07:07:36.382523Z",
     "shell.execute_reply": "2026-02-04T07:07:36.381903Z"
    },
    "papermill": {
     "duration": 3.293163,
     "end_time": "2026-02-04T07:07:36.383128",
     "exception": false,
     "start_time": "2026-02-04T07:07:33.089965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'Fortune favors the bold.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - Parrot: 'Fortune be favorin' the bold, me hearty! Arrr!'\n",
      "# User: 'I came, I saw, I conquered.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - Parrot: 'I came, I saw, I conquered, says ye captain! Arrr!'\n",
      "# User: 'Practice makes perfect.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - Parrot: 'Practice makes perfect, me matey! Arrr!'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "AGENT_NAME = \"Parrot\"\n",
    "AGENT_INSTRUCTIONS = \"You are a helpful parrot that repeats the user message in a pirate voice, then ends with 'Arrr!'\"\n",
    "\n",
    "# Création du Kernel\n",
    "kernel = Kernel()\n",
    "# On suppose que vous avez défini ou récupéré des clés d'API :\n",
    "# kernel.add_service(OpenAIChatCompletion(...)) ou AzureChatCompletion(...)\n",
    "kernel.add_service(OpenAIChatCompletion(service_id=\"agent\"))\n",
    "\n",
    "agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=AGENT_NAME,\n",
    "    instructions=AGENT_INSTRUCTIONS\n",
    ")\n",
    "user_inputs = [\n",
    "    \"Fortune favors the bold.\",\n",
    "    \"I came, I saw, I conquered.\",\n",
    "    \"Practice makes perfect.\",\n",
    "]\n",
    "\n",
    "async def simple_agent_demo():\n",
    "    chat_history = ChatHistory()\n",
    "    # On ajoute les instructions de l'agent en tant que 'developer' ou 'system'\n",
    "    chat_history.add_developer_message(AGENT_INSTRUCTIONS)\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        chat_history.add_user_message(user_input)\n",
    "        print(f\"# User: '{user_input}'\")\n",
    "        async for content in agent.invoke(chat_history):\n",
    "            # CORRECTION DÉFINITIVE : Toujours utiliser add_assistant_message\n",
    "            # L'API SemanticKernel agents retourne des objets incompatibles avec add_message()\n",
    "            if hasattr(content, 'content'):\n",
    "                # Extraire le contenu et le convertir en string\n",
    "                content_str = str(content.content) if content.content else str(content)\n",
    "                chat_history.add_assistant_message(content_str)\n",
    "                print(f\"# Agent - {content.name or AGENT_NAME}: '{content_str}'\")\n",
    "            else:\n",
    "                # Fallback: convertir tout l'objet en string\n",
    "                content_str = str(content)\n",
    "                chat_history.add_assistant_message(content_str)\n",
    "                print(f\"# Agent - {AGENT_NAME}: '{content_str}'\")\n",
    "\n",
    "await simple_agent_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d5de8",
   "metadata": {
    "papermill": {
     "duration": 0.00192,
     "end_time": "2026-02-04T07:07:36.387152",
     "exception": false,
     "start_time": "2026-02-04T07:07:36.385232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Architecture des Agents SK\n",
    "\n",
    "L'agent Parrot illustre le pattern le plus simple. Voici la taxonomie complete des agents SK :\n",
    "\n",
    "| Type d'Agent | Description | Cas d'usage |\n",
    "|--------------|-------------|-------------|\n",
    "| **ChatCompletionAgent** | Agent base sur chat completion standard | Assistants, chatbots, taches simples |\n",
    "| **OpenAIAssistantAgent** | Utilise l'API Assistants OpenAI | Code Interpreter, File Search, threads persistants |\n",
    "| **AzureAIAgent** | Agent Azure AI Foundry | Integration enterprise Azure |\n",
    "\n",
    "**Composants d'un agent** :\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────┐\n",
    "│           ChatCompletionAgent           │\n",
    "│  ┌─────────────┐  ┌─────────────────┐  │\n",
    "│  │   Kernel    │  │  Instructions   │  │\n",
    "│  │ (Services,  │  │  (System msg)   │  │\n",
    "│  │  Plugins)   │  │                 │  │\n",
    "│  └─────────────┘  └─────────────────┘  │\n",
    "│           ↓              ↓              │\n",
    "│       ┌─────────────────────────┐      │\n",
    "│       │   invoke(chat_history)  │      │\n",
    "│       │   invoke_stream(...)    │      │\n",
    "│       └─────────────────────────┘      │\n",
    "└─────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Point cle** : Un agent encapsule un Kernel avec ses services et plugins, plus des instructions qui definissent sa personnalite et son comportement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gw9dqp9zmu",
   "metadata": {
    "papermill": {
     "duration": 0.00162,
     "end_time": "2026-02-04T07:07:36.391137",
     "exception": false,
     "start_time": "2026-02-04T07:07:36.389517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Execution de l'agent Parrot\n",
    "\n",
    "L'agent \"Parrot\" illustre le cas le plus simple :\n",
    "- **Instructions systeme** : Definissent le comportement (repeter en voix de pirate)\n",
    "- **Invocation** : Chaque message utilisateur est transforme par l'agent\n",
    "- **Historique** : Les reponses sont ajoutees a `ChatHistory` pour le contexte\n",
    "\n",
    "**Point technique** : La methode `invoke()` est asynchrone et retourne un flux (streaming) de contenus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f12a31",
   "metadata": {
    "papermill": {
     "duration": 0.001624,
     "end_time": "2026-02-04T07:07:36.396444",
     "exception": false,
     "start_time": "2026-02-04T07:07:36.394820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bloc 3 : Agent simple avec Plugins\n",
    "\n",
    "Exemple de plugin `MenuPlugin`, et agent unique qui répond en utilisant ces fonctions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1546a45e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:36.400629Z",
     "iopub.status.busy": "2026-02-04T07:07:36.400434Z",
     "iopub.status.idle": "2026-02-04T07:07:42.567818Z",
     "shell.execute_reply": "2026-02-04T07:07:42.567348Z"
    },
    "papermill": {
     "duration": 6.170561,
     "end_time": "2026-02-04T07:07:42.568509",
     "exception": false,
     "start_time": "2026-02-04T07:07:36.397948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'Hello'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Host: 'Hi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " there"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " assist"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " today"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "# User: 'What is the special soup?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Host: 'get_specials called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " special"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " soup"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chow"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Would"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " know"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anything"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " else"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " menu"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "# User: 'What does it cost?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Host: 'get_item_price called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chow"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " priced"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " at"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " $"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Would"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " know"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anything"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " else"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "# User: 'Thanks'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Host: 'You're"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " welcome"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " If"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " have"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " any"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " questions"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " feel"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " free"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ask"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enjoy"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " day"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import TYPE_CHECKING, Annotated\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import KernelArguments, kernel_function\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "class MenuPlugin:\n",
    "    \"\"\"Plugin pour gérer un menu\"\"\"\n",
    "    @kernel_function(description=\"Liste les specials\")\n",
    "    def get_specials(self) -> Annotated[str, \"Describes specials\"]:\n",
    "        # print function call\n",
    "        print(\"get_specials called\")\n",
    "        return \"Special Soup: Clam Chowder\\nSpecial Salad: Cobb Salad\\nSpecial Drink: Chai Tea\"\n",
    "    @kernel_function(description=\"Donne le prix d'un item\")\n",
    "    def get_item_price(self, menu_item: Annotated[str, \"nom de l'item\"]) -> str:\n",
    "         # print function call\n",
    "        print(\"get_item_price called\")\n",
    "        return \"$9.99\"\n",
    "# Créer kernel\n",
    "kernel2 = Kernel()\n",
    "# Ajout du plugin\n",
    "kernel2.add_plugin(MenuPlugin(), plugin_name=\"menu\")\n",
    "# Ajout du service\n",
    "kernel2.add_service(OpenAIChatCompletion(service_id=\"agent2\"))\n",
    "# On configure l'auto function-calling\n",
    "settings2 = kernel2.get_prompt_execution_settings_from_service_id(service_id=\"agent2\")\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "settings2.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "AGENT2_NAME = \"Host\"\n",
    "AGENT2_INSTRUCTIONS = \"Answer questions about the menu.\"\n",
    "agent2 = ChatCompletionAgent(\n",
    "    kernel=kernel2,\n",
    "    name=AGENT2_NAME,\n",
    "    instructions=AGENT2_INSTRUCTIONS,\n",
    "    arguments=KernelArguments(settings=settings2),\n",
    ")\n",
    "async def plugin_agent_demo():\n",
    "    chat_history = ChatHistory()\n",
    "    user_msgs = [\n",
    "        \"Hello\",\n",
    "        \"What is the special soup?\",\n",
    "        \"What does it cost?\",\n",
    "        \"Thanks\",\n",
    "    ]\n",
    "    for user_input in user_msgs:\n",
    "        chat_history.add_user_message(user_input)\n",
    "        print(f\"# User: '{user_input}'\")\n",
    "        agent_name = None\n",
    "        full_response = \"\"  # Accumulateur pour la réponse complète\n",
    "        \n",
    "        async for content in agent2.invoke_stream(chat_history):\n",
    "            if not agent_name:\n",
    "                agent_name = content.name or AGENT2_NAME\n",
    "                print(f\"# {agent_name}: '\", end=\"\")\n",
    "            \n",
    "            # CORRECTION: Gestion appropriée du StreamingChatMessageContent\n",
    "            if hasattr(content, 'content'):\n",
    "                # Conversion sécurisée du contenu\n",
    "                content_str = str(content.content) if content.content else \"\"\n",
    "                # Accumulation de la réponse\n",
    "                full_response += content_str\n",
    "                # Affichage incrémental\n",
    "                if content_str:\n",
    "                    print(content_str, end=\"\", flush=True)\n",
    "        \n",
    "        print(\"'\")\n",
    "        \n",
    "        # Ajout sécurisé du message complet à l'historique\n",
    "        if full_response:\n",
    "            chat_history.add_assistant_message(full_response)\n",
    "        else:\n",
    "            # Si pas de contenu, ajouter un message par défaut\n",
    "            chat_history.add_assistant_message(\"[No response generated]\")\n",
    "\n",
    "await plugin_agent_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe75ad9",
   "metadata": {
    "papermill": {
     "duration": 0.003499,
     "end_time": "2026-02-04T07:07:42.575692",
     "exception": false,
     "start_time": "2026-02-04T07:07:42.572193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Analyse des appels de fonction automatiques\n",
    "\n",
    "Dans l'execution ci-dessus, observez la sequence d'appels :\n",
    "\n",
    "1. **User** : \"What is the special soup?\"\n",
    "2. **Agent interne** : Appelle `get_specials()` (affiche \"get_specials called\")\n",
    "3. **Agent repond** : \"The special soup is Clam Chowder\"\n",
    "4. **User** : \"What does it cost?\"\n",
    "5. **Agent interne** : Appelle `get_item_price(\"Clam Chowder\")` (affiche \"get_item_price called\")\n",
    "6. **Agent repond** : \"It costs $9.99\"\n",
    "\n",
    "Le parametre `FunctionChoiceBehavior.Auto()` permet a l'agent de :\n",
    "- Analyser la question de l'utilisateur\n",
    "- Determiner quelle fonction appeler\n",
    "- Extraire les parametres (ex: \"Clam Chowder\")\n",
    "- Integrer le resultat dans sa reponse\n",
    "\n",
    "C'est la base du **ReAct pattern** (Reasoning + Acting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p17wlpq5mr",
   "metadata": {
    "papermill": {
     "duration": 0.00327,
     "end_time": "2026-02-04T07:07:42.582492",
     "exception": false,
     "start_time": "2026-02-04T07:07:42.579222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Execution de l'agent avec plugins\n",
    "\n",
    "Le plugin `MenuPlugin` expose des fonctions que l'agent peut appeler automatiquement :\n",
    "- `get_specials()` : Retourne les plats du jour\n",
    "- `get_item_price()` : Retourne le prix d'un article\n",
    "\n",
    "**Function Calling Auto** : Le parametre `FunctionChoiceBehavior.Auto()` permet a l'agent de decider lui-meme quand appeler ces fonctions en fonction du contexte de la conversation.\n",
    "\n",
    "Observez les appels `get_specials called` et `get_item_price called` dans la sortie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88566ce4",
   "metadata": {
    "papermill": {
     "duration": 0.003154,
     "end_time": "2026-02-04T07:07:42.588822",
     "exception": false,
     "start_time": "2026-02-04T07:07:42.585668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bloc 4 : Group Chat\n",
    "\n",
    "Exemple d'un chat groupé : un agent CopyWriter, un agent ArtDirector, etc. On utilise la `AgentGroupChat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e10355e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:42.596554Z",
     "iopub.status.busy": "2026-02-04T07:07:42.596326Z",
     "iopub.status.idle": "2026-02-04T07:07:47.823995Z",
     "shell.execute_reply": "2026-02-04T07:07:47.823025Z"
    },
    "papermill": {
     "duration": 5.232284,
     "end_time": "2026-02-04T07:07:47.824564",
     "exception": false,
     "start_time": "2026-02-04T07:07:42.592280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'I need a slogan for a new line of electric bikes'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - ArtDirector: 'Sure! Here's a suggestion: \"Ride the Future: Electrify Your Journey\"\n",
      "\n",
      "If you like the direction but want something tweaked, let me know!'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - CopyWriter: 'Sure! How about this: \"Unleash the Power of Green: Ride Beyond\"'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - ArtDirector: 'Sure! Here's a suggestion: \"Ride the Future: Electrify Your Journey\"\n",
      "\n",
      "If you like the direction but want something tweaked, let me know!'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - CopyWriter: '\"Unchain Your Commute: Ride the Electric Revolution.\"'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - ArtDirector: 'I’m looking for a tagline for our organic skincare line.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - CopyWriter: '\"Purely You: Embrace Nature's Glow.\"'\n",
      "# IS COMPLETE: False\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from semantic_kernel.agents import AgentGroupChat, ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import AuthorRole, ChatMessageContent\n",
    "from semantic_kernel.agents.strategies import TerminationStrategy\n",
    "from semantic_kernel import Kernel\n",
    "\n",
    "class ApprovalTerminationStrategy(TerminationStrategy):\n",
    "    async def should_agent_terminate(self, agent, history):\n",
    "        return \"approved\" in history[-1].content.lower()\n",
    "\n",
    "# On crée un kernel par agent, ou le même kernel + service differencié.\n",
    "def create_kernel_for(name):\n",
    "    k = Kernel()\n",
    "    # on admet qu'on a paramétré un service openAI.\n",
    "    k.add_service(OpenAIChatCompletion(service_id=name))\n",
    "    return k\n",
    "\n",
    "REVIEWER_NAME = \"ArtDirector\"\n",
    "REVIEWER_INSTRUCTIONS = \"You are an art director. If the copy is good, say 'Approved'. Otherwise, propose improvements.\"\n",
    "reviewer_agent = ChatCompletionAgent(\n",
    "    kernel=create_kernel_for(REVIEWER_NAME),\n",
    "    name=REVIEWER_NAME,\n",
    "    instructions=REVIEWER_INSTRUCTIONS,\n",
    ")\n",
    "COPYWRITER_NAME = \"CopyWriter\"\n",
    "COPYWRITER_INSTRUCTIONS = \"You are a copywriter. Provide short but strong marketing copy.\"\n",
    "writer_agent = ChatCompletionAgent(\n",
    "    kernel=create_kernel_for(COPYWRITER_NAME),\n",
    "    name=COPYWRITER_NAME,\n",
    "    instructions=COPYWRITER_INSTRUCTIONS,\n",
    ")\n",
    "group_chat = AgentGroupChat(\n",
    "    agents=[reviewer_agent, writer_agent],\n",
    "    termination_strategy=ApprovalTerminationStrategy(agents=[reviewer_agent], maximum_iterations=6)\n",
    ")\n",
    "\n",
    "async def group_chat_demo():\n",
    "    user_msg = \"I need a slogan for a new line of electric bikes\"\n",
    "    await group_chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_msg))\n",
    "    print(f\"# User: '{user_msg}'\")\n",
    "    async for content in group_chat.invoke():\n",
    "        # Gestion sécurisée du contenu pour éviter ContentInitializationError\n",
    "        if hasattr(content, 'content') and content.content:\n",
    "            print(f\"# Agent - {content.name or '*'}: '{content.content}'\")\n",
    "        else:\n",
    "            print(f\"# Agent - {content.name or '*'}: '{str(content)}'\")\n",
    "\n",
    "    print(f\"# IS COMPLETE: {group_chat.is_complete}\")\n",
    "\n",
    "await group_chat_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be500dd5",
   "metadata": {
    "papermill": {
     "duration": 0.003759,
     "end_time": "2026-02-04T07:07:47.832029",
     "exception": false,
     "start_time": "2026-02-04T07:07:47.828270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Orchestration Multi-Agents\n",
    "\n",
    "Le Group Chat ci-dessus orchestre un dialogue iteratif entre agents specialises.\n",
    "\n",
    "**Flux de conversation** :\n",
    "\n",
    "```\n",
    "User: \"I need a slogan for electric bikes\"\n",
    "    ↓\n",
    "┌─────────────┐     ┌─────────────┐\n",
    "│ CopyWriter  │────→│ ArtDirector │\n",
    "│  (propose)  │←────│  (review)   │\n",
    "└─────────────┘     └─────────────┘\n",
    "    ↓                    ↓\n",
    "    └────────────────────┘\n",
    "         (iterate until \"approved\")\n",
    "```\n",
    "\n",
    "**Strategies de Selection** (qui parle ensuite ?) :\n",
    "\n",
    "| Strategie | Description | Exemple |\n",
    "|-----------|-------------|---------|\n",
    "| **SequentialSelectionStrategy** | Round-robin entre agents | A → B → A → B |\n",
    "| **KernelFunctionSelectionStrategy** | Selection par LLM | \"Qui devrait repondre ?\" |\n",
    "| **Custom** | Logique personnalisee | Basee sur mots-cles, contexte |\n",
    "\n",
    "**Strategies de Terminaison** (quand s'arreter ?) :\n",
    "\n",
    "| Strategie | Description | Exemple |\n",
    "|-----------|-------------|---------|\n",
    "| **DefaultTerminationStrategy** | Limite d'iterations | `maximum_iterations=10` |\n",
    "| **ApprovalTerminationStrategy** | Mot-cle de validation | \"approved\" dans la reponse |\n",
    "| **KernelFunctionTerminationStrategy** | Decision par LLM | \"L'objectif est-il atteint ?\" |\n",
    "| **AggregatorTerminationStrategy** | Combine plusieurs | ALL / ANY conditions |\n",
    "\n",
    "**Cas d'usage avances** :\n",
    "- **Peer review** : Coder + Reviewer (cf. [05-NotebookMaker](05-NotebookMaker.ipynb))\n",
    "- **Brainstorming** : Ideator + Critic + Synthesizer\n",
    "- **Pipeline** : Researcher → Writer → Editor → Publisher\n",
    "\n",
    "> **Note** : Notre notebook [05-NotebookMaker](05-NotebookMaker.ipynb) implemente un systeme 3-agents (Admin, Coder, Reviewer) pour la generation automatique de notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3pf1gsiqf4",
   "metadata": {
    "papermill": {
     "duration": 0.003505,
     "end_time": "2026-02-04T07:07:47.839182",
     "exception": false,
     "start_time": "2026-02-04T07:07:47.835677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bloc 5 : OpenAIAssistantAgent (Apercu)\n",
    "\n",
    "L'API Assistants d'OpenAI offre des capacites avancees que `ChatCompletionAgent` n'a pas nativement :\n",
    "\n",
    "| Fonctionnalite | Description | Cas d'usage |\n",
    "|----------------|-------------|-------------|\n",
    "| **Code Interpreter** | Execute du Python dans un sandbox | Calculs, graphiques, analyse de donnees |\n",
    "| **File Search** | RAG integre sur fichiers uploades | Questions sur documents PDF, DOCX |\n",
    "| **Threads persistants** | Historique conserve cote serveur | Conversations longues, reprise de session |\n",
    "\n",
    "### Architecture OpenAIAssistantAgent\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────┐\n",
    "│          OpenAIAssistantAgent               │\n",
    "│  ┌─────────────────────────────────────┐   │\n",
    "│  │         OpenAI Assistants API       │   │\n",
    "│  │  ┌───────────┐  ┌───────────────┐  │   │\n",
    "│  │  │   Code    │  │  File Search  │  │   │\n",
    "│  │  │Interpreter│  │  (RAG integre)│  │   │\n",
    "│  │  └───────────┘  └───────────────┘  │   │\n",
    "│  │         ↓              ↓           │   │\n",
    "│  │       Thread (persistent state)    │   │\n",
    "│  └─────────────────────────────────────┘   │\n",
    "└─────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Exemple conceptuel (non execute)\n",
    "\n",
    "```python\n",
    "from semantic_kernel.agents.open_ai import OpenAIAssistantAgent\n",
    "\n",
    "# Creation de l'agent avec Code Interpreter\n",
    "agent = await OpenAIAssistantAgent.create(\n",
    "    kernel=kernel,\n",
    "    name=\"DataAnalyst\",\n",
    "    instructions=\"Tu es un analyste de donnees. Utilise Python pour les calculs.\",\n",
    "    enable_code_interpreter=True,\n",
    "    enable_file_search=True\n",
    ")\n",
    "\n",
    "# Creation d'un thread (session persistante)\n",
    "thread = await agent.create_thread()\n",
    "\n",
    "# Ajout d'un fichier pour analyse\n",
    "await agent.add_file(thread_id=thread.id, file_path=\"data.csv\")\n",
    "\n",
    "# Invocation avec contexte fichier\n",
    "response = await agent.invoke(thread_id=thread.id, message=\"Analyse ce CSV et genere un graphique\")\n",
    "```\n",
    "\n",
    "**Points cles** :\n",
    "- `enable_code_interpreter=True` : L'agent peut executer du Python\n",
    "- `enable_file_search=True` : L'agent peut rechercher dans les fichiers\n",
    "- `thread` : Session persistante cote OpenAI (pas de `ChatHistory` local)\n",
    "- Les fichiers sont uploades vers OpenAI et indexes automatiquement\n",
    "\n",
    "> **Note** : Cette API necessite un compte OpenAI avec acces aux Assistants (payant). Pour des alternatives locales, voir les Vector Stores dans le [notebook 05](05-SemanticKernel-VectorStores.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87unbuhefim",
   "metadata": {
    "papermill": {
     "duration": 0.003343,
     "end_time": "2026-02-04T07:07:47.846228",
     "exception": false,
     "start_time": "2026-02-04T07:07:47.842885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Execution du Group Chat\n",
    "\n",
    "Le `AgentGroupChat` orchestre plusieurs agents qui collaborent :\n",
    "- **ArtDirector** : Valide ou demande des ameliorations du texte\n",
    "- **CopyWriter** : Propose du contenu marketing\n",
    "\n",
    "**Strategie de terminaison** : La classe `ApprovalTerminationStrategy` arrete la conversation quand l'ArtDirector dit \"approved\". Cela illustre comment definir des conditions d'arret personnalisees.\n",
    "\n",
    "La limite `maximum_iterations=6` protege contre les boucles infinies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910fffa7",
   "metadata": {
    "papermill": {
     "duration": 0.003333,
     "end_time": "2026-02-04T07:07:47.853094",
     "exception": false,
     "start_time": "2026-02-04T07:07:47.849761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "## Resume des concepts\n",
    "\n",
    "| Concept | Description | Code cle |\n",
    "|---------|-------------|----------|\n",
    "| **ChatCompletionAgent** | Agent de base SK | `ChatCompletionAgent(kernel, name, instructions)` |\n",
    "| **Instructions** | Personnalite de l'agent | Message systeme definissant le comportement |\n",
    "| **Plugins + Agent** | Outils pour l'agent | `FunctionChoiceBehavior.Auto()` |\n",
    "| **AgentGroupChat** | Orchestration multi-agents | `AgentGroupChat(agents, termination_strategy)` |\n",
    "| **TerminationStrategy** | Condition d'arret | `ApprovalTerminationStrategy`, custom |\n",
    "| **OpenAIAssistantAgent** | API Assistants | Code Interpreter, File Search, Threads |\n",
    "\n",
    "## Points cles a retenir\n",
    "\n",
    "1. **Un agent = Kernel + Instructions** - Le Kernel fournit les capacites, les instructions definissent le comportement\n",
    "2. **Function Calling automatique** - `FunctionChoiceBehavior.Auto()` permet a l'agent de decider quand utiliser les outils\n",
    "3. **AgentGroupChat pour la collaboration** - Plusieurs agents peuvent dialoguer et iterer\n",
    "4. **Strategies configurables** - Selection et terminaison sont personnalisables\n",
    "5. **OpenAIAssistantAgent pour les cas avances** - Code Interpreter et RAG integres\n",
    "\n",
    "## Exercice suggere\n",
    "\n",
    "Creez un groupe de 2 agents :\n",
    "- **Researcher** : Recherche des informations (simule avec un plugin)\n",
    "- **Writer** : Redige un article base sur les recherches\n",
    "\n",
    "```python\n",
    "# Squelette de depart\n",
    "class ResearchPlugin:\n",
    "    @kernel_function(description=\"Recherche sur un sujet\")\n",
    "    def search(self, topic: str) -> str:\n",
    "        return f\"Resultats de recherche pour: {topic}...\"\n",
    "\n",
    "# A vous de creer les agents et le group chat !\n",
    "```\n",
    "\n",
    "## Pour aller plus loin\n",
    "\n",
    "| Notebook | Contenu |\n",
    "|----------|---------|\n",
    "| [04-Filters](04-SemanticKernel-Filters-Observability.ipynb) | Intercepter et modifier les appels |\n",
    "| [05-VectorStores](05-SemanticKernel-VectorStores.ipynb) | RAG avec Qdrant |\n",
    "| [05-NotebookMaker](05-NotebookMaker.ipynb) | Systeme 3-agents en production |\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation** : [<< 02-Functions](02-SemanticKernel-Advanced.ipynb) | [Index](README.md) | [04-Filters >>](04-SemanticKernel-Filters-Observability.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.447265,
   "end_time": "2026-02-04T07:07:48.314932",
   "environment_variables": {},
   "exception": null,
   "input_path": "03-SemanticKernel-Agents.ipynb",
   "output_path": "03-SemanticKernel-Agents.ipynb",
   "parameters": {},
   "start_time": "2026-02-04T07:07:30.867667",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}