{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb171a6",
   "metadata": {
    "papermill": {
     "duration": 0.003189,
     "end_time": "2026-02-04T07:07:31.960139",
     "exception": false,
     "start_time": "2026-02-04T07:07:31.956950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SK-3-Agents : Agent Framework Semantic Kernel\n",
    "\n",
    "**Navigation** : [<< 02-Functions](02-SemanticKernel-Advanced.ipynb) | [Index](README.md) | [04-Filters >>](04-SemanticKernel-Filters-Observability.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs d'apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous saurez :\n",
    "1. Creer un **ChatCompletionAgent** simple avec instructions\n",
    "2. Integrer des **plugins** avec Function Calling automatique\n",
    "3. Orchestrer plusieurs agents via **AgentGroupChat**\n",
    "4. Definir des **strategies de terminaison** personnalisees\n",
    "5. Comprendre les bases d'**OpenAIAssistantAgent** (Code Interpreter, File Search)\n",
    "\n",
    "### Prerequis\n",
    "\n",
    "- Python 3.10+\n",
    "- Notebooks 01 et 02 completes\n",
    "- Cle API OpenAI configuree (`.env`)\n",
    "\n",
    "### Duree estimee : 55 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Sommaire\n",
    "\n",
    "| Section | Contenu | Concepts cles |\n",
    "|---------|---------|---------------|\n",
    "| 1 | Installation | semantic-kernel, imports |\n",
    "| 2 | Agent Simple | ChatCompletionAgent, instructions, invoke |\n",
    "| 3 | Agent + Plugins | MenuPlugin, FunctionChoiceBehavior.Auto() |\n",
    "| 4 | Group Chat | AgentGroupChat, TerminationStrategy |\n",
    "| 5 | OpenAIAssistantAgent | Code Interpreter, File Search, Threads |\n",
    "| 6 | Conclusion | Resume, exercices, navigation |\n",
    "\n",
    "> **Qu'est-ce que l'Agent Framework ?** Introduit avec SK 1.0, il permet de creer des agents autonomes capables de raisonner, utiliser des outils, et collaborer entre eux. C'est l'evolution naturelle des plugins vers des entites plus intelligentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c8e9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:31.965044Z",
     "iopub.status.busy": "2026-02-04T07:07:31.964641Z",
     "iopub.status.idle": "2026-02-04T07:07:33.081010Z",
     "shell.execute_reply": "2026-02-04T07:07:33.080547Z"
    },
    "papermill": {
     "duration": 1.119647,
     "end_time": "2026-02-04T07:07:33.081657",
     "exception": false,
     "start_time": "2026-02-04T07:07:31.962010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Configuration chargee:\n",
      "  - API Key: OK\n",
      "  - Modele: gpt-4o\n",
      "semantic-kernel installe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\jsboi\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Bloc 1 : Installation semantic-kernel et imports\n",
    "# ============================\n",
    "\n",
    "# A n'executer qu'une fois\n",
    "%pip install semantic-kernel python-dotenv --quiet\n",
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Chargement du fichier .env (cles API)\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Verification de la configuration\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_id = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-4o\")\n",
    "print(f\"Configuration chargee:\")\n",
    "print(f\"  - API Key: {'OK' if api_key else 'MANQUANTE'}\")\n",
    "print(f\"  - Modele: {model_id}\")\n",
    "print(\"semantic-kernel installe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w26cdtzp6e",
   "metadata": {
    "papermill": {
     "duration": 0.001784,
     "end_time": "2026-02-04T07:07:33.085290",
     "exception": false,
     "start_time": "2026-02-04T07:07:33.083506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Installation et imports\n",
    "\n",
    "Cette cellule installe le SDK Semantic Kernel et importe les modules necessaires pour creer des agents conversationnels.\n",
    "\n",
    "**Concepts cles** :\n",
    "- `ChatCompletionAgent` : Un agent base sur un modele de chat completion\n",
    "- `AgentGroupChat` : Orchestrateur pour faire collaborer plusieurs agents\n",
    "- `ChatHistory` : Historique de conversation partage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cefe0",
   "metadata": {
    "papermill": {
     "duration": 0.001605,
     "end_time": "2026-02-04T07:07:33.088420",
     "exception": false,
     "start_time": "2026-02-04T07:07:33.086815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bloc 2 : Simple Agent (Parrot)\n",
    "\n",
    "Nous créons un agent tout simple, qui répète le message de l’utilisateur sur le ton d’un pirate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd991043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:33.092525Z",
     "iopub.status.busy": "2026-02-04T07:07:33.092316Z",
     "iopub.status.idle": "2026-02-04T07:07:36.382523Z",
     "shell.execute_reply": "2026-02-04T07:07:36.381903Z"
    },
    "papermill": {
     "duration": 3.293163,
     "end_time": "2026-02-04T07:07:36.383128",
     "exception": false,
     "start_time": "2026-02-04T07:07:33.089965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'Fortune favors the bold.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - Parrot: 'Fortune be favorin' the bold, me hearty! Arrr!'\n",
      "# User: 'I came, I saw, I conquered.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - Parrot: 'I came, I saw, I conquered, says ye captain! Arrr!'\n",
      "# User: 'Practice makes perfect.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - Parrot: 'Practice makes perfect, me matey! Arrr!'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "AGENT_NAME = \"Parrot\"\n",
    "AGENT_INSTRUCTIONS = \"You are a helpful parrot that repeats the user message in a pirate voice, then ends with 'Arrr!'\"\n",
    "\n",
    "# Création du Kernel\n",
    "kernel = Kernel()\n",
    "# On suppose que vous avez défini ou récupéré des clés d'API :\n",
    "# kernel.add_service(OpenAIChatCompletion(...)) ou AzureChatCompletion(...)\n",
    "kernel.add_service(OpenAIChatCompletion(service_id=\"agent\"))\n",
    "\n",
    "agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=AGENT_NAME,\n",
    "    instructions=AGENT_INSTRUCTIONS\n",
    ")\n",
    "user_inputs = [\n",
    "    \"Fortune favors the bold.\",\n",
    "    \"I came, I saw, I conquered.\",\n",
    "    \"Practice makes perfect.\",\n",
    "]\n",
    "\n",
    "async def simple_agent_demo():\n",
    "    chat_history = ChatHistory()\n",
    "    # On ajoute les instructions de l'agent en tant que 'developer' ou 'system'\n",
    "    chat_history.add_developer_message(AGENT_INSTRUCTIONS)\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        chat_history.add_user_message(user_input)\n",
    "        print(f\"# User: '{user_input}'\")\n",
    "        async for content in agent.invoke(chat_history):\n",
    "            # CORRECTION DÉFINITIVE : Toujours utiliser add_assistant_message\n",
    "            # L'API SemanticKernel agents retourne des objets incompatibles avec add_message()\n",
    "            if hasattr(content, 'content'):\n",
    "                # Extraire le contenu et le convertir en string\n",
    "                content_str = str(content.content) if content.content else str(content)\n",
    "                chat_history.add_assistant_message(content_str)\n",
    "                print(f\"# Agent - {content.name or AGENT_NAME}: '{content_str}'\")\n",
    "            else:\n",
    "                # Fallback: convertir tout l'objet en string\n",
    "                content_str = str(content)\n",
    "                chat_history.add_assistant_message(content_str)\n",
    "                print(f\"# Agent - {AGENT_NAME}: '{content_str}'\")\n",
    "\n",
    "await simple_agent_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jz45a5u7dzp",
   "source": "### Interprétation : Anatomie d'un Agent Simple\n\n**Sortie obtenue** : L'agent Parrot transforme 3 proverbes en voix de pirate avec la signature \"Arrr!\"\n\n| Aspect | Valeur | Signification |\n|--------|--------|---------------|\n| **Instructions** | \"repeat in a pirate voice\" | Définit la personnalité de l'agent |\n| **Invocation** | `agent.invoke(chat_history)` | Traite les messages de manière asynchrone |\n| **Streaming** | `async for content in ...` | Réception progressive des tokens |\n| **Historique** | `ChatHistory()` | Maintient le contexte conversationnel |\n\n**Points clés** :\n\n1. **Séparation des responsabilités** : Le Kernel fournit les services (modèle LLM), l'agent ajoute la logique comportementale\n2. **Instructions = System Message** : Les instructions sont injectées comme message développeur, invisibles pour l'utilisateur\n3. **Asynchrone par défaut** : SK utilise `async/await` pour toutes les opérations I/O (appels API)\n4. **Historique explicite** : Contrairement à l'API OpenAI brute, SK gère l'historique via `ChatHistory`\n\n**Composants d'initialisation** :\n\n```python\nKernel() ─→ add_service(OpenAIChatCompletion) ─→ ChatCompletionAgent(kernel, instructions)\n```\n\n**Note technique** : La correction `add_assistant_message()` est nécessaire car `invoke()` retourne des objets `StreamingChatMessageContent` incompatibles avec `add_message()` générique.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "gw9dqp9zmu",
   "metadata": {
    "papermill": {
     "duration": 0.00162,
     "end_time": "2026-02-04T07:07:36.391137",
     "exception": false,
     "start_time": "2026-02-04T07:07:36.389517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Execution de l'agent Parrot\n",
    "\n",
    "L'agent \"Parrot\" illustre le cas le plus simple :\n",
    "- **Instructions systeme** : Definissent le comportement (repeter en voix de pirate)\n",
    "- **Invocation** : Chaque message utilisateur est transforme par l'agent\n",
    "- **Historique** : Les reponses sont ajoutees a `ChatHistory` pour le contexte\n",
    "\n",
    "**Point technique** : La methode `invoke()` est asynchrone et retourne un flux (streaming) de contenus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f12a31",
   "metadata": {
    "papermill": {
     "duration": 0.001624,
     "end_time": "2026-02-04T07:07:36.396444",
     "exception": false,
     "start_time": "2026-02-04T07:07:36.394820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bloc 3 : Agent simple avec Plugins\n",
    "\n",
    "Exemple de plugin `MenuPlugin`, et agent unique qui répond en utilisant ces fonctions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1546a45e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:36.400629Z",
     "iopub.status.busy": "2026-02-04T07:07:36.400434Z",
     "iopub.status.idle": "2026-02-04T07:07:42.567818Z",
     "shell.execute_reply": "2026-02-04T07:07:42.567348Z"
    },
    "papermill": {
     "duration": 6.170561,
     "end_time": "2026-02-04T07:07:42.568509",
     "exception": false,
     "start_time": "2026-02-04T07:07:36.397948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'Hello'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Host: 'Hi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " there"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " assist"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " today"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "# User: 'What is the special soup?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Host: 'get_specials called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " special"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " soup"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chow"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Would"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " know"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anything"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " else"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " menu"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "# User: 'What does it cost?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Host: 'get_item_price called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chow"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " priced"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " at"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " $"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Would"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " know"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anything"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " else"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "# User: 'Thanks'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Host: 'You're"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " welcome"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " If"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " have"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " any"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " questions"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " feel"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " free"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ask"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enjoy"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " day"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import TYPE_CHECKING, Annotated\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import KernelArguments, kernel_function\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "class MenuPlugin:\n",
    "    \"\"\"Plugin pour gérer un menu\"\"\"\n",
    "    @kernel_function(description=\"Liste les specials\")\n",
    "    def get_specials(self) -> Annotated[str, \"Describes specials\"]:\n",
    "        # print function call\n",
    "        print(\"get_specials called\")\n",
    "        return \"Special Soup: Clam Chowder\\nSpecial Salad: Cobb Salad\\nSpecial Drink: Chai Tea\"\n",
    "    @kernel_function(description=\"Donne le prix d'un item\")\n",
    "    def get_item_price(self, menu_item: Annotated[str, \"nom de l'item\"]) -> str:\n",
    "         # print function call\n",
    "        print(\"get_item_price called\")\n",
    "        return \"$9.99\"\n",
    "# Créer kernel\n",
    "kernel2 = Kernel()\n",
    "# Ajout du plugin\n",
    "kernel2.add_plugin(MenuPlugin(), plugin_name=\"menu\")\n",
    "# Ajout du service\n",
    "kernel2.add_service(OpenAIChatCompletion(service_id=\"agent2\"))\n",
    "# On configure l'auto function-calling\n",
    "settings2 = kernel2.get_prompt_execution_settings_from_service_id(service_id=\"agent2\")\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "settings2.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "AGENT2_NAME = \"Host\"\n",
    "AGENT2_INSTRUCTIONS = \"Answer questions about the menu.\"\n",
    "agent2 = ChatCompletionAgent(\n",
    "    kernel=kernel2,\n",
    "    name=AGENT2_NAME,\n",
    "    instructions=AGENT2_INSTRUCTIONS,\n",
    "    arguments=KernelArguments(settings=settings2),\n",
    ")\n",
    "async def plugin_agent_demo():\n",
    "    chat_history = ChatHistory()\n",
    "    user_msgs = [\n",
    "        \"Hello\",\n",
    "        \"What is the special soup?\",\n",
    "        \"What does it cost?\",\n",
    "        \"Thanks\",\n",
    "    ]\n",
    "    for user_input in user_msgs:\n",
    "        chat_history.add_user_message(user_input)\n",
    "        print(f\"# User: '{user_input}'\")\n",
    "        agent_name = None\n",
    "        full_response = \"\"  # Accumulateur pour la réponse complète\n",
    "        \n",
    "        async for content in agent2.invoke_stream(chat_history):\n",
    "            if not agent_name:\n",
    "                agent_name = content.name or AGENT2_NAME\n",
    "                print(f\"# {agent_name}: '\", end=\"\")\n",
    "            \n",
    "            # CORRECTION: Gestion appropriée du StreamingChatMessageContent\n",
    "            if hasattr(content, 'content'):\n",
    "                # Conversion sécurisée du contenu\n",
    "                content_str = str(content.content) if content.content else \"\"\n",
    "                # Accumulation de la réponse\n",
    "                full_response += content_str\n",
    "                # Affichage incrémental\n",
    "                if content_str:\n",
    "                    print(content_str, end=\"\", flush=True)\n",
    "        \n",
    "        print(\"'\")\n",
    "        \n",
    "        # Ajout sécurisé du message complet à l'historique\n",
    "        if full_response:\n",
    "            chat_history.add_assistant_message(full_response)\n",
    "        else:\n",
    "            # Si pas de contenu, ajouter un message par défaut\n",
    "            chat_history.add_assistant_message(\"[No response generated]\")\n",
    "\n",
    "await plugin_agent_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0qofoa5suu",
   "source": "### Interprétation : Function Calling Automatique (ReAct Pattern)\n\n**Sortie obtenue** : L'agent Host répond aux questions sur le menu en appelant automatiquement les bonnes fonctions du plugin\n\n| Question | Fonction appelée | Résultat |\n|----------|------------------|----------|\n| \"What is the special soup?\" | `get_specials()` | Liste des spéciaux → extraction \"Clam Chowder\" |\n| \"What does it cost?\" | `get_item_price(\"Clam Chowder\")` | \"$9.99\" (contexte conservé) |\n| \"Hello\" / \"Thanks\" | Aucune | Réponse conversationnelle directe |\n\n**Architecture du ReAct Pattern (Reasoning + Acting)** :\n\n```\nUser: \"What is the special soup?\"\n    ↓\n┌──────────────────────────────────────────────┐\n│         LLM (gpt-4o)                         │\n│  1. Analyse la question                      │\n│  2. Identifie la fonction: get_specials()    │\n│  3. Appel de fonction (tool call)            │\n└──────────────────────────────────────────────┘\n    ↓\n┌──────────────────────────────────────────────┐\n│         MenuPlugin.get_specials()            │\n│  Retourne: \"Special Soup: Clam Chowder...\"   │\n└──────────────────────────────────────────────┘\n    ↓\n┌──────────────────────────────────────────────┐\n│         LLM (gpt-4o)                         │\n│  4. Synthétise: \"The special soup is...\"     │\n└──────────────────────────────────────────────┘\n```\n\n**Comparaison avec les Plugins simples** :\n\n| Aspect | Plugin sans Agent | Agent + Plugin |\n|--------|-------------------|----------------|\n| Appel de fonction | Manuel (`kernel.invoke(\"plugin-func\")`) | Automatique (LLM décide) |\n| Extraction paramètres | Développeur spécifie | LLM extrait du contexte |\n| Contexte conversationnel | Absent | Conservé dans ChatHistory |\n| Raisonnement | Aucun | LLM raisonne avant d'agir |\n\n**Points clés** :\n\n1. **FunctionChoiceBehavior.Auto()** : Active le mode \"tool use\" du LLM (équivalent à `tools` dans l'API OpenAI brute)\n2. **Inférence de paramètres** : Le LLM extrait \"Clam Chowder\" du contexte précédent pour `get_item_price()`\n3. **Transparence** : Les appels de fonction sont invisibles pour l'utilisateur final\n4. **Streaming multi-phases** : Le flux contient à la fois les tool calls et la réponse textuelle finale\n\n**Note technique** : Le pattern `invoke_stream()` + accumulation de `full_response` permet d'afficher progressivement la réponse tout en maintenant l'historique complet.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "2fe75ad9",
   "metadata": {
    "papermill": {
     "duration": 0.003499,
     "end_time": "2026-02-04T07:07:42.575692",
     "exception": false,
     "start_time": "2026-02-04T07:07:42.572193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Analyse des appels de fonction automatiques\n",
    "\n",
    "Dans l'execution ci-dessus, observez la sequence d'appels :\n",
    "\n",
    "1. **User** : \"What is the special soup?\"\n",
    "2. **Agent interne** : Appelle `get_specials()` (affiche \"get_specials called\")\n",
    "3. **Agent repond** : \"The special soup is Clam Chowder\"\n",
    "4. **User** : \"What does it cost?\"\n",
    "5. **Agent interne** : Appelle `get_item_price(\"Clam Chowder\")` (affiche \"get_item_price called\")\n",
    "6. **Agent repond** : \"It costs $9.99\"\n",
    "\n",
    "Le parametre `FunctionChoiceBehavior.Auto()` permet a l'agent de :\n",
    "- Analyser la question de l'utilisateur\n",
    "- Determiner quelle fonction appeler\n",
    "- Extraire les parametres (ex: \"Clam Chowder\")\n",
    "- Integrer le resultat dans sa reponse\n",
    "\n",
    "C'est la base du **ReAct pattern** (Reasoning + Acting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p17wlpq5mr",
   "metadata": {
    "papermill": {
     "duration": 0.00327,
     "end_time": "2026-02-04T07:07:42.582492",
     "exception": false,
     "start_time": "2026-02-04T07:07:42.579222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Execution de l'agent avec plugins\n",
    "\n",
    "Le plugin `MenuPlugin` expose des fonctions que l'agent peut appeler automatiquement :\n",
    "- `get_specials()` : Retourne les plats du jour\n",
    "- `get_item_price()` : Retourne le prix d'un article\n",
    "\n",
    "**Function Calling Auto** : Le parametre `FunctionChoiceBehavior.Auto()` permet a l'agent de decider lui-meme quand appeler ces fonctions en fonction du contexte de la conversation.\n",
    "\n",
    "Observez les appels `get_specials called` et `get_item_price called` dans la sortie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88566ce4",
   "metadata": {
    "papermill": {
     "duration": 0.003154,
     "end_time": "2026-02-04T07:07:42.588822",
     "exception": false,
     "start_time": "2026-02-04T07:07:42.585668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bloc 4 : Group Chat\n",
    "\n",
    "Exemple d'un chat groupé : un agent CopyWriter, un agent ArtDirector, etc. On utilise la `AgentGroupChat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e10355e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:07:42.596554Z",
     "iopub.status.busy": "2026-02-04T07:07:42.596326Z",
     "iopub.status.idle": "2026-02-04T07:07:47.823995Z",
     "shell.execute_reply": "2026-02-04T07:07:47.823025Z"
    },
    "papermill": {
     "duration": 5.232284,
     "end_time": "2026-02-04T07:07:47.824564",
     "exception": false,
     "start_time": "2026-02-04T07:07:42.592280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'I need a slogan for a new line of electric bikes'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - ArtDirector: 'Sure! Here's a suggestion: \"Ride the Future: Electrify Your Journey\"\n",
      "\n",
      "If you like the direction but want something tweaked, let me know!'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - CopyWriter: 'Sure! How about this: \"Unleash the Power of Green: Ride Beyond\"'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - ArtDirector: 'Sure! Here's a suggestion: \"Ride the Future: Electrify Your Journey\"\n",
      "\n",
      "If you like the direction but want something tweaked, let me know!'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - CopyWriter: '\"Unchain Your Commute: Ride the Electric Revolution.\"'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - ArtDirector: 'I’m looking for a tagline for our organic skincare line.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Agent - CopyWriter: '\"Purely You: Embrace Nature's Glow.\"'\n",
      "# IS COMPLETE: False\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from semantic_kernel.agents import AgentGroupChat, ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import AuthorRole, ChatMessageContent\n",
    "from semantic_kernel.agents.strategies import TerminationStrategy\n",
    "from semantic_kernel import Kernel\n",
    "\n",
    "class ApprovalTerminationStrategy(TerminationStrategy):\n",
    "    async def should_agent_terminate(self, agent, history):\n",
    "        return \"approved\" in history[-1].content.lower()\n",
    "\n",
    "# On crée un kernel par agent, ou le même kernel + service differencié.\n",
    "def create_kernel_for(name):\n",
    "    k = Kernel()\n",
    "    # on admet qu'on a paramétré un service openAI.\n",
    "    k.add_service(OpenAIChatCompletion(service_id=name))\n",
    "    return k\n",
    "\n",
    "REVIEWER_NAME = \"ArtDirector\"\n",
    "REVIEWER_INSTRUCTIONS = \"You are an art director. If the copy is good, say 'Approved'. Otherwise, propose improvements.\"\n",
    "reviewer_agent = ChatCompletionAgent(\n",
    "    kernel=create_kernel_for(REVIEWER_NAME),\n",
    "    name=REVIEWER_NAME,\n",
    "    instructions=REVIEWER_INSTRUCTIONS,\n",
    ")\n",
    "COPYWRITER_NAME = \"CopyWriter\"\n",
    "COPYWRITER_INSTRUCTIONS = \"You are a copywriter. Provide short but strong marketing copy.\"\n",
    "writer_agent = ChatCompletionAgent(\n",
    "    kernel=create_kernel_for(COPYWRITER_NAME),\n",
    "    name=COPYWRITER_NAME,\n",
    "    instructions=COPYWRITER_INSTRUCTIONS,\n",
    ")\n",
    "group_chat = AgentGroupChat(\n",
    "    agents=[reviewer_agent, writer_agent],\n",
    "    termination_strategy=ApprovalTerminationStrategy(agents=[reviewer_agent], maximum_iterations=6)\n",
    ")\n",
    "\n",
    "async def group_chat_demo():\n",
    "    user_msg = \"I need a slogan for a new line of electric bikes\"\n",
    "    await group_chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_msg))\n",
    "    print(f\"# User: '{user_msg}'\")\n",
    "    async for content in group_chat.invoke():\n",
    "        # Gestion sécurisée du contenu pour éviter ContentInitializationError\n",
    "        if hasattr(content, 'content') and content.content:\n",
    "            print(f\"# Agent - {content.name or '*'}: '{content.content}'\")\n",
    "        else:\n",
    "            print(f\"# Agent - {content.name or '*'}: '{str(content)}'\")\n",
    "\n",
    "    print(f\"# IS COMPLETE: {group_chat.is_complete}\")\n",
    "\n",
    "await group_chat_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iunechkbmin",
   "source": "### Interprétation : Orchestration Multi-Agents et Stratégies\n\n**Sortie obtenue** : Dialogue itératif entre CopyWriter (propose des slogans) et ArtDirector (critique), mais **incomplet** (`is_complete=False`)\n\n| Itération | Agent | Message | État |\n|-----------|-------|---------|------|\n| 1 | ArtDirector | \"Ride the Future: Electrify Your Journey\" | Suggestion initiale |\n| 2 | CopyWriter | \"Unleash the Power of Green: Ride Beyond\" | Proposition |\n| 3 | ArtDirector | (répète slogan #1) | Problème de contexte |\n| 4 | CopyWriter | \"Unchain Your Commute...\" | Nouvelle proposition |\n| 5 | ArtDirector | \"I'm looking for organic skincare\" | **Dérapage** (hors sujet) |\n| 6 | CopyWriter | \"Purely You: Embrace Nature's Glow\" | Répond au dérapage |\n\n**Analyse du problème de terminaison** :\n\n```\nApprovalTerminationStrategy attend \"approved\" dans le message\n    ↓\nAucun message ne contient \"approved\"\n    ↓\nMaximum 6 itérations atteint → STOP (sans validation)\n    ↓\nis_complete = False (terminaison par limite, pas par succès)\n```\n\n**Comparaison des stratégies de terminaison** :\n\n| Stratégie | Condition de succès | Cas d'échec |\n|-----------|---------------------|-------------|\n| **ApprovalTerminationStrategy** | Mot-clé \"approved\" détecté | Itérations épuisées sans mot-clé |\n| **DefaultTerminationStrategy** | Toujours success à la limite | Aucun (accepte l'état final) |\n| **KernelFunctionTerminationStrategy** | LLM juge l'objectif atteint | LLM désynchronisé du contexte |\n| **AggregatorTerminationStrategy** | ALL/ANY conditions remplies | Conditions contradictoires |\n\n**Flux d'orchestration AgentGroupChat** :\n\n```\n┌─────────────────────────────────────────────────────────┐\n│              AgentGroupChat                             │\n│  ┌────────────────────┐  ┌────────────────────────┐    │\n│  │ SelectionStrategy  │  │ TerminationStrategy    │    │\n│  │ (qui parle ?)      │  │ (quand arrêter ?)      │    │\n│  └────────────────────┘  └────────────────────────┘    │\n│           ↓                        ↓                    │\n│  ┌──────────────────────────────────────────────┐      │\n│  │  Invoke Loop                                 │      │\n│  │  1. Sélectionne agent (ex: round-robin)     │      │\n│  │  2. Agent génère réponse                     │      │\n│  │  3. Ajoute à l'historique                    │      │\n│  │  4. Vérifie terminaison                      │      │\n│  │  5. Si non-terminé → retour à 1              │      │\n│  └──────────────────────────────────────────────┘      │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Points clés** :\n\n1. **Limite d'itérations cruciale** : Sans `maximum_iterations`, risque de boucle infinie si le mot-clé n'apparaît jamais\n2. **Prompt engineering pour terminaison** : Les instructions de l'ArtDirector devraient explicitement mentionner \"Say 'Approved' when satisfied\"\n3. **Dérapage de contexte** : L'itération 5 montre que les agents peuvent perdre le fil (problème connu avec les longs historiques)\n4. **is_complete vs succès** : `False` signifie que la stratégie n'a pas validé, pas nécessairement un échec fonctionnel\n\n**Améliorations possibles** :\n\n```python\n# Instructions plus explicites\nREVIEWER_INSTRUCTIONS = \"\"\"You are an art director. \nReview the copywriter's slogan. If it's good, respond with exactly 'APPROVED'.\nOtherwise, suggest ONE specific improvement.\"\"\"\n\n# Stratégie hybride\nclass HybridTerminationStrategy(TerminationStrategy):\n    async def should_agent_terminate(self, agent, history):\n        last_msg = history[-1].content.lower()\n        # Condition 1: Mot-clé explicite\n        if \"approved\" in last_msg:\n            return True\n        # Condition 2: LLM juge l'objectif atteint\n        judgment = await llm_judge(history, objective=\"Create bike slogan\")\n        return judgment == \"SUCCESS\"\n```\n\n**Cas d'usage production** : Le notebook [05-NotebookMaker](05-NotebookMaker.ipynb) implémente un système 3-agents (Admin, Coder, Reviewer) avec stratégies robustes pour éviter ces problèmes.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "0f3pf1gsiqf4",
   "metadata": {
    "papermill": {
     "duration": 0.003505,
     "end_time": "2026-02-04T07:07:47.839182",
     "exception": false,
     "start_time": "2026-02-04T07:07:47.835677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bloc 5 : OpenAIAssistantAgent (Apercu)\n",
    "\n",
    "L'API Assistants d'OpenAI offre des capacites avancees que `ChatCompletionAgent` n'a pas nativement :\n",
    "\n",
    "| Fonctionnalite | Description | Cas d'usage |\n",
    "|----------------|-------------|-------------|\n",
    "| **Code Interpreter** | Execute du Python dans un sandbox | Calculs, graphiques, analyse de donnees |\n",
    "| **File Search** | RAG integre sur fichiers uploades | Questions sur documents PDF, DOCX |\n",
    "| **Threads persistants** | Historique conserve cote serveur | Conversations longues, reprise de session |\n",
    "\n",
    "### Architecture OpenAIAssistantAgent\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────┐\n",
    "│          OpenAIAssistantAgent               │\n",
    "│  ┌─────────────────────────────────────┐   │\n",
    "│  │         OpenAI Assistants API       │   │\n",
    "│  │  ┌───────────┐  ┌───────────────┐  │   │\n",
    "│  │  │   Code    │  │  File Search  │  │   │\n",
    "│  │  │Interpreter│  │  (RAG integre)│  │   │\n",
    "│  │  └───────────┘  └───────────────┘  │   │\n",
    "│  │         ↓              ↓           │   │\n",
    "│  │       Thread (persistent state)    │   │\n",
    "│  └─────────────────────────────────────┘   │\n",
    "└─────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Exemple conceptuel (non execute)\n",
    "\n",
    "```python\n",
    "from semantic_kernel.agents.open_ai import OpenAIAssistantAgent\n",
    "\n",
    "# Creation de l'agent avec Code Interpreter\n",
    "agent = await OpenAIAssistantAgent.create(\n",
    "    kernel=kernel,\n",
    "    name=\"DataAnalyst\",\n",
    "    instructions=\"Tu es un analyste de donnees. Utilise Python pour les calculs.\",\n",
    "    enable_code_interpreter=True,\n",
    "    enable_file_search=True\n",
    ")\n",
    "\n",
    "# Creation d'un thread (session persistante)\n",
    "thread = await agent.create_thread()\n",
    "\n",
    "# Ajout d'un fichier pour analyse\n",
    "await agent.add_file(thread_id=thread.id, file_path=\"data.csv\")\n",
    "\n",
    "# Invocation avec contexte fichier\n",
    "response = await agent.invoke(thread_id=thread.id, message=\"Analyse ce CSV et genere un graphique\")\n",
    "```\n",
    "\n",
    "**Points cles** :\n",
    "- `enable_code_interpreter=True` : L'agent peut executer du Python\n",
    "- `enable_file_search=True` : L'agent peut rechercher dans les fichiers\n",
    "- `thread` : Session persistante cote OpenAI (pas de `ChatHistory` local)\n",
    "- Les fichiers sont uploades vers OpenAI et indexes automatiquement\n",
    "\n",
    "> **Note** : Cette API necessite un compte OpenAI avec acces aux Assistants (payant). Pour des alternatives locales, voir les Vector Stores dans le [notebook 05](05-SemanticKernel-VectorStores.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87unbuhefim",
   "metadata": {
    "papermill": {
     "duration": 0.003343,
     "end_time": "2026-02-04T07:07:47.846228",
     "exception": false,
     "start_time": "2026-02-04T07:07:47.842885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Execution du Group Chat\n",
    "\n",
    "Le `AgentGroupChat` orchestre plusieurs agents qui collaborent :\n",
    "- **ArtDirector** : Valide ou demande des ameliorations du texte\n",
    "- **CopyWriter** : Propose du contenu marketing\n",
    "\n",
    "**Strategie de terminaison** : La classe `ApprovalTerminationStrategy` arrete la conversation quand l'ArtDirector dit \"approved\". Cela illustre comment definir des conditions d'arret personnalisees.\n",
    "\n",
    "La limite `maximum_iterations=6` protege contre les boucles infinies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910fffa7",
   "metadata": {
    "papermill": {
     "duration": 0.003333,
     "end_time": "2026-02-04T07:07:47.853094",
     "exception": false,
     "start_time": "2026-02-04T07:07:47.849761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "## Resume des concepts\n",
    "\n",
    "| Concept | Description | Code cle |\n",
    "|---------|-------------|----------|\n",
    "| **ChatCompletionAgent** | Agent de base SK | `ChatCompletionAgent(kernel, name, instructions)` |\n",
    "| **Instructions** | Personnalite de l'agent | Message systeme definissant le comportement |\n",
    "| **Plugins + Agent** | Outils pour l'agent | `FunctionChoiceBehavior.Auto()` |\n",
    "| **AgentGroupChat** | Orchestration multi-agents | `AgentGroupChat(agents, termination_strategy)` |\n",
    "| **TerminationStrategy** | Condition d'arret | `ApprovalTerminationStrategy`, custom |\n",
    "| **OpenAIAssistantAgent** | API Assistants | Code Interpreter, File Search, Threads |\n",
    "\n",
    "## Points cles a retenir\n",
    "\n",
    "1. **Un agent = Kernel + Instructions** - Le Kernel fournit les capacites, les instructions definissent le comportement\n",
    "2. **Function Calling automatique** - `FunctionChoiceBehavior.Auto()` permet a l'agent de decider quand utiliser les outils\n",
    "3. **AgentGroupChat pour la collaboration** - Plusieurs agents peuvent dialoguer et iterer\n",
    "4. **Strategies configurables** - Selection et terminaison sont personnalisables\n",
    "5. **OpenAIAssistantAgent pour les cas avances** - Code Interpreter et RAG integres\n",
    "\n",
    "## Exercice suggere\n",
    "\n",
    "Creez un groupe de 2 agents :\n",
    "- **Researcher** : Recherche des informations (simule avec un plugin)\n",
    "- **Writer** : Redige un article base sur les recherches\n",
    "\n",
    "```python\n",
    "# Squelette de depart\n",
    "class ResearchPlugin:\n",
    "    @kernel_function(description=\"Recherche sur un sujet\")\n",
    "    def search(self, topic: str) -> str:\n",
    "        return f\"Resultats de recherche pour: {topic}...\"\n",
    "\n",
    "# A vous de creer les agents et le group chat !\n",
    "```\n",
    "\n",
    "## Pour aller plus loin\n",
    "\n",
    "| Notebook | Contenu |\n",
    "|----------|---------|\n",
    "| [04-Filters](04-SemanticKernel-Filters-Observability.ipynb) | Intercepter et modifier les appels |\n",
    "| [05-VectorStores](05-SemanticKernel-VectorStores.ipynb) | RAG avec Qdrant |\n",
    "| [05-NotebookMaker](05-NotebookMaker.ipynb) | Systeme 3-agents en production |\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation** : [<< 02-Functions](02-SemanticKernel-Advanced.ipynb) | [Index](README.md) | [04-Filters >>](04-SemanticKernel-Filters-Observability.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doh8h45ycol",
   "source": "## Synthèse : Taxonomie Complète des Agents Semantic Kernel\n\n### 1. Types d'agents et leurs capacités\n\n| Type | Backend | Capacités natives | Persistance | Coût |\n|------|---------|-------------------|-------------|------|\n| **ChatCompletionAgent** | Chat Completion API | Streaming, Function Calling, Vision | Locale (ChatHistory) | Token/token |\n| **OpenAIAssistantAgent** | Assistants API | + Code Interpreter, File Search, Vector Store | Serveur (Threads) | Token + stockage |\n| **AzureAIAgent** | Azure AI Foundry | + Enterprise security, compliance | Azure Storage | Enterprise pricing |\n\n### 2. Patterns d'utilisation\n\n**Pattern 1 : Agent solo avec outils (ReAct)**\n\n```python\nAgent + Kernel(Plugins) + FunctionChoiceBehavior.Auto()\n    → Raisonne et agit de manière autonome\n```\n\n**Cas d'usage** : Chatbot avec accès à des APIs, assistant de recherche\n\n**Pattern 2 : Multi-agents collaboratifs (AutoGen-like)**\n\n```python\nAgentGroupChat([Agent1, Agent2, Agent3])\n    + SelectionStrategy (qui parle ?)\n    + TerminationStrategy (quand arrêter ?)\n    → Dialogue itératif jusqu'à validation\n```\n\n**Cas d'usage** : Peer review (Coder + Reviewer), brainstorming (Ideator + Critic), pipeline (Research → Write → Edit)\n\n**Pattern 3 : Agent avec état persistant (Assistants API)**\n\n```python\nOpenAIAssistantAgent + Thread (stocké serveur OpenAI)\n    → Conversations longues, reprise de session\n```\n\n**Cas d'usage** : Support client, tuteurs éducatifs, assistants personnels\n\n### 3. Composants clés de l'orchestration\n\n| Composant | Rôle | Options courantes |\n|-----------|------|-------------------|\n| **SelectionStrategy** | Qui parle ensuite ? | Sequential, KernelFunction, Custom |\n| **TerminationStrategy** | Quand arrêter ? | Approval, MaxIterations, KernelFunction, Aggregator |\n| **ChatHistory** | Contexte conversationnel | Partagé entre agents, trimming automatique |\n| **FunctionChoiceBehavior** | Quand utiliser les outils ? | Auto, Required, None |\n\n### 4. Pièges courants et solutions\n\n| Problème | Cause | Solution |\n|----------|-------|----------|\n| Boucle infinie | Pas de limite d'itérations | `maximum_iterations` dans TerminationStrategy |\n| Agent ne termine pas | Mot-clé \"approved\" jamais prononcé | Instructions explicites + prompt engineering |\n| Dérapage de contexte | Historique trop long | Trimming automatique (`max_tokens` dans ChatHistory) |\n| Tool calls ignorés | `FunctionChoiceBehavior` non configuré | Définir dans `KernelArguments` de l'agent |\n| StreamingChatMessageContent error | Mauvaise méthode d'ajout à l'historique | Utiliser `add_assistant_message(str(content.content))` |\n\n### 5. Progression recommandée\n\n```\n1. Agent simple (Parrot)\n    → Comprendre Instructions + Kernel + invoke()\n    \n2. Agent + Plugins (Menu)\n    → Maîtriser FunctionChoiceBehavior.Auto()\n    \n3. AgentGroupChat (CopyWriter + ArtDirector)\n    → Orchestrer des agents, gérer les stratégies\n    \n4. OpenAIAssistantAgent (Code Interpreter)\n    → Cas avancés : code execution, RAG intégré\n    \n5. Production (NotebookMaker)\n    → Système robuste 3+ agents avec gestion d'erreurs\n```\n\n### 6. Comparaison avec d'autres frameworks\n\n| Framework | Philosophie | Forces | Faiblesses |\n|-----------|-------------|--------|------------|\n| **Semantic Kernel** | \"Kernel-centric\" (services partagés) | Intégration .NET, plugins réutilisables | Moins mature qu'AutoGen |\n| **AutoGen** | \"Agent-centric\" (agents autonomes) | Patterns multi-agents éprouvés, communauté active | Principalement Python |\n| **LangGraph** | \"Graph-centric\" (workflows as graphs) | Contrôle fin, debugging visuel | Courbe d'apprentissage |\n| **CrewAI** | \"Role-centric\" (agents = métiers) | Abstractions haut niveau | Moins flexible |\n\n**Positionnement SK** : Meilleur choix pour écosystème Microsoft (.NET, Azure), plugins partagés entre agents, et migration progressive depuis des applications SK existantes.\n\n---\n\n**Prochaine étape** : [Notebook 04 - Filters & Observability](04-SemanticKernel-Filters-Observability.ipynb) pour instrumenter et intercepter les agents en production.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.447265,
   "end_time": "2026-02-04T07:07:48.314932",
   "environment_variables": {},
   "exception": null,
   "input_path": "03-SemanticKernel-Agents.ipynb",
   "output_path": "03-SemanticKernel-Agents.ipynb",
   "parameters": {},
   "start_time": "2026-02-04T07:07:30.867667",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}