{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {
    "papermill": {
     "duration": 0.003111,
     "end_time": "2026-02-19T09:29:27.212184",
     "exception": false,
     "start_time": "2026-02-19T09:29:27.209073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HunyuanVideo - Generation Video Haute Qualite\n",
    "\n",
    "**Module :** 02-Video-Advanced  \n",
    "**Niveau :** Intermediaire  \n",
    "**Technologies :** HunyuanVideo (Tencent, open-source), diffusers, bitsandbytes  \n",
    "**Duree estimee :** 60 minutes  \n",
    "**VRAM :** ~18 GB (avec quantification INT8)  \n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "- [ ] Comprendre l'architecture HunyuanVideo et ses avantages\n",
    "- [ ] Charger le modele avec quantification INT8 pour 24 GB VRAM\n",
    "- [ ] Generer des videos text-to-video avec des prompts detailles\n",
    "- [ ] Explorer les parametres de generation (steps, guidance_scale, num_frames, fps)\n",
    "- [ ] Controler la resolution et la duree des videos\n",
    "- [ ] Sauvegarder les resultats en MP4 avec imageio\n",
    "- [ ] Analyser la qualite et les metriques de generation\n",
    "\n",
    "## Prerequis\n",
    "\n",
    "- GPU avec 24 GB VRAM (RTX 3090 / RTX 4090)\n",
    "- Module 01-Foundation complete (notamment 01-5 AnimateDiff)\n",
    "- Packages : `diffusers>=0.32`, `transformers`, `torch`, `accelerate`, `bitsandbytes`, `imageio`, `imageio-ffmpeg`\n",
    "\n",
    "**Navigation :** [<< 01-5](../01-Foundation/01-5-AnimateDiff-Introduction.ipynb) | [Index](../README.md) | [Suivant >>](02-2-LTX-Video-Lightweight.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:27.219809Z",
     "iopub.status.busy": "2026-02-19T09:29:27.219270Z",
     "iopub.status.idle": "2026-02-19T09:29:27.225011Z",
     "shell.execute_reply": "2026-02-19T09:29:27.224258Z"
    },
    "papermill": {
     "duration": 0.011136,
     "end_time": "2026-02-19T09:29:27.226419",
     "exception": false,
     "start_time": "2026-02-19T09:29:27.215283",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parametres Papermill - JAMAIS modifier ce commentaire\n",
    "\n",
    "# Configuration notebook\n",
    "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
    "skip_widgets = False               # True pour mode batch MCP\n",
    "debug_level = \"INFO\"\n",
    "\n",
    "# Parametres modele\n",
    "model_id = \"tencent/HunyuanVideo\"  # Modele HunyuanVideo\n",
    "quantize = True                    # Quantification INT8 (recommande pour 24GB)\n",
    "device = \"cuda\"                    # Device de calcul\n",
    "\n",
    "# Parametres generation\n",
    "num_frames = 24                    # Nombre de frames a generer\n",
    "guidance_scale = 6.0               # CFG scale (adherence au prompt)\n",
    "num_inference_steps = 30           # Nombre d'etapes de debruitage\n",
    "height = 320                       # Hauteur video\n",
    "width = 512                        # Largeur video\n",
    "fps_output = 8                     # FPS de la video de sortie\n",
    "\n",
    "# Configuration\n",
    "run_generation = True              # Executer la generation\n",
    "save_as_mp4 = True                 # Sauvegarder en MP4\n",
    "save_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c54c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:27.232469Z",
     "iopub.status.busy": "2026-02-19T09:29:27.232054Z",
     "iopub.status.idle": "2026-02-19T09:29:27.235055Z",
     "shell.execute_reply": "2026-02-19T09:29:27.234449Z"
    },
    "papermill": {
     "duration": 0.007031,
     "end_time": "2026-02-19T09:29:27.235844",
     "exception": false,
     "start_time": "2026-02-19T09:29:27.228813",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "notebook_mode = \"batch\"\n",
    "skip_widgets = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:27.241714Z",
     "iopub.status.busy": "2026-02-19T09:29:27.241297Z",
     "iopub.status.idle": "2026-02-19T09:29:27.784103Z",
     "shell.execute_reply": "2026-02-19T09:29:27.783405Z"
    },
    "papermill": {
     "duration": 0.546923,
     "end_time": "2026-02-19T09:29:27.785069",
     "exception": false,
     "start_time": "2026-02-19T09:29:27.238146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HunyuanVideo - Generation Video Haute Qualite\n",
      "Date : 2026-02-19 10:29:27\n",
      "Mode : batch\n",
      "Frames : 24, Steps : 30, CFG : 6.0\n",
      "Quantification : INT8\n"
     ]
    }
   ],
   "source": [
    "# Setup environnement et imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Import helpers GenAI\n",
    "GENAI_ROOT = Path.cwd()\n",
    "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
    "    GENAI_ROOT = GENAI_ROOT.parent\n",
    "\n",
    "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
    "if HELPERS_PATH.exists():\n",
    "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
    "    try:\n",
    "        from helpers.genai_helpers import setup_genai_logging\n",
    "        print(\"Helpers GenAI importes\")\n",
    "    except ImportError:\n",
    "        print(\"Helpers GenAI non disponibles - mode autonome\")\n",
    "\n",
    "OUTPUT_DIR = GENAI_ROOT / 'outputs' / 'hunyuan_video'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=getattr(logging, debug_level))\n",
    "logger = logging.getLogger('hunyuan_video')\n",
    "\n",
    "print(f\"HunyuanVideo - Generation Video Haute Qualite\")\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Mode : {notebook_mode}\")\n",
    "print(f\"Frames : {num_frames}, Steps : {num_inference_steps}, CFG : {guidance_scale}\")\n",
    "print(f\"Quantification : {'INT8' if quantize else 'FP16'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:27.790477Z",
     "iopub.status.busy": "2026-02-19T09:29:27.790228Z",
     "iopub.status.idle": "2026-02-19T09:29:31.943484Z",
     "shell.execute_reply": "2026-02-19T09:29:31.942563Z"
    },
    "papermill": {
     "duration": 4.157906,
     "end_time": "2026-02-19T09:29:31.945233",
     "exception": false,
     "start_time": "2026-02-19T09:29:27.787327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucun fichier .env trouve\n",
      "\n",
      "--- VERIFICATION GPU ---\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA non disponible.\n",
      "HunyuanVideo necessite un GPU. Le notebook montrera le code sans executer.\n",
      "\n",
      "--- VERIFICATION DEPENDANCES ---\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffusers : v0.36.0\n",
      "transformers NON INSTALLE\n",
      "bitsandbytes NON INSTALLE (pip install bitsandbytes)\n",
      "  Quantification INT8 non disponible, FP16 sera utilise\n",
      "imageio : v2.37.2\n",
      "\n",
      "Dependances manquantes. Le notebook montrera le code sans executer.\n",
      "\n",
      "Device : cpu\n",
      "Generation activee : False\n",
      "Quantification : FP16\n"
     ]
    }
   ],
   "source": [
    "# Chargement .env et verification GPU\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_path = Path.cwd()\n",
    "found_env = False\n",
    "for _ in range(4):\n",
    "    env_path = current_path / '.env'\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"Fichier .env charge depuis : {env_path}\")\n",
    "        found_env = True\n",
    "        break\n",
    "    current_path = current_path.parent\n",
    "\n",
    "if not found_env:\n",
    "    print(\"Aucun fichier .env trouve\")\n",
    "\n",
    "# Verification GPU\n",
    "print(\"\\n--- VERIFICATION GPU ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    vram_total = torch.cuda.get_device_properties(0).total_mem / 1024**3\n",
    "    vram_free = (torch.cuda.get_device_properties(0).total_mem - torch.cuda.memory_allocated(0)) / 1024**3\n",
    "    \n",
    "    print(f\"GPU : {gpu_name}\")\n",
    "    print(f\"VRAM totale : {vram_total:.1f} GB\")\n",
    "    print(f\"VRAM libre : {vram_free:.1f} GB\")\n",
    "    print(f\"CUDA : {torch.version.cuda}\")\n",
    "    \n",
    "    if vram_total < 18:\n",
    "        print(f\"\\nAttention : VRAM ({vram_total:.0f} GB) < 18 GB recommandes\")\n",
    "        print(\"La quantification INT8 est fortement recommandee\")\n",
    "        quantize = True\n",
    "        if vram_total < 12:\n",
    "            height = 256\n",
    "            width = 384\n",
    "            num_frames = 16\n",
    "            print(f\"  Resolution reduite a {width}x{height}, {num_frames} frames\")\n",
    "else:\n",
    "    print(\"CUDA non disponible.\")\n",
    "    print(\"HunyuanVideo necessite un GPU. Le notebook montrera le code sans executer.\")\n",
    "    run_generation = False\n",
    "    device = \"cpu\"\n",
    "\n",
    "# Verification des dependances\n",
    "print(\"\\n--- VERIFICATION DEPENDANCES ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "deps_ok = True\n",
    "\n",
    "try:\n",
    "    import diffusers\n",
    "    print(f\"diffusers : v{diffusers.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"diffusers NON INSTALLE (pip install diffusers>=0.32)\")\n",
    "    deps_ok = False\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"transformers : v{transformers.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"transformers NON INSTALLE\")\n",
    "    deps_ok = False\n",
    "\n",
    "if quantize:\n",
    "    try:\n",
    "        import bitsandbytes as bnb\n",
    "        print(f\"bitsandbytes : v{bnb.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"bitsandbytes NON INSTALLE (pip install bitsandbytes)\")\n",
    "        print(\"  Quantification INT8 non disponible, FP16 sera utilise\")\n",
    "        quantize = False\n",
    "\n",
    "try:\n",
    "    import imageio\n",
    "    print(f\"imageio : v{imageio.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"imageio NON INSTALLE\")\n",
    "    deps_ok = False\n",
    "\n",
    "if not deps_ok:\n",
    "    print(\"\\nDependances manquantes. Le notebook montrera le code sans executer.\")\n",
    "    run_generation = False\n",
    "\n",
    "print(f\"\\nDevice : {device}\")\n",
    "print(f\"Generation activee : {run_generation}\")\n",
    "print(f\"Quantification : {'INT8' if quantize else 'FP16'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {
    "papermill": {
     "duration": 0.003668,
     "end_time": "2026-02-19T09:29:31.952253",
     "exception": false,
     "start_time": "2026-02-19T09:29:31.948585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 1 : Architecture HunyuanVideo\n",
    "\n",
    "HunyuanVideo est un modele de generation text-to-video open-source developpe par Tencent.\n",
    "Il se distingue par sa qualite de generation et sa capacite a produire des videos longues\n",
    "avec une bonne coherence temporelle.\n",
    "\n",
    "| Composant | Description |\n",
    "|-----------|-------------|\n",
    "| **Backbone** | Transformer 3D avec attention spatio-temporelle |\n",
    "| **Text encoder** | LLaMA-based pour la comprehension des prompts |\n",
    "| **VAE** | Encodeur/decodeur video avec compression temporelle |\n",
    "| **Scheduler** | Flow matching pour un debruitage progressif |\n",
    "\n",
    "### Avantages par rapport a AnimateDiff\n",
    "\n",
    "| Aspect | AnimateDiff (01-5) | HunyuanVideo |\n",
    "|--------|-------------------|---------------|\n",
    "| Architecture | SD 1.5 + motion module | Transformer 3D natif |\n",
    "| Resolution | 512x512 max | Jusqu'a 720p |\n",
    "| Coherence temporelle | Moyenne | Elevee |\n",
    "| Duree video | 2-3 secondes | 5+ secondes |\n",
    "| VRAM | ~12 GB | ~18 GB (INT8) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:31.958801Z",
     "iopub.status.busy": "2026-02-19T09:29:31.958341Z",
     "iopub.status.idle": "2026-02-19T09:29:31.965370Z",
     "shell.execute_reply": "2026-02-19T09:29:31.964885Z"
    },
    "papermill": {
     "duration": 0.011337,
     "end_time": "2026-02-19T09:29:31.966272",
     "exception": false,
     "start_time": "2026-02-19T09:29:31.954935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement pipeline desactive\n"
     ]
    }
   ],
   "source": [
    "# Chargement du pipeline HunyuanVideo\n",
    "pipe = None\n",
    "\n",
    "if run_generation:\n",
    "    print(\"\\n--- CHARGEMENT DU PIPELINE ---\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        from diffusers import HunyuanVideoPipeline\n",
    "        from diffusers.utils import export_to_video\n",
    "        \n",
    "        start_load = time.time()\n",
    "        \n",
    "        if quantize:\n",
    "            # Chargement avec quantification INT8 via bitsandbytes\n",
    "            from diffusers import BitsAndBytesConfig\n",
    "            \n",
    "            print(f\"Chargement avec quantification INT8...\")\n",
    "            print(f\"  Modele : {model_id}\")\n",
    "            \n",
    "            quant_config = BitsAndBytesConfig(\n",
    "                load_in_8bit=True\n",
    "            )\n",
    "            \n",
    "            pipe = HunyuanVideoPipeline.from_pretrained(\n",
    "                model_id,\n",
    "                quantization_config=quant_config,\n",
    "                torch_dtype=torch.float16\n",
    "            )\n",
    "        else:\n",
    "            # Chargement en FP16 (necessite plus de VRAM)\n",
    "            print(f\"Chargement en FP16...\")\n",
    "            print(f\"  Modele : {model_id}\")\n",
    "            \n",
    "            pipe = HunyuanVideoPipeline.from_pretrained(\n",
    "                model_id,\n",
    "                torch_dtype=torch.float16\n",
    "            )\n",
    "        \n",
    "        pipe = pipe.to(device)\n",
    "        \n",
    "        # Optimisations memoire\n",
    "        pipe.enable_vae_slicing()\n",
    "        pipe.enable_vae_tiling()\n",
    "        try:\n",
    "            pipe.enable_model_cpu_offload()\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        load_time = time.time() - start_load\n",
    "        \n",
    "        if device == \"cuda\":\n",
    "            vram_used = torch.cuda.memory_allocated(0) / 1024**3\n",
    "            print(f\"  VRAM utilisee : {vram_used:.1f} GB\")\n",
    "        \n",
    "        print(f\"Pipeline charge en {load_time:.1f}s\")\n",
    "        print(f\"  Quantification : {'INT8' if quantize else 'FP16'}\")\n",
    "        print(f\"  VAE slicing + tiling : actif\")\n",
    "        print(f\"  Resolution : {width}x{height}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur chargement pipeline : {type(e).__name__}: {str(e)[:200]}\")\n",
    "        print(\"Le notebook continuera sans generation.\")\n",
    "        run_generation = False\n",
    "        pipe = None\n",
    "else:\n",
    "    print(\"Chargement pipeline desactive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {
    "papermill": {
     "duration": 0.00222,
     "end_time": "2026-02-19T09:29:31.971138",
     "exception": false,
     "start_time": "2026-02-19T09:29:31.968918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Chargement du modele\n",
    "\n",
    "| Aspect | Valeur | Signification |\n",
    "|--------|--------|---------------|\n",
    "| Quantification INT8 | ~18 GB VRAM | Reduit la precision pour tenir en 24 GB |\n",
    "| FP16 | ~30+ GB VRAM | Pleine precision mais necessite GPU haut de gamme |\n",
    "| VAE slicing | Reduit VRAM pic | Decoupe les frames en tranches pour le decodage |\n",
    "| VAE tiling | Reduit VRAM pic | Decoupe spatialement pour les hautes resolutions |\n",
    "| CPU offload | Variable | Deplace dynamiquement les couches entre CPU et GPU |\n",
    "\n",
    "**Points cles** :\n",
    "1. La quantification INT8 avec bitsandbytes permet de charger le modele sur une RTX 3090 (24 GB)\n",
    "2. Les optimisations VAE (slicing + tiling) sont essentielles pour eviter les pics de memoire\n",
    "3. Le temps de chargement est plus long avec la quantification mais l'economie de VRAM est significative\n",
    "\n",
    "## Section 2 : Generation text-to-video\n",
    "\n",
    "Nous allons generer des videos a partir de descriptions textuelles detaillees.\n",
    "HunyuanVideo repond bien aux prompts descriptifs avec des indications de mouvement,\n",
    "d'eclairage et de style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:31.976644Z",
     "iopub.status.busy": "2026-02-19T09:29:31.976248Z",
     "iopub.status.idle": "2026-02-19T09:29:31.987889Z",
     "shell.execute_reply": "2026-02-19T09:29:31.986523Z"
    },
    "papermill": {
     "duration": 0.01635,
     "end_time": "2026-02-19T09:29:31.989602",
     "exception": false,
     "start_time": "2026-02-19T09:29:31.973252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GENERATION TEXT-TO-VIDEO ---\n",
      "========================================\n",
      "Generation desactivee\n",
      "\n",
      "Exemple de code pour generer :\n",
      "  result = generate_hunyuan_video('a majestic eagle soaring over snow-capped mountain...', seed=42)\n"
     ]
    }
   ],
   "source": [
    "# Generation text-to-video\n",
    "print(\"\\n--- GENERATION TEXT-TO-VIDEO ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def generate_hunyuan_video(prompt: str, negative_prompt: str = \"\",\n",
    "                           seed: int = 42) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Genere une video avec HunyuanVideo.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Description textuelle de la video\n",
    "        negative_prompt: Elements a eviter\n",
    "        seed: Graine aleatoire pour reproductibilite\n",
    "    \n",
    "    Returns:\n",
    "        Dict avec frames, temps de generation et metadonnees\n",
    "    \"\"\"\n",
    "    if pipe is None:\n",
    "        return {\"success\": False, \"error\": \"Pipeline non charge\"}\n",
    "    \n",
    "    try:\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        \n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            vram_before = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        output = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt or \"low quality, blurry, distorted, watermark, text\",\n",
    "            num_frames=num_frames,\n",
    "            guidance_scale=guidance_scale,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            generator=generator\n",
    "        )\n",
    "        \n",
    "        gen_time = time.time() - start_time\n",
    "        frames = output.frames[0]  # Liste d'images PIL\n",
    "        \n",
    "        result = {\n",
    "            \"success\": True,\n",
    "            \"frames\": frames,\n",
    "            \"generation_time\": gen_time,\n",
    "            \"time_per_frame\": gen_time / num_frames,\n",
    "            \"prompt\": prompt,\n",
    "            \"seed\": seed,\n",
    "            \"params\": {\n",
    "                \"num_frames\": num_frames,\n",
    "                \"guidance_scale\": guidance_scale,\n",
    "                \"num_inference_steps\": num_inference_steps,\n",
    "                \"height\": height,\n",
    "                \"width\": width\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if device == \"cuda\":\n",
    "            result[\"vram_peak\"] = torch.cuda.max_memory_allocated(0) / 1024**3\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": f\"{type(e).__name__}: {str(e)[:200]}\"}\n",
    "\n",
    "\n",
    "# Premier test : prompt cinematographique\n",
    "prompt_1 = \"a majestic eagle soaring over snow-capped mountains at golden hour, cinematic aerial shot, smooth camera movement, volumetric clouds\"\n",
    "\n",
    "if run_generation:\n",
    "    print(f\"Prompt : {prompt_1}\")\n",
    "    print(f\"Parametres : {num_frames} frames, {num_inference_steps} steps, CFG={guidance_scale}\")\n",
    "    print(f\"Resolution : {width}x{height}\")\n",
    "    print(f\"\\nGeneration en cours...\")\n",
    "    \n",
    "    result_1 = generate_hunyuan_video(prompt_1, seed=42)\n",
    "    \n",
    "    if result_1['success']:\n",
    "        frames = result_1['frames']\n",
    "        print(f\"\\nGeneration reussie\")\n",
    "        print(f\"  Temps total : {result_1['generation_time']:.1f}s\")\n",
    "        print(f\"  Temps/frame : {result_1['time_per_frame']:.1f}s\")\n",
    "        print(f\"  Frames : {len(frames)}\")\n",
    "        if 'vram_peak' in result_1:\n",
    "            print(f\"  VRAM pic : {result_1['vram_peak']:.1f} GB\")\n",
    "        \n",
    "        # Affichage en grille\n",
    "        n_display = min(8, len(frames))\n",
    "        indices = np.linspace(0, len(frames) - 1, n_display, dtype=int)\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "        axes_flat = axes.flatten()\n",
    "        for i, idx in enumerate(indices):\n",
    "            if i < len(axes_flat):\n",
    "                axes_flat[i].imshow(frames[idx])\n",
    "                axes_flat[i].set_title(f\"Frame {idx + 1}/{len(frames)}\", fontsize=9)\n",
    "                axes_flat[i].axis('off')\n",
    "        for i in range(len(indices), len(axes_flat)):\n",
    "            axes_flat[i].axis('off')\n",
    "        plt.suptitle(f\"HunyuanVideo : {prompt_1[:60]}...\", fontsize=11, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Sauvegarde MP4\n",
    "        if save_as_mp4:\n",
    "            mp4_path = OUTPUT_DIR / \"hunyuan_demo.mp4\"\n",
    "            export_to_video(frames, str(mp4_path), fps=fps_output)\n",
    "            mp4_size_kb = mp4_path.stat().st_size / 1024\n",
    "            print(f\"  MP4 sauvegarde : {mp4_path.name} ({mp4_size_kb:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"Erreur : {result_1['error']}\")\n",
    "else:\n",
    "    print(\"Generation desactivee\")\n",
    "    print(f\"\\nExemple de code pour generer :\")\n",
    "    print(f\"  result = generate_hunyuan_video('{prompt_1[:50]}...', seed=42)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {
    "papermill": {
     "duration": 0.003832,
     "end_time": "2026-02-19T09:29:31.997763",
     "exception": false,
     "start_time": "2026-02-19T09:29:31.993931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Premiere generation\n",
    "\n",
    "### MODE PEDAGOGIQUE (GPU non disponible)\n",
    "\n",
    "Sur un environnement GPU (RTX 3090, 24GB VRAM), ce code générerait:\n",
    "\n",
    "| Paramètre | Valeur typique | Signification |\n",
    "|--------|---------------|---------------|\n",
    "| **Temps total** | 60-180s (RTX 3090) | Significativement plus long qu'AnimateDiff |\n",
    "| **VRAM pic** | 16-22 GB | La quantification INT8 maintient la VRAM sous 24 GB |\n",
    "| **Qualité** | Haute | Meilleure cohérence temporelle que AnimateDiff |\n",
    "| **Résolution** | 512x320 | Compromis qualité/mémoire |\n",
    "| **Frames** | 24 | ~3 secondes à 8fps |\n",
    "\n",
    "**Résultat visuel attendu:**\n",
    "\n",
    "Pour le prompt \"a majestic eagle soaring over snow-capped mountains at golden hour\", HunyuanVideo générerait:\n",
    "\n",
    "- **Aigle**: Ailes déployées, plumage détaillé, mouvement de vol naturel\n",
    "- **Montagnes**: Pics enneigés, ombres dramatiques, profondeur de champ\n",
    "- **Ciel**: Nuages volumétriques, lumière dorée, atmosphère cinématographique\n",
    "- **Caméra**: Mouvement fluide de suivi de l'aigle, cadrage large\n",
    "\n",
    "**Comparaison avec AnimateDiff (01-5):**\n",
    "\n",
    "| Aspect | AnimateDiff | HunyuanVideo | Avantage |\n",
    "|--------|-------------|--------------|----------|\n",
    "| **Architecture** | SD 1.5 + motion module | Transformer 3D natif | Hunyuan |\n",
    "| **Résolution max** | 512x512 | 720p | Hunyuan |\n",
    "| **Cohérence temporelle** | Moyenne | Élevée | Hunyuan |\n",
    "| **Durée vidéo** | 2-3s | 5+s | Hunyuan |\n",
    "| **VRAM** | ~12 GB | ~18 GB (INT8) | AnimateDiff |\n",
    "| **Vitesse** | Rapide | Lent | AnimateDiff |\n",
    "\n",
    "**Code pour reproduire:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from diffusers import HunyuanVideoPipeline\n",
    "\n",
    "# Pipeline avec quantification INT8\n",
    "from diffusers import BitsAndBytesConfig\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "pipe = HunyuanVideoPipeline.from_pretrained(\n",
    "    \"tencent/HunyuanVideo\",\n",
    "    quantization_config=quant_config,\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Optimisations mémoire\n",
    "pipe.enable_vae_slicing()\n",
    "pipe.enable_vae_tiling()\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "# Génération\n",
    "prompt = \"a majestic eagle soaring over snow-capped mountains at golden hour, cinematic aerial shot\"\n",
    "output = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=\"low quality, blurry\",\n",
    "    num_frames=24,\n",
    "    guidance_scale=6.0,\n",
    "    num_inference_steps=30,\n",
    "    height=320,\n",
    "    width=512,\n",
    "    generator=torch.Generator(\"cuda\").manual_seed(42)\n",
    ")\n",
    "\n",
    "frames = output.frames[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:32.005905Z",
     "iopub.status.busy": "2026-02-19T09:29:32.005256Z",
     "iopub.status.idle": "2026-02-19T09:29:32.016502Z",
     "shell.execute_reply": "2026-02-19T09:29:32.015392Z"
    },
    "papermill": {
     "duration": 0.017453,
     "end_time": "2026-02-19T09:29:32.018271",
     "exception": false,
     "start_time": "2026-02-19T09:29:32.000818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploration des parametres : generation desactivee\n",
      "\n",
      "Guide des parametres :\n",
      "  CFG 3-4 : Creatif, plus de liberte\n",
      "  CFG 5-7 : Equilibre (recommande)\n",
      "  CFG 8-10 : Strict, peut introduire des artefacts\n"
     ]
    }
   ],
   "source": [
    "# Exploration des parametres\n",
    "if run_generation and pipe is not None:\n",
    "    print(\"\\n--- EXPLORATION DES PARAMETRES ---\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Test avec differentes valeurs de guidance_scale\n",
    "    test_prompt = \"a serene waterfall in a lush forest, sunlight filtering through trees, mist rising\"\n",
    "    \n",
    "    cfg_values = [3.0, 6.0, 9.0]\n",
    "    cfg_results = []\n",
    "    \n",
    "    print(f\"Test guidance_scale : {cfg_values}\")\n",
    "    print(f\"Prompt : {test_prompt[:60]}...\")\n",
    "    \n",
    "    for cfg_val in cfg_values:\n",
    "        print(f\"\\n  CFG = {cfg_val}...\")\n",
    "        \n",
    "        # Sauvegarder et modifier temporairement\n",
    "        original_cfg = guidance_scale\n",
    "        original_steps = num_inference_steps\n",
    "        guidance_scale = cfg_val\n",
    "        num_inference_steps = 20  # Reduit pour acceleration\n",
    "        \n",
    "        result = generate_hunyuan_video(test_prompt, seed=42)\n",
    "        \n",
    "        # Restaurer\n",
    "        guidance_scale = original_cfg\n",
    "        num_inference_steps = original_steps\n",
    "        \n",
    "        if result['success']:\n",
    "            cfg_results.append({\n",
    "                \"cfg\": cfg_val,\n",
    "                \"frames\": result['frames'],\n",
    "                \"time\": result['generation_time'],\n",
    "                \"vram_peak\": result.get('vram_peak', 0)\n",
    "            })\n",
    "            print(f\"    Temps : {result['generation_time']:.1f}s\")\n",
    "        else:\n",
    "            print(f\"    Erreur : {result['error']}\")\n",
    "    \n",
    "    # Affichage comparatif\n",
    "    if cfg_results:\n",
    "        n_cfgs = len(cfg_results)\n",
    "        n_preview = 4\n",
    "        fig, axes = plt.subplots(n_cfgs, n_preview, figsize=(3.5 * n_preview, 3 * n_cfgs))\n",
    "        if n_cfgs == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for v_idx, cr in enumerate(cfg_results):\n",
    "            frame_indices = np.linspace(0, len(cr['frames']) - 1, n_preview, dtype=int)\n",
    "            for f_idx, fi in enumerate(frame_indices):\n",
    "                axes[v_idx][f_idx].imshow(cr['frames'][fi])\n",
    "                axes[v_idx][f_idx].axis('off')\n",
    "                if f_idx == 0:\n",
    "                    axes[v_idx][f_idx].set_ylabel(f\"CFG={cr['cfg']}\", fontsize=11, fontweight='bold')\n",
    "        \n",
    "        plt.suptitle(\"Impact de guidance_scale sur la generation\", fontsize=13, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Tableau recapitulatif\n",
    "        print(f\"\\nRecapitulatif guidance_scale :\")\n",
    "        print(f\"{'CFG':<10} {'Temps (s)':<12} {'VRAM pic (GB)':<15}\")\n",
    "        print(\"-\" * 37)\n",
    "        for cr in cfg_results:\n",
    "            print(f\"  {cr['cfg']:<10} {cr['time']:<12.1f} {cr['vram_peak']:<15.1f}\")\n",
    "else:\n",
    "    print(\"Exploration des parametres : generation desactivee\")\n",
    "    print(\"\\nGuide des parametres :\")\n",
    "    print(\"  CFG 3-4 : Creatif, plus de liberte\")\n",
    "    print(\"  CFG 5-7 : Equilibre (recommande)\")\n",
    "    print(\"  CFG 8-10 : Strict, peut introduire des artefacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {
    "papermill": {
     "duration": 0.002974,
     "end_time": "2026-02-19T09:29:32.024207",
     "exception": false,
     "start_time": "2026-02-19T09:29:32.021233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Impact des parametres\n",
    "\n",
    "| guidance_scale | Comportement | Recommandation |\n",
    "|---------------|-------------|----------------|\n",
    "| 3.0 (bas) | Creatif, variations, parfois hors-sujet | Exploration creative |\n",
    "| 6.0 (moyen) | Bon equilibre fidelite/creativite | Usage general |\n",
    "| 9.0 (haut) | Tres fidele au prompt, risque artefacts | Prompt precis |\n",
    "\n",
    "**Points cles** :\n",
    "1. Contrairement a Stable Diffusion Image, une CFG trop elevee degrade la coherence temporelle\n",
    "2. Pour HunyuanVideo, la plage 5.0-7.0 donne generalement les meilleurs resultats\n",
    "3. Le temps de generation varie peu avec la CFG (meme nombre de steps)\n",
    "\n",
    "## Section 4 : Resolution et duree\n",
    "\n",
    "Nous allons explorer les compromis entre resolution, nombre de frames et consommation memoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:32.032365Z",
     "iopub.status.busy": "2026-02-19T09:29:32.031540Z",
     "iopub.status.idle": "2026-02-19T09:29:32.042365Z",
     "shell.execute_reply": "2026-02-19T09:29:32.041627Z"
    },
    "papermill": {
     "duration": 0.016651,
     "end_time": "2026-02-19T09:29:32.043709",
     "exception": false,
     "start_time": "2026-02-19T09:29:32.027058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test resolution/duree : generation desactivee\n",
      "\n",
      "Guide resolution/VRAM :\n",
      "  384x256 : ~14 GB, rapide, basse qualite\n",
      "  512x320 : ~18 GB, bon compromis (recommande)\n",
      "  640x480 : ~22 GB, haute qualite, lent\n",
      "  720p    : ~28 GB+, necessite quantification avancee\n"
     ]
    }
   ],
   "source": [
    "# Test de resolution et duree\n",
    "if run_generation and pipe is not None:\n",
    "    print(\"\\n--- RESOLUTION ET DUREE ---\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    resolution_prompt = \"a golden retriever running through a field of sunflowers, joyful, sunny day, slow motion\"\n",
    "    \n",
    "    # Configurations a tester (resolution, frames)\n",
    "    configs = [\n",
    "        {\"w\": 384, \"h\": 256, \"frames\": 24, \"label\": \"384x256 / 24f\"},\n",
    "        {\"w\": 512, \"h\": 320, \"frames\": 16, \"label\": \"512x320 / 16f\"},\n",
    "        {\"w\": 512, \"h\": 320, \"frames\": 32, \"label\": \"512x320 / 32f\"},\n",
    "    ]\n",
    "    \n",
    "    config_results = []\n",
    "    \n",
    "    for cfg in configs:\n",
    "        print(f\"\\nTest : {cfg['label']}\")\n",
    "        \n",
    "        # Modifier temporairement les parametres globaux\n",
    "        orig_w, orig_h, orig_f = width, height, num_frames\n",
    "        original_steps = num_inference_steps\n",
    "        \n",
    "        # Variables locales pour la generation\n",
    "        gen_width = cfg['w']\n",
    "        gen_height = cfg['h']\n",
    "        gen_frames = cfg['frames']\n",
    "        \n",
    "        try:\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "            generator = torch.Generator(device=device).manual_seed(42)\n",
    "            start_time = time.time()\n",
    "            \n",
    "            output = pipe(\n",
    "                prompt=resolution_prompt,\n",
    "                negative_prompt=\"low quality, blurry, distorted\",\n",
    "                num_frames=gen_frames,\n",
    "                guidance_scale=6.0,\n",
    "                num_inference_steps=20,\n",
    "                height=gen_height,\n",
    "                width=gen_width,\n",
    "                generator=generator\n",
    "            )\n",
    "            \n",
    "            gen_time = time.time() - start_time\n",
    "            frames = output.frames[0]\n",
    "            \n",
    "            vram_peak = 0\n",
    "            if device == \"cuda\":\n",
    "                vram_peak = torch.cuda.max_memory_allocated(0) / 1024**3\n",
    "            \n",
    "            config_results.append({\n",
    "                \"label\": cfg['label'],\n",
    "                \"frames\": frames,\n",
    "                \"time\": gen_time,\n",
    "                \"vram_peak\": vram_peak,\n",
    "                \"n_frames\": gen_frames,\n",
    "                \"resolution\": f\"{gen_width}x{gen_height}\"\n",
    "            })\n",
    "            \n",
    "            print(f\"  Temps : {gen_time:.1f}s, VRAM pic : {vram_peak:.1f} GB\")\n",
    "            \n",
    "            # Sauvegarder en MP4\n",
    "            if save_as_mp4:\n",
    "                mp4_path = OUTPUT_DIR / f\"hunyuan_{cfg['label'].replace(' / ', '_').replace('x', '_')}.mp4\"\n",
    "                export_to_video(frames, str(mp4_path), fps=fps_output)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Erreur : {type(e).__name__}: {str(e)[:100]}\")\n",
    "    \n",
    "    # Tableau recapitulatif\n",
    "    if config_results:\n",
    "        print(f\"\\n{'Configuration':<25} {'Temps (s)':<12} {'VRAM (GB)':<12} {'Duree video':<15}\")\n",
    "        print(\"-\" * 64)\n",
    "        for cr in config_results:\n",
    "            duration = cr['n_frames'] / fps_output\n",
    "            print(f\"  {cr['label']:<25} {cr['time']:<12.1f} {cr['vram_peak']:<12.1f} {duration:.1f}s\")\n",
    "else:\n",
    "    print(\"Test resolution/duree : generation desactivee\")\n",
    "    print(\"\\nGuide resolution/VRAM :\")\n",
    "    print(\"  384x256 : ~14 GB, rapide, basse qualite\")\n",
    "    print(\"  512x320 : ~18 GB, bon compromis (recommande)\")\n",
    "    print(\"  640x480 : ~22 GB, haute qualite, lent\")\n",
    "    print(\"  720p    : ~28 GB+, necessite quantification avancee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {
    "papermill": {
     "duration": 0.00289,
     "end_time": "2026-02-19T09:29:32.049566",
     "exception": false,
     "start_time": "2026-02-19T09:29:32.046676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Resolution et duree\n",
    "\n",
    "### MODE PEDAGOGIQUE (GPU non disponible)\n",
    "\n",
    "Sur un environnement GPU (RTX 3090, 24GB VRAM), ce code générerait:\n",
    "\n",
    "| Paramètre | Valeur |\n",
    "|-----------|--------|\n",
    "| **Device** | cuda (RTX 3090/4090) |\n",
    "| **VRAM utilisée** | ~14-22 GB (selon config) |\n",
    "| **Temps par génération** | 20-60 secondes |\n",
    "| **Configurations testées** | 3 résolutions/durées |\n",
    "\n",
    "**Résultat attendu:**\n",
    "HunyuanVideo générerait 3 vidéos du golden retriever avec differentes configurations:\n",
    "\n",
    "| Configuration | VRAM | Temps relatif | Durée vidéo | Qualité |\n",
    "|--------------|------|---------------|-------------|---------|\n",
    "| **384x256 / 24f** | ~14 GB | 1x (20s) | 3s @ 8fps | Basique, rapide |\n",
    "| **512x320 / 16f** | ~16 GB | 1.2x (24s) | 2s @ 8fps | Bon compromis |\n",
    "| **512x320 / 32f** | ~20 GB | 2x (40s) | 4s @ 8fps | Haute qualité |\n",
    "\n",
    "**Description visuelle:**\n",
    "\n",
    "- **384x256 / 24f**: Chien courant visible, textures simplifiées, mouvement fluide mais basse résolution\n",
    "- **512x320 / 16f**: Meilleure résolution, pelage plus détaillé, durée plus courte\n",
    "- **512x320 / 32f**: Meilleure qualité globale, durée plus longue, cohérence temporelle excellente\n",
    "\n",
    "**Analyse des compromis:**\n",
    "\n",
    "| Aspect | Augmente avec... | Impact |\n",
    "|--------|-----------------|--------|\n",
    "| **VRAM** | Résolution (W x H) | Plus de pixels = plus de memoire |\n",
    "| **VRAM** | Nombre de frames | Lineaire avec la durée |\n",
    "| **Temps** | Frames + Steps | Proportionnel |\n",
    "| **Qualité** | Résolution | Details visuels |\n",
    "\n",
    "**Code pour reproduire:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from diffusers import HunyuanVideoPipeline\n",
    "\n",
    "pipe = HunyuanVideoPipeline.from_pretrained(\n",
    "    \"tencent/HunyuanVideo\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "pipe.enable_vae_slicing()\n",
    "pipe.enable_vae_tiling()\n",
    "\n",
    "configs = [\n",
    "    {\"w\": 384, \"h\": 256, \"frames\": 24},\n",
    "    {\"w\": 512, \"h\": 320, \"frames\": 16},\n",
    "    {\"w\": 512, \"h\": 320, \"frames\": 32},\n",
    "]\n",
    "\n",
    "prompt = \"a golden retriever running through a field of sunflowers\"\n",
    "\n",
    "for cfg in configs:\n",
    "    output = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=\"low quality\",\n",
    "        num_frames=cfg['frames'],\n",
    "        guidance_scale=6.0,\n",
    "        num_inference_steps=20,\n",
    "        height=cfg['h'],\n",
    "        width=cfg['w'],\n",
    "        generator=torch.Generator(\"cuda\").manual_seed(42)\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:32.058546Z",
     "iopub.status.busy": "2026-02-19T09:29:32.058269Z",
     "iopub.status.idle": "2026-02-19T09:29:32.067100Z",
     "shell.execute_reply": "2026-02-19T09:29:32.066543Z"
    },
    "papermill": {
     "duration": 0.015572,
     "end_time": "2026-02-19T09:29:32.068170",
     "exception": false,
     "start_time": "2026-02-19T09:29:32.052598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison de prompts : generation desactivee\n",
      "\n",
      "Types de prompts efficaces pour HunyuanVideo :\n",
      "  - Mouvements naturels : eau, feu, nuages, vent\n",
      "  - Scenes cinematographiques : camera aerienne, slow motion\n",
      "  - Timelapse : nuages, coucher de soleil, fleurs\n",
      "  - Animaux en mouvement : vol d'oiseau, course de chien\n"
     ]
    }
   ],
   "source": [
    "# Comparaison de prompts et analyse qualite\n",
    "if run_generation and pipe is not None:\n",
    "    print(\"\\n--- COMPARAISON DE PROMPTS ---\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    prompts = [\n",
    "        {\n",
    "            \"text\": \"a candle flame flickering gently in a dark room, warm light, intimate atmosphere, close-up\",\n",
    "            \"label\": \"Bougie\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"ocean waves rolling onto a sandy beach at sunset, aerial view, golden hour lighting\",\n",
    "            \"label\": \"Ocean\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"a timelapse of clouds moving over a mountain landscape, dramatic sky, epic scale\",\n",
    "            \"label\": \"Timelapse\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    for p_idx, prompt_info in enumerate(prompts):\n",
    "        print(f\"\\nGeneration {p_idx + 1}/{len(prompts)} : {prompt_info['label']}\")\n",
    "        print(f\"  Prompt : {prompt_info['text'][:70]}...\")\n",
    "        \n",
    "        result = generate_hunyuan_video(prompt_info['text'], seed=42 + p_idx)\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"  Temps : {result['generation_time']:.1f}s\")\n",
    "            comparison_results.append({\n",
    "                \"label\": prompt_info['label'],\n",
    "                \"prompt\": prompt_info['text'],\n",
    "                \"frames\": result['frames'],\n",
    "                \"time\": result['generation_time']\n",
    "            })\n",
    "            \n",
    "            if save_as_mp4:\n",
    "                mp4_path = OUTPUT_DIR / f\"hunyuan_{prompt_info['label'].lower()}.mp4\"\n",
    "                export_to_video(result['frames'], str(mp4_path), fps=fps_output)\n",
    "        else:\n",
    "            print(f\"  Erreur : {result['error']}\")\n",
    "    \n",
    "    # Affichage comparatif\n",
    "    if comparison_results:\n",
    "        n_videos = len(comparison_results)\n",
    "        n_preview = 4\n",
    "        fig, axes = plt.subplots(n_videos, n_preview, figsize=(3.5 * n_preview, 3 * n_videos))\n",
    "        if n_videos == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for v_idx, cr in enumerate(comparison_results):\n",
    "            frame_indices = np.linspace(0, len(cr['frames']) - 1, n_preview, dtype=int)\n",
    "            for f_idx, fi in enumerate(frame_indices):\n",
    "                axes[v_idx][f_idx].imshow(cr['frames'][fi])\n",
    "                axes[v_idx][f_idx].axis('off')\n",
    "                if f_idx == 0:\n",
    "                    axes[v_idx][f_idx].set_ylabel(cr['label'], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        plt.suptitle(\"Comparaison de prompts - HunyuanVideo\", fontsize=13, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyse de coherence temporelle (difference entre frames consecutives)\n",
    "        print(f\"\\nAnalyse de coherence temporelle :\")\n",
    "        print(f\"{'Prompt':<15} {'Temps (s)':<12} {'Diff moy frames':<18} {'Stabilite':<15}\")\n",
    "        print(\"-\" * 60)\n",
    "        for cr in comparison_results:\n",
    "            # Calculer la difference moyenne entre frames consecutives\n",
    "            diffs = []\n",
    "            for i in range(len(cr['frames']) - 1):\n",
    "                f1 = np.array(cr['frames'][i]).astype(float)\n",
    "                f2 = np.array(cr['frames'][i + 1]).astype(float)\n",
    "                diff = np.mean(np.abs(f1 - f2))\n",
    "                diffs.append(diff)\n",
    "            avg_diff = np.mean(diffs)\n",
    "            stability = \"Haute\" if avg_diff < 15 else \"Moyenne\" if avg_diff < 30 else \"Basse\"\n",
    "            print(f\"  {cr['label']:<15} {cr['time']:<12.1f} {avg_diff:<18.2f} {stability:<15}\")\n",
    "else:\n",
    "    print(\"Comparaison de prompts : generation desactivee\")\n",
    "    print(\"\\nTypes de prompts efficaces pour HunyuanVideo :\")\n",
    "    print(\"  - Mouvements naturels : eau, feu, nuages, vent\")\n",
    "    print(\"  - Scenes cinematographiques : camera aerienne, slow motion\")\n",
    "    print(\"  - Timelapse : nuages, coucher de soleil, fleurs\")\n",
    "    print(\"  - Animaux en mouvement : vol d'oiseau, course de chien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:32.075171Z",
     "iopub.status.busy": "2026-02-19T09:29:32.074622Z",
     "iopub.status.idle": "2026-02-19T09:29:32.081564Z",
     "shell.execute_reply": "2026-02-19T09:29:32.081063Z"
    },
    "papermill": {
     "duration": 0.011719,
     "end_time": "2026-02-19T09:29:32.082685",
     "exception": false,
     "start_time": "2026-02-19T09:29:32.070966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode batch - Interface interactive desactivee\n"
     ]
    }
   ],
   "source": [
    "# Mode interactif\n",
    "if notebook_mode == \"interactive\" and not skip_widgets:\n",
    "    print(\"\\n--- MODE INTERACTIF ---\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Entrez votre propre prompt pour generer une video HunyuanVideo.\")\n",
    "    print(\"(Laissez vide pour passer a la suite)\")\n",
    "    \n",
    "    try:\n",
    "        user_prompt = input(\"\\nVotre prompt : \").strip()\n",
    "        \n",
    "        if user_prompt and run_generation and pipe is not None:\n",
    "            print(f\"\\nGeneration en cours...\")\n",
    "            result_user = generate_hunyuan_video(user_prompt, seed=123)\n",
    "            \n",
    "            if result_user['success']:\n",
    "                print(f\"Generation reussie en {result_user['generation_time']:.1f}s\")\n",
    "                \n",
    "                # Affichage\n",
    "                n_display = min(8, len(result_user['frames']))\n",
    "                fig, axes = plt.subplots(1, n_display, figsize=(2.5 * n_display, 3))\n",
    "                if n_display == 1:\n",
    "                    axes = [axes]\n",
    "                indices = np.linspace(0, len(result_user['frames']) - 1, n_display, dtype=int)\n",
    "                for ax, idx in zip(axes, indices):\n",
    "                    ax.imshow(result_user['frames'][idx])\n",
    "                    ax.set_title(f\"Frame {idx+1}\", fontsize=8)\n",
    "                    ax.axis('off')\n",
    "                plt.suptitle(f\"Votre video : {user_prompt[:50]}...\", fontweight='bold')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                if save_as_mp4:\n",
    "                    user_mp4 = OUTPUT_DIR / \"user_generation.mp4\"\n",
    "                    export_to_video(result_user['frames'], str(user_mp4), fps=fps_output)\n",
    "                    print(f\"MP4 sauvegarde : {user_mp4.name}\")\n",
    "            else:\n",
    "                print(f\"Erreur : {result_user['error']}\")\n",
    "        elif user_prompt:\n",
    "            print(\"Generation non disponible (pipeline non charge)\")\n",
    "        else:\n",
    "            print(\"Mode interactif ignore\")\n",
    "    \n",
    "    except (KeyboardInterrupt, EOFError) as e:\n",
    "        print(f\"\\nMode interactif interrompu ({type(e).__name__})\")\n",
    "    except Exception as e:\n",
    "        error_type = type(e).__name__\n",
    "        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n",
    "            print(\"\\nMode interactif non disponible (execution automatisee)\")\n",
    "        else:\n",
    "            print(f\"\\nErreur inattendue : {error_type} - {str(e)[:100]}\")\n",
    "            print(\"Passage a la suite du notebook\")\n",
    "else:\n",
    "    print(\"\\nMode batch - Interface interactive desactivee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {
    "papermill": {
     "duration": 0.003803,
     "end_time": "2026-02-19T09:29:32.090288",
     "exception": false,
     "start_time": "2026-02-19T09:29:32.086485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bonnes pratiques et optimisation HunyuanVideo\n",
    "\n",
    "### Conseils de prompt engineering\n",
    "\n",
    "| Bon prompt | Mauvais prompt | Raison |\n",
    "|-----------|---------------|--------|\n",
    "| \"a bird flying over a lake, aerial shot, cinematic\" | \"bird lake\" | Preciser l'action et le style |\n",
    "| \"timelapse of sunset, clouds moving, warm colors\" | \"nice sunset video\" | Indiquer le type de mouvement |\n",
    "| \"close-up of rain drops on a window\" | \"rain\" | Le cadrage guide la generation |\n",
    "\n",
    "### Comparaison avec les autres modeles du Module 02\n",
    "\n",
    "| Aspect | HunyuanVideo | LTX-Video (02-2) | Wan (02-3) | SVD (02-4) |\n",
    "|--------|-------------|------------------|-----------|------------|\n",
    "| Type | Text-to-video | Text/Img/Vid | Text-to-video | Image-to-video |\n",
    "| VRAM | ~18 GB | ~8 GB | ~10 GB | ~10 GB |\n",
    "| Qualite | Haute | Moyenne | Haute | Haute |\n",
    "| Vitesse | Lente | Rapide | Moyenne | Moyenne |\n",
    "| Resolution max | 720p | 512p | 720p | 576p |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:29:32.096903Z",
     "iopub.status.busy": "2026-02-19T09:29:32.096655Z",
     "iopub.status.idle": "2026-02-19T09:29:32.103089Z",
     "shell.execute_reply": "2026-02-19T09:29:32.102580Z"
    },
    "papermill": {
     "duration": 0.011144,
     "end_time": "2026-02-19T09:29:32.104207",
     "exception": false,
     "start_time": "2026-02-19T09:29:32.093063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STATISTIQUES DE SESSION ---\n",
      "========================================\n",
      "Date : 2026-02-19 10:29:32\n",
      "Mode : batch\n",
      "Modele : tencent/HunyuanVideo\n",
      "Quantification : FP16\n",
      "Device : cpu\n",
      "Parametres : 24 frames, 30 steps, CFG=6.0\n",
      "Resolution : 512x320\n",
      "\n",
      "Fichiers generes (0) :\n",
      "\n",
      "--- PROCHAINES ETAPES ---\n",
      "1. Notebook 02-2 : LTX-Video (generation rapide et legere, ~8 GB VRAM)\n",
      "2. Notebook 02-3 : Wan 2.1/2.2 (prompts multilingues, motion control)\n",
      "3. Notebook 02-4 : SVD (animation d'images statiques)\n",
      "4. Module 03 : Comparaison multi-modeles et orchestration de pipelines\n",
      "\n",
      "Notebook 02-1 HunyuanVideo Generation termine - 10:29:32\n"
     ]
    }
   ],
   "source": [
    "# Statistiques de session et prochaines etapes\n",
    "print(\"\\n--- STATISTIQUES DE SESSION ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Mode : {notebook_mode}\")\n",
    "print(f\"Modele : {model_id}\")\n",
    "print(f\"Quantification : {'INT8' if quantize else 'FP16'}\")\n",
    "print(f\"Device : {device}\")\n",
    "print(f\"Parametres : {num_frames} frames, {num_inference_steps} steps, CFG={guidance_scale}\")\n",
    "print(f\"Resolution : {width}x{height}\")\n",
    "\n",
    "if device == \"cuda\" and torch.cuda.is_available():\n",
    "    vram_peak = torch.cuda.max_memory_allocated(0) / 1024**3\n",
    "    print(f\"VRAM pic session : {vram_peak:.1f} GB\")\n",
    "\n",
    "if save_results and OUTPUT_DIR.exists():\n",
    "    generated_files = list(OUTPUT_DIR.glob('*'))\n",
    "    print(f\"\\nFichiers generes ({len(generated_files)}) :\")\n",
    "    for f in sorted(generated_files):\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f\"  {f.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "# Liberation VRAM\n",
    "if pipe is not None:\n",
    "    del pipe\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\nVRAM liberee\")\n",
    "\n",
    "print(f\"\\n--- PROCHAINES ETAPES ---\")\n",
    "print(f\"1. Notebook 02-2 : LTX-Video (generation rapide et legere, ~8 GB VRAM)\")\n",
    "print(f\"2. Notebook 02-3 : Wan 2.1/2.2 (prompts multilingues, motion control)\")\n",
    "print(f\"3. Notebook 02-4 : SVD (animation d'images statiques)\")\n",
    "print(f\"4. Module 03 : Comparaison multi-modeles et orchestration de pipelines\")\n",
    "\n",
    "print(f\"\\nNotebook 02-1 HunyuanVideo Generation termine - {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.371373,
   "end_time": "2026-02-19T09:29:33.226785",
   "environment_variables": {},
   "exception": null,
   "input_path": "MyIA.AI.Notebooks\\GenAI\\Video\\02-Advanced\\02-1-HunyuanVideo-Generation.ipynb",
   "output_path": "MyIA.AI.Notebooks\\GenAI\\Video\\02-Advanced\\02-1-HunyuanVideo-Generation.ipynb",
   "parameters": {
    "notebook_mode": "batch",
    "skip_widgets": true
   },
   "start_time": "2026-02-19T09:29:25.855412",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}