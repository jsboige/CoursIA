{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {
    "papermill": {
     "duration": 0.002313,
     "end_time": "2026-02-18T10:03:35.741986",
     "exception": false,
     "start_time": "2026-02-18T10:03:35.739673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Qwen2.5-VL Video Analysis - Comprehension Video Locale\n",
    "\n",
    "**Module :** 01-Video-Foundation  \n",
    "**Niveau :** Intermediaire  \n",
    "**Technologies :** Qwen2.5-VL 7B, transformers, torch  \n",
    "**Duree estimee :** 50 minutes  \n",
    "**VRAM :** ~18 GB (degradation possible sur GPU plus petits)  \n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "- [ ] Charger le modele Qwen2.5-VL-7B-Instruct localement avec transformers\n",
    "- [ ] Comprendre le video understanding avec echantillonnage FPS dynamique\n",
    "- [ ] Realiser une analyse frame par frame\n",
    "- [ ] Effectuer du temporal grounding (localiser des evenements avec timestamps)\n",
    "- [ ] Extraire du texte (OCR) dans les frames video\n",
    "- [ ] Comparer les performances avec GPT-5 API (qualite, vitesse, cout)\n",
    "\n",
    "## Prerequis\n",
    "\n",
    "- GPU avec 18+ GB VRAM (RTX 3090, RTX 4090, A100)\n",
    "- Notebook 01-2 (GPT-5 Video Understanding) complete\n",
    "- Packages : `transformers>=4.45`, `torch`, `qwen-vl-utils`, `decord`, `accelerate`\n",
    "\n",
    "> **Note** : Si votre GPU a moins de 18 GB de VRAM, le notebook tentera un chargement\n",
    "> en precision reduite (bfloat16 ou int8). Les resultats peuvent varier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T10:03:35.746615Z",
     "iopub.status.busy": "2026-02-18T10:03:35.746271Z",
     "iopub.status.idle": "2026-02-18T10:03:35.750468Z",
     "shell.execute_reply": "2026-02-18T10:03:35.749856Z"
    },
    "papermill": {
     "duration": 0.007957,
     "end_time": "2026-02-18T10:03:35.751772",
     "exception": false,
     "start_time": "2026-02-18T10:03:35.743815",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parametres Papermill - JAMAIS modifier ce commentaire\n",
    "\n",
    "# Configuration notebook\n",
    "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
    "skip_widgets = False               # True pour mode batch MCP\n",
    "debug_level = \"INFO\"\n",
    "\n",
    "# Parametres modele\n",
    "model_name = \"Qwen/Qwen2.5-VL-7B-Instruct\"  # Modele Hugging Face\n",
    "device = \"cuda\"                    # \"cuda\" ou \"cpu\" (tres lent)\n",
    "torch_dtype = \"bfloat16\"           # \"bfloat16\", \"float16\", \"auto\"\n",
    "max_frames = 16                    # Nombre max de frames pour le modele\n",
    "\n",
    "# Configuration video de test\n",
    "sample_fps = 24\n",
    "sample_duration = 10\n",
    "\n",
    "# Configuration analyse\n",
    "run_analysis = True                # Executer les analyses (False pour validation)\n",
    "run_ocr = True                     # Tester l'OCR video\n",
    "run_temporal_grounding = True      # Tester le temporal grounding\n",
    "save_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T10:03:35.759989Z",
     "iopub.status.busy": "2026-02-18T10:03:35.759592Z",
     "iopub.status.idle": "2026-02-18T10:03:36.086175Z",
     "shell.execute_reply": "2026-02-18T10:03:36.085533Z"
    },
    "papermill": {
     "duration": 0.331761,
     "end_time": "2026-02-18T10:03:36.087029",
     "exception": false,
     "start_time": "2026-02-18T10:03:35.755268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers GenAI importes\n",
      "Qwen2.5-VL Video Analysis\n",
      "Date : 2026-02-18 11:03:36\n",
      "Mode : interactive, Modele : Qwen/Qwen2.5-VL-7B-Instruct\n",
      "Max frames : 16, Device : cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup environnement et imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Import helpers GenAI\n",
    "GENAI_ROOT = Path.cwd()\n",
    "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
    "    GENAI_ROOT = GENAI_ROOT.parent\n",
    "\n",
    "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
    "if HELPERS_PATH.exists():\n",
    "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
    "    try:\n",
    "        from helpers.genai_helpers import setup_genai_logging\n",
    "        print(\"Helpers GenAI importes\")\n",
    "    except ImportError:\n",
    "        print(\"Helpers GenAI non disponibles - mode autonome\")\n",
    "\n",
    "OUTPUT_DIR = GENAI_ROOT / 'outputs' / 'video_qwen_vl'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=getattr(logging, debug_level))\n",
    "logger = logging.getLogger('video_qwen_vl')\n",
    "\n",
    "print(f\"Qwen2.5-VL Video Analysis\")\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Mode : {notebook_mode}, Modele : {model_name}\")\n",
    "print(f\"Max frames : {max_frames}, Device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T10:03:36.091878Z",
     "iopub.status.busy": "2026-02-18T10:03:36.091662Z",
     "iopub.status.idle": "2026-02-18T10:03:37.371021Z",
     "shell.execute_reply": "2026-02-18T10:03:37.370449Z"
    },
    "papermill": {
     "duration": 1.282468,
     "end_time": "2026-02-18T10:03:37.371769",
     "exception": false,
     "start_time": "2026-02-18T10:03:36.089301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier .env charge depuis : D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\.env\n",
      "\n",
      "--- VERIFICATION GPU ---\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA non disponible. Passage en mode CPU (tres lent).\n",
      "\n",
      "Device final : cpu\n",
      "Precision : bfloat16\n"
     ]
    }
   ],
   "source": [
    "# Chargement .env et verification GPU\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_path = Path.cwd()\n",
    "found_env = False\n",
    "for _ in range(4):\n",
    "    env_path = current_path / '.env'\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"Fichier .env charge depuis : {env_path}\")\n",
    "        found_env = True\n",
    "        break\n",
    "    current_path = current_path.parent\n",
    "\n",
    "if not found_env:\n",
    "    print(\"Aucun fichier .env trouve\")\n",
    "\n",
    "# Verification GPU et VRAM\n",
    "print(\"\\n--- VERIFICATION GPU ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    vram_total = torch.cuda.get_device_properties(0).total_mem / 1024**3\n",
    "    vram_free = (torch.cuda.get_device_properties(0).total_mem - torch.cuda.memory_allocated(0)) / 1024**3\n",
    "    \n",
    "    print(f\"GPU : {gpu_name}\")\n",
    "    print(f\"VRAM totale : {vram_total:.1f} GB\")\n",
    "    print(f\"VRAM libre : {vram_free:.1f} GB\")\n",
    "    print(f\"CUDA : {torch.version.cuda}\")\n",
    "    print(f\"PyTorch : {torch.__version__}\")\n",
    "    \n",
    "    if vram_total < 18:\n",
    "        print(f\"\\nAttention : VRAM ({vram_total:.0f} GB) < 18 GB recommandes\")\n",
    "        print(\"Le modele sera charge en precision reduite si possible\")\n",
    "        if vram_total < 8:\n",
    "            print(\"VRAM insuffisante. Passage en mode CPU (tres lent).\")\n",
    "            device = \"cpu\"\n",
    "elif device == \"cuda\":\n",
    "    print(\"CUDA non disponible. Passage en mode CPU (tres lent).\")\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    print(f\"Mode CPU selectionne (pas de GPU)\")\n",
    "\n",
    "print(f\"\\nDevice final : {device}\")\n",
    "print(f\"Precision : {torch_dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {
    "papermill": {
     "duration": 0.001754,
     "end_time": "2026-02-18T10:03:37.375416",
     "exception": false,
     "start_time": "2026-02-18T10:03:37.373662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 1 : Chargement du modele Qwen2.5-VL\n",
    "\n",
    "Qwen2.5-VL est un modele vision-langage capable de comprendre des videos nativement.\n",
    "Contrairement a GPT-5 qui recoit des frames statiques, Qwen-VL peut traiter une\n",
    "sequence de frames avec une notion de temporalite integree.\n",
    "\n",
    "| Modele | Parametres | VRAM | Contexte video |\n",
    "|--------|-----------|------|----------------|\n",
    "| Qwen2.5-VL-2B | 2B | ~6 GB | Basique |\n",
    "| Qwen2.5-VL-7B | 7B | ~18 GB | Avance |\n",
    "| Qwen2.5-VL-72B | 72B | ~150 GB | Etat de l'art |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T10:03:37.380007Z",
     "iopub.status.busy": "2026-02-18T10:03:37.379558Z",
     "iopub.status.idle": "2026-02-18T10:03:38.173119Z",
     "shell.execute_reply": "2026-02-18T10:03:38.172548Z"
    },
    "papermill": {
     "duration": 0.796874,
     "end_time": "2026-02-18T10:03:38.173903",
     "exception": false,
     "start_time": "2026-02-18T10:03:37.377029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CHARGEMENT DU MODELE ---\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur chargement modele : ImportError: huggingface-hub>=0.30.0,<1.0 is required for a normal functioning of this module, but found huggingface-hub==1.4.1.\n",
      "Try: `pip install transformers -U`\n",
      "Le notebook continuera sans executer les analyses.\n"
     ]
    }
   ],
   "source": [
    "# Chargement du modele Qwen2.5-VL\n",
    "print(\"\\n--- CHARGEMENT DU MODELE ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "model = None\n",
    "processor = None\n",
    "\n",
    "if run_analysis:\n",
    "    try:\n",
    "        from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "        \n",
    "        # Selection de la precision selon la VRAM\n",
    "        dtype_map = {\n",
    "            \"bfloat16\": torch.bfloat16,\n",
    "            \"float16\": torch.float16,\n",
    "            \"auto\": \"auto\"\n",
    "        }\n",
    "        selected_dtype = dtype_map.get(torch_dtype, torch.bfloat16)\n",
    "        \n",
    "        print(f\"Chargement de {model_name}...\")\n",
    "        print(f\"  Precision : {torch_dtype}\")\n",
    "        print(f\"  Device : {device}\")\n",
    "        start_load = time.time()\n",
    "        \n",
    "        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=selected_dtype,\n",
    "            device_map=\"auto\" if device == \"cuda\" else None,\n",
    "            attn_implementation=\"flash_attention_2\" if device == \"cuda\" else \"eager\"\n",
    "        )\n",
    "        \n",
    "        processor = AutoProcessor.from_pretrained(model_name)\n",
    "        \n",
    "        load_time = time.time() - start_load\n",
    "        \n",
    "        if device == \"cuda\":\n",
    "            vram_used = torch.cuda.memory_allocated(0) / 1024**3\n",
    "            print(f\"  VRAM utilisee : {vram_used:.1f} GB\")\n",
    "        \n",
    "        print(f\"Modele charge en {load_time:.1f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur chargement modele : {type(e).__name__}: {str(e)[:150]}\")\n",
    "        print(\"Le notebook continuera sans executer les analyses.\")\n",
    "        run_analysis = False\n",
    "        run_ocr = False\n",
    "        run_temporal_grounding = False\n",
    "else:\n",
    "    print(\"Chargement modele desactive (run_analysis=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {
    "papermill": {
     "duration": 0.001525,
     "end_time": "2026-02-18T10:03:38.177360",
     "exception": false,
     "start_time": "2026-02-18T10:03:38.175835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 2 : Creation de la video de test et analyse\n",
    "\n",
    "Nous reutilisons le meme type de video multi-scenes que dans le notebook 01-2\n",
    "pour pouvoir comparer les resultats entre GPT-5 et Qwen-VL. En ajoutant du texte\n",
    "lisible dans les frames, nous pourrons aussi tester les capacites OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T10:03:38.181341Z",
     "iopub.status.busy": "2026-02-18T10:03:38.181101Z",
     "iopub.status.idle": "2026-02-18T10:03:39.055435Z",
     "shell.execute_reply": "2026-02-18T10:03:39.054644Z"
    },
    "papermill": {
     "duration": 0.877409,
     "end_time": "2026-02-18T10:03:39.056394",
     "exception": false,
     "start_time": "2026-02-18T10:03:38.178985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CREATION VIDEO DE TEST ---\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video creee : test_qwen_analysis.mp4\n",
      "  5 scenes, 240 frames, 10.0s\n",
      "\n",
      "Evenements temporels (verite terrain) :\n",
      "  titre_apparait : t=0.0s\n",
      "  chapitre_ml : t=2.0s\n",
      "  formule_visible : t=4.0s\n",
      "  resultat_affiche : t=6.0s\n",
      "  fin_presentation : t=8.0s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creation video de test avec texte OCR et evenements temporels\n",
    "import imageio\n",
    "\n",
    "print(\"\\n--- CREATION VIDEO DE TEST ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "scenes = [\n",
    "    {\"name\": \"Introduction\", \"bg\": (40, 40, 100), \"text\": \"Bienvenue dans CoursIA\",\n",
    "     \"event\": \"titre_apparait\"},\n",
    "    {\"name\": \"Chapitre 1\", \"bg\": (100, 60, 40), \"text\": \"Machine Learning\",\n",
    "     \"event\": \"chapitre_ml\"},\n",
    "    {\"name\": \"Demo\", \"bg\": (40, 100, 60), \"text\": \"Regression lineaire y=ax+b\",\n",
    "     \"event\": \"formule_visible\"},\n",
    "    {\"name\": \"Resultats\", \"bg\": (100, 100, 40), \"text\": \"Accuracy: 95.3%\",\n",
    "     \"event\": \"resultat_affiche\"},\n",
    "    {\"name\": \"Conclusion\", \"bg\": (80, 40, 100), \"text\": \"Merci - Questions?\",\n",
    "     \"event\": \"fin_presentation\"},\n",
    "]\n",
    "\n",
    "width, height = 640, 480\n",
    "frames_per_scene = sample_fps * sample_duration // len(scenes)\n",
    "all_frames = []\n",
    "event_timestamps = {}\n",
    "\n",
    "for scene_idx, scene in enumerate(scenes):\n",
    "    event_timestamps[scene['event']] = scene_idx * frames_per_scene / sample_fps\n",
    "    \n",
    "    for frame_i in range(frames_per_scene):\n",
    "        t = frame_i / frames_per_scene\n",
    "        global_frame = scene_idx * frames_per_scene + frame_i\n",
    "        global_t = global_frame / sample_fps\n",
    "        \n",
    "        img = Image.new('RGB', (width, height), scene['bg'])\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # Barre de progression en bas\n",
    "        progress = global_frame / (frames_per_scene * len(scenes))\n",
    "        draw.rectangle([0, height-10, int(width * progress), height], fill=(200, 200, 200))\n",
    "        \n",
    "        # Texte principal (pour OCR)\n",
    "        draw.text((width // 2 - 80, height // 2 - 20), scene['text'], fill='white')\n",
    "        \n",
    "        # Numero de scene\n",
    "        draw.text((20, 20), f\"Scene {scene_idx + 1}/5 : {scene['name']}\", fill='white')\n",
    "        draw.text((20, height - 30), f\"t={global_t:.1f}s | Frame {global_frame}\", fill='white')\n",
    "        \n",
    "        # Cercle anime\n",
    "        cx = int(width * 0.8 + 50 * np.cos(2 * np.pi * t))\n",
    "        cy = int(height * 0.3 + 30 * np.sin(2 * np.pi * t))\n",
    "        draw.ellipse([cx-15, cy-15, cx+15, cy+15], fill=(255, 255, 100))\n",
    "        \n",
    "        all_frames.append(np.array(img))\n",
    "\n",
    "# Sauvegarde\n",
    "test_video_path = OUTPUT_DIR / \"test_qwen_analysis.mp4\"\n",
    "writer = imageio.get_writer(str(test_video_path), fps=sample_fps, codec='libx264')\n",
    "for frame in all_frames:\n",
    "    writer.append_data(frame)\n",
    "writer.close()\n",
    "\n",
    "print(f\"Video creee : {test_video_path.name}\")\n",
    "print(f\"  {len(scenes)} scenes, {len(all_frames)} frames, {len(all_frames)/sample_fps:.1f}s\")\n",
    "print(f\"\\nEvenements temporels (verite terrain) :\")\n",
    "for event, ts in event_timestamps.items():\n",
    "    print(f\"  {event} : t={ts:.1f}s\")\n",
    "\n",
    "# Apercu\n",
    "fig, axes = plt.subplots(1, 5, figsize=(16, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = i * frames_per_scene + frames_per_scene // 2\n",
    "    ax.imshow(all_frames[idx])\n",
    "    ax.set_title(scenes[i]['name'], fontsize=9)\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Scenes de la video de test\", fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T10:03:39.061681Z",
     "iopub.status.busy": "2026-02-18T10:03:39.061467Z",
     "iopub.status.idle": "2026-02-18T10:03:39.068096Z",
     "shell.execute_reply": "2026-02-18T10:03:39.067575Z"
    },
    "papermill": {
     "duration": 0.010135,
     "end_time": "2026-02-18T10:03:39.068899",
     "exception": false,
     "start_time": "2026-02-18T10:03:39.058764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ANALYSE VIDEO QWEN2.5-VL ---\n",
      "=============================================\n",
      "Analyse desactivee\n"
     ]
    }
   ],
   "source": [
    "# Analyse video avec Qwen2.5-VL\n",
    "print(\"\\n--- ANALYSE VIDEO QWEN2.5-VL ---\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "def analyze_video_qwen(video_path: str, prompt: str,\n",
    "                       max_frames: int = 16) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyse une video avec Qwen2.5-VL.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Chemin vers le fichier video\n",
    "        prompt: Question ou instruction d'analyse\n",
    "        max_frames: Nombre max de frames a traiter\n",
    "    \n",
    "    Returns:\n",
    "        Dict avec analyse, temps de traitement et VRAM\n",
    "    \"\"\"\n",
    "    if model is None or processor is None:\n",
    "        return {\"success\": False, \"error\": \"Modele non charge\"}\n",
    "    \n",
    "    try:\n",
    "        # Construction du message avec video\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"video\",\n",
    "                    \"video\": str(video_path),\n",
    "                    \"max_pixels\": 360 * 420,\n",
    "                    \"fps\": 1.0  # 1 frame par seconde pour economiser la VRAM\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "        # Preparation des inputs\n",
    "        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        \n",
    "        from qwen_vl_utils import process_vision_info\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        \n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "        \n",
    "        # Generation\n",
    "        if device == \"cuda\":\n",
    "            vram_before = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        \n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=512\n",
    "            )\n",
    "        gen_time = time.time() - start_time\n",
    "        \n",
    "        # Decodage\n",
    "        generated_ids = output_ids[:, inputs['input_ids'].shape[1]:]\n",
    "        response_text = processor.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True\n",
    "        )[0]\n",
    "        \n",
    "        result = {\n",
    "            \"success\": True,\n",
    "            \"analysis\": response_text,\n",
    "            \"generation_time\": gen_time,\n",
    "            \"output_tokens\": generated_ids.shape[1],\n",
    "        }\n",
    "        \n",
    "        if device == \"cuda\":\n",
    "            vram_after = torch.cuda.memory_allocated(0) / 1024**3\n",
    "            result[\"vram_peak\"] = torch.cuda.max_memory_allocated(0) / 1024**3\n",
    "            result[\"vram_delta\"] = vram_after - vram_before\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": f\"{type(e).__name__}: {str(e)[:200]}\"}\n",
    "\n",
    "\n",
    "# Analyse 1 : Description globale\n",
    "if run_analysis:\n",
    "    print(\"Analyse 1 : Description globale\")\n",
    "    result_global = analyze_video_qwen(\n",
    "        test_video_path,\n",
    "        \"Decris cette video en francais. Identifie les differentes scenes, \"\n",
    "        \"les elements visuels principaux et la progression temporelle.\"\n",
    "    )\n",
    "    \n",
    "    if result_global['success']:\n",
    "        print(f\"  Temps : {result_global['generation_time']:.1f}s\")\n",
    "        print(f\"  Tokens generes : {result_global['output_tokens']}\")\n",
    "        if 'vram_peak' in result_global:\n",
    "            print(f\"  VRAM pic : {result_global['vram_peak']:.1f} GB\")\n",
    "        print(f\"\\n--- Analyse Qwen-VL ---\")\n",
    "        print(result_global['analysis'])\n",
    "    else:\n",
    "        print(f\"  Erreur : {result_global['error']}\")\n",
    "else:\n",
    "    print(\"Analyse desactivee\")\n",
    "    result_global = {\"success\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T10:03:39.073413Z",
     "iopub.status.busy": "2026-02-18T10:03:39.073243Z",
     "iopub.status.idle": "2026-02-18T10:03:39.076970Z",
     "shell.execute_reply": "2026-02-18T10:03:39.076592Z"
    },
    "papermill": {
     "duration": 0.006644,
     "end_time": "2026-02-18T10:03:39.077647",
     "exception": false,
     "start_time": "2026-02-18T10:03:39.071003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OCR video et temporal grounding\n",
    "results_ocr = {\"success\": False}\n",
    "results_grounding = {\"success\": False}\n",
    "\n",
    "if run_ocr and run_analysis:\n",
    "    print(\"\\n--- OCR VIDEO ---\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    results_ocr = analyze_video_qwen(\n",
    "        test_video_path,\n",
    "        \"Lis tout le texte visible dans cette video. Pour chaque texte trouve, \"\n",
    "        \"indique a quel moment il apparait et ce qu'il dit exactement.\"\n",
    "    )\n",
    "    \n",
    "    if results_ocr['success']:\n",
    "        print(f\"  Temps : {results_ocr['generation_time']:.1f}s\")\n",
    "        print(f\"\\n--- OCR Resultats ---\")\n",
    "        print(results_ocr['analysis'])\n",
    "    else:\n",
    "        print(f\"  Erreur OCR : {results_ocr['error']}\")\n",
    "\n",
    "if run_temporal_grounding and run_analysis:\n",
    "    print(\"\\n--- TEMPORAL GROUNDING ---\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    results_grounding = analyze_video_qwen(\n",
    "        test_video_path,\n",
    "        \"Dans cette video, identifie precisement les moments suivants :\\n\"\n",
    "        \"1. Quand le titre apparait pour la premiere fois\\n\"\n",
    "        \"2. Quand une formule mathematique est visible\\n\"\n",
    "        \"3. Quand un resultat de precision (accuracy) est affiche\\n\"\n",
    "        \"Donne les timestamps au format [debut - fin] en secondes.\"\n",
    "    )\n",
    "    \n",
    "    if results_grounding['success']:\n",
    "        print(f\"  Temps : {results_grounding['generation_time']:.1f}s\")\n",
    "        print(f\"\\n--- Temporal Grounding ---\")\n",
    "        print(results_grounding['analysis'])\n",
    "        \n",
    "        # Comparaison avec la verite terrain\n",
    "        print(f\"\\nVerite terrain (timestamps reels) :\")\n",
    "        for event, ts in event_timestamps.items():\n",
    "            print(f\"  {event} : t={ts:.1f}s\")\n",
    "    else:\n",
    "        print(f\"  Erreur grounding : {results_grounding['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T10:03:39.081821Z",
     "iopub.status.busy": "2026-02-18T10:03:39.081675Z",
     "iopub.status.idle": "2026-02-18T10:03:39.085918Z",
     "shell.execute_reply": "2026-02-18T10:03:39.085377Z"
    },
    "papermill": {
     "duration": 0.007202,
     "end_time": "2026-02-18T10:03:39.086597",
     "exception": false,
     "start_time": "2026-02-18T10:03:39.079395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MODE INTERACTIF ---\n",
      "========================================\n",
      "Posez une question sur la video de test a Qwen-VL.\n",
      "(Laissez vide pour passer a la suite)\n",
      "\n",
      "Mode interactif non disponible (execution automatisee)\n"
     ]
    }
   ],
   "source": [
    "# Mode interactif\n",
    "if notebook_mode == \"interactive\" and not skip_widgets:\n",
    "    print(\"\\n--- MODE INTERACTIF ---\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Posez une question sur la video de test a Qwen-VL.\")\n",
    "    print(\"(Laissez vide pour passer a la suite)\")\n",
    "    \n",
    "    try:\n",
    "        user_question = input(\"\\nVotre question : \").strip()\n",
    "        \n",
    "        if user_question and run_analysis:\n",
    "            result_user = analyze_video_qwen(test_video_path, user_question)\n",
    "            if result_user['success']:\n",
    "                print(f\"\\nReponse Qwen-VL :\")\n",
    "                print(result_user['analysis'])\n",
    "                print(f\"\\n({result_user['generation_time']:.1f}s, {result_user['output_tokens']} tokens)\")\n",
    "            else:\n",
    "                print(f\"Erreur : {result_user['error']}\")\n",
    "        elif not user_question:\n",
    "            print(\"Mode interactif ignore\")\n",
    "    \n",
    "    except (KeyboardInterrupt, EOFError) as e:\n",
    "        print(f\"\\nMode interactif interrompu ({type(e).__name__})\")\n",
    "    except Exception as e:\n",
    "        error_type = type(e).__name__\n",
    "        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n",
    "            print(\"\\nMode interactif non disponible (execution automatisee)\")\n",
    "        else:\n",
    "            print(f\"\\nErreur inattendue : {error_type} - {str(e)[:100]}\")\n",
    "            print(\"Passage a la suite du notebook\")\n",
    "else:\n",
    "    print(\"\\nMode batch - Interface interactive desactivee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {
    "papermill": {
     "duration": 0.001732,
     "end_time": "2026-02-18T10:03:39.090442",
     "exception": false,
     "start_time": "2026-02-18T10:03:39.088710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Comparaison GPT-5 vs Qwen2.5-VL\n",
    "\n",
    "| Critere | GPT-5 (API) | Qwen2.5-VL (local) |\n",
    "|---------|-------------|--------------------|\n",
    "| **Acces** | API cloud (cle requise) | Local (GPU requis) |\n",
    "| **VRAM** | 0 (cloud) | ~18 GB |\n",
    "| **Latence** | 2-10s (reseau) | 5-30s (GPU) |\n",
    "| **Cout** | ~$0.01-0.05/analyse | Gratuit apres setup |\n",
    "| **Confidentialite** | Donnees envoyees au cloud | 100% local |\n",
    "| **Video native** | Non (frames statiques) | Oui (temporal attention) |\n",
    "| **OCR** | Bon | Bon |\n",
    "| **Temporal grounding** | Approximatif | Natif |\n",
    "\n",
    "**Recommandations** :\n",
    "- Utilisez **GPT-5** pour du prototypage rapide ou sans GPU\n",
    "- Utilisez **Qwen-VL** pour du traitement en volume ou des donnees sensibles\n",
    "- Pour la production, evaluez sur votre cas d'usage specifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T10:03:39.094997Z",
     "iopub.status.busy": "2026-02-18T10:03:39.094665Z",
     "iopub.status.idle": "2026-02-18T10:03:39.101048Z",
     "shell.execute_reply": "2026-02-18T10:03:39.100572Z"
    },
    "papermill": {
     "duration": 0.009608,
     "end_time": "2026-02-18T10:03:39.101823",
     "exception": false,
     "start_time": "2026-02-18T10:03:39.092215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STATISTIQUES DE SESSION ---\n",
      "========================================\n",
      "Date : 2026-02-18 11:03:39\n",
      "Modele : Qwen/Qwen2.5-VL-7B-Instruct\n",
      "Device : cpu\n",
      "Analyses reussies : 0/3\n",
      "Resultats sauvegardes : qwen_vl_analysis_20260218_110339.json\n",
      "\n",
      "--- PROCHAINES ETAPES ---\n",
      "1. Notebook 01-4 : Amelioration video avec Real-ESRGAN (upscaling, interpolation)\n",
      "2. Notebook 01-5 : Introduction a AnimateDiff (generation text-to-video)\n",
      "3. Module 02 : Modeles generatifs video avances (HunyuanVideo, LTX-Video)\n",
      "\n",
      "Notebook 01-3 Qwen-VL Video Analysis termine - 11:03:39\n"
     ]
    }
   ],
   "source": [
    "# Statistiques de session et prochaines etapes\n",
    "print(\"\\n--- STATISTIQUES DE SESSION ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Modele : {model_name}\")\n",
    "print(f\"Device : {device}\")\n",
    "\n",
    "if device == \"cuda\" and torch.cuda.is_available():\n",
    "    vram_used = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    vram_peak = torch.cuda.max_memory_allocated(0) / 1024**3\n",
    "    print(f\"VRAM actuelle : {vram_used:.1f} GB\")\n",
    "    print(f\"VRAM pic : {vram_peak:.1f} GB\")\n",
    "\n",
    "analyses_done = sum([\n",
    "    result_global.get('success', False),\n",
    "    results_ocr.get('success', False),\n",
    "    results_grounding.get('success', False)\n",
    "])\n",
    "print(f\"Analyses reussies : {analyses_done}/3\")\n",
    "\n",
    "if save_results:\n",
    "    results_data = {\n",
    "        \"model\": model_name,\n",
    "        \"device\": device,\n",
    "        \"global_analysis\": result_global if result_global.get('success') else None,\n",
    "        \"ocr\": results_ocr if results_ocr.get('success') else None,\n",
    "        \"temporal_grounding\": results_grounding if results_grounding.get('success') else None,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    results_file = OUTPUT_DIR / f\"qwen_vl_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(results_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results_data, f, indent=2, ensure_ascii=False, default=str)\n",
    "    print(f\"Resultats sauvegardes : {results_file.name}\")\n",
    "\n",
    "# Liberation VRAM\n",
    "if model is not None:\n",
    "    del model\n",
    "    del processor\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"VRAM liberee\")\n",
    "\n",
    "print(f\"\\n--- PROCHAINES ETAPES ---\")\n",
    "print(f\"1. Notebook 01-4 : Amelioration video avec Real-ESRGAN (upscaling, interpolation)\")\n",
    "print(f\"2. Notebook 01-5 : Introduction a AnimateDiff (generation text-to-video)\")\n",
    "print(f\"3. Module 02 : Modeles generatifs video avances (HunyuanVideo, LTX-Video)\")\n",
    "\n",
    "print(f\"\\nNotebook 01-3 Qwen-VL Video Analysis termine - {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.422975,
   "end_time": "2026-02-18T10:03:39.340938",
   "environment_variables": {},
   "exception": null,
   "input_path": "D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\Video\\01-Foundation\\01-3-Qwen-VL-Video-Analysis.ipynb",
   "output_path": "D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\Video\\01-Foundation\\01-3-Qwen-VL-Video-Analysis.ipynb",
   "parameters": {},
   "start_time": "2026-02-18T10:03:33.917963",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}