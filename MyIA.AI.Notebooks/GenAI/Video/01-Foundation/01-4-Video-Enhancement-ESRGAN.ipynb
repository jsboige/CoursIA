{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Video Enhancement - Real-ESRGAN et Interpolation de Frames\n",
    "\n",
    "**Module :** 01-Video-Foundation  \n",
    "**Niveau :** Intermediaire  \n",
    "**Technologies :** Real-ESRGAN, basicsr, RIFE (concept), imageio  \n",
    "**Duree estimee :** 45 minutes  \n",
    "**VRAM :** ~4 GB  \n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "- [ ] Creer une video basse resolution pour tester l'upscaling\n",
    "- [ ] Appliquer Real-ESRGAN frame par frame (upscaling 2x et 4x)\n",
    "- [ ] Comprendre le pipeline extract -> upscale -> reassemble\n",
    "- [ ] Decouvrir le concept d'interpolation de frames (RIFE, 24fps -> 60fps)\n",
    "- [ ] Calculer les metriques de qualite PSNR et SSIM\n",
    "- [ ] Analyser le compromis qualite vs temps de traitement\n",
    "\n",
    "## Prerequis\n",
    "\n",
    "- GPU avec 4+ GB VRAM\n",
    "- Notebook 01-1 (Video Operations Basics) complete\n",
    "- Packages : `realesrgan`, `basicsr`, `torch`, `imageio`, `imageio-ffmpeg`, `scikit-image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parametres Papermill - JAMAIS modifier ce commentaire\n",
    "\n",
    "# Configuration notebook\n",
    "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
    "skip_widgets = False               # True pour mode batch MCP\n",
    "debug_level = \"INFO\"\n",
    "\n",
    "# Parametres upscaling\n",
    "scale_factor = 2                   # 2 ou 4\n",
    "model_name = \"RealESRGAN_x2plus\"   # \"RealESRGAN_x2plus\" ou \"RealESRGAN_x4plus\"\n",
    "tile_size = 256                    # Taille des tuiles (reduit la VRAM)\n",
    "\n",
    "# Video de test\n",
    "low_res_width = 160                # Largeur basse resolution\n",
    "low_res_height = 120               # Hauteur basse resolution\n",
    "test_fps = 12                      # FPS de la video de test\n",
    "test_duration = 3                  # Duree en secondes\n",
    "\n",
    "# Configuration\n",
    "run_upscaling = True               # Executer l'upscaling\n",
    "compute_metrics = True             # Calculer PSNR/SSIM\n",
    "save_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environnement et imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Import helpers GenAI\n",
    "GENAI_ROOT = Path.cwd()\n",
    "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
    "    GENAI_ROOT = GENAI_ROOT.parent\n",
    "\n",
    "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
    "if HELPERS_PATH.exists():\n",
    "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
    "    try:\n",
    "        from helpers.genai_helpers import setup_genai_logging\n",
    "        print(\"Helpers GenAI importes\")\n",
    "    except ImportError:\n",
    "        print(\"Helpers GenAI non disponibles - mode autonome\")\n",
    "\n",
    "OUTPUT_DIR = GENAI_ROOT / 'outputs' / 'video_enhancement'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=getattr(logging, debug_level))\n",
    "logger = logging.getLogger('video_enhancement')\n",
    "\n",
    "print(f\"Video Enhancement - Real-ESRGAN\")\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Mode : {notebook_mode}, Scale : {scale_factor}x, Modele : {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement .env et verification GPU\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_path = Path.cwd()\n",
    "found_env = False\n",
    "for _ in range(4):\n",
    "    env_path = current_path / '.env'\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"Fichier .env charge depuis : {env_path}\")\n",
    "        found_env = True\n",
    "        break\n",
    "    current_path = current_path.parent\n",
    "\n",
    "if not found_env:\n",
    "    print(\"Aucun fichier .env trouve\")\n",
    "\n",
    "# Verification GPU\n",
    "print(\"\\n--- VERIFICATION GPU ET DEPENDANCES ---\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    vram_total = torch.cuda.get_device_properties(0).total_mem / 1024**3\n",
    "    print(f\"GPU : {gpu_name}\")\n",
    "    print(f\"VRAM : {vram_total:.1f} GB\")\n",
    "else:\n",
    "    print(\"Pas de GPU. L'upscaling sera tres lent en mode CPU.\")\n",
    "\n",
    "# Verification Real-ESRGAN\n",
    "esrgan_available = False\n",
    "try:\n",
    "    from realesrgan import RealESRGANer\n",
    "    from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "    esrgan_available = True\n",
    "    print(f\"Real-ESRGAN : disponible\")\n",
    "except ImportError as e:\n",
    "    print(f\"Real-ESRGAN : NON INSTALLE\")\n",
    "    print(f\"  pip install realesrgan basicsr\")\n",
    "    print(f\"  Erreur : {e}\")\n",
    "\n",
    "# Verification imageio\n",
    "import imageio\n",
    "print(f\"imageio : v{imageio.__version__}\")\n",
    "\n",
    "# Verification scikit-image pour metriques\n",
    "metrics_available = False\n",
    "try:\n",
    "    from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "    metrics_available = True\n",
    "    print(f\"scikit-image : disponible (metriques PSNR/SSIM)\")\n",
    "except ImportError:\n",
    "    print(f\"scikit-image : NON INSTALLE (pip install scikit-image)\")\n",
    "    print(f\"  Metriques PSNR/SSIM non disponibles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Section 1 : Creation d'une video basse resolution\n",
    "\n",
    "Pour tester l'upscaling, nous creons d'abord une video \"haute resolution\" de reference,\n",
    "puis nous la degradons en basse resolution. Cela nous permet de comparer objectivement\n",
    "la version upscalee avec l'originale (calcul PSNR et SSIM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation de videos de reference et basse resolution\n",
    "print(\"\\n--- CREATION DES VIDEOS DE TEST ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Resolution haute (reference)\n",
    "hr_width = low_res_width * scale_factor\n",
    "hr_height = low_res_height * scale_factor\n",
    "n_frames = test_fps * test_duration\n",
    "\n",
    "print(f\"Resolution basse : {low_res_width}x{low_res_height}\")\n",
    "print(f\"Resolution haute (reference) : {hr_width}x{hr_height}\")\n",
    "print(f\"Frames : {n_frames}, FPS : {test_fps}\")\n",
    "\n",
    "# Generer les frames haute resolution\n",
    "hr_frames = []\n",
    "lr_frames = []\n",
    "\n",
    "for i in range(n_frames):\n",
    "    t = i / n_frames\n",
    "    \n",
    "    # Image HD avec details fins\n",
    "    img_hr = Image.new('RGB', (hr_width, hr_height), (30, 30, 60))\n",
    "    draw = ImageDraw.Draw(img_hr)\n",
    "    \n",
    "    # Formes avec details fins\n",
    "    cx = int(hr_width * 0.5 + hr_width * 0.3 * np.cos(2 * np.pi * t))\n",
    "    cy = int(hr_height * 0.5 + hr_height * 0.2 * np.sin(2 * np.pi * t))\n",
    "    \n",
    "    # Cercle principal\n",
    "    r = hr_height // 5\n",
    "    draw.ellipse([cx-r, cy-r, cx+r, cy+r], fill=(200, 80, 80), outline=(255, 200, 200), width=2)\n",
    "    \n",
    "    # Grille de fond (details fins pour tester la super-resolution)\n",
    "    for gx in range(0, hr_width, 20):\n",
    "        draw.line([(gx, 0), (gx, hr_height)], fill=(50, 50, 80), width=1)\n",
    "    for gy in range(0, hr_height, 20):\n",
    "        draw.line([(0, gy), (hr_width, gy)], fill=(50, 50, 80), width=1)\n",
    "    \n",
    "    # Petits cercles decoratifs\n",
    "    for j in range(5):\n",
    "        sx = int(hr_width * (0.1 + 0.2 * j) + 10 * np.sin(2 * np.pi * t + j))\n",
    "        sy = int(hr_height * 0.1 + 10 * np.cos(2 * np.pi * t + j))\n",
    "        draw.ellipse([sx-5, sy-5, sx+5, sy+5], fill=(100, 200, 100))\n",
    "    \n",
    "    # Texte\n",
    "    draw.text((10, 10), f\"Frame {i+1}/{n_frames}\", fill='white')\n",
    "    draw.text((10, hr_height - 20), f\"HR {hr_width}x{hr_height}\", fill='white')\n",
    "    \n",
    "    hr_frames.append(np.array(img_hr))\n",
    "    \n",
    "    # Version basse resolution (downscale)\n",
    "    img_lr = img_hr.resize((low_res_width, low_res_height), Image.Resampling.BICUBIC)\n",
    "    lr_frames.append(np.array(img_lr))\n",
    "\n",
    "# Sauvegarde des deux videos\n",
    "hr_video_path = OUTPUT_DIR / \"reference_hr.mp4\"\n",
    "lr_video_path = OUTPUT_DIR / \"input_lr.mp4\"\n",
    "\n",
    "for frames, path, label in [(hr_frames, hr_video_path, \"HR\"), (lr_frames, lr_video_path, \"LR\")]:\n",
    "    writer = imageio.get_writer(str(path), fps=test_fps, codec='libx264')\n",
    "    for frame in frames:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "    size_kb = path.stat().st_size / 1024\n",
    "    print(f\"Video {label} sauvegardee : {path.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "# Apercu comparatif\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 6))\n",
    "preview_indices = [0, n_frames // 3, 2 * n_frames // 3, n_frames - 1]\n",
    "for i, idx in enumerate(preview_indices):\n",
    "    axes[0, i].imshow(hr_frames[idx])\n",
    "    axes[0, i].set_title(f\"HR - Frame {idx}\", fontsize=9)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(lr_frames[idx])\n",
    "    axes[1, i].set_title(f\"LR - Frame {idx}\", fontsize=9)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel(f\"HR\\n{hr_width}x{hr_height}\", fontsize=10, fontweight='bold')\n",
    "axes[1, 0].set_ylabel(f\"LR\\n{low_res_width}x{low_res_height}\", fontsize=10, fontweight='bold')\n",
    "plt.suptitle(\"Reference HR vs Input LR\", fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Section 2 : Upscaling frame par frame avec Real-ESRGAN\n",
    "\n",
    "Le pipeline d'upscaling video est :\n",
    "1. **Extraire** les frames de la video basse resolution\n",
    "2. **Upscaler** chaque frame avec Real-ESRGAN\n",
    "3. **Reassembler** les frames upscalees en video\n",
    "\n",
    "Real-ESRGAN utilise un reseau RRDB (Residual-in-Residual Dense Block) entraine\n",
    "sur des paires d'images haute/basse resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscaling avec Real-ESRGAN\n",
    "sr_frames = []\n",
    "\n",
    "if run_upscaling and esrgan_available:\n",
    "    print(\"\\n--- UPSCALING REAL-ESRGAN ---\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Configuration du modele\n",
    "    if scale_factor == 2:\n",
    "        esrgan_model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
    "                               num_block=23, num_grow_ch=32, scale=2)\n",
    "        model_url = 'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth'\n",
    "    else:\n",
    "        esrgan_model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
    "                               num_block=23, num_grow_ch=32, scale=4)\n",
    "        model_url = 'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth'\n",
    "    \n",
    "    # Initialisation upsampler\n",
    "    upsampler = RealESRGANer(\n",
    "        scale=scale_factor,\n",
    "        model_path=model_url,\n",
    "        model=esrgan_model,\n",
    "        tile=tile_size,\n",
    "        tile_pad=10,\n",
    "        pre_pad=0,\n",
    "        half=True if device == \"cuda\" else False,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(f\"Modele : {model_name}\")\n",
    "    print(f\"Scale : {scale_factor}x\")\n",
    "    print(f\"Tile : {tile_size}\")\n",
    "    print(f\"Device : {device}\")\n",
    "    print(f\"\\nUpscaling de {len(lr_frames)} frames...\")\n",
    "    \n",
    "    # Upscaling frame par frame\n",
    "    start_time = time.time()\n",
    "    frame_times = []\n",
    "    \n",
    "    for i, lr_frame in enumerate(lr_frames):\n",
    "        frame_start = time.time()\n",
    "        \n",
    "        # Real-ESRGAN attend un array BGR (OpenCV convention)\n",
    "        import cv2\n",
    "        lr_bgr = cv2.cvtColor(lr_frame, cv2.COLOR_RGB2BGR)\n",
    "        sr_bgr, _ = upsampler.enhance(lr_bgr, outscale=scale_factor)\n",
    "        sr_rgb = cv2.cvtColor(sr_bgr, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        sr_frames.append(sr_rgb)\n",
    "        frame_time = time.time() - frame_start\n",
    "        frame_times.append(frame_time)\n",
    "        \n",
    "        if (i + 1) % 10 == 0 or i == 0:\n",
    "            print(f\"  Frame {i+1}/{len(lr_frames)} : {frame_time*1000:.0f}ms\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    avg_time = np.mean(frame_times)\n",
    "    \n",
    "    print(f\"\\nUpscaling termine\")\n",
    "    print(f\"  Temps total : {total_time:.1f}s\")\n",
    "    print(f\"  Temps moyen/frame : {avg_time*1000:.0f}ms\")\n",
    "    print(f\"  Resolution sortie : {sr_frames[0].shape[1]}x{sr_frames[0].shape[0]}\")\n",
    "    \n",
    "    # Sauvegarder la video upscalee\n",
    "    sr_video_path = OUTPUT_DIR / f\"upscaled_{scale_factor}x.mp4\"\n",
    "    writer = imageio.get_writer(str(sr_video_path), fps=test_fps, codec='libx264')\n",
    "    for frame in sr_frames:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "    \n",
    "    sr_size_kb = sr_video_path.stat().st_size / 1024\n",
    "    print(f\"  Video sauvegardee : {sr_video_path.name} ({sr_size_kb:.1f} KB)\")\n",
    "    \n",
    "elif not esrgan_available:\n",
    "    print(\"Real-ESRGAN non installe - upscaling ignore\")\n",
    "    print(\"Simulation avec resize bicubique pour la suite du notebook\")\n",
    "    \n",
    "    # Fallback : upscale bicubique (pour que le reste du notebook fonctionne)\n",
    "    for lr_frame in lr_frames:\n",
    "        img = Image.fromarray(lr_frame)\n",
    "        img_up = img.resize((hr_width, hr_height), Image.Resampling.BICUBIC)\n",
    "        sr_frames.append(np.array(img_up))\n",
    "    \n",
    "    sr_video_path = OUTPUT_DIR / f\"upscaled_bicubic_{scale_factor}x.mp4\"\n",
    "    writer = imageio.get_writer(str(sr_video_path), fps=test_fps, codec='libx264')\n",
    "    for frame in sr_frames:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "    print(f\"Video bicubique sauvegardee : {sr_video_path.name}\")\n",
    "else:\n",
    "    print(\"Upscaling desactive (run_upscaling=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison visuelle et metriques de qualite\n",
    "print(\"\\n--- COMPARAISON ET METRIQUES ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if sr_frames:\n",
    "    # Comparaison visuelle LR vs SR vs HR\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 10))\n",
    "    preview_indices = [0, n_frames // 3, 2 * n_frames // 3, n_frames - 1]\n",
    "    \n",
    "    for i, idx in enumerate(preview_indices):\n",
    "        # LR (upscalee en bicubique pour meme taille d'affichage)\n",
    "        lr_display = Image.fromarray(lr_frames[idx]).resize((hr_width, hr_height), Image.Resampling.NEAREST)\n",
    "        axes[0, i].imshow(np.array(lr_display))\n",
    "        axes[0, i].set_title(f\"Frame {idx}\", fontsize=9)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # SR\n",
    "        axes[1, i].imshow(sr_frames[idx])\n",
    "        axes[1, i].set_title(f\"Frame {idx}\", fontsize=9)\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # HR reference\n",
    "        axes[2, i].imshow(hr_frames[idx])\n",
    "        axes[2, i].set_title(f\"Frame {idx}\", fontsize=9)\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    axes[0, 0].set_ylabel(f\"LR\\n{low_res_width}x{low_res_height}\", fontsize=10, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel(f\"SR {scale_factor}x\\n{sr_frames[0].shape[1]}x{sr_frames[0].shape[0]}\",\n",
    "                          fontsize=10, fontweight='bold')\n",
    "    axes[2, 0].set_ylabel(f\"HR (ref)\\n{hr_width}x{hr_height}\", fontsize=10, fontweight='bold')\n",
    "    plt.suptitle(f\"Comparaison LR / SR ({scale_factor}x) / HR\", fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Metriques PSNR et SSIM\n",
    "    if compute_metrics and metrics_available and len(sr_frames) > 0:\n",
    "        print(\"\\nCalcul des metriques PSNR et SSIM...\")\n",
    "        psnr_values = []\n",
    "        ssim_values = []\n",
    "        \n",
    "        for i in range(min(len(sr_frames), len(hr_frames))):\n",
    "            sr_f = sr_frames[i]\n",
    "            hr_f = hr_frames[i]\n",
    "            \n",
    "            # Ajuster les dimensions si necessaire\n",
    "            if sr_f.shape != hr_f.shape:\n",
    "                sr_img = Image.fromarray(sr_f).resize((hr_width, hr_height), Image.Resampling.LANCZOS)\n",
    "                sr_f = np.array(sr_img)\n",
    "            \n",
    "            psnr_val = peak_signal_noise_ratio(hr_f, sr_f)\n",
    "            ssim_val = structural_similarity(hr_f, sr_f, channel_axis=2, data_range=255)\n",
    "            psnr_values.append(psnr_val)\n",
    "            ssim_values.append(ssim_val)\n",
    "        \n",
    "        avg_psnr = np.mean(psnr_values)\n",
    "        avg_ssim = np.mean(ssim_values)\n",
    "        \n",
    "        print(f\"\\nResultats metriques :\")\n",
    "        print(f\"{'Metrique':<15} {'Moyenne':<12} {'Min':<12} {'Max':<12}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'PSNR (dB)':<15} {avg_psnr:<12.2f} {min(psnr_values):<12.2f} {max(psnr_values):<12.2f}\")\n",
    "        print(f\"{'SSIM':<15} {avg_ssim:<12.4f} {min(ssim_values):<12.4f} {max(ssim_values):<12.4f}\")\n",
    "        \n",
    "        # Interpretation\n",
    "        print(f\"\\nInterpretation :\")\n",
    "        if avg_psnr > 30:\n",
    "            print(f\"  PSNR {avg_psnr:.1f} dB : Bonne qualite de reconstruction\")\n",
    "        elif avg_psnr > 25:\n",
    "            print(f\"  PSNR {avg_psnr:.1f} dB : Qualite acceptable\")\n",
    "        else:\n",
    "            print(f\"  PSNR {avg_psnr:.1f} dB : Qualite a ameliorer\")\n",
    "        \n",
    "        if avg_ssim > 0.9:\n",
    "            print(f\"  SSIM {avg_ssim:.4f} : Excellente similarite structurelle\")\n",
    "        elif avg_ssim > 0.8:\n",
    "            print(f\"  SSIM {avg_ssim:.4f} : Bonne similarite\")\n",
    "        else:\n",
    "            print(f\"  SSIM {avg_ssim:.4f} : Similarite moderee\")\n",
    "        \n",
    "        # Graphique evolution metriques\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        ax1.plot(psnr_values, 'b-', linewidth=1)\n",
    "        ax1.axhline(y=avg_psnr, color='r', linestyle='--', label=f'Moy: {avg_psnr:.1f}')\n",
    "        ax1.set_xlabel('Frame')\n",
    "        ax1.set_ylabel('PSNR (dB)')\n",
    "        ax1.set_title('PSNR par frame')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax2.plot(ssim_values, 'g-', linewidth=1)\n",
    "        ax2.axhline(y=avg_ssim, color='r', linestyle='--', label=f'Moy: {avg_ssim:.4f}')\n",
    "        ax2.set_xlabel('Frame')\n",
    "        ax2.set_ylabel('SSIM')\n",
    "        ax2.set_title('SSIM par frame')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle(f\"Metriques qualite - Upscaling {scale_factor}x\", fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    elif not metrics_available:\n",
    "        print(\"scikit-image non disponible - metriques non calculees\")\n",
    "else:\n",
    "    print(\"Pas de frames upscalees disponibles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Interpretation : Metriques de qualite\n",
    "\n",
    "| Metrique | Plage | Signification |\n",
    "|----------|-------|---------------|\n",
    "| **PSNR** | 0 - inf dB | Plus c'est eleve, meilleure est la qualite. >30 dB = bon, >40 dB = excellent |\n",
    "| **SSIM** | 0 - 1 | Similarite structurelle percue. >0.9 = excellent, >0.8 = bon |\n",
    "\n",
    "**Limites de ces metriques** :\n",
    "- PSNR mesure la difference pixel a pixel : ne capture pas la qualite percue\n",
    "- SSIM est meilleur pour la perception humaine mais reste imparfait\n",
    "- Real-ESRGAN peut generer des details qui n'existent pas dans la reference (hallucinations)\n",
    "\n",
    "## Section 3 : Concept d'interpolation de frames (RIFE)\n",
    "\n",
    "RIFE (Real-Time Intermediate Flow Estimation) permet de generer des frames\n",
    "intermediaires pour augmenter le framerate d'une video (ex: 24fps -> 60fps).\n",
    "Nous illustrons le concept avec une interpolation lineaire simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept d'interpolation de frames\n",
    "print(\"\\n--- INTERPOLATION DE FRAMES (CONCEPT) ---\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "def interpolate_frames_linear(frame_a: np.ndarray, frame_b: np.ndarray,\n",
    "                               n_intermediate: int = 1) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Interpolation lineaire simple entre deux frames.\n",
    "    Ceci est une demonstration du concept ; RIFE utilise un reseau neuronal\n",
    "    pour estimer le flux optique et generer des frames bien plus realistes.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in range(1, n_intermediate + 1):\n",
    "        alpha = i / (n_intermediate + 1)\n",
    "        interpolated = ((1 - alpha) * frame_a.astype(float) +\n",
    "                        alpha * frame_b.astype(float)).astype(np.uint8)\n",
    "        result.append(interpolated)\n",
    "    return result\n",
    "\n",
    "# Demonstration : interpoler entre 2 frames\n",
    "frame_a = lr_frames[0]\n",
    "frame_b = lr_frames[min(5, len(lr_frames) - 1)]\n",
    "n_inter = 3\n",
    "\n",
    "interpolated = interpolate_frames_linear(frame_a, frame_b, n_inter)\n",
    "all_display = [frame_a] + interpolated + [frame_b]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(all_display), figsize=(3 * len(all_display), 3))\n",
    "labels = [\"Frame A\"] + [f\"Interp {i+1}\" for i in range(n_inter)] + [\"Frame B\"]\n",
    "for ax, frame, label in zip(axes, all_display, labels):\n",
    "    ax.imshow(frame)\n",
    "    ax.set_title(label, fontsize=9)\n",
    "    ax.axis('off')\n",
    "plt.suptitle(f\"Interpolation lineaire ({n_inter} frames intermediaires)\",\n",
    "             fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Explication RIFE vs interpolation lineaire\n",
    "print(f\"\\nComparaison des methodes d'interpolation :\")\n",
    "print(f\"\")\n",
    "print(f\"{'Methode':<25} {'Qualite':<15} {'Vitesse':<15} {'VRAM':<10}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Lineaire (blend)':<25} {'Faible':<15} {'Instantanee':<15} {'0 MB':<10}\")\n",
    "print(f\"{'RIFE (flux optique)':<25} {'Excellente':<15} {'~50ms/frame':<15} {'~2 GB':<10}\")\n",
    "print(f\"{'Frame duplication':<25} {'Nulle':<15} {'Instantanee':<15} {'0 MB':<10}\")\n",
    "print(f\"\")\n",
    "print(f\"L'interpolation lineaire produit des artefacts de transparence (ghosting).\")\n",
    "print(f\"RIFE estime le mouvement entre frames et genere des intermediaires realistes.\")\n",
    "print(f\"Application typique : convertir 24fps en 60fps pour un rendu plus fluide.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode interactif\n",
    "if notebook_mode == \"interactive\" and not skip_widgets:\n",
    "    print(\"\\n--- MODE INTERACTIF ---\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Entrez un chemin vers une video pour l'upscaler.\")\n",
    "    print(\"(Laissez vide pour passer a la suite)\")\n",
    "    \n",
    "    try:\n",
    "        user_video = input(\"\\nChemin video (ou vide) : \").strip()\n",
    "        \n",
    "        if user_video and Path(user_video).exists() and esrgan_available:\n",
    "            import decord\n",
    "            decord.bridge.set_bridge('native')\n",
    "            vr = decord.VideoReader(user_video)\n",
    "            \n",
    "            # Extraire et upscaler quelques frames\n",
    "            indices = np.linspace(0, len(vr) - 1, 4, dtype=int).tolist()\n",
    "            user_frames = vr.get_batch(indices).asnumpy()\n",
    "            \n",
    "            print(f\"Upscaling de {len(indices)} frames...\")\n",
    "            for i, frame in enumerate(user_frames):\n",
    "                import cv2\n",
    "                bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                sr_bgr, _ = upsampler.enhance(bgr, outscale=scale_factor)\n",
    "                sr_rgb = cv2.cvtColor(sr_bgr, cv2.COLOR_BGR2RGB)\n",
    "                print(f\"  Frame {i+1}: {frame.shape[:2]} -> {sr_rgb.shape[:2]}\")\n",
    "            print(\"Upscaling termine\")\n",
    "        elif user_video:\n",
    "            print(f\"Fichier non trouve ou Real-ESRGAN non disponible\")\n",
    "        else:\n",
    "            print(\"Mode interactif ignore\")\n",
    "    \n",
    "    except (KeyboardInterrupt, EOFError) as e:\n",
    "        print(f\"\\nMode interactif interrompu ({type(e).__name__})\")\n",
    "    except Exception as e:\n",
    "        error_type = type(e).__name__\n",
    "        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n",
    "            print(\"\\nMode interactif non disponible (execution automatisee)\")\n",
    "        else:\n",
    "            print(f\"\\nErreur inattendue : {error_type} - {str(e)[:100]}\")\n",
    "            print(\"Passage a la suite du notebook\")\n",
    "else:\n",
    "    print(\"\\nMode batch - Interface interactive desactivee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Bonnes pratiques et conseils d'optimisation\n",
    "\n",
    "| Aspect | Recommandation | Raison |\n",
    "|--------|---------------|--------|\n",
    "| **Scale factor** | 2x sauf si necessaire | 4x quadruple le temps et la VRAM |\n",
    "| **Tile size** | 256-512 | Plus petit = moins de VRAM, plus lent |\n",
    "| **Codec sortie** | H.264 (libx264) | Meilleur compromis qualite/compatibilite |\n",
    "| **Batch size** | 1 frame a la fois | Evite les OOM sur GPU |\n",
    "| **Pre-processing** | Debruiter avant upscale | ESRGAN amplifie aussi le bruit |\n",
    "\n",
    "**Quand utiliser l'upscaling** :\n",
    "- Videos anciennes ou de faible resolution d'origine\n",
    "- Preparation de contenu pour affichage haute resolution\n",
    "- Post-production de videos generees par IA (souvent en faible resolution)\n",
    "\n",
    "**Quand NE PAS utiliser l'upscaling** :\n",
    "- Video deja en haute resolution\n",
    "- Temps de traitement critique (streaming en temps reel)\n",
    "- Quand la fidelite pixel-exact est requise (imagerie medicale, satellite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques de session et prochaines etapes\n",
    "print(\"\\n--- STATISTIQUES DE SESSION ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Mode : {notebook_mode}\")\n",
    "print(f\"Scale factor : {scale_factor}x\")\n",
    "print(f\"Modele : {model_name}\")\n",
    "print(f\"Device : {device}\")\n",
    "print(f\"Frames traitees : {len(sr_frames)}\")\n",
    "\n",
    "if save_results and OUTPUT_DIR.exists():\n",
    "    generated_files = list(OUTPUT_DIR.glob('*'))\n",
    "    print(f\"\\nFichiers generes ({len(generated_files)}) :\")\n",
    "    for f in sorted(generated_files):\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f\"  {f.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(f\"\\n--- PROCHAINES ETAPES ---\")\n",
    "print(f\"1. Notebook 01-5 : Introduction a AnimateDiff (generation text-to-video)\")\n",
    "print(f\"2. Combiner upscaling + generation pour des videos haute qualite\")\n",
    "print(f\"3. Module 02 : Modeles generatifs video avances\")\n",
    "\n",
    "print(f\"\\nNotebook 01-4 Video Enhancement termine - {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}