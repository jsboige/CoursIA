{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-header",
   "metadata": {
    "papermill": {
     "duration": 0.002856,
     "end_time": "2026-02-26T07:10:11.312182",
     "exception": false,
     "start_time": "2026-02-26T07:10:11.309326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ComfyUI - Workflows Video via API\n",
    "\n",
    "**Module :** 03-Video-Orchestration  \n",
    "**Niveau :** Avance  \n",
    "**Technologies :** ComfyUI API, AnimateDiff nodes, VideoHelperSuite  \n",
    "**Duree estimee :** 60 minutes  \n",
    "**VRAM :** ~20 GB (depends on workflow)  \n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "- [ ] Se connecter a l'API ComfyUI et verifier l'etat du serveur\n",
    "- [ ] Soumettre un workflow AnimateDiff via l'API JSON\n",
    "- [ ] Utiliser les nodes VideoHelperSuite pour l'entree/sortie de frames\n",
    "- [ ] Suivre la progression et le monitoring d'un workflow\n",
    "- [ ] Telecharger et afficher la video generee\n",
    "- [ ] Comparer l'approche diffusers vs l'approche ComfyUI\n",
    "\n",
    "## Prerequis\n",
    "\n",
    "- Instance ComfyUI accessible (locale ou distante)\n",
    "- Notebooks 03-1 et 03-2 completes\n",
    "- Custom nodes : AnimateDiff-Evolved, VideoHelperSuite\n",
    "- Packages : `requests`, `websocket-client`, `torch`, `Pillow`, `imageio`\n",
    "\n",
    "**Navigation :** [<< 03-2](03-2-Video-Workflow-Orchestration.ipynb) | [Index](../README.md) | [Suivant >>](../04-Applications/04-1-Educational-Video-Generation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-params",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T07:10:11.319007Z",
     "iopub.status.busy": "2026-02-26T07:10:11.318729Z",
     "iopub.status.idle": "2026-02-26T07:10:11.324098Z",
     "shell.execute_reply": "2026-02-26T07:10:11.323246Z"
    },
    "papermill": {
     "duration": 0.010203,
     "end_time": "2026-02-26T07:10:11.325407",
     "exception": false,
     "start_time": "2026-02-26T07:10:11.315204",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parametres Papermill - JAMAIS modifier ce commentaire\n",
    "\n",
    "# Configuration notebook\n",
    "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
    "skip_widgets = False               # True pour mode batch MCP\n",
    "debug_level = \"INFO\"\n",
    "\n",
    "# Parametres ComfyUI\n",
    "comfyui_url = \"http://localhost:8188\"  # URL du serveur ComfyUI\n",
    "workflow_type = \"animatediff\"         # Type de workflow : \"animatediff\"\n",
    "enable_video_helper = True           # Utiliser VideoHelperSuite\n",
    "\n",
    "# Parametres generation\n",
    "prompt_text = \"a serene lake at sunset, soft ripples on water, golden light, cinematic\"  # Prompt\n",
    "negative_prompt = \"low quality, blurry, distorted, watermark\"  # Prompt negatif\n",
    "num_frames = 16                      # Nombre de frames\n",
    "width = 512                          # Largeur\n",
    "height = 512                         # Hauteur\n",
    "steps = 25                           # Etapes de debruitage\n",
    "cfg_scale = 7.5                      # CFG scale\n",
    "seed_value = 42                      # Graine\n",
    "fps_output = 8                       # FPS de sortie\n",
    "\n",
    "# Configuration\n",
    "run_workflow = True                   # Executer le workflow\n",
    "save_as_mp4 = True                   # Sauvegarder en MP4\n",
    "save_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc50087b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T07:10:11.331482Z",
     "iopub.status.busy": "2026-02-26T07:10:11.331237Z",
     "iopub.status.idle": "2026-02-26T07:10:11.334757Z",
     "shell.execute_reply": "2026-02-26T07:10:11.333966Z"
    },
    "papermill": {
     "duration": 0.007664,
     "end_time": "2026-02-26T07:10:11.335766",
     "exception": false,
     "start_time": "2026-02-26T07:10:11.328102",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "notebook_mode = \"batch\"\n",
    "skip_widgets = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T07:10:11.342243Z",
     "iopub.status.busy": "2026-02-26T07:10:11.341976Z",
     "iopub.status.idle": "2026-02-26T07:10:11.779438Z",
     "shell.execute_reply": "2026-02-26T07:10:11.778696Z"
    },
    "papermill": {
     "duration": 0.441473,
     "end_time": "2026-02-26T07:10:11.780492",
     "exception": false,
     "start_time": "2026-02-26T07:10:11.339019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers GenAI importes\n",
      "ComfyUI - Workflows Video via API\n",
      "Date : 2026-02-26 08:10:11\n",
      "Mode : batch\n",
      "ComfyUI URL : http://localhost:8188\n",
      "Workflow : animatediff\n",
      "VideoHelperSuite : True\n"
     ]
    }
   ],
   "source": [
    "# Setup environnement et imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Import helpers GenAI\n",
    "GENAI_ROOT = Path.cwd()\n",
    "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
    "    GENAI_ROOT = GENAI_ROOT.parent\n",
    "\n",
    "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
    "if HELPERS_PATH.exists():\n",
    "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
    "    try:\n",
    "        from helpers.genai_helpers import setup_genai_logging\n",
    "        print(\"Helpers GenAI importes\")\n",
    "    except ImportError:\n",
    "        print(\"Helpers GenAI non disponibles - mode autonome\")\n",
    "\n",
    "OUTPUT_DIR = GENAI_ROOT / 'outputs' / 'comfyui_video'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=getattr(logging, debug_level))\n",
    "logger = logging.getLogger('comfyui_video')\n",
    "\n",
    "print(f\"ComfyUI - Workflows Video via API\")\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Mode : {notebook_mode}\")\n",
    "print(f\"ComfyUI URL : {comfyui_url}\")\n",
    "print(f\"Workflow : {workflow_type}\")\n",
    "print(f\"VideoHelperSuite : {enable_video_helper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-env",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T07:10:11.786461Z",
     "iopub.status.busy": "2026-02-26T07:10:11.785922Z",
     "iopub.status.idle": "2026-02-26T07:10:16.219803Z",
     "shell.execute_reply": "2026-02-26T07:10:16.219301Z"
    },
    "papermill": {
     "duration": 4.437971,
     "end_time": "2026-02-26T07:10:16.220803",
     "exception": false,
     "start_time": "2026-02-26T07:10:11.782832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier .env charge depuis : D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\.env\n",
      "Token ComfyUI : non configure (connexion sans authentification)\n",
      "\n",
      "--- VERIFICATION COMFYUI ---\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComfyUI non accessible a http://localhost:8188\n",
      "Le notebook montrera les workflows sans les executer.\n",
      "\n",
      "ComfyUI disponible : False\n",
      "Workflow active : False\n"
     ]
    }
   ],
   "source": [
    "# Chargement .env et verification de la connexion ComfyUI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_path = Path.cwd()\n",
    "found_env = False\n",
    "for _ in range(4):\n",
    "    env_path = current_path / '.env'\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"Fichier .env charge depuis : {env_path}\")\n",
    "        found_env = True\n",
    "        break\n",
    "    current_path = current_path.parent\n",
    "\n",
    "if not found_env:\n",
    "    print(\"Aucun fichier .env trouve\")\n",
    "\n",
    "# Token d'authentification ComfyUI\n",
    "comfyui_token = os.environ.get('COMFYUI_AUTH_TOKEN', os.environ.get('COMFYUI_BEARER_TOKEN', ''))\n",
    "if comfyui_token:\n",
    "    print(f\"Token ComfyUI : configure ({comfyui_token[:8]}...)\")\n",
    "else:\n",
    "    print(\"Token ComfyUI : non configure (connexion sans authentification)\")\n",
    "\n",
    "# Verification de la connexion\n",
    "print(\"\\n--- VERIFICATION COMFYUI ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import requests\n",
    "\n",
    "comfyui_available = False\n",
    "comfyui_info = {}\n",
    "\n",
    "headers = {}\n",
    "if comfyui_token:\n",
    "    headers['Authorization'] = f'Bearer {comfyui_token}'\n",
    "\n",
    "try:\n",
    "    # Health check\n",
    "    response = requests.get(f\"{comfyui_url}/system_stats\", headers=headers, timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        stats = response.json()\n",
    "        comfyui_available = True\n",
    "        comfyui_info = stats\n",
    "        \n",
    "        print(f\"ComfyUI accessible : {comfyui_url}\")\n",
    "        \n",
    "        # GPU info\n",
    "        devices = stats.get('devices', [])\n",
    "        for dev in devices:\n",
    "            name = dev.get('name', 'Inconnu')\n",
    "            vram_total = dev.get('vram_total', 0) / 1024**3\n",
    "            vram_free = dev.get('vram_free', 0) / 1024**3\n",
    "            print(f\"  GPU : {name}\")\n",
    "            print(f\"  VRAM : {vram_free:.1f} / {vram_total:.1f} GB libre\")\n",
    "        \n",
    "        # Verifier les custom nodes\n",
    "        try:\n",
    "            obj_info = requests.get(f\"{comfyui_url}/object_info\", headers=headers, timeout=30)\n",
    "            if obj_info.status_code == 200:\n",
    "                nodes = obj_info.json()\n",
    "                animatediff_nodes = [n for n in nodes.keys() if 'animatediff' in n.lower()]\n",
    "                vhs_nodes = [n for n in nodes.keys() if 'video' in n.lower() and 'helper' in n.lower()]\n",
    "                \n",
    "                print(f\"\\n  AnimateDiff nodes : {len(animatediff_nodes)}\")\n",
    "                for n in animatediff_nodes[:5]:\n",
    "                    print(f\"    - {n}\")\n",
    "                if len(animatediff_nodes) > 5:\n",
    "                    print(f\"    ... et {len(animatediff_nodes) - 5} autres\")\n",
    "                \n",
    "                print(f\"  VideoHelperSuite nodes : {len(vhs_nodes)}\")\n",
    "                for n in vhs_nodes[:5]:\n",
    "                    print(f\"    - {n}\")\n",
    "                \n",
    "                if not animatediff_nodes:\n",
    "                    print(\"\\n  AnimateDiff-Evolved non installe dans ComfyUI\")\n",
    "                    print(\"  Le notebook montrera les workflows sans les executer\")\n",
    "        except Exception:\n",
    "            print(\"  Impossible de lister les nodes\")\n",
    "    else:\n",
    "        print(f\"ComfyUI repond avec status {response.status_code}\")\n",
    "        run_workflow = False\n",
    "\n",
    "except requests.ConnectionError:\n",
    "    print(f\"ComfyUI non accessible a {comfyui_url}\")\n",
    "    print(\"Le notebook montrera les workflows sans les executer.\")\n",
    "    run_workflow = False\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur connexion : {type(e).__name__}: {str(e)[:100]}\")\n",
    "    run_workflow = False\n",
    "\n",
    "print(f\"\\nComfyUI disponible : {comfyui_available}\")\n",
    "print(f\"Workflow active : {run_workflow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section1-intro",
   "metadata": {
    "papermill": {
     "duration": 0.00203,
     "end_time": "2026-02-26T07:10:16.225131",
     "exception": false,
     "start_time": "2026-02-26T07:10:16.223101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 1 : API ComfyUI et soumission de workflows\n",
    "\n",
    "ComfyUI expose une API REST et WebSocket pour piloter la generation.\n",
    "Contrairement a l'approche diffusers (Python direct), ComfyUI utilise\n",
    "des workflows JSON (graphes de nodes) que l'on soumet a un serveur.\n",
    "\n",
    "| Endpoint | Methode | Description |\n",
    "|----------|---------|-------------|\n",
    "| `/system_stats` | GET | Etat du serveur (GPU, queue) |\n",
    "| `/object_info` | GET | Liste des nodes disponibles |\n",
    "| `/prompt` | POST | Soumettre un workflow |\n",
    "| `/history/{id}` | GET | Resultats d'un workflow execute |\n",
    "| `/view` | GET | Telecharger une image/video generee |\n",
    "| `/ws` | WebSocket | Suivi en temps reel de la progression |\n",
    "\n",
    "### Architecture ComfyUI vs diffusers\n",
    "\n",
    "| Aspect | diffusers (Python) | ComfyUI (API) |\n",
    "|--------|--------------------|---------------|\n",
    "| Flexibilite | Code personnalise | Workflow visuel/JSON |\n",
    "| Reproductibilite | Script Python | Fichier JSON exportable |\n",
    "| GPU requis localement | Oui | Non (serveur distant possible) |\n",
    "| Custom nodes | Non applicable | Ecosysteme riche |\n",
    "| Monitoring | Manuel | WebSocket integre |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-workflow-def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T07:10:16.230473Z",
     "iopub.status.busy": "2026-02-26T07:10:16.230073Z",
     "iopub.status.idle": "2026-02-26T07:10:16.238645Z",
     "shell.execute_reply": "2026-02-26T07:10:16.238110Z"
    },
    "papermill": {
     "duration": 0.012452,
     "end_time": "2026-02-26T07:10:16.239661",
     "exception": false,
     "start_time": "2026-02-26T07:10:16.227209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WORKFLOW ANIMATEDIFF ---\n",
      "=============================================\n",
      "Workflow construit : 9 nodes\n",
      "\n",
      "Nodes du workflow :\n",
      "  [1] CheckpointLoaderSimple\n",
      "  [2] CLIPTextEncode\n",
      "  [3] CLIPTextEncode\n",
      "  [4] ADE_LoadAnimateDiffModel\n",
      "  [5] ADE_ApplyAnimateDiffModelSimple\n",
      "  [6] EmptyLatentImage\n",
      "  [7] KSampler\n",
      "  [8] VAEDecode\n",
      "  [9] VHS_VideoCombine\n",
      "\n",
      "Workflow sauvegarde : animatediff_workflow.json\n"
     ]
    }
   ],
   "source": [
    "# Definition du workflow AnimateDiff via l'API ComfyUI\n",
    "print(\"\\n--- WORKFLOW ANIMATEDIFF ---\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "\n",
    "def build_animatediff_workflow(\n",
    "    prompt: str,\n",
    "    negative: str,\n",
    "    width: int,\n",
    "    height: int,\n",
    "    frames: int,\n",
    "    steps: int,\n",
    "    cfg: float,\n",
    "    seed: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Construit un workflow AnimateDiff au format ComfyUI API.\n",
    "    \n",
    "    Le workflow suit la chaine :\n",
    "    CheckpointLoader -> CLIPTextEncode (pos/neg) -> AnimateDiffLoader\n",
    "    -> KSampler -> VAEDecode -> VHS_VideoCombine (ou SaveImage)\n",
    "    \n",
    "    Args:\n",
    "        prompt: Description textuelle positive\n",
    "        negative: Prompt negatif\n",
    "        width, height: Resolution video\n",
    "        frames: Nombre de frames\n",
    "        steps: Etapes de debruitage\n",
    "        cfg: CFG scale\n",
    "        seed: Graine de generation\n",
    "    \n",
    "    Returns:\n",
    "        Dict au format ComfyUI prompt API\n",
    "    \"\"\"\n",
    "    workflow = {\n",
    "        # Node 1 : Charger le modele SD 1.5\n",
    "        \"1\": {\n",
    "            \"class_type\": \"CheckpointLoaderSimple\",\n",
    "            \"inputs\": {\n",
    "                \"ckpt_name\": \"v1-5-pruned-emaonly.safetensors\"\n",
    "            }\n",
    "        },\n",
    "        # Node 2 : Encodage du prompt positif\n",
    "        \"2\": {\n",
    "            \"class_type\": \"CLIPTextEncode\",\n",
    "            \"inputs\": {\n",
    "                \"text\": prompt,\n",
    "                \"clip\": [\"1\", 1]  # Sortie CLIP du checkpoint\n",
    "            }\n",
    "        },\n",
    "        # Node 3 : Encodage du prompt negatif\n",
    "        \"3\": {\n",
    "            \"class_type\": \"CLIPTextEncode\",\n",
    "            \"inputs\": {\n",
    "                \"text\": negative,\n",
    "                \"clip\": [\"1\", 1]\n",
    "            }\n",
    "        },\n",
    "        # Node 4 : Charger le motion module AnimateDiff\n",
    "        \"4\": {\n",
    "            \"class_type\": \"ADE_LoadAnimateDiffModel\",\n",
    "            \"inputs\": {\n",
    "                \"model_name\": \"v3_sd15_mm.ckpt\"\n",
    "            }\n",
    "        },\n",
    "        # Node 5 : Appliquer AnimateDiff au modele\n",
    "        \"5\": {\n",
    "            \"class_type\": \"ADE_ApplyAnimateDiffModelSimple\",\n",
    "            \"inputs\": {\n",
    "                \"model\": [\"1\", 0],  # Sortie MODEL du checkpoint\n",
    "                \"motion_model\": [\"4\", 0]\n",
    "            }\n",
    "        },\n",
    "        # Node 6 : Latent vide (batch de frames)\n",
    "        \"6\": {\n",
    "            \"class_type\": \"EmptyLatentImage\",\n",
    "            \"inputs\": {\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"batch_size\": frames\n",
    "            }\n",
    "        },\n",
    "        # Node 7 : KSampler\n",
    "        \"7\": {\n",
    "            \"class_type\": \"KSampler\",\n",
    "            \"inputs\": {\n",
    "                \"model\": [\"5\", 0],  # Modele avec AnimateDiff\n",
    "                \"positive\": [\"2\", 0],\n",
    "                \"negative\": [\"3\", 0],\n",
    "                \"latent_image\": [\"6\", 0],\n",
    "                \"seed\": seed,\n",
    "                \"steps\": steps,\n",
    "                \"cfg\": cfg,\n",
    "                \"sampler_name\": \"euler\",\n",
    "                \"scheduler\": \"normal\",\n",
    "                \"denoise\": 1.0\n",
    "            }\n",
    "        },\n",
    "        # Node 8 : Decodage VAE\n",
    "        \"8\": {\n",
    "            \"class_type\": \"VAEDecode\",\n",
    "            \"inputs\": {\n",
    "                \"samples\": [\"7\", 0],\n",
    "                \"vae\": [\"1\", 2]  # Sortie VAE du checkpoint\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Node 9 : Sortie video (VideoHelperSuite ou SaveImage)\n",
    "    if enable_video_helper:\n",
    "        workflow[\"9\"] = {\n",
    "            \"class_type\": \"VHS_VideoCombine\",\n",
    "            \"inputs\": {\n",
    "                \"images\": [\"8\", 0],\n",
    "                \"frame_rate\": fps_output,\n",
    "                \"loop_count\": 0,\n",
    "                \"filename_prefix\": \"animatediff\",\n",
    "                \"format\": \"video/h264-mp4\",\n",
    "                \"pingpong\": False,\n",
    "                \"save_output\": True\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        workflow[\"9\"] = {\n",
    "            \"class_type\": \"SaveImage\",\n",
    "            \"inputs\": {\n",
    "                \"images\": [\"8\", 0],\n",
    "                \"filename_prefix\": \"animatediff_frame\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return workflow\n",
    "\n",
    "\n",
    "# Construire le workflow\n",
    "workflow = build_animatediff_workflow(\n",
    "    prompt=prompt_text,\n",
    "    negative=negative_prompt,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    frames=num_frames,\n",
    "    steps=steps,\n",
    "    cfg=cfg_scale,\n",
    "    seed=seed_value\n",
    ")\n",
    "\n",
    "print(f\"Workflow construit : {len(workflow)} nodes\")\n",
    "print(f\"\\nNodes du workflow :\")\n",
    "for node_id, node_data in workflow.items():\n",
    "    print(f\"  [{node_id}] {node_data['class_type']}\")\n",
    "\n",
    "# Sauvegarder le workflow JSON\n",
    "workflow_path = OUTPUT_DIR / \"animatediff_workflow.json\"\n",
    "with open(workflow_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\"prompt\": workflow}, f, indent=2)\n",
    "print(f\"\\nWorkflow sauvegarde : {workflow_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section2-intro",
   "metadata": {
    "papermill": {
     "duration": 0.001872,
     "end_time": "2026-02-26T07:10:16.243697",
     "exception": false,
     "start_time": "2026-02-26T07:10:16.241825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Structure du workflow\n",
    "\n",
    "| Node | Classe | Role |\n",
    "|------|--------|------|\n",
    "| 1 | `CheckpointLoaderSimple` | Charge le modele SD 1.5 (MODEL + CLIP + VAE) |\n",
    "| 2-3 | `CLIPTextEncode` | Encode les prompts positif et negatif |\n",
    "| 4 | `ADE_LoadAnimateDiffModel` | Charge le motion module v3 |\n",
    "| 5 | `ADE_ApplyAnimateDiffModelSimple` | Applique le motion module au modele |\n",
    "| 6 | `EmptyLatentImage` | Cree un batch de latents (1 par frame) |\n",
    "| 7 | `KSampler` | Debruite les latents |\n",
    "| 8 | `VAEDecode` | Decode les latents en images |\n",
    "| 9 | `VHS_VideoCombine` | Assemble les frames en video MP4 |\n",
    "\n",
    "**Points cles** :\n",
    "1. Chaque node est identifie par un ID unique (string) et a un `class_type`\n",
    "2. Les connexions sont exprimees par `[\"node_id\", output_index]`\n",
    "3. Le workflow est un DAG (graphe acyclique dirige) - pas de boucles\n",
    "\n",
    "## Section 2 : Soumission et monitoring du workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-submit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T07:10:16.249866Z",
     "iopub.status.busy": "2026-02-26T07:10:16.249497Z",
     "iopub.status.idle": "2026-02-26T07:10:16.264371Z",
     "shell.execute_reply": "2026-02-26T07:10:16.263222Z"
    },
    "papermill": {
     "duration": 0.020351,
     "end_time": "2026-02-26T07:10:16.266182",
     "exception": false,
     "start_time": "2026-02-26T07:10:16.245831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SOUMISSION DU WORKFLOW ---\n",
      "=============================================\n",
      "Workflow non execute (ComfyUI non disponible ou desactive)\n",
      "\n",
      "Schema d'execution :\n",
      "  1. POST /prompt avec le workflow JSON\n",
      "  2. Poll /history/{prompt_id} pour attendre la completion\n",
      "  3. GET /view pour telecharger les images/videos\n"
     ]
    }
   ],
   "source": [
    "# Soumission du workflow et monitoring\n",
    "print(\"\\n--- SOUMISSION DU WORKFLOW ---\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "client_id = str(uuid.uuid4())\n",
    "prompt_id = None\n",
    "generation_result = {\"success\": False}\n",
    "\n",
    "\n",
    "def submit_workflow(workflow: Dict, server_url: str, auth_headers: Dict) -> Optional[str]:\n",
    "    \"\"\"Soumet un workflow a ComfyUI et retourne le prompt_id.\"\"\"\n",
    "    payload = {\n",
    "        \"prompt\": workflow,\n",
    "        \"client_id\": client_id\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{server_url}/prompt\",\n",
    "            json=payload,\n",
    "            headers=auth_headers,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result.get('prompt_id')\n",
    "        else:\n",
    "            print(f\"  Erreur HTTP {response.status_code} : {response.text[:200]}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"  Erreur soumission : {type(e).__name__}: {str(e)[:100]}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def poll_progress(prompt_id: str, server_url: str, auth_headers: Dict,\n",
    "                  timeout: int = 300, poll_interval: float = 2.0) -> Dict:\n",
    "    \"\"\"\n",
    "    Attend la fin d'un workflow en interrogeant periodiquement l'historique.\n",
    "    \n",
    "    Retourne le resultat du workflow ou un dict d'erreur.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < timeout:\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{server_url}/history/{prompt_id}\",\n",
    "                headers=auth_headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                history = response.json()\n",
    "                if prompt_id in history:\n",
    "                    entry = history[prompt_id]\n",
    "                    status = entry.get('status', {})\n",
    "                    \n",
    "                    if status.get('completed', False):\n",
    "                        elapsed = time.time() - start_time\n",
    "                        return {\n",
    "                            \"success\": True,\n",
    "                            \"outputs\": entry.get('outputs', {}),\n",
    "                            \"elapsed\": elapsed\n",
    "                        }\n",
    "                    \n",
    "                    if status.get('status_str') == 'error':\n",
    "                        return {\n",
    "                            \"success\": False,\n",
    "                            \"error\": \"Workflow en erreur\",\n",
    "                            \"details\": status\n",
    "                        }\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"  En cours... {elapsed:.0f}s\", end='\\r')\n",
    "        time.sleep(poll_interval)\n",
    "    \n",
    "    return {\"success\": False, \"error\": f\"Timeout apres {timeout}s\"}\n",
    "\n",
    "\n",
    "def download_outputs(outputs: Dict, server_url: str, auth_headers: Dict) -> List[Image.Image]:\n",
    "    \"\"\"\n",
    "    Telecharge les images/videos generees depuis les outputs du workflow.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    \n",
    "    for node_id, node_output in outputs.items():\n",
    "        # Images standard (SaveImage node)\n",
    "        if 'images' in node_output:\n",
    "            for img_info in node_output['images']:\n",
    "                filename = img_info.get('filename', '')\n",
    "                subfolder = img_info.get('subfolder', '')\n",
    "                img_type = img_info.get('type', 'output')\n",
    "                \n",
    "                params = {\n",
    "                    'filename': filename,\n",
    "                    'subfolder': subfolder,\n",
    "                    'type': img_type\n",
    "                }\n",
    "                \n",
    "                try:\n",
    "                    resp = requests.get(\n",
    "                        f\"{server_url}/view\",\n",
    "                        params=params,\n",
    "                        headers=auth_headers,\n",
    "                        timeout=30\n",
    "                    )\n",
    "                    if resp.status_code == 200:\n",
    "                        from io import BytesIO\n",
    "                        img = Image.open(BytesIO(resp.content)).convert('RGB')\n",
    "                        images.append(img)\n",
    "                except Exception as e:\n",
    "                    print(f\"  Erreur telechargement {filename}: {e}\")\n",
    "        \n",
    "        # Videos (VHS_VideoCombine node)\n",
    "        if 'gifs' in node_output:\n",
    "            for vid_info in node_output['gifs']:\n",
    "                filename = vid_info.get('filename', '')\n",
    "                subfolder = vid_info.get('subfolder', '')\n",
    "                print(f\"  Video generee : {filename}\")\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "# Soumettre le workflow\n",
    "if run_workflow and comfyui_available:\n",
    "    print(f\"Client ID : {client_id[:8]}...\")\n",
    "    print(f\"Prompt : {prompt_text[:50]}...\")\n",
    "    print(f\"Parametres : {num_frames} frames, {steps} steps, CFG={cfg_scale}\")\n",
    "    \n",
    "    prompt_id = submit_workflow(workflow, comfyui_url, headers)\n",
    "    \n",
    "    if prompt_id:\n",
    "        print(f\"Workflow soumis : {prompt_id[:12]}...\")\n",
    "        print(f\"\\nAttente de la completion...\")\n",
    "        \n",
    "        generation_result = poll_progress(prompt_id, comfyui_url, headers, timeout=300)\n",
    "        \n",
    "        if generation_result['success']:\n",
    "            print(f\"\\nWorkflow termine en {generation_result['elapsed']:.1f}s\")\n",
    "            \n",
    "            # Telecharger les resultats\n",
    "            output_images = download_outputs(\n",
    "                generation_result['outputs'], comfyui_url, headers\n",
    "            )\n",
    "            generation_result['images'] = output_images\n",
    "            \n",
    "            if output_images:\n",
    "                print(f\"Images telechargees : {len(output_images)}\")\n",
    "                \n",
    "                # Affichage\n",
    "                n_display = min(8, len(output_images))\n",
    "                fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "                axes_flat = axes.flatten()\n",
    "                for i in range(n_display):\n",
    "                    axes_flat[i].imshow(output_images[i])\n",
    "                    axes_flat[i].set_title(f\"Frame {i+1}/{len(output_images)}\", fontsize=9)\n",
    "                    axes_flat[i].axis('off')\n",
    "                for i in range(n_display, len(axes_flat)):\n",
    "                    axes_flat[i].axis('off')\n",
    "                plt.suptitle(f\"ComfyUI AnimateDiff : {prompt_text[:50]}...\", fontsize=11, fontweight='bold')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Sauvegarder en MP4 local\n",
    "                if save_as_mp4 and output_images:\n",
    "                    import imageio\n",
    "                    mp4_path = OUTPUT_DIR / \"comfyui_animatediff.mp4\"\n",
    "                    frames_array = [np.array(img) for img in output_images]\n",
    "                    imageio.mimsave(str(mp4_path), frames_array, fps=fps_output)\n",
    "                    print(f\"MP4 sauvegarde : {mp4_path.name}\")\n",
    "            else:\n",
    "                print(\"Aucune image telechargee (la sortie est peut-etre une video)\")\n",
    "        else:\n",
    "            print(f\"\\nErreur : {generation_result.get('error', 'inconnue')}\")\n",
    "    else:\n",
    "        print(\"Soumission echouee\")\n",
    "else:\n",
    "    print(\"Workflow non execute (ComfyUI non disponible ou desactive)\")\n",
    "    print(\"\\nSchema d'execution :\")\n",
    "    print(\"  1. POST /prompt avec le workflow JSON\")\n",
    "    print(\"  2. Poll /history/{prompt_id} pour attendre la completion\")\n",
    "    print(\"  3. GET /view pour telecharger les images/videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section3-intro",
   "metadata": {
    "papermill": {
     "duration": 0.002516,
     "end_time": "2026-02-26T07:10:16.271838",
     "exception": false,
     "start_time": "2026-02-26T07:10:16.269322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Execution du workflow\n",
    "\n",
    "| Etape | Endpoint | Description |\n",
    "|-------|----------|-------------|\n",
    "| Soumission | `POST /prompt` | Envoie le workflow, retourne `prompt_id` |\n",
    "| Monitoring | `GET /history/{id}` | Interroge periodiquement l'etat |\n",
    "| Telechargement | `GET /view` | Recupere les images/videos generees |\n",
    "\n",
    "**Points cles** :\n",
    "1. ComfyUI traite les workflows de facon asynchrone (queue)\n",
    "2. Le monitoring par polling est simple mais moins reactif que WebSocket\n",
    "3. Les images sont stockees sur le serveur et telechargees a la demande\n",
    "\n",
    "## Section 3 : Comparaison diffusers vs ComfyUI\n",
    "\n",
    "Nous avons explore les deux approches de generation video. Comparons-les objectivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-comparison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T07:10:16.279227Z",
     "iopub.status.busy": "2026-02-26T07:10:16.278941Z",
     "iopub.status.idle": "2026-02-26T07:10:16.286049Z",
     "shell.execute_reply": "2026-02-26T07:10:16.285274Z"
    },
    "papermill": {
     "duration": 0.011855,
     "end_time": "2026-02-26T07:10:16.287183",
     "exception": false,
     "start_time": "2026-02-26T07:10:16.275328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- COMPARAISON DIFFUSERS VS COMFYUI ---\n",
      "==================================================\n",
      "Critere                diffusers              ComfyUI               \n",
      "------------------------------------------------------------------\n",
      "  Installation           pip install            Git clone + setup     \n",
      "  Flexibilite code       Totale (Python)        Via nodes JSON        \n",
      "  Interface visuelle     Non                    Oui (navigateur)      \n",
      "  Custom nodes           Non applicable         Ecosysteme riche      \n",
      "  Reproductibilite       Script Python          Workflow JSON         \n",
      "  GPU distant            Non (local only)       Oui (API REST)        \n",
      "  Debugging              pdb / print            Logs serveur          \n",
      "  Integration Python     Native                 Via API REST          \n",
      "  Community              HuggingFace            ComfyUI Manager       \n",
      "  Production batch       Scripts Python         API programmable      \n",
      "\n",
      "\n",
      "--- RECAPITULATIF DU MODULE 03 ---\n",
      "==================================================\n",
      "\n",
      "Notebook                                      Contenu principal                       \n",
      "-------------------------------------------------------------------------------------\n",
      "  03-1 Multi-Model Comparison                   Benchmark HunyuanVideo/LTX/Wan/SVD      \n",
      "  03-2 Workflow Orchestration                   Pipelines multi-modeles, batch, upscale \n",
      "  03-3 ComfyUI Video Workflows                  API ComfyUI, AnimateDiff, monitoring    \n",
      "\n",
      "Recommandation selon le profil :\n",
      "  Chercheur/Dev Python : diffusers (controle total, scripts personnalises)\n",
      "  Artiste/Designer : ComfyUI (interface visuelle, workflows partageables)\n",
      "  Production : ComfyUI API (GPU distant, file d'attente, monitoring)\n"
     ]
    }
   ],
   "source": [
    "# Comparaison diffusers vs ComfyUI\n",
    "print(\"\\n--- COMPARAISON DIFFUSERS VS COMFYUI ---\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "comparison_data = {\n",
    "    \"Critere\": [\n",
    "        \"Installation\",\n",
    "        \"Flexibilite code\",\n",
    "        \"Interface visuelle\",\n",
    "        \"Custom nodes\",\n",
    "        \"Reproductibilite\",\n",
    "        \"GPU distant\",\n",
    "        \"Debugging\",\n",
    "        \"Integration Python\",\n",
    "        \"Community\",\n",
    "        \"Production batch\"\n",
    "    ],\n",
    "    \"diffusers\": [\n",
    "        \"pip install\",\n",
    "        \"Totale (Python)\",\n",
    "        \"Non\",\n",
    "        \"Non applicable\",\n",
    "        \"Script Python\",\n",
    "        \"Non (local only)\",\n",
    "        \"pdb / print\",\n",
    "        \"Native\",\n",
    "        \"HuggingFace\",\n",
    "        \"Scripts Python\"\n",
    "    ],\n",
    "    \"ComfyUI\": [\n",
    "        \"Git clone + setup\",\n",
    "        \"Via nodes JSON\",\n",
    "        \"Oui (navigateur)\",\n",
    "        \"Ecosysteme riche\",\n",
    "        \"Workflow JSON\",\n",
    "        \"Oui (API REST)\",\n",
    "        \"Logs serveur\",\n",
    "        \"Via API REST\",\n",
    "        \"ComfyUI Manager\",\n",
    "        \"API programmable\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Affichage du tableau\n",
    "print(f\"{'Critere':<22} {'diffusers':<22} {'ComfyUI':<22}\")\n",
    "print(\"-\" * 66)\n",
    "for i in range(len(comparison_data['Critere'])):\n",
    "    print(f\"  {comparison_data['Critere'][i]:<22} {comparison_data['diffusers'][i]:<22} {comparison_data['ComfyUI'][i]:<22}\")\n",
    "\n",
    "# Recapitulatif du notebook\n",
    "print(f\"\\n\\n--- RECAPITULATIF DU MODULE 03 ---\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n{'Notebook':<45} {'Contenu principal':<40}\")\n",
    "print(\"-\" * 85)\n",
    "print(f\"  {'03-1 Multi-Model Comparison':<45} {'Benchmark HunyuanVideo/LTX/Wan/SVD':<40}\")\n",
    "print(f\"  {'03-2 Workflow Orchestration':<45} {'Pipelines multi-modeles, batch, upscale':<40}\")\n",
    "print(f\"  {'03-3 ComfyUI Video Workflows':<45} {'API ComfyUI, AnimateDiff, monitoring':<40}\")\n",
    "\n",
    "print(f\"\\nRecommandation selon le profil :\")\n",
    "print(f\"  Chercheur/Dev Python : diffusers (controle total, scripts personnalises)\")\n",
    "print(f\"  Artiste/Designer : ComfyUI (interface visuelle, workflows partageables)\")\n",
    "print(f\"  Production : ComfyUI API (GPU distant, file d'attente, monitoring)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-interactive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T07:10:16.294740Z",
     "iopub.status.busy": "2026-02-26T07:10:16.293871Z",
     "iopub.status.idle": "2026-02-26T07:10:16.302461Z",
     "shell.execute_reply": "2026-02-26T07:10:16.301609Z"
    },
    "papermill": {
     "duration": 0.013565,
     "end_time": "2026-02-26T07:10:16.303650",
     "exception": false,
     "start_time": "2026-02-26T07:10:16.290085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode batch - Interface interactive desactivee\n"
     ]
    }
   ],
   "source": [
    "# Mode interactif : modifier les parametres du workflow\n",
    "if notebook_mode == \"interactive\" and not skip_widgets:\n",
    "    print(\"\\n--- MODE INTERACTIF ---\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Entrez un prompt pour generer via ComfyUI AnimateDiff.\")\n",
    "    print(\"(Laissez vide pour passer a la suite)\")\n",
    "    \n",
    "    try:\n",
    "        user_prompt = input(\"\\nVotre prompt : \").strip()\n",
    "        \n",
    "        if user_prompt and run_workflow and comfyui_available:\n",
    "            print(f\"\\nGeneration : {user_prompt}\")\n",
    "            \n",
    "            user_workflow = build_animatediff_workflow(\n",
    "                prompt=user_prompt,\n",
    "                negative=negative_prompt,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                frames=num_frames,\n",
    "                steps=steps,\n",
    "                cfg=cfg_scale,\n",
    "                seed=seed_value + 100\n",
    "            )\n",
    "            \n",
    "            user_prompt_id = submit_workflow(user_workflow, comfyui_url, headers)\n",
    "            if user_prompt_id:\n",
    "                print(f\"Workflow soumis. Attente...\")\n",
    "                user_result = poll_progress(user_prompt_id, comfyui_url, headers)\n",
    "                \n",
    "                if user_result['success']:\n",
    "                    user_images = download_outputs(user_result['outputs'], comfyui_url, headers)\n",
    "                    if user_images:\n",
    "                        n_display = min(8, len(user_images))\n",
    "                        fig, axes = plt.subplots(1, n_display, figsize=(2.5 * n_display, 3))\n",
    "                        if n_display == 1:\n",
    "                            axes = [axes]\n",
    "                        for i in range(n_display):\n",
    "                            axes[i].imshow(user_images[i])\n",
    "                            axes[i].set_title(f\"Frame {i+1}\", fontsize=8)\n",
    "                            axes[i].axis('off')\n",
    "                        plt.suptitle(f\"ComfyUI : {user_prompt[:50]}...\", fontweight='bold')\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                    print(f\"Generation terminee en {user_result['elapsed']:.1f}s\")\n",
    "                else:\n",
    "                    print(f\"Erreur : {user_result.get('error', 'inconnue')}\")\n",
    "        elif user_prompt:\n",
    "            print(\"ComfyUI non disponible\")\n",
    "        else:\n",
    "            print(\"Mode interactif ignore\")\n",
    "    \n",
    "    except (KeyboardInterrupt, EOFError) as e:\n",
    "        print(f\"\\nMode interactif interrompu ({type(e).__name__})\")\n",
    "    except Exception as e:\n",
    "        error_type = type(e).__name__\n",
    "        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n",
    "            print(\"\\nMode interactif non disponible (execution automatisee)\")\n",
    "        else:\n",
    "            print(f\"\\nErreur inattendue : {error_type} - {str(e)[:100]}\")\n",
    "            print(\"Passage a la suite du notebook\")\n",
    "else:\n",
    "    print(\"\\nMode batch - Interface interactive desactivee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-conclusion",
   "metadata": {
    "papermill": {
     "duration": 0.002159,
     "end_time": "2026-02-26T07:10:16.308274",
     "exception": false,
     "start_time": "2026-02-26T07:10:16.306115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bonnes pratiques ComfyUI pour la video\n",
    "\n",
    "### Workflow AnimateDiff - conseils\n",
    "\n",
    "| Conseil | Details |\n",
    "|---------|--------|\n",
    "| Modele de base | SD 1.5 (recommande pour AnimateDiff v3) |\n",
    "| Motion module | `v3_sd15_mm.ckpt` (meilleure coherence) |\n",
    "| Sampler | `euler` ou `euler_ancestral` |\n",
    "| CFG | 6.0-8.0 (eviter > 10 pour la coherence temporelle) |\n",
    "| Frames | 16-24 (au-dela, la coherence diminue) |\n",
    "| Resolution | 512x512 (limitation SD 1.5) |\n",
    "\n",
    "### VideoHelperSuite - nodes essentiels\n",
    "\n",
    "| Node | Usage |\n",
    "|------|-------|\n",
    "| `VHS_VideoCombine` | Assembler les frames en video MP4/GIF |\n",
    "| `VHS_LoadVideo` | Charger une video existante comme input |\n",
    "| `VHS_SplitVideo` | Decomposer une video en frames |\n",
    "| `VHS_MergeImages` | Combiner des sequences de frames |\n",
    "\n",
    "### Securite et authentification\n",
    "\n",
    "| Aspect | Recommandation |\n",
    "|--------|---------------|\n",
    "| Token Bearer | Toujours utiliser en production |\n",
    "| HTTPS | Obligatoire pour les connexions distantes |\n",
    "| Timeouts | Configurer des timeouts raisonnables (5 min max) |\n",
    "| Validation | Verifier les outputs avant traitement |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-stats",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T07:10:16.314769Z",
     "iopub.status.busy": "2026-02-26T07:10:16.314482Z",
     "iopub.status.idle": "2026-02-26T07:10:16.321468Z",
     "shell.execute_reply": "2026-02-26T07:10:16.320661Z"
    },
    "papermill": {
     "duration": 0.012006,
     "end_time": "2026-02-26T07:10:16.322716",
     "exception": false,
     "start_time": "2026-02-26T07:10:16.310710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STATISTIQUES DE SESSION ---\n",
      "========================================\n",
      "Date : 2026-02-26 08:10:16\n",
      "Mode : batch\n",
      "ComfyUI URL : http://localhost:8188\n",
      "ComfyUI disponible : False\n",
      "Workflow type : animatediff\n",
      "VideoHelperSuite : True\n",
      "Parametres : 16 frames, 25 steps, CFG=7.5\n",
      "Resolution : 512x512\n",
      "\n",
      "Generation : non executee ou echouee\n",
      "\n",
      "Fichiers generes (1) :\n",
      "  animatediff_workflow.json (2.1 KB)\n",
      "\n",
      "--- PROCHAINES ETAPES ---\n",
      "1. Module 04-1 : Generation video educative (applications production)\n",
      "2. Explorer les workflows ComfyUI avances (ControlNet video, IP-Adapter)\n",
      "3. Combiner ComfyUI + diffusers dans un pipeline hybride\n",
      "4. Deployer un serveur ComfyUI pour la generation a la demande\n",
      "\n",
      "Notebook 03-3 ComfyUI Video Workflows termine - 08:10:16\n"
     ]
    }
   ],
   "source": [
    "# Statistiques de session et prochaines etapes\n",
    "print(\"\\n--- STATISTIQUES DE SESSION ---\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Mode : {notebook_mode}\")\n",
    "print(f\"ComfyUI URL : {comfyui_url}\")\n",
    "print(f\"ComfyUI disponible : {comfyui_available}\")\n",
    "print(f\"Workflow type : {workflow_type}\")\n",
    "print(f\"VideoHelperSuite : {enable_video_helper}\")\n",
    "print(f\"Parametres : {num_frames} frames, {steps} steps, CFG={cfg_scale}\")\n",
    "print(f\"Resolution : {width}x{height}\")\n",
    "\n",
    "if generation_result.get('success'):\n",
    "    print(f\"\\nGeneration : OK en {generation_result.get('elapsed', 0):.1f}s\")\n",
    "    n_images = len(generation_result.get('images', []))\n",
    "    print(f\"Images telechargees : {n_images}\")\n",
    "else:\n",
    "    print(f\"\\nGeneration : non executee ou echouee\")\n",
    "\n",
    "if save_results and OUTPUT_DIR.exists():\n",
    "    generated_files = list(OUTPUT_DIR.glob('*'))\n",
    "    print(f\"\\nFichiers generes ({len(generated_files)}) :\")\n",
    "    for f in sorted(generated_files):\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f\"  {f.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(f\"\\n--- PROCHAINES ETAPES ---\")\n",
    "print(f\"1. Module 04-1 : Generation video educative (applications production)\")\n",
    "print(f\"2. Explorer les workflows ComfyUI avances (ControlNet video, IP-Adapter)\")\n",
    "print(f\"3. Combiner ComfyUI + diffusers dans un pipeline hybride\")\n",
    "print(f\"4. Deployer un serveur ComfyUI pour la generation a la demande\")\n",
    "\n",
    "print(f\"\\nNotebook 03-3 ComfyUI Video Workflows termine - {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.337919,
   "end_time": "2026-02-26T07:10:16.672668",
   "environment_variables": {},
   "exception": null,
   "input_path": "D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\Video\\03-Orchestration\\03-3-ComfyUI-Video-Workflows.ipynb",
   "output_path": "D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\Video\\03-Orchestration\\03-3-ComfyUI-Video-Workflows.ipynb",
   "parameters": {
    "notebook_mode": "batch",
    "skip_widgets": true
   },
   "start_time": "2026-02-26T07:10:09.334749",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}