{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération d’un patron de point de croix à partir d’une image\n",
    "\n",
    "Ce notebook a pour objectif de transformer une image en **patron de point de croix**. Il va :\n",
    "1. Permettre l’upload d’une image via un widget.\n",
    "2. Envoyer cette image (ou un prompt associé) à l’API d’un service **Stable Diffusion** pour en obtenir une version “pixel art”.\n",
    "3. Réduire la palette de couleurs et associer chaque couleur aux fils **DMC** les plus proches en s’appuyant sur un fichier JSON local.\n",
    "4. Générer une grille adaptée, avec un symbole distinct pour chaque couleur, afin de faciliter la broderie.\n",
    "\n",
    "Les étapes suivantes vous guideront pas à pas :\n",
    "- **Installation des dépendances**  \n",
    "- **Imports et configuration**  \n",
    "- **Upload de l’image**  \n",
    "- … *(à compléter ensuite)* …\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation / Mise à jour des dépendances\n",
    "\n",
    "La cellule suivante permet d’installer ou de mettre à jour les librairies nécessaires :\n",
    "\n",
    "- `numpy` pour le traitement en tableaux numériques.\n",
    "- `pillow` pour la gestion des images (PIL).\n",
    "- `requests` pour les requêtes HTTP (appel à l’API).\n",
    "- `ipywidgets` pour les widgets interactifs.\n",
    "- `jupyter-ui-poll` pour la boucle d’événements asynchrone dans Jupyter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installe/Met à jour les bibliothèques manquantes.\n",
    "\n",
    "%pip install numpy pillow requests ipywidgets jupyter-ui-poll --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import io\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Chargement du fichier local DMC_colors.json\n",
    "# (Assurez-vous que le fichier DMC_colors.json est bien dans le même dossier que le notebook)\n",
    "try:\n",
    "    with open(\"DMC_colors.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        DMC_COLORS = json.load(f)\n",
    "    print(f\"Nombre de références DMC chargées : {len(DMC_COLORS)}\")\n",
    "except FileNotFoundError:\n",
    "    DMC_COLORS = []\n",
    "    print(\"Fichier DMC_colors.json non trouvé. Veuillez vérifier son emplacement.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramètres de génération (img2img)\n",
    "\n",
    "- **prompt** : C’est la description textuelle qui oriente la génération.  \n",
    "- **steps** : Nombre d’itérations de sampling (plus haut = plus de détails, plus long).  \n",
    "- **sampler_name** : Algorithme de sampling (ex. Euler a, DPM++ 2M, etc.).  \n",
    "- **cfg_scale** : Facteur de guidance (plus c’est élevé, plus l’image colle au prompt, mais peut être moins créative).  \n",
    "- **width / height** : Dimensions de l’image en pixels.  \n",
    "- **denoising_strength** : Dans le contexte img2img, indique dans quelle mesure l’image initiale est altérée par la diffusion (0.0 = pas de changement, 1.0 = radicalement transformée).  \n",
    "- **n_iter** / **batch_size** : Contrôlent le nombre d’images générées. Ici, nous renvoyons 3 images pour laisser le choix.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Paramètre de base pour l’endpoint Stable Diffusion\n",
    "\n",
    "# Chargement des variables d'environnement depuis .env\n",
    "load_dotenv()\n",
    "\n",
    "# Récupération de l'URL de l'API Stable Diffusion depuis .env\n",
    "SD_BASE_URL = os.getenv(\"SD_BASE_URL\", \"https://stable-diffusion-webui-forge.yourdomain.com\")\n",
    "\n",
    "# Construct the full API URL by appending the endpoint path\n",
    "SD_API_URL = f\"{SD_BASE_URL}/sdapi/v1/img2img\"\n",
    "\n",
    "# Paramètres par défaut pour la requête (vous pouvez les affiner à la demande)\n",
    "default_img2img_payload = {\n",
    "    \"prompt\": \"<lora:pixelbuildings128-v2:1> Pixel Art\",\n",
    "    \"steps\": 20,\n",
    "    \"sampler_name\": \"DPM++ 2M SDE\",\n",
    "    \"scheduler\": \"karras\",\n",
    "    \"cfg_scale\": 7.5,\n",
    "    \"width\": 1024,\n",
    "    \"height\": 1024,\n",
    "    \"denoising_strength\": 0.37,\n",
    "    \"override_settings\": {\n",
    "        \"sd_model_checkpoint\": \"sd_xl_base_1.0\"\n",
    "    },\n",
    "    # \"seed\": 2096377536\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload de l’image\n",
    "\n",
    "Dans la prochaine cellule, vous pourrez sélectionner l’image que vous souhaitez transformer en patron de point de croix.\n",
    "\n",
    "- Choisissez un fichier **.png**, **.jpg**, ou **.jpeg** depuis votre ordinateur.\n",
    "- Le fichier sera ensuite stocké en mémoire dans le notebook (nous le lirons pour l’envoyer à l’API, ou pour l’afficher).\n",
    "\n",
    "**Étapes suivantes** (à venir) :\n",
    "- Nous enverrons l’image à notre endpoint Stable Diffusion pour obtenir la version \"pixel art\".\n",
    "- Nous appliquerons ensuite une réduction de palette et un matching avec les codes DMC.\n",
    "- Enfin, nous générerons la grille de points de croix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from jupyter_ui_poll import ui_events\n",
    "\n",
    "# ========================\n",
    "# Widgets pour l'upload et la génération\n",
    "# ========================\n",
    "upload_btn = widgets.FileUpload(\n",
    "    accept='image/*',\n",
    "    multiple=False,\n",
    "    description='Uploader une image'\n",
    ")\n",
    "\n",
    "generate_btn = widgets.Button(\n",
    "    description=\"Générer (img2img, 3 variantes)\",\n",
    "    button_style='success',\n",
    "    icon='magic'\n",
    ")\n",
    "\n",
    "upload_output = widgets.Output()\n",
    "generate_output = widgets.Output()\n",
    "\n",
    "# ========================\n",
    "# Widgets pour la sélection de l'image préférée\n",
    "# ========================\n",
    "selection_dropdown = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description='Choix :',\n",
    "    disabled=False\n",
    ")\n",
    "confirm_selection_btn = widgets.Button(\n",
    "    description=\"Valider ce choix\",\n",
    "    button_style='info',\n",
    "    icon='check'\n",
    ")\n",
    "selection_output = widgets.Output()\n",
    "\n",
    "# ========================\n",
    "# Variables de contrôle\n",
    "# ========================\n",
    "image_uploaded = False\n",
    "generation_done = False\n",
    "encoded_init_image = None\n",
    "candidate_images = []  # contiendra la liste des images générées (PIL)\n",
    "\n",
    "# ========================\n",
    "# Callbacks\n",
    "# ========================\n",
    "def on_upload_change(change):\n",
    "    \"\"\"\n",
    "    Callback appelé lorsque l'utilisateur a uploadé un fichier.\n",
    "    \"\"\"\n",
    "    global image_uploaded, encoded_init_image\n",
    "    if upload_btn.value:\n",
    "        file_info = upload_btn.value[0]\n",
    "        file_bytes = file_info['content']\n",
    "\n",
    "        # Convertir en base64 pour l'envoyer à l'API\n",
    "        encoded_init_image = base64.b64encode(file_bytes).decode('utf-8')\n",
    "\n",
    "        with upload_output:\n",
    "            upload_output.clear_output()\n",
    "            print(\"✅ Image chargée. Taille (octets) :\", len(file_bytes))\n",
    "            # Affichage de l'image en miniature\n",
    "            img = Image.open(io.BytesIO(file_bytes))\n",
    "            display(img)\n",
    "\n",
    "        image_uploaded = True\n",
    "\n",
    "def on_generate_click_batch(button):\n",
    "    \"\"\"\n",
    "    Callback appelé lorsque l'utilisateur clique sur 'Générer'.\n",
    "    Effectue l'appel à l'API /sdapi/v1/img2img pour générer 3 images.\n",
    "    \"\"\"\n",
    "    global generation_done, candidate_images\n",
    "    generation_done = False\n",
    "    candidate_images = []\n",
    "\n",
    "    if not image_uploaded or not encoded_init_image:\n",
    "        with generate_output:\n",
    "            generate_output.clear_output()\n",
    "            print(\"❌ Veuillez d'abord uploader une image.\")\n",
    "        return\n",
    "\n",
    "    # Construire le payload pour l'img2img, en générant 3 images\n",
    "    payload = default_img2img_payload.copy()\n",
    "    payload[\"init_images\"] = [encoded_init_image]\n",
    "    payload[\"n_iter\"] = 1\n",
    "    payload[\"batch_size\"] = 3\n",
    "\n",
    "    with generate_output:\n",
    "        generate_output.clear_output()\n",
    "        print(\"⏳ Génération en cours (3 images)...\")\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url=SD_API_URL, json=payload, timeout=120)\n",
    "            r = response.json()\n",
    "\n",
    "            # Récupérer la liste des images générées (base64)\n",
    "            result_images = r.get('images', [])\n",
    "            if not result_images:\n",
    "                print(\"❌ Aucune image reçue de l'API.\")\n",
    "            else:\n",
    "                print(f\"✅ {len(result_images)} image(s) générée(s).\")\n",
    "                for idx, img_b64 in enumerate(result_images):\n",
    "                    img_data = base64.b64decode(img_b64)\n",
    "                    img_pil = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "                    # On stocke l'image dans la liste\n",
    "                    candidate_images.append(img_pil)\n",
    "\n",
    "                    # Affichage rapide\n",
    "                    display(img_pil)\n",
    "                    print(f\"↑ Image #{idx} ↑\\n\")\n",
    "\n",
    "                # On remplit le dropdown pour la sélection\n",
    "                selection_dropdown.options = [\n",
    "                    (f\"Image #{i}\", i) for i in range(len(candidate_images))\n",
    "                ]\n",
    "                selection_dropdown.value = 0  # sélection par défaut de la première\n",
    "                print(\"👉 Choisissez votre image préférée ci-dessous, puis cliquez sur 'Valider ce choix'.\")\n",
    "\n",
    "            generation_done = True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lors de l'appel à l'API img2img : {e}\")\n",
    "\n",
    "def on_confirm_selection_click(b):\n",
    "    \"\"\"\n",
    "    Callback pour valider l'image sélectionnée dans le dropdown.\n",
    "    \"\"\"\n",
    "    global generated_image  # On mettra l'image choisie ici\n",
    "    with selection_output:\n",
    "        selection_output.clear_output()\n",
    "\n",
    "        if not candidate_images:\n",
    "            print(\"❌ Aucune image à sélectionner. Veuillez d'abord générer.\")\n",
    "            return\n",
    "\n",
    "        chosen_idx = selection_dropdown.value\n",
    "        chosen_img = candidate_images[chosen_idx]\n",
    "        generated_image = chosen_img  # On définit l'image globale\n",
    "\n",
    "        print(f\"✅ Vous avez choisi l'image #{chosen_idx}. Elle est maintenant stockée dans 'generated_image'.\")\n",
    "\n",
    "# ========================\n",
    "# Liaisons des callbacks\n",
    "# ========================\n",
    "upload_btn.observe(on_upload_change, names='value')\n",
    "generate_btn.on_click(on_generate_click_batch)\n",
    "confirm_selection_btn.on_click(on_confirm_selection_click)\n",
    "\n",
    "# ========================\n",
    "# Affichage des widgets\n",
    "# ========================\n",
    "display(widgets.HTML(\"<h3>Étape : Chargement de l'image et génération (3 variantes)</h3>\"))\n",
    "display(upload_btn)\n",
    "display(upload_output)\n",
    "display(generate_btn)\n",
    "display(generate_output)\n",
    "\n",
    "display(widgets.HTML(\"<h4>Étape : Sélection de l'image préférée</h4>\"))\n",
    "display(selection_dropdown)\n",
    "display(confirm_selection_btn)\n",
    "display(selection_output)\n",
    "\n",
    "# ========================\n",
    "# Boucle bloquante (optionnelle)\n",
    "# ========================\n",
    "print(\"En attente de l'upload puis du clic sur 'Générer (img2img, 3 variantes)' ...\")\n",
    "\n",
    "with ui_events() as poll:\n",
    "    # On attend que la génération soit terminée\n",
    "    while not generation_done:\n",
    "        # IMPORTANT : poll() ne doit pas recevoir un float, mais un entier.\n",
    "        poll(1)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "print(\"✅ Génération terminée ! Vous pouvez passer à la suite (ou refaire une génération).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduction de l’image en blocs de 8×8\n",
    "\n",
    "Le modèle de diffusion nous donne une image de 1024×800 pixels, mais il s’agit visuellement d’un « pixel art » où chaque “carré” mesure 8×8 pixels.  \n",
    "Pour simplifier le traitement, nous allons réduire l’image de la façon suivante :\n",
    "\n",
    "1. **Parcourir** l’image d’entrée par blocs de 8×8.  \n",
    "2. **Calculer la couleur moyenne** (ou dominante) de chaque bloc.  \n",
    "3. **Construire** une nouvelle image dont la taille sera (largeur/8) × (hauteur/8).  \n",
    "4. Chaque pixel de cette nouvelle image représentera le bloc 8×8 original.\n",
    "\n",
    "Ce résultat final de 128×100 (si l’image initiale fait 1024×800) sera bien plus simple à manipuler pour la suite du matching couleurs (DMC) et la création de la grille finale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "BLOCK_SIZE = 8\n",
    "\n",
    "def reduce_by_blocks(img: Image.Image, block_size: int = 8) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Réduit l'image en regroupant chaque bloc block_size x block_size\n",
    "    en un seul pixel, basé sur la couleur moyenne de ce bloc.\n",
    "    \"\"\"\n",
    "    # Convertir l'image en tableau numpy (RGBA ou RGB)\n",
    "    arr = np.array(img.convert(\"RGB\"))\n",
    "    h, w, _ = arr.shape\n",
    "    \n",
    "    # Dimensions du résultat final\n",
    "    new_w = w // block_size\n",
    "    new_h = h // block_size\n",
    "    \n",
    "    # Tableau numpy pour accueillir le résultat\n",
    "    small_arr = np.zeros((new_h, new_w, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Parcours par blocs\n",
    "    for y in range(new_h):\n",
    "        for x in range(new_w):\n",
    "            # Coordonnées du bloc\n",
    "            y0 = y * block_size\n",
    "            x0 = x * block_size\n",
    "            \n",
    "            # Sous-tableau correspondant au bloc (block_size x block_size x 3)\n",
    "            block = arr[y0:y0+block_size, x0:x0+block_size, :]\n",
    "            \n",
    "            # Moyenne sur l'axe (0,1) => (hauteur, largeur du bloc)\n",
    "            mean_color = block.mean(axis=(0,1))\n",
    "            \n",
    "            # On assigne au pixel (y, x)\n",
    "            small_arr[y, x] = mean_color.astype(np.uint8)\n",
    "    \n",
    "    # Création de l'image PIL à partir du tableau small_arr\n",
    "    small_img = Image.fromarray(small_arr, mode=\"RGB\")\n",
    "    return small_img\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# On suppose que vous avez déjà une variable `generated_image` (la sortie stable diffusion).\n",
    "# Si vous avez besoin de la relire depuis le disque, faites : generated_image = Image.open(\"nom_fichier.png\")\n",
    "\n",
    "if 'generated_image' in globals():\n",
    "    reduced_image = reduce_by_blocks(generated_image, block_size=BLOCK_SIZE)\n",
    "    \n",
    "    # Affichage du résultat\n",
    "    display(reduced_image)\n",
    "    print(f\"Nouvelle dimension : {reduced_image.width} x {reduced_image.height}\")\n",
    "else:\n",
    "    print(\"⚠️ La variable 'generated_image' n'est pas définie. Veuillez définir ou charger l'image d'abord.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching des couleurs et conversion vers la palette DMC\n",
    "\n",
    "Maintenant que nous avons une **image réduite** (par blocs 8×8) avec une dimension plus raisonnable (p. ex. 128×100), nous allons :\n",
    "\n",
    "1. **Analyser chaque pixel** pour connaître sa couleur.  \n",
    "2. Pour chacun de ces pixels (R, G, B), **trouver la couleur de fil DMC la plus proche**. Nous utiliserons un fichier `DMC_colors.json` contenant l’équivalence entre un code de fil (ex. 310, 498...) et un triplet (R, G, B).  \n",
    "3. Cette étape nous donnera une image où chaque pixel est remplacé par la couleur “officielle” du fil DMC correspondant, et/ou un tableau d’index de couleurs.  \n",
    "4. Enfin, nous pourrons générer la **grille de point de croix**, où chaque couleur DMC aura un **symbole** distinct pour la lisibilité.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def get_closest_dmc_color(r, g, b, dmc_list):\n",
    "    \"\"\"\n",
    "    Retourne (floss_code, floss_name, (R_dmc, G_dmc, B_dmc)) de la couleur DMC \n",
    "    la plus proche de (r,g,b). floss_code est une chaîne (car parfois c'est \"White\", \"B5200\"...).\n",
    "    \"\"\"\n",
    "    best_dist = float('inf')\n",
    "    best_data = (\"UNKNOWN\", \"NoName\", (0, 0, 0))\n",
    "\n",
    "    # Convertir r, g, b en int \"classique\" de Python (pas numpy)\n",
    "    r = int(r)\n",
    "    g = int(g)\n",
    "    b = int(b)\n",
    "\n",
    "    for item in dmc_list:\n",
    "        try:\n",
    "            R_dmc = int(item[\"r\"])\n",
    "            G_dmc = int(item[\"g\"])\n",
    "            B_dmc = int(item[\"b\"])\n",
    "        except (ValueError, TypeError, KeyError):\n",
    "            # Si on ne peut pas convertir en entier, on saute\n",
    "            continue\n",
    "\n",
    "        # Calcul de la distance au carré en Python pur\n",
    "        d_r = R_dmc - r\n",
    "        d_g = G_dmc - g\n",
    "        d_b = B_dmc - b\n",
    "        dist = d_r*d_r + d_g*d_g + d_b*d_b\n",
    "\n",
    "        if dist < best_dist:\n",
    "            best_dist = dist\n",
    "            floss_code = str(item[\"floss\"])  # ex: \"White\", \"B5200\", \"310\"\n",
    "            floss_name = item.get(\"name\", \"Unknown\")\n",
    "            best_data = (floss_code, floss_name, (R_dmc, G_dmc, B_dmc))\n",
    "\n",
    "    return best_data\n",
    "\n",
    "\n",
    "def convert_image_to_dmc(img: Image.Image, dmc_list):\n",
    "    \"\"\"\n",
    "    Parcourt chaque pixel de l'image (img) et renvoie:\n",
    "      - new_img: PIL Image recolorisée avec la couleur DMC la plus proche\n",
    "      - dmc_codes: tableau 2D (h,w) des codes 'floss' (str)\n",
    "    \"\"\"\n",
    "    # On convertit l'image en 'RGB', puis en numpy array\n",
    "    arr_rgb = np.array(img.convert(\"RGB\"), dtype=np.int16)\n",
    "    h, w, _ = arr_rgb.shape\n",
    "\n",
    "    # Création de deux tableaux de sortie\n",
    "    dmc_arr   = np.zeros((h, w, 3), dtype=np.uint8)   # image DMC (R,G,B)\n",
    "    dmc_codes = np.empty((h, w), dtype=object)        # codes DMC (str)\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            # On récupère la couleur du pixel en int16 (0..255 mais sign-safe)\n",
    "            r, g, b = arr_rgb[y, x]\n",
    "            floss_code, floss_name, (dr, dg, db) = get_closest_dmc_color(r, g, b, dmc_list)\n",
    "\n",
    "            dmc_arr[y, x]   = [dr, dg, db]\n",
    "            dmc_codes[y, x] = floss_code\n",
    "\n",
    "    # On convertit dmc_arr en image PIL\n",
    "    new_img = Image.fromarray(dmc_arr, mode=\"RGB\")\n",
    "    return new_img, dmc_codes\n",
    "\n",
    "\n",
    "# Exemple d’utilisation\n",
    "if 'reduced_image' in globals():\n",
    "    dmc_image, dmc_codes_array = convert_image_to_dmc(reduced_image, DMC_COLORS)\n",
    "    display(dmc_image)\n",
    "    print(\"Exemple: code DMC du pixel (0,0) =\", dmc_codes_array[0,0])\n",
    "else:\n",
    "    print(\"⚠️ 'reduced_image' n'est pas défini.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
