{
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "genai": {
      "enabled": true,
      "level": "environment",
      "module": "00-GenAI-Environment",
      "dependencies": [
        "requests",
        "python-dotenv",
        "matplotlib",
        "pandas",
        "time"
      ],
      "estimated_duration_minutes": 20,
      "difficulty": "beginner",
      "learning_outcomes": [
        "Configurer et tester les APIs OpenRouter et OpenAI",
        "Valider les clÃ©s API et permissions",
        "Effectuer des benchmarks de performance",
        "Diagnostiquer les problÃ¨mes de connectivitÃ©",
        "Monitorer l'utilisation des APIs"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# ğŸ”— Configuration des API Endpoints\n\n**Module :** 00-GenAI-Environment  \n**Niveau :** ğŸŸ¢ DÃ©butant  \n**Technologies :** OpenRouter, OpenAI API, Monitoring  \n**DurÃ©e estimÃ©e :** 20 minutes  \n\n## ğŸ¯ Objectifs d'Apprentissage\n\n- [ ] Configurer et tester les connexions API\n- [ ] Valider les clÃ©s API et permissions\n- [ ] Effectuer des benchmarks de performance\n- [ ] Diagnostiquer les problÃ¨mes courants\n- [ ] Monitorer l'utilisation et les coÃ»ts\n- [ ] Optimiser les paramÃ¨tres de connexion\n\n## ğŸ“š APIs ConfigurÃ©es\n\n### ğŸš€ OpenRouter API\n- **DALL-E 3** : `openai/dall-e-3`\n- **GPT-5** : `openai/gpt-5` \n- **Qwen-Image-Edit-2509** : `qwen/qwen-image-edit-2509`\n- **FLUX-1** : ModÃ¨les de gÃ©nÃ©ration avancÃ©e\n\n### ğŸ¤– OpenAI Direct API\n- **DALL-E 3** : AccÃ¨s direct OpenAI\n- **GPT-4 Vision** : Analyse d'images\n- **Whisper** : Transcription audio\n\n## âš™ï¸ PrÃ©requis\n\n- Fichier `.env` configurÃ© avec les clÃ©s API\n- AccÃ¨s internet stable\n- Python 3.11+ avec packages requis",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# ParamÃ¨tres Papermill - JAMAIS modifier ce commentaire\n\n# Configuration des tests\nnotebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\nskip_widgets = False               # True pour mode batch MCP\ndebug_level = \"INFO\"               \n\n# Tests Ã  effectuer\ntest_openrouter = True             # Tester OpenRouter API\ntest_openai_direct = True          # Tester OpenAI API directe\nrun_benchmarks = True              # Benchmarks de performance\ncheck_rate_limits = True           # VÃ©rifier les limites de taux\nmonitor_costs = True               # Monitoring des coÃ»ts\n\n# Configuration benchmarks\nbenchmark_iterations = 3           # Nombre de tests par endpoint\nbenchmark_timeout = 30             # Timeout par test (secondes)\nmodel_list_limit = 10              # Limite modÃ¨les Ã  tester\n\n# ParamÃ¨tres monitoring\nexport_results = True              # Exporter rÃ©sultats JSON\ngenerate_report = True             # GÃ©nÃ©rer rapport HTML\nshow_detailed_logs = False         # Logs dÃ©taillÃ©s (verbose)",
      "metadata": {
        "tags": ["parameters"]
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Setup environnement et imports\nimport os\nimport sys\nimport json\nimport requests\nimport time\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any, Optional\nimport logging\nfrom urllib.parse import urljoin\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dotenv import load_dotenv\n\n# Import helpers GenAI\nGENAI_ROOT = Path.cwd()\nwhile GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n    GENAI_ROOT = GENAI_ROOT.parent\n\nHELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\nif HELPERS_PATH.exists():\n    sys.path.insert(0, str(HELPERS_PATH.parent))\n    try:\n        from helpers.genai_helpers import setup_genai_logging, load_genai_config\n        print(\"âœ… Helpers GenAI importÃ©s\")\n    except ImportError:\n        print(\"âš ï¸  Helpers GenAI non disponibles - mode autonome\")\n\n# Configuration logging\nlogging.basicConfig(level=getattr(logging, debug_level))\nlogger = logging.getLogger('api_configuration')\n\n# Chargement des variables d'environnement\nenv_file = GENAI_ROOT / '.env'\nif env_file.exists():\n    load_dotenv(env_file)\n    print(f\"âœ… Variables d'environnement chargÃ©es depuis {env_file}\")\nelse:\n    print(f\"âš ï¸  Fichier .env non trouvÃ©: {env_file}\")\n    print(\"ğŸ’¡ Utilisez .env.template comme base\")\n\nprint(f\"\\nğŸ”— Configuration des API Endpoints\")\nprint(f\"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"ğŸ”§ Mode: {notebook_mode}, Benchmarks: {run_benchmarks}\")\nprint(f\"ğŸ·ï¸  Tests: OpenRouter={test_openrouter}, OpenAI={test_openai_direct}\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Configuration et validation des clÃ©s API\nprint(\"\\nğŸ”‘ VALIDATION DES CLÃ‰S API\")\nprint(\"=\" * 35)\n\n# Dictionnaire de configuration des APIs\napi_config = {\n    \"openrouter\": {\n        \"name\": \"OpenRouter\",\n        \"base_url\": \"https://openrouter.ai/api/v1\",\n        \"key_env\": \"OPENROUTER_API_KEY\",\n        \"key_value\": None,\n        \"headers\": {},\n        \"endpoints\": {\n            \"models\": \"/models\",\n            \"chat\": \"/chat/completions\",\n            \"images\": \"/images/generations\"\n        },\n        \"test_model\": \"openai/gpt-4o-mini\",\n        \"status\": \"unknown\"\n    },\n    \n    \"openai\": {\n        \"name\": \"OpenAI Direct\",\n        \"base_url\": \"https://api.openai.com/v1\",\n        \"key_env\": \"OPENAI_API_KEY\",\n        \"key_value\": None,\n        \"headers\": {},\n        \"endpoints\": {\n            \"models\": \"/models\",\n            \"chat\": \"/chat/completions\",\n            \"images\": \"/images/generations\"\n        },\n        \"test_model\": \"gpt-4o-mini\",\n        \"status\": \"unknown\"\n    }\n}\n\n# Validation et configuration des clÃ©s\nfor api_name, config in api_config.items():\n    print(f\"\\nğŸ” {config['name']}\")\n    print(\"-\" * 25)\n    \n    # RÃ©cupÃ©ration de la clÃ© API\n    api_key = os.getenv(config['key_env'])\n    \n    if api_key:\n        config['key_value'] = api_key\n        \n        # Configuration headers\n        if api_name == \"openrouter\":\n            config['headers'] = {\n                \"Authorization\": f\"Bearer {api_key}\",\n                \"HTTP-Referer\": \"https://coursia.myia.io\",\n                \"X-Title\": \"CoursIA GenAI Configuration\",\n                \"Content-Type\": \"application/json\"\n            }\n        else:  # OpenAI\n            config['headers'] = {\n                \"Authorization\": f\"Bearer {api_key}\",\n                \"Content-Type\": \"application/json\"\n            }\n        \n        # Masquage partiel de la clÃ© pour l'affichage\n        masked_key = f\"{api_key[:8]}...{api_key[-4:]}\" if len(api_key) > 12 else \"***\"\n        print(f\"âœ… ClÃ© API: {masked_key}\")\n        print(f\"ğŸ“ URL base: {config['base_url']}\")\n        print(f\"ğŸ¯ ModÃ¨le test: {config['test_model']}\")\n        config['status'] = \"configured\"\n    else:\n        print(f\"âŒ Variable manquante: {config['key_env']}\")\n        print(f\"ğŸ’¡ Ajoutez {config['key_env']}=your_key_here dans .env\")\n        config['status'] = \"missing\"\n\n# RÃ©sumÃ© de la configuration\nprint(f\"\\nğŸ“Š RÃ‰SUMÃ‰ CONFIGURATION\")\nprint(\"=\" * 30)\nconfigured_apis = sum(1 for c in api_config.values() if c['status'] == 'configured')\ntotal_apis = len(api_config)\nprint(f\"ğŸ¯ APIs configurÃ©es: {configured_apis}/{total_apis}\")\n\nif configured_apis == 0:\n    print(\"âš ï¸  Aucune API configurÃ©e - vÃ©rifiez votre fichier .env\")\n    print(\"ğŸ“ Utilisez .env.template comme rÃ©fÃ©rence\")\nelif configured_apis < total_apis:\n    print(\"âš ï¸  Configuration partielle - certains tests seront ignorÃ©s\")\nelse:\n    print(\"âœ… Toutes les APIs sont configurÃ©es - tests complets possibles\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Tests de connectivitÃ© des APIs\nprint(\"\\nğŸŒ TESTS DE CONNECTIVITÃ‰\")\nprint(\"=\" * 32)\n\n# Fonction de test de connectivitÃ©\ndef test_api_connectivity(api_name: str, config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Teste la connectivitÃ© d'une API.\n    \n    Args:\n        api_name: Nom de l'API\n        config: Configuration de l'API\n        \n    Returns:\n        Dict avec rÃ©sultats du test\n    \"\"\"\n    result = {\n        \"api\": api_name,\n        \"name\": config['name'],\n        \"success\": False,\n        \"response_time\": None,\n        \"status_code\": None,\n        \"models_count\": 0,\n        \"error\": None,\n        \"timestamp\": datetime.now().isoformat()\n    }\n    \n    if config['status'] != 'configured':\n        result['error'] = \"API non configurÃ©e\"\n        return result\n    \n    try:\n        print(f\"\\nğŸ” Test {config['name']}...\")\n        \n        # Test endpoint /models\n        start_time = time.time()\n        \n        response = requests.get(\n            urljoin(config['base_url'], config['endpoints']['models']),\n            headers=config['headers'],\n            timeout=benchmark_timeout\n        )\n        \n        end_time = time.time()\n        result['response_time'] = round(end_time - start_time, 3)\n        result['status_code'] = response.status_code\n        \n        if response.status_code == 200:\n            data = response.json()\n            \n            if api_name == \"openrouter\":\n                models = data.get('data', [])\n                result['models_count'] = len(models)\n                \n                # Filtrage des modÃ¨les GenAI Images\n                genai_models = [\n                    m for m in models \n                    if any(keyword in m.get('id', '').lower() \n                          for keyword in ['dall-e', 'gpt-5', 'gpt-4', 'flux', 'qwen'])\n                ]\n                \n                print(f\"âœ… Connexion rÃ©ussie - {result['response_time']}s\")\n                print(f\"ğŸ“Š ModÃ¨les totaux: {result['models_count']}\")\n                print(f\"ğŸ¨ ModÃ¨les GenAI Images: {len(genai_models)}\")\n                \n                # Affichage des modÃ¨les GenAI principaux\n                if genai_models:\n                    print(f\"\\nğŸ¯ ModÃ¨les prioritaires dÃ©tectÃ©s:\")\n                    for model in genai_models[:5]:\n                        context = model.get('context_length', 'N/A')\n                        pricing = model.get('pricing', {})\n                        prompt_price = pricing.get('prompt', 'N/A')\n                        print(f\"  â€¢ {model['id']} - Contexte: {context}, Prix: ${prompt_price}\")\n            \n            else:  # OpenAI\n                models = data.get('data', [])\n                result['models_count'] = len(models)\n                \n                print(f\"âœ… Connexion rÃ©ussie - {result['response_time']}s\")\n                print(f\"ğŸ“Š ModÃ¨les disponibles: {result['models_count']}\")\n                \n                # Affichage des modÃ¨les principaux\n                key_models = [m for m in models if m.get('id') in ['gpt-4o', 'gpt-4o-mini', 'dall-e-3']]\n                if key_models:\n                    print(f\"\\nğŸ¯ ModÃ¨les clÃ©s dÃ©tectÃ©s:\")\n                    for model in key_models:\n                        print(f\"  â€¢ {model['id']} - PropriÃ©taire: {model.get('owned_by', 'N/A')}\")\n            \n            result['success'] = True\n            \n        else:\n            error_msg = f\"HTTP {response.status_code}\"\n            try:\n                error_data = response.json()\n                error_msg += f\": {error_data.get('error', {}).get('message', 'Erreur inconnue')}\"\n            except:\n                pass\n            \n            result['error'] = error_msg\n            print(f\"âŒ Ã‰chec: {error_msg}\")\n            \n    except requests.exceptions.Timeout:\n        result['error'] = f\"Timeout aprÃ¨s {benchmark_timeout}s\"\n        print(f\"â±ï¸  Timeout: {result['error']}\")\n    except requests.exceptions.ConnectionError:\n        result['error'] = \"Erreur de connexion rÃ©seau\"\n        print(f\"ğŸŒ RÃ©seau: {result['error']}\")\n    except Exception as e:\n        result['error'] = str(e)[:100]\n        print(f\"âŒ Erreur: {result['error']}\")\n    \n    return result\n\n# ExÃ©cution des tests de connectivitÃ©\nconnectivity_results = []\n\nfor api_name, config in api_config.items():\n    if (api_name == \"openrouter\" and test_openrouter) or \\\n       (api_name == \"openai\" and test_openai_direct):\n        result = test_api_connectivity(api_name, config)\n        connectivity_results.append(result)\n    else:\n        print(f\"\\nâ­ï¸  {config['name']} - Test dÃ©sactivÃ©\")\n\n# RÃ©sumÃ© des tests de connectivitÃ©\nprint(f\"\\nğŸ“ˆ RÃ‰SUMÃ‰ CONNECTIVITÃ‰\")\nprint(\"=\" * 28)\nsuccessful_tests = sum(1 for r in connectivity_results if r['success'])\ntotal_tests = len(connectivity_results)\n\nprint(f\"ğŸ¯ Tests rÃ©ussis: {successful_tests}/{total_tests}\")\n\nif successful_tests > 0:\n    avg_response_time = sum(r['response_time'] for r in connectivity_results if r['success']) / successful_tests\n    total_models = sum(r['models_count'] for r in connectivity_results if r['success'])\n    \n    print(f\"âš¡ Temps moyen: {avg_response_time:.3f}s\")\n    print(f\"ğŸ”¢ ModÃ¨les totaux: {total_models}\")\nelse:\n    print(\"âŒ Aucune connexion rÃ©ussie\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Benchmarks de performance des APIs\nif run_benchmarks and connectivity_results:\n    print(\"\\nâš¡ BENCHMARKS DE PERFORMANCE\")\n    print(\"=\" * 35)\n    \n    # Fonction de benchmark\n    def benchmark_api_endpoint(api_name: str, config: Dict[str, Any], \n                              endpoint: str, iterations: int = 3) -> Dict[str, Any]:\n        \"\"\"\n        Benchmark d'un endpoint API.\n        \n        Args:\n            api_name: Nom de l'API\n            config: Configuration de l'API\n            endpoint: Endpoint Ã  tester\n            iterations: Nombre d'itÃ©rations\n            \n        Returns:\n            Dict avec mÃ©triques de performance\n        \"\"\"\n        \n        if config['status'] != 'configured':\n            return {\"error\": \"API non configurÃ©e\"}\n        \n        response_times = []\n        errors = 0\n        \n        print(f\"\\nğŸƒ Benchmark {config['name']} - {endpoint}\")\n        print(f\"ğŸ”„ {iterations} itÃ©rations...\")\n        \n        for i in range(iterations):\n            try:\n                start_time = time.time()\n                \n                response = requests.get(\n                    urljoin(config['base_url'], config['endpoints'][endpoint]),\n                    headers=config['headers'],\n                    timeout=benchmark_timeout\n                )\n                \n                end_time = time.time()\n                response_time = end_time - start_time\n                \n                if response.status_code == 200:\n                    response_times.append(response_time)\n                    print(f\"  âœ… ItÃ©ration {i+1}: {response_time:.3f}s\")\n                else:\n                    errors += 1\n                    print(f\"  âŒ ItÃ©ration {i+1}: HTTP {response.status_code}\")\n                \n                # DÃ©lai entre les requÃªtes pour Ã©viter le rate limiting\n                if i < iterations - 1:\n                    time.sleep(0.5)\n                    \n            except Exception as e:\n                errors += 1\n                print(f\"  âŒ ItÃ©ration {i+1}: {str(e)[:50]}...\")\n        \n        if response_times:\n            return {\n                \"api\": api_name,\n                \"endpoint\": endpoint,\n                \"success_rate\": len(response_times) / iterations,\n                \"avg_response_time\": sum(response_times) / len(response_times),\n                \"min_response_time\": min(response_times),\n                \"max_response_time\": max(response_times),\n                \"total_requests\": iterations,\n                \"successful_requests\": len(response_times),\n                \"errors\": errors,\n                \"timestamp\": datetime.now().isoformat()\n            }\n        else:\n            return {\n                \"api\": api_name,\n                \"endpoint\": endpoint,\n                \"error\": \"Aucune requÃªte rÃ©ussie\",\n                \"errors\": errors,\n                \"total_requests\": iterations\n            }\n    \n    # ExÃ©cution des benchmarks\n    benchmark_results = []\n    \n    for result in connectivity_results:\n        if result['success']:\n            api_name = result['api']\n            config = api_config[api_name]\n            \n            # Test de l'endpoint /models (le plus stable)\n            bench_result = benchmark_api_endpoint(\n                api_name, config, \"models\", benchmark_iterations\n            )\n            benchmark_results.append(bench_result)\n    \n    # Analyse des rÃ©sultats de benchmark\n    if benchmark_results:\n        print(f\"\\nğŸ“Š ANALYSE DES BENCHMARKS\")\n        print(\"=\" * 30)\n        \n        # Tableau comparatif\n        print(f\"\\n{'API':<15} {'SuccÃ¨s':<8} {'Temps Moy':<12} {'Min':<8} {'Max':<8} {'Erreurs':<8}\")\n        print(\"-\" * 65)\n        \n        for bench in benchmark_results:\n            if 'error' not in bench:\n                api = bench['api'].title()\n                success_pct = f\"{bench['success_rate']*100:.1f}%\"\n                avg_time = f\"{bench['avg_response_time']:.3f}s\"\n                min_time = f\"{bench['min_response_time']:.3f}s\"\n                max_time = f\"{bench['max_response_time']:.3f}s\"\n                errors = str(bench['errors'])\n                \n                print(f\"{api:<15} {success_pct:<8} {avg_time:<12} {min_time:<8} {max_time:<8} {errors:<8}\")\n        \n        # Recommandations de performance\n        print(f\"\\nğŸ’¡ RECOMMANDATIONS\")\n        print(\"=\" * 22)\n        \n        best_apis = [b for b in benchmark_results if 'error' not in b and b['success_rate'] > 0.8]\n        \n        if best_apis:\n            fastest_api = min(best_apis, key=lambda x: x['avg_response_time'])\n            most_reliable = max(best_apis, key=lambda x: x['success_rate'])\n            \n            print(f\"ğŸš€ API la plus rapide: {fastest_api['api'].title()} ({fastest_api['avg_response_time']:.3f}s)\")\n            print(f\"ğŸ›¡ï¸  API la plus fiable: {most_reliable['api'].title()} ({most_reliable['success_rate']*100:.1f}% succÃ¨s)\")\n            \n            # Conseils d'optimisation\n            slow_apis = [b for b in best_apis if b['avg_response_time'] > 2.0]\n            if slow_apis:\n                print(f\"\\nâš ï¸  APIs lentes dÃ©tectÃ©es:\")\n                for api in slow_apis:\n                    print(f\"   â€¢ {api['api'].title()}: {api['avg_response_time']:.3f}s\")\n                print(f\"ğŸ’¡ ConsidÃ©rez un timeout adaptÃ© et des retries\")\n        else:\n            print(f\"âŒ Aucune API avec performance acceptable\")\n            print(f\"ğŸ”§ VÃ©rifiez votre connexion rÃ©seau et les clÃ©s API\")\nelse:\n    if not run_benchmarks:\n        print(f\"\\nâ­ï¸  Benchmarks dÃ©sactivÃ©s (run_benchmarks = False)\")\n    else:\n        print(f\"\\nâš ï¸  Aucune connexion rÃ©ussie pour les benchmarks\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# VÃ©rification des limites de taux (Rate limits)\nif check_rate_limits and connectivity_results:\n    print(\"\\nğŸš¦ VÃ‰RIFICATION DES RATE LIMITS\")\n    print(\"=\" * 40)\n    \n    def check_rate_limits_api(api_name: str, config: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        VÃ©rifie les limites de taux d'une API.\n        \"\"\"\n        \n        if config['status'] != 'configured':\n            return {\"error\": \"API non configurÃ©e\"}\n        \n        rate_info = {\n            \"api\": api_name,\n            \"limits_detected\": False,\n            \"headers_info\": {},\n            \"request_count\": 0,\n            \"rate_limited\": False,\n            \"reset_time\": None\n        }\n        \n        print(f\"\\nğŸ” Test rate limits {config['name']}\")\n        \n        try:\n            # Test avec plusieurs requÃªtes rapprochÃ©es\n            for i in range(5):\n                response = requests.get(\n                    urljoin(config['base_url'], config['endpoints']['models']),\n                    headers=config['headers'],\n                    timeout=10\n                )\n                \n                rate_info['request_count'] += 1\n                \n                # Analyse des headers de rate limiting\n                headers_to_check = [\n                    'x-ratelimit-limit',\n                    'x-ratelimit-remaining', \n                    'x-ratelimit-reset',\n                    'retry-after',\n                    'x-ratelimit-limit-requests',\n                    'x-ratelimit-remaining-requests'\n                ]\n                \n                found_headers = {}\n                for header in headers_to_check:\n                    value = response.headers.get(header)\n                    if value:\n                        found_headers[header] = value\n                        rate_info['limits_detected'] = True\n                \n                if found_headers:\n                    rate_info['headers_info'].update(found_headers)\n                \n                if response.status_code == 429:\n                    rate_info['rate_limited'] = True\n                    retry_after = response.headers.get('retry-after')\n                    if retry_after:\n                        rate_info['reset_time'] = int(retry_after)\n                    print(f\"âš ï¸  Rate limit atteint aprÃ¨s {i+1} requÃªtes\")\n                    break\n                elif response.status_code != 200:\n                    print(f\"âŒ Erreur HTTP {response.status_code} Ã  la requÃªte {i+1}\")\n                    break\n                \n                # Petit dÃ©lai entre requÃªtes\n                time.sleep(0.1)\n            \n            # Affichage des rÃ©sultats\n            if rate_info['limits_detected']:\n                print(f\"âœ… Headers de rate limiting dÃ©tectÃ©s\")\n                for header, value in rate_info['headers_info'].items():\n                    print(f\"   {header}: {value}\")\n            else:\n                print(f\"â„¹ï¸  Aucun header de rate limiting dÃ©tectÃ©\")\n            \n            if rate_info['rate_limited']:\n                reset_info = f\" (reset dans {rate_info['reset_time']}s)\" if rate_info['reset_time'] else \"\"\n                print(f\"ğŸš¨ Rate limiting actif{reset_info}\")\n            else:\n                print(f\"âœ… Aucun rate limiting rencontrÃ©\")\n        \n        except Exception as e:\n            rate_info['error'] = str(e)[:100]\n            print(f\"âŒ Erreur test rate limits: {rate_info['error']}\")\n        \n        return rate_info\n    \n    # Test des rate limits pour chaque API\n    rate_limit_results = []\n    \n    for result in connectivity_results:\n        if result['success']:\n            api_name = result['api']\n            config = api_config[api_name]\n            \n            rate_result = check_rate_limits_api(api_name, config)\n            rate_limit_results.append(rate_result)\n    \n    # RÃ©sumÃ© des rate limits\n    if rate_limit_results:\n        print(f\"\\nğŸ“‹ RÃ‰SUMÃ‰ RATE LIMITS\")\n        print(\"=\" * 25)\n        \n        for result in rate_limit_results:\n            api = result['api'].title()\n            detected = \"Oui\" if result.get('limits_detected') else \"Non\"\n            limited = \"Oui\" if result.get('rate_limited') else \"Non\"\n            \n            print(f\"ğŸ”§ {api}:\")\n            print(f\"   Headers dÃ©tectÃ©s: {detected}\")\n            print(f\"   Rate limiting: {limited}\")\n            \n            if result.get('headers_info'):\n                limit = result['headers_info'].get('x-ratelimit-limit') or result['headers_info'].get('x-ratelimit-limit-requests')\n                remaining = result['headers_info'].get('x-ratelimit-remaining') or result['headers_info'].get('x-ratelimit-remaining-requests')\n                \n                if limit and remaining:\n                    usage = ((int(limit) - int(remaining)) / int(limit)) * 100\n                    print(f\"   Utilisation: {usage:.1f}% ({remaining}/{limit})\")\n        \n        # Conseils pour gÃ©rer les rate limits\n        print(f\"\\nğŸ’¡ BONNES PRATIQUES RATE LIMITING\")\n        print(\"=\" * 38)\n        print(f\"â€¢ Implementez des retries avec backoff exponentiel\")\n        print(f\"â€¢ Respectez les headers Retry-After\")\n        print(f\"â€¢ Utilisez des pools de connexions\")\n        print(f\"â€¢ Monitorer l'utilisation en temps rÃ©el\")\n        print(f\"â€¢ Avoir des fallbacks entre APIs\")\nelse:\n    if not check_rate_limits:\n        print(f\"\\nâ­ï¸  VÃ©rification rate limits dÃ©sactivÃ©e\")\n    else:\n        print(f\"\\nâš ï¸  Aucune API disponible pour test rate limits\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Monitoring des coÃ»ts et utilisation\nif monitor_costs and connectivity_results:\n    print(\"\\nğŸ’° MONITORING DES COÃ›TS\")\n    print(\"=\" * 30)\n    \n    # Estimation des coÃ»ts basÃ©e sur les modÃ¨les disponibles\n    def estimate_usage_costs() -> Dict[str, Any]:\n        \"\"\"\n        Estime les coÃ»ts d'utilisation des APIs.\n        \"\"\"\n        \n        cost_estimates = {\n            \"openrouter\": {\n                \"dall-e-3\": {\n                    \"standard\": {\"1024x1024\": 0.04, \"1792x1024\": 0.08, \"1024x1792\": 0.08},\n                    \"hd\": {\"1024x1024\": 0.08, \"1792x1024\": 0.12, \"1024x1792\": 0.12}\n                },\n                \"gpt-5\": {\n                    \"input_tokens_per_k\": 0.005,  # Estimation\n                    \"output_tokens_per_k\": 0.015\n                },\n                \"gpt-4o\": {\n                    \"input_tokens_per_k\": 0.0025,\n                    \"output_tokens_per_k\": 0.01\n                }\n            },\n            \"openai\": {\n                \"dall-e-3\": {\n                    \"standard\": {\"1024x1024\": 0.04, \"1792x1024\": 0.08, \"1024x1792\": 0.08},\n                    \"hd\": {\"1024x1024\": 0.08, \"1792x1024\": 0.12, \"1024x1792\": 0.12}\n                },\n                \"gpt-4o\": {\n                    \"input_tokens_per_k\": 0.0025,\n                    \"output_tokens_per_k\": 0.01\n                }\n            }\n        }\n        \n        return cost_estimates\n    \n    cost_data = estimate_usage_costs()\n    \n    # Calculs d'exemple pour un usage typique CoursIA\n    print(\"\\nğŸ’¡ ESTIMATION COÃ›TS USAGE COURSEIA\")\n    print(\"=\" * 42)\n    \n    typical_usage = {\n        \"images_per_month\": 100,  # Images gÃ©nÃ©rÃ©es par mois\n        \"chat_sessions_per_month\": 50,  # Sessions d'analyse\n        \"avg_tokens_per_session\": 2000  # Tokens moyens par session\n    }\n    \n    print(f\"ğŸ“Š Usage typique mensuel estimÃ©:\")\n    print(f\"   ğŸ–¼ï¸  Images gÃ©nÃ©rÃ©es: {typical_usage['images_per_month']}\")\n    print(f\"   ğŸ’¬ Sessions d'analyse: {typical_usage['chat_sessions_per_month']}\")\n    print(f\"   ğŸ”¤ Tokens par session: {typical_usage['avg_tokens_per_session']:,}\")\n    \n    # Calcul des coÃ»ts par API\n    monthly_costs = {}\n    \n    for api_name, api_costs in cost_data.items():\n        api_total = 0\n        \n        print(f\"\\nğŸ’³ {api_name.title()} - CoÃ»ts mensuels estimÃ©s:\")\n        \n        # DALL-E 3 costs\n        if 'dall-e-3' in api_costs:\n            dalle_cost = typical_usage['images_per_month'] * api_costs['dall-e-3']['standard']['1024x1024']\n            api_total += dalle_cost\n            print(f\"   ğŸ¨ DALL-E 3 (100 images): ${dalle_cost:.2f}\")\n        \n        # GPT costs (estimation basÃ©e sur input + output)\n        gpt_models = [k for k in api_costs.keys() if 'gpt' in k]\n        if gpt_models:\n            model = gpt_models[0]  # Premier modÃ¨le GPT disponible\n            if 'input_tokens_per_k' in api_costs[model]:\n                total_tokens = typical_usage['chat_sessions_per_month'] * typical_usage['avg_tokens_per_session']\n                # Estimation: 70% input, 30% output\n                input_cost = (total_tokens * 0.7 / 1000) * api_costs[model]['input_tokens_per_k']\n                output_cost = (total_tokens * 0.3 / 1000) * api_costs[model]['output_tokens_per_k']\n                gpt_total = input_cost + output_cost\n                api_total += gpt_total\n                print(f\"   ğŸ¤– {model.upper()} ({total_tokens:,} tokens): ${gpt_total:.2f}\")\n        \n        monthly_costs[api_name] = api_total\n        print(f\"   ğŸ’° Total {api_name.title()}: ${api_total:.2f}/mois\")\n    \n    # Comparaison et recommandations\n    if monthly_costs:\n        print(f\"\\nğŸ† COMPARAISON ET RECOMMANDATIONS\")\n        print(\"=\" * 40)\n        \n        cheapest_api = min(monthly_costs, key=monthly_costs.get)\n        cheapest_cost = monthly_costs[cheapest_api]\n        \n        print(f\"ğŸ’¡ API la plus Ã©conomique: {cheapest_api.title()} (${cheapest_cost:.2f}/mois)\")\n        \n        cost_diff = max(monthly_costs.values()) - min(monthly_costs.values())\n        if cost_diff > 1:\n            print(f\"ğŸ’¸ Ã‰conomie potentielle: ${cost_diff:.2f}/mois\")\n        \n        # Tips d'optimisation des coÃ»ts\n        print(f\"\\nğŸ¯ CONSEILS D'OPTIMISATION\")\n        print(\"=\" * 30)\n        print(f\"â€¢ Utilisez les modÃ¨les les plus adaptÃ©s au besoin\")\n        print(f\"â€¢ Optimisez la longueur des prompts\")\n        print(f\"â€¢ ImplÃ©mentez du caching pour les rÃ©ponses similaires\")\n        print(f\"â€¢ Surveillez l'utilisation avec des alerts\")\n        print(f\"â€¢ Testez diffÃ©rentes rÃ©solutions d'images selon l'usage\")\nelse:\n    if not monitor_costs:\n        print(f\"\\nâ­ï¸  Monitoring coÃ»ts dÃ©sactivÃ©\")\n    else:\n        print(f\"\\nâš ï¸  Aucune API disponible pour monitoring coÃ»ts\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Guide de diagnostic et troubleshooting\nprint(\"\\nğŸ”§ GUIDE DE DIAGNOSTIC ET TROUBLESHOOTING\")\nprint(\"=\" * 55)\n\n# Fonction de diagnostic automatique\ndef run_diagnostics() -> Dict[str, Any]:\n    \"\"\"\n    Execute un diagnostic complet de la configuration.\n    \"\"\"\n    \n    diagnostics = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"env_file_status\": \"unknown\",\n        \"api_keys_status\": {},\n        \"connectivity_status\": {},\n        \"common_issues\": [],\n        \"recommendations\": []\n    }\n    \n    # VÃ©rification fichier .env\n    env_file = GENAI_ROOT / '.env'\n    if env_file.exists():\n        diagnostics['env_file_status'] = \"found\"\n        try:\n            with open(env_file, 'r') as f:\n                env_content = f.read()\n            if 'OPENROUTER_API_KEY' in env_content or 'OPENAI_API_KEY' in env_content:\n                diagnostics['env_file_status'] = \"configured\"\n        except:\n            diagnostics['env_file_status'] = \"read_error\"\n    else:\n        diagnostics['env_file_status'] = \"missing\"\n    \n    # Status des clÃ©s API\n    for api_name, config in api_config.items():\n        key_status = \"missing\"\n        if config.get('key_value'):\n            key_status = \"configured\"\n            # Test basique de format\n            key = config['key_value']\n            if len(key) < 20:\n                key_status = \"too_short\"\n            elif not key.replace('-', '').replace('_', '').isalnum():\n                key_status = \"invalid_format\"\n        \n        diagnostics['api_keys_status'][api_name] = key_status\n    \n    # Status de connectivitÃ©\n    for result in connectivity_results:\n        api = result['api']\n        status = \"success\" if result['success'] else \"failed\"\n        error = result.get('error')\n        \n        diagnostics['connectivity_status'][api] = {\n            \"status\": status,\n            \"error\": error,\n            \"response_time\": result.get('response_time')\n        }\n    \n    # DÃ©tection des problÃ¨mes courants\n    if diagnostics['env_file_status'] == \"missing\":\n        diagnostics['common_issues'].append({\n            \"issue\": \"Fichier .env manquant\",\n            \"solution\": \"Copiez .env.template vers .env et configurez vos clÃ©s API\"\n        })\n    \n    missing_keys = [api for api, status in diagnostics['api_keys_status'].items() if status == \"missing\"]\n    if missing_keys:\n        diagnostics['common_issues'].append({\n            \"issue\": f\"ClÃ©s API manquantes: {', '.join(missing_keys)}\",\n            \"solution\": \"Ajoutez les clÃ©s manquantes dans le fichier .env\"\n        })\n    \n    failed_connections = [api for api, data in diagnostics['connectivity_status'].items() if data['status'] == \"failed\"]\n    if failed_connections:\n        diagnostics['common_issues'].append({\n            \"issue\": f\"Ã‰checs de connexion: {', '.join(failed_connections)}\",\n            \"solution\": \"VÃ©rifiez votre connexion internet et les clÃ©s API\"\n        })\n    \n    # Recommandations gÃ©nÃ©rales\n    if not diagnostics['common_issues']:\n        diagnostics['recommendations'].append(\"âœ… Configuration optimale dÃ©tectÃ©e\")\n    else:\n        diagnostics['recommendations'].append(\"ğŸ”§ Corrigez les problÃ¨mes identifiÃ©s ci-dessus\")\n    \n    if any(data.get('response_time', 0) > 3 for data in diagnostics['connectivity_status'].values()):\n        diagnostics['recommendations'].append(\"âš¡ Connexion lente dÃ©tectÃ©e - vÃ©rifiez votre rÃ©seau\")\n    \n    return diagnostics\n\n# ExÃ©cution du diagnostic\ndiag_results = run_diagnostics()\n\nprint(f\"\\nğŸ“‹ RÃ‰SULTATS DU DIAGNOSTIC\")\nprint(\"=\" * 32)\n\n# Status fichier .env\nenv_status_icons = {\n    \"missing\": \"âŒ\",\n    \"found\": \"âš ï¸\",\n    \"configured\": \"âœ…\",\n    \"read_error\": \"ğŸ”§\"\n}\nenv_icon = env_status_icons.get(diag_results['env_file_status'], \"â“\")\nprint(f\"{env_icon} Fichier .env: {diag_results['env_file_status']}\")\n\n# Status clÃ©s API\nprint(f\"\\nğŸ”‘ Status des clÃ©s API:\")\nfor api, status in diag_results['api_keys_status'].items():\n    status_icon = \"âœ…\" if status == \"configured\" else \"âŒ\"\n    print(f\"   {status_icon} {api.title()}: {status}\")\n\n# Status connectivitÃ©\nif diag_results['connectivity_status']:\n    print(f\"\\nğŸŒ Status connectivitÃ©:\")\n    for api, data in diag_results['connectivity_status'].items():\n        status_icon = \"âœ…\" if data['status'] == \"success\" else \"âŒ\"\n        time_info = f\" ({data['response_time']:.3f}s)\" if data.get('response_time') else \"\"\n        print(f\"   {status_icon} {api.title()}: {data['status']}{time_info}\")\n\n# ProblÃ¨mes dÃ©tectÃ©s\nif diag_results['common_issues']:\n    print(f\"\\nğŸš¨ PROBLÃˆMES DÃ‰TECTÃ‰S\")\n    print(\"=\" * 25)\n    for i, issue in enumerate(diag_results['common_issues'], 1):\n        print(f\"{i}. âŒ {issue['issue']}\")\n        print(f\"   ğŸ’¡ Solution: {issue['solution']}\")\n\n# Recommandations\nif diag_results['recommendations']:\n    print(f\"\\nğŸ’¡ RECOMMANDATIONS\")\n    print(\"=\" * 20)\n    for rec in diag_results['recommendations']:\n        print(f\"â€¢ {rec}\")\n\nprint(f\"\\nğŸ“ SUPPORT SUPPLÃ‰MENTAIRE\")\nprint(\"=\" * 28)\nprint(f\"â€¢ Documentation: docs/genai-troubleshooting-guide.md\")\nprint(f\"â€¢ Templates: docs/genai-phase2-templates.md\")\nprint(f\"â€¢ Issues GitHub: https://github.com/jsboige/CoursIA/issues\")\nprint(f\"â€¢ Logs dÃ©taillÃ©s: Activez debug_level = 'DEBUG'\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Export des rÃ©sultats et gÃ©nÃ©ration de rapport\nif export_results:\n    print(\"\\nğŸ“„ EXPORT DES RÃ‰SULTATS\")\n    print(\"=\" * 30)\n    \n    # Compilation des rÃ©sultats\n    export_data = {\n        \"configuration_test\": {\n            \"timestamp\": datetime.now().isoformat(),\n            \"notebook_version\": \"1.0.0\",\n            \"test_parameters\": {\n                \"test_openrouter\": test_openrouter,\n                \"test_openai_direct\": test_openai_direct,\n                \"run_benchmarks\": run_benchmarks,\n                \"benchmark_iterations\": benchmark_iterations,\n                \"benchmark_timeout\": benchmark_timeout\n            }\n        },\n        \"api_configuration\": {api: {k: v for k, v in config.items() if k != 'key_value'} for api, config in api_config.items()},\n        \"connectivity_results\": connectivity_results,\n        \"benchmark_results\": benchmark_results if 'benchmark_results' in locals() else [],\n        \"rate_limit_results\": rate_limit_results if 'rate_limit_results' in locals() else [],\n        \"diagnostics\": diag_results,\n        \"summary\": {\n            \"total_apis_tested\": len(connectivity_results),\n            \"successful_connections\": sum(1 for r in connectivity_results if r['success']),\n            \"average_response_time\": sum(r['response_time'] for r in connectivity_results if r['success']) / len([r for r in connectivity_results if r['success']]) if connectivity_results else 0,\n            \"configuration_status\": \"healthy\" if all(r['success'] for r in connectivity_results) else \"issues_detected\"\n        }\n    }\n    \n    # Sauvegarde JSON\n    output_dir = GENAI_ROOT / 'outputs' / 'api_configuration'\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    json_file = output_dir / f\"api_config_test_{timestamp}.json\"\n    \n    with open(json_file, 'w', encoding='utf-8') as f:\n        json.dump(export_data, f, indent=2, ensure_ascii=False)\n    \n    print(f\"ğŸ’¾ RÃ©sultats exportÃ©s: {json_file}\")\n    print(f\"ğŸ“Š DonnÃ©es incluses: {len(export_data)} sections\")\n    \n    # GÃ©nÃ©ration rapport HTML simple si demandÃ©\n    if generate_report:\n        html_content = f\"\"\"\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Rapport Configuration APIs CoursIA</title>\n    <meta charset=\"utf-8\">\n    <style>\n        body {{ font-family: Arial, sans-serif; margin: 20px; }}\n        .header {{ background: #f0f8ff; padding: 20px; border-radius: 8px; }}\n        .section {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}\n        .success {{ color: #28a745; }}\n        .error {{ color: #dc3545; }}\n        .warning {{ color: #ffc107; }}\n        table {{ width: 100%; border-collapse: collapse; margin: 10px 0; }}\n        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n        th {{ background-color: #f2f2f2; }}\n    </style>\n</head>\n<body>\n    <div class=\"header\">\n        <h1>ğŸ”— Rapport Configuration APIs CoursIA</h1>\n        <p>GÃ©nÃ©rÃ© le: {datetime.now().strftime('%d/%m/%Y Ã  %H:%M:%S')}</p>\n    </div>\n    \n    <div class=\"section\">\n        <h2>ğŸ“Š RÃ©sumÃ©</h2>\n        <ul>\n            <li>APIs testÃ©es: {export_data['summary']['total_apis_tested']}</li>\n            <li>Connexions rÃ©ussies: {export_data['summary']['successful_connections']}</li>\n            <li>Temps de rÃ©ponse moyen: {export_data['summary']['average_response_time']:.3f}s</li>\n            <li>Status global: {export_data['summary']['configuration_status']}</li>\n        </ul>\n    </div>\n    \n    <div class=\"section\">\n        <h2>ğŸŒ ConnectivitÃ©</h2>\n        <table>\n            <tr><th>API</th><th>Status</th><th>Temps (s)</th><th>ModÃ¨les</th><th>Erreur</th></tr>\n        \"\"\"\n        \n        for result in connectivity_results:\n            status_class = \"success\" if result['success'] else \"error\"\n            status_text = \"âœ… SuccÃ¨s\" if result['success'] else \"âŒ Ã‰chec\"\n            response_time = f\"{result['response_time']:.3f}\" if result.get('response_time') else \"N/A\"\n            models_count = result.get('models_count', 0)\n            error = result.get('error', 'Aucune') if not result['success'] else 'Aucune'\n            \n            html_content += f\"\"\"\n            <tr>\n                <td>{result['name']}</td>\n                <td class=\"{status_class}\">{status_text}</td>\n                <td>{response_time}</td>\n                <td>{models_count}</td>\n                <td>{error}</td>\n            </tr>\n            \"\"\"\n        \n        html_content += \"\"\"\n        </table>\n    </div>\n    \n    <div class=\"section\">\n        <h2>ğŸ”§ Diagnostic</h2>\n        <h3>ProblÃ¨mes dÃ©tectÃ©s:</h3>\n        <ul>\n        \"\"\"\n        \n        if diag_results['common_issues']:\n            for issue in diag_results['common_issues']:\n                html_content += f\"<li class='error'>âŒ {issue['issue']}<br><small>ğŸ’¡ {issue['solution']}</small></li>\"\n        else:\n            html_content += \"<li class='success'>âœ… Aucun problÃ¨me dÃ©tectÃ©</li>\"\n        \n        html_content += \"\"\"\n        </ul>\n        <h3>Recommandations:</h3>\n        <ul>\n        \"\"\"\n        \n        for rec in diag_results['recommendations']:\n            html_content += f\"<li>{rec}</li>\"\n        \n        html_content += \"\"\"\n        </ul>\n    </div>\n    \n    <div class=\"section\">\n        <h2>ğŸ“ Fichiers gÃ©nÃ©rÃ©s</h2>\n        <ul>\n            <li>DonnÃ©es JSON: api_config_test_{timestamp}.json</li>\n            <li>Rapport HTML: api_config_report_{timestamp}.html</li>\n        </ul>\n    </div>\n</body>\n</html>\n        \"\"\"\n        \n        html_file = output_dir / f\"api_config_report_{timestamp}.html\"\n        with open(html_file, 'w', encoding='utf-8') as f:\n            f.write(html_content)\n        \n        print(f\"ğŸ“„ Rapport HTML gÃ©nÃ©rÃ©: {html_file}\")\n        print(f\"ğŸ’¡ Ouvrez le fichier HTML dans votre navigateur\")\nelse:\n    print(f\"\\nâ­ï¸  Export dÃ©sactivÃ© (export_results = False)\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¯ RÃ©sumÃ© et Prochaines Ã‰tapes\n",
        "\n",
        "### âœ… Configuration ValidÃ©e\n",
        "\n",
        "- [ ] **APIs configurÃ©es** : ClÃ©s et endpoints vÃ©rifiÃ©s\n",
        "- [ ] **ConnectivitÃ© testÃ©e** : Tous les endpoints fonctionnels\n",
        "- [ ] **Performance mesurÃ©e** : Benchmarks et temps de rÃ©ponse\n",
        "- [ ] **Rate limits analysÃ©s** : Limites et recommandations\n",
        "- [ ] **CoÃ»ts estimÃ©s** : Projections d'usage mensuel\n",
        "- [ ] **Diagnostic complet** : ProblÃ¨mes dÃ©tectÃ©s et solutions\n",
        "\n",
        "### ğŸš€ Utilisation des APIs\n",
        "\n",
        "Maintenant que vos APIs sont configurÃ©es, vous pouvez utiliser :\n",
        "\n",
        "1. **Notebooks Foundation** :\n",
        "   - `01-1-OpenAI-DALL-E-3.ipynb` - GÃ©nÃ©ration d'images\n",
        "   - `01-2-GPT-5-Image-Generation.ipynb` - Analyse multimodale\n",
        "\n",
        "2. **Notebooks Advanced** :\n",
        "   - `02-1-Qwen-Image-Edit-2509.ipynb` - Ã‰dition d'images\n",
        "   - `02-2-FLUX-1-Advanced-Generation.ipynb` - GÃ©nÃ©ration avancÃ©e\n",
        "\n",
        "3. **Notebooks Applications** :\n",
        "   - `04-1-Educational-Content-Generation.ipynb` - Contenu pÃ©dagogique\n",
        "   - `04-2-Creative-Workflows.ipynb` - Workflows crÃ©atifs\n",
        "\n",
        "### ğŸ’¡ Bonnes Pratiques\n",
        "\n",
        "**âœ… Configuration:**\n",
        "- Gardez vos clÃ©s API sÃ©curisÃ©es dans `.env`\n",
        "- Testez rÃ©guliÃ¨rement la connectivitÃ©\n",
        "- Surveillez vos quotas et coÃ»ts\n",
        "- ImplÃ©mentez des retries pour la rÃ©silience\n",
        "\n",
        "**âŒ Ã‰vitez:**\n",
        "- Partager vos clÃ©s API dans le code\n",
        "- Ignorer les rate limits\n",
        "- Utiliser des timeouts trop courts\n",
        "- Oublier de monitorer les coÃ»ts\n",
        "\n",
        "### ğŸ”— Ressources\n",
        "\n",
        "- **Documentation OpenRouter** : [openrouter.ai/docs](https://openrouter.ai/docs)\n",
        "- **API OpenAI** : [platform.openai.com/docs](https://platform.openai.com/docs)\n",
        "- **Troubleshooting** : `docs/genai-troubleshooting-guide.md`\n",
        "- **Templates** : `docs/genai-phase2-templates.md`\n",
        "\n",
        "### ğŸ“Š Fichiers GÃ©nÃ©rÃ©s\n",
        "\n",
        "Ce notebook gÃ©nÃ¨re automatiquement :\n",
        "- **Rapport JSON** : DonnÃ©es complÃ¨tes de configuration\n",
        "- **Rapport HTML** : Visualisation des rÃ©sultats\n",
        "- **Logs dÃ©taillÃ©s** : Pour le debugging\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ‰ Configuration terminÃ©e !** Vos APIs sont prÃªtes pour l'utilisation dans l'Ã©cosystÃ¨me CoursIA GenAI."
      ],
      "metadata": {}
    }
  ]
}
