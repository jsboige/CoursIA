{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Stable Diffusion 3.5 - G√©n√©ration de Pointe\n",
    "\n",
    "**Module :** 02-Images-Advanced  \n",
    "**Niveau :** Interm√©diaire/Avanc√©  \n",
    "**Dur√©e estim√©e :** 50 minutes  \n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Stable Diffusion 3.5** repr√©sente la derni√®re g√©n√©ration de mod√®les de Stability AI, combinant une architecture MMDiT (Multimodal Diffusion Transformer) avec des encodeurs de texte avanc√©s.\n",
    "\n",
    "### Variantes SD 3.5\n",
    "\n",
    "| Variante | Params | VRAM | Caract√©ristiques |\n",
    "|----------|--------|------|------------------|\n",
    "| **SD 3.5 Large** | 8B | 16GB+ | Meilleure qualit√© |\n",
    "| **SD 3.5 Large Turbo** | 8B | 16GB+ | 4 steps, rapide |\n",
    "| **SD 3.5 Medium** | 2.5B | 8GB+ | Balance qualit√©/vitesse |\n",
    "\n",
    "### Architecture MMDiT\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ            Stable Diffusion 3.5 Architecture            ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ   Text Prompt ‚Üí [CLIP-L] + [CLIP-G] + [T5-XXL]         ‚îÇ\n",
    "‚îÇ       ‚Üì                                                 ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ\n",
    "‚îÇ   ‚îÇ    MMDiT (Multimodal Diffusion    ‚îÇ                ‚îÇ\n",
    "‚îÇ   ‚îÇ    Transformer)                    ‚îÇ                ‚îÇ\n",
    "‚îÇ   ‚îÇ    - Joint attention text+image   ‚îÇ                ‚îÇ\n",
    "‚îÇ   ‚îÇ    - Flow Matching objective      ‚îÇ                ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ\n",
    "‚îÇ       ‚Üì                                                 ‚îÇ\n",
    "‚îÇ   [16-ch VAE] ‚Üí Output Image (1024x1024)               ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "## Pr√©requis\n",
    "\n",
    "- Module 00-GenAI-Environment compl√©t√©\n",
    "- GPU avec 8GB+ VRAM (Medium) ou 16GB+ (Large)\n",
    "- Token HuggingFace avec acceptation licence SD 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. CONFIGURATION ET IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chargement variables d'environnement\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "load_dotenv(\"../00-GenAI-Environment/.env\")\n",
    "\n",
    "# Configuration\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\") or os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "print(\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\")\n",
    "print(\"‚ïë   Stable Diffusion 3.5 - G√©n√©ration de Pointe     ‚ïë\")\n",
    "print(\"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\")\n",
    "print(f\"\\nüìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nüîë HuggingFace: {'‚úÖ Token configur√©' if HF_TOKEN else '‚ùå Token manquant'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. D√âTECTION GPU ET CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "\n",
    "def get_gpu_info():\n",
    "    \"\"\"D√©tecte et retourne les informations GPU.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return None, 0, \"cpu\"\n",
    "    \n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    return gpu_name, gpu_memory, \"cuda\"\n",
    "\n",
    "def recommend_model(gpu_memory: float) -> str:\n",
    "    \"\"\"Recommande la variante SD3.5 selon la VRAM.\"\"\"\n",
    "    if gpu_memory >= 24:\n",
    "        return \"stabilityai/stable-diffusion-3.5-large\"\n",
    "    elif gpu_memory >= 16:\n",
    "        return \"stabilityai/stable-diffusion-3.5-large-turbo\"\n",
    "    elif gpu_memory >= 8:\n",
    "        return \"stabilityai/stable-diffusion-3.5-medium\"\n",
    "    return None\n",
    "\n",
    "GPU_NAME, GPU_MEMORY, DEVICE = get_gpu_info()\n",
    "RECOMMENDED_MODEL = recommend_model(GPU_MEMORY) if GPU_MEMORY else None\n",
    "DTYPE = torch.float16 if GPU_MEMORY and GPU_MEMORY >= 16 else torch.bfloat16\n",
    "\n",
    "if GPU_NAME:\n",
    "    print(f\"\\nüéÆ GPU: {GPU_NAME}\")\n",
    "    print(f\"   VRAM: {GPU_MEMORY:.1f} GB\")\n",
    "    if RECOMMENDED_MODEL:\n",
    "        print(f\"   ‚úÖ Recommandation: {RECOMMENDED_MODEL.split('/')[-1]}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Pas de GPU CUDA d√©tect√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. CLIENT SD 3.5\n",
    "# =============================================================================\n",
    "\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "\n",
    "class SD35Client:\n",
    "    \"\"\"Client pour Stable Diffusion 3.5 avec optimisations m√©moire.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_id: str = None):\n",
    "        self.model_id = model_id or RECOMMENDED_MODEL\n",
    "        self.pipeline = None\n",
    "        self.is_turbo = \"turbo\" in (self.model_id or \"\").lower()\n",
    "        \n",
    "        if not self.model_id:\n",
    "            raise ValueError(\"Pas assez de VRAM pour SD3.5 local.\")\n",
    "        \n",
    "        print(f\"üîß SD35Client: {self.model_id.split('/')[-1]}\")\n",
    "        print(f\"   Turbo: {'Oui' if self.is_turbo else 'Non'}\")\n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"Charge le pipeline.\"\"\"\n",
    "        if self.pipeline:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nüì• Chargement du mod√®le...\")\n",
    "        start = time.time()\n",
    "        \n",
    "        self.pipeline = StableDiffusion3Pipeline.from_pretrained(\n",
    "            self.model_id,\n",
    "            torch_dtype=DTYPE,\n",
    "            token=HF_TOKEN,\n",
    "            use_safetensors=True\n",
    "        )\n",
    "        self.pipeline.enable_model_cpu_offload()\n",
    "        self.pipeline.enable_attention_slicing()\n",
    "        \n",
    "        print(f\"   ‚úÖ Charg√© en {time.time()-start:.1f}s\")\n",
    "    \n",
    "    def generate(self, prompt: str, negative_prompt: str = \"\",\n",
    "                 width: int = 1024, height: int = 1024,\n",
    "                 num_inference_steps: int = None,\n",
    "                 guidance_scale: float = None,\n",
    "                 seed: int = None) -> List[Image.Image]:\n",
    "        \"\"\"G√©n√®re des images.\"\"\"\n",
    "        self.load()\n",
    "        \n",
    "        if num_inference_steps is None:\n",
    "            num_inference_steps = 4 if self.is_turbo else 28\n",
    "        if guidance_scale is None:\n",
    "            guidance_scale = 0.0 if self.is_turbo else 4.5\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(0, 2**32)\n",
    "        if not negative_prompt:\n",
    "            negative_prompt = \"blurry, low quality, distorted, deformed\"\n",
    "        \n",
    "        generator = torch.Generator(device=DEVICE).manual_seed(seed)\n",
    "        \n",
    "        print(f\"\\nüé® G√©n√©ration (seed: {seed}, steps: {num_inference_steps})...\")\n",
    "        start = time.time()\n",
    "        \n",
    "        result = self.pipeline(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ G√©n√©r√© en {time.time()-start:.1f}s\")\n",
    "        return result.images\n",
    "    \n",
    "    def unload(self):\n",
    "        \"\"\"Lib√®re la m√©moire.\"\"\"\n",
    "        if self.pipeline:\n",
    "            del self.pipeline\n",
    "            self.pipeline = None\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            print(\"‚úÖ M√©moire lib√©r√©e\")\n",
    "\n",
    "# Instanciation\n",
    "try:\n",
    "    sd35 = SD35Client()\n",
    "except ValueError as e:\n",
    "    print(f\"‚ö†Ô∏è {e}\")\n",
    "    sd35 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 4. G√©n√©ration de Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. G√âN√âRATION DE BASE\n",
    "# =============================================================================\n",
    "\n",
    "if sd35:\n",
    "    base_prompt = \"\"\"\n",
    "    A majestic phoenix rising from flames, \n",
    "    intricate feather details, golden and crimson colors,\n",
    "    magical sparks, dark fantasy background,\n",
    "    highly detailed digital art, 8k resolution\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    print(f\"üìù Prompt: {base_prompt[:60]}...\")\n",
    "    \n",
    "    images = sd35.generate(prompt=base_prompt, seed=42)\n",
    "    \n",
    "    if images:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(images[0])\n",
    "        plt.title(f\"SD 3.5 - {sd35.model_id.split('/')[-1]}\", fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SD35 non initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 5. Analyse CFG Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. ANALYSE CFG SCALE\n",
    "# =============================================================================\n",
    "\n",
    "if sd35 and not sd35.is_turbo:\n",
    "    cfg_prompt = \"A serene lake reflecting mountains, sunset, photorealistic\"\n",
    "    cfg_values = [2.0, 4.5, 7.0, 10.0]\n",
    "    \n",
    "    print(f\"\\nüìä Analyse CFG Scale\")\n",
    "    cfg_results = []\n",
    "    \n",
    "    for cfg in cfg_values:\n",
    "        print(f\"--- CFG = {cfg} ---\")\n",
    "        images = sd35.generate(cfg_prompt, width=768, height=768,\n",
    "                               num_inference_steps=20, guidance_scale=cfg, seed=12345)\n",
    "        if images:\n",
    "            cfg_results.append((cfg, images[0]))\n",
    "    \n",
    "    if cfg_results:\n",
    "        fig, axes = plt.subplots(1, len(cfg_results), figsize=(16, 5))\n",
    "        for i, (cfg, img) in enumerate(cfg_results):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"CFG = {cfg}\")\n",
    "            axes[i].axis('off')\n",
    "        plt.suptitle(\"Impact du Guidance Scale (CFG)\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "elif sd35:\n",
    "    print(\"Mode Turbo: CFG fix√© √† 0\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SD35 non initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 6. Comparaison Inference Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. ANALYSE INFERENCE STEPS\n",
    "# =============================================================================\n",
    "\n",
    "if sd35:\n",
    "    steps_prompt = \"A cyberpunk city at night, neon lights, rain, cinematic\"\n",
    "    step_values = [1, 2, 4, 8] if sd35.is_turbo else [10, 20, 28, 40]\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è Analyse Steps ({'Turbo' if sd35.is_turbo else 'Standard'})\")\n",
    "    steps_results = []\n",
    "    \n",
    "    for steps in step_values:\n",
    "        print(f\"--- Steps = {steps} ---\")\n",
    "        start = time.time()\n",
    "        images = sd35.generate(steps_prompt, width=768, height=768,\n",
    "                               num_inference_steps=steps, seed=7777)\n",
    "        elapsed = time.time() - start\n",
    "        if images:\n",
    "            steps_results.append((steps, elapsed, images[0]))\n",
    "    \n",
    "    if steps_results:\n",
    "        fig, axes = plt.subplots(1, len(steps_results), figsize=(16, 5))\n",
    "        for i, (steps, t, img) in enumerate(steps_results):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Steps={steps}\\n({t:.1f}s)\")\n",
    "            axes[i].axis('off')\n",
    "        plt.suptitle(\"Impact des Inference Steps\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SD35 non initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 7. Styles Artistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. STYLES ARTISTIQUES\n",
    "# =============================================================================\n",
    "\n",
    "if sd35:\n",
    "    base_subject = \"a ancient tree in a mystical forest\"\n",
    "    \n",
    "    styles = {\n",
    "        \"Photorealistic\": f\"{base_subject}, photorealistic, natural lighting, 8k\",\n",
    "        \"Oil Painting\": f\"{base_subject}, oil painting, impressionist, brushstrokes\",\n",
    "        \"Anime\": f\"{base_subject}, anime style, Studio Ghibli, vibrant colors\",\n",
    "        \"Watercolor\": f\"{base_subject}, watercolor painting, soft edges, pastel\",\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüé® Styles Artistiques\")\n",
    "    style_results = []\n",
    "    \n",
    "    for style_name, prompt in styles.items():\n",
    "        print(f\"--- {style_name} ---\")\n",
    "        images = sd35.generate(prompt, width=768, height=768, seed=5555)\n",
    "        if images:\n",
    "            style_results.append((style_name, images[0]))\n",
    "    \n",
    "    if style_results:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        axes = axes.flatten()\n",
    "        for i, (style, img) in enumerate(style_results):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(style, fontsize=12)\n",
    "            axes[i].axis('off')\n",
    "        plt.suptitle(\"Comparaison des Styles\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SD35 non initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 8. Exercices Pratiques\n",
    "\n",
    "### Exercice 1: Portrait Artistique\n",
    "Cr√©ez un portrait avec le style \"Oil Painting\" et diff√©rentes valeurs CFG.\n",
    "\n",
    "### Exercice 2: Comparaison Negative Prompts\n",
    "Testez l'impact de diff√©rents negative prompts sur la qualit√©.\n",
    "\n",
    "### Exercice 3: Exploration Ratios\n",
    "G√©n√©rez la m√™me sc√®ne en 1:1, 16:9 et 9:16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. ESPACE D'EXERCICES\n",
    "# =============================================================================\n",
    "\n",
    "# D√©commentez pour tester:\n",
    "\n",
    "# portrait_prompt = \"Portrait of a wise elderly man, oil painting style, Rembrandt lighting\"\n",
    "# if sd35:\n",
    "#     for cfg in [3.0, 5.0, 7.0]:\n",
    "#         images = sd35.generate(portrait_prompt, guidance_scale=cfg, seed=42)\n",
    "#         plt.imshow(images[0])\n",
    "#         plt.title(f\"CFG={cfg}\")\n",
    "#         plt.show()\n",
    "\n",
    "print(\"üìù D√©commentez le code pour commencer les exercices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 9. Nettoyage M√©moire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 9. NETTOYAGE\n",
    "# =============================================================================\n",
    "\n",
    "if sd35:\n",
    "    print(\"üßπ Lib√©ration m√©moire...\")\n",
    "    if torch.cuda.is_available():\n",
    "        vram_before = torch.cuda.memory_allocated() / 1e9\n",
    "    sd35.unload()\n",
    "    if torch.cuda.is_available():\n",
    "        vram_after = torch.cuda.memory_allocated() / 1e9\n",
    "        print(f\"   Lib√©r√©: {vram_before - vram_after:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 10. R√©capitulatif\n",
    "\n",
    "### Param√®tres SD 3.5\n",
    "\n",
    "| Param√®tre | Standard | Turbo |\n",
    "|-----------|----------|-------|\n",
    "| `steps` | 28-50 | 4 |\n",
    "| `guidance_scale` | 4.0-7.5 | 0.0 |\n",
    "| `width/height` | 1024 | 1024 |\n",
    "\n",
    "### Points Cl√©s\n",
    "\n",
    "1. **MMDiT** pour meilleure coh√©rence\n",
    "2. **Triple encodeur** (CLIP-L, CLIP-G, T5)\n",
    "3. **Turbo** pour g√©n√©ration rapide\n",
    "4. **Toujours lib√©rer** la m√©moire apr√®s usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIN DU NOTEBOOK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"   ‚úÖ Notebook Stable Diffusion 3.5 Compl√©t√©\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìÖ Termin√©: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nüìö Concepts couverts:\")\n",
    "print(\"   ‚Ä¢ Architecture MMDiT\")\n",
    "print(\"   ‚Ä¢ Variantes (Large, Turbo, Medium)\")\n",
    "print(\"   ‚Ä¢ CFG et Inference Steps\")\n",
    "print(\"   ‚Ä¢ Styles artistiques\")\n",
    "print(\"\\n‚û°Ô∏è  Prochain module: 03-Images-Orchestration/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
