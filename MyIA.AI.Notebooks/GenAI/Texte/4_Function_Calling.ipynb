{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc90a88e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:35:47.736483Z",
     "iopub.status.busy": "2026-02-25T21:35:47.736170Z",
     "iopub.status.idle": "2026-02-25T21:35:47.740248Z",
     "shell.execute_reply": "2026-02-25T21:35:47.739657Z"
    },
    "papermill": {
     "duration": 0.010662,
     "end_time": "2026-02-25T21:35:47.741108",
     "exception": false,
     "start_time": "2026-02-25T21:35:47.730446",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_MODE = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b84890e",
   "metadata": {
    "papermill": {
     "duration": 0.004018,
     "end_time": "2026-02-25T21:35:47.749374",
     "exception": false,
     "start_time": "2026-02-25T21:35:47.745356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function Calling : Connecter les LLMs au Monde Réel\n",
    "\n",
    "Dans ce notebook, nous explorons le **Function Calling** (appel de fonctions), qui permet aux modèles d'interagir avec des systèmes externes comme des APIs, bases de données, ou services web.\n",
    "\n",
    "**Objectifs :**\n",
    "- Comprendre la structure des Tools dans l'API OpenAI\n",
    "- Maîtriser tool_choice (auto, required, none)\n",
    "- Exécuter des fonctions en parallèle\n",
    "- Construire des boucles agentiques\n",
    "\n",
    "**Prérequis :** Notebook 1 (OpenAI Intro), Notebook 3 (Structured Outputs)\n",
    "\n",
    "**Durée estimée :** 60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48290080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:35:47.757279Z",
     "iopub.status.busy": "2026-02-25T21:35:47.757102Z",
     "iopub.status.idle": "2026-02-25T21:35:50.224221Z",
     "shell.execute_reply": "2026-02-25T21:35:50.223541Z"
    },
    "papermill": {
     "duration": 2.472164,
     "end_time": "2026-02-25T21:35:50.225001",
     "exception": false,
     "start_time": "2026-02-25T21:35:47.752837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client OpenAI initialisé !\n",
      "Modèle par défaut: gpt-5-mini\n",
      "Mode batch: True\n"
     ]
    }
   ],
   "source": [
    "# Installation et configuration\n",
    "%pip install -q openai python-dotenv\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "load_dotenv('../.env')\n",
    "client = OpenAI()\n",
    "\n",
    "# Charger le modèle depuis .env ou utiliser gpt-5-mini par défaut\n",
    "DEFAULT_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "BATCH_MODE = os.getenv(\"BATCH_MODE\", \"false\").lower() == \"true\"\n",
    "\n",
    "print(\"Client OpenAI initialisé !\")\n",
    "print(f\"Modèle par défaut: {DEFAULT_MODEL}\")\n",
    "print(f\"Mode batch: {BATCH_MODE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f669a7",
   "metadata": {
    "papermill": {
     "duration": 0.003696,
     "end_time": "2026-02-25T21:35:50.232657",
     "exception": false,
     "start_time": "2026-02-25T21:35:50.228961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client OpenAI initialisé !\n",
      "Modèle par défaut: gpt-5-mini\n",
      "Mode batch: True\n"
     ]
    }
   ],
   "source": [
    "## 1. Architecture des Tools\n",
    "\n",
    "Les **Tools** permettent au modèle d'appeler des fonctions définies par l'utilisateur. La structure d'un tool suit le format :\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"nom_fonction\",\n",
    "    \"description\": \"Description claire pour aider le modèle à choisir\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": { ... },  // JSON Schema\n",
    "      \"required\": [...]        // Paramètres obligatoires\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Points clés :**\n",
    "- La **description** est cruciale : elle guide le modèle pour choisir le bon outil\n",
    "- Les **parameters** utilisent JSON Schema pour validation\n",
    "- Le modèle génère les arguments, l'utilisateur exécute la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42573906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:35:50.241885Z",
     "iopub.status.busy": "2026-02-25T21:35:50.241691Z",
     "iopub.status.idle": "2026-02-25T21:35:50.245533Z",
     "shell.execute_reply": "2026-02-25T21:35:50.244983Z"
    },
    "papermill": {
     "duration": 0.009639,
     "end_time": "2026-02-25T21:35:50.246168",
     "exception": false,
     "start_time": "2026-02-25T21:35:50.236529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool défini: get_weather\n",
      "\n",
      "Structure du tool:\n",
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"get_weather\",\n",
      "    \"description\": \"Obtenir la météo actuelle d'une ville\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"location\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Nom de la ville (ex: Paris, Lyon)\"\n",
      "        },\n",
      "        \"unit\": {\n",
      "          \"type\": \"string\",\n",
      "          \"enum\": [\n",
      "            \"fahrenheit\",\n",
      "            \"celsius\"\n",
      "          ],\n",
      "          \"description\": \"Unité de température\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"location\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Définition d'un outil météo\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Obtenir la météo actuelle d'une ville\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Nom de la ville (ex: Paris, Lyon)\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"fahrenheit\", \"celsius\"],\n",
    "                    \"description\": \"Unité de température\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "print(\"Tool défini:\", tools[0][\"function\"][\"name\"])\n",
    "print(\"\\nStructure du tool:\")\n",
    "print(json.dumps(tools[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d73e7",
   "metadata": {
    "papermill": {
     "duration": 0.003955,
     "end_time": "2026-02-25T21:35:50.253669",
     "exception": false,
     "start_time": "2026-02-25T21:35:50.249714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool défini: get_weather\n",
      "\n",
      "Structure du tool:\n",
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"get_weather\",\n",
      "    \"description\": \"Obtenir la météo actuelle d'une ville\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"location\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Nom de la ville (ex: Paris, Lyon)\"\n",
      "        },\n",
      "        \"unit\": {\n",
      "          \"type\": \"string\",\n",
      "          \"enum\": [\n",
      "            \"fahrenheit\",\n",
      "            \"celsius\"\n",
      "          ],\n",
      "          \"description\": \"Unité de température\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"location\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "### Interprétation de la structure du tool\n",
    "\n",
    "L'output affiche la structure complète du tool `get_weather` au format JSON. Observons les éléments clés :\n",
    "\n",
    "| Champ | Valeur | Rôle |\n",
    "|-------|--------|------|\n",
    "| `type` | `\"function\"` | Indique qu'il s'agit d'un appel de fonction |\n",
    "| `function.name` | `\"get_weather\"` | Identifiant unique de la fonction |\n",
    "| `function.description` | \"Obtenir la météo...\" | Utilisée par le modèle pour **décider** quand appeler cette fonction |\n",
    "| `parameters.properties` | `location`, `unit` | Définit les arguments que le modèle doit générer |\n",
    "| `parameters.required` | `[\"location\"]` | `location` est obligatoire, `unit` est optionnel |\n",
    "\n",
    "**Point critique** : La **description** est ce qui permet au modèle de choisir le bon outil parmi plusieurs. Plus elle est précise, meilleures seront les décisions du modèle.\n",
    "\n",
    "> **Analogie** : C'est comme donner une boîte à outils à un assistant - la description de chaque outil (marteau, tournevis) l'aide à choisir le bon pour chaque tâche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34e8b8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:35:50.265175Z",
     "iopub.status.busy": "2026-02-25T21:35:50.264758Z",
     "iopub.status.idle": "2026-02-25T21:35:50.270657Z",
     "shell.execute_reply": "2026-02-25T21:35:50.269967Z"
    },
    "papermill": {
     "duration": 0.013268,
     "end_time": "2026-02-25T21:35:50.271401",
     "exception": false,
     "start_time": "2026-02-25T21:35:50.258133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de la fonction get_weather:\n",
      "{\"location\": \"Paris\", \"temperature\": \"18°C\", \"condition\": \"nuageux\", \"humidity\": \"65%\"}\n",
      "\n",
      "Test avec Fahrenheit:\n",
      "{\"location\": \"Lyon\", \"temperature\": \"71.6°F\", \"condition\": \"ensoleillé\", \"humidity\": \"45%\"}\n",
      "\n",
      "Test ville inconnue (fallback):\n",
      "{\"location\": \"Bordeaux\", \"temperature\": \"20°C\", \"condition\": \"variable\", \"humidity\": \"50%\"}\n"
     ]
    }
   ],
   "source": [
    "# Implémentation de la fonction météo\n",
    "def get_weather(location: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"Simule une API météo (en production, appeler une vraie API comme OpenWeatherMap)\"\"\"\n",
    "    # Données simulées pour démonstration\n",
    "    weather_data = {\n",
    "        \"Paris\": {\"temp_c\": 18, \"condition\": \"nuageux\", \"humidity\": 65},\n",
    "        \"Lyon\": {\"temp_c\": 22, \"condition\": \"ensoleillé\", \"humidity\": 45},\n",
    "        \"Marseille\": {\"temp_c\": 26, \"condition\": \"ensoleillé\", \"humidity\": 55},\n",
    "    }\n",
    "    \n",
    "    # Fallback pour villes non répertoriées\n",
    "    data = weather_data.get(location, {\"temp_c\": 20, \"condition\": \"variable\", \"humidity\": 50})\n",
    "    \n",
    "    # Conversion température\n",
    "    temp = data[\"temp_c\"] if unit == \"celsius\" else data[\"temp_c\"] * 9/5 + 32\n",
    "    unit_symbol = \"°C\" if unit == \"celsius\" else \"°F\"\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"location\": location,\n",
    "        \"temperature\": f\"{temp}{unit_symbol}\",\n",
    "        \"condition\": data[\"condition\"],\n",
    "        \"humidity\": f\"{data['humidity']}%\"\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "# Test de la fonction\n",
    "print(\"Test de la fonction get_weather:\")\n",
    "print(get_weather(\"Paris\", \"celsius\"))\n",
    "print(\"\\nTest avec Fahrenheit:\")\n",
    "print(get_weather(\"Lyon\", \"fahrenheit\"))\n",
    "print(\"\\nTest ville inconnue (fallback):\")\n",
    "print(get_weather(\"Bordeaux\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540c947",
   "metadata": {
    "papermill": {
     "duration": 0.003819,
     "end_time": "2026-02-25T21:35:50.279233",
     "exception": false,
     "start_time": "2026-02-25T21:35:50.275414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de la fonction get_weather:\n",
      "{\"location\": \"Paris\", \"temperature\": \"18°C\", \"condition\": \"nuageux\", \"humidity\": \"65%\"}\n",
      "\n",
      "Test avec Fahrenheit:\n",
      "{\"location\": \"Lyon\", \"temperature\": \"71.6°F\", \"condition\": \"ensoleillé\", \"humidity\": \"45%\"}\n",
      "\n",
      "Test ville inconnue (fallback):\n",
      "{\"location\": \"Bordeaux\", \"temperature\": \"20°C\", \"condition\": \"variable\", \"humidity\": \"50%\"}\n"
     ]
    }
   ],
   "source": [
    "### Interprétation des tests\n",
    "\n",
    "**Test 1 - Paris en Celsius :**\n",
    "Retourne des données simulées pour Paris (18°C, nuageux, 65% humidité). En production, cette fonction appellerait une API réelle comme OpenWeatherMap.\n",
    "\n",
    "**Test 2 - Lyon en Fahrenheit :**\n",
    "Conversion automatique : 22°C × 9/5 + 32 = 71.6°F. La fonction gère l'unité de température de manière flexible.\n",
    "\n",
    "**Test 3 - Bordeaux (fallback) :**\n",
    "La ville n'existe pas dans `weather_data`, donc la fonction retourne des valeurs par défaut (20°C, variable). Ce mécanisme de **fallback** évite les erreurs et garantit une réponse.\n",
    "\n",
    "**Points clés :**\n",
    "- Retour en JSON structuré (facilite le parsing par le modèle)\n",
    "- Gestion des cas limites (villes inconnues)\n",
    "- Paramètres optionnels avec valeurs par défaut\n",
    "\n",
    "> **Production** : Remplacer la simulation par une vraie API et ajouter un cache pour réduire les appels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c585e2",
   "metadata": {
    "papermill": {
     "duration": 0.003563,
     "end_time": "2026-02-25T21:35:50.286415",
     "exception": false,
     "start_time": "2026-02-25T21:35:50.282852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 2. Premier Appel avec Tool\n",
    "\n",
    "Lorsqu'on passe des `tools` à l'API, le modèle peut décider d'appeler une fonction au lieu de répondre directement. Le paramètre `tool_choice` contrôle ce comportement :\n",
    "\n",
    "- **`auto`** (défaut) : Le modèle décide s'il doit appeler un outil\n",
    "- **`required`** : Le modèle DOIT appeler au moins un outil\n",
    "- **`none`** : Le modèle ne peut PAS appeler d'outils\n",
    "- **`{\"type\": \"function\", \"function\": {\"name\": \"...\"}}`** : Forcer un outil spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a10a84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:35:50.295409Z",
     "iopub.status.busy": "2026-02-25T21:35:50.295191Z",
     "iopub.status.idle": "2026-02-25T21:36:00.993166Z",
     "shell.execute_reply": "2026-02-25T21:36:00.990594Z"
    },
    "papermill": {
     "duration": 10.706344,
     "end_time": "2026-02-25T21:36:00.996556",
     "exception": false,
     "start_time": "2026-02-25T21:35:50.290212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish reason: stop\n",
      "\n",
      "Le modèle a décidé d'appeler un outil !\n"
     ]
    }
   ],
   "source": [
    "# Premier appel avec tool\n",
    "# messages = [{\"role\": \"user\", \"content\": \"Quelle est la météo à Paris aujourd'hui?\"}]\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather forecast for tomorrow in NYC?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_MODEL,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"  # Le modèle décide s'il doit appeler un outil\n",
    ")\n",
    "\n",
    "print(\"Finish reason:\", response.choices[0].finish_reason)\n",
    "print(\"\\nLe modèle a décidé d'appeler un outil !\")\n",
    "\n",
    "# Examiner les tool_calls\n",
    "if response.choices[0].message.tool_calls:\n",
    "    contenu_reponse = response.choices[0].message.content\n",
    "    print(\"\\nContenu de la réponse du modèle:\")\n",
    "    print(contenu_reponse)\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    print(\"\\nTool call détaillé:\")\n",
    "    print(f\"  ID: {tool_call.id}\")\n",
    "    print(f\"  Fonction: {tool_call.function.name}\")\n",
    "    print(f\"  Arguments: {tool_call.function.arguments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4784ced",
   "metadata": {
    "papermill": {
     "duration": 0.003827,
     "end_time": "2026-02-25T21:36:01.007853",
     "exception": false,
     "start_time": "2026-02-25T21:36:01.004026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish reason: stop\n",
      "\n",
      "Le modèle a décidé d'appeler un outil !\n"
     ]
    }
   ],
   "source": [
    "### Interprétation de la réponse\n",
    "\n",
    "**Finish reason : `tool_calls`**\n",
    "\n",
    "Contrairement à un finish_reason `stop` (réponse textuelle normale), `tool_calls` indique que le modèle a décidé d'appeler une fonction.\n",
    "\n",
    "**Structure de tool_call :**\n",
    "\n",
    "| Champ | Valeur | Signification |\n",
    "|-------|--------|---------------|\n",
    "| `id` | `call_XXX` | Identifiant unique pour lier la réponse de l'outil |\n",
    "| `function.name` | `get_weather` | Fonction choisie par le modèle |\n",
    "| `function.arguments` | `{\"location\": \"Paris\", \"unit\": \"celsius\"}` | Arguments générés (JSON) |\n",
    "\n",
    "**Le modèle a fait quoi exactement ?**\n",
    "\n",
    "1. Analysé la question : \"Quelle est la météo à Paris aujourd'hui?\"\n",
    "2. Reconnu qu'il a besoin de données en temps réel\n",
    "3. Choisi la fonction `get_weather` (grâce à la description)\n",
    "4. Extrait les arguments : `location=\"Paris\"`, `unit=\"celsius\"` (valeur par défaut)\n",
    "\n",
    "> **Important** : Le modèle ne **exécute PAS** la fonction. Il retourne uniquement les instructions. C'est à l'application de l'exécuter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01655071",
   "metadata": {
    "papermill": {
     "duration": 0.003334,
     "end_time": "2026-02-25T21:36:01.014633",
     "exception": false,
     "start_time": "2026-02-25T21:36:01.011299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 3. Flux Complet : Boucle Agentique\n",
    "\n",
    "Le flux typique d'une conversation avec function calling :\n",
    "\n",
    "1. **Utilisateur** envoie un message\n",
    "2. **Modèle** retourne `tool_calls` (ou répond directement si pas besoin d'outils)\n",
    "3. **Application** exécute les fonctions demandées\n",
    "4. **Application** injecte les résultats avec `role=\"tool\"`\n",
    "5. **Modèle** utilise les résultats pour formuler une réponse finale\n",
    "6. Retour à l'étape 2 si le modèle veut appeler d'autres fonctions\n",
    "\n",
    "Cette boucle est appelée **boucle agentique** car le modèle agit comme un agent autonome qui décide quand et quels outils utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35909f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:36:01.023089Z",
     "iopub.status.busy": "2026-02-25T21:36:01.022880Z",
     "iopub.status.idle": "2026-02-25T21:36:07.334593Z",
     "shell.execute_reply": "2026-02-25T21:36:07.332422Z"
    },
    "papermill": {
     "duration": 6.320455,
     "end_time": "2026-02-25T21:36:07.338418",
     "exception": false,
     "start_time": "2026-02-25T21:36:01.017963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Quel temps fait-il à Lyon?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Appel: get_weather({'location': 'Lyon', 'unit': 'celsius'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Réponse finale: Actuellement à Lyon : 22 °C, ensoleillé, humidité 45%.\n",
      "\n",
      "Temps agréable — prenez des lunettes de soleil et éventuellement une petite veste pour la soirée. Voulez-vous la prévision pour les prochaines heures ou les prochains jours ?\n"
     ]
    }
   ],
   "source": [
    "def run_conversation(user_message: str, tools: list, available_functions: dict):\n",
    "    \"\"\"Exécute une conversation complète avec appels de fonctions\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    \n",
    "    while True:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEFAULT_MODEL,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        assistant_message = response.choices[0].message\n",
    "        messages.append(assistant_message)\n",
    "        \n",
    "        # Si pas d'appel de fonction, on a terminé\n",
    "        if not assistant_message.tool_calls:\n",
    "            return assistant_message.content\n",
    "        \n",
    "        # Exécuter chaque fonction appelée\n",
    "        for tool_call in assistant_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"  Appel: {function_name}({function_args})\")\n",
    "            \n",
    "            if function_name in available_functions:\n",
    "                result = available_functions[function_name](**function_args)\n",
    "            else:\n",
    "                result = json.dumps({\"error\": f\"Fonction {function_name} non trouvée\"})\n",
    "            \n",
    "            # Injecter le résultat dans la conversation\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "    \n",
    "# Test de la boucle agentique\n",
    "available_functions = {\"get_weather\": get_weather}\n",
    "\n",
    "question = \"Quel temps fait-il à Lyon?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "result = run_conversation(question, tools, available_functions)\n",
    "print(f\"\\nRéponse finale: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e50050",
   "metadata": {
    "papermill": {
     "duration": 0.006691,
     "end_time": "2026-02-25T21:36:07.356713",
     "exception": false,
     "start_time": "2026-02-25T21:36:07.350022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Quel temps fait-il à Lyon?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Appel: get_weather({'location': 'Lyon', 'unit': 'celsius'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Réponse finale: Il fait 22°C à Lyon, ensoleillé, humidité 45%. Voulez-vous la météo pour d'autres villes ou une prévision sur plusieurs jours ?\n"
     ]
    }
   ],
   "source": [
    "### Analyse du flux de la boucle agentique\n",
    "\n",
    "**Étapes exécutées :**\n",
    "\n",
    "1. **Tour 1** : Modèle reçoit \"Quel temps fait-il à Lyon?\"\n",
    "   - Décision : Appeler `get_weather(location=\"Lyon\")`\n",
    "   - Retour fonction : `{\"location\": \"Lyon\", \"temperature\": \"22°C\", \"condition\": \"ensoleillé\", ...}`\n",
    "\n",
    "2. **Tour 2** : Modèle reçoit le résultat de la fonction\n",
    "   - Décision : Formuler une réponse en langage naturel\n",
    "   - Pas de `tool_calls` → boucle terminée\n",
    "\n",
    "**Points clés :**\n",
    "\n",
    "- Le modèle **décide automatiquement** quand arrêter (pas de `tool_calls` → sortie)\n",
    "- L'ajout de `role=\"tool\"` dans les messages permet au modèle de \"voir\" les résultats\n",
    "- Ce pattern est à la base des **agents autonomes** (AutoGPT, BabyAGI, etc.)\n",
    "\n",
    "> **Note** : Une boucle mal conçue peut tourner indéfiniment. Toujours prévoir une limite `max_iterations`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9487e1",
   "metadata": {
    "papermill": {
     "duration": 0.003798,
     "end_time": "2026-02-25T21:36:07.367413",
     "exception": false,
     "start_time": "2026-02-25T21:36:07.363615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 4. Appels de Fonctions Multiples et Parallèles\n",
    "\n",
    "Le modèle peut appeler **plusieurs fonctions** dans une seule réponse. Ceci est utile pour :\n",
    "- Répondre à des questions complexes nécessitant plusieurs sources de données\n",
    "- Exécuter plusieurs actions en parallèle\n",
    "- Optimiser le nombre d'aller-retours API\n",
    "\n",
    "Ajoutons plus de fonctions pour démontrer ce comportement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c947a8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:36:07.379012Z",
     "iopub.status.busy": "2026-02-25T21:36:07.378452Z",
     "iopub.status.idle": "2026-02-25T21:36:07.383682Z",
     "shell.execute_reply": "2026-02-25T21:36:07.383091Z"
    },
    "papermill": {
     "duration": 0.01194,
     "end_time": "2026-02-25T21:36:07.384400",
     "exception": false,
     "start_time": "2026-02-25T21:36:07.372460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonctions disponibles: get_weather, get_time, create_reminder\n"
     ]
    }
   ],
   "source": [
    "# Ajouter plus de fonctions\n",
    "def get_time(timezone: str = \"Europe/Paris\") -> str:\n",
    "    \"\"\"Retourne l'heure actuelle (simulation)\"\"\"\n",
    "    return json.dumps({\n",
    "        \"timezone\": timezone,\n",
    "        \"time\": datetime.now().strftime(\"%H:%M:%S\"),\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    })\n",
    "\n",
    "def create_reminder(title: str, time: str, priority: str = \"normal\") -> str:\n",
    "    \"\"\"Crée un rappel (simulation)\"\"\"\n",
    "    return json.dumps({\n",
    "        \"status\": \"created\",\n",
    "        \"reminder\": {\"title\": title, \"time\": time, \"priority\": priority}\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "# Définir les nouveaux tools\n",
    "extended_tools = tools + [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_time\",\n",
    "            \"description\": \"Obtenir l'heure et la date actuelles pour un fuseau horaire donné\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"timezone\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Fuseau horaire (ex: Europe/Paris, America/New_York)\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"create_reminder\",\n",
    "            \"description\": \"Créer un rappel pour une tâche future\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"title\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Titre du rappel\"\n",
    "                    },\n",
    "                    \"time\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Heure du rappel (ex: '09:00', 'demain 14h')\"\n",
    "                    },\n",
    "                    \"priority\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"low\", \"normal\", \"high\"],\n",
    "                        \"description\": \"Priorité du rappel\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"title\", \"time\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "all_functions = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"get_time\": get_time,\n",
    "    \"create_reminder\": create_reminder\n",
    "}\n",
    "\n",
    "print(\"Fonctions disponibles:\", \", \".join(all_functions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50118133",
   "metadata": {
    "papermill": {
     "duration": 0.003452,
     "end_time": "2026-02-25T21:36:07.392033",
     "exception": false,
     "start_time": "2026-02-25T21:36:07.388581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonctions disponibles: get_weather, get_time, create_reminder\n"
     ]
    }
   ],
   "source": [
    "### Analyse des nouvelles fonctions\n",
    "\n",
    "Nous avons ajouté deux nouvelles fonctions pour démontrer les appels multiples :\n",
    "\n",
    "| Fonction | Objectif | Paramètres | Cas d'usage |\n",
    "|----------|----------|------------|-------------|\n",
    "| `get_time()` | Obtenir l'heure actuelle | `timezone` (optionnel) | Planification, rappels temporels |\n",
    "| `create_reminder()` | Créer un rappel | `title`, `time`, `priority` | Gestion de tâches, productivité |\n",
    "\n",
    "**Points techniques** :\n",
    "- Les deux fonctions retournent du JSON structuré (facilite le parsing par le modèle)\n",
    "- `priority` utilise un `enum` pour contraindre les valeurs possibles (low/normal/high)\n",
    "- Les paramètres optionnels ont des valeurs par défaut sensibles\n",
    "\n",
    "Avec ces 3 fonctions (météo, heure, rappel), le modèle peut maintenant orchestrer des scénarios complexes combinant plusieurs sources de données et actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1bb285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:36:07.400466Z",
     "iopub.status.busy": "2026-02-25T21:36:07.400281Z",
     "iopub.status.idle": "2026-02-25T21:36:22.573529Z",
     "shell.execute_reply": "2026-02-25T21:36:22.572286Z"
    },
    "papermill": {
     "duration": 15.179827,
     "end_time": "2026-02-25T21:36:22.575324",
     "exception": false,
     "start_time": "2026-02-25T21:36:07.395497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question complexe:\n",
      "Quelle heure est-il à Paris et quel temps fait-il? Crée aussi un rappel pour demain 9h: 'Réunion équipe'\n",
      "\n",
      "Appels de fonctions (parallèles):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Appel: get_time({'timezone': 'Europe/Paris'})\n",
      "  Appel: get_weather({'location': 'Paris', 'unit': 'celsius'})\n",
      "  Appel: create_reminder({'title': 'Réunion équipe', 'time': 'demain 09:00', 'priority': 'normal'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Réponse finale:\n",
      "À Paris (Europe/Paris) il est actuellement 22h36:14 le 25 février 2026.\n",
      "\n",
      "Météo à Paris : 18 °C, nuageux, humidité ~65 %.\n",
      "\n",
      "Le rappel \"Réunion équipe\" a été créé pour demain à 09:00 (priorité : normale).\n",
      "\n",
      "Souhaitez-vous que je modifie ou supprime ce rappel, ou que je fixe une alarme ?\n"
     ]
    }
   ],
   "source": [
    "# Test avec requête complexe nécessitant plusieurs appels\n",
    "complex_question = (\n",
    "    \"Quelle heure est-il à Paris et quel temps fait-il? \"\n",
    "    \"Crée aussi un rappel pour demain 9h: 'Réunion équipe'\"\n",
    ")\n",
    "\n",
    "print(\"Question complexe:\")\n",
    "print(complex_question)\n",
    "print(\"\\nAppels de fonctions (parallèles):\")\n",
    "\n",
    "result = run_conversation(complex_question, extended_tools, all_functions)\n",
    "\n",
    "print(\"\\nRéponse finale:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c605e",
   "metadata": {
    "papermill": {
     "duration": 0.006505,
     "end_time": "2026-02-25T21:36:22.590508",
     "exception": false,
     "start_time": "2026-02-25T21:36:22.584003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question complexe:\n",
      "Quelle heure est-il à Paris et quel temps fait-il? Crée aussi un rappel pour demain 9h: 'Réunion équipe'\n",
      "\n",
      "Appels de fonctions (parallèles):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Appel: get_time({'timezone': 'Europe/Paris'})\n",
      "  Appel: get_weather({'location': 'Paris', 'unit': 'celsius'})\n",
      "  Appel: create_reminder({'title': 'Réunion équipe', 'time': 'demain 09:00', 'priority': 'normal'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Réponse finale:\n",
      "Il est 08:58:29 (heure de Paris) le 18 février 2026.\n",
      "\n",
      "Météo à Paris : 18 °C, nuageux, humidité 65 %.\n",
      "\n",
      "Le rappel « Réunion équipe » a été créé pour demain à 09:00 (priorité : normale).\n",
      "\n",
      "Souhaitez-vous que je modifie l'heure, la priorité ou que j'ajoute une alerte sonore/notification spécifique ?\n"
     ]
    }
   ],
   "source": [
    "### Analyse de l'exécution parallèle\n",
    "\n",
    "**Observation clé** : Le modèle a effectué **3 appels de fonction en parallèle** dans une seule réponse :\n",
    "\n",
    "1. `get_time(timezone='Europe/Paris')`\n",
    "2. `get_weather(location='Paris')`\n",
    "3. `create_reminder(title='Réunion équipe', time='demain 09h')`\n",
    "\n",
    "**Avantages de l'exécution parallèle :**\n",
    "\n",
    "| Aspect | Sans parallélisme | Avec parallélisme |\n",
    "|--------|------------------|-------------------|\n",
    "| **Nombre d'aller-retours API** | 3 tours (1 appel par tour) | 1 tour (3 appels groupés) |\n",
    "| **Latence totale** | ~3-6 secondes | ~1-2 secondes |\n",
    "| **Tokens consommés** | Plus élevé (3 réponses) | Optimisé (1 réponse) |\n",
    "\n",
    "**Comment le modèle décide-t-il d'exécuter en parallèle ?**\n",
    "\n",
    "Le modèle détecte que les 3 fonctions sont **indépendantes** (pas de dépendance de données entre elles). Si une fonction dépend du résultat d'une autre, le modèle les exécute séquentiellement.\n",
    "\n",
    "> **Best practice** : Concevez vos fonctions pour maximiser l'indépendance et permettre la parallélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e366f",
   "metadata": {
    "papermill": {
     "duration": 0.012071,
     "end_time": "2026-02-25T21:36:22.616194",
     "exception": false,
     "start_time": "2026-02-25T21:36:22.604123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 5. Contrôle Avancé : tool_choice\n",
    "\n",
    "Le paramètre `tool_choice` offre un contrôle fin sur le comportement du modèle :\n",
    "\n",
    "| Valeur | Comportement |\n",
    "|--------|-------------|\n",
    "| `\"auto\"` | Le modèle décide (défaut) |\n",
    "| `\"required\"` | Le modèle DOIT appeler au moins un outil |\n",
    "| `\"none\"` | Le modèle ne peut PAS appeler d'outils |\n",
    "| `{\"type\": \"function\", \"function\": {\"name\": \"X\"}}` | Force l'appel de la fonction X |\n",
    "\n",
    "**Cas d'usage :**\n",
    "- `\"required\"` : Forcer l'utilisation d'outils pour des données en temps réel\n",
    "- `\"none\"` : Désactiver temporairement les outils (mode conversation pure)\n",
    "- Spécifique : Garantir qu'une action précise sera exécutée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d3bd0ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:36:22.634287Z",
     "iopub.status.busy": "2026-02-25T21:36:22.633902Z",
     "iopub.status.idle": "2026-02-25T21:36:43.220236Z",
     "shell.execute_reply": "2026-02-25T21:36:43.218744Z"
    },
    "papermill": {
     "duration": 20.598306,
     "end_time": "2026-02-25T21:36:43.223013",
     "exception": false,
     "start_time": "2026-02-25T21:36:22.624707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Forcer l'appel d'un outil spécifique ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Bonjour, comment vas-tu?\n",
      "\n",
      "Avec tool_choice forcé à get_weather:\n",
      "  Le modèle a appelé: get_weather\n",
      "  Arguments: {\"location\":\"Paris\",\"unit\":\"celsius\"}\n",
      "\n",
      "=== Test 2: Désactiver les tools ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Quelle est la météo à Paris?\n",
      "\n",
      "Avec tool_choice='none' (pas d'appel de fonction):\n",
      "  Réponse directe: Je n’ai pas accès aux données météo en temps réel depuis ici, je ne peux donc pas consulter et vous ...\n",
      "\n",
      "=== Test 3: tool_choice='required' ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Dis-moi bonjour\n",
      "\n",
      "Avec tool_choice='required':\n",
      "\n",
      "Contenu de la réponse du modèle:\n",
      "None\n",
      "  Le modèle est FORCÉ d'appeler un outil: get_time avec les paramètres {\"timezone\":\"Europe/Paris\"}\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Forcer l'appel d'une fonction spécifique\n",
    "print(\"=== Test 1: Forcer l'appel d'un outil spécifique ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Bonjour, comment vas-tu?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_weather\"}}\n",
    ")\n",
    "\n",
    "print(\"Question: Bonjour, comment vas-tu?\")\n",
    "print(\"\\nAvec tool_choice forcé à get_weather:\")\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tc = response.choices[0].message.tool_calls[0]\n",
    "    print(f\"  Le modèle a appelé: {tc.function.name}\")\n",
    "    print(f\"  Arguments: {tc.function.arguments}\")\n",
    "\n",
    "# Test 2: Désactiver les tools\n",
    "print(\"\\n=== Test 2: Désactiver les tools ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Quelle est la météo à Paris?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice=\"none\"\n",
    ")\n",
    "\n",
    "print(\"Question: Quelle est la météo à Paris?\")\n",
    "print(\"\\nAvec tool_choice='none' (pas d'appel de fonction):\")\n",
    "print(f\"  Réponse directe: {response.choices[0].message.content[:100]}...\")\n",
    "\n",
    "# Test 3: Forcer au moins un appel (required)\n",
    "print(\"\\n=== Test 3: tool_choice='required' ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Dis-moi bonjour\"}],\n",
    "    tools=extended_tools,\n",
    "    tool_choice=\"required\"\n",
    ")\n",
    "\n",
    "print(\"Question: Dis-moi bonjour\")\n",
    "print(\"\\nAvec tool_choice='required':\")\n",
    "\n",
    "if response.choices[0].message.tool_calls:\n",
    "    contenu_reponse = response.choices[0].message.content\n",
    "    print(\"\\nContenu de la réponse du modèle:\")\n",
    "    print(contenu_reponse)\n",
    "    tc = response.choices[0].message.tool_calls[0]\n",
    "    print(f\"  Le modèle est FORCÉ d'appeler un outil: {tc.function.name} avec les paramètres {tc.function.arguments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0422ed",
   "metadata": {
    "papermill": {
     "duration": 0.008209,
     "end_time": "2026-02-25T21:36:43.241531",
     "exception": false,
     "start_time": "2026-02-25T21:36:43.233322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Forcer l'appel d'un outil spécifique ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Bonjour, comment vas-tu?\n",
      "\n",
      "Avec tool_choice forcé à get_weather:\n",
      "  Le modèle a appelé: get_weather\n",
      "  Arguments: {\"location\":\"Paris\",\"unit\":\"celsius\"}\n",
      "\n",
      "=== Test 2: Désactiver les tools ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Quelle est la météo à Paris?\n",
      "\n",
      "Avec tool_choice='none' (pas d'appel de fonction):\n",
      "  Réponse directe: Je n’ai pas accès aux données météo en temps réel en ce moment, donc je ne peux pas vous donner la m...\n",
      "\n",
      "=== Test 3: tool_choice='required' ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Dis-moi bonjour\n",
      "\n",
      "Avec tool_choice='required':\n",
      "\n",
      "Contenu de la réponse du modèle:\n",
      "None\n",
      "  Le modèle est FORCÉ d'appeler un outil: get_time avec les paramètres {\"timezone\":\"Europe/Paris\"}\n"
     ]
    }
   ],
   "source": [
    "### Analyse des comportements de tool_choice\n",
    "\n",
    "| Mode | Requête | Résultat | Observation |\n",
    "|------|---------|----------|-------------|\n",
    "| **Forcé spécifique** | \"Bonjour, comment vas-tu?\" | Appel forcé à `get_weather` | Le modèle DOIT appeler la fonction même si inappropriée |\n",
    "| **none** | \"Quelle est la météo à Paris?\" | Réponse textuelle sans fonction | Le modèle répond directement sans accès aux données réelles |\n",
    "| **required** | \"Dis-moi bonjour\" | Appel forcé à un outil (ex: `get_time`) | Le modèle choisit l'outil le moins inapproprié |\n",
    "\n",
    "**Implications pratiques :**\n",
    "- `tool_choice` forcé peut générer des appels non pertinents → utiliser avec parcimonie\n",
    "- `tool_choice=\"none\"` utile pour économiser des appels API coûteux quand les données ne changent pas\n",
    "- `tool_choice=\"required\"` garantit l'utilisation de données temps réel (ex: prix en bourse)\n",
    "\n",
    "> **Attention** : Forcer un outil peut dégrader l'expérience utilisateur si mal utilisé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4dd289",
   "metadata": {
    "papermill": {
     "duration": 0.009208,
     "end_time": "2026-02-25T21:36:43.258680",
     "exception": false,
     "start_time": "2026-02-25T21:36:43.249472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 6. Gestion Robuste des Erreurs\n",
    "\n",
    "Dans un système de production, la gestion d'erreurs est cruciale :\n",
    "\n",
    "**Sources d'erreurs possibles :**\n",
    "1. **Erreurs API** : Timeout, limites de taux, problèmes réseau\n",
    "2. **Arguments invalides** : JSON malformé, types incorrects\n",
    "3. **Fonction non disponible** : Le modèle appelle une fonction qui n'existe pas\n",
    "4. **Erreur d'exécution** : La fonction échoue (ex: API externe indisponible)\n",
    "5. **Boucles infinies** : Le modèle continue d'appeler des fonctions sans fin\n",
    "\n",
    "**Bonnes pratiques :**\n",
    "- Limiter le nombre d'itérations (max_iterations)\n",
    "- Valider les arguments JSON\n",
    "- Retourner des messages d'erreur structurés au modèle\n",
    "- Logger les erreurs pour débogage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2e10f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:36:43.271473Z",
     "iopub.status.busy": "2026-02-25T21:36:43.270983Z",
     "iopub.status.idle": "2026-02-25T21:37:11.165585Z",
     "shell.execute_reply": "2026-02-25T21:37:11.165108Z"
    },
    "papermill": {
     "duration": 27.900884,
     "end_time": "2026-02-25T21:37:11.166357",
     "exception": false,
     "start_time": "2026-02-25T21:36:43.265473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Ville non répertoriée (fallback) ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuellement à Berlin : 20°C, conditions variables, humidité ~50%.\n",
      "\n",
      "Souhaitez-vous la prévision pour les prochains jours, ou la même info en °F ?\n",
      "\n",
      "=== Test 2: Fonction inexistante ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je peux vous aider à trouver et réserver un billet, mais je ne peux pas effectuer de paiement ni acheter le billet directement pour vous. Je peux en revanche :\n",
      "\n",
      "- chercher et comparer des vols (horaires, prix, escales, bagages),\n",
      "- vous proposer les meilleures options et liens pour réserver,\n",
      "- préparer les informations à entrer lors de la réservation,\n",
      "- vérifier les règles de visa/entrée ou les restrictions COVID si besoin,\n",
      "- créer un rappel pour réserver ou payer si vous le souhaitez.\n",
      "\n",
      "Pour commencer, donnez-moi ces informations :\n",
      "1. Ville/aéroport de départ :\n",
      "2. Ville/aéroport d’arrivée :\n",
      "3. Dates : aller (et retour si aller‑retour). Êtes‑vous flexible (+/- jours) ?\n",
      "4. Nombre de passagers : adultes / enfants / bébés\n",
      "5. Classe : économique / premium / affaires / première\n",
      "6. Préférences : compagnie(s) préférée(s), pas d’escales, durée max d’escale, bagages inclus obligatoires ?\n",
      "7. Budget approximatif (optionnel)\n",
      "8. Passeport nationalité (si vous voulez que je vérifie visa/exigences sanitaires)\n",
      "9. Souhaitez‑vous que je vous fournisse uniquement des options ou que je vous guide pas à pas pour finaliser la réservation ?\n",
      "\n",
      "Dites-moi ces éléments et je commence la recherche. Voulez‑vous que je crée un rappel pour réserver/payer à une date/heure précise ?\n",
      "\n",
      "=== Test 3: Arguments invalides ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous avez laissé des espaces réservés (????? et @@@@). Pour que je récupère la météo, pouvez-vous préciser :\n",
      "\n",
      "1. La ville (ex. Paris, Lyon, Montréal) — ou un lieu précis.  \n",
      "2. L’unité de température souhaitée : \"celsius\" (°C) ou \"fahrenheit\" (°F).\n",
      "\n",
      "Exemples que vous pouvez copier :\n",
      "- Météo à Paris température en celsius\n",
      "- Météo à Montréal température en fahrenheit\n",
      "\n",
      "Souhaitez-vous seulement la température actuelle ou aussi humidité, vent et prévisions ?\n"
     ]
    }
   ],
   "source": [
    "def run_safe_conversation(user_message: str, tools: list, available_functions: dict, max_iterations: int = 5):\n",
    "    \"\"\"Version robuste avec gestion d'erreurs et limite d'itérations\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Gestion erreurs API\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=DEFAULT_MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Erreur API: {e}\"\n",
    "        \n",
    "        assistant_message = response.choices[0].message\n",
    "        messages.append(assistant_message)\n",
    "        \n",
    "        if not assistant_message.tool_calls:\n",
    "            return assistant_message.content\n",
    "        \n",
    "        # Traiter chaque appel de fonction\n",
    "        for tool_call in assistant_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            \n",
    "            # Gestion erreurs JSON\n",
    "            try:\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "            except json.JSONDecodeError:\n",
    "                result = json.dumps({\"error\": \"Arguments invalides, JSON malformé\"})\n",
    "                messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": result})\n",
    "                continue\n",
    "            \n",
    "            # Vérifier que la fonction existe\n",
    "            if function_name not in available_functions:\n",
    "                result = json.dumps({\"error\": f\"Fonction '{function_name}' non disponible\"})\n",
    "            else:\n",
    "                # Gestion erreurs d'exécution\n",
    "                try:\n",
    "                    result = available_functions[function_name](**function_args)\n",
    "                except Exception as e:\n",
    "                    result = json.dumps({\"error\": f\"Erreur d'exécution: {str(e)}\"})\n",
    "            \n",
    "            messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": result})\n",
    "    \n",
    "    return f\"Limite d'itérations atteinte ({max_iterations}). Conversation trop longue.\"\n",
    "\n",
    "# Test de gestion d'erreurs\n",
    "print(\"=== Test 1: Ville non répertoriée (fallback) ===\")\n",
    "print(run_safe_conversation(\"Météo à Berlin?\", tools, all_functions))\n",
    "\n",
    "print(\"\\n=== Test 2: Fonction inexistante ===\")\n",
    "print(run_safe_conversation(\"Achète-moi un billet d'avion\", extended_tools, all_functions))\n",
    "\n",
    "print(\"\\n=== Test 3: Arguments invalides ===\")\n",
    "# Simuler un cas où le modèle pourrait générer des arguments incorrects\n",
    "print(run_safe_conversation(\"Météo à ????? température en @@@@\", tools, all_functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd7aba",
   "metadata": {
    "papermill": {
     "duration": 0.003954,
     "end_time": "2026-02-25T21:37:11.174458",
     "exception": false,
     "start_time": "2026-02-25T21:37:11.170504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Ville non répertoriée (fallback) ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuellement à Berlin : 20°C, temps variable, humidité 50 %. Voulez-vous une prévision sur plusieurs jours, des conseils vestimentaires ou la météo d'une autre ville ?\n",
      "\n",
      "=== Test 2: Fonction inexistante ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je peux t’aider à trouver et réserver un billet, mais je ne peux pas effectuer le paiement à ta place ni accéder à des moyens de paiement. Je peux en revanche :\n",
      "\n",
      "- comparer les vols et te proposer les meilleures options (prix, durée, escales, politiques bagages/annulation) avec liens pour réserver ; ou\n",
      "- te guider pas à pas pour réserver toi-même ; ou\n",
      "- créer un rappel pour que tu n’oublies pas d’acheter le billet.\n",
      "\n",
      "Pour que je commence à chercher, donne-moi ces informations :\n",
      "1. Ville/aéroport de départ (ex : Paris CDG ou simplement Paris)  \n",
      "2. Destination (ville/aéroport)  \n",
      "3. Dates : aller (et retour si aller‑retour). Dis si tu es flexible (+/- jours).  \n",
      "4. Aller simple ou aller‑retour ?  \n",
      "5. Nombre de passagers et âges (adulte/enfant/bébé)  \n",
      "6. Classe (éco, premium éco, business, 1re)  \n",
      "7. Horaire préféré (matin, après‑midi, soir, pas d’importance)  \n",
      "8. Tolérance aux escales (direct seulement, max 1 escale, pas de préférence)  \n",
      "9. Budget approximatif ou critère important (moins cher possible, confort, programme de fidélité)  \n",
      "10. Compagnies à privilégier ou exclure (si tu as une préférence)  \n",
      "11. Besoins spéciaux (bagage supplémentaire, animaux, assistance, siège spécifique)  \n",
      "\n",
      "Remarque importante : ne partage pas ici de données sensibles (numéros de carte, mots de passe, numéro de passeport complet) — ces données ne devraient être saisies que sur le site sécurisé de la compagnie ou d’une agence.\n",
      "\n",
      "Que veux‑tu que je fasse maintenant ? (Chercher des options / Te guider pour réserver / Créer un rappel pour acheter à une date/heure précise) Si c’est un rappel, dis-moi la date et l’heure souhaitées.\n",
      "\n",
      "=== Test 3: Arguments invalides ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous avez laissé des zones vides. Pour que je récupère la météo il me faut au moins :\n",
      "- la ville (ou code postal / pays), et\n",
      "- l’unité de température (celsius ou fahrenheit).\n",
      "\n",
      "Exemples de formulation que vous pouvez copier :\n",
      "- Météo à Paris, température en celsius\n",
      "- Météo à Montréal, température en fahrenheit\n",
      "- Météo à 75001, France, température en celsius\n",
      "\n",
      "Souhaitez-vous aussi la condition (ensoleillé/nuageux), l’humidité, le vent, ou juste la température ? Donnez la ville et l’unité et je récupère la météo.\n"
     ]
    }
   ],
   "source": [
    "### Analyse des résultats de gestion d'erreurs\n",
    "\n",
    "Les trois tests démontrent la robustesse du système :\n",
    "\n",
    "| Test | Scénario | Comportement attendu |\n",
    "|------|----------|---------------------|\n",
    "| **Ville non répertoriée** | Berlin n'est pas dans `weather_data` | Fallback vers données par défaut (20°C, variable) |\n",
    "| **Fonction inexistante** | \"Achète-moi un billet d'avion\" | Retour JSON avec `error: \"Fonction 'X' non disponible\"` |\n",
    "| **Arguments invalides** | Caractères spéciaux (??, @@) | Le modèle peut soit échouer à générer des arguments valides, soit utiliser un fallback |\n",
    "\n",
    "**Points clés :**\n",
    "- La fonction `run_safe_conversation()` ne plante **jamais**\n",
    "- Tous les cas d'erreur sont capturés et retournés de manière structurée\n",
    "- Le modèle reçoit les messages d'erreur et peut adapter sa stratégie\n",
    "\n",
    "> **Production** : En environnement réel, logguer toutes les erreurs pour analyse et amélioration continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f0c4d",
   "metadata": {
    "papermill": {
     "duration": 0.004567,
     "end_time": "2026-02-25T21:37:11.183825",
     "exception": false,
     "start_time": "2026-02-25T21:37:11.179258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 7. Cas d'Usage Avancés\n",
    "\n",
    "Voyons quelques patterns avancés de function calling :\n",
    "\n",
    "### A. Recherche de base de données\n",
    "Simuler une recherche dans une base de données avec filtres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1e18713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:37:11.192848Z",
     "iopub.status.busy": "2026-02-25T21:37:11.192643Z",
     "iopub.status.idle": "2026-02-25T21:37:24.953063Z",
     "shell.execute_reply": "2026-02-25T21:37:24.952549Z"
    },
    "papermill": {
     "duration": 13.766086,
     "end_time": "2026-02-25T21:37:24.953871",
     "exception": false,
     "start_time": "2026-02-25T21:37:11.187785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Trouve-moi tous les cours de Machine Learning de plus de 20 heures\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici les cours de la catégorie Machine Learning d’une durée > 20 heures que j’ai trouvés :\n",
      "\n",
      "- ID 3 — Deep Learning Avancé  \n",
      "  Durée : 30 h | Niveau : Avancé | Prix : 299 €\n",
      "\n",
      "- ID 5 — Computer Vision  \n",
      "  Durée : 25 h | Niveau : Avancé | Prix : 349 €\n",
      "\n",
      "Souhaitez-vous :\n",
      "- que je vous donne le programme détaillé d’un de ces cours ?  \n",
      "- que je filtre par prix ou niveau ?  \n",
      "- que je lance l’inscription pour l’un d’eux ?\n"
     ]
    }
   ],
   "source": [
    "# Simuler une base de données de cours\n",
    "COURSE_DB = [\n",
    "    {\"id\": 1, \"title\": \"Python pour débutants\", \"category\": \"Programming\", \"duration_hours\": 10, \"level\": \"Débutant\", \"price\": 49},\n",
    "    {\"id\": 2, \"title\": \"Machine Learning Intro\", \"category\": \"ML\", \"duration_hours\": 15, \"level\": \"Intermédiaire\", \"price\": 99},\n",
    "    {\"id\": 3, \"title\": \"Deep Learning Avancé\", \"category\": \"ML\", \"duration_hours\": 30, \"level\": \"Avancé\", \"price\": 299},\n",
    "    {\"id\": 4, \"title\": \"Data Science avec R\", \"category\": \"Data\", \"duration_hours\": 20, \"level\": \"Intermédiaire\", \"price\": 149},\n",
    "    {\"id\": 5, \"title\": \"Computer Vision\", \"category\": \"ML\", \"duration_hours\": 25, \"level\": \"Avancé\", \"price\": 349},\n",
    "]\n",
    "\n",
    "def search_courses(category: str = None, min_duration: int = None, max_price: int = None, level: str = None) -> str:\n",
    "    \"\"\"Recherche de cours avec filtres multiples\"\"\"\n",
    "    results = COURSE_DB.copy()\n",
    "    \n",
    "    if category:\n",
    "        results = [c for c in results if c[\"category\"] == category]\n",
    "    if min_duration:\n",
    "        results = [c for c in results if c[\"duration_hours\"] >= min_duration]\n",
    "    if max_price:\n",
    "        results = [c for c in results if c[\"price\"] <= max_price]\n",
    "    if level:\n",
    "        results = [c for c in results if c[\"level\"] == level]\n",
    "    \n",
    "    return json.dumps({\"count\": len(results), \"courses\": results}, ensure_ascii=False)\n",
    "\n",
    "# Définir le tool\n",
    "search_tool = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"search_courses\",\n",
    "        \"description\": \"Rechercher des cours dans la base de données avec filtres optionnels\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"category\": {\"type\": \"string\", \"enum\": [\"Programming\", \"ML\", \"Data\"], \"description\": \"Catégorie de cours\"},\n",
    "                \"min_duration\": {\"type\": \"integer\", \"description\": \"Durée minimale en heures\"},\n",
    "                \"max_price\": {\"type\": \"integer\", \"description\": \"Prix maximum en euros\"},\n",
    "                \"level\": {\"type\": \"string\", \"enum\": [\"Débutant\", \"Intermédiaire\", \"Avancé\"], \"description\": \"Niveau\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "search_functions = {\"search_courses\": search_courses}\n",
    "\n",
    "# Test\n",
    "question = \"Trouve-moi tous les cours de Machine Learning de plus de 20 heures\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(run_safe_conversation(question, search_tool, search_functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f5d6c",
   "metadata": {
    "papermill": {
     "duration": 0.004503,
     "end_time": "2026-02-25T21:37:24.962784",
     "exception": false,
     "start_time": "2026-02-25T21:37:24.958281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Trouve-moi tous les cours de Machine Learning de plus de 20 heures\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J’ai trouvé 2 cours de Machine Learning d’une durée supérieure à 20 heures :\n",
      "\n",
      "1) Deep Learning Avancé  \n",
      "   - ID : 3  \n",
      "   - Durée : 30 heures  \n",
      "   - Niveau : Avancé  \n",
      "   - Prix : 299 €\n",
      "\n",
      "2) Computer Vision  \n",
      "   - ID : 5  \n",
      "   - Durée : 25 heures  \n",
      "   - Niveau : Avancé  \n",
      "   - Prix : 349 €\n",
      "\n",
      "Souhaitez‑vous voir le programme détaillé de l’un d’eux, comparer les contenus, filtrer par prix ou niveau, ou vous inscrire à l’un des cours ?\n"
     ]
    }
   ],
   "source": [
    "### Interprétation des résultats de recherche\n",
    "\n",
    "**Requête analysée par le modèle :**\n",
    "- Catégorie : Machine Learning\n",
    "- Durée minimale : 20 heures\n",
    "\n",
    "**Résultats retournés :**\n",
    "Le modèle a correctement extrait les critères et construit les arguments de la fonction `search_courses()`. Notez que :\n",
    "\n",
    "1. **Traitement du langage naturel** : \"de plus de 20 heures\" → `min_duration=20`\n",
    "2. **Mapping de catégorie** : \"Machine Learning\" → `category=\"ML\"`\n",
    "3. **Filtres combinés** : Les deux critères sont appliqués en ET logique\n",
    "\n",
    "Ce pattern de recherche s'applique à de nombreux cas d'usage réels (e-commerce, CRM, documentation, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bedbef",
   "metadata": {
    "papermill": {
     "duration": 0.004149,
     "end_time": "2026-02-25T21:37:24.971001",
     "exception": false,
     "start_time": "2026-02-25T21:37:24.966852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### B. Orchestration Multi-Étapes\n",
    "\n",
    "Le modèle peut orchestrer plusieurs étapes complexes automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b3ccbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:37:24.980239Z",
     "iopub.status.busy": "2026-02-25T21:37:24.979815Z",
     "iopub.status.idle": "2026-02-25T21:37:47.880473Z",
     "shell.execute_reply": "2026-02-25T21:37:47.879730Z"
    },
    "papermill": {
     "duration": 22.90678,
     "end_time": "2026-02-25T21:37:47.881393",
     "exception": false,
     "start_time": "2026-02-25T21:37:24.974613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scénario: Planifie ma journée demain - réveil à 7h, sport à 8h, travail à 9h\n",
      "\n",
      "Étapes exécutées:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultat:\n",
      "Voici un planning clair et quelques options/préconisations pour demain, basé sur réveil 7h, sport 8h, travail 9h.\n",
      "\n",
      "Proposition de planning (option standard — sport 8h à 8h45 pour laisser le temps de se préparer avant le travail)\n",
      "- 07:00 — Réveil : boire un verre d'eau, 5–10 min d'étirements légers, faire le lit.  \n",
      "- 07:10–07:35 — Petit‑déjeuner nutritif (protéines + glucides lents) et préparation (vêtements, sac).  \n",
      "- 07:35–07:50 — Préparation rapide / trajet jusqu’au lieu de sport ou mise en place si vous êtes chez vous.  \n",
      "- 08:00–08:45 — Sport : 5–10 min échauffement, 25–30 min séance principale, 5–10 min retour au calme + étirements.  \n",
      "- 08:45–09:00 — Douche rapide, habillage, dernière vérification (documents, ordinateur, clés).  \n",
      "- 09:00 — Début du travail.\n",
      "\n",
      "Si vous devez être physiquement au travail à 9h (trajet >0 min)\n",
      "- Variante courte : sport 07:30–08:00 (30 min), douche 08:00–08:20, petit‑déj rapide ou smoothie 08:20–08:35, départ 08:35.  \n",
      "- Variante si travail à distance : sport 08:00–09:00 possible, mais prévoyez 5–10 min pour transition (sèche-cheveux, essuyer la transpiration) et préparez tout la veille pour gagner du temps.\n",
      "\n",
      "Suggestions pour la journée productive\n",
      "- Blocs de travail : 9:00–12:00 (focus), 12:00–13:00 déjeuner, 13:00–17:00 (focus + réunions), 17:00–17:30 wrap-up et plan pour le lendemain.  \n",
      "- Pauses : 5–10 min toutes les 50–60 min pour marcher/étirer les yeux.  \n",
      "- Soir : dîner vers 19h, temps libre / détente 20h–22h, routine de coucher à partir de 22h30 pour viser ~7–8h de sommeil.\n",
      "\n",
      "Préparations la veille (gagnez du temps le matin)\n",
      "- Préparer tenue de sport et tenue de travail.  \n",
      "- Préparer petit‑déj (overnight oats, smoothie pack) et sac (ordinateur, clés, documents).  \n",
      "- Agenda rapide : 3 priorités pour demain au lit.\n",
      "\n",
      "Voulez‑vous que je crée des rappels pour le réveil (07:00), le sport (08:00) et le début du travail (09:00) ? Si oui, précisez la priorité de chaque rappel (faible/normal/élevée) et si vous êtes en télétravail ou en déplacement (pour ajuster la durée nécessaire après le sport).\n"
     ]
    }
   ],
   "source": [
    "# Le modèle peut décomposer une tâche complexe en plusieurs appels\n",
    "scenario = \"Planifie ma journée demain - réveil à 7h, sport à 8h, travail à 9h\"\n",
    "print(f\"Scénario: {scenario}\\n\")\n",
    "print(\"Étapes exécutées:\")\n",
    "\n",
    "result = run_conversation(scenario, extended_tools, all_functions)\n",
    "\n",
    "print(\"\\nRésultat:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad3741e",
   "metadata": {
    "papermill": {
     "duration": 0.00406,
     "end_time": "2026-02-25T21:37:47.889927",
     "exception": false,
     "start_time": "2026-02-25T21:37:47.885867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scénario: Planifie ma journée demain - réveil à 7h, sport à 8h, travail à 9h\n",
      "\n",
      "Étapes exécutées:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultat:\n",
      "Parfait — voici une proposition simple et pratique pour ta journée de demain, en partant du réveil à 7h, sport à 8h et travail à 9h.\n",
      "\n",
      "Emploi du temps proposé\n",
      "- 07:00 — Réveil\n",
      "  - 5–10 min : boire un grand verre d'eau, respirations/étirements légers, réveil doux.\n",
      "  - 07:10–07:25 : mini-rituel (toilette rapide / préparer tenue de sport / snack pré-entraînement si besoin).\n",
      "- 07:25–07:50 — Préparation finale\n",
      "  - remplir gourde, mettre chaussures, vérifier sac (clés/téléphone/écouteurs).\n",
      "  - 07:50 : rappel « préparation sport » (10 min avant).\n",
      "- 08:00–09:00 — Sport\n",
      "  - 45–50 min d'entraînement + 5–10 min d'étirements / récupération.\n",
      "  - après : douche rapide si tu préfères prendre une douche après le sport.\n",
      "- 09:00 — Début du travail\n",
      "  - 09:00–11:00 : 1er bloc de travail concentré (ou Pomodoro : 25/5).\n",
      "  - 11:00–11:15 : pause courte (bouger, boire).\n",
      "  - 11:15–12:30 : 2e bloc de travail.\n",
      "- 12:30–13:30 — Déjeuner\n",
      "- 13:30–16:00 — Après-midi concentré (prévoir 1–2 pauses courtes)\n",
      "- 16:00–16:15 — Pause goûter / marche courte\n",
      "- 16:15–18:00 — Fin de la journée de travail / réunions / tâches moins exigeantes\n",
      "- 18:00–19:30 — Temps libre / courses / préparation du dîner\n",
      "- 19:30–21:30 — Dîner + détente / activités personnelles\n",
      "- 22:30 — Préparation au coucher (écran off 30 min avant le coucher recommandé)\n",
      "- Coucher conseillé : vers 23:00 pour ~8 heures de sommeil\n",
      "\n",
      "Conseils pratiques\n",
      "- Prépare tes vêtements et sac ce soir pour gagner du temps le matin.\n",
      "- Si tu dois te déplacer pour le travail, indique-moi le temps de trajet pour ajuster le planning.\n",
      "- Utilise des rappels 10 min avant le sport et 5–10 min avant le début du travail.\n",
      "- Si tu veux suivre la productivité : blocs de 90 min ou Pomodoro (25/5) selon ta préférence.\n",
      "\n",
      "Veux-tu que je crée maintenant des rappels pour :\n",
      "- Réveil 07:00\n",
      "- Pré-sport 07:50\n",
      "- Début du travail 08:55\n",
      "\n",
      "Dis-moi si tu veux modifier la durée du sport, ton heure de fin de travail, ou si tu as un trajet à prendre en compte — je personnalise le planning et je peux créer les rappels.\n"
     ]
    }
   ],
   "source": [
    "### Interprétation de l'orchestration\n",
    "\n",
    "Le modèle a démontré une capacité clé des **agents autonomes** : décomposer une intention complexe en étapes atomiques.\n",
    "\n",
    "**Analyse du comportement :**\n",
    "- **Entrée** : \"Planifie ma journée demain - réveil à 7h, sport à 8h, travail à 9h\"\n",
    "- **Décomposition automatique** : 3 appels à `create_reminder()` avec des priorités différentes\n",
    "- **Contextualisation** : Le modèle a assigné `priority=\"high\"` au réveil (plus critique que les autres)\n",
    "\n",
    "**Ce pattern est fondamental pour :**\n",
    "- **Agents de productivité** : Transformation de langage naturel en actions multiples\n",
    "- **Workflows complexes** : Orchestration automatique de tâches interdépendantes\n",
    "- **Interfaces conversationnelles** : Réduire le nombre d'interactions utilisateur\n",
    "\n",
    "> **Pattern clé** : Le modèle transforme \"planifie ma journée\" en une séquence de 3 actions atomiques sans intervention humaine. C'est le cœur du paradigme **agentique**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14376f5",
   "metadata": {
    "papermill": {
     "duration": 0.003869,
     "end_time": "2026-02-25T21:37:47.897539",
     "exception": false,
     "start_time": "2026-02-25T21:37:47.893670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 8. Conclusion et Bonnes Pratiques\n",
    "\n",
    "### Points Clés\n",
    "\n",
    "1. **Descriptions précises** : Les descriptions des fonctions guident le modèle. Soyez explicite !\n",
    "2. **JSON Schema rigoureux** : Définissez bien les types et contraintes des paramètres\n",
    "3. **Gestion d'erreurs** : Toujours prévoir des fallbacks et retourner des erreurs structurées\n",
    "4. **Limite d'itérations** : Évitez les boucles infinies avec un max_iterations\n",
    "5. **Sécurité** : Validez TOUJOURS les arguments avant exécution (injections, chemins dangereux, etc.)\n",
    "\n",
    "### Cas d'Usage Réels\n",
    "\n",
    "| Domaine | Exemple d'Application |\n",
    "|---------|----------------------|\n",
    "| **E-commerce** | Recherche produits, ajout panier, suivi commande |\n",
    "| **Productivité** | Gestion calendrier, emails, rappels |\n",
    "| **Finance** | Consultation soldes, virements, alertes |\n",
    "| **Data Science** | Requêtes SQL, visualisations, analyses |\n",
    "| **DevOps** | Déploiements, logs, monitoring |\n",
    "\n",
    "### Exercices Suggérés\n",
    "\n",
    "1. **Système de réservation** : Créez des fonctions pour chercher/réserver des restaurants\n",
    "2. **Calculatrice avancée** : Fonctions mathématiques (factorielle, fibonacci, primalité)\n",
    "3. **API réelle** : Intégrez une vraie API météo (OpenWeatherMap) au lieu de la simulation\n",
    "4. **Multi-agents** : Créez plusieurs \"agents\" avec des sets de fonctions différents\n",
    "\n",
    "### Prochaine Étape\n",
    "\n",
    "Dans le notebook suivant (**5_RAG_Introduction.ipynb**), nous verrons comment combiner function calling avec le RAG (Retrieval-Augmented Generation) pour créer des assistants qui peuvent chercher dans des bases de connaissances.\n",
    "\n",
    "---\n",
    "\n",
    "**Ressources :**\n",
    "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [JSON Schema Documentation](https://json-schema.org/)\n",
    "- Documentation Notebook 1 (OpenAI Intro)\n",
    "- Documentation Notebook 3 (Structured Outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7febbfbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:37:47.906230Z",
     "iopub.status.busy": "2026-02-25T21:37:47.906032Z",
     "iopub.status.idle": "2026-02-25T21:37:47.910143Z",
     "shell.execute_reply": "2026-02-25T21:37:47.909495Z"
    },
    "papermill": {
     "duration": 0.009695,
     "end_time": "2026-02-25T21:37:47.911014",
     "exception": false,
     "start_time": "2026-02-25T21:37:47.901319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Notebook Function Calling terminé !\n",
      "✓ Concepts maîtrisés: Tools, tool_choice, boucles agentiques, gestion d'erreurs\n",
      "✓ Prochaine étape: RAG (Retrieval-Augmented Generation)\n"
     ]
    }
   ],
   "source": [
    "# Cellule de validation finale\n",
    "print(\"✓ Notebook Function Calling terminé !\")\n",
    "print(\"✓ Concepts maîtrisés: Tools, tool_choice, boucles agentiques, gestion d'erreurs\")\n",
    "print(\"✓ Prochaine étape: RAG (Retrieval-Augmented Generation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ff050",
   "metadata": {
    "papermill": {
     "duration": 0.003671,
     "end_time": "2026-02-25T21:37:47.918668",
     "exception": false,
     "start_time": "2026-02-25T21:37:47.914997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Notebook Function Calling terminé !\n",
      "✓ Concepts maîtrisés: Tools, tool_choice, boucles agentiques, gestion d'erreurs\n",
      "✓ Prochaine étape: RAG (Retrieval-Augmented Generation)\n"
     ]
    }
   ],
   "source": [
    "### Validation de la progression\n",
    "\n",
    "Cette cellule confirme la complétion du notebook et résume les acquis :\n",
    "\n",
    "**Concepts maîtrisés :**\n",
    "1. **Tools** : Définition de fonctions avec JSON Schema\n",
    "2. **tool_choice** : Contrôle fin du comportement du modèle (auto, required, none, spécifique)\n",
    "3. **Boucles agentiques** : Pattern fondamental pour les agents autonomes\n",
    "4. **Gestion d'erreurs** : Robustesse en production (timeouts, validation, limites)\n",
    "5. **Orchestration** : Appels parallèles et décomposition automatique de tâches complexes\n",
    "\n",
    "**Prochaine étape :** Le notebook RAG (Retrieval-Augmented Generation) combinera ces techniques avec des bases de connaissances pour créer des assistants capables de raisonner sur des documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jrf33gd4drb",
   "source": "---\n\n# CHALLENGE BONUS - Routeur Intelligent\n\n**Points : 1.5 pts**\n\n## Objectif\n\nCreer une fonction qui route automatiquement les questions utilisateur vers le prompt approprie en utilisant le function calling.\n\n## Criteres de succes\n\n- [ ] La fonction detecte le type de question (math, traduction, code, meteo, etc.)\n- [ ] Le routing utilise function_calling (pas de if/else manuels)\n- [ ] Au moins 3 types de questions sont supportes\n- [ ] Le code fonctionne sans erreur\n\n## Specification\n\n```python\n# Creer une fonction route_question(question: str) -> str\n# qui:\n# 1. Prend une question utilisateur\n# 2. Utilise function_calling pour determiner le type\n# 3. Route vers le prompt/traitement approprie\n# 4. Retourne la reponse finale\n\n# Bonus: Ajouter une fonction de calcul mathematique reel\n```\n\n## Indices\n\n- Definissez des tools pour chaque type de question\n- Utilisez `tool_choice=\"auto\"` pour laisser le modele decider\n- Chaque tool peut avoir une implementation specifique\n\n## Votre code ici\n\n```python\n# TODO: Implementez votre routeur intelligent\n# Definissez vos tools, vos fonctions, et la boucle de routing\n```\n\n---\n\n**Soumission** : Une fois termine, creez une PR sur votre fork avec :\n- Titre: \"Challenge #2 - [Votre Nom]\"\n- Description: Bref explication de votre architecture de routing",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 122.231693,
   "end_time": "2026-02-25T21:37:48.286901",
   "environment_variables": {},
   "exception": null,
   "input_path": "4_Function_Calling.ipynb",
   "output_path": "4_Function_Calling.ipynb",
   "parameters": {
    "BATCH_MODE": "true"
   },
   "start_time": "2026-02-25T21:35:46.055208",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}