{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f88dabf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:08.305413Z",
     "iopub.status.busy": "2026-02-18T07:58:08.305154Z",
     "iopub.status.idle": "2026-02-18T07:58:08.310122Z",
     "shell.execute_reply": "2026-02-18T07:58:08.309196Z"
    },
    "papermill": {
     "duration": 0.011447,
     "end_time": "2026-02-18T07:58:08.311543",
     "exception": false,
     "start_time": "2026-02-18T07:58:08.300096",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_MODE = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c3705",
   "metadata": {
    "papermill": {
     "duration": 0.004036,
     "end_time": "2026-02-18T07:58:08.319122",
     "exception": false,
     "start_time": "2026-02-18T07:58:08.315086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function Calling : Connecter les LLMs au Monde Réel\n",
    "\n",
    "Dans ce notebook, nous explorons le **Function Calling** (appel de fonctions), qui permet aux modèles d'interagir avec des systèmes externes comme des APIs, bases de données, ou services web.\n",
    "\n",
    "**Objectifs :**\n",
    "- Comprendre la structure des Tools dans l'API OpenAI\n",
    "- Maîtriser tool_choice (auto, required, none)\n",
    "- Exécuter des fonctions en parallèle\n",
    "- Construire des boucles agentiques\n",
    "\n",
    "**Prérequis :** Notebook 1 (OpenAI Intro), Notebook 3 (Structured Outputs)\n",
    "\n",
    "**Durée estimée :** 60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb27bff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:08.331680Z",
     "iopub.status.busy": "2026-02-18T07:58:08.331253Z",
     "iopub.status.idle": "2026-02-18T07:58:12.309536Z",
     "shell.execute_reply": "2026-02-18T07:58:12.308656Z"
    },
    "papermill": {
     "duration": 3.987322,
     "end_time": "2026-02-18T07:58:12.311243",
     "exception": false,
     "start_time": "2026-02-18T07:58:08.323921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client OpenAI initialisé !\n",
      "Modèle par défaut: gpt-5-mini\n",
      "Mode batch: True\n"
     ]
    }
   ],
   "source": [
    "# Installation et configuration\n",
    "%pip install -q openai python-dotenv\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "load_dotenv('../.env')\n",
    "client = OpenAI()\n",
    "\n",
    "# Charger le modèle depuis .env ou utiliser gpt-5-mini par défaut\n",
    "DEFAULT_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "BATCH_MODE = os.getenv(\"BATCH_MODE\", \"false\").lower() == \"true\"\n",
    "\n",
    "print(\"Client OpenAI initialisé !\")\n",
    "print(f\"Modèle par défaut: {DEFAULT_MODEL}\")\n",
    "print(f\"Mode batch: {BATCH_MODE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f47c47",
   "metadata": {
    "papermill": {
     "duration": 0.006025,
     "end_time": "2026-02-18T07:58:12.322532",
     "exception": false,
     "start_time": "2026-02-18T07:58:12.316507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Architecture des Tools\n",
    "\n",
    "Les **Tools** permettent au modèle d'appeler des fonctions définies par l'utilisateur. La structure d'un tool suit le format :\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"nom_fonction\",\n",
    "    \"description\": \"Description claire pour aider le modèle à choisir\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": { ... },  // JSON Schema\n",
    "      \"required\": [...]        // Paramètres obligatoires\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Points clés :**\n",
    "- La **description** est cruciale : elle guide le modèle pour choisir le bon outil\n",
    "- Les **parameters** utilisent JSON Schema pour validation\n",
    "- Le modèle génère les arguments, l'utilisateur exécute la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04d03f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:12.333679Z",
     "iopub.status.busy": "2026-02-18T07:58:12.332944Z",
     "iopub.status.idle": "2026-02-18T07:58:12.340428Z",
     "shell.execute_reply": "2026-02-18T07:58:12.339545Z"
    },
    "papermill": {
     "duration": 0.014538,
     "end_time": "2026-02-18T07:58:12.341637",
     "exception": false,
     "start_time": "2026-02-18T07:58:12.327099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool défini: get_weather\n",
      "\n",
      "Structure du tool:\n",
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"get_weather\",\n",
      "    \"description\": \"Obtenir la météo actuelle d'une ville\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"location\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Nom de la ville (ex: Paris, Lyon)\"\n",
      "        },\n",
      "        \"unit\": {\n",
      "          \"type\": \"string\",\n",
      "          \"enum\": [\n",
      "            \"fahrenheit\",\n",
      "            \"celsius\"\n",
      "          ],\n",
      "          \"description\": \"Unité de température\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"location\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Définition d'un outil météo\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Obtenir la météo actuelle d'une ville\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Nom de la ville (ex: Paris, Lyon)\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"fahrenheit\", \"celsius\"],\n",
    "                    \"description\": \"Unité de température\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "print(\"Tool défini:\", tools[0][\"function\"][\"name\"])\n",
    "print(\"\\nStructure du tool:\")\n",
    "print(json.dumps(tools[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5461d",
   "metadata": {
    "papermill": {
     "duration": 0.004291,
     "end_time": "2026-02-18T07:58:12.349414",
     "exception": false,
     "start_time": "2026-02-18T07:58:12.345123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interprétation de la structure du tool\n",
    "\n",
    "L'output affiche la structure complète du tool `get_weather` au format JSON. Observons les éléments clés :\n",
    "\n",
    "| Champ | Valeur | Rôle |\n",
    "|-------|--------|------|\n",
    "| `type` | `\"function\"` | Indique qu'il s'agit d'un appel de fonction |\n",
    "| `function.name` | `\"get_weather\"` | Identifiant unique de la fonction |\n",
    "| `function.description` | \"Obtenir la météo...\" | Utilisée par le modèle pour **décider** quand appeler cette fonction |\n",
    "| `parameters.properties` | `location`, `unit` | Définit les arguments que le modèle doit générer |\n",
    "| `parameters.required` | `[\"location\"]` | `location` est obligatoire, `unit` est optionnel |\n",
    "\n",
    "**Point critique** : La **description** est ce qui permet au modèle de choisir le bon outil parmi plusieurs. Plus elle est précise, meilleures seront les décisions du modèle.\n",
    "\n",
    "> **Analogie** : C'est comme donner une boîte à outils à un assistant - la description de chaque outil (marteau, tournevis) l'aide à choisir le bon pour chaque tâche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6722bd40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:12.362899Z",
     "iopub.status.busy": "2026-02-18T07:58:12.362268Z",
     "iopub.status.idle": "2026-02-18T07:58:12.371587Z",
     "shell.execute_reply": "2026-02-18T07:58:12.370224Z"
    },
    "papermill": {
     "duration": 0.016896,
     "end_time": "2026-02-18T07:58:12.372895",
     "exception": false,
     "start_time": "2026-02-18T07:58:12.355999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de la fonction get_weather:\n",
      "{\"location\": \"Paris\", \"temperature\": \"18°C\", \"condition\": \"nuageux\", \"humidity\": \"65%\"}\n",
      "\n",
      "Test avec Fahrenheit:\n",
      "{\"location\": \"Lyon\", \"temperature\": \"71.6°F\", \"condition\": \"ensoleillé\", \"humidity\": \"45%\"}\n",
      "\n",
      "Test ville inconnue (fallback):\n",
      "{\"location\": \"Bordeaux\", \"temperature\": \"20°C\", \"condition\": \"variable\", \"humidity\": \"50%\"}\n"
     ]
    }
   ],
   "source": [
    "# Implémentation de la fonction météo\n",
    "def get_weather(location: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"Simule une API météo (en production, appeler une vraie API comme OpenWeatherMap)\"\"\"\n",
    "    # Données simulées pour démonstration\n",
    "    weather_data = {\n",
    "        \"Paris\": {\"temp_c\": 18, \"condition\": \"nuageux\", \"humidity\": 65},\n",
    "        \"Lyon\": {\"temp_c\": 22, \"condition\": \"ensoleillé\", \"humidity\": 45},\n",
    "        \"Marseille\": {\"temp_c\": 26, \"condition\": \"ensoleillé\", \"humidity\": 55},\n",
    "    }\n",
    "    \n",
    "    # Fallback pour villes non répertoriées\n",
    "    data = weather_data.get(location, {\"temp_c\": 20, \"condition\": \"variable\", \"humidity\": 50})\n",
    "    \n",
    "    # Conversion température\n",
    "    temp = data[\"temp_c\"] if unit == \"celsius\" else data[\"temp_c\"] * 9/5 + 32\n",
    "    unit_symbol = \"°C\" if unit == \"celsius\" else \"°F\"\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"location\": location,\n",
    "        \"temperature\": f\"{temp}{unit_symbol}\",\n",
    "        \"condition\": data[\"condition\"],\n",
    "        \"humidity\": f\"{data['humidity']}%\"\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "# Test de la fonction\n",
    "print(\"Test de la fonction get_weather:\")\n",
    "print(get_weather(\"Paris\", \"celsius\"))\n",
    "print(\"\\nTest avec Fahrenheit:\")\n",
    "print(get_weather(\"Lyon\", \"fahrenheit\"))\n",
    "print(\"\\nTest ville inconnue (fallback):\")\n",
    "print(get_weather(\"Bordeaux\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ec44c",
   "metadata": {
    "papermill": {
     "duration": 0.005635,
     "end_time": "2026-02-18T07:58:12.382862",
     "exception": false,
     "start_time": "2026-02-18T07:58:12.377227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interprétation des tests\n",
    "\n",
    "**Test 1 - Paris en Celsius :**\n",
    "Retourne des données simulées pour Paris (18°C, nuageux, 65% humidité). En production, cette fonction appellerait une API réelle comme OpenWeatherMap.\n",
    "\n",
    "**Test 2 - Lyon en Fahrenheit :**\n",
    "Conversion automatique : 22°C × 9/5 + 32 = 71.6°F. La fonction gère l'unité de température de manière flexible.\n",
    "\n",
    "**Test 3 - Bordeaux (fallback) :**\n",
    "La ville n'existe pas dans `weather_data`, donc la fonction retourne des valeurs par défaut (20°C, variable). Ce mécanisme de **fallback** évite les erreurs et garantit une réponse.\n",
    "\n",
    "**Points clés :**\n",
    "- Retour en JSON structuré (facilite le parsing par le modèle)\n",
    "- Gestion des cas limites (villes inconnues)\n",
    "- Paramètres optionnels avec valeurs par défaut\n",
    "\n",
    "> **Production** : Remplacer la simulation par une vraie API et ajouter un cache pour réduire les appels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccac231",
   "metadata": {
    "papermill": {
     "duration": 0.005604,
     "end_time": "2026-02-18T07:58:12.393533",
     "exception": false,
     "start_time": "2026-02-18T07:58:12.387929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Premier Appel avec Tool\n",
    "\n",
    "Lorsqu'on passe des `tools` à l'API, le modèle peut décider d'appeler une fonction au lieu de répondre directement. Le paramètre `tool_choice` contrôle ce comportement :\n",
    "\n",
    "- **`auto`** (défaut) : Le modèle décide s'il doit appeler un outil\n",
    "- **`required`** : Le modèle DOIT appeler au moins un outil\n",
    "- **`none`** : Le modèle ne peut PAS appeler d'outils\n",
    "- **`{\"type\": \"function\", \"function\": {\"name\": \"...\"}}`** : Forcer un outil spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa8d5d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:12.405909Z",
     "iopub.status.busy": "2026-02-18T07:58:12.405260Z",
     "iopub.status.idle": "2026-02-18T07:58:20.449218Z",
     "shell.execute_reply": "2026-02-18T07:58:20.447847Z"
    },
    "papermill": {
     "duration": 8.052794,
     "end_time": "2026-02-18T07:58:20.451224",
     "exception": false,
     "start_time": "2026-02-18T07:58:12.398430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish reason: stop\n",
      "\n",
      "Le modèle a décidé d'appeler un outil !\n"
     ]
    }
   ],
   "source": [
    "# Premier appel avec tool\n",
    "# messages = [{\"role\": \"user\", \"content\": \"Quelle est la météo à Paris aujourd'hui?\"}]\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather forecast for tomorrow in NYC?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_MODEL,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"  # Le modèle décide s'il doit appeler un outil\n",
    ")\n",
    "\n",
    "print(\"Finish reason:\", response.choices[0].finish_reason)\n",
    "print(\"\\nLe modèle a décidé d'appeler un outil !\")\n",
    "\n",
    "# Examiner les tool_calls\n",
    "if response.choices[0].message.tool_calls:\n",
    "    contenu_reponse = response.choices[0].message.content\n",
    "    print(\"\\nContenu de la réponse du modèle:\")\n",
    "    print(contenu_reponse)\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    print(\"\\nTool call détaillé:\")\n",
    "    print(f\"  ID: {tool_call.id}\")\n",
    "    print(f\"  Fonction: {tool_call.function.name}\")\n",
    "    print(f\"  Arguments: {tool_call.function.arguments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98408cfb",
   "metadata": {
    "papermill": {
     "duration": 0.004128,
     "end_time": "2026-02-18T07:58:20.459205",
     "exception": false,
     "start_time": "2026-02-18T07:58:20.455077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interprétation de la réponse\n",
    "\n",
    "**Finish reason : `tool_calls`**\n",
    "\n",
    "Contrairement à un finish_reason `stop` (réponse textuelle normale), `tool_calls` indique que le modèle a décidé d'appeler une fonction.\n",
    "\n",
    "**Structure de tool_call :**\n",
    "\n",
    "| Champ | Valeur | Signification |\n",
    "|-------|--------|---------------|\n",
    "| `id` | `call_XXX` | Identifiant unique pour lier la réponse de l'outil |\n",
    "| `function.name` | `get_weather` | Fonction choisie par le modèle |\n",
    "| `function.arguments` | `{\"location\": \"Paris\", \"unit\": \"celsius\"}` | Arguments générés (JSON) |\n",
    "\n",
    "**Le modèle a fait quoi exactement ?**\n",
    "\n",
    "1. Analysé la question : \"Quelle est la météo à Paris aujourd'hui?\"\n",
    "2. Reconnu qu'il a besoin de données en temps réel\n",
    "3. Choisi la fonction `get_weather` (grâce à la description)\n",
    "4. Extrait les arguments : `location=\"Paris\"`, `unit=\"celsius\"` (valeur par défaut)\n",
    "\n",
    "> **Important** : Le modèle ne **exécute PAS** la fonction. Il retourne uniquement les instructions. C'est à l'application de l'exécuter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f41f00",
   "metadata": {
    "papermill": {
     "duration": 0.003282,
     "end_time": "2026-02-18T07:58:20.466233",
     "exception": false,
     "start_time": "2026-02-18T07:58:20.462951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Flux Complet : Boucle Agentique\n",
    "\n",
    "Le flux typique d'une conversation avec function calling :\n",
    "\n",
    "1. **Utilisateur** envoie un message\n",
    "2. **Modèle** retourne `tool_calls` (ou répond directement si pas besoin d'outils)\n",
    "3. **Application** exécute les fonctions demandées\n",
    "4. **Application** injecte les résultats avec `role=\"tool\"`\n",
    "5. **Modèle** utilise les résultats pour formuler une réponse finale\n",
    "6. Retour à l'étape 2 si le modèle veut appeler d'autres fonctions\n",
    "\n",
    "Cette boucle est appelée **boucle agentique** car le modèle agit comme un agent autonome qui décide quand et quels outils utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23bea546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:20.478105Z",
     "iopub.status.busy": "2026-02-18T07:58:20.477598Z",
     "iopub.status.idle": "2026-02-18T07:58:23.995616Z",
     "shell.execute_reply": "2026-02-18T07:58:23.995150Z"
    },
    "papermill": {
     "duration": 3.526206,
     "end_time": "2026-02-18T07:58:23.996384",
     "exception": false,
     "start_time": "2026-02-18T07:58:20.470178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Quel temps fait-il à Lyon?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Appel: get_weather({'location': 'Lyon', 'unit': 'celsius'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Réponse finale: Il fait 22°C à Lyon, ensoleillé, humidité 45%. Voulez-vous la météo pour d'autres villes ou une prévision sur plusieurs jours ?\n"
     ]
    }
   ],
   "source": [
    "def run_conversation(user_message: str, tools: list, available_functions: dict):\n",
    "    \"\"\"Exécute une conversation complète avec appels de fonctions\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    \n",
    "    while True:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEFAULT_MODEL,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        assistant_message = response.choices[0].message\n",
    "        messages.append(assistant_message)\n",
    "        \n",
    "        # Si pas d'appel de fonction, on a terminé\n",
    "        if not assistant_message.tool_calls:\n",
    "            return assistant_message.content\n",
    "        \n",
    "        # Exécuter chaque fonction appelée\n",
    "        for tool_call in assistant_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"  Appel: {function_name}({function_args})\")\n",
    "            \n",
    "            if function_name in available_functions:\n",
    "                result = available_functions[function_name](**function_args)\n",
    "            else:\n",
    "                result = json.dumps({\"error\": f\"Fonction {function_name} non trouvée\"})\n",
    "            \n",
    "            # Injecter le résultat dans la conversation\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "    \n",
    "# Test de la boucle agentique\n",
    "available_functions = {\"get_weather\": get_weather}\n",
    "\n",
    "question = \"Quel temps fait-il à Lyon?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "result = run_conversation(question, tools, available_functions)\n",
    "print(f\"\\nRéponse finale: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4372690",
   "metadata": {
    "papermill": {
     "duration": 0.00284,
     "end_time": "2026-02-18T07:58:24.002154",
     "exception": false,
     "start_time": "2026-02-18T07:58:23.999314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Analyse du flux de la boucle agentique\n",
    "\n",
    "**Étapes exécutées :**\n",
    "\n",
    "1. **Tour 1** : Modèle reçoit \"Quel temps fait-il à Lyon?\"\n",
    "   - Décision : Appeler `get_weather(location=\"Lyon\")`\n",
    "   - Retour fonction : `{\"location\": \"Lyon\", \"temperature\": \"22°C\", \"condition\": \"ensoleillé\", ...}`\n",
    "\n",
    "2. **Tour 2** : Modèle reçoit le résultat de la fonction\n",
    "   - Décision : Formuler une réponse en langage naturel\n",
    "   - Pas de `tool_calls` → boucle terminée\n",
    "\n",
    "**Points clés :**\n",
    "\n",
    "- Le modèle **décide automatiquement** quand arrêter (pas de `tool_calls` → sortie)\n",
    "- L'ajout de `role=\"tool\"` dans les messages permet au modèle de \"voir\" les résultats\n",
    "- Ce pattern est à la base des **agents autonomes** (AutoGPT, BabyAGI, etc.)\n",
    "\n",
    "> **Note** : Une boucle mal conçue peut tourner indéfiniment. Toujours prévoir une limite `max_iterations`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194056b",
   "metadata": {
    "papermill": {
     "duration": 0.002853,
     "end_time": "2026-02-18T07:58:24.007722",
     "exception": false,
     "start_time": "2026-02-18T07:58:24.004869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Appels de Fonctions Multiples et Parallèles\n",
    "\n",
    "Le modèle peut appeler **plusieurs fonctions** dans une seule réponse. Ceci est utile pour :\n",
    "- Répondre à des questions complexes nécessitant plusieurs sources de données\n",
    "- Exécuter plusieurs actions en parallèle\n",
    "- Optimiser le nombre d'aller-retours API\n",
    "\n",
    "Ajoutons plus de fonctions pour démontrer ce comportement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4583e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:24.014591Z",
     "iopub.status.busy": "2026-02-18T07:58:24.014345Z",
     "iopub.status.idle": "2026-02-18T07:58:24.020056Z",
     "shell.execute_reply": "2026-02-18T07:58:24.019494Z"
    },
    "papermill": {
     "duration": 0.00993,
     "end_time": "2026-02-18T07:58:24.020756",
     "exception": false,
     "start_time": "2026-02-18T07:58:24.010826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonctions disponibles: get_weather, get_time, create_reminder\n"
     ]
    }
   ],
   "source": [
    "# Ajouter plus de fonctions\n",
    "def get_time(timezone: str = \"Europe/Paris\") -> str:\n",
    "    \"\"\"Retourne l'heure actuelle (simulation)\"\"\"\n",
    "    return json.dumps({\n",
    "        \"timezone\": timezone,\n",
    "        \"time\": datetime.now().strftime(\"%H:%M:%S\"),\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    })\n",
    "\n",
    "def create_reminder(title: str, time: str, priority: str = \"normal\") -> str:\n",
    "    \"\"\"Crée un rappel (simulation)\"\"\"\n",
    "    return json.dumps({\n",
    "        \"status\": \"created\",\n",
    "        \"reminder\": {\"title\": title, \"time\": time, \"priority\": priority}\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "# Définir les nouveaux tools\n",
    "extended_tools = tools + [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_time\",\n",
    "            \"description\": \"Obtenir l'heure et la date actuelles pour un fuseau horaire donné\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"timezone\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Fuseau horaire (ex: Europe/Paris, America/New_York)\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"create_reminder\",\n",
    "            \"description\": \"Créer un rappel pour une tâche future\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"title\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Titre du rappel\"\n",
    "                    },\n",
    "                    \"time\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Heure du rappel (ex: '09:00', 'demain 14h')\"\n",
    "                    },\n",
    "                    \"priority\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"low\", \"normal\", \"high\"],\n",
    "                        \"description\": \"Priorité du rappel\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"title\", \"time\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "all_functions = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"get_time\": get_time,\n",
    "    \"create_reminder\": create_reminder\n",
    "}\n",
    "\n",
    "print(\"Fonctions disponibles:\", \", \".join(all_functions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5788c03",
   "metadata": {
    "papermill": {
     "duration": 0.002873,
     "end_time": "2026-02-18T07:58:24.026706",
     "exception": false,
     "start_time": "2026-02-18T07:58:24.023833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Analyse des nouvelles fonctions\n",
    "\n",
    "Nous avons ajouté deux nouvelles fonctions pour démontrer les appels multiples :\n",
    "\n",
    "| Fonction | Objectif | Paramètres | Cas d'usage |\n",
    "|----------|----------|------------|-------------|\n",
    "| `get_time()` | Obtenir l'heure actuelle | `timezone` (optionnel) | Planification, rappels temporels |\n",
    "| `create_reminder()` | Créer un rappel | `title`, `time`, `priority` | Gestion de tâches, productivité |\n",
    "\n",
    "**Points techniques** :\n",
    "- Les deux fonctions retournent du JSON structuré (facilite le parsing par le modèle)\n",
    "- `priority` utilise un `enum` pour contraindre les valeurs possibles (low/normal/high)\n",
    "- Les paramètres optionnels ont des valeurs par défaut sensibles\n",
    "\n",
    "Avec ces 3 fonctions (météo, heure, rappel), le modèle peut maintenant orchestrer des scénarios complexes combinant plusieurs sources de données et actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "541b20e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:24.033905Z",
     "iopub.status.busy": "2026-02-18T07:58:24.033407Z",
     "iopub.status.idle": "2026-02-18T07:58:35.383223Z",
     "shell.execute_reply": "2026-02-18T07:58:35.381669Z"
    },
    "papermill": {
     "duration": 11.355142,
     "end_time": "2026-02-18T07:58:35.384852",
     "exception": false,
     "start_time": "2026-02-18T07:58:24.029710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question complexe:\n",
      "Quelle heure est-il à Paris et quel temps fait-il? Crée aussi un rappel pour demain 9h: 'Réunion équipe'\n",
      "\n",
      "Appels de fonctions (parallèles):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Appel: get_time({'timezone': 'Europe/Paris'})\n",
      "  Appel: get_weather({'location': 'Paris', 'unit': 'celsius'})\n",
      "  Appel: create_reminder({'title': 'Réunion équipe', 'time': 'demain 09:00', 'priority': 'normal'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Réponse finale:\n",
      "Il est 08:58:29 (heure de Paris) le 18 février 2026.\n",
      "\n",
      "Météo à Paris : 18 °C, nuageux, humidité 65 %.\n",
      "\n",
      "Le rappel « Réunion équipe » a été créé pour demain à 09:00 (priorité : normale).\n",
      "\n",
      "Souhaitez-vous que je modifie l'heure, la priorité ou que j'ajoute une alerte sonore/notification spécifique ?\n"
     ]
    }
   ],
   "source": [
    "# Test avec requête complexe nécessitant plusieurs appels\n",
    "complex_question = (\n",
    "    \"Quelle heure est-il à Paris et quel temps fait-il? \"\n",
    "    \"Crée aussi un rappel pour demain 9h: 'Réunion équipe'\"\n",
    ")\n",
    "\n",
    "print(\"Question complexe:\")\n",
    "print(complex_question)\n",
    "print(\"\\nAppels de fonctions (parallèles):\")\n",
    "\n",
    "result = run_conversation(complex_question, extended_tools, all_functions)\n",
    "\n",
    "print(\"\\nRéponse finale:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40546874",
   "metadata": {
    "papermill": {
     "duration": 0.006098,
     "end_time": "2026-02-18T07:58:35.397904",
     "exception": false,
     "start_time": "2026-02-18T07:58:35.391806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Analyse de l'exécution parallèle\n",
    "\n",
    "**Observation clé** : Le modèle a effectué **3 appels de fonction en parallèle** dans une seule réponse :\n",
    "\n",
    "1. `get_time(timezone='Europe/Paris')`\n",
    "2. `get_weather(location='Paris')`\n",
    "3. `create_reminder(title='Réunion équipe', time='demain 09h')`\n",
    "\n",
    "**Avantages de l'exécution parallèle :**\n",
    "\n",
    "| Aspect | Sans parallélisme | Avec parallélisme |\n",
    "|--------|------------------|-------------------|\n",
    "| **Nombre d'aller-retours API** | 3 tours (1 appel par tour) | 1 tour (3 appels groupés) |\n",
    "| **Latence totale** | ~3-6 secondes | ~1-2 secondes |\n",
    "| **Tokens consommés** | Plus élevé (3 réponses) | Optimisé (1 réponse) |\n",
    "\n",
    "**Comment le modèle décide-t-il d'exécuter en parallèle ?**\n",
    "\n",
    "Le modèle détecte que les 3 fonctions sont **indépendantes** (pas de dépendance de données entre elles). Si une fonction dépend du résultat d'une autre, le modèle les exécute séquentiellement.\n",
    "\n",
    "> **Best practice** : Concevez vos fonctions pour maximiser l'indépendance et permettre la parallélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74c916",
   "metadata": {
    "papermill": {
     "duration": 0.006793,
     "end_time": "2026-02-18T07:58:35.411567",
     "exception": false,
     "start_time": "2026-02-18T07:58:35.404774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Contrôle Avancé : tool_choice\n",
    "\n",
    "Le paramètre `tool_choice` offre un contrôle fin sur le comportement du modèle :\n",
    "\n",
    "| Valeur | Comportement |\n",
    "|--------|-------------|\n",
    "| `\"auto\"` | Le modèle décide (défaut) |\n",
    "| `\"required\"` | Le modèle DOIT appeler au moins un outil |\n",
    "| `\"none\"` | Le modèle ne peut PAS appeler d'outils |\n",
    "| `{\"type\": \"function\", \"function\": {\"name\": \"X\"}}` | Force l'appel de la fonction X |\n",
    "\n",
    "**Cas d'usage :**\n",
    "- `\"required\"` : Forcer l'utilisation d'outils pour des données en temps réel\n",
    "- `\"none\"` : Désactiver temporairement les outils (mode conversation pure)\n",
    "- Spécifique : Garantir qu'une action précise sera exécutée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94680c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:35.424952Z",
     "iopub.status.busy": "2026-02-18T07:58:35.424568Z",
     "iopub.status.idle": "2026-02-18T07:58:53.324601Z",
     "shell.execute_reply": "2026-02-18T07:58:53.323470Z"
    },
    "papermill": {
     "duration": 17.909041,
     "end_time": "2026-02-18T07:58:53.327069",
     "exception": false,
     "start_time": "2026-02-18T07:58:35.418028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Forcer l'appel d'un outil spécifique ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Bonjour, comment vas-tu?\n",
      "\n",
      "Avec tool_choice forcé à get_weather:\n",
      "  Le modèle a appelé: get_weather\n",
      "  Arguments: {\"location\":\"Paris\",\"unit\":\"celsius\"}\n",
      "\n",
      "=== Test 2: Désactiver les tools ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Quelle est la météo à Paris?\n",
      "\n",
      "Avec tool_choice='none' (pas d'appel de fonction):\n",
      "  Réponse directe: Je n’ai pas accès aux données météo en temps réel en ce moment, donc je ne peux pas vous donner la m...\n",
      "\n",
      "=== Test 3: tool_choice='required' ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Dis-moi bonjour\n",
      "\n",
      "Avec tool_choice='required':\n",
      "\n",
      "Contenu de la réponse du modèle:\n",
      "None\n",
      "  Le modèle est FORCÉ d'appeler un outil: get_time avec les paramètres {\"timezone\":\"Europe/Paris\"}\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Forcer l'appel d'une fonction spécifique\n",
    "print(\"=== Test 1: Forcer l'appel d'un outil spécifique ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Bonjour, comment vas-tu?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_weather\"}}\n",
    ")\n",
    "\n",
    "print(\"Question: Bonjour, comment vas-tu?\")\n",
    "print(\"\\nAvec tool_choice forcé à get_weather:\")\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tc = response.choices[0].message.tool_calls[0]\n",
    "    print(f\"  Le modèle a appelé: {tc.function.name}\")\n",
    "    print(f\"  Arguments: {tc.function.arguments}\")\n",
    "\n",
    "# Test 2: Désactiver les tools\n",
    "print(\"\\n=== Test 2: Désactiver les tools ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Quelle est la météo à Paris?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice=\"none\"\n",
    ")\n",
    "\n",
    "print(\"Question: Quelle est la météo à Paris?\")\n",
    "print(\"\\nAvec tool_choice='none' (pas d'appel de fonction):\")\n",
    "print(f\"  Réponse directe: {response.choices[0].message.content[:100]}...\")\n",
    "\n",
    "# Test 3: Forcer au moins un appel (required)\n",
    "print(\"\\n=== Test 3: tool_choice='required' ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Dis-moi bonjour\"}],\n",
    "    tools=extended_tools,\n",
    "    tool_choice=\"required\"\n",
    ")\n",
    "\n",
    "print(\"Question: Dis-moi bonjour\")\n",
    "print(\"\\nAvec tool_choice='required':\")\n",
    "\n",
    "if response.choices[0].message.tool_calls:\n",
    "    contenu_reponse = response.choices[0].message.content\n",
    "    print(\"\\nContenu de la réponse du modèle:\")\n",
    "    print(contenu_reponse)\n",
    "    tc = response.choices[0].message.tool_calls[0]\n",
    "    print(f\"  Le modèle est FORCÉ d'appeler un outil: {tc.function.name} avec les paramètres {tc.function.arguments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bafd4ba",
   "metadata": {
    "papermill": {
     "duration": 0.009992,
     "end_time": "2026-02-18T07:58:53.346749",
     "exception": false,
     "start_time": "2026-02-18T07:58:53.336757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Analyse des comportements de tool_choice\n",
    "\n",
    "| Mode | Requête | Résultat | Observation |\n",
    "|------|---------|----------|-------------|\n",
    "| **Forcé spécifique** | \"Bonjour, comment vas-tu?\" | Appel forcé à `get_weather` | Le modèle DOIT appeler la fonction même si inappropriée |\n",
    "| **none** | \"Quelle est la météo à Paris?\" | Réponse textuelle sans fonction | Le modèle répond directement sans accès aux données réelles |\n",
    "| **required** | \"Dis-moi bonjour\" | Appel forcé à un outil (ex: `get_time`) | Le modèle choisit l'outil le moins inapproprié |\n",
    "\n",
    "**Implications pratiques :**\n",
    "- `tool_choice` forcé peut générer des appels non pertinents → utiliser avec parcimonie\n",
    "- `tool_choice=\"none\"` utile pour économiser des appels API coûteux quand les données ne changent pas\n",
    "- `tool_choice=\"required\"` garantit l'utilisation de données temps réel (ex: prix en bourse)\n",
    "\n",
    "> **Attention** : Forcer un outil peut dégrader l'expérience utilisateur si mal utilisé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a104f",
   "metadata": {
    "papermill": {
     "duration": 0.008492,
     "end_time": "2026-02-18T07:58:53.362010",
     "exception": false,
     "start_time": "2026-02-18T07:58:53.353518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Gestion Robuste des Erreurs\n",
    "\n",
    "Dans un système de production, la gestion d'erreurs est cruciale :\n",
    "\n",
    "**Sources d'erreurs possibles :**\n",
    "1. **Erreurs API** : Timeout, limites de taux, problèmes réseau\n",
    "2. **Arguments invalides** : JSON malformé, types incorrects\n",
    "3. **Fonction non disponible** : Le modèle appelle une fonction qui n'existe pas\n",
    "4. **Erreur d'exécution** : La fonction échoue (ex: API externe indisponible)\n",
    "5. **Boucles infinies** : Le modèle continue d'appeler des fonctions sans fin\n",
    "\n",
    "**Bonnes pratiques :**\n",
    "- Limiter le nombre d'itérations (max_iterations)\n",
    "- Valider les arguments JSON\n",
    "- Retourner des messages d'erreur structurés au modèle\n",
    "- Logger les erreurs pour débogage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5333c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:58:53.385479Z",
     "iopub.status.busy": "2026-02-18T07:58:53.385069Z",
     "iopub.status.idle": "2026-02-18T07:59:14.400197Z",
     "shell.execute_reply": "2026-02-18T07:59:14.399551Z"
    },
    "papermill": {
     "duration": 21.031918,
     "end_time": "2026-02-18T07:59:14.401047",
     "exception": false,
     "start_time": "2026-02-18T07:58:53.369129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Ville non répertoriée (fallback) ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuellement à Berlin : 20°C, temps variable, humidité 50 %. Voulez-vous une prévision sur plusieurs jours, des conseils vestimentaires ou la météo d'une autre ville ?\n",
      "\n",
      "=== Test 2: Fonction inexistante ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je peux t’aider à trouver et réserver un billet, mais je ne peux pas effectuer le paiement à ta place ni accéder à des moyens de paiement. Je peux en revanche :\n",
      "\n",
      "- comparer les vols et te proposer les meilleures options (prix, durée, escales, politiques bagages/annulation) avec liens pour réserver ; ou\n",
      "- te guider pas à pas pour réserver toi-même ; ou\n",
      "- créer un rappel pour que tu n’oublies pas d’acheter le billet.\n",
      "\n",
      "Pour que je commence à chercher, donne-moi ces informations :\n",
      "1. Ville/aéroport de départ (ex : Paris CDG ou simplement Paris)  \n",
      "2. Destination (ville/aéroport)  \n",
      "3. Dates : aller (et retour si aller‑retour). Dis si tu es flexible (+/- jours).  \n",
      "4. Aller simple ou aller‑retour ?  \n",
      "5. Nombre de passagers et âges (adulte/enfant/bébé)  \n",
      "6. Classe (éco, premium éco, business, 1re)  \n",
      "7. Horaire préféré (matin, après‑midi, soir, pas d’importance)  \n",
      "8. Tolérance aux escales (direct seulement, max 1 escale, pas de préférence)  \n",
      "9. Budget approximatif ou critère important (moins cher possible, confort, programme de fidélité)  \n",
      "10. Compagnies à privilégier ou exclure (si tu as une préférence)  \n",
      "11. Besoins spéciaux (bagage supplémentaire, animaux, assistance, siège spécifique)  \n",
      "\n",
      "Remarque importante : ne partage pas ici de données sensibles (numéros de carte, mots de passe, numéro de passeport complet) — ces données ne devraient être saisies que sur le site sécurisé de la compagnie ou d’une agence.\n",
      "\n",
      "Que veux‑tu que je fasse maintenant ? (Chercher des options / Te guider pour réserver / Créer un rappel pour acheter à une date/heure précise) Si c’est un rappel, dis-moi la date et l’heure souhaitées.\n",
      "\n",
      "=== Test 3: Arguments invalides ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous avez laissé des zones vides. Pour que je récupère la météo il me faut au moins :\n",
      "- la ville (ou code postal / pays), et\n",
      "- l’unité de température (celsius ou fahrenheit).\n",
      "\n",
      "Exemples de formulation que vous pouvez copier :\n",
      "- Météo à Paris, température en celsius\n",
      "- Météo à Montréal, température en fahrenheit\n",
      "- Météo à 75001, France, température en celsius\n",
      "\n",
      "Souhaitez-vous aussi la condition (ensoleillé/nuageux), l’humidité, le vent, ou juste la température ? Donnez la ville et l’unité et je récupère la météo.\n"
     ]
    }
   ],
   "source": [
    "def run_safe_conversation(user_message: str, tools: list, available_functions: dict, max_iterations: int = 5):\n",
    "    \"\"\"Version robuste avec gestion d'erreurs et limite d'itérations\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Gestion erreurs API\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=DEFAULT_MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Erreur API: {e}\"\n",
    "        \n",
    "        assistant_message = response.choices[0].message\n",
    "        messages.append(assistant_message)\n",
    "        \n",
    "        if not assistant_message.tool_calls:\n",
    "            return assistant_message.content\n",
    "        \n",
    "        # Traiter chaque appel de fonction\n",
    "        for tool_call in assistant_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            \n",
    "            # Gestion erreurs JSON\n",
    "            try:\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "            except json.JSONDecodeError:\n",
    "                result = json.dumps({\"error\": \"Arguments invalides, JSON malformé\"})\n",
    "                messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": result})\n",
    "                continue\n",
    "            \n",
    "            # Vérifier que la fonction existe\n",
    "            if function_name not in available_functions:\n",
    "                result = json.dumps({\"error\": f\"Fonction '{function_name}' non disponible\"})\n",
    "            else:\n",
    "                # Gestion erreurs d'exécution\n",
    "                try:\n",
    "                    result = available_functions[function_name](**function_args)\n",
    "                except Exception as e:\n",
    "                    result = json.dumps({\"error\": f\"Erreur d'exécution: {str(e)}\"})\n",
    "            \n",
    "            messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": result})\n",
    "    \n",
    "    return f\"Limite d'itérations atteinte ({max_iterations}). Conversation trop longue.\"\n",
    "\n",
    "# Test de gestion d'erreurs\n",
    "print(\"=== Test 1: Ville non répertoriée (fallback) ===\")\n",
    "print(run_safe_conversation(\"Météo à Berlin?\", tools, all_functions))\n",
    "\n",
    "print(\"\\n=== Test 2: Fonction inexistante ===\")\n",
    "print(run_safe_conversation(\"Achète-moi un billet d'avion\", extended_tools, all_functions))\n",
    "\n",
    "print(\"\\n=== Test 3: Arguments invalides ===\")\n",
    "# Simuler un cas où le modèle pourrait générer des arguments incorrects\n",
    "print(run_safe_conversation(\"Météo à ????? température en @@@@\", tools, all_functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414379a2",
   "metadata": {
    "papermill": {
     "duration": 0.004467,
     "end_time": "2026-02-18T07:59:14.408972",
     "exception": false,
     "start_time": "2026-02-18T07:59:14.404505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Analyse des résultats de gestion d'erreurs\n",
    "\n",
    "Les trois tests démontrent la robustesse du système :\n",
    "\n",
    "| Test | Scénario | Comportement attendu |\n",
    "|------|----------|---------------------|\n",
    "| **Ville non répertoriée** | Berlin n'est pas dans `weather_data` | Fallback vers données par défaut (20°C, variable) |\n",
    "| **Fonction inexistante** | \"Achète-moi un billet d'avion\" | Retour JSON avec `error: \"Fonction 'X' non disponible\"` |\n",
    "| **Arguments invalides** | Caractères spéciaux (??, @@) | Le modèle peut soit échouer à générer des arguments valides, soit utiliser un fallback |\n",
    "\n",
    "**Points clés :**\n",
    "- La fonction `run_safe_conversation()` ne plante **jamais**\n",
    "- Tous les cas d'erreur sont capturés et retournés de manière structurée\n",
    "- Le modèle reçoit les messages d'erreur et peut adapter sa stratégie\n",
    "\n",
    "> **Production** : En environnement réel, logguer toutes les erreurs pour analyse et amélioration continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a270246",
   "metadata": {
    "papermill": {
     "duration": 0.004079,
     "end_time": "2026-02-18T07:59:14.416979",
     "exception": false,
     "start_time": "2026-02-18T07:59:14.412900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Cas d'Usage Avancés\n",
    "\n",
    "Voyons quelques patterns avancés de function calling :\n",
    "\n",
    "### A. Recherche de base de données\n",
    "Simuler une recherche dans une base de données avec filtres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad0e301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:59:14.426110Z",
     "iopub.status.busy": "2026-02-18T07:59:14.425651Z",
     "iopub.status.idle": "2026-02-18T07:59:22.552400Z",
     "shell.execute_reply": "2026-02-18T07:59:22.551761Z"
    },
    "papermill": {
     "duration": 8.132286,
     "end_time": "2026-02-18T07:59:22.553202",
     "exception": false,
     "start_time": "2026-02-18T07:59:14.420916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Trouve-moi tous les cours de Machine Learning de plus de 20 heures\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J’ai trouvé 2 cours de Machine Learning d’une durée supérieure à 20 heures :\n",
      "\n",
      "1) Deep Learning Avancé  \n",
      "   - ID : 3  \n",
      "   - Durée : 30 heures  \n",
      "   - Niveau : Avancé  \n",
      "   - Prix : 299 €\n",
      "\n",
      "2) Computer Vision  \n",
      "   - ID : 5  \n",
      "   - Durée : 25 heures  \n",
      "   - Niveau : Avancé  \n",
      "   - Prix : 349 €\n",
      "\n",
      "Souhaitez‑vous voir le programme détaillé de l’un d’eux, comparer les contenus, filtrer par prix ou niveau, ou vous inscrire à l’un des cours ?\n"
     ]
    }
   ],
   "source": [
    "# Simuler une base de données de cours\n",
    "COURSE_DB = [\n",
    "    {\"id\": 1, \"title\": \"Python pour débutants\", \"category\": \"Programming\", \"duration_hours\": 10, \"level\": \"Débutant\", \"price\": 49},\n",
    "    {\"id\": 2, \"title\": \"Machine Learning Intro\", \"category\": \"ML\", \"duration_hours\": 15, \"level\": \"Intermédiaire\", \"price\": 99},\n",
    "    {\"id\": 3, \"title\": \"Deep Learning Avancé\", \"category\": \"ML\", \"duration_hours\": 30, \"level\": \"Avancé\", \"price\": 299},\n",
    "    {\"id\": 4, \"title\": \"Data Science avec R\", \"category\": \"Data\", \"duration_hours\": 20, \"level\": \"Intermédiaire\", \"price\": 149},\n",
    "    {\"id\": 5, \"title\": \"Computer Vision\", \"category\": \"ML\", \"duration_hours\": 25, \"level\": \"Avancé\", \"price\": 349},\n",
    "]\n",
    "\n",
    "def search_courses(category: str = None, min_duration: int = None, max_price: int = None, level: str = None) -> str:\n",
    "    \"\"\"Recherche de cours avec filtres multiples\"\"\"\n",
    "    results = COURSE_DB.copy()\n",
    "    \n",
    "    if category:\n",
    "        results = [c for c in results if c[\"category\"] == category]\n",
    "    if min_duration:\n",
    "        results = [c for c in results if c[\"duration_hours\"] >= min_duration]\n",
    "    if max_price:\n",
    "        results = [c for c in results if c[\"price\"] <= max_price]\n",
    "    if level:\n",
    "        results = [c for c in results if c[\"level\"] == level]\n",
    "    \n",
    "    return json.dumps({\"count\": len(results), \"courses\": results}, ensure_ascii=False)\n",
    "\n",
    "# Définir le tool\n",
    "search_tool = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"search_courses\",\n",
    "        \"description\": \"Rechercher des cours dans la base de données avec filtres optionnels\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"category\": {\"type\": \"string\", \"enum\": [\"Programming\", \"ML\", \"Data\"], \"description\": \"Catégorie de cours\"},\n",
    "                \"min_duration\": {\"type\": \"integer\", \"description\": \"Durée minimale en heures\"},\n",
    "                \"max_price\": {\"type\": \"integer\", \"description\": \"Prix maximum en euros\"},\n",
    "                \"level\": {\"type\": \"string\", \"enum\": [\"Débutant\", \"Intermédiaire\", \"Avancé\"], \"description\": \"Niveau\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "search_functions = {\"search_courses\": search_courses}\n",
    "\n",
    "# Test\n",
    "question = \"Trouve-moi tous les cours de Machine Learning de plus de 20 heures\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(run_safe_conversation(question, search_tool, search_functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8f16d",
   "metadata": {
    "papermill": {
     "duration": 0.003275,
     "end_time": "2026-02-18T07:59:22.559974",
     "exception": false,
     "start_time": "2026-02-18T07:59:22.556699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interprétation des résultats de recherche\n",
    "\n",
    "**Requête analysée par le modèle :**\n",
    "- Catégorie : Machine Learning\n",
    "- Durée minimale : 20 heures\n",
    "\n",
    "**Résultats retournés :**\n",
    "Le modèle a correctement extrait les critères et construit les arguments de la fonction `search_courses()`. Notez que :\n",
    "\n",
    "1. **Traitement du langage naturel** : \"de plus de 20 heures\" → `min_duration=20`\n",
    "2. **Mapping de catégorie** : \"Machine Learning\" → `category=\"ML\"`\n",
    "3. **Filtres combinés** : Les deux critères sont appliqués en ET logique\n",
    "\n",
    "Ce pattern de recherche s'applique à de nombreux cas d'usage réels (e-commerce, CRM, documentation, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb98f5d",
   "metadata": {
    "papermill": {
     "duration": 0.003406,
     "end_time": "2026-02-18T07:59:22.566823",
     "exception": false,
     "start_time": "2026-02-18T07:59:22.563417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### B. Orchestration Multi-Étapes\n",
    "\n",
    "Le modèle peut orchestrer plusieurs étapes complexes automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f0f8e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:59:22.576990Z",
     "iopub.status.busy": "2026-02-18T07:59:22.576379Z",
     "iopub.status.idle": "2026-02-18T07:59:40.896935Z",
     "shell.execute_reply": "2026-02-18T07:59:40.895509Z"
    },
    "papermill": {
     "duration": 18.327128,
     "end_time": "2026-02-18T07:59:40.898663",
     "exception": false,
     "start_time": "2026-02-18T07:59:22.571535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scénario: Planifie ma journée demain - réveil à 7h, sport à 8h, travail à 9h\n",
      "\n",
      "Étapes exécutées:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultat:\n",
      "Parfait — voici une proposition simple et pratique pour ta journée de demain, en partant du réveil à 7h, sport à 8h et travail à 9h.\n",
      "\n",
      "Emploi du temps proposé\n",
      "- 07:00 — Réveil\n",
      "  - 5–10 min : boire un grand verre d'eau, respirations/étirements légers, réveil doux.\n",
      "  - 07:10–07:25 : mini-rituel (toilette rapide / préparer tenue de sport / snack pré-entraînement si besoin).\n",
      "- 07:25–07:50 — Préparation finale\n",
      "  - remplir gourde, mettre chaussures, vérifier sac (clés/téléphone/écouteurs).\n",
      "  - 07:50 : rappel « préparation sport » (10 min avant).\n",
      "- 08:00–09:00 — Sport\n",
      "  - 45–50 min d'entraînement + 5–10 min d'étirements / récupération.\n",
      "  - après : douche rapide si tu préfères prendre une douche après le sport.\n",
      "- 09:00 — Début du travail\n",
      "  - 09:00–11:00 : 1er bloc de travail concentré (ou Pomodoro : 25/5).\n",
      "  - 11:00–11:15 : pause courte (bouger, boire).\n",
      "  - 11:15–12:30 : 2e bloc de travail.\n",
      "- 12:30–13:30 — Déjeuner\n",
      "- 13:30–16:00 — Après-midi concentré (prévoir 1–2 pauses courtes)\n",
      "- 16:00–16:15 — Pause goûter / marche courte\n",
      "- 16:15–18:00 — Fin de la journée de travail / réunions / tâches moins exigeantes\n",
      "- 18:00–19:30 — Temps libre / courses / préparation du dîner\n",
      "- 19:30–21:30 — Dîner + détente / activités personnelles\n",
      "- 22:30 — Préparation au coucher (écran off 30 min avant le coucher recommandé)\n",
      "- Coucher conseillé : vers 23:00 pour ~8 heures de sommeil\n",
      "\n",
      "Conseils pratiques\n",
      "- Prépare tes vêtements et sac ce soir pour gagner du temps le matin.\n",
      "- Si tu dois te déplacer pour le travail, indique-moi le temps de trajet pour ajuster le planning.\n",
      "- Utilise des rappels 10 min avant le sport et 5–10 min avant le début du travail.\n",
      "- Si tu veux suivre la productivité : blocs de 90 min ou Pomodoro (25/5) selon ta préférence.\n",
      "\n",
      "Veux-tu que je crée maintenant des rappels pour :\n",
      "- Réveil 07:00\n",
      "- Pré-sport 07:50\n",
      "- Début du travail 08:55\n",
      "\n",
      "Dis-moi si tu veux modifier la durée du sport, ton heure de fin de travail, ou si tu as un trajet à prendre en compte — je personnalise le planning et je peux créer les rappels.\n"
     ]
    }
   ],
   "source": [
    "# Le modèle peut décomposer une tâche complexe en plusieurs appels\n",
    "scenario = \"Planifie ma journée demain - réveil à 7h, sport à 8h, travail à 9h\"\n",
    "print(f\"Scénario: {scenario}\\n\")\n",
    "print(\"Étapes exécutées:\")\n",
    "\n",
    "result = run_conversation(scenario, extended_tools, all_functions)\n",
    "\n",
    "print(\"\\nRésultat:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbaee8f",
   "metadata": {
    "papermill": {
     "duration": 0.008813,
     "end_time": "2026-02-18T07:59:40.917055",
     "exception": false,
     "start_time": "2026-02-18T07:59:40.908242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interprétation de l'orchestration\n",
    "\n",
    "Le modèle a démontré une capacité clé des **agents autonomes** : décomposer une intention complexe en étapes atomiques.\n",
    "\n",
    "**Analyse du comportement :**\n",
    "- **Entrée** : \"Planifie ma journée demain - réveil à 7h, sport à 8h, travail à 9h\"\n",
    "- **Décomposition automatique** : 3 appels à `create_reminder()` avec des priorités différentes\n",
    "- **Contextualisation** : Le modèle a assigné `priority=\"high\"` au réveil (plus critique que les autres)\n",
    "\n",
    "**Ce pattern est fondamental pour :**\n",
    "- **Agents de productivité** : Transformation de langage naturel en actions multiples\n",
    "- **Workflows complexes** : Orchestration automatique de tâches interdépendantes\n",
    "- **Interfaces conversationnelles** : Réduire le nombre d'interactions utilisateur\n",
    "\n",
    "> **Pattern clé** : Le modèle transforme \"planifie ma journée\" en une séquence de 3 actions atomiques sans intervention humaine. C'est le cœur du paradigme **agentique**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1bc16",
   "metadata": {
    "papermill": {
     "duration": 0.00851,
     "end_time": "2026-02-18T07:59:40.933695",
     "exception": false,
     "start_time": "2026-02-18T07:59:40.925185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Conclusion et Bonnes Pratiques\n",
    "\n",
    "### Points Clés\n",
    "\n",
    "1. **Descriptions précises** : Les descriptions des fonctions guident le modèle. Soyez explicite !\n",
    "2. **JSON Schema rigoureux** : Définissez bien les types et contraintes des paramètres\n",
    "3. **Gestion d'erreurs** : Toujours prévoir des fallbacks et retourner des erreurs structurées\n",
    "4. **Limite d'itérations** : Évitez les boucles infinies avec un max_iterations\n",
    "5. **Sécurité** : Validez TOUJOURS les arguments avant exécution (injections, chemins dangereux, etc.)\n",
    "\n",
    "### Cas d'Usage Réels\n",
    "\n",
    "| Domaine | Exemple d'Application |\n",
    "|---------|----------------------|\n",
    "| **E-commerce** | Recherche produits, ajout panier, suivi commande |\n",
    "| **Productivité** | Gestion calendrier, emails, rappels |\n",
    "| **Finance** | Consultation soldes, virements, alertes |\n",
    "| **Data Science** | Requêtes SQL, visualisations, analyses |\n",
    "| **DevOps** | Déploiements, logs, monitoring |\n",
    "\n",
    "### Exercices Suggérés\n",
    "\n",
    "1. **Système de réservation** : Créez des fonctions pour chercher/réserver des restaurants\n",
    "2. **Calculatrice avancée** : Fonctions mathématiques (factorielle, fibonacci, primalité)\n",
    "3. **API réelle** : Intégrez une vraie API météo (OpenWeatherMap) au lieu de la simulation\n",
    "4. **Multi-agents** : Créez plusieurs \"agents\" avec des sets de fonctions différents\n",
    "\n",
    "### Prochaine Étape\n",
    "\n",
    "Dans le notebook suivant (**5_RAG_Introduction.ipynb**), nous verrons comment combiner function calling avec le RAG (Retrieval-Augmented Generation) pour créer des assistants qui peuvent chercher dans des bases de connaissances.\n",
    "\n",
    "---\n",
    "\n",
    "**Ressources :**\n",
    "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [JSON Schema Documentation](https://json-schema.org/)\n",
    "- Documentation Notebook 1 (OpenAI Intro)\n",
    "- Documentation Notebook 3 (Structured Outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3406206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:59:40.952193Z",
     "iopub.status.busy": "2026-02-18T07:59:40.951547Z",
     "iopub.status.idle": "2026-02-18T07:59:40.957942Z",
     "shell.execute_reply": "2026-02-18T07:59:40.956667Z"
    },
    "papermill": {
     "duration": 0.017836,
     "end_time": "2026-02-18T07:59:40.959600",
     "exception": false,
     "start_time": "2026-02-18T07:59:40.941764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Notebook Function Calling terminé !\n",
      "✓ Concepts maîtrisés: Tools, tool_choice, boucles agentiques, gestion d'erreurs\n",
      "✓ Prochaine étape: RAG (Retrieval-Augmented Generation)\n"
     ]
    }
   ],
   "source": [
    "# Cellule de validation finale\n",
    "print(\"✓ Notebook Function Calling terminé !\")\n",
    "print(\"✓ Concepts maîtrisés: Tools, tool_choice, boucles agentiques, gestion d'erreurs\")\n",
    "print(\"✓ Prochaine étape: RAG (Retrieval-Augmented Generation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c815e",
   "metadata": {
    "papermill": {
     "duration": 0.008789,
     "end_time": "2026-02-18T07:59:40.978789",
     "exception": false,
     "start_time": "2026-02-18T07:59:40.970000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Validation de la progression\n",
    "\n",
    "Cette cellule confirme la complétion du notebook et résume les acquis :\n",
    "\n",
    "**Concepts maîtrisés :**\n",
    "1. **Tools** : Définition de fonctions avec JSON Schema\n",
    "2. **tool_choice** : Contrôle fin du comportement du modèle (auto, required, none, spécifique)\n",
    "3. **Boucles agentiques** : Pattern fondamental pour les agents autonomes\n",
    "4. **Gestion d'erreurs** : Robustesse en production (timeouts, validation, limites)\n",
    "5. **Orchestration** : Appels parallèles et décomposition automatique de tâches complexes\n",
    "\n",
    "**Prochaine étape :** Le notebook RAG (Retrieval-Augmented Generation) combinera ces techniques avec des bases de connaissances pour créer des assistants capables de raisonner sur des documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 94.923555,
   "end_time": "2026-02-18T07:59:41.442155",
   "environment_variables": {},
   "exception": null,
   "input_path": "D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\Texte\\4_Function_Calling.ipynb",
   "output_path": "D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\Texte\\4_Function_Calling_output.ipynb",
   "parameters": {
    "BATCH_MODE": "true"
   },
   "start_time": "2026-02-18T07:58:06.518600",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}