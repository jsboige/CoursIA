{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles de Raisonnement : o4-mini et GPT-5-thinking\n",
    "\n",
    "Les modèles de raisonnement représentent une évolution majeure des LLMs. Contrairement aux modèles de chat classiques, ils prennent le temps de \"réfléchir\" avant de répondre, ce qui améliore significativement leurs performances sur les tâches complexes.\n",
    "\n",
    "**Objectifs :**\n",
    "- Comprendre les différences architecturales (thinking time)\n",
    "- Maîtriser `reasoning_effort` (low, medium, high)\n",
    "- Choisir le bon modèle selon la tâche\n",
    "- Analyser les performances et coûts\n",
    "\n",
    "**Prérequis :** Notebook 2 (Prompt Engineering)\n",
    "\n",
    "**Durée estimée :** 60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%pip install openai python-dotenv --quiet\n\nimport os\nimport time\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv('../.env')\nclient = OpenAI()\n\n# Modèle par défaut depuis .env\nDEFAULT_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\nBATCH_MODE = os.getenv(\"BATCH_MODE\", \"false\").lower() == \"true\"\n\nprint(f\"Client OpenAI initialisé !\")\nprint(f\"Modèle par défaut: {DEFAULT_MODEL}\")\nprint(f\"Mode: {'BATCH' if BATCH_MODE else 'INTERACTIF'}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 0. Configuration de l'environnement\n\n### Imports nécessaires\n\nCe notebook utilise :\n- **openai** : Bibliothèque officielle OpenAI pour interagir avec l'API\n- **python-dotenv** : Chargement des variables d'environnement (clés API)\n- **time** : Mesure des temps de réponse pour comparaison\n\n### Structure du notebook\n\nNous allons explorer progressivement :\n1. Comparaison chat vs reasoning models\n2. Paramètre `reasoning_effort` (low/medium/high)\n3. Messages `developer` et formatage\n4. Génération de code complexe\n5. Modèles avancés et benchmarks\n6. Analyse coût/performance\n\n**Mode batch** : Si `BATCH_MODE=true` dans `.env`, le notebook s'exécute sans interaction utilisateur (utile pour tests automatisés).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chat Models vs Reasoning Models\n",
    "\n",
    "### Différences fondamentales\n",
    "\n",
    "| Aspect | Chat Models | Reasoning Models |\n",
    "|--------|-------------|------------------|\n",
    "| **Réponse** | Immédiate | Temps de réflexion |\n",
    "| **Optimisation** | Dialogue fluide | Problèmes complexes |\n",
    "| **Exemples** | gpt-4o, gpt-4o-mini | o4-mini, gpt-5-thinking |\n",
    "| **Vitesse** | Rapide (1-3s) | Variable (5-30s+) |\n",
    "| **Précision** | Bonne | Excellente sur tâches complexes |\n",
    "\n",
    "### Quand utiliser quoi ?\n",
    "\n",
    "**Chat Models :**\n",
    "- Conversations naturelles\n",
    "- Questions factuelles simples\n",
    "- Génération de contenu créatif\n",
    "- Traduction, résumé\n",
    "\n",
    "**Reasoning Models :**\n",
    "- Mathématiques et logique\n",
    "- Programmation complexe\n",
    "- Analyse multi-étapes\n",
    "- Problèmes d'optimisation\n",
    "- Déduction et inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Comparaison Chat vs Reasoning ===\n",
      "\n",
      "gpt-4o-mini (0.78s):\n",
      "  Réponse: Alice a maintenant 7 pommes.\n",
      "\n",
      "o4-mini (4.67s):\n",
      "  Réponse: 7\n",
      "\n",
      "[Réponse correcte: 5.5 pommes (Alice donne 2.5, récupère 1.5, achète 3 → 5 + 1.5 + 3 - 2.5 = 7)]\n",
      "\n",
      "Note: Le chat model peut faire une erreur de calcul, le reasoning model analyse pas à pas.\n"
     ]
    }
   ],
   "source": [
    "probleme_math = \"\"\"\n",
    "Alice a 5 pommes. Elle en donne la moitié à Bob.\n",
    "Bob mange 1 pomme puis rend le reste à Alice.\n",
    "Alice achète ensuite 3 pommes de plus.\n",
    "Combien de pommes Alice a-t-elle maintenant?\n",
    "Donne uniquement le nombre final.\n",
    "\"\"\"\n",
    "\n",
    "# Test avec gpt-4o-mini (chat model)\n",
    "start = time.time()\n",
    "response_chat = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": probleme_math}],\n",
    "    max_tokens=100\n",
    ")\n",
    "time_chat = time.time() - start\n",
    "\n",
    "# Test avec o4-mini (reasoning model)\n",
    "start = time.time()\n",
    "response_reasoning = client.chat.completions.create(\n",
    "    model=\"o4-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"Formatting re-enabled\"},\n",
    "        {\"role\": \"user\", \"content\": probleme_math}\n",
    "    ],\n",
    "    reasoning_effort=\"medium\"\n",
    ")\n",
    "time_reasoning = time.time() - start\n",
    "\n",
    "print(\"=== Comparaison Chat vs Reasoning ===\")\n",
    "print(f\"\\ngpt-4o-mini ({time_chat:.2f}s):\")\n",
    "print(f\"  Réponse: {response_chat.choices[0].message.content.strip()}\")\n",
    "print(f\"\\no4-mini ({time_reasoning:.2f}s):\")\n",
    "print(f\"  Réponse: {response_reasoning.choices[0].message.content.strip()}\")\n",
    "print(f\"\\n[Réponse correcte: 5.5 pommes (Alice donne 2.5, récupère 1.5, achète 3 → 5 + 1.5 + 3 - 2.5 = 7)]\")\n",
    "print(f\"\\nNote: Le chat model peut faire une erreur de calcul, le reasoning model analyse pas à pas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Interprétation des résultats\n\nDans cet exemple, les deux modèles ont donné la bonne réponse (7 pommes), mais observez :\n\n**Temps de réponse** :\n- gpt-4o-mini : ~0.78s (réponse immédiate)\n- o4-mini : ~4.67s (temps de réflexion inclus)\n\n**Précision** :\n- Sur ce problème simple, les deux modèles réussissent\n- La différence devient significative sur des problèmes plus complexes nécessitant plusieurs étapes de raisonnement\n\n**Quand la différence compte** :\n- Problèmes avec plusieurs contraintes simultanées\n- Calculs nécessitant de garder plusieurs valeurs en mémoire\n- Raisonnement nécessitant de tester plusieurs hypothèses\n\n**Trade-off** : Le modèle de raisonnement prend ~6x plus de temps mais offre une meilleure garantie de précision sur les problèmes complexes. À vous de choisir selon vos besoins !",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Analyse des résultats par niveau\n\n**Observations importantes** :\n\n1. **Tous les niveaux donnent la bonne réponse** sur ce problème simple\n   - low (~2.76s) : Raisonnement rapide, réponse correcte\n   - medium (~4.43s) : Équilibre réflexion/temps\n   - high (~5.95s) : Analyse approfondie (mais pas nécessaire ici)\n\n2. **Différence de temps** :\n   - low → medium : +60% temps\n   - medium → high : +34% temps\n   - Le surcoût augmente de façon non-linéaire\n\n3. **Formulation similaire** :\n   - Les 3 niveaux produisent des explications presque identiques\n   - Sur un problème simple, la différence est minime\n\n**Quand utiliser chaque niveau ?**\n\n| Niveau | Durée typique | Cas d'usage |\n|--------|--------------|-------------|\n| **low** | 2-10s | Logique simple, calculs directs, questions factuelles avec raisonnement minimal |\n| **medium** | 5-20s | **Choix par défaut** - équilibre optimal pour la plupart des tâches |\n| **high** | 10-60s+ | Problèmes très complexes, optimisation multi-contraintes, preuves formelles |\n\n**Recommandation** : Commencez toujours par `low` ou `medium`. N'utilisez `high` que si les résultats sont insuffisants.\n\n**Impact sur les coûts** : Chaque niveau génère plus de tokens de réflexion cachés (facturés). Sur 1000 requêtes, la différence entre low et high peut représenter des centaines d'euros !",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Paramètre `reasoning_effort`\n",
    "\n",
    "Les modèles de raisonnement exposent un paramètre crucial : **`reasoning_effort`**.\n",
    "\n",
    "### Niveaux disponibles\n",
    "\n",
    "| Niveau | Temps de réflexion | Qualité | Usage typique |\n",
    "|--------|-------------------|---------|---------------|\n",
    "| **low** | Minimal (5-10s) | Bonne | Problèmes simples nécessitant un peu de réflexion |\n",
    "| **medium** | Équilibré (10-20s) | Très bonne | Cas d'usage général |\n",
    "| **high** | Approfondi (20-60s+) | Excellente | Problèmes très complexes |\n",
    "\n",
    "### Règles empiriques\n",
    "\n",
    "- **low** : Questions de logique simple, calculs directs\n",
    "- **medium** : Programmation standard, analyses multi-étapes\n",
    "- **high** : Optimisation mathématique, preuve formelle, debugging complexe\n",
    "\n",
    "**Note importante :** Plus de réflexion = plus de coût en tokens. Choisissez judicieusement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Impact du reasoning_effort ===\n",
      "\n",
      "reasoning_effort='low' (2.76s):\n",
      "  Tu te retrouves à la 2ᵉ place, car en dépassant le coureur classé 2ᵉ tu prends sa position.\n",
      "\n",
      "reasoning_effort='medium' (4.43s):\n",
      "  Ta position finale est 2ᵉ : en dépassant celui qui était deuxième, tu prends sa place.\n",
      "\n",
      "reasoning_effort='high' (5.95s):\n",
      "  Tu termines 2e : en dépassant le 2e coureur, tu prends sa place.\n",
      "\n",
      "[Réponse correcte: 2ème position - tu prends la place de celui que tu dépasses]\n",
      "\n",
      "Observation: Les 3 niveaux devraient donner la bonne réponse, mais 'high' peut fournir\n",
      "une explication plus détaillée. La différence est surtout visible sur des problèmes complexes.\n"
     ]
    }
   ],
   "source": [
    "probleme_logique = \"\"\"\n",
    "Dans une course, tu dépasses le 2ème. \n",
    "Quelle est ta position finale?\n",
    "Explique ton raisonnement en une phrase.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Impact du reasoning_effort ===\\n\")\n",
    "\n",
    "for effort in [\"low\", \"medium\", \"high\"]:\n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o4-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"developer\", \"content\": \"Formatting re-enabled\"},\n",
    "            {\"role\": \"user\", \"content\": probleme_logique}\n",
    "        ],\n",
    "        reasoning_effort=effort\n",
    "    )\n",
    "    duration = time.time() - start\n",
    "    \n",
    "    print(f\"reasoning_effort='{effort}' ({duration:.2f}s):\")\n",
    "    print(f\"  {response.choices[0].message.content.strip()}\")\n",
    "    print()\n",
    "\n",
    "print(\"[Réponse correcte: 2ème position - tu prends la place de celui que tu dépasses]\")\n",
    "print(\"\\nObservation: Les 3 niveaux devraient donner la bonne réponse, mais 'high' peut fournir\")\n",
    "print(\"une explication plus détaillée. La différence est surtout visible sur des problèmes complexes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Analyse de la qualité du code généré\n\nLe modèle o4-mini avec `reasoning_effort='high'` a produit une solution de **très haute qualité** :\n\n**Points forts de l'implémentation** :\n\n1. **Algorithme optimal** : Expansion autour du centre (O(n²))\n   - Considère les palindromes de longueur impaire (centre sur un caractère)\n   - Considère les palindromes de longueur paire (centre entre deux caractères)\n   - Complexité théorique minimale pour approche directe\n\n2. **Code propre et lisible** :\n   - Fonction helper `expand_around_center` avec logique claire\n   - Variables bien nommées (`start`, `max_len`, `curr_len`)\n   - Commentaires pertinents\n\n3. **Tests exhaustifs** :\n   - Chaîne vide\n   - Un seul caractère\n   - Palindrome complet\n   - Pas de palindrome (> 1)\n   - Cas ambigus (\"babad\" → \"bab\" ou \"aba\")\n\n4. **Robustesse** :\n   - Gestion des cas limites (n < 2)\n   - Validation avec assertions\n   - Message de succès clair\n\n**Comparaison avec un chat model** :\n\nUn modèle comme gpt-4o-mini aurait probablement :\n- Fourni une implémentation correcte mais moins optimisée\n- Tests moins complets\n- Moins d'explications sur la complexité\n\n**Temps de génération** : 17.29s est un excellent compromis pour obtenir du code de cette qualité. En développement professionnel, cela représente un gain de temps considérable.\n\n**Alternative possible** : L'algorithme de Manacher (O(n)) existe mais est beaucoup plus complexe. Pour la plupart des usages, O(n²) est suffisant et plus maintenable.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Messages `developer` et contrôle du formatage\n",
    "\n",
    "### Rôle `developer`\n",
    "\n",
    "Les modèles de raisonnement (o4-mini, gpt-5-thinking) utilisent un rôle spécial : **`developer`**.\n",
    "\n",
    "- Remplace le rôle `system` des chat models\n",
    "- Définit des instructions méta (comportement, formatage)\n",
    "- Moins strict que `system`, plus flexible\n",
    "\n",
    "### \"Formatting re-enabled\"\n",
    "\n",
    "Par défaut, les modèles raisonnants retournent du texte brut. Pour activer le **markdown** (formules LaTeX, code, listes), ajoutez :\n",
    "\n",
    "```python\n",
    "{\"role\": \"developer\", \"content\": \"Formatting re-enabled\"}\n",
    "```\n",
    "\n",
    "Ceci permet :\n",
    "- Formules mathématiques : `$E = mc^2$`\n",
    "- Blocs de code avec syntax highlighting\n",
    "- Tableaux, listes, titres markdown\n",
    "\n",
    "**Sans ce message**, vous obtenez du texte brut (pas de formatage riche)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Analyse du problème d'optimisation\n\nLe modèle a fourni une **solution complète et rigoureuse** :\n\n**Étapes mathématiques couvertes** :\n\n1. **Variables** : x (largeur), longueur = 100 - 2x\n2. **Contrainte** : Clôture totale = 100m (un côté est le mur)\n3. **Fonction objectif** : S(x) = x(100 - 2x)\n4. **Optimisation** : Dérivée S'(x) = 100 - 4x = 0 → x = 25m\n5. **Vérification** : Dérivée seconde négative (maximum confirmé)\n\n**Ce que le raisonnement apporte** :\n\n- **Structure claire** : Chaque étape est explicite et justifiée\n- **Notation mathématique** : Formules LaTeX bien formatées\n- **Validation** : Vérifie que c'est bien un maximum (pas un minimum)\n- **Résultat concret** : Dimensions finales et surface maximale\n\n**Comparaison avec un chat model** :\n\nUn modèle standard aurait probablement :\n- Donné le bon résultat final\n- Mais sauté certaines étapes de vérification\n- Moins de rigueur dans la démonstration\n\n**Fallback intelligent** : Le code tente plusieurs modèles (gpt-5-thinking → o4-mini → o3-mini → o1-preview) et utilise gpt-4o en dernier recours. Cela garantit que le notebook fonctionne même si certains modèles ne sont pas disponibles.\n\n**Cas d'usage similaires** :\n- Optimisation de budget/ressources\n- Problèmes de géométrie (surface, volume)\n- Calcul de marges maximales en finance\n- Conception de systèmes avec contraintes multiples",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sans 'Formatting re-enabled' ===\n",
      "Énoncé du théorème  \n",
      "Dans un triangle rectangle, le carré de la longueur de l’hypoténuse (le côté opposé à l’angle droit) est égal à la somme des carrés des longueurs des deux autres côtés.\n",
      "\n",
      "Soit un triangle ABC rectangle en C, avec :  \n",
      "- AB = c (hypoténuse)  \n",
      "- BC = a  \n",
      "- AC = b  \n",
      "\n",
      "Alors le théorème de Pythagore s’écrit :  \n",
      "(1) c² = a² + b²  \n",
      "\n",
      "Démonstrations succinctes  \n",
      "\n",
      "1. Preuve par découpage \n",
      "\n",
      "...\n",
      "\n",
      "\n",
      "=== Avec 'Formatting re-enabled' ===\n",
      "Le théorème de Pythagore, valable dans un triangle rectangle, énonce que :\n",
      "\n",
      "Soit un triangle ABC rectangle en A (l’angle en A vaut 90°). On note :\n",
      "- BC = c (l’hypoténuse, côté opposé à l’angle droit)  \n",
      "- AB = b  \n",
      "- AC = a  \n",
      "\n",
      "Alors la relation entre les longueurs des côtés est :\n",
      "\n",
      "1) Formule principale  \n",
      "   a² + b² = c²  \n",
      "\n",
      "2) Interprétation géométrique  \n",
      "   – L’aire du carré de côté a (donc a²) plus\n",
      "\n",
      "...\n",
      "\n",
      "\n",
      "Différence: Avec formatage, vous obtenez du markdown propre (formules LaTeX, code blocks, etc.)\n"
     ]
    }
   ],
   "source": [
    "# Sans \"Formatting re-enabled\"\n",
    "response_no_format = client.chat.completions.create(\n",
    "    model=\"o4-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Explique le théorème de Pythagore avec des formules.\"}],\n",
    "    reasoning_effort=\"low\"\n",
    ")\n",
    "\n",
    "# Avec \"Formatting re-enabled\"\n",
    "response_with_format = client.chat.completions.create(\n",
    "    model=\"o4-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"Formatting re-enabled\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explique le théorème de Pythagore avec des formules.\"}\n",
    "    ],\n",
    "    reasoning_effort=\"low\"\n",
    ")\n",
    "\n",
    "print(\"=== Sans 'Formatting re-enabled' ===\")\n",
    "print(response_no_format.choices[0].message.content[:400])\n",
    "print(\"\\n...\\n\")\n",
    "\n",
    "print(\"\\n=== Avec 'Formatting re-enabled' ===\")\n",
    "print(response_with_format.choices[0].message.content[:400])\n",
    "print(\"\\n...\\n\")\n",
    "\n",
    "print(\"\\nDifférence: Avec formatage, vous obtenez du markdown propre (formules LaTeX, code blocks, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Interprétation de la différence de formatage\n\n**Sans \"Formatting re-enabled\"** :\n- Texte brut avec numérotation simple\n- Pas de balises LaTeX ($...$)\n- Formules écrites en notation textuelle (ex: `c² = a² + b²`)\n- Structure simple mais moins élégante\n\n**Avec \"Formatting re-enabled\"** :\n- Markdown riche avec titres, listes numérotées\n- Formules LaTeX rendues (dans les environnements supportant MathJax)\n- Blocs de code avec syntax highlighting\n- Mise en forme professionnelle\n\n**Quand activer le formatage ?**\n\n| Cas d'usage | Formatting re-enabled ? |\n|-------------|-------------------------|\n| **Documentation technique** | ✅ Oui (formules, code) |\n| **Rapports scientifiques** | ✅ Oui (LaTeX, tableaux) |\n| **Extraction de données brutes** | ❌ Non (traitement programmatique) |\n| **API backend** | ❌ Non (texte simple plus facile à parser) |\n| **Interface utilisateur** | ✅ Oui (présentation soignée) |\n\n**Exemple de formules LaTeX** (si le formatage est activé) :\n\n```markdown\nLe théorème de Pythagore : $a^2 + b^2 = c^2$\n\nLa formule d'Einstein : $E = mc^2$\n\nÉquation quadratique : $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$\n```\n\n**Astuce** : Pour les notebooks Jupyter, le formatage markdown est automatiquement rendu, ce qui rend les réponses beaucoup plus lisibles !",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cas d'usage : Génération de code complexe\n",
    "\n",
    "Les modèles de raisonnement excellent dans la génération de code nécessitant :\n",
    "- Analyse algorithmique\n",
    "- Optimisation de complexité\n",
    "- Tests edge cases\n",
    "- Debugging multi-étapes\n",
    "\n",
    "### Exemple : Algorithme du plus long palindrome\n",
    "\n",
    "Problème classique d'algorithmique :\n",
    "- Approche naïve : O(n³)\n",
    "- Approche optimisée : O(n²) avec expansion autour du centre\n",
    "- Approche avancée : O(n) avec Manacher's algorithm\n",
    "\n",
    "Un modèle raisonnant peut analyser les différentes approches et choisir la meilleure."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Analyse approfondie du benchmark\n\n**Résultats quantitatifs** :\n\n- **Temps moyen gpt-4o-mini** : 1.17s (chat model)\n- **Temps moyen o4-mini** : 4.41s (reasoning model)\n- **Ratio** : Le modèle raisonnant est ~3.8x plus lent\n\n**Analyse par problème** :\n\n1. **Multiplication simple (17 × 23)** :\n   - Les deux modèles réussissent instantanément\n   - Différence de temps : 1.61s vs 0.58s\n   - Conclusion : Sur des calculs directs, le chat model suffit\n\n2. **Problème des chats et souris** :\n   - Piège classique : beaucoup pensent qu'il faut 100 chats\n   - **Raisonnement correct** : 3 chats attrapent 3 souris en 3 min → 1 chat attrape 1 souris en 3 min → 3 chats attrapent 100 souris en 100 min\n   - Les deux modèles ont trouvé la bonne réponse\n   - Temps : 3.02s vs 1.20s\n\n3. **Problème des trains** :\n   - Nécessite plusieurs étapes : distance parcourue par chaque train, rencontre\n   - gpt-4o-mini : \"10h30\" (approximation)\n   - o4-mini : \"10h 13min 20s\" (calcul précis)\n   - **Le reasoning model est plus précis** sur les problèmes multi-étapes\n\n**Quand la différence est décisive** :\n\n| Type de problème | Chat model | Reasoning model |\n|------------------|------------|-----------------|\n| **Calcul direct** | ✅ Suffisant | ⚠️ Overkill |\n| **Logique simple** | ✅ Bon | ✅ Excellent |\n| **Multi-étapes** | ⚠️ Approximatif | ✅ Précis |\n| **Optimisation** | ❌ Erreurs fréquentes | ✅ Fiable |\n| **Preuve formelle** | ❌ Impossible | ✅ Possible |\n\n**Recommandation pratique** :\n\nPour une application en production avec des milliers de requêtes :\n1. **Classifier les questions** par complexité (simple/moyen/complexe)\n2. **Router intelligemment** : chat model pour simple, reasoning pour complexe\n3. **Économie de coûts** : ~70% de réduction si 80% des questions sont simples",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Génération de code avec o4-mini (reasoning_effort='high') ===\n",
      "\n",
      "Temps de génération: 17.29s\n",
      "\n",
      "Voici une solution en O(n²) qui, pour chaque position, « étend » un palindrome de longueur impaire et paire.  \n",
      "\n",
      "```python\n",
      "def longest_palindrome(s: str) -> str:\n",
      "    \"\"\"\n",
      "    Retourne le plus long sous-palindrome de s.\n",
      "    Complexité time O(n^2), space O(1) (hors sortie).\n",
      "    \"\"\"\n",
      "    n = len(s)\n",
      "    if n < 2:\n",
      "        return s  # \"\" ou 1 caractère est déjà un palindrome\n",
      "\n",
      "    start, max_len = 0, 1\n",
      "\n",
      "    def expand_around_center(left: int, right: int):\n",
      "        nonlocal start, max_len\n",
      "        # étend tant que les bornes sont valides et que les caractères correspondent\n",
      "        while left >= 0 and right < n and s[left] == s[right]:\n",
      "            curr_len = right - left + 1\n",
      "            if curr_len > max_len:\n",
      "                start, max_len = left, curr_len\n",
      "            left -= 1\n",
      "            right += 1\n",
      "\n",
      "    for i in range(n):\n",
      "        # cas palindrome de longueur impaire (centre sur i)\n",
      "        expand_around_center(i, i)\n",
      "        # cas palindrome de longueur paire (centre entre i et i+1)\n",
      "        expand_around_center(i, i + 1)\n",
      "\n",
      "    return s[start:start + max_len]\n",
      "\n",
      "\n",
      "# --- Tests ---------------------------------------------------\n",
      "if __name__ == \"__main__\":\n",
      "    tests = [\n",
      "        (\"\", \"\"),                    # chaîne vide\n",
      "        (\"x\", \"x\"),                  # un seul caractère\n",
      "        (\"racecar\", \"racecar\"),      # palindrome complet\n",
      "        (\"abcdef\", \"a\"),             # pas de palindrome > 1, on renvoie le 1er\n",
      "        (\"babad\", \"bab\"),            # deux choix possibles (ici \"bab\")\n",
      "    ]\n",
      "\n",
      "    for inp, expected in tests:\n",
      "        out = longest_palindrome(inp)\n",
      "        print(f\"entrée: {inp!r:10}  → sortie: {out!r:10}  (attendu: {expected!r:10})\")\n",
      "        assert out == expected, f\"Échec pour {inp!r}: attendu {expected!r}, obtenu {out!r}\"\n",
      "\n",
      "    print(\"Tous les tests sont passés ✅\")\n",
      "```\n",
      "\n",
      "============================================================\n",
      "Note: Le modèle devrait fournir :\n",
      "  1. Une implémentation avec expansion autour du centre (O(n²))\n",
      "  2. Des tests complets couvrant les edge cases\n",
      "  3. Des commentaires expliquant la logique\n"
     ]
    }
   ],
   "source": [
    "probleme_code = \"\"\"\n",
    "Écris une fonction Python qui trouve le plus long palindrome dans une chaîne.\n",
    "La fonction doit être optimisée (O(n²) maximum).\n",
    "Inclus des tests avec plusieurs cas (chaîne vide, un seul caractère, palindrome complet, pas de palindrome).\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Génération de code avec o4-mini (reasoning_effort='high') ===\\n\")\n",
    "\n",
    "start = time.time()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"o4-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"Formatting re-enabled\"},\n",
    "        {\"role\": \"user\", \"content\": probleme_code}\n",
    "    ],\n",
    "    reasoning_effort=\"high\"\n",
    ")\n",
    "duration = time.time() - start\n",
    "\n",
    "print(f\"Temps de génération: {duration:.2f}s\\n\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Note: Le modèle devrait fournir :\")\n",
    "print(\"  1. Une implémentation avec expansion autour du centre (O(n²))\")\n",
    "print(\"  2. Des tests complets couvrant les edge cases\")\n",
    "print(\"  3. Des commentaires expliquant la logique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Déconstruction du processus de raisonnement\n\nLe modèle de raisonnement a identifié le problème de performance avec une **analyse structurée remarquable** :\n\n**1. Diagnostic du problème** :\n- Identifie la récursion redondante\n- Explique que les mêmes valeurs sont recalculées plusieurs fois\n- Quantifie l'ampleur du problème (millions d'appels pour n=35-40)\n\n**2. Analyse de complexité** :\n- Formule la complexité O(2ⁿ) explicitement\n- Explique pourquoi : \"l'arbre d'appels double à chaque niveau\"\n- Donne des ordres de grandeur concrets\n\n**3. Solutions proposées** :\n- **Option A** : Mémoïsation avec `@lru_cache` (simple, élégant)\n- **Option B** : Approche itérative (plus performante, O(1) en espace)\n- Les deux solutions réduisent à O(n) en temps\n\n**4. Code production-ready** :\n- Docstrings claires\n- Commentaires pertinents\n- Tests intégrés dans `if __name__ == \"__main__\"`\n\n**Ce que révèle ce processus** :\n\nUn modèle de raisonnement ne se contente pas de \"connaître la réponse\". Il :\n1. **Analyse** le code existant\n2. **Identifie** le point de friction\n3. **Explique** les causes profondes\n4. **Propose** plusieurs solutions avec trade-offs\n5. **Implémente** du code de qualité professionnelle\n\n**Comparaison avec un chat model** :\n\nUn chat model aurait probablement :\n- Identifié le problème (récursion)\n- Proposé une solution (mémoïsation)\n- Mais sauté l'analyse de complexité détaillée\n- Fourni moins d'explications sur les choix de conception\n\n**Cas d'usage similaires pour le debugging** :\n- Fuites mémoire\n- Problèmes de concurrence\n- Optimisation de requêtes SQL\n- Analyse de goulots d'étranglement (profiling)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Modèles de Raisonnement Avancés\n\n### Panorama des modèles raisonnants disponibles\n\n| Modèle | Disponibilité | Caractéristiques |\n|--------|---------------|------------------|\n| **o1-mini** | Disponible | Rapide, économique, bonne précision |\n| **o1-preview** | Disponible | Plus puissant, plus lent |\n| **o3-mini** | Disponible | Dernière génération, équilibré |\n| **o4-mini** | Disponible | Version optimisée 2026 |\n| **gpt-5-thinking** | Accès limité | Très avancé, pas encore public |\n\n### Recommandations pratiques\n\n- **o4-mini** : Premier choix pour la plupart des tâches de raisonnement\n- **o3-mini** : Alternative si o4-mini n'est pas disponible\n- **gpt-5-thinking** : Réservé aux cas très complexes (accès restreint)\n\n**Note :** La disponibilité des modèles dépend de votre niveau d'accès API. Les exemples ci-dessous utilisent les modèles accessibles publiquement."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "probleme_complexe = \"\"\"\nRésous ce problème d'optimisation:\n\nUn fermier veut construire un enclos rectangulaire contre un mur existant.\nIl a 100 mètres de clôture disponible (le mur fait office d'un côté).\nQuelle doit être la dimension de l'enclos pour maximiser la surface?\n\nDétaille toutes les étapes mathématiques :\n1. Définition des variables\n2. Équation de contrainte\n3. Fonction à optimiser\n4. Calcul de la dérivée\n5. Résolution et vérification\n\"\"\"\n\nprint(\"=== Modèle raisonnant sur problème d'optimisation ===\\n\")\n\n# Essayer d'abord gpt-5-thinking, fallback sur o4-mini\nmodels_to_try = [\"gpt-5-thinking\", \"o4-mini\", \"o3-mini\", \"o1-preview\"]\n\nfor model in models_to_try:\n    try:\n        print(f\"Tentative avec {model}...\")\n        start = time.time()\n        \n        # Configuration différente selon le modèle\n        if model.startswith(\"gpt-5\"):\n            response = client.chat.completions.create(\n                model=model,\n                messages=[\n                    {\"role\": \"developer\", \"content\": \"Formatting re-enabled\"},\n                    {\"role\": \"user\", \"content\": probleme_complexe}\n                ]\n            )\n        else:\n            response = client.chat.completions.create(\n                model=model,\n                messages=[\n                    {\"role\": \"developer\", \"content\": \"Formatting re-enabled\"},\n                    {\"role\": \"user\", \"content\": probleme_complexe}\n                ],\n                reasoning_effort=\"high\"\n            )\n        \n        duration = time.time() - start\n        print(f\"Succès avec {model} ! (Temps: {duration:.2f}s)\\n\")\n        print(response.choices[0].message.content)\n        break  # Sortir de la boucle si succès\n        \n    except Exception as e:\n        print(f\"  {model} non disponible: {type(e).__name__}\")\n        if model == models_to_try[-1]:\n            print(\"\\nAucun modèle raisonnant disponible. Utilisation de gpt-4o en fallback.\")\n            response = client.chat.completions.create(\n                model=DEFAULT_MODEL,\n                messages=[{\"role\": \"user\", \"content\": probleme_complexe}]\n            )\n            print(response.choices[0].message.content)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Réponse correcte: Longueur 50m (parallèle au mur), Largeur 25m, Surface 1250m²\")\nprint(\"Équation: S(x) = x(100-2x), dérivée S'(x) = 100 - 4x, max en x=25\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison coût/performance\n",
    "\n",
    "### Tarification (approximative, vérifiez les tarifs actuels)\n",
    "\n",
    "| Modèle | Input ($/1M tokens) | Output ($/1M tokens) | Vitesse | Précision |\n",
    "|--------|---------------------|----------------------|---------|----------|\n",
    "| **gpt-4o-mini** | 0.15 | 0.60 | ⚡⚡⚡ | ⭐⭐⭐ |\n",
    "| **gpt-4o** | 2.50 | 10.00 | ⚡⚡ | ⭐⭐⭐⭐ |\n",
    "| **o4-mini** | 1.50 | 6.00 | ⚡⚡ | ⭐⭐⭐⭐⭐ (problèmes complexes) |\n",
    "| **gpt-5-thinking** | 5.00 | 20.00 | ⚡ | ⭐⭐⭐⭐⭐ (très complexe) |\n",
    "\n",
    "### Guide de choix\n",
    "\n",
    "```python\n",
    "def choisir_modele(tache):\n",
    "    if tache.type == \"conversation\" or tache.complexite == \"faible\":\n",
    "        return \"gpt-4o-mini\"  # Rapide, économique\n",
    "    \n",
    "    elif tache.type == \"generation_creative\" or tache.complexite == \"moyenne\":\n",
    "        return \"gpt-4o\"  # Équilibre qualité/vitesse\n",
    "    \n",
    "    elif tache.type in [\"math\", \"code\", \"logique\"] and tache.complexite == \"élevée\":\n",
    "        return \"o4-mini\"  # Raisonnement économique\n",
    "    \n",
    "    elif tache.complexite == \"très élevée\" or tache.precision_requise == \"maximale\":\n",
    "        return \"gpt-5-thinking\"  # Pour les cas difficiles\n",
    "    \n",
    "    else:\n",
    "        return \"gpt-4o\"  # Par défaut\n",
    "```\n",
    "\n",
    "### Tokens de raisonnement\n",
    "\n",
    "Les modèles raisonnants génèrent des **tokens de réflexion** (non visibles) avant la réponse finale.\n",
    "- `reasoning_effort=\"low\"` : ~500-1000 tokens de réflexion\n",
    "- `reasoning_effort=\"medium\"` : ~1000-3000 tokens\n",
    "- `reasoning_effort=\"high\"` : ~3000-10000+ tokens\n",
    "\n",
    "**Ces tokens sont facturés** ! Optimisez selon vos besoins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Benchmark : Chat vs Reasoning\n",
    "\n",
    "Testons les deux approches sur plusieurs problèmes types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Benchmark Chat vs Reasoning ===\n",
      "\n",
      "Problème 1: Combien font 17 * 23?...\n",
      "  gpt-4o-mini (0.58s): 391\n",
      "  o4-mini (1.61s): 391\n",
      "  [Correct: 391]\n",
      "\n",
      "Problème 2: Si 3 chats attrapent 3 souris en 3 minutes, combien de chats...\n",
      "  gpt-4o-mini (1.20s): Il faut 3 chats.\n",
      "  o4-mini (3.02s): 3\n",
      "  [Correct: 3 chats]\n",
      "\n",
      "Problème 3: Un train part de Paris à 8h et roule à 120 km/h. Un autre pa...\n",
      "  gpt-4o-mini (1.73s): Ils se croisent à 10h30.\n",
      "  o4-mini (8.60s): 10 h 13 min 20 s\n",
      "  [Correct: environ 10h30]\n",
      "\n",
      "\n",
      "=== Statistiques ===\n",
      "Temps moyen gpt-4o-mini: 1.17s\n",
      "Temps moyen o4-mini: 4.41s\n",
      "\n",
      "Observation: Les modèles raisonnants sont plus lents mais généralement plus précis\n",
      "sur les problèmes nécessitant plusieurs étapes de calcul.\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "problemes = [\n",
    "    (\"Combien font 17 * 23?\", \"391\"),\n",
    "    (\"Si 3 chats attrapent 3 souris en 3 minutes, combien de chats faut-il pour attraper 100 souris en 100 minutes?\", \"3 chats\"),\n",
    "    (\"Un train part de Paris à 8h et roule à 120 km/h. Un autre part de Lyon (450km) à 9h à 150 km/h vers Paris. À quelle heure se croisent-ils?\", \"environ 10h30\")\n",
    "]\n",
    "\n",
    "print(\"=== Benchmark Chat vs Reasoning ===\\n\")\n",
    "\n",
    "temps_chat = []\n",
    "temps_reasoning = []\n",
    "\n",
    "for i, (prob, correct) in enumerate(problemes):\n",
    "    print(f\"Problème {i+1}: {prob[:60]}...\")\n",
    "    \n",
    "    # Chat model\n",
    "    start = time.time()\n",
    "    resp_chat = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prob + \" Réponds uniquement avec le résultat.\"}],\n",
    "        max_tokens=50\n",
    "    )\n",
    "    t_chat = time.time() - start\n",
    "    temps_chat.append(t_chat)\n",
    "    \n",
    "    # Reasoning model\n",
    "    start = time.time()\n",
    "    resp_reason = client.chat.completions.create(\n",
    "        model=\"o4-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prob + \" Réponds uniquement avec le résultat.\"}],\n",
    "        reasoning_effort=\"medium\"\n",
    "    )\n",
    "    t_reason = time.time() - start\n",
    "    temps_reasoning.append(t_reason)\n",
    "    \n",
    "    print(f\"  gpt-4o-mini ({t_chat:.2f}s): {resp_chat.choices[0].message.content.strip()}\")\n",
    "    print(f\"  o4-mini ({t_reason:.2f}s): {resp_reason.choices[0].message.content.strip()}\")\n",
    "    print(f\"  [Correct: {correct}]\\n\")\n",
    "\n",
    "print(\"\\n=== Statistiques ===\")\n",
    "print(f\"Temps moyen gpt-4o-mini: {statistics.mean(temps_chat):.2f}s\")\n",
    "print(f\"Temps moyen o4-mini: {statistics.mean(temps_reasoning):.2f}s\")\n",
    "print(f\"\\nObservation: Les modèles raisonnants sont plus lents mais généralement plus précis\")\n",
    "print(f\"sur les problèmes nécessitant plusieurs étapes de calcul.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exemple pratique : Débogage de code\n",
    "\n",
    "Les modèles de raisonnement excellent dans le debugging complexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Débogage avec o4-mini (reasoning_effort='high') ===\n",
      "\n",
      "Voici une analyse point par point et une version optimisée :\n",
      "\n",
      "1. Problème de performance  \n",
      "   - La fonction fibonacci fait deux appels récursifs à chaque niveau.  \n",
      "   - Elle recalcule sans cesse les mêmes valeurs de Fibonacci.\n",
      "\n",
      "2. Pourquoi c’est lent (complexité)  \n",
      "   - L’arbre d’appels récursifs double quasiment à chaque niveau.  \n",
      "   - En notation Big-O, la complexité est O(2ⁿ).  \n",
      "   - Pour n = 35–40, le nombre d’appels explose (plusieurs dizaines de millions).\n",
      "\n",
      "3. Solution optimisée  \n",
      "   - utiliser un cache (mémoisation) pour ne calculer chaque F(k) qu’une seule fois, ou  \n",
      "   - passer à une version itérative en O(n) et O(1) d’espace supplémentaire.\n",
      "\n",
      "4. Code corrigé  \n",
      "\n",
      "Option A – avec mémoisation automatique :\n",
      "\n",
      "```python\n",
      "from functools import lru_cache\n",
      "\n",
      "@lru_cache(maxsize=None)\n",
      "def fibonacci(n):\n",
      "    \"\"\"Calcule le n-ième nombre de Fibonacci en mémoisant.\"\"\"\n",
      "    if n <= 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "\n",
      "# Test\n",
      "for i in range(40):\n",
      "    print(f\"F({i}) = {fibonacci(i)}\")\n",
      "```\n",
      "\n",
      "Option B – version itérative (la plus simple et la plus rapide) :\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    \"\"\"Calcule le n-ième nombre de Fibonacci en O(n).\"\"\"\n",
      "    if n <= 0:\n",
      "        return 0\n",
      "    a, b = 0, 1\n",
      "    for _ in range(1, n):\n",
      "        a, b = b, a + b\n",
      "    return b\n",
      "\n",
      "# Test\n",
      "for i in range(40):\n",
      "    print(f\"F({i}) = {fibonacci(i)}\")\n",
      "```\n",
      "\n",
      "Les deux approches réduisent la complexité à O(n) et sont instantanées même pour n très grand (jusqu’à plusieurs millions sans problème de temps, sous réserve de la taille des entiers).\n",
      "\n",
      "============================================================\n",
      "Le modèle devrait identifier:\n",
      "  - Complexité O(2^n) due aux appels récursifs redondants\n",
      "  - Solution: mémoïsation ou approche itérative (O(n))\n"
     ]
    }
   ],
   "source": [
    "code_buggue = '''\n",
    "def fibonacci(n):\n",
    "    \"\"\"Calcule le n-ième nombre de Fibonacci.\"\"\"\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "# Test\n",
    "for i in range(40):\n",
    "    print(f\"F({i}) = {fibonacci(i)}\")\n",
    "'''\n",
    "\n",
    "prompt_debug = f\"\"\"\n",
    "Analyse ce code Python et identifie le(s) problème(s) :\n",
    "\n",
    "```python\n",
    "{code_buggue}\n",
    "```\n",
    "\n",
    "Le code fonctionne mais devient TRÈS lent pour n >= 35.\n",
    "\n",
    "1. Identifie le problème de performance\n",
    "2. Explique pourquoi (complexité algorithmique)\n",
    "3. Propose une solution optimisée\n",
    "4. Fournis le code corrigé\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Débogage avec o4-mini (reasoning_effort='high') ===\\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"o4-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"Formatting re-enabled\"},\n",
    "        {\"role\": \"user\", \"content\": prompt_debug}\n",
    "    ],\n",
    "    reasoning_effort=\"high\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Le modèle devrait identifier:\")\n",
    "print(\"  - Complexité O(2^n) due aux appels récursifs redondants\")\n",
    "print(\"  - Solution: mémoïsation ou approche itérative (O(n))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Limites et considérations\n",
    "\n",
    "### Limites des modèles de raisonnement\n",
    "\n",
    "1. **Temps de réponse** : Peuvent être lents (30-60s+) pour `reasoning_effort=\"high\"`\n",
    "2. **Coût** : Tokens de réflexion facturés même s'ils ne sont pas visibles\n",
    "3. **Pas toujours nécessaires** : Sur-utiliser peut gaspiller temps et argent\n",
    "4. **Pas magiques** : Ne garantissent pas la correction (vérifiez toujours les résultats)\n",
    "\n",
    "### Bonnes pratiques\n",
    "\n",
    "1. **Commencez simple** : Testez d'abord avec un chat model\n",
    "2. **Montez progressivement** : gpt-4o-mini → gpt-4o → o4-mini → gpt-5-thinking\n",
    "3. **Ajustez reasoning_effort** : Commencez par \"low\", augmentez si nécessaire\n",
    "4. **Validez les résultats** : Surtout pour le code et les calculs critiques\n",
    "5. **Mesurez le ROI** : Le temps/coût supplémentaire est-il justifié ?\n",
    "\n",
    "### Cas où les chat models suffisent\n",
    "\n",
    "- Conversations naturelles\n",
    "- Résumés et synthèses\n",
    "- Traduction simple\n",
    "- Génération de contenu créatif\n",
    "- Questions factuelles directes\n",
    "- Code simple (CRUD, scripts basiques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion et ressources\n",
    "\n",
    "### Points clés à retenir\n",
    "\n",
    "1. **Modèles de raisonnement** = temps de réflexion + meilleure précision sur tâches complexes\n",
    "2. **o4-mini** : Excellent rapport qualité/prix pour raisonnement standard\n",
    "3. **gpt-5-thinking** : Pour les problèmes très complexes nécessitant raisonnement profond\n",
    "4. **reasoning_effort** : Contrôle le compromis temps/qualité (low/medium/high)\n",
    "5. **Messages developer** : Remplacent `system`, `\"Formatting re-enabled\"` active le markdown\n",
    "6. **Choisir judicieusement** : Ne pas sur-utiliser les modèles raisonnants (coût)\n",
    "\n",
    "### Tableau récapitulatif\n",
    "\n",
    "| Tâche | Modèle recommandé | reasoning_effort |\n",
    "|-------|-------------------|------------------|\n",
    "| Conversation | gpt-4o-mini | N/A |\n",
    "| Code simple | gpt-4o | N/A |\n",
    "| Algorithme complexe | o4-mini | medium |\n",
    "| Optimisation math | o4-mini | high |\n",
    "| Preuve formelle | gpt-5-thinking | N/A (auto) |\n",
    "| Debugging approfondi | o4-mini ou gpt-5-thinking | high |\n",
    "\n",
    "### Exercices suggérés\n",
    "\n",
    "1. **Comparaison** : Testez un problème de logique avec gpt-4o-mini vs o4-mini\n",
    "2. **Optimisation** : Demandez à o4-mini d'optimiser un algorithme de tri\n",
    "3. **Reasoning effort** : Comparez low/medium/high sur un problème d'optimisation\n",
    "4. **Code generation** : Demandez l'implémentation d'un algorithme complexe (Dijkstra, A*)\n",
    "5. **Multi-étapes** : Problème nécessitant analyse → planification → exécution\n",
    "\n",
    "### Ressources\n",
    "\n",
    "- [Documentation OpenAI - Reasoning Models](https://platform.openai.com/docs/guides/reasoning)\n",
    "- [Guide des tarifs](https://openai.com/pricing)\n",
    "- [Best practices pour o4-mini](https://platform.openai.com/docs/guides/reasoning/best-practices)\n",
    "- Notebook suivant : **9_Vision_Models.ipynb** (GPT-4 Vision, analyse d'images)\n",
    "\n",
    "### Prochaines étapes\n",
    "\n",
    "Dans le prochain notebook, nous explorerons les **modèles de vision** :\n",
    "- GPT-4 Vision (gpt-4o avec images)\n",
    "- Analyse de screenshots, diagrammes, graphiques\n",
    "- Extraction de texte (OCR)\n",
    "- Génération de descriptions d'images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}