# ============================================================================
# GenAI CoursIA - Configuration Unifiee
# ============================================================================
#
# INSTRUCTIONS :
# 1. Copier ce fichier vers .env : cp .env.example .env
# 2. Remplacer les valeurs "your_..._here" par vos vraies cles API
# 3. Le fichier .env est automatiquement ignore par Git (securite)
#
# ============================================================================

# ============================================================================
# SECTION 1 : ComfyUI
# ============================================================================
# Configuration pour le serveur ComfyUI local (Docker)
# Documentation : docker-configurations/services/comfyui-qwen/README.md

# URL du serveur ComfyUI
COMFYUI_API_URL=http://localhost:8188

# Token d'authentification Bearer pour ComfyUI
# Obtenu via: scripts/genai-auth/extract-bearer-tokens.ps1
# Note: L'authentification est OPTIONNELLE (graceful degradation)
# - Sans token : connexion sans auth (serveur non securise uniquement)
# - Avec token : requis pour serveur securise avec ComfyUI-Login
COMFYUI_API_TOKEN=your_bearer_token_here

# Token alternatif pour Qwen Image Edit (utilise par notebooks 01-Foundation)
# Credentials par defaut : Username: etudiant | Password: CourIA2025!
QWEN_API_TOKEN=your_qwen_token_here

# ============================================================================
# SECTION 2 : OpenAI
# ============================================================================
# Configuration pour l'API OpenAI
# Documentation : https://platform.openai.com/docs

# Cle API OpenAI
OPENAI_API_KEY=your_openai_key_here

# URL de base OpenAI (laisser vide pour URL par defaut)
# OPENAI_BASE_URL=https://api.openai.com/v1

# Modele de chat OpenAI (gpt-5.2, gpt-5-mini, gpt-5o-mini, etc.)
OPENAI_CHAT_MODEL_ID=gpt-5-mini

# Nom du endpoint OpenAI (pour Semantic Kernel)
OPENAI_ENDPOINT_NAME=OpenAI

# Endpoints locaux supplementaires (optionnel)
# OPENAI_ENDPOINT_NAME_2=Local Model - Micro
# OPENAI_API_KEY_2=your_local_key_here
# OPENAI_BASE_URL_2=https://api.micro.yourdomain.com/v1

# ============================================================================
# SECTION 3 : Anthropic
# ============================================================================
# Configuration pour l'API Anthropic (Claude)
# Documentation : https://docs.anthropic.com/

# Cle API Anthropic
ANTHROPIC_API_KEY=your_anthropic_key_here

# Modele Claude (claude-opus-4-5, claude-sonnet-4-5, claude-haiku-4-5)
ANTHROPIC_CHAT_MODEL_ID=claude-sonnet-4-5

# ============================================================================
# SECTION 4 : OpenRouter
# ============================================================================
# Configuration pour OpenRouter (acces multi-modeles)
# Documentation : https://openrouter.ai/docs

# Cle API OpenRouter
OPENROUTER_API_KEY=your_openrouter_key_here

# URL de base OpenRouter
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Nom de l'application (pour tracking et rate limiting)
OPENROUTER_APP_NAME=CoursIA-GenAI

# ============================================================================
# SECTION 5 : Modeles par defaut
# ============================================================================
# Configuration des modeles preferes pour differentes taches

# Modele par defaut pour la vision (analyse d'images)
DEFAULT_VISION_MODEL=gpt-5o-mini

# Modele par defaut pour la generation d'images
DEFAULT_IMAGE_MODEL=gpt-5o-mini

# Modeles specifiques
QWEN_IMAGE_MODEL=qwen/qwen-vl-max
FLUX_MODEL=black-forest-labs/flux.1-dev

# ============================================================================
# SECTION 6 : Configuration GenAI
# ============================================================================
# Parametres generaux pour les notebooks GenAI

# Timeout pour les requetes API (en secondes)
GENAI_TIMEOUT_SECONDS=300

# Nombre maximum de tentatives en cas d'erreur
GENAI_MAX_RETRIES=3

# Repertoire de sortie pour les fichiers generes
GENAI_OUTPUT_DIR=outputs/generated

# Niveau de log (DEBUG, INFO, WARNING, ERROR)
GENAI_LOG_LEVEL=INFO

# Taille des lots pour le traitement par batch
GENAI_BATCH_SIZE=1

# Sauvegarde automatique des outputs
AUTO_SAVE_OUTPUTS=true
SAVE_METADATA=true
COMPRESSION_ENABLED=true

# ============================================================================
# SECTION 7 : Semantic Kernel
# ============================================================================
# Configuration pour Microsoft Semantic Kernel
# Documentation : https://learn.microsoft.com/semantic-kernel/

# Service LLM a utiliser (OpenAI, AzureOpenAI, Anthropic)
GLOBAL_LLM_SERVICE=OpenAI

# ============================================================================
# SECTION 8 : Mode Batch
# ============================================================================
# Configuration pour l'execution automatisee (Papermill/MCP)

# Active le mode batch (skip les parties interactives)
# Mettre a "true" pour Papermill/MCP, "false" pour mode interactif
BATCH_MODE=false

# Texte personnalise pour tests en mode batch (optionnel)
# BATCH_TEXT=Texte de test pour analyse...

# ============================================================================
# SECTION 9 : GitHub (optionnel)
# ============================================================================
# Configuration pour l'integration GitHub (requis pour LeanDojo)
# Documentation : https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens

# Token GitHub pour l'API
GITHUB_TOKEN=your_github_token_here

# Alternative (nom utilise par LeanDojo)
GITHUB_ACCESS_TOKEN=your_github_token_here

# ============================================================================
# SECTION 10 : Docker Local (optionnel)
# ============================================================================
# Configuration pour les services Docker locaux

# Active les services Docker locaux
DOCKER_ENABLED=false

# URLs des services Docker
FLUX_API_URL=http://localhost:8189
SD_API_URL=http://localhost:8190

# ============================================================================
# SECTION 11 : Lean (optionnel)
# ============================================================================
# Configuration pour les notebooks Lean (proof assistant)

# Version de Lean a utiliser (stable, nightly, ou version specifique)
LEAN_VERSION=stable

# Chemin vers elan (si non standard)
# ELAN_HOME=/custom/path/to/.elan

# Modele LLM pour la generation de preuves (Lean-8)
LLM_MODEL=gpt-5.2

# ============================================================================
# NOTES IMPORTANTES
# ============================================================================
#
# SECURITE :
#   - Ne JAMAIS partager vos cles API avec d'autres personnes
#   - Ne JAMAIS commiter le fichier .env dans Git
#   - Le fichier .env est deja dans .gitignore (protection automatique)
#   - En cas de compromission, regenerez vos cles immediatement
#
# DEPANNAGE :
#   - Si erreur "variable non trouvee" : verifier que le fichier .env existe
#   - Si erreur "401 Unauthorized" : verifier que la cle API est correcte
#   - Les cles doivent etre copiees exactement (aucun espace avant/apres)
#
# UTILISATION DANS LES NOTEBOOKS :
#   Les notebooks chargent automatiquement les variables via python-dotenv :
#   ```python
#   from dotenv import load_dotenv
#   import os
#
#   load_dotenv()
#   api_key = os.getenv("OPENAI_API_KEY")
#   ```
#
# ============================================================================
