# ============================================================================
# GenAI CoursIA - Configuration Unifiee
# ============================================================================
#
# INSTRUCTIONS :
# 1. Copier ce fichier vers .env : cp .env.example .env
# 2. Remplacer les valeurs "your_..._here" par vos vraies cles API
# 3. Le fichier .env est automatiquement ignore par Git (securite)
#
# ============================================================================
# ETUDIANTS - CONFIGURATION RAPIDE
# ============================================================================
#
# Option A - Avec token enseignant (cours GenAI Images) :
#   1. cp .env.example .env
#   2. Remplacer "your_bearer_token_here" par le token fourni par l'enseignant
#   3. C'est tout! Les services myia.io sont pre-configures
#
# Option B - Services Docker locaux (si vous avez un GPU) :
#   1. cp .env.example .env
#   2. Mettre LOCAL_MODE=true ci-dessous
#   3. Suivre le notebook 00-2-Local-Docker-Deployment.ipynb
#
# Option C - Avec OpenRouter (LLMs gratuits) :
#   1. Creer un compte gratuit sur https://openrouter.ai
#   2. Copier votre cle API OpenRouter
#   3. Decommenter les lignes "OPENAI_BASE_URL=https://openrouter.ai/api/v1"
#   4. Remplacer "your_openrouter_key_here" par votre cle
#
# ============================================================================

# ============================================================================
# MODE LOCAL vs REMOTE
# ============================================================================
# Mettre a "true" pour utiliser les services Docker locaux
# Mettre a "false" pour utiliser les services heberges sur myia.io
#
# IMPORTANT: Si LOCAL_MODE=true, les URLs sont automatiquement basculees
# vers les ports locaux. Assurez-vous que les services Docker sont demarres!
# Voir notebook 00-2-Local-Docker-Deployment.ipynb
#
LOCAL_MODE=false

# ============================================================================
# SECTION 1 : Services GenAI Image (MyIA.io)
# ============================================================================
# Services heberges sur myia.io pour le cours GenAI
# Ces URLs sont accessibles depuis l'exterieur via reverse-proxy HTTPS
#
# POUR LES ETUDIANTS : Utilisez les URLs myia.io ci-dessous
# POUR USAGE LOCAL : Decommentez les URLs localhost correspondantes
#
# ============================================================================

# --- Qwen Image Edit (ComfyUI) ---
# Service principal d'edition d'images avec le modele Qwen
# Backend: ComfyUI avec workflow Qwen Image Edit 2509
#
# URL pour etudiants (via Internet):
COMFYUI_API_URL=https://qwen-image-edit.myia.io
# URL locale (si Docker tourne sur votre machine):
# COMFYUI_API_URL=http://localhost:8188

# Token d'authentification Bearer pour ComfyUI
# Credentials cours : Username: etudiant | Password: CoursIA2025!
# Le token ci-dessous est pre-genere pour le cours
COMFYUI_API_TOKEN=your_bearer_token_here
# Alias pour compatibilite avec certains notebooks (meme valeur)
COMFYUI_AUTH_TOKEN=your_bearer_token_here
QWEN_API_TOKEN=your_bearer_token_here

# --- Z-Image (Lumina/vLLM) ---
# Generation d'images text-to-image via API OpenAI-compatible
# Backend: vLLM Omni avec Z-Image-Turbo
# Endpoint: /v1/chat/completions
#
# URL pour etudiants:
ZIMAGE_API_URL=https://z-image.myia.io
ZIMAGE_API_BASE=https://z-image.myia.io/v1
# URL locale:
# ZIMAGE_API_URL=http://localhost:8001
# ZIMAGE_API_BASE=http://localhost:8001/v1

# --- Stable Diffusion WebUI Forge ---
# Generation d'images avec Stable Diffusion (SDXL, SD 1.5, etc.)
# Backend: SD WebUI Forge sur serveur GPU
#
# URL pour etudiants:
SD_FORGE_API_URL=https://stable-diffusion-webui-forge.myia.io
SD_FORGE_TURBO_URL=https://turbo.stable-diffusion-webui-forge.myia.io
# Aliases pour compatibilite avec certains notebooks
FORGE_API_URL=https://turbo.stable-diffusion-webui-forge.myia.io
SD_BASE_URL=https://stable-diffusion-webui-forge.myia.io
# URL locale (si vous avez SD Forge installe):
# SD_FORGE_API_URL=http://localhost:7860
# FORGE_API_URL=http://localhost:7860

# Credentials SD Forge (si authentification requise)
FORGE_USER=your_username_here
FORGE_PASSWORD=your_password_here

# --- SD.Next ---
# Alternative a SD Forge avec plus de modeles
#
# URL pour etudiants:
SDNEXT_API_URL=https://sdnext.myia.io
# URL locale:
# SDNEXT_API_URL=http://localhost:7861

# ============================================================================
# SECTION 2 : OpenAI
# ============================================================================
# Configuration pour l'API OpenAI
# Documentation : https://platform.openai.com/docs
#
# ALTERNATIVE GRATUITE (OpenRouter) :
# Decommentez les 3 lignes ci-dessous pour utiliser des modeles gratuits
# via OpenRouter au lieu de l'API OpenAI payante
#
# OPENAI_BASE_URL=https://openrouter.ai/api/v1
# OPENAI_API_KEY=your_openrouter_key_here
# OPENAI_CHAT_MODEL_ID=meta-llama/llama-3.2-3b-instruct:free

# Cle API OpenAI (ou OpenRouter si OPENAI_BASE_URL pointe vers OpenRouter)
OPENAI_API_KEY=your_openai_key_here

# URL de base OpenAI (laisser vide pour URL par defaut)
# OPENAI_BASE_URL=https://api.openai.com/v1

# Modele de chat OpenAI (gpt-5.2, gpt-5-mini, gpt-5o-mini, etc.)
OPENAI_CHAT_MODEL_ID=gpt-5-mini

# Nom du endpoint OpenAI (pour Semantic Kernel)
OPENAI_ENDPOINT_NAME=OpenAI

# Endpoints locaux supplementaires (optionnel)
# OPENAI_ENDPOINT_NAME_2=Local Model - Micro
# OPENAI_API_KEY_2=your_local_key_here
# OPENAI_BASE_URL_2=https://api.micro.yourdomain.com/v1

# ============================================================================
# SECTION 3 : Anthropic
# ============================================================================
# Configuration pour l'API Anthropic (Claude)
# Documentation : https://docs.anthropic.com/

# Cle API Anthropic
ANTHROPIC_API_KEY=your_anthropic_key_here

# Modele Claude (claude-opus-4-5, claude-sonnet-4-5, claude-haiku-4-5)
ANTHROPIC_CHAT_MODEL_ID=claude-sonnet-4-5

# ============================================================================
# SECTION 4 : OpenRouter
# ============================================================================
# Configuration pour OpenRouter (acces multi-modeles)
# Documentation : https://openrouter.ai/docs
# Inscription gratuite : https://openrouter.ai
#
# MODELES GRATUITS DISPONIBLES (suffixe :free) :
#   - meta-llama/llama-3.2-3b-instruct:free (recommande pour debuter)
#   - google/gemma-2-9b-it:free
#   - mistralai/mistral-7b-instruct:free
#   - Voir liste complete : https://openrouter.ai/models?q=free

# Cle API OpenRouter
OPENROUTER_API_KEY=your_openrouter_key_here

# URL de base OpenRouter
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Nom de l'application (pour tracking et rate limiting)
OPENROUTER_APP_NAME=CoursIA-GenAI

# ============================================================================
# SECTION 5 : Modeles par defaut
# ============================================================================
# Configuration des modeles preferes pour differentes taches

# Modele par defaut pour la vision (analyse d'images)
DEFAULT_VISION_MODEL=gpt-5o-mini

# Modele par defaut pour la generation d'images
DEFAULT_IMAGE_MODEL=gpt-5o-mini

# Modeles specifiques
QWEN_IMAGE_MODEL=qwen/qwen-vl-max
FLUX_MODEL=black-forest-labs/flux.1-dev

# ============================================================================
# SECTION 6 : Configuration GenAI
# ============================================================================
# Parametres generaux pour les notebooks GenAI

# Timeout pour les requetes API (en secondes)
GENAI_TIMEOUT_SECONDS=300

# Nombre maximum de tentatives en cas d'erreur
GENAI_MAX_RETRIES=3

# Repertoire de sortie pour les fichiers generes
GENAI_OUTPUT_DIR=outputs/generated

# Niveau de log (DEBUG, INFO, WARNING, ERROR)
GENAI_LOG_LEVEL=INFO

# Taille des lots pour le traitement par batch
GENAI_BATCH_SIZE=1

# Sauvegarde automatique des outputs
AUTO_SAVE_OUTPUTS=true
SAVE_METADATA=true
COMPRESSION_ENABLED=true

# ============================================================================
# SECTION 7 : Semantic Kernel
# ============================================================================
# Configuration pour Microsoft Semantic Kernel
# Documentation : https://learn.microsoft.com/semantic-kernel/

# Service LLM a utiliser (OpenAI, AzureOpenAI, Anthropic)
GLOBAL_LLM_SERVICE=OpenAI

# --- Qdrant Vector Store ---
# Base de donnees vectorielle pour RAG (notebook SK-05)
# Documentation : https://qdrant.tech/documentation/
#
# URL du serveur Qdrant
QDRANT_URL=https://qdrant.myia.io
# Cle API Qdrant (obtenir aupres de l'administrateur)
QDRANT_API_KEY=your_qdrant_api_key_here

# ============================================================================
# SECTION 8 : Mode Batch
# ============================================================================
# Configuration pour l'execution automatisee (Papermill/MCP)

# Active le mode batch (skip les parties interactives)
# Mettre a "true" pour Papermill/MCP, "false" pour mode interactif
BATCH_MODE=false

# Texte personnalise pour tests en mode batch (optionnel)
# BATCH_TEXT=Texte de test pour analyse...

# ============================================================================
# SECTION 9 : GitHub (optionnel)
# ============================================================================
# Configuration pour l'integration GitHub (requis pour LeanDojo)
# Documentation : https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens

# Token GitHub pour l'API
GITHUB_TOKEN=your_github_token_here

# Alternative (nom utilise par LeanDojo)
GITHUB_ACCESS_TOKEN=your_github_token_here

# ============================================================================
# SECTION 10 : LLMs Locaux via MyIA.io (optionnel)
# ============================================================================
# Serveurs de generation de texte heberges sur myia.io
# API compatible OpenAI (/v1/chat/completions)
#
# Ces endpoints peuvent etre utilises comme OPENAI_BASE_URL alternatifs
# pour utiliser des modeles locaux au lieu de l'API OpenAI

# Text Generation WebUI - Differentes tailles de modeles
# Micro: Modeles legers (7B params)
TGWUI_MICRO_API_URL=https://api.micro.text-generation-webui.myia.io/v1
# Mini: Modeles moyens (13B params)
TGWUI_MINI_API_URL=https://api.mini.text-generation-webui.myia.io/v1
# Medium: Modeles standards (30B params)
TGWUI_MEDIUM_API_URL=https://api.medium.text-generation-webui.myia.io/v1
# Large: Gros modeles (70B+ params)
TGWUI_LARGE_API_URL=https://api.large.text-generation-webui.myia.io/v1

# Pour utiliser un LLM local au lieu d'OpenAI, configurez:
# OPENAI_BASE_URL=https://api.mini.text-generation-webui.myia.io/v1
# OPENAI_API_KEY=not-needed
# OPENAI_CHAT_MODEL_ID=local-model

# ============================================================================
# SECTION 10b : Docker Local (optionnel)
# ============================================================================
# Configuration pour les services Docker locaux sur votre machine

# Active les services Docker locaux
DOCKER_ENABLED=false

# URLs des services Docker
FLUX_API_URL=http://localhost:8189
SD_API_URL=http://localhost:8190

# ============================================================================
# SECTION 11 : Lean (optionnel)
# ============================================================================
# Configuration pour les notebooks Lean (proof assistant)

# Version de Lean a utiliser (stable, nightly, ou version specifique)
LEAN_VERSION=stable

# Chemin vers elan (si non standard)
# ELAN_HOME=/custom/path/to/.elan

# Modele LLM pour la generation de preuves (Lean-8)
LLM_MODEL=gpt-5.2

# ============================================================================
# NOTES IMPORTANTES
# ============================================================================
#
# SECURITE :
#   - Ne JAMAIS partager vos cles API avec d'autres personnes
#   - Ne JAMAIS commiter le fichier .env dans Git
#   - Le fichier .env est deja dans .gitignore (protection automatique)
#   - En cas de compromission, regenerez vos cles immediatement
#
# DEPANNAGE :
#   - Si erreur "variable non trouvee" : verifier que le fichier .env existe
#   - Si erreur "401 Unauthorized" : verifier que la cle API est correcte
#   - Les cles doivent etre copiees exactement (aucun espace avant/apres)
#
# UTILISATION DANS LES NOTEBOOKS :
#   Les notebooks chargent automatiquement les variables via python-dotenv :
#   ```python
#   from dotenv import load_dotenv
#   import os
#
#   load_dotenv()
#   api_key = os.getenv("OPENAI_API_KEY")
#   ```
#
# ============================================================================
