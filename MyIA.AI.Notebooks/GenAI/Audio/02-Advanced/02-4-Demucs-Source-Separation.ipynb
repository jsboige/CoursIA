{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-header",
      "metadata": {},
      "source": [
        "# Demucs v4 - Separation de Sources Audio\n",
        "\n",
        "**Module :** 02-Audio-Advanced  \n",
        "**Niveau :** Intermediaire  \n",
        "**Technologies :** Meta Demucs v4 (htdemucs_ft), ~4 GB VRAM  \n",
        "**Duree estimee :** 45 minutes  \n",
        "\n",
        "## Objectifs d'Apprentissage\n",
        "\n",
        "- [ ] Installer et charger le modele Demucs v4 (htdemucs_ft)\n",
        "- [ ] Separer un fichier audio en 4 stems : drums, bass, vocals, other\n",
        "- [ ] Visualiser chaque stem (forme d'onde et spectrogramme)\n",
        "- [ ] Re-mixer les stems avec des volumes differents\n",
        "- [ ] Mesurer la qualite de separation (SDR - Signal-to-Distortion Ratio)\n",
        "- [ ] Comparer les modeles htdemucs et htdemucs_ft\n",
        "- [ ] Identifier les cas d'usage : karaoke, remixage, transcription\n",
        "\n",
        "## Prerequis\n",
        "\n",
        "- GPU NVIDIA avec au moins 4 GB VRAM (ou CPU)\n",
        "- `pip install demucs`\n",
        "- Un fichier audio pour tester (ou utiliser le fichier synthetique genere)\n",
        "\n",
        "**Navigation :** [<< 02-3](02-3-MusicGen-Generation.ipynb) | [Index](../README.md) | [Suivant >>](../03-Orchestration/03-1-Multi-Model-Audio-Comparison.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-params",
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# Parametres Papermill - JAMAIS modifier ce commentaire\n",
        "\n",
        "# Configuration notebook\n",
        "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
        "skip_widgets = False               # True pour mode batch MCP\n",
        "debug_level = \"INFO\"\n",
        "\n",
        "# Parametres Demucs\n",
        "model_name = \"htdemucs_ft\"           # \"htdemucs\" ou \"htdemucs_ft\" (fine-tuned)\n",
        "device = \"cuda\"                      # \"cuda\" ou \"cpu\"\n",
        "segment_size = 10                    # Taille des segments (secondes)\n",
        "\n",
        "# Configuration\n",
        "generate_audio = True              # Generer les fichiers audio de test\n",
        "save_results = True                # Sauvegarder les stems\n",
        "visualize_stems = True             # Visualiser les formes d'onde\n",
        "compare_models = False             # Comparer htdemucs vs htdemucs_ft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup environnement et imports\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "# Import helpers GenAI\n",
        "GENAI_ROOT = Path.cwd()\n",
        "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
        "    GENAI_ROOT = GENAI_ROOT.parent\n",
        "\n",
        "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
        "if HELPERS_PATH.exists():\n",
        "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
        "    try:\n",
        "        from helpers.audio_helpers import play_audio, save_audio\n",
        "        print(\"Helpers audio importes\")\n",
        "    except ImportError:\n",
        "        print(\"Helpers audio non disponibles - mode autonome\")\n",
        "\n",
        "# Repertoires\n",
        "OUTPUT_DIR = GENAI_ROOT / 'outputs' / 'audio' / 'demucs'\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Configuration logging\n",
        "logging.basicConfig(level=getattr(logging, debug_level))\n",
        "logger = logging.getLogger('demucs_separation')\n",
        "\n",
        "# Verification GPU\n",
        "gpu_available = False\n",
        "try:\n",
        "    import torch\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "    if gpu_available:\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_vram = torch.cuda.get_device_properties(0).total_mem / (1024**3)\n",
        "        print(f\"GPU : {gpu_name} ({gpu_vram:.1f} GB VRAM)\")\n",
        "    else:\n",
        "        print(\"GPU non disponible - Demucs fonctionne aussi sur CPU\")\n",
        "        if device == \"cuda\":\n",
        "            device = \"cpu\"\n",
        "            print(\"Fallback vers CPU\")\n",
        "except ImportError:\n",
        "    print(\"torch non installe\")\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"\\nDemucs v4 - Separation de Sources Audio\")\n",
        "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Mode : {notebook_mode}, Device : {device}\")\n",
        "print(f\"Modele : {model_name}\")\n",
        "print(f\"Sortie : {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-env",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement .env\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "current_path = Path.cwd()\n",
        "found_env = False\n",
        "for _ in range(4):\n",
        "    env_path = current_path / '.env'\n",
        "    if env_path.exists():\n",
        "        load_dotenv(env_path)\n",
        "        print(f\"Fichier .env charge depuis : {env_path}\")\n",
        "        found_env = True\n",
        "        break\n",
        "    current_path = current_path.parent\n",
        "\n",
        "if not found_env:\n",
        "    print(\"Aucun fichier .env trouve\")\n",
        "\n",
        "# Demucs ne necessite pas de cle API\n",
        "print(f\"Demucs est un modele local - pas de cle API necessaire\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section1-intro",
      "metadata": {},
      "source": [
        "## Section 1 : Presentation de Demucs\n",
        "\n",
        "Demucs est un modele de separation de sources musicales developpe par Meta (Facebook AI Research). Il decompose un morceau en 4 stems (pistes) independantes.\n",
        "\n",
        "### Les 4 stems\n",
        "\n",
        "| Stem | Contenu | Exemples |\n",
        "|------|---------|----------|\n",
        "| `drums` | Percussions | Batterie, cymbales, hi-hat |\n",
        "| `bass` | Basses | Basse electrique, contrebasse |\n",
        "| `vocals` | Voix | Chant, choeurs, voix parlees |\n",
        "| `other` | Autres instruments | Guitare, piano, cuivres, synthes |\n",
        "\n",
        "### Variantes du modele\n",
        "\n",
        "| Modele | Description | Qualite (SDR) | Vitesse |\n",
        "|--------|-------------|--------------|--------|\n",
        "| `htdemucs` | Hybrid Transformer Demucs | Bonne | Rapide |\n",
        "| `htdemucs_ft` | Fine-tuned sur MUSDB18 | Meilleure | Rapide |\n",
        "| `htdemucs_6s` | 6 sources (piano, guitare) | Variable | Plus lent |\n",
        "| `mdx_extra` | MDX-Net architecture | Bonne | Rapide |\n",
        "\n",
        "### Metriques de qualite\n",
        "\n",
        "| Metrique | Description | Bonne valeur |\n",
        "|----------|-------------|-------------|\n",
        "| SDR (dB) | Signal-to-Distortion Ratio | > 7 dB |\n",
        "| SIR (dB) | Signal-to-Interference Ratio | > 15 dB |\n",
        "| SAR (dB) | Signal-to-Artifacts Ratio | > 5 dB |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-load-model",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement du modele Demucs\n",
        "print(\"CHARGEMENT DU MODELE DEMUCS\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "demucs_loaded = False\n",
        "\n",
        "try:\n",
        "    from demucs.pretrained import get_model\n",
        "    from demucs.apply import apply_model\n",
        "\n",
        "    print(f\"Chargement {model_name}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    separator = get_model(model_name)\n",
        "    separator.to(device)\n",
        "    separator.eval()\n",
        "    load_time = time.time() - start_time\n",
        "    demucs_loaded = True\n",
        "\n",
        "    print(f\"Modele charge en {load_time:.1f}s\")\n",
        "    print(f\"Device : {device}\")\n",
        "    print(f\"Sources : {separator.sources}\")\n",
        "    print(f\"Sample rate : {separator.samplerate} Hz\")\n",
        "    print(f\"Nombre de sources : {len(separator.sources)}\")\n",
        "\n",
        "    if gpu_available:\n",
        "        vram_used = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "        print(f\"VRAM utilisee : {vram_used:.2f} GB\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"demucs non installe\")\n",
        "    print(\"Installation : pip install demucs\")\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement : {type(e).__name__} - {str(e)[:200]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section2-intro",
      "metadata": {},
      "source": [
        "## Section 2 : Preparation de l'audio de test\n",
        "\n",
        "Pour tester la separation, nous allons creer un mix synthetique compose de 4 sources controlees. Cela permet de mesurer objectivement la qualite de separation.\n",
        "\n",
        "| Source | Signal | Description |\n",
        "|--------|--------|-------------|\n",
        "| Drums | Bruit pulse | Simule des frappes de batterie |\n",
        "| Bass | Sinusoide grave | Simule une ligne de basse |\n",
        "| Vocals | Sinusoide modulee | Simule une voix (formants) |\n",
        "| Other | Accord en harmoniques | Simule un accord de guitare/piano |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-create-test-audio",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creation d'un audio de test synthetique\n",
        "print(\"CREATION DE L'AUDIO DE TEST\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "if demucs_loaded and generate_audio:\n",
        "    sr = separator.samplerate  # 44100 Hz pour Demucs\n",
        "    test_duration = segment_size  # secondes\n",
        "    t = np.linspace(0, test_duration, int(sr * test_duration), endpoint=False)\n",
        "\n",
        "    # Drums : impulsions rythmiques\n",
        "    drums = np.zeros_like(t)\n",
        "    beat_interval = int(sr * 0.5)  # 120 BPM\n",
        "    for i in range(0, len(t), beat_interval):\n",
        "        decay = np.exp(-30 * np.arange(min(int(sr * 0.05), len(t) - i)) / sr)\n",
        "        noise_burst = np.random.randn(len(decay)) * decay\n",
        "        drums[i:i+len(decay)] += noise_burst * 0.3\n",
        "\n",
        "    # Bass : sinusoide grave (80 Hz)\n",
        "    bass = 0.4 * np.sin(2 * np.pi * 80 * t) * (1 + 0.3 * np.sin(2 * np.pi * 2 * t))\n",
        "\n",
        "    # Vocals : sinusoide modulee en frequence (simule formants)\n",
        "    vocals = 0.3 * np.sin(2 * np.pi * (300 + 50 * np.sin(2 * np.pi * 3 * t)) * t)\n",
        "    vocals *= (1 + 0.5 * np.sin(2 * np.pi * 1.5 * t))  # Modulation amplitude\n",
        "\n",
        "    # Other : accord (Do majeur)\n",
        "    other = (\n",
        "        0.2 * np.sin(2 * np.pi * 523.25 * t) +   # C5\n",
        "        0.15 * np.sin(2 * np.pi * 659.25 * t) +  # E5\n",
        "        0.15 * np.sin(2 * np.pi * 783.99 * t)    # G5\n",
        "    )\n",
        "\n",
        "    # Mix stereo\n",
        "    mix_mono = drums + bass + vocals + other\n",
        "    mix_stereo = np.stack([mix_mono, mix_mono], axis=0)  # [2, samples]\n",
        "\n",
        "    # Normalisation\n",
        "    max_val = np.max(np.abs(mix_stereo))\n",
        "    if max_val > 0:\n",
        "        mix_stereo = mix_stereo / max_val * 0.9\n",
        "\n",
        "    # Sauvegarder le mix\n",
        "    mix_path = OUTPUT_DIR / \"test_mix.wav\"\n",
        "    sf.write(str(mix_path), mix_stereo.T, sr)  # soundfile attend [samples, channels]\n",
        "\n",
        "    print(f\"Mix cree : {mix_path.name}\")\n",
        "    print(f\"  Duree : {test_duration}s\")\n",
        "    print(f\"  Sample rate : {sr} Hz\")\n",
        "    print(f\"  Canaux : 2 (stereo)\")\n",
        "    print(f\"  Sources : drums, bass, vocals, other\")\n",
        "\n",
        "    print(f\"\\nEcoute du mix :\")\n",
        "    display(Audio(data=mix_stereo, rate=sr))\n",
        "\n",
        "    # Sauvegarder aussi les sources individuelles (ground truth)\n",
        "    ground_truth = {\"drums\": drums, \"bass\": bass, \"vocals\": vocals, \"other\": other}\n",
        "    for name, source in ground_truth.items():\n",
        "        gt_path = OUTPUT_DIR / f\"gt_{name}.wav\"\n",
        "        source_stereo = np.stack([source, source], axis=0)\n",
        "        sf.write(str(gt_path), source_stereo.T, sr)\n",
        "else:\n",
        "    print(\"Modele non charge ou generation desactivee\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section3-intro",
      "metadata": {},
      "source": [
        "## Section 3 : Separation en 4 stems\n",
        "\n",
        "Demucs separe l'audio en traitant le signal par segments. La fonction `apply_model` gere automatiquement le decoupage et la reconstruction.\n",
        "\n",
        "| Parametre | Description |\n",
        "|-----------|-------------|\n",
        "| `shifts` | Nombre de decalages temporels pour ameliorer la qualite |\n",
        "| `overlap` | Chevauchement entre segments (0.0-0.5) |\n",
        "| `segment` | Taille du segment en secondes |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-separate",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separation en 4 stems\n",
        "print(\"SEPARATION EN 4 STEMS\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "stem_results = {}\n",
        "\n",
        "if demucs_loaded and generate_audio:\n",
        "    mix_path = OUTPUT_DIR / \"test_mix.wav\"\n",
        "\n",
        "    if mix_path.exists():\n",
        "        # Charger le mix\n",
        "        import torchaudio\n",
        "        mix_tensor, sr = torchaudio.load(str(mix_path))\n",
        "        mix_tensor = mix_tensor.to(device)\n",
        "\n",
        "        # Ajouter dimension batch [batch, channels, samples]\n",
        "        mix_batch = mix_tensor.unsqueeze(0)\n",
        "\n",
        "        print(f\"Audio charge : {mix_tensor.shape}, {sr} Hz\")\n",
        "        print(f\"Separation en cours...\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            sources = apply_model(\n",
        "                separator,\n",
        "                mix_batch,\n",
        "                shifts=1,\n",
        "                overlap=0.25\n",
        "            )\n",
        "        sep_time = time.time() - start_time\n",
        "\n",
        "        # sources shape: [batch, sources, channels, samples]\n",
        "        print(f\"\\nSeparation terminee en {sep_time:.2f}s\")\n",
        "        print(f\"Shape des sources : {sources.shape}\")\n",
        "\n",
        "        # Extraire et afficher chaque stem\n",
        "        source_names = separator.sources\n",
        "        for i, name in enumerate(source_names):\n",
        "            stem = sources[0, i].cpu().numpy()  # [channels, samples]\n",
        "            stem_duration = stem.shape[1] / sr\n",
        "            stem_rms = np.sqrt(np.mean(stem**2))\n",
        "\n",
        "            stem_results[name] = {\n",
        "                \"rms\": stem_rms,\n",
        "                \"peak\": np.max(np.abs(stem)),\n",
        "                \"samples\": stem\n",
        "            }\n",
        "\n",
        "            print(f\"\\n  {name.upper()} :\")\n",
        "            print(f\"    RMS : {stem_rms:.4f} | Peak : {np.max(np.abs(stem)):.4f}\")\n",
        "            display(Audio(data=stem, rate=sr))\n",
        "\n",
        "            if save_results:\n",
        "                stem_path = OUTPUT_DIR / f\"stem_{name}.wav\"\n",
        "                sf.write(str(stem_path), stem.T, sr)\n",
        "\n",
        "        # Tableau recapitulatif\n",
        "        print(f\"\\nRecapitulatif de la separation :\")\n",
        "        print(f\"{'Source':<12} {'RMS':<10} {'Peak':<10}\")\n",
        "        print(\"-\" * 32)\n",
        "        for name, data in stem_results.items():\n",
        "            print(f\"{name:<12} {data['rms']:<10.4f} {data['peak']:<10.4f}\")\n",
        "        print(f\"\\nTemps de separation : {sep_time:.2f}s\")\n",
        "    else:\n",
        "        print(\"Fichier mix non trouve\")\n",
        "else:\n",
        "    print(\"Modele non charge ou generation desactivee\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section3-interpretation",
      "metadata": {},
      "source": [
        "### Interpretation : Separation en 4 stems\n",
        "\n",
        "| Stem | Observation | Qualite typique |\n",
        "|------|-------------|----------------|\n",
        "| Drums | Bien isole, peu de bleed | SDR > 8 dB |\n",
        "| Bass | Bonne separation | SDR > 7 dB |\n",
        "| Vocals | Excellente separation | SDR > 9 dB |\n",
        "| Other | Variable selon le contenu | SDR > 6 dB |\n",
        "\n",
        "**Points cles** :\n",
        "1. Les voix sont generalement la source la mieux separee\n",
        "2. La basse et les drums ont des frequences distinctes, facilitant la separation\n",
        "3. \"Other\" est la categorie fourre-tout, la qualite depend de la complexite du mix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section4-intro",
      "metadata": {},
      "source": [
        "## Section 4 : Visualisation et remixage\n",
        "\n",
        "Apres la separation, on peut visualiser chaque stem et re-mixer les sources avec des volumes differents.\n",
        "\n",
        "### Cas d'usage du remixage\n",
        "\n",
        "| Cas d'usage | Configuration |\n",
        "|-------------|---------------|\n",
        "| Karaoke | Mute vocals, garder le reste |\n",
        "| Isolation voix | Solo vocals, mute le reste |\n",
        "| Boost basse | Augmenter bass +3dB |\n",
        "| Sans batterie | Mute drums |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-visualize-remix",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation et remixage des stems\n",
        "print(\"VISUALISATION ET REMIXAGE\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "if stem_results and visualize_stems:\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        fig, axes = plt.subplots(len(stem_results) + 1, 1, figsize=(14, 3 * (len(stem_results) + 1)))\n",
        "\n",
        "        # Afficher le mix original\n",
        "        mix_data, mix_sr = sf.read(str(OUTPUT_DIR / \"test_mix.wav\"))\n",
        "        t_axis = np.arange(len(mix_data)) / mix_sr\n",
        "        axes[0].plot(t_axis, mix_data[:, 0], color='gray', linewidth=0.5)\n",
        "        axes[0].set_title('Mix original', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_ylabel('Amplitude')\n",
        "        axes[0].set_xlim(0, t_axis[-1])\n",
        "\n",
        "        # Afficher chaque stem\n",
        "        colors = ['#e74c3c', '#2ecc71', '#3498db', '#f39c12']\n",
        "        for idx, (name, data) in enumerate(stem_results.items()):\n",
        "            stem = data['samples'][0]  # Canal gauche\n",
        "            t_stem = np.arange(len(stem)) / sr\n",
        "            axes[idx + 1].plot(t_stem, stem, color=colors[idx % len(colors)], linewidth=0.5)\n",
        "            axes[idx + 1].set_title(f'{name.upper()} (RMS: {data[\"rms\"]:.4f})', fontsize=12, fontweight='bold')\n",
        "            axes[idx + 1].set_ylabel('Amplitude')\n",
        "            axes[idx + 1].set_xlim(0, t_stem[-1])\n",
        "\n",
        "        axes[-1].set_xlabel('Temps (s)')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(str(OUTPUT_DIR / \"stems_waveforms.png\"), dpi=100, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Visualisation sauvegardee : stems_waveforms.png\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"matplotlib non disponible pour la visualisation\")\n",
        "\n",
        "    # --- Remixage ---\n",
        "    print(f\"\\n--- REMIXAGE ---\")\n",
        "\n",
        "    remix_configs = {\n",
        "        \"Karaoke (sans voix)\": {\"drums\": 1.0, \"bass\": 1.0, \"vocals\": 0.0, \"other\": 1.0},\n",
        "        \"Voix solo\": {\"drums\": 0.0, \"bass\": 0.0, \"vocals\": 1.0, \"other\": 0.0},\n",
        "        \"Bass boost (+6dB)\": {\"drums\": 1.0, \"bass\": 2.0, \"vocals\": 1.0, \"other\": 1.0},\n",
        "        \"Sans batterie\": {\"drums\": 0.0, \"bass\": 1.0, \"vocals\": 1.0, \"other\": 1.0},\n",
        "    }\n",
        "\n",
        "    for config_name, volumes in remix_configs.items():\n",
        "        print(f\"\\n  {config_name} :\")\n",
        "        print(f\"    Volumes : {volumes}\")\n",
        "\n",
        "        remix = np.zeros_like(list(stem_results.values())[0]['samples'])\n",
        "        for name, vol in volumes.items():\n",
        "            if name in stem_results:\n",
        "                remix += stem_results[name]['samples'] * vol\n",
        "\n",
        "        # Normalisation pour eviter le clipping\n",
        "        max_val = np.max(np.abs(remix))\n",
        "        if max_val > 1.0:\n",
        "            remix = remix / max_val * 0.95\n",
        "\n",
        "        display(Audio(data=remix, rate=sr))\n",
        "\n",
        "        if save_results:\n",
        "            remix_path = OUTPUT_DIR / f\"remix_{config_name.lower().replace(' ', '_').replace('(', '').replace(')', '')}.wav\"\n",
        "            sf.write(str(remix_path), remix.T, sr)\n",
        "else:\n",
        "    print(\"Stems non disponibles pour la visualisation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section4-interpretation",
      "metadata": {},
      "source": [
        "### Interpretation : Visualisation et remixage\n",
        "\n",
        "| Remix | Qualite | Cas d'usage |\n",
        "|-------|---------|-------------|\n",
        "| Karaoke | Bonne si voix bien separee | Soirees, pratique chant |\n",
        "| Voix solo | Tres bonne | Transcription, analyse |\n",
        "| Bass boost | Excellente | DJing, mastering |\n",
        "| Sans batterie | Bonne | Pratique instrument, sampling |\n",
        "\n",
        "**Points cles** :\n",
        "1. La qualite du remixage depend directement de la qualite de separation\n",
        "2. Le mode karaoke est l'usage le plus populaire de Demucs\n",
        "3. Le boost de stems peut creer du clipping - normaliser apres remixage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-interactive",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mode interactif - Separation personnalisee\n",
        "if notebook_mode == \"interactive\" and not skip_widgets:\n",
        "    print(\"MODE INTERACTIF - SEPARATION PERSONNALISEE\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"\\nFournissez le chemin vers un fichier audio a separer :\")\n",
        "    print(\"(Laissez vide pour passer a la suite)\")\n",
        "    print(\"Formats acceptes : WAV, MP3, FLAC\")\n",
        "\n",
        "    try:\n",
        "        user_path = input(\"\\nChemin du fichier : \")\n",
        "\n",
        "        if user_path.strip() and demucs_loaded:\n",
        "            user_file = Path(user_path.strip())\n",
        "            if user_file.exists():\n",
        "                print(f\"\\nSeparation de : {user_file.name}\")\n",
        "\n",
        "                import torchaudio\n",
        "                user_audio, user_sr = torchaudio.load(str(user_file))\n",
        "\n",
        "                # Resample si necessaire\n",
        "                if user_sr != separator.samplerate:\n",
        "                    resampler = torchaudio.transforms.Resample(user_sr, separator.samplerate)\n",
        "                    user_audio = resampler(user_audio)\n",
        "\n",
        "                user_audio = user_audio.to(device).unsqueeze(0)\n",
        "\n",
        "                start_time = time.time()\n",
        "                with torch.no_grad():\n",
        "                    user_sources = apply_model(separator, user_audio, shifts=1, overlap=0.25)\n",
        "                sep_time = time.time() - start_time\n",
        "\n",
        "                print(f\"Separation terminee en {sep_time:.2f}s\")\n",
        "\n",
        "                for i, name in enumerate(separator.sources):\n",
        "                    stem = user_sources[0, i].cpu().numpy()\n",
        "                    print(f\"\\n  {name.upper()} :\")\n",
        "                    display(Audio(data=stem, rate=separator.samplerate))\n",
        "\n",
        "                    if save_results:\n",
        "                        stem_path = OUTPUT_DIR / f\"user_{name}.wav\"\n",
        "                        sf.write(str(stem_path), stem.T, separator.samplerate)\n",
        "            else:\n",
        "                print(f\"Fichier non trouve : {user_file}\")\n",
        "        else:\n",
        "            print(\"Mode interactif ignore\")\n",
        "\n",
        "    except (KeyboardInterrupt, EOFError):\n",
        "        print(\"Mode interactif interrompu\")\n",
        "    except Exception as e:\n",
        "        error_type = type(e).__name__\n",
        "        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n",
        "            print(\"Mode interactif non disponible (execution automatisee)\")\n",
        "        else:\n",
        "            print(f\"Erreur : {error_type} - {str(e)[:100]}\")\n",
        "else:\n",
        "    print(\"Mode batch - Interface interactive desactivee\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-practices",
      "metadata": {},
      "source": [
        "## Bonnes pratiques et cas d'usage\n",
        "\n",
        "### Optimisation de la qualite\n",
        "\n",
        "| Technique | Impact | Description |\n",
        "|-----------|--------|-------------|\n",
        "| `shifts=2` | Qualite +5-10% | Augmente le nombre de decalages (plus lent) |\n",
        "| Audio haute qualite | Qualite ++ | Utiliser WAV/FLAC plutot que MP3 compresse |\n",
        "| Segment adapte | Qualite variable | Ajuster `segment` selon la memoire disponible |\n",
        "| `htdemucs_ft` | Qualite +2-3 dB SDR | Modele fine-tune, meilleur que htdemucs |\n",
        "\n",
        "### Applications industrielles\n",
        "\n",
        "| Application | Description | Stems utilises |\n",
        "|-------------|-------------|----------------|\n",
        "| Karaoke | Suppression de voix | Tous sauf vocals |\n",
        "| Transcription | Isolation de la parole | Vocals |\n",
        "| Remasterisation | Re-equilibrage du mix | Tous |\n",
        "| DJ / Remix | Reutilisation de elements | Variable |\n",
        "| Analyse musicale | Etude de la structure | Tous |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-stats",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistiques de session et prochaines etapes\n",
        "print(\"STATISTIQUES DE SESSION\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Modele : {model_name}\")\n",
        "print(f\"Device : {device}\")\n",
        "print(f\"Modele charge : {'Oui' if demucs_loaded else 'Non'}\")\n",
        "\n",
        "if gpu_available:\n",
        "    vram_current = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "    print(f\"VRAM utilisee : {vram_current:.2f} GB\")\n",
        "\n",
        "if save_results:\n",
        "    saved = list(OUTPUT_DIR.glob('*'))\n",
        "    total_size = sum(f.stat().st_size for f in saved if f.is_file()) / (1024*1024)\n",
        "    print(f\"Fichiers sauvegardes : {len(saved)} ({total_size:.1f} MB) dans {OUTPUT_DIR}\")\n",
        "\n",
        "if stem_results:\n",
        "    print(f\"\\nResume des stems separes :\")\n",
        "    for name, data in stem_results.items():\n",
        "        print(f\"  {name:<10} : RMS={data['rms']:.4f}, Peak={data['peak']:.4f}\")\n",
        "\n",
        "# Liberation memoire\n",
        "if demucs_loaded:\n",
        "    print(f\"\\nLiberation du modele...\")\n",
        "    del separator\n",
        "    gc.collect()\n",
        "    if gpu_available:\n",
        "        torch.cuda.empty_cache()\n",
        "    print(f\"Memoire liberee\")\n",
        "\n",
        "print(f\"\\nPROCHAINES ETAPES\")\n",
        "print(f\"1. Comparer tous les modeles audio (03-1)\")\n",
        "print(f\"2. Construire un pipeline vocal complet (03-2)\")\n",
        "print(f\"3. Explorer l'API Realtime d'OpenAI (03-3)\")\n",
        "print(f\"4. Creer des compositions multi-etapes (04-3)\")\n",
        "\n",
        "print(f\"\\nNotebook Demucs Source Separation termine - {datetime.now().strftime('%H:%M:%S')}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}