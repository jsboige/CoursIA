{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-header",
      "metadata": {},
      "source": [
        "# MusicGen - Generation Musicale par IA\n",
        "\n",
        "**Module :** 02-Audio-Advanced  \n",
        "**Niveau :** Intermediaire  \n",
        "**Technologies :** Meta MusicGen (AudioCraft), ~10 GB VRAM  \n",
        "**Duree estimee :** 45 minutes  \n",
        "\n",
        "## Objectifs d'Apprentissage\n",
        "\n",
        "- [ ] Installer et charger MusicGen depuis la bibliotheque AudioCraft\n",
        "- [ ] Generer de la musique a partir de descriptions textuelles\n",
        "- [ ] Utiliser le melody conditioning (melodie de reference + description)\n",
        "- [ ] Maitriser les parametres de generation (temperature, top_k, top_p)\n",
        "- [ ] Controler la duree des morceaux generes\n",
        "- [ ] Comparer les modeles small, medium et large\n",
        "- [ ] Experimenter avec des descriptions en francais\n",
        "\n",
        "## Prerequis\n",
        "\n",
        "- GPU NVIDIA avec au moins 10 GB VRAM (medium), 4 GB (small)\n",
        "- `pip install audiocraft`\n",
        "- Connaissances de base en traitement audio\n",
        "\n",
        "**Navigation :** [<< 02-2](02-2-XTTS-Voice-Cloning.ipynb) | [Index](../README.md) | [Suivant >>](02-4-Demucs-Source-Separation.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-params",
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# Parametres Papermill - JAMAIS modifier ce commentaire\n",
        "\n",
        "# Configuration notebook\n",
        "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
        "skip_widgets = False               # True pour mode batch MCP\n",
        "debug_level = \"INFO\"\n",
        "\n",
        "# Parametres MusicGen\n",
        "model_size = \"facebook/musicgen-medium\"  # small, medium ou large\n",
        "duration_seconds = 10                     # Duree de generation (secondes)\n",
        "device = \"cuda\"                           # \"cuda\" ou \"cpu\"\n",
        "temperature = 1.0                         # Temperature de sampling (0.5-1.5)\n",
        "\n",
        "# Configuration\n",
        "generate_audio = True              # Generer les fichiers audio\n",
        "save_results = True                # Sauvegarder les fichiers generes\n",
        "test_melody_conditioning = True    # Tester le melody conditioning\n",
        "compare_models = False             # Comparer small/medium (necessite plus de VRAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup environnement et imports\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "# Import helpers GenAI\n",
        "GENAI_ROOT = Path.cwd()\n",
        "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
        "    GENAI_ROOT = GENAI_ROOT.parent\n",
        "\n",
        "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
        "if HELPERS_PATH.exists():\n",
        "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
        "    try:\n",
        "        from helpers.audio_helpers import play_audio, save_audio\n",
        "        print(\"Helpers audio importes\")\n",
        "    except ImportError:\n",
        "        print(\"Helpers audio non disponibles - mode autonome\")\n",
        "\n",
        "# Repertoires\n",
        "OUTPUT_DIR = GENAI_ROOT / 'outputs' / 'audio' / 'musicgen'\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Configuration logging\n",
        "logging.basicConfig(level=getattr(logging, debug_level))\n",
        "logger = logging.getLogger('musicgen')\n",
        "\n",
        "# Verification GPU\n",
        "gpu_available = False\n",
        "try:\n",
        "    import torch\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "    if gpu_available:\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_vram = torch.cuda.get_device_properties(0).total_mem / (1024**3)\n",
        "        print(f\"GPU : {gpu_name} ({gpu_vram:.1f} GB VRAM)\")\n",
        "    else:\n",
        "        print(\"GPU non disponible - MusicGen sera tres lent sur CPU\")\n",
        "        if device == \"cuda\":\n",
        "            device = \"cpu\"\n",
        "            print(\"Fallback vers CPU\")\n",
        "except ImportError:\n",
        "    print(\"torch non installe\")\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"\\nMusicGen - Generation Musicale par IA\")\n",
        "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Mode : {notebook_mode}, Device : {device}\")\n",
        "print(f\"Modele : {model_size}, Duree : {duration_seconds}s\")\n",
        "print(f\"Temperature : {temperature}\")\n",
        "print(f\"Sortie : {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-env",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement .env\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "current_path = Path.cwd()\n",
        "found_env = False\n",
        "for _ in range(4):\n",
        "    env_path = current_path / '.env'\n",
        "    if env_path.exists():\n",
        "        load_dotenv(env_path)\n",
        "        print(f\"Fichier .env charge depuis : {env_path}\")\n",
        "        found_env = True\n",
        "        break\n",
        "    current_path = current_path.parent\n",
        "\n",
        "if not found_env:\n",
        "    print(\"Aucun fichier .env trouve\")\n",
        "\n",
        "# MusicGen ne necessite pas de cle API\n",
        "# HuggingFace token utile pour le telechargement\n",
        "hf_token = os.getenv('HUGGINGFACE_TOKEN') or os.getenv('HF_TOKEN')\n",
        "if hf_token:\n",
        "    print(f\"Token HuggingFace disponible\")\n",
        "else:\n",
        "    print(f\"Token HuggingFace non disponible (telechargement public uniquement)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section1-intro",
      "metadata": {},
      "source": [
        "## Section 1 : Presentation de MusicGen\n",
        "\n",
        "MusicGen est un modele de generation musicale developpe par Meta dans le cadre du projet AudioCraft. Il genere de la musique mono-source de haute qualite a partir de descriptions textuelles.\n",
        "\n",
        "### Variantes disponibles\n",
        "\n",
        "| Modele | Parametres | VRAM | Qualite | Vitesse |\n",
        "|--------|-----------|------|---------|--------|\n",
        "| `musicgen-small` | 300M | ~4 GB | Bonne | Rapide |\n",
        "| `musicgen-medium` | 1.5B | ~10 GB | Tres bonne | Moyen |\n",
        "| `musicgen-large` | 3.3B | ~20 GB | Excellente | Lent |\n",
        "| `musicgen-melody` | 1.5B | ~10 GB | Tres bonne | Moyen |\n",
        "\n",
        "### Modes de generation\n",
        "\n",
        "| Mode | Description | Modele requis |\n",
        "|------|-------------|---------------|\n",
        "| Text-to-music | Description textuelle -> musique | Tous |\n",
        "| Melody conditioning | Melodie de reference + description -> musique | musicgen-melody |\n",
        "| Continuation | Continuer un morceau existant | Tous |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-load-model",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement du modele MusicGen\n",
        "print(\"CHARGEMENT DU MODELE MUSICGEN\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "musicgen_loaded = False\n",
        "\n",
        "try:\n",
        "    from audiocraft.models import MusicGen\n",
        "\n",
        "    print(f\"Chargement {model_size}...\")\n",
        "    print(f\"(Premier lancement : telechargement du modele)\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    musicgen = MusicGen.get_pretrained(model_size)\n",
        "    load_time = time.time() - start_time\n",
        "    musicgen_loaded = True\n",
        "\n",
        "    # Configuration de la generation\n",
        "    musicgen.set_generation_params(\n",
        "        duration=duration_seconds,\n",
        "        temperature=temperature,\n",
        "        top_k=250,\n",
        "        top_p=0.0,       # Desactive si top_k > 0\n",
        "        cfg_coef=3.0     # Classifier-free guidance\n",
        "    )\n",
        "\n",
        "    print(f\"Modele charge en {load_time:.1f}s\")\n",
        "    print(f\"Sample rate : {musicgen.sample_rate} Hz\")\n",
        "    print(f\"Duree configuree : {duration_seconds}s\")\n",
        "\n",
        "    if gpu_available:\n",
        "        vram_used = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "        print(f\"VRAM utilisee : {vram_used:.2f} GB\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"audiocraft non installe\")\n",
        "    print(\"Installation : pip install audiocraft\")\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement : {type(e).__name__} - {str(e)[:200]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section2-intro",
      "metadata": {},
      "source": [
        "## Section 2 : Generation text-to-music\n",
        "\n",
        "La generation text-to-music est le mode principal de MusicGen. La description textuelle guide le style, les instruments, le tempo et l'ambiance.\n",
        "\n",
        "### Conseils pour les descriptions\n",
        "\n",
        "| Element | Exemples | Impact |\n",
        "|---------|----------|--------|\n",
        "| Genre | jazz, rock, classical, electronic | Style general |\n",
        "| Instruments | piano, guitar, drums, synthesizer | Timbres |\n",
        "| Tempo | slow, medium, fast, 120 BPM | Rythme |\n",
        "| Ambiance | happy, melancholic, energetic, calm | Emotion |\n",
        "| Qualite | high quality, lo-fi, crisp, warm | Production |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-text-to-music",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generation text-to-music\n",
        "print(\"GENERATION TEXT-TO-MUSIC\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "descriptions = [\n",
        "    \"A happy upbeat jazz piece with piano and saxophone, medium tempo\",\n",
        "    \"Calm ambient electronic music with soft pads and gentle arpeggios\",\n",
        "    \"Energetic rock with electric guitar riffs and driving drums, high energy\",\n",
        "]\n",
        "\n",
        "generation_results = {}\n",
        "\n",
        "if musicgen_loaded and generate_audio:\n",
        "    for i, desc in enumerate(descriptions):\n",
        "        print(f\"\\n--- Morceau {i+1} ---\")\n",
        "        print(f\"Description : {desc}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        wav = musicgen.generate([desc])\n",
        "        gen_time = time.time() - start_time\n",
        "\n",
        "        # wav shape: [batch, channels, samples]\n",
        "        samples = wav[0, 0].cpu().numpy()\n",
        "        sample_rate = musicgen.sample_rate\n",
        "        duration = len(samples) / sample_rate\n",
        "\n",
        "        generation_results[f\"morceau_{i+1}\"] = {\n",
        "            \"description\": desc,\n",
        "            \"duration\": duration,\n",
        "            \"gen_time\": gen_time\n",
        "        }\n",
        "\n",
        "        print(f\"  Duree : {duration:.1f}s | Temps de generation : {gen_time:.2f}s\")\n",
        "        print(f\"  Ratio temps reel : {duration / gen_time:.2f}x\")\n",
        "        display(Audio(data=samples, rate=sample_rate))\n",
        "\n",
        "        if save_results:\n",
        "            filepath = OUTPUT_DIR / f\"music_{i+1}_{desc[:30].replace(' ', '_')}.wav\"\n",
        "            sf.write(str(filepath), samples, sample_rate)\n",
        "            print(f\"  Sauvegarde : {filepath.name}\")\n",
        "\n",
        "    # Recapitulatif\n",
        "    print(f\"\\nRecapitulatif des generations :\")\n",
        "    print(f\"{'Morceau':<12} {'Duree (s)':<12} {'Temps gen (s)':<15} {'Description':<40}\")\n",
        "    print(\"-\" * 79)\n",
        "    for name, data in generation_results.items():\n",
        "        print(f\"{name:<12} {data['duration']:<12.1f} {data['gen_time']:<15.2f} {data['description'][:40]}\")\n",
        "else:\n",
        "    print(\"Modele non charge ou generation desactivee\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section2-interpretation",
      "metadata": {},
      "source": [
        "### Interpretation : Generation text-to-music\n",
        "\n",
        "| Aspect | Valeur typique | Signification |\n",
        "|--------|---------------|---------------|\n",
        "| Ratio temps reel | 0.5-2x (GPU) | La generation musicale est plus lente que le TTS |\n",
        "| Qualite audio | 32kHz mono | Qualite correcte pour la musique generee |\n",
        "| Coherence | Bonne | La musique suit generalement bien la description |\n",
        "\n",
        "**Points cles** :\n",
        "1. Les descriptions en anglais donnent de meilleurs resultats (langue d'entrainement)\n",
        "2. Plus la description est precise, plus le resultat est fidele\n",
        "3. La generation est non-deterministe : deux appels donnent des resultats differents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section3-intro",
      "metadata": {},
      "source": [
        "## Section 3 : Parametres de generation\n",
        "\n",
        "Les parametres de sampling influencent la diversite et la qualite de la musique generee.\n",
        "\n",
        "| Parametre | Valeur par defaut | Plage | Impact |\n",
        "|-----------|-------------------|-------|--------|\n",
        "| `temperature` | 1.0 | 0.5-1.5 | Diversite (bas=conservateur, haut=creatif) |\n",
        "| `top_k` | 250 | 0-1000 | Filtre les k tokens les plus probables |\n",
        "| `top_p` | 0.0 | 0.0-1.0 | Nucleus sampling (0 = desactive) |\n",
        "| `cfg_coef` | 3.0 | 1.0-10.0 | Fidelite a la description (haut=plus fidele) |\n",
        "| `duration` | 10 | 1-30 | Duree en secondes |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-parameters-test",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test des parametres de generation\n",
        "print(\"TEST DES PARAMETRES\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "test_description = \"A gentle classical piano melody, slow tempo, emotional\"\n",
        "\n",
        "temperatures = [0.5, 0.8, 1.0, 1.2]\n",
        "param_results = {}\n",
        "\n",
        "if musicgen_loaded and generate_audio:\n",
        "    print(f\"Description : {test_description}\")\n",
        "    print(f\"Duree : {duration_seconds}s\")\n",
        "\n",
        "    for temp in temperatures:\n",
        "        print(f\"\\nTemperature = {temp}\")\n",
        "\n",
        "        musicgen.set_generation_params(\n",
        "            duration=duration_seconds,\n",
        "            temperature=temp,\n",
        "            top_k=250,\n",
        "            top_p=0.0,\n",
        "            cfg_coef=3.0\n",
        "        )\n",
        "\n",
        "        start_time = time.time()\n",
        "        wav = musicgen.generate([test_description])\n",
        "        gen_time = time.time() - start_time\n",
        "\n",
        "        samples = wav[0, 0].cpu().numpy()\n",
        "        sample_rate = musicgen.sample_rate\n",
        "        duration = len(samples) / sample_rate\n",
        "\n",
        "        # Mesure de la dynamique (indicateur indirect de diversite)\n",
        "        rms = np.sqrt(np.mean(samples**2))\n",
        "        peak = np.max(np.abs(samples))\n",
        "        dynamic_range = 20 * np.log10(peak / (rms + 1e-10))\n",
        "\n",
        "        param_results[temp] = {\n",
        "            \"gen_time\": gen_time,\n",
        "            \"rms\": rms,\n",
        "            \"dynamic_range\": dynamic_range\n",
        "        }\n",
        "\n",
        "        print(f\"  Temps : {gen_time:.2f}s | RMS : {rms:.4f} | Dynamic range : {dynamic_range:.1f} dB\")\n",
        "        display(Audio(data=samples, rate=sample_rate))\n",
        "\n",
        "        if save_results:\n",
        "            filepath = OUTPUT_DIR / f\"temp_{temp:.1f}.wav\"\n",
        "            sf.write(str(filepath), samples, sample_rate)\n",
        "\n",
        "    # Restaurer les parametres par defaut\n",
        "    musicgen.set_generation_params(\n",
        "        duration=duration_seconds,\n",
        "        temperature=temperature,\n",
        "        top_k=250,\n",
        "        top_p=0.0,\n",
        "        cfg_coef=3.0\n",
        "    )\n",
        "\n",
        "    # Tableau recapitulatif\n",
        "    print(f\"\\nRecapitulatif :\")\n",
        "    print(f\"{'Temperature':<14} {'Temps gen (s)':<15} {'RMS':<10} {'Dyn. range (dB)':<16}\")\n",
        "    print(\"-\" * 55)\n",
        "    for temp, data in param_results.items():\n",
        "        print(f\"{temp:<14.1f} {data['gen_time']:<15.2f} {data['rms']:<10.4f} {data['dynamic_range']:<16.1f}\")\n",
        "else:\n",
        "    print(\"Modele non charge ou generation desactivee\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section3-interpretation",
      "metadata": {},
      "source": [
        "### Interpretation : Parametres de generation\n",
        "\n",
        "| Temperature | Observation | Recommandation |\n",
        "|------------|-------------|----------------|\n",
        "| 0.5 | Conservateur, peu varie | Quand on veut un resultat previsible |\n",
        "| 0.8 | Bon equilibre | Usage general |\n",
        "| 1.0 | Standard, creatif | Exploration, diversite |\n",
        "| 1.2 | Tres creatif, parfois incoherent | Experimentation |\n",
        "\n",
        "**Points cles** :\n",
        "1. La temperature n'affecte pas significativement le temps de generation\n",
        "2. Des temperatures elevees augmentent la diversite mais peuvent reduire la coherence\n",
        "3. Le cfg_coef controle la fidelite a la description (3.0 est un bon defaut)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section4-intro",
      "metadata": {},
      "source": [
        "## Section 4 : Melody conditioning\n",
        "\n",
        "Le melody conditioning permet de fournir une melodie de reference que le modele reproduira avec le style demande dans la description textuelle.\n",
        "\n",
        "| Element | Description |\n",
        "|---------|-------------|\n",
        "| Entree melodie | Audio WAV avec la melodie de base |\n",
        "| Entree texte | Description du style souhaite |\n",
        "| Sortie | Musique combinant la melodie et le style |\n",
        "\n",
        "> **Note** : Le melody conditioning necessite le modele `musicgen-melody` specifique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-melody",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Melody conditioning\n",
        "print(\"MELODY CONDITIONING\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "if musicgen_loaded and generate_audio and test_melody_conditioning:\n",
        "    # Creer une melodie de reference simple (sinusoides)\n",
        "    print(\"Creation d'une melodie de reference synthetique...\")\n",
        "    melody_sr = musicgen.sample_rate\n",
        "    t = np.linspace(0, duration_seconds, int(melody_sr * duration_seconds), endpoint=False)\n",
        "\n",
        "    # Melodie simple : Do-Mi-Sol-Do (arpege de Do majeur)\n",
        "    freqs = [261.63, 329.63, 392.00, 523.25]  # C4, E4, G4, C5\n",
        "    melody_samples = np.zeros_like(t)\n",
        "    note_duration = duration_seconds / len(freqs)\n",
        "    for i, freq in enumerate(freqs):\n",
        "        start_idx = int(i * note_duration * melody_sr)\n",
        "        end_idx = int((i + 1) * note_duration * melody_sr)\n",
        "        note_t = t[start_idx:end_idx]\n",
        "        # Enveloppe ADSR simplifiee\n",
        "        envelope = np.minimum(1.0, (note_t - note_t[0]) * 10) * np.exp(-1.5 * (note_t - note_t[0]))\n",
        "        melody_samples[start_idx:end_idx] = 0.5 * np.sin(2 * np.pi * freq * note_t) * envelope\n",
        "\n",
        "    melody_path = OUTPUT_DIR / \"melody_reference.wav\"\n",
        "    sf.write(str(melody_path), melody_samples, melody_sr)\n",
        "    print(f\"Melodie de reference : {melody_path.name} ({duration_seconds}s)\")\n",
        "    display(Audio(data=melody_samples, rate=melody_sr))\n",
        "\n",
        "    # Chargement du modele melody (si different)\n",
        "    melody_model_name = \"facebook/musicgen-melody\"\n",
        "    if model_size != melody_model_name:\n",
        "        print(f\"\\nChargement du modele melody ({melody_model_name})...\")\n",
        "        try:\n",
        "            melody_model = MusicGen.get_pretrained(melody_model_name)\n",
        "            melody_model.set_generation_params(\n",
        "                duration=duration_seconds,\n",
        "                temperature=temperature\n",
        "            )\n",
        "            melody_model_loaded = True\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur : {str(e)[:100]}\")\n",
        "            print(\"Utilisation du modele principal sans conditioning\")\n",
        "            melody_model_loaded = False\n",
        "    else:\n",
        "        melody_model = musicgen\n",
        "        melody_model_loaded = True\n",
        "\n",
        "    # Generation avec melody conditioning\n",
        "    style_descriptions = [\n",
        "        \"Jazz version with saxophone and piano\",\n",
        "        \"Electronic ambient version with synthesizers and reverb\",\n",
        "    ]\n",
        "\n",
        "    if melody_model_loaded:\n",
        "        import torchaudio\n",
        "        melody_tensor, _ = torchaudio.load(str(melody_path))\n",
        "        melody_tensor = melody_tensor.unsqueeze(0)  # [1, channels, samples]\n",
        "\n",
        "        for i, style in enumerate(style_descriptions):\n",
        "            print(f\"\\nStyle : {style}\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            wav = melody_model.generate_with_chroma(\n",
        "                descriptions=[style],\n",
        "                melody_wavs=melody_tensor,\n",
        "                melody_sample_rate=melody_sr\n",
        "            )\n",
        "\n",
        "            gen_time = time.time() - start_time\n",
        "            samples = wav[0, 0].cpu().numpy()\n",
        "\n",
        "            print(f\"  Temps : {gen_time:.2f}s\")\n",
        "            display(Audio(data=samples, rate=musicgen.sample_rate))\n",
        "\n",
        "            if save_results:\n",
        "                filepath = OUTPUT_DIR / f\"melody_style_{i+1}.wav\"\n",
        "                sf.write(str(filepath), samples, musicgen.sample_rate)\n",
        "\n",
        "        # Liberation modele melody si charge separement\n",
        "        if model_size != melody_model_name:\n",
        "            del melody_model\n",
        "            gc.collect()\n",
        "            if gpu_available:\n",
        "                torch.cuda.empty_cache()\n",
        "    else:\n",
        "        print(\"Modele melody non disponible\")\n",
        "else:\n",
        "    print(\"Melody conditioning desactive ou modele non charge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-section4-interpretation",
      "metadata": {},
      "source": [
        "### Interpretation : Melody conditioning\n",
        "\n",
        "| Aspect | Observation | Signification |\n",
        "|--------|-------------|---------------|\n",
        "| Fidelite melodique | Bonne | La melodie de base est recognaissable |\n",
        "| Adaptation de style | Tres bonne | Les instruments et l'ambiance changent |\n",
        "| Temps de generation | Similaire | Le conditioning n'ajoute pas de surcout majeur |\n",
        "\n",
        "**Points cles** :\n",
        "1. Le melody conditioning extrait le chroma (contenu melodique) de la reference\n",
        "2. L'arrangement et les instruments sont determines par la description textuelle\n",
        "3. Le modele `musicgen-melody` est specifiquement entraine pour cette tache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-interactive",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mode interactif - Generation personnalisee\n",
        "if notebook_mode == \"interactive\" and not skip_widgets:\n",
        "    print(\"MODE INTERACTIF - GENERATION MUSICALE PERSONNALISEE\")\n",
        "    print(\"=\" * 55)\n",
        "    print(\"\\nDecrivez la musique que vous souhaitez generer :\")\n",
        "    print(\"(Laissez vide pour passer a la suite)\")\n",
        "    print(\"Exemple : 'A calm acoustic guitar melody with soft percussion'\")\n",
        "\n",
        "    try:\n",
        "        user_desc = input(\"\\nDescription : \")\n",
        "\n",
        "        if user_desc.strip() and musicgen_loaded:\n",
        "            user_duration = input(f\"Duree [{duration_seconds}s] (1-30) : \").strip()\n",
        "            user_duration = int(user_duration) if user_duration else duration_seconds\n",
        "            user_duration = max(1, min(30, user_duration))\n",
        "\n",
        "            musicgen.set_generation_params(\n",
        "                duration=user_duration,\n",
        "                temperature=temperature,\n",
        "                top_k=250,\n",
        "                cfg_coef=3.0\n",
        "            )\n",
        "\n",
        "            print(f\"\\nGeneration en cours ({user_duration}s)...\")\n",
        "            start_time = time.time()\n",
        "            wav = musicgen.generate([user_desc])\n",
        "            gen_time = time.time() - start_time\n",
        "\n",
        "            samples = wav[0, 0].cpu().numpy()\n",
        "            print(f\"Genere en {gen_time:.2f}s\")\n",
        "            display(Audio(data=samples, rate=musicgen.sample_rate))\n",
        "\n",
        "            if save_results:\n",
        "                ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "                filepath = OUTPUT_DIR / f\"custom_{ts}.wav\"\n",
        "                sf.write(str(filepath), samples, musicgen.sample_rate)\n",
        "                print(f\"Sauvegarde : {filepath.name}\")\n",
        "\n",
        "            # Restaurer la duree par defaut\n",
        "            musicgen.set_generation_params(\n",
        "                duration=duration_seconds,\n",
        "                temperature=temperature,\n",
        "                top_k=250,\n",
        "                cfg_coef=3.0\n",
        "            )\n",
        "        else:\n",
        "            print(\"Mode interactif ignore\")\n",
        "\n",
        "    except (KeyboardInterrupt, EOFError):\n",
        "        print(\"Mode interactif interrompu\")\n",
        "    except Exception as e:\n",
        "        error_type = type(e).__name__\n",
        "        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n",
        "            print(\"Mode interactif non disponible (execution automatisee)\")\n",
        "        else:\n",
        "            print(f\"Erreur : {error_type} - {str(e)[:100]}\")\n",
        "else:\n",
        "    print(\"Mode batch - Interface interactive desactivee\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-practices",
      "metadata": {},
      "source": [
        "## Bonnes pratiques et guide de generation\n",
        "\n",
        "### Rediger de bonnes descriptions\n",
        "\n",
        "| Element | Bon exemple | Mauvais exemple |\n",
        "|---------|------------|----------------|\n",
        "| Genre | \"Smooth jazz with piano\" | \"Jazz\" |\n",
        "| Ambiance | \"Melancholic and introspective\" | \"Triste\" |\n",
        "| Instruments | \"Acoustic guitar, soft drums, double bass\" | \"Guitare\" |\n",
        "| Tempo | \"Slow tempo, around 70 BPM\" | \"Lent\" |\n",
        "\n",
        "### Limites actuelles\n",
        "\n",
        "| Limite | Description | Contournement |\n",
        "|--------|-------------|---------------|\n",
        "| Duree max ~30s | Le modele genere des extraits courts | Concatener plusieurs generations |\n",
        "| Mono uniquement | Pas de stereo natif | Post-traitement avec panning |\n",
        "| Pas de paroles | Genere uniquement de la musique instrumentale | Combiner avec un modele TTS |\n",
        "| Anglais | Les descriptions en anglais sont les plus efficaces | Traduire les descriptions |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-stats",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistiques de session et prochaines etapes\n",
        "print(\"STATISTIQUES DE SESSION\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Modele : {model_size}\")\n",
        "print(f\"Device : {device}\")\n",
        "print(f\"Duree configuree : {duration_seconds}s\")\n",
        "print(f\"Temperature : {temperature}\")\n",
        "print(f\"Modele charge : {'Oui' if musicgen_loaded else 'Non'}\")\n",
        "\n",
        "if gpu_available:\n",
        "    vram_current = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "    print(f\"VRAM utilisee : {vram_current:.2f} GB\")\n",
        "\n",
        "if save_results:\n",
        "    saved = list(OUTPUT_DIR.glob('*.wav'))\n",
        "    total_size = sum(f.stat().st_size for f in saved) / (1024*1024)\n",
        "    print(f\"Fichiers sauvegardes : {len(saved)} ({total_size:.1f} MB) dans {OUTPUT_DIR}\")\n",
        "\n",
        "# Liberation memoire\n",
        "if musicgen_loaded:\n",
        "    print(f\"\\nLiberation du modele...\")\n",
        "    del musicgen\n",
        "    gc.collect()\n",
        "    if gpu_available:\n",
        "        torch.cuda.empty_cache()\n",
        "    print(f\"Memoire liberee\")\n",
        "\n",
        "print(f\"\\nPROCHAINES ETAPES\")\n",
        "print(f\"1. Decouvrir la separation de sources avec Demucs (02-4)\")\n",
        "print(f\"2. Comparer tous les modeles audio (03-1)\")\n",
        "print(f\"3. Construire un pipeline vocal complet (03-2)\")\n",
        "print(f\"4. Creer des compositions multi-etapes (04-3)\")\n",
        "\n",
        "print(f\"\\nNotebook MusicGen termine - {datetime.now().strftime('%H:%M:%S')}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}