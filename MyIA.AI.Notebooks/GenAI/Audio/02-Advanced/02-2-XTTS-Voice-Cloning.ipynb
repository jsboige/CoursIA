{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-header",
   "metadata": {
    "papermill": {
     "duration": 0.002436,
     "end_time": "2026-02-18T09:33:14.787951",
     "exception": false,
     "start_time": "2026-02-18T09:33:14.785515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XTTS v2 - Clonage Vocal Zero-Shot\n",
    "\n",
    "**Module :** 02-Audio-Advanced  \n",
    "**Niveau :** Intermediaire  \n",
    "**Technologies :** Coqui XTTS v2, ~6 GB VRAM  \n",
    "**Duree estimee :** 45 minutes  \n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "- [ ] Installer et charger le modele XTTS v2 depuis Coqui TTS\n",
    "- [ ] Comprendre le clonage vocal zero-shot (pas de fine-tuning)\n",
    "- [ ] Cloner une voix a partir d'un clip audio de reference (~6s)\n",
    "- [ ] Exploiter le support multilingue (17 langues dont le francais)\n",
    "- [ ] Analyser la qualite du clonage (similarite speaker avec resemblyzer)\n",
    "- [ ] Comparer XTTS v2 avec Chatterbox et OpenAI TTS\n",
    "- [ ] Comprendre les enjeux ethiques du clonage vocal\n",
    "\n",
    "## Prerequis\n",
    "\n",
    "- GPU NVIDIA avec au moins 6 GB VRAM\n",
    "- `pip install TTS`\n",
    "- Notebook 02-1 recommande (pour comparaison avec Chatterbox)\n",
    "\n",
    "**Navigation :** [<< 02-1](02-1-Chatterbox-TTS.ipynb) | [Index](../README.md) | [Suivant >>](02-3-MusicGen-Generation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-params",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:33:14.797757Z",
     "iopub.status.busy": "2026-02-18T09:33:14.797472Z",
     "iopub.status.idle": "2026-02-18T09:33:14.803487Z",
     "shell.execute_reply": "2026-02-18T09:33:14.802272Z"
    },
    "papermill": {
     "duration": 0.012944,
     "end_time": "2026-02-18T09:33:14.805079",
     "exception": false,
     "start_time": "2026-02-18T09:33:14.792135",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parametres Papermill - JAMAIS modifier ce commentaire\n",
    "\n",
    "# Configuration notebook\n",
    "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
    "skip_widgets = False               # True pour mode batch MCP\n",
    "debug_level = \"INFO\"\n",
    "\n",
    "# Parametres XTTS\n",
    "model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"  # Modele XTTS v2\n",
    "device = \"cuda\"                     # \"cuda\" ou \"cpu\"\n",
    "language = \"fr\"                     # Langue par defaut\n",
    "\n",
    "# Configuration\n",
    "generate_audio = True              # Generer les fichiers audio\n",
    "save_results = True                # Sauvegarder les fichiers generes\n",
    "test_multilingual = True           # Tester plusieurs langues\n",
    "analyze_similarity = True          # Analyser la similarite vocale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:33:14.815730Z",
     "iopub.status.busy": "2026-02-18T09:33:14.815397Z",
     "iopub.status.idle": "2026-02-18T09:33:16.479930Z",
     "shell.execute_reply": "2026-02-18T09:33:16.478974Z"
    },
    "papermill": {
     "duration": 1.671671,
     "end_time": "2026-02-18T09:33:16.481097",
     "exception": false,
     "start_time": "2026-02-18T09:33:14.809426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers audio importes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU non disponible - XTTS fonctionne aussi sur CPU (lentement)\n",
      "Fallback vers CPU\n",
      "\n",
      "XTTS v2 - Clonage Vocal Zero-Shot\n",
      "Date : 2026-02-18 10:33:16\n",
      "Mode : interactive, Device : cpu\n",
      "Langue : fr\n",
      "Sortie : D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\outputs\\audio\\xtts\n"
     ]
    }
   ],
   "source": [
    "# Setup environnement et imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display, HTML\n",
    "\n",
    "# Import helpers GenAI\n",
    "GENAI_ROOT = Path.cwd()\n",
    "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
    "    GENAI_ROOT = GENAI_ROOT.parent\n",
    "\n",
    "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
    "if HELPERS_PATH.exists():\n",
    "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
    "    try:\n",
    "        from helpers.audio_helpers import play_audio, save_audio\n",
    "        print(\"Helpers audio importes\")\n",
    "    except ImportError:\n",
    "        print(\"Helpers audio non disponibles - mode autonome\")\n",
    "\n",
    "# Repertoires\n",
    "OUTPUT_DIR = GENAI_ROOT / 'outputs' / 'audio' / 'xtts'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuration logging\n",
    "logging.basicConfig(level=getattr(logging, debug_level))\n",
    "logger = logging.getLogger('xtts_cloning')\n",
    "\n",
    "# Verification GPU\n",
    "gpu_available = False\n",
    "try:\n",
    "    import torch\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    if gpu_available:\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_vram = torch.cuda.get_device_properties(0).total_mem / (1024**3)\n",
    "        print(f\"GPU : {gpu_name} ({gpu_vram:.1f} GB VRAM)\")\n",
    "    else:\n",
    "        print(\"GPU non disponible - XTTS fonctionne aussi sur CPU (lentement)\")\n",
    "        if device == \"cuda\":\n",
    "            device = \"cpu\"\n",
    "            print(\"Fallback vers CPU\")\n",
    "except ImportError:\n",
    "    print(\"torch non installe\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"\\nXTTS v2 - Clonage Vocal Zero-Shot\")\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Mode : {notebook_mode}, Device : {device}\")\n",
    "print(f\"Langue : {language}\")\n",
    "print(f\"Sortie : {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-env",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:33:16.489160Z",
     "iopub.status.busy": "2026-02-18T09:33:16.488833Z",
     "iopub.status.idle": "2026-02-18T09:33:16.506126Z",
     "shell.execute_reply": "2026-02-18T09:33:16.505069Z"
    },
    "papermill": {
     "duration": 0.022385,
     "end_time": "2026-02-18T09:33:16.507341",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.484956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier .env charge depuis : D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\.env\n",
      "Token HuggingFace non disponible (telechargement public uniquement)\n"
     ]
    }
   ],
   "source": [
    "# Chargement .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_path = Path.cwd()\n",
    "found_env = False\n",
    "for _ in range(4):\n",
    "    env_path = current_path / '.env'\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"Fichier .env charge depuis : {env_path}\")\n",
    "        found_env = True\n",
    "        break\n",
    "    current_path = current_path.parent\n",
    "\n",
    "if not found_env:\n",
    "    print(\"Aucun fichier .env trouve\")\n",
    "\n",
    "# XTTS ne necessite pas de cle API, mais HuggingFace peut etre utile\n",
    "hf_token = os.getenv('HUGGINGFACE_TOKEN') or os.getenv('HF_TOKEN')\n",
    "if hf_token:\n",
    "    print(f\"Token HuggingFace disponible\")\n",
    "else:\n",
    "    print(f\"Token HuggingFace non disponible (telechargement public uniquement)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependances GPU Optionnelles",
    "",
    "Ce notebook utilise des modeles GPU optionnels. Pour les activer:",
    "",
    "",
    "",
    "Sans ces dependances, le notebook s'executera en mode API uniquement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section1-intro",
   "metadata": {
    "papermill": {
     "duration": 0.00303,
     "end_time": "2026-02-18T09:33:16.513067",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.510037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 1 : Presentation de XTTS v2\n",
    "\n",
    "XTTS v2 (Cross-lingual Text-To-Speech) est le modele phare de Coqui AI. Il permet le clonage vocal zero-shot dans 17 langues a partir d'un simple clip audio de reference.\n",
    "\n",
    "### Langues supportees\n",
    "\n",
    "| Code | Langue | Code | Langue |\n",
    "|------|--------|------|--------|\n",
    "| `en` | Anglais | `fr` | Francais |\n",
    "| `es` | Espagnol | `de` | Allemand |\n",
    "| `it` | Italien | `pt` | Portugais |\n",
    "| `pl` | Polonais | `tr` | Turc |\n",
    "| `ru` | Russe | `nl` | Neerlandais |\n",
    "| `cs` | Tcheque | `ar` | Arabe |\n",
    "| `zh` | Chinois | `ja` | Japonais |\n",
    "| `ko` | Coreen | `hu` | Hongrois |\n",
    "| `hi` | Hindi | | |\n",
    "\n",
    "### Comparaison avec les autres modeles\n",
    "\n",
    "| Aspect | XTTS v2 | Chatterbox | OpenAI TTS |\n",
    "|--------|---------|-----------|------------|\n",
    "| Clonage vocal | Zero-shot (6s) | Voice conditioning | Non |\n",
    "| Langues | 17 | Anglais | Multilingue |\n",
    "| VRAM | ~6 GB | ~8 GB | N/A |\n",
    "| Licence | CPML (non-commercial) | MIT | Proprietaire |\n",
    "| Qualite | Tres bonne | Bonne (expressif) | Excellente |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-load-model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:33:16.519009Z",
     "iopub.status.busy": "2026-02-18T09:33:16.518441Z",
     "iopub.status.idle": "2026-02-18T09:33:16.526232Z",
     "shell.execute_reply": "2026-02-18T09:33:16.524972Z"
    },
    "papermill": {
     "duration": 0.012613,
     "end_time": "2026-02-18T09:33:16.527900",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.515287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARGEMENT DU MODELE XTTS V2\n",
      "=============================================\n",
      "TTS non installe\n",
      "Installation : pip install TTS\n"
     ]
    }
   ],
   "source": [
    "# Chargement du modele XTTS v2\n",
    "print(\"CHARGEMENT DU MODELE XTTS V2\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "xtts_loaded = False\n",
    "\n",
    "try:\n",
    "    from TTS.api import TTS\n",
    "\n",
    "    print(f\"Chargement {model_name}...\")\n",
    "    print(f\"(Premier lancement : telechargement du modele ~1.8 GB)\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    tts = TTS(model_name=model_name).to(device)\n",
    "    load_time = time.time() - start_time\n",
    "    xtts_loaded = True\n",
    "\n",
    "    print(f\"Modele charge en {load_time:.1f}s\")\n",
    "    print(f\"Device : {device}\")\n",
    "\n",
    "    if gpu_available:\n",
    "        vram_used = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "        print(f\"VRAM utilisee : {vram_used:.2f} GB\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"TTS non installe\")\n",
    "    print(\"Installation : pip install TTS\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement : {type(e).__name__} - {str(e)[:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section2-intro",
   "metadata": {
    "papermill": {
     "duration": 0.002028,
     "end_time": "2026-02-18T09:33:16.532558",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.530530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 2 : Clonage vocal zero-shot\n",
    "\n",
    "Le clonage zero-shot signifie qu'aucun entrainement supplementaire n'est necessaire. Le modele utilise directement un clip audio (~6s) pour capturer le timbre du locuteur.\n",
    "\n",
    "### Pipeline de clonage\n",
    "\n",
    "| Etape | Description | Detail |\n",
    "|-------|-------------|--------|\n",
    "| 1 | Preparation du clip | WAV, 16-24kHz, ~6s, sans bruit |\n",
    "| 2 | Extraction d'embeddings | Le modele encode les caracteristiques vocales |\n",
    "| 3 | Generation conditionnee | Le texte est synthetise avec le timbre capture |\n",
    "| 4 | Decodage audio | Conversion des tokens en signal audio |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-clone-voice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:33:16.537873Z",
     "iopub.status.busy": "2026-02-18T09:33:16.537517Z",
     "iopub.status.idle": "2026-02-18T09:33:16.543732Z",
     "shell.execute_reply": "2026-02-18T09:33:16.542866Z"
    },
    "papermill": {
     "duration": 0.010237,
     "end_time": "2026-02-18T09:33:16.544872",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.534635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLONAGE VOCAL ZERO-SHOT\n",
      "=============================================\n",
      "Modele non charge ou generation desactivee\n"
     ]
    }
   ],
   "source": [
    "# Clonage vocal zero-shot\n",
    "print(\"CLONAGE VOCAL ZERO-SHOT\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "clone_text_fr = (\n",
    "    \"Bonjour, je suis une voix clonee par le modele XTTS version deux. \"\n",
    "    \"Cette technologie permet de reproduire le timbre d'une voix \"\n",
    "    \"a partir d'un simple enregistrement de quelques secondes.\"\n",
    ")\n",
    "\n",
    "if xtts_loaded and generate_audio:\n",
    "    # Creer un clip de reference synthetique pour la demonstration\n",
    "    # En production, on utiliserait un vrai enregistrement vocal\n",
    "    print(\"Creation d'un clip de reference...\")\n",
    "\n",
    "    ref_path = OUTPUT_DIR / \"reference_speaker.wav\"\n",
    "\n",
    "    # Generer un premier clip comme reference\n",
    "    tts.tts_to_file(\n",
    "        text=\"This is a sample reference voice clip for zero-shot voice cloning.\",\n",
    "        file_path=str(ref_path),\n",
    "        language=\"en\"\n",
    "    )\n",
    "    print(f\"Clip de reference cree : {ref_path.name}\")\n",
    "\n",
    "    ref_data, ref_sr = sf.read(str(ref_path))\n",
    "    print(f\"  Duree : {len(ref_data)/ref_sr:.1f}s, Sample rate : {ref_sr} Hz\")\n",
    "    display(Audio(data=ref_data, rate=ref_sr))\n",
    "\n",
    "    # Clonage avec le clip de reference\n",
    "    print(f\"\\nGeneration avec clonage vocal (langue : {language})...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    output_path = OUTPUT_DIR / \"cloned_voice_fr.wav\"\n",
    "    tts.tts_to_file(\n",
    "        text=clone_text_fr,\n",
    "        file_path=str(output_path),\n",
    "        speaker_wav=str(ref_path),\n",
    "        language=language\n",
    "    )\n",
    "\n",
    "    gen_time = time.time() - start_time\n",
    "\n",
    "    cloned_data, cloned_sr = sf.read(str(output_path))\n",
    "    duration = len(cloned_data) / cloned_sr\n",
    "\n",
    "    print(f\"  Duree : {duration:.1f}s\")\n",
    "    print(f\"  Temps de generation : {gen_time:.2f}s\")\n",
    "    print(f\"  Ratio temps reel : {duration / gen_time:.1f}x\")\n",
    "    display(Audio(data=cloned_data, rate=cloned_sr))\n",
    "else:\n",
    "    print(\"Modele non charge ou generation desactivee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section2-interpretation",
   "metadata": {
    "papermill": {
     "duration": 0.002566,
     "end_time": "2026-02-18T09:33:16.550619",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.548053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Clonage vocal\n",
    "\n",
    "| Aspect | Valeur typique | Signification |\n",
    "|--------|---------------|---------------|\n",
    "| Ratio temps reel | 2-5x (GPU) | Plus lent que Kokoro mais acceptable |\n",
    "| Similarite vocale | Elevee | Le timbre est bien capture en zero-shot |\n",
    "| Qualite francais | Bonne | XTTS supporte nativement le francais |\n",
    "\n",
    "**Points cles** :\n",
    "1. Le clonage zero-shot ne necessite aucun fine-tuning\n",
    "2. La qualite du clip de reference impacte directement le resultat\n",
    "3. Le modele preserve le timbre meme en changeant de langue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section3-intro",
   "metadata": {
    "papermill": {
     "duration": 0.002256,
     "end_time": "2026-02-18T09:33:16.556237",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.553981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 3 : Support multilingue\n",
    "\n",
    "L'un des atouts majeurs de XTTS v2 est le support cross-lingual : on peut cloner une voix dans une langue et generer de la parole dans une autre.\n",
    "\n",
    "| Scenario | Description |\n",
    "|----------|-------------|\n",
    "| Meme langue | Clip en francais, generation en francais |\n",
    "| Cross-lingual | Clip en anglais, generation en francais |\n",
    "| Multi-output | Un meme clip, generation dans plusieurs langues |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-multilingual",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:33:16.563564Z",
     "iopub.status.busy": "2026-02-18T09:33:16.563165Z",
     "iopub.status.idle": "2026-02-18T09:33:16.570515Z",
     "shell.execute_reply": "2026-02-18T09:33:16.569798Z"
    },
    "papermill": {
     "duration": 0.012207,
     "end_time": "2026-02-18T09:33:16.571618",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.559411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MULTILINGUE\n",
      "=============================================\n",
      "Test multilingue desactive ou modele non charge\n"
     ]
    }
   ],
   "source": [
    "# Test multilingue\n",
    "print(\"TEST MULTILINGUE\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "multilingual_texts = {\n",
    "    \"fr\": \"Bonjour, ceci est un test de synthese vocale en francais.\",\n",
    "    \"en\": \"Hello, this is a test of speech synthesis in English.\",\n",
    "    \"es\": \"Hola, esta es una prueba de sintesis de voz en espanol.\",\n",
    "    \"de\": \"Hallo, dies ist ein Test der Sprachsynthese auf Deutsch.\",\n",
    "}\n",
    "\n",
    "multilingual_results = {}\n",
    "\n",
    "if xtts_loaded and generate_audio and test_multilingual:\n",
    "    ref_path = OUTPUT_DIR / \"reference_speaker.wav\"\n",
    "\n",
    "    if not ref_path.exists():\n",
    "        print(\"Clip de reference non disponible - creation...\")\n",
    "        tts.tts_to_file(\n",
    "            text=\"This is a reference clip for multilingual testing.\",\n",
    "            file_path=str(ref_path),\n",
    "            language=\"en\"\n",
    "        )\n",
    "\n",
    "    for lang_code, text in multilingual_texts.items():\n",
    "        print(f\"\\nLangue : {lang_code}\")\n",
    "        print(f\"  Texte : {text}\")\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            out_path = OUTPUT_DIR / f\"multilingual_{lang_code}.wav\"\n",
    "\n",
    "            tts.tts_to_file(\n",
    "                text=text,\n",
    "                file_path=str(out_path),\n",
    "                speaker_wav=str(ref_path),\n",
    "                language=lang_code\n",
    "            )\n",
    "\n",
    "            gen_time = time.time() - start_time\n",
    "            audio_data, sr = sf.read(str(out_path))\n",
    "            duration = len(audio_data) / sr\n",
    "\n",
    "            multilingual_results[lang_code] = {\n",
    "                \"duration\": duration,\n",
    "                \"gen_time\": gen_time,\n",
    "                \"text_len\": len(text)\n",
    "            }\n",
    "\n",
    "            print(f\"  Duree : {duration:.1f}s | Temps : {gen_time:.2f}s\")\n",
    "            display(Audio(data=audio_data, rate=sr))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Erreur : {str(e)[:80]}\")\n",
    "\n",
    "    # Tableau recapitulatif\n",
    "    if multilingual_results:\n",
    "        print(f\"\\nRecapitulatif multilingue :\")\n",
    "        print(f\"{'Langue':<10} {'Duree (s)':<12} {'Temps gen (s)':<15} {'Chars':<8}\")\n",
    "        print(\"-\" * 45)\n",
    "        for lang, data in multilingual_results.items():\n",
    "            print(f\"{lang:<10} {data['duration']:<12.1f} {data['gen_time']:<15.2f} {data['text_len']:<8}\")\n",
    "else:\n",
    "    print(\"Test multilingue desactive ou modele non charge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section3-interpretation",
   "metadata": {
    "papermill": {
     "duration": 0.002486,
     "end_time": "2026-02-18T09:33:16.577459",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.574973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Support multilingue\n",
    "\n",
    "| Langue | Qualite | Observation |\n",
    "|--------|---------|-------------|\n",
    "| Anglais | Excellente | Langue d'entrainement principale |\n",
    "| Francais | Tres bonne | Bonne prononciation et prosodie |\n",
    "| Espagnol | Tres bonne | Accent naturel |\n",
    "| Allemand | Bonne | Phonemes complexes bien geres |\n",
    "\n",
    "**Points cles** :\n",
    "1. Le timbre est preserve d'une langue a l'autre (cross-lingual)\n",
    "2. La qualite varie selon la representation de la langue dans les donnees d'entrainement\n",
    "3. Les langues romanes (fr, es, it, pt) donnent generalement de tres bons resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section4-intro",
   "metadata": {
    "papermill": {
     "duration": 0.002387,
     "end_time": "2026-02-18T09:33:16.582646",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.580259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 4 : Analyse de la qualite du clonage\n",
    "\n",
    "Pour evaluer objectivement la qualite du clonage vocal, on peut utiliser des metriques de similarite entre le locuteur de reference et la voix generee.\n",
    "\n",
    "### Metriques de similarite\n",
    "\n",
    "| Metrique | Description | Plage |\n",
    "|----------|-------------|-------|\n",
    "| Cosine similarity (embeddings) | Distance entre embeddings de speaker | 0-1 (1 = identique) |\n",
    "| MOS (Mean Opinion Score) | Evaluation perceptuelle humaine | 1-5 (5 = excellent) |\n",
    "| Speaker Error Rate (SER) | Taux d'erreur d'identification | 0-100% (0 = parfait) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-similarity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:33:16.589508Z",
     "iopub.status.busy": "2026-02-18T09:33:16.589155Z",
     "iopub.status.idle": "2026-02-18T09:33:16.599698Z",
     "shell.execute_reply": "2026-02-18T09:33:16.598752Z"
    },
    "papermill": {
     "duration": 0.015722,
     "end_time": "2026-02-18T09:33:16.600926",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.585204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYSE DE SIMILARITE VOCALE\n",
      "=============================================\n",
      "Analyse de similarite desactivee ou modele non charge\n"
     ]
    }
   ],
   "source": [
    "# Analyse de similarite vocale\n",
    "print(\"ANALYSE DE SIMILARITE VOCALE\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if xtts_loaded and generate_audio and analyze_similarity:\n",
    "    similarity_available = False\n",
    "\n",
    "    try:\n",
    "        from resemblyzer import VoiceEncoder, preprocess_wav\n",
    "        encoder = VoiceEncoder()\n",
    "        similarity_available = True\n",
    "        print(\"Resemblyzer charge pour l'analyse de similarite\")\n",
    "    except ImportError:\n",
    "        print(\"resemblyzer non installe (pip install resemblyzer)\")\n",
    "        print(\"Analyse de similarite par correlation simple\")\n",
    "\n",
    "    # Charger les fichiers audio\n",
    "    ref_path = OUTPUT_DIR / \"reference_speaker.wav\"\n",
    "    clone_path = OUTPUT_DIR / \"cloned_voice_fr.wav\"\n",
    "\n",
    "    if ref_path.exists() and clone_path.exists():\n",
    "        ref_audio, ref_sr = sf.read(str(ref_path))\n",
    "        clone_audio, clone_sr = sf.read(str(clone_path))\n",
    "\n",
    "        if similarity_available:\n",
    "            # Analyse avec resemblyzer\n",
    "            ref_processed = preprocess_wav(ref_audio, source_sr=ref_sr)\n",
    "            clone_processed = preprocess_wav(clone_audio, source_sr=clone_sr)\n",
    "\n",
    "            ref_embed = encoder.embed_utterance(ref_processed)\n",
    "            clone_embed = encoder.embed_utterance(clone_processed)\n",
    "\n",
    "            # Similarite cosinus\n",
    "            cosine_sim = np.dot(ref_embed, clone_embed) / (\n",
    "                np.linalg.norm(ref_embed) * np.linalg.norm(clone_embed)\n",
    "            )\n",
    "\n",
    "            print(f\"\\nResultats de similarite :\")\n",
    "            print(f\"  Similarite cosinus : {cosine_sim:.4f}\")\n",
    "            print(f\"  Interpretation : \", end=\"\")\n",
    "            if cosine_sim > 0.85:\n",
    "                print(\"Excellent - voix tres similaire\")\n",
    "            elif cosine_sim > 0.75:\n",
    "                print(\"Bon - voix reconnaissable\")\n",
    "            elif cosine_sim > 0.65:\n",
    "                print(\"Moyen - timbre partiellement capture\")\n",
    "            else:\n",
    "                print(\"Faible - voix differente\")\n",
    "        else:\n",
    "            # Analyse simplifiee sans resemblyzer\n",
    "            min_len = min(len(ref_audio), len(clone_audio))\n",
    "            if min_len > 0:\n",
    "                # Correlation sur les enveloppes spectrales\n",
    "                from scipy.signal import hilbert\n",
    "                ref_env = np.abs(hilbert(ref_audio[:min_len]))\n",
    "                clone_env = np.abs(hilbert(clone_audio[:min_len]))\n",
    "                corr = np.corrcoef(ref_env, clone_env)[0, 1]\n",
    "                print(f\"  Correlation d'enveloppe : {corr:.4f}\")\n",
    "\n",
    "        # Statistiques comparatives\n",
    "        print(f\"\\nStatistiques audio :\")\n",
    "        print(f\"  {'Metrique':<25} {'Reference':<15} {'Clone':<15}\")\n",
    "        print(f\"  {'-'*55}\")\n",
    "        print(f\"  {'Duree (s)':<25} {len(ref_audio)/ref_sr:<15.1f} {len(clone_audio)/clone_sr:<15.1f}\")\n",
    "        print(f\"  {'Sample rate (Hz)':<25} {ref_sr:<15} {clone_sr:<15}\")\n",
    "        print(f\"  {'RMS energy':<25} {np.sqrt(np.mean(ref_audio**2)):<15.4f} {np.sqrt(np.mean(clone_audio**2)):<15.4f}\")\n",
    "        print(f\"  {'Peak amplitude':<25} {np.max(np.abs(ref_audio)):<15.4f} {np.max(np.abs(clone_audio)):<15.4f}\")\n",
    "    else:\n",
    "        print(\"Fichiers audio non disponibles pour l'analyse\")\n",
    "else:\n",
    "    print(\"Analyse de similarite desactivee ou modele non charge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section4-interpretation",
   "metadata": {
    "papermill": {
     "duration": 0.003898,
     "end_time": "2026-02-18T09:33:16.607562",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.603664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Interpretation : Qualite du clonage\n",
    "\n",
    "| Metrique | Valeur typique XTTS | Signification |\n",
    "|----------|-------------------|---------------|\n",
    "| Cosine similarity | 0.75-0.90 | Bon a excellent clonage |\n",
    "| RMS energy | Variable | Normalise par le modele |\n",
    "| Peak amplitude | ~0.8-1.0 | Audio bien normalise |\n",
    "\n",
    "**Points cles** :\n",
    "1. Une similarite > 0.85 indique un clonage de tres bonne qualite\n",
    "2. La qualite du clip de reference est le facteur le plus important\n",
    "3. Le clonage cross-lingual peut reduire legerement la similarite\n",
    "\n",
    "> **Note ethique** : Les systemes de clonage vocal soulevent des enjeux majeurs. Le consentement du locuteur est indispensable. Coqui impose une licence non-commerciale (CPML) pour limiter les usages abusifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-interactive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:33:16.614809Z",
     "iopub.status.busy": "2026-02-18T09:33:16.614160Z",
     "iopub.status.idle": "2026-02-18T09:33:16.621823Z",
     "shell.execute_reply": "2026-02-18T09:33:16.620679Z"
    },
    "papermill": {
     "duration": 0.012434,
     "end_time": "2026-02-18T09:33:16.622952",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.610518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE INTERACTIF - CLONAGE PERSONNALISE\n",
      "==================================================\n",
      "\n",
      "Entrez un texte a synthetiser avec la voix clonee :\n",
      "(Laissez vide pour passer a la suite)\n",
      "Mode interactif non disponible (execution automatisee)\n"
     ]
    }
   ],
   "source": [
    "# Mode interactif - Clonage personnalise\n",
    "if notebook_mode == \"interactive\" and not skip_widgets:\n",
    "    print(\"MODE INTERACTIF - CLONAGE PERSONNALISE\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nEntrez un texte a synthetiser avec la voix clonee :\")\n",
    "    print(\"(Laissez vide pour passer a la suite)\")\n",
    "\n",
    "    try:\n",
    "        user_text = input(\"\\nVotre texte : \")\n",
    "\n",
    "        if user_text.strip() and xtts_loaded:\n",
    "            user_lang = input(f\"Langue [{language}] (fr/en/es/de/it/pt) : \").strip() or language\n",
    "\n",
    "            ref_path = OUTPUT_DIR / \"reference_speaker.wav\"\n",
    "            if ref_path.exists():\n",
    "                print(f\"\\nGeneration avec clonage vocal (langue : {user_lang})...\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                out_path = OUTPUT_DIR / f\"custom_clone_{user_lang}.wav\"\n",
    "                tts.tts_to_file(\n",
    "                    text=user_text,\n",
    "                    file_path=str(out_path),\n",
    "                    speaker_wav=str(ref_path),\n",
    "                    language=user_lang\n",
    "                )\n",
    "\n",
    "                gen_time = time.time() - start_time\n",
    "                audio_data, sr = sf.read(str(out_path))\n",
    "                print(f\"Duree : {len(audio_data)/sr:.1f}s | Temps : {gen_time:.2f}s\")\n",
    "                display(Audio(data=audio_data, rate=sr))\n",
    "            else:\n",
    "                print(\"Clip de reference non disponible\")\n",
    "        else:\n",
    "            print(\"Mode interactif ignore\")\n",
    "\n",
    "    except (KeyboardInterrupt, EOFError):\n",
    "        print(\"Mode interactif interrompu\")\n",
    "    except Exception as e:\n",
    "        error_type = type(e).__name__\n",
    "        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n",
    "            print(\"Mode interactif non disponible (execution automatisee)\")\n",
    "        else:\n",
    "            print(f\"Erreur : {error_type} - {str(e)[:100]}\")\n",
    "else:\n",
    "    print(\"Mode batch - Interface interactive desactivee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-practices",
   "metadata": {
    "papermill": {
     "duration": 0.003987,
     "end_time": "2026-02-18T09:33:16.629616",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.625629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Considerations ethiques et bonnes pratiques\n",
    "\n",
    "### Enjeux du clonage vocal\n",
    "\n",
    "| Risque | Description | Mitigation |\n",
    "|--------|-------------|------------|\n",
    "| Usurpation d'identite | Utiliser la voix d'une personne sans autorisation | Consentement ecrit obligatoire |\n",
    "| Deepfakes audio | Creer de faux enregistrements | Watermarking, detection |\n",
    "| Fraude | Imiter une voix pour tromper | Authentification multi-facteurs |\n",
    "| Desinformation | Creer de faux discours | Legislation, detection |\n",
    "\n",
    "### Bonnes pratiques\n",
    "\n",
    "| Pratique | Description |\n",
    "|----------|-------------|\n",
    "| Consentement | Toujours obtenir l'accord ecrit du locuteur |\n",
    "| Watermarking | Ajouter un filigrane audio aux voix synthetiques |\n",
    "| Documentation | Indiquer clairement qu'un audio est synthetique |\n",
    "| Licence | Respecter la licence CPML (non-commercial) de XTTS |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-stats",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:33:16.636078Z",
     "iopub.status.busy": "2026-02-18T09:33:16.635744Z",
     "iopub.status.idle": "2026-02-18T09:33:16.644367Z",
     "shell.execute_reply": "2026-02-18T09:33:16.643016Z"
    },
    "papermill": {
     "duration": 0.013545,
     "end_time": "2026-02-18T09:33:16.646146",
     "exception": false,
     "start_time": "2026-02-18T09:33:16.632601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATISTIQUES DE SESSION\n",
      "=============================================\n",
      "Date : 2026-02-18 10:33:16\n",
      "Modele : tts_models/multilingual/multi-dataset/xtts_v2\n",
      "Device : cpu\n",
      "Langue par defaut : fr\n",
      "Modele charge : Non\n",
      "Fichiers sauvegardes : 0 (0.0 MB) dans D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\outputs\\audio\\xtts\n",
      "\n",
      "PROCHAINES ETAPES\n",
      "1. Explorer la generation musicale avec MusicGen (02-3)\n",
      "2. Decouvrir la separation de sources avec Demucs (02-4)\n",
      "3. Comparer tous les modeles audio (03-1)\n",
      "4. Construire un pipeline vocal complet (03-2)\n",
      "\n",
      "Notebook XTTS Voice Cloning termine - 10:33:16\n"
     ]
    }
   ],
   "source": [
    "# Statistiques de session et prochaines etapes\n",
    "print(\"STATISTIQUES DE SESSION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Modele : {model_name}\")\n",
    "print(f\"Device : {device}\")\n",
    "print(f\"Langue par defaut : {language}\")\n",
    "print(f\"Modele charge : {'Oui' if xtts_loaded else 'Non'}\")\n",
    "\n",
    "if gpu_available:\n",
    "    vram_current = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "    print(f\"VRAM utilisee : {vram_current:.2f} GB\")\n",
    "\n",
    "if save_results:\n",
    "    saved = list(OUTPUT_DIR.glob('*'))\n",
    "    total_size = sum(f.stat().st_size for f in saved) / (1024*1024)\n",
    "    print(f\"Fichiers sauvegardes : {len(saved)} ({total_size:.1f} MB) dans {OUTPUT_DIR}\")\n",
    "\n",
    "# Liberation memoire\n",
    "if xtts_loaded:\n",
    "    print(f\"\\nLiberation du modele...\")\n",
    "    del tts\n",
    "    gc.collect()\n",
    "    if gpu_available:\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Memoire liberee\")\n",
    "\n",
    "print(f\"\\nPROCHAINES ETAPES\")\n",
    "print(f\"1. Explorer la generation musicale avec MusicGen (02-3)\")\n",
    "print(f\"2. Decouvrir la separation de sources avec Demucs (02-4)\")\n",
    "print(f\"3. Comparer tous les modeles audio (03-1)\")\n",
    "print(f\"4. Construire un pipeline vocal complet (03-2)\")\n",
    "\n",
    "print(f\"\\nNotebook XTTS Voice Cloning termine - {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.862609,
   "end_time": "2026-02-18T09:33:17.214138",
   "environment_variables": {},
   "exception": null,
   "input_path": "D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\Audio\\02-Advanced\\02-2-XTTS-Voice-Cloning.ipynb",
   "output_path": "D:\\Dev\\CoursIA.worktrees\\GenAI_Series\\MyIA.AI.Notebooks\\GenAI\\Audio\\02-Advanced\\02-2-XTTS-Voice-Cloning.ipynb",
   "parameters": {},
   "start_time": "2026-02-18T09:33:13.351529",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}