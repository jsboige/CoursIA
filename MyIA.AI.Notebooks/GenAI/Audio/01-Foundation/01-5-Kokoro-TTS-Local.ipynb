{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-header",
   "metadata": {},
   "source": [
    "# Kokoro TTS Local - Synthese Vocale Legere\n",
    "\n",
    "**Module :** 01-Audio-Foundation  \n",
    "**Niveau :** Intermediaire  \n",
    "**Technologies :** Kokoro TTS (82M params, MIT license)  \n",
    "**Duree estimee :** 35 minutes  \n",
    "**VRAM :** ~2 GB  \n",
    "\n",
    "## Objectifs d'Apprentissage\n",
    "\n",
    "- [ ] Installer et charger le modele Kokoro depuis HuggingFace\n",
    "- [ ] Comprendre l'architecture et les avantages de Kokoro (82M params, MIT)\n",
    "- [ ] Generer de la parole avec differentes voix et langues\n",
    "- [ ] Comparer la qualite avec OpenAI TTS (evaluation subjective MOS-like)\n",
    "- [ ] Mesurer la latence et le debit de generation\n",
    "- [ ] Analyser le cout : local gratuit vs API payante\n",
    "- [ ] Identifier quand utiliser le TTS local vs cloud\n",
    "\n",
    "## Prerequis\n",
    "\n",
    "- GPU NVIDIA avec au moins 2 GB VRAM (ou CPU)\n",
    "- `pip install kokoro-onnx` ou `pip install kokoro`\n",
    "- Notebook 01-1 recommande (pour la comparaison avec OpenAI TTS)\n",
    "\n",
    "**Navigation :** [Index](../README.md) | [<< Precedent](01-4-Whisper-Local.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-params",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parametres Papermill - JAMAIS modifier ce commentaire\n",
    "\n",
    "# Configuration notebook\n",
    "notebook_mode = \"interactive\"        # \"interactive\" ou \"batch\"\n",
    "skip_widgets = False               # True pour mode batch MCP\n",
    "debug_level = \"INFO\"\n",
    "\n",
    "# Parametres Kokoro\n",
    "kokoro_model = \"hexgrad/Kokoro-82M\"   # Modele HuggingFace\n",
    "voice = \"af_heart\"                    # Voix par defaut\n",
    "use_onnx = True                       # Utiliser le backend ONNX (plus rapide)\n",
    "\n",
    "# Configuration\n",
    "compare_with_openai = True         # Comparer avec OpenAI TTS\n",
    "test_multiple_voices = True        # Tester plusieurs voix\n",
    "benchmark_latency = True           # Benchmarks de latence\n",
    "save_results = True                # Sauvegarder les resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environnement et imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Import helpers GenAI\n",
    "GENAI_ROOT = Path.cwd()\n",
    "while GENAI_ROOT.name != 'GenAI' and len(GENAI_ROOT.parts) > 1:\n",
    "    GENAI_ROOT = GENAI_ROOT.parent\n",
    "\n",
    "HELPERS_PATH = GENAI_ROOT / 'shared' / 'helpers'\n",
    "if HELPERS_PATH.exists():\n",
    "    sys.path.insert(0, str(HELPERS_PATH.parent))\n",
    "    try:\n",
    "        from helpers.audio_helpers import play_audio, save_audio\n",
    "        print(\"Helpers audio importes\")\n",
    "    except ImportError:\n",
    "        print(\"Helpers audio non disponibles - mode autonome\")\n",
    "\n",
    "# Repertoires\n",
    "OUTPUT_DIR = GENAI_ROOT / 'outputs' / 'audio' / 'kokoro'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuration logging\n",
    "logging.basicConfig(level=getattr(logging, debug_level))\n",
    "logger = logging.getLogger('kokoro_tts')\n",
    "\n",
    "# Verification GPU\n",
    "gpu_available = False\n",
    "try:\n",
    "    import torch\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    if gpu_available:\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_vram = torch.cuda.get_device_properties(0).total_mem / (1024**3)\n",
    "        print(f\"GPU : {gpu_name} ({gpu_vram:.1f} GB VRAM)\")\n",
    "    else:\n",
    "        print(\"GPU non disponible - Kokoro fonctionne aussi sur CPU\")\n",
    "except ImportError:\n",
    "    print(\"torch non installe - utilisation CPU\")\n",
    "\n",
    "print(f\"\\nKokoro TTS Local - Synthese Vocale\")\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Modele : {kokoro_model}\")\n",
    "print(f\"Voix : {voice}\")\n",
    "print(f\"Backend ONNX : {use_onnx}\")\n",
    "print(f\"Sortie : {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-env",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement .env (pour comparaison OpenAI)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_path = Path.cwd()\n",
    "found_env = False\n",
    "for _ in range(4):\n",
    "    env_path = current_path / '.env'\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"Fichier .env charge depuis : {env_path}\")\n",
    "        found_env = True\n",
    "        break\n",
    "    current_path = current_path.parent\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_key:\n",
    "    print(f\"OPENAI_API_KEY disponible (pour comparaison)\")\n",
    "else:\n",
    "    print(f\"OPENAI_API_KEY non disponible - comparaison avec OpenAI desactivee\")\n",
    "    compare_with_openai = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section1-intro",
   "metadata": {},
   "source": [
    "## Section 1 : Presentation de Kokoro\n",
    "\n",
    "Kokoro est un modele TTS leger et open-source sous licence MIT.\n",
    "\n",
    "### Caracteristiques\n",
    "\n",
    "| Aspect | Kokoro 82M | OpenAI TTS |\n",
    "|--------|-----------|------------|\n",
    "| Parametres | 82 millions | Non publie |\n",
    "| Licence | MIT (libre) | Proprietaire |\n",
    "| Cout | Gratuit | $15-30 / 1M chars |\n",
    "| Hebergement | Local | Cloud OpenAI |\n",
    "| VRAM | ~2 GB | N/A (API) |\n",
    "| Latence | ~0.5-1s (GPU) | ~1-3s (reseau) |\n",
    "| Langues | EN, FR, ES, ZH, JA, KO | Multilingue |\n",
    "| Qualite | Bonne (MOS ~4.0) | Excellente (MOS ~4.5) |\n",
    "\n",
    "### Quand utiliser Kokoro vs OpenAI\n",
    "\n",
    "| Scenario | Recommandation | Raison |\n",
    "|----------|---------------|--------|\n",
    "| Prototypage | Kokoro | Gratuit, pas de cle API |\n",
    "| Production web | OpenAI TTS | Qualite superieure |\n",
    "| Donnees sensibles | Kokoro | Execution locale |\n",
    "| Volume eleve | Kokoro | Pas de cout par caractere |\n",
    "| Meilleure qualite | OpenAI TTS-HD | Voix les plus naturelles |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modele Kokoro\n",
    "print(\"CHARGEMENT DU MODELE KOKORO\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "kokoro_loaded = False\n",
    "\n",
    "if use_onnx:\n",
    "    try:\n",
    "        from kokoro_onnx import Kokoro\n",
    "        print(\"Chargement Kokoro (backend ONNX)...\")\n",
    "        start_time = time.time()\n",
    "        kokoro = Kokoro(kokoro_model)\n",
    "        load_time = time.time() - start_time\n",
    "        kokoro_loaded = True\n",
    "        print(f\"Modele charge en {load_time:.1f}s (ONNX)\")\n",
    "    except ImportError:\n",
    "        print(\"kokoro-onnx non installe, tentative avec kokoro standard...\")\n",
    "        use_onnx = False\n",
    "\n",
    "if not use_onnx and not kokoro_loaded:\n",
    "    try:\n",
    "        from kokoro import KPipeline\n",
    "        print(\"Chargement Kokoro (backend PyTorch)...\")\n",
    "        start_time = time.time()\n",
    "        pipeline = KPipeline(lang_code='a')  # 'a' = auto\n",
    "        load_time = time.time() - start_time\n",
    "        kokoro_loaded = True\n",
    "        print(f\"Modele charge en {load_time:.1f}s (PyTorch)\")\n",
    "    except ImportError:\n",
    "        print(\"Ni kokoro-onnx ni kokoro ne sont installes\")\n",
    "        print(\"Installation : pip install kokoro-onnx\")\n",
    "        print(\"Ou : pip install kokoro soundfile\")\n",
    "\n",
    "if kokoro_loaded:\n",
    "    print(f\"\\nModele pret pour la generation\")\n",
    "    if gpu_available:\n",
    "        vram_used = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "        print(f\"VRAM utilisee : {vram_used:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section2-intro",
   "metadata": {},
   "source": [
    "## Section 2 : Premiere generation\n",
    "\n",
    "La generation avec Kokoro suit un pipeline simple :\n",
    "1. Charger le modele (fait une seule fois)\n",
    "2. Specifier le texte et la voix\n",
    "3. Appeler la methode de generation\n",
    "4. Recevoir un array numpy + sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-first-gen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premiere generation TTS avec Kokoro\n",
    "print(\"PREMIERE GENERATION KOKORO\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "sample_text = (\n",
    "    \"Bonjour et bienvenue dans ce cours sur la synthese vocale locale. \"\n",
    "    \"Kokoro est un modele leger et open-source qui fonctionne directement \"\n",
    "    \"sur votre machine.\"\n",
    ")\n",
    "\n",
    "print(f\"Texte : {sample_text}\")\n",
    "print(f\"Voix : {voice}\")\n",
    "\n",
    "if kokoro_loaded:\n",
    "    start_time = time.time()\n",
    "\n",
    "    if use_onnx:\n",
    "        # API kokoro-onnx\n",
    "        samples, sample_rate = kokoro.create(\n",
    "            sample_text,\n",
    "            voice=voice,\n",
    "            speed=1.0\n",
    "        )\n",
    "    else:\n",
    "        # API kokoro standard (KPipeline)\n",
    "        generator = pipeline(\n",
    "            sample_text,\n",
    "            voice=voice,\n",
    "            speed=1.0\n",
    "        )\n",
    "        # Concatener tous les segments\n",
    "        all_samples = []\n",
    "        sample_rate = 24000\n",
    "        for gs, ps, audio_chunk in generator:\n",
    "            all_samples.append(audio_chunk)\n",
    "        samples = np.concatenate(all_samples) if all_samples else np.array([])\n",
    "\n",
    "    gen_time = time.time() - start_time\n",
    "    duration = len(samples) / sample_rate\n",
    "\n",
    "    print(f\"\\nGeneration reussie\")\n",
    "    print(f\"  Duree audio : {duration:.1f}s\")\n",
    "    print(f\"  Sample rate : {sample_rate} Hz\")\n",
    "    print(f\"  Temps de generation : {gen_time:.2f}s\")\n",
    "    print(f\"  Ratio temps reel : {duration / gen_time:.1f}x\")\n",
    "    print(f\"  Taille : {len(samples) * 4 / 1024:.1f} KB (float32)\")\n",
    "\n",
    "    # Lecture\n",
    "    print(f\"\\nEcoute :\")\n",
    "    display(Audio(data=samples, rate=sample_rate))\n",
    "\n",
    "    # Sauvegarde\n",
    "    if save_results:\n",
    "        filepath = OUTPUT_DIR / f\"kokoro_{voice}.wav\"\n",
    "        sf.write(str(filepath), samples, sample_rate)\n",
    "        print(f\"Fichier sauvegarde : {filepath.name}\")\n",
    "else:\n",
    "    print(\"Modele Kokoro non charge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section2-interpretation",
   "metadata": {},
   "source": [
    "### Interpretation : Premiere generation\n",
    "\n",
    "| Aspect | Valeur typique | Signification |\n",
    "|--------|---------------|---------------|\n",
    "| Ratio temps reel | 5-20x (GPU), 1-3x (CPU) | Kokoro genere bien plus vite que le temps reel |\n",
    "| Sample rate | 24000 Hz | Standard pour la parole (qualite telephone HD) |\n",
    "| Qualite | Bonne | Moins naturelle qu'OpenAI TTS mais acceptable |\n",
    "\n",
    "> **Note technique** : Le premier appel est plus lent (compilation JIT). Les appels suivants beneficient du cache."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section3-intro",
   "metadata": {},
   "source": [
    "## Section 3 : Voix et langues\n",
    "\n",
    "Kokoro propose plusieurs voix organisees par langue :\n",
    "\n",
    "| Prefixe | Langue | Exemples de voix |\n",
    "|---------|--------|------------------|\n",
    "| `af_` | Anglais (feminin) | `af_heart`, `af_bella`, `af_sarah` |\n",
    "| `am_` | Anglais (masculin) | `am_adam`, `am_michael` |\n",
    "| `bf_` | Anglais britannique (f) | `bf_emma`, `bf_isabella` |\n",
    "| `bm_` | Anglais britannique (m) | `bm_george`, `bm_lewis` |\n",
    "| `ff_` | Francais (f) | `ff_siwis` |\n",
    "| `fm_` | Francais (m) | (a venir) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-voices",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de differentes voix\n",
    "print(\"TEST DES VOIX\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if kokoro_loaded and test_multiple_voices:\n",
    "    voices_to_test = [\n",
    "        (\"af_heart\", \"Hello, I am the Heart voice from Kokoro.\"),\n",
    "        (\"af_bella\", \"Hello, I am the Bella voice from Kokoro.\"),\n",
    "        (\"am_adam\", \"Hello, I am the Adam voice from Kokoro.\"),\n",
    "        (\"ff_siwis\", \"Bonjour, je suis la voix Siwis de Kokoro.\"),\n",
    "    ]\n",
    "\n",
    "    voice_results = {}\n",
    "\n",
    "    for v, text in voices_to_test:\n",
    "        print(f\"\\nVoix : {v}\")\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "\n",
    "            if use_onnx:\n",
    "                samples, sample_rate = kokoro.create(text, voice=v, speed=1.0)\n",
    "            else:\n",
    "                generator = pipeline(text, voice=v, speed=1.0)\n",
    "                all_samples = []\n",
    "                sample_rate = 24000\n",
    "                for gs, ps, audio_chunk in generator:\n",
    "                    all_samples.append(audio_chunk)\n",
    "                samples = np.concatenate(all_samples) if all_samples else np.array([])\n",
    "\n",
    "            gen_time = time.time() - start_time\n",
    "            duration = len(samples) / sample_rate\n",
    "\n",
    "            voice_results[v] = {\n",
    "                \"duration\": duration,\n",
    "                \"gen_time\": gen_time,\n",
    "                \"samples\": samples,\n",
    "                \"sample_rate\": sample_rate\n",
    "            }\n",
    "\n",
    "            print(f\"  Duree : {duration:.1f}s | Temps : {gen_time:.2f}s | Ratio : {duration/gen_time:.1f}x\")\n",
    "            display(Audio(data=samples, rate=sample_rate))\n",
    "\n",
    "            if save_results:\n",
    "                filepath = OUTPUT_DIR / f\"voice_{v}.wav\"\n",
    "                sf.write(str(filepath), samples, sample_rate)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Erreur : {str(e)[:80]}\")\n",
    "\n",
    "    # Tableau recapitulatif\n",
    "    if voice_results:\n",
    "        print(f\"\\nRecapitulatif :\")\n",
    "        print(f\"{'Voix':<15} {'Duree':<10} {'Temps gen':<12} {'Ratio':<8}\")\n",
    "        print(\"-\" * 45)\n",
    "        for v, data in voice_results.items():\n",
    "            ratio = data['duration'] / data['gen_time'] if data['gen_time'] > 0 else 0\n",
    "            print(f\"{v:<15} {data['duration']:<10.1f} {data['gen_time']:<12.2f} {ratio:<8.1f}\")\n",
    "else:\n",
    "    print(\"Test des voix desactive ou modele non charge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section4-intro",
   "metadata": {},
   "source": [
    "## Section 4 : Comparaison avec OpenAI TTS\n",
    "\n",
    "Comparaison directe entre Kokoro (local, gratuit) et OpenAI TTS (cloud, payant) sur les memes textes.\n",
    "\n",
    "### Criteres d'evaluation\n",
    "\n",
    "| Critere | Description |\n",
    "|---------|-------------|\n",
    "| Latence | Temps entre la requete et le debut de l'audio |\n",
    "| Naturalite | Ressemblance avec la voix humaine |\n",
    "| Prosodie | Rythme, intonation, accentuation |\n",
    "| Cout | Prix par caractere synthetise |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison Kokoro vs OpenAI TTS\n",
    "print(\"COMPARAISON KOKORO VS OPENAI TTS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "comparison_text = (\n",
    "    \"L'intelligence artificielle generative transforme la facon \"\n",
    "    \"dont nous creons et consommons du contenu audio.\"\n",
    ")\n",
    "\n",
    "comparison_results = {}\n",
    "\n",
    "# --- Kokoro ---\n",
    "if kokoro_loaded:\n",
    "    print(f\"\\n--- Kokoro ({voice}) ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    if use_onnx:\n",
    "        kokoro_samples, kokoro_sr = kokoro.create(comparison_text, voice=voice, speed=1.0)\n",
    "    else:\n",
    "        generator = pipeline(comparison_text, voice=voice, speed=1.0)\n",
    "        all_samples = []\n",
    "        kokoro_sr = 24000\n",
    "        for gs, ps, audio_chunk in generator:\n",
    "            all_samples.append(audio_chunk)\n",
    "        kokoro_samples = np.concatenate(all_samples) if all_samples else np.array([])\n",
    "\n",
    "    kokoro_time = time.time() - start_time\n",
    "    kokoro_duration = len(kokoro_samples) / kokoro_sr\n",
    "\n",
    "    comparison_results[\"Kokoro\"] = {\n",
    "        \"time\": kokoro_time,\n",
    "        \"duration\": kokoro_duration,\n",
    "        \"cost\": 0.0\n",
    "    }\n",
    "\n",
    "    print(f\"  Temps : {kokoro_time:.2f}s\")\n",
    "    print(f\"  Duree audio : {kokoro_duration:.1f}s\")\n",
    "    print(f\"  Cout : $0.00\")\n",
    "    display(Audio(data=kokoro_samples, rate=kokoro_sr))\n",
    "\n",
    "# --- OpenAI TTS ---\n",
    "if compare_with_openai:\n",
    "    from openai import OpenAI\n",
    "    client_api = OpenAI(api_key=openai_key)\n",
    "\n",
    "    for tts_model in [\"tts-1\", \"tts-1-hd\"]:\n",
    "        print(f\"\\n--- OpenAI {tts_model} (alloy) ---\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = client_api.audio.speech.create(\n",
    "            model=tts_model,\n",
    "            voice=\"alloy\",\n",
    "            input=comparison_text,\n",
    "            response_format=\"wav\"\n",
    "        )\n",
    "\n",
    "        openai_time = time.time() - start_time\n",
    "        openai_bytes = response.content\n",
    "\n",
    "        # Charger pour connaitre la duree\n",
    "        import io\n",
    "        openai_data, openai_sr = sf.read(io.BytesIO(openai_bytes))\n",
    "        openai_duration = len(openai_data) / openai_sr\n",
    "\n",
    "        cost_per_char = 0.015 if tts_model == \"tts-1\" else 0.030\n",
    "        cost = len(comparison_text) * cost_per_char / 1000\n",
    "\n",
    "        comparison_results[f\"OpenAI {tts_model}\"] = {\n",
    "            \"time\": openai_time,\n",
    "            \"duration\": openai_duration,\n",
    "            \"cost\": cost\n",
    "        }\n",
    "\n",
    "        print(f\"  Temps : {openai_time:.2f}s\")\n",
    "        print(f\"  Duree audio : {openai_duration:.1f}s\")\n",
    "        print(f\"  Cout : ${cost:.5f}\")\n",
    "        display(Audio(data=openai_bytes, autoplay=False))\n",
    "\n",
    "# --- Tableau comparatif ---\n",
    "if comparison_results:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TABLEAU COMPARATIF\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"{'Service':<22} {'Latence (s)':<14} {'Duree (s)':<12} {'Cout ($)':<10}\")\n",
    "    print(\"-\" * 58)\n",
    "    for name, data in comparison_results.items():\n",
    "        print(f\"{name:<22} {data['time']:<14.2f} {data['duration']:<12.1f} {data['cost']:<10.5f}\")\n",
    "\n",
    "    # Estimation pour 1 heure de narration (~50K caracteres)\n",
    "    chars_1h = 50000\n",
    "    print(f\"\\nEstimation pour 1 heure de narration (~{chars_1h:,} caracteres) :\")\n",
    "    print(f\"  Kokoro          : $0.00\")\n",
    "    print(f\"  OpenAI tts-1    : ${chars_1h * 0.015 / 1000:.2f}\")\n",
    "    print(f\"  OpenAI tts-1-hd : ${chars_1h * 0.030 / 1000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section4-interpretation",
   "metadata": {},
   "source": [
    "### Interpretation : Comparaison Kokoro vs OpenAI\n",
    "\n",
    "| Critere | Kokoro | OpenAI tts-1 | OpenAI tts-1-hd |\n",
    "|---------|--------|-------------|------------------|\n",
    "| Latence | ~0.5s (GPU) | ~1-2s (reseau) | ~2-3s (reseau) |\n",
    "| Naturalite | Bonne | Tres bonne | Excellente |\n",
    "| Cout/1h | $0 | ~$0.75 | ~$1.50 |\n",
    "| Confidentialite | Locale | Cloud | Cloud |\n",
    "\n",
    "**Points cles** :\n",
    "1. Kokoro est imbattable sur le cout pour les gros volumes\n",
    "2. OpenAI offre une meilleure qualite perceptuelle, surtout en tts-1-hd\n",
    "3. Pour les donnees sensibles, Kokoro est le seul choix viable\n",
    "4. En termes de latence, Kokoro avec GPU est competitif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-interactive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode interactif\n",
    "if notebook_mode == \"interactive\" and not skip_widgets:\n",
    "    print(\"MODE INTERACTIF\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nEntrez un texte a synthetiser avec Kokoro :\")\n",
    "    print(\"(Laissez vide pour passer a la suite)\")\n",
    "\n",
    "    try:\n",
    "        user_text = input(\"\\nVotre texte : \")\n",
    "\n",
    "        if user_text.strip() and kokoro_loaded:\n",
    "            user_voice = input(f\"Voix [{voice}] : \").strip() or voice\n",
    "\n",
    "            print(f\"\\nGeneration avec Kokoro ({user_voice})...\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            if use_onnx:\n",
    "                samples, sr_out = kokoro.create(user_text, voice=user_voice, speed=1.0)\n",
    "            else:\n",
    "                generator = pipeline(user_text, voice=user_voice, speed=1.0)\n",
    "                all_samples = []\n",
    "                sr_out = 24000\n",
    "                for gs, ps, audio_chunk in generator:\n",
    "                    all_samples.append(audio_chunk)\n",
    "                samples = np.concatenate(all_samples) if all_samples else np.array([])\n",
    "\n",
    "            gen_time = time.time() - start_time\n",
    "            print(f\"Duree : {len(samples)/sr_out:.1f}s | Temps : {gen_time:.2f}s\")\n",
    "            display(Audio(data=samples, rate=sr_out))\n",
    "\n",
    "            if save_results:\n",
    "                ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                filepath = OUTPUT_DIR / f\"custom_{user_voice}_{ts}.wav\"\n",
    "                sf.write(str(filepath), samples, sr_out)\n",
    "                print(f\"Sauvegarde : {filepath.name}\")\n",
    "        else:\n",
    "            print(\"Mode interactif ignore\")\n",
    "\n",
    "    except (KeyboardInterrupt, EOFError):\n",
    "        print(\"Mode interactif interrompu\")\n",
    "    except Exception as e:\n",
    "        error_type = type(e).__name__\n",
    "        if \"StdinNotImplemented\" in error_type or \"input\" in str(e).lower():\n",
    "            print(\"Mode interactif non disponible (execution automatisee)\")\n",
    "        else:\n",
    "            print(f\"Erreur : {error_type} - {str(e)[:100]}\")\n",
    "else:\n",
    "    print(\"Mode batch - Interface interactive desactivee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-practices",
   "metadata": {},
   "source": [
    "## Bonnes pratiques et guide de decision\n",
    "\n",
    "### Arbre de decision : local vs cloud\n",
    "\n",
    "| Question | Oui -> | Non -> |\n",
    "|----------|--------|--------|\n",
    "| Donnees sensibles ? | Local (Kokoro) | Continuer |\n",
    "| Budget limite ? | Local (Kokoro) | Continuer |\n",
    "| Qualite maximale requise ? | Cloud (OpenAI HD) | Continuer |\n",
    "| GPU disponible ? | Local (Kokoro) | Cloud (OpenAI tts-1) |\n",
    "| Volume > 1M chars/mois ? | Local (Kokoro) | Cloud (OpenAI tts-1) |\n",
    "\n",
    "### Optimisation Kokoro\n",
    "\n",
    "| Technique | Impact | Description |\n",
    "|-----------|--------|-------------|\n",
    "| Backend ONNX | Vitesse +30-50% | Inference optimisee sans PyTorch |\n",
    "| Batch generation | Debit +50% | Regrouper les textes courts |\n",
    "| GPU | Vitesse 5-10x vs CPU | Recommande pour la production |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques de session et prochaines etapes\n",
    "print(\"STATISTIQUES DE SESSION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "print(f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Modele : {kokoro_model}\")\n",
    "print(f\"Backend : {'ONNX' if use_onnx else 'PyTorch'}\")\n",
    "print(f\"Voix par defaut : {voice}\")\n",
    "print(f\"Modele charge : {'Oui' if kokoro_loaded else 'Non'}\")\n",
    "\n",
    "if gpu_available:\n",
    "    vram_current = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "    print(f\"VRAM utilisee : {vram_current:.2f} GB\")\n",
    "\n",
    "if save_results:\n",
    "    saved = list(OUTPUT_DIR.glob('*'))\n",
    "    total_size = sum(f.stat().st_size for f in saved) / (1024*1024)\n",
    "    print(f\"Fichiers sauvegardes : {len(saved)} ({total_size:.1f} MB) dans {OUTPUT_DIR}\")\n",
    "\n",
    "# Liberation memoire\n",
    "if kokoro_loaded:\n",
    "    print(f\"\\nLiberation du modele...\")\n",
    "    if use_onnx:\n",
    "        del kokoro\n",
    "    else:\n",
    "        del pipeline\n",
    "    gc.collect()\n",
    "    if gpu_available:\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Memoire liberee\")\n",
    "\n",
    "print(f\"\\nPROCHAINES ETAPES\")\n",
    "print(f\"1. Explorer le TTS avance avec Chatterbox (02-1)\")\n",
    "print(f\"2. Decouvrir le voice cloning avec XTTS (02-2)\")\n",
    "print(f\"3. Comparer tous les modeles TTS et STT (03-1)\")\n",
    "print(f\"4. Construire un pipeline vocal complet (03-2)\")\n",
    "\n",
    "print(f\"\\nNotebook Kokoro TTS termine - {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}