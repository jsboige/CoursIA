{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 - Anatomie de votre premier Agent d'IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un agent est un programme qui utilise un LLM pour raisonner, choisir des actions (outils) et atteindre un objectif. Dans ce lab, nous allons construire les 4 piliers d'un agent LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1 : Le \"Cerveau\" - Le LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le LLM (Large Language Model) est le moteur de raisonnement de notre agent. Nous utiliserons `ChatOpenAI`, qui nécessite une clé API OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Assurez-vous d'avoir défini votre clé OPENAI_API_KEY dans vos variables d'environnement\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 2 : Les \"Mains\" - Les Outils (Tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les outils sont des fonctions que l'agent peut appeler pour interagir avec le monde extérieur. La *docstring* de la fonction est cruciale, car c'est ce que le LLM lit pour comprendre l'utilité de l'outil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langchain_core.tools import tool\nimport math\n\n@tool\ndef calculer_racine_carree(nombre: float) -> float:\n    \"\"\"Calcule la racine carrée d'un nombre.\"\"\"\n    return math.sqrt(nombre)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 3 : Les \"Instructions\" - Le Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le prompt est le modèle d'instructions qui guide le raisonnement de l'agent. Pour commencer, nous allons utiliser un prompt pré-construit et éprouvé depuis le `LangChain Hub`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langchain_hub import pull\n\nprompt = pull(\"hwchase17/react\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 4 : L' \"Orchestrateur\" - L'Agent et son Exécuteur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous assemblons maintenant tous les composants pour créer l'agent, puis nous le faisons tourner avec un `AgentExecutor`. L'Executor gère la boucle `Pensée -> Action -> Observation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langchain.agents import create_react_agent, AgentExecutor\n\ntools = [calculer_racine_carree]\nagent = create_react_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Quelle est la racine carrée de 256 ?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Félicitations ! Vous avez assemblé les 4 composants fondamentaux d'un agent : un LLM pour raisonner, un Outil pour agir, un Prompt pour guider, et un Exécuteur pour orchestrer.\n",
    "\n",
    "Maintenant que nous savons construire un agent et lui donner un outil simple, nous sommes prêts pour la prochaine étape : lui donner des outils puissants pour interagir avec des DataFrames Pandas et devenir un véritable assistant d'analyse de données. C'est l'objet du Lab 7 !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}