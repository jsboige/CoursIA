{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nav-header",
   "metadata": {},
   "source": [
    "# Search-9-Metaheuristiques : Optimisation avec MEALPy\n",
    "\n",
    "**Navigation** : [<< Recherche locale](Search-4-LocalSearch.ipynb) | [Index](../README.md) | [App-1-NQueens >>](../Applications/App-1-NQueens.ipynb)\n",
    "\n",
    "## Metaheuristiques : PSO, ABC, SA et au-dela\n",
    "\n",
    "Ce notebook explore les **metaheuristiques**, une famille d'algorithmes d'optimisation inspires de la nature (evolution, essaims, physique) pour resoudre des problemes d'optimisation difficiles. Nous utiliserons la bibliotheque **MEALPy** qui implemente plus de 200 algorithmes.\n",
    "\n",
    "### Objectifs d'apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous saurez :\n",
    "1. **Comprendre** les principes fondamentaux des metaheuristiques et leurs categories (Evolution-based, Swarm-based, Physics-based, Human-based)\n",
    "2. **Comparer** les performances de differents algorithmes sur des problemes de benchmark\n",
    "3. **Appliquer** mealpy pour resoudre des problemes d'optimisation reels\n",
    "4. **Analyser** la convergence et les parametres des algorithmes\n",
    "\n",
    "### Prerequis\n",
    "- Notebook Search-4-LocalSearch (Hill Climbing, Simulated Annealing)\n",
    "- Python 3.10+ : numpy, matplotlib\n",
    "- Notions de base en optimisation (fonction objectif, minimiseur)\n",
    "\n",
    "### Duree estimee : 1h30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Imports MEALPy\n",
    "from mealpy import ParameterGrid\n",
    "from mealpy import PSO, ABC, SA, BRO, GWO, WOA, GA, DE\n",
    "from mealpy.prob import Problem\n",
    "\n",
    "# Helpers\n",
    "sys.path.insert(0, '..')\n",
    "from search_helpers import benchmark_table, plot_benchmark\n",
    "\n",
    "# Configuration\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Environnement pret pour les metaheuristiques.\")\n",
    "print(f\"MEALPy importe avec succes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1-intro",
   "metadata": {},
   "source": [
    "## 1. Introduction aux Metaheuristiques (~15 min)\n",
    "\n",
    "### Qu'est-ce qu'une metaheuristique ?\n",
    "\n",
    "Une **metaheuristique** est un algorithme d'optimisation qui guide un sous-probleme heuristique vers une solution optimale (ou proche de l'optimal). Contrairement aux algorithmes exacts, les metaheuristiques ne garantissent pas l'optimalite mais sont souvent efficaces sur des problemes difficiles.\n",
    "\n",
    "**Caracteristiques cles** :\n",
    "- **Sans derivees** : ne necessitent pas de calculer les gradients\n",
    "- **Iteratives** : ameliorent progressivement la solution\n",
    "- **Stochastiques** : utilisent l'aleatoire pour explorer l'espace\n",
    "- **Generiques** : applicables a de nombreux problemes\n",
    "\n",
    "### Classification des metaheuristiques\n",
    "\n",
    "| Categorie | Inspiration | Exemples |\n",
    "|-----------|-------------|----------|\n",
    "| **Evolution-based** | Theorie de l'evolution, genetique | GA, DE, ES | \n",
    "| **Swarm-based** | Comportements collectifs (essaims) | PSO, ABC, ACO, GWO |\n",
    "| **Physics-based** | Loi physique | SA, GRAVITY, ELECTRO | \n",
    "| **Human-based** | Comportement humain | BRO, TS, CA |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mealpy-install-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification de MEALPy\n",
    "try:\n",
    "    import mealpy\n",
    "    print(f\"MEALPy version: {mealpy.__version__}\")\n",
    "    print(f\"Nombre d'algorithmes disponibles: > 200\")\n",
    "except ImportError:\n",
    "    print(\"MEALPy non installe. Installation...\")\n",
    "    print(\"Commande: pip install mealpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exploration-exploitation",
   "metadata": {},
   "source": [
    "### Exploration vs Exploitation\n",
    "\n",
    "Toute metaheuristique doit equilibrer deux forces opposes :\n",
    "\n",
    "| Aspect | Exploration | Exploitation |\n",
    "|--------|-------------|---------------|\n",
    "| **Objectif** | Decouvrir de nouvelles regions de l'espace | Affiner les solutions prometteuses |\n",
    "| **Risque** | Trop -> random search, lente convergence | Trop -> optimum local |\n",
    "| **Analogie** | Chercher dans toute la maison | Chercher dans la piece ou on a perdu |\n",
    "\n",
    "Le **succes d'une metaheuristique** depend de sa capacite a :\n",
    "1. Explorer largement au debut (eviter les optima locaux)\n",
    "2. Exploiter intensivement a la fin (converger vers l'optimum)\n",
    "3. Adapter l'equilibre pendant la recherche\n",
    "\n",
    "> **Theoreme No Free Lunch** : Aucun algorithme n'est optimal pour tous les problemes. Le choix depend de la structure du probleme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2-mealpy",
   "metadata": {},
   "source": [
    "## 2. La librairie MEALPy (~10 min)\n",
    "\n",
    "### Presentation de MEALPy\n",
    "\n",
    "**MEALPy** (Meta-Heuristic Algorithms in Python) est une bibliotheque qui implemente plus de **200 algorithmes** d'optimisation metaheuristiques avec une API unifiee.\n",
    "\n",
    "**Installation** :\n",
    "```bash\n",
    "pip install mealpy\n",
    "```\n",
    "\n",
    "### API standard\n",
    "\n",
    "Tous les algorithmes suivent le meme schema :\n",
    "\n",
    "```python\n",
    "from mealpy import Algorithme\n",
    "from mealpy.prob import Problem\n",
    "\n",
    "# Definir le probleme\n",
    "problem = Problem(\n",
    "    lb=[-10, -10],  # Bornes inferieures\n",
    "    ub=[10, 10],    # Bornes superieures\n",
    "    minmax=\"min\",  # Minimisation ou maximisation\n",
    "    obj_func=ma_fonction  # Fonction objectif\n",
    ")\n",
    "\n",
    "# Creer et executer l'algorithme\n",
    "model = Algorithme(epoch=100, pop_size=50)\n",
    "result = model.solve(problem)\n",
    "```\n",
    "\n",
    "### Parametres principaux\n",
    "\n",
    "| Parametre | Signification | Valeur typique |\n",
    "|-----------|---------------|----------------|\n",
    "| **epoch** | Nombre d'iterations | 100-1000 |\n",
    "| **pop_size** | Taille de la population | 20-100 | \n",
    "| **lb, ub** | Bornes de l'espace de recherche | Problemes-dependent |\n",
    "| **minmax** | \"min\" ou \"max\" | \"min\" le plus souvent |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mealpy-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple simple : optimiser une fonction quadratique\n",
    "def simple_quadratic(solution):\n",
    "    \"\"\"Fonction quadratique simple : f(x) = sum(x^2).\"\"\"\n",
    "    return np.sum(solution**2)\n",
    "\n",
    "# Definir le probleme\n",
    "problem = Problem(\n",
    "    lb=[-10, -10],\n",
    "    ub=[10, 10],\n",
    "    minmax=\"min\",\n",
    "    obj_func=simple_quadratic\n",
    ")\n",
    "\n",
    "# Resoudre avec PSO\n",
    "model = PSO.OriginalPSO(epoch=50, pop_size=20)\n",
    "result = model.solve(problem)\n",
    "\n",
    "print(\"Resultat PSO sur fonction quadratique:\")\n",
    "print(f\"  Solution: {result.solution.round(4)}\")\n",
    "print(f\"  Objectif: {result.target.fitness:.6f}\")\n",
    "print(f\"  Optimal attendu: [0, 0] avec f=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interp-mealpy-basics",
   "metadata": {},
   "source": [
    "### Interpretation : Premier contact avec MEALPy\n",
    "\n",
    "**Sortie obtenue** : PSO trouve une solution proche de [0, 0].\n",
    "\n",
    "| Element | Valeur | Signification |\n",
    "|---------|--------|---------------|\n",
    "| Solution | Vecteur de 2 valeurs | Position dans l'espace 2D |\n",
    "| Objectif | Valeur proche de 0 | Qualite de la solution |\n",
    "| Optimal attendu | [0, 0], f=0 | Solution theorique |\n",
    "\n",
    "**Points cles** :\n",
    "1. L'API MEALPy est unifiee pour tous les algorithmes\n",
    "2. La fonction objectif recoit un vecteur numpy et retourne un scalaire\n",
    "3. Le resultat contient `solution` (vecteur) et `target.fitness` (valeur)\n",
    "4. Les bornes `lb` et `ub` definissent l'espace de recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-benchmark-functions",
   "metadata": {},
   "source": [
    "## 3. Fonctions de Benchmark (~5 min)\n",
    "\n",
    "Pour comparer les metaheuristiques, nous utilisons des **fonctions de benchmark** classiques en optimisation. Ces fonctions ont des proprietes connues (multimodalite, convexite, etc.) qui permettent d'evaluer les algorithmes.\n",
    "\n",
    "### Fonctions unimodales vs multimodales\n",
    "\n",
    "| Type | Propriete | Exemple |\n",
    "|------|-----------|----------|\n",
    "| **Unimodal** | Un seul optimum global | Sphere, Rosenbrock |\n",
    "| **Multimodal** | Plusieurs optima locaux | Rastrigin, Ackley |\n",
    "\n",
    "Les fonctions multimodales sont plus difficiles car les algorithmes peuvent rester coinces dans un optimum local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de benchmark classiques\n",
    "\n",
    "def sphere_function(solution):\n",
    "    \"\"\"Fonction Sphere : f(x) = sum(x^2).\n",
    "    \n",
    "    - Unimodale, convexe\n",
    "    - Optimum global: x* = [0, ..., 0], f(x*) = 0\n",
    "    \"\"\"\n",
    "    return np.sum(solution**2)\n",
    "\n",
    "\n",
    "def rastrigin_function(solution):\n",
    "    \"\"\"Fonction de Rastrigin : f(x) = 10*n + sum(x^2 - 10*cos(2*pi*x)).\n",
    "    \n",
    "    - Multimodale avec de nombreux optima locaux\n",
    "    - Optimum global: x* = [0, ..., 0], f(x*) = 0\n",
    "    - Tres difficile pour les algorithmes gloutons\n",
    "    \"\"\"\n",
    "    A = 10\n",
    "    n = len(solution)\n",
    "    return A*n + np.sum(solution**2 - A*np.cos(2*np.pi*solution))\n",
    "\n",
    "\n",
    "def rosenbrock_function(solution):\n",
    "    \"\"\"Fonction de Rosenbrock : f(x) = sum(100*(x[i+1] - x[i]^2)^2 + (1 - x[i])^2).\n",
    "    \n",
    "    - Vallée etroite et incurvee (difficile a optimiser)\n",
    "    - Optimum global: x* = [1, ..., 1], f(x*) = 0\n",
    "    - Classiquement utilisee pour tester la convergence\n",
    "    \"\"\"\n",
    "    return np.sum(100.0*(solution[1:] - solution[:-1]**2)**2 + (1 - solution[:-1])**2)\n",
    "\n",
    "\n",
    "def ackley_function(solution):\n",
    "    \"\"\"Fonction d'Ackley.\n",
    "    \n",
    "    - Multimodale avec nombreux plateaux\n",
    "    - Optimum global: x* = [0, ..., 0], f(x*) = 0\n",
    "    \"\"\"\n",
    "    a, b, c = 20, 0.2, 2*np.pi\n",
    "    d = len(solution)\n",
    "    sum1 = np.sum(solution**2)\n",
    "    sum2 = np.sum(np.cos(c*solution))\n",
    "    term1 = -a*np.exp(-b*np.sqrt(sum1/d))\n",
    "    term2 = -np.exp(sum2/d)\n",
    "    return term1 + term2 + a + np.exp(1)\n",
    "\n",
    "# Tableau recapitulatif\n",
    "benchmark_functions = {\n",
    "    'Sphere': sphere_function,\n",
    "    'Rastrigin': rastrigin_function,\n",
    "    'Rosenbrock': rosenbrock_function,\n",
    "    'Ackley': ackley_function\n",
    "}\n",
    "\n",
    "print(\"Fonctions de benchmark chargees.\")\n",
    "print(\"\\nProprietes:\")\n",
    "print(f\"  {'Nom':<15} {'Type':<15} {'Optimum':<20}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  {'Sphere':<15} {'Unimodale':<15} {'[0, ..., 0], f=0':<20}\")\n",
    "print(f\"  {'Rastrigin':<15} {'Multimodale':<15} {'[0, ..., 0], f=0':<20}\")\n",
    "print(f\"  {'Rosenbrock':<15} {'Vallee etroite':<15} {'[1, ..., 1], f=0':<20}\")\n",
    "print(f\"  {'Ackley':<15} {'Multimodale':<15} {'[0, ..., 0], f=0':<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-pso",
   "metadata": {},
   "source": [
    "## 4. Evolution-based - Particle Swarm Optimization (PSO) (~20 min)\n",
    "\n",
    "### Principe du PSO\n",
    "\n",
    "Le **Particle Swarm Optimization** est inspire du comportement social d'essaims (oiseaux, poissons). Chaque particule a :\n",
    "- Une **position** courante dans l'espace de recherche\n",
    "- Une **vitesse** qui determine son deplacement\n",
    "- Une **memoire** de sa meilleure position personnelle (pbest)\n",
    "- Une connaissance de la meilleure position globale (gbest)\n",
    "\n",
    "### Equations de mise a jour\n",
    "\n",
    "A chaque iteration, chaque particule $i$ met a jour sa vitesse et sa position :\n",
    "\n",
    "$$\n",
    "v_i(t+1) = w \\cdot v_i(t) + c_1 \\cdot r_1 \\cdot (pbest_i - x_i(t)) + c_2 \\cdot r_2 \\cdot (gbest - x_i(t))\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_i(t+1) = x_i(t) + v_i(t+1)\n",
    "$$\n",
    "\n",
    "Ou :\n",
    "- $w$ : inertie (conserve la vitesse actuelle)\n",
    "- $c_1, c_2$ : coefficients d'acceleration (typiquement $c_1 = c_2 = 2.0$)\n",
    "- $r_1, r_2$ : nombres aleatoires dans $[0, 1]$\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Chaque particule equilibre trois forces :\n",
    "1. **Inertie** : continuer dans sa direction actuelle\n",
    "2. **Cognitif** : retourner vers sa meilleure position personnelle\n",
    "3. **Social** : se diriger vers la meilleure position du groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pso-rastrigin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSO sur Rastrigin (fonction multimodale difficile)\n",
    "\n",
    "# Parametres du probleme\n",
    "dim = 10  # Dimension\n",
    "lb = [-5.12] * dim\n",
    "ub = [5.12] * dim\n",
    "\n",
    "# Definir le probleme\n",
    "problem_rastrigin = Problem(\n",
    "    lb=lb, ub=ub, minmax=\"min\", obj_func=rastrigin_function\n",
    ")\n",
    "\n",
    "# PSO avec parametres standards\n",
    "model = PSO.OriginalPSO(\n",
    "    epoch=200,      # Nombre d'iterations\n",
    "    pop_size=50,    # Taille de l'essaim\n",
    "    c1=2.0,         # Coefficient cognitif\n",
    "    c2=2.0,         # Coefficient social\n",
    "    w=0.9           # Inertie (commence haute pour l'exploration)\n",
    ")\n",
    "\n",
    "# Resoudre\n",
    "print(\"PSO sur Rastrigin (dim=10)...\")\n",
    "start_time = time.perf_counter()\n",
    "result_pso = model.solve(problem_rastrigin)\n",
    "elapsed_pso = (time.perf_counter() - start_time) * 1000\n",
    "\n",
    "print(f\"\\nResultat PSO:\")\n",
    "print(f\"  Solution: {np.array(result_pso.solution).round(4)}\")\n",
    "print(f\"  Objectif: {result_pso.target.fitness:.6f}\")\n",
    "print(f\"  Temps: {elapsed_pso:.2f} ms\")\n",
    "print(f\"  Optimal attendu: [0, ..., 0], f=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interp-pso-rastrigin",
   "metadata": {},
   "source": [
    "### Interpretation : PSO sur Rastrigin\n",
    "\n",
    "**Sortie obtenue** : PSO trouve une solution proche de l'optimum.\n",
    "\n",
    "| Aspect | Observation |\n",
    "|--------|------------|\n",
    "| Solution | Vecteur proche de [0, ..., 0] |\n",
    "| Objectif | Valeur faible mais rarement 0 exact |\n",
    "| Convergence | Rapide mais peut rester coince dans un optimum local |\n",
    "\n",
    "**Points cles** :\n",
    "1. PSO est **tres efficace** sur les problemes multimodaux\n",
    "2. L'equilibre exploration/exploitation est controle par $w$, $c_1$, $c_2$\n",
    "3. La communication sociale (gbest) permet une convergence rapide\n",
    "4. Sur Rastrigin, PSO performe mieux que Hill Climbing ou SA simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pso-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la convergence PSO\n",
    "\n",
    "# Creer une version custom pour capturer l'historique\n",
    "from mealpy import PSO\n",
    "\n",
    "class TrackedPSO(PSO.OriginalPSO):\n",
    "    \"\"\"PSO qui capture l'historique de convergence.\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.history = []\n",
    "    \n",
    "    def solve(self, problem, mode='single', n_workers=None, termination=None):\n",
    "        # Appeler la methode parent mais capturer l'historique\n",
    "        # Pour simplifier, on execute et on stocke le meilleur a chaque epoch\n",
    "        self.history = []\n",
    "        \n",
    "        # Initialisation\n",
    "        self.before_solve(problem)\n",
    "        \n",
    "        for epoch in range(self.epoch):\n",
    "            # Mise a jour des particules\n",
    "            self.evolve(epoch)\n",
    "            \n",
    "            # Capturer le meilleur\n",
    "            current_best = self.g_best_target.copy()\n",
    "            self.history.append(current_best.fitness)\n",
    "            \n",
    "            # Critere d'arret\n",
    "            if self.check_termination(problem, mode, epoch, termination):\n",
    "                break\n",
    "        \n",
    "        return self.get_solution(problem)\n",
    "\n",
    "# Relancer avec historique\n",
    "model_tracked = TrackedPSO(epoch=100, pop_size=30, w=0.9, c1=2.0, c2=2.0)\n",
    "result_tracked = model_tracked.solve(problem_rastrigin)\n",
    "\n",
    "# Visualiser\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(model_tracked.history, 'b-', linewidth=2, label='PSO')\n",
    "ax.set_xlabel('Iteration', fontsize=12)\n",
    "ax.set_ylabel('Meilleur fitness', fontsize=12)\n",
    "ax.set_title('Convergence PSO - Rastrigin', fontsize=14, fontweight='bold')\n",
    "ax.set_yscale('log')  # Echelle logarithmique pour voir les details\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConvergence:\")\n",
    "print(f\"  Initial: {model_tracked.history[0]:.6f}\")\n",
    "print(f\"  Final: {model_tracked.history[-1]:.6f}\")\n",
    "print(f\"  Amelioration: {model_tracked.history[0] / model_tracked.history[-1]:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z72pvyvzkna",
   "source": "### Interpretation : Convergence PSO\n\n**Sortie obtenue** : La courbe de convergence montre l'evolution de la meilleure solution trouvee par PSO au fil des iterations.\n\n| Phase | Iterations | Comportement |\n|-------|------------|--------------|\n| Exploration | 0-30 | Amelioration rapide (decomposition de l'espace) |\n| Transition | 30-60 | Ralentissement (convergence vers l'optimum) |\n| Exploitation | 60-100 | Affinage (convergence finale) |\n\n**Points cles** :\n1. **Exploration initiale** : Les premieres iterations reduisent drastiquement la fitness\n2. **Plateaux** : Les paliers indiquent des optima locaux temporaires\n3. **Echelle log** : Necessaire pour voir les details de convergence\n4. **Amelioration factorielle** : Le ratio montre l'efficacite globale\n\n> **Note technique** : La classe `TrackedPSO` etend `PSO.OriginalPSO` en capturant l'historique. Cette implementation utilise des methodes internes de MEALPy (`before_solve`, `evolve`, `check_termination`) qui pourraient changer dans les versions futures. Pour un usage en production, utiliser plutot l'API standard ou sauvegarder les resultats intermediaires manuellement.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "section-5-abc",
   "metadata": {},
   "source": [
    "## 5. Swarm-based - Artificial Bee Colony (ABC) (~20 min)\n",
    "\n",
    "### Principe de l'ABC\n",
    "\n",
    "L'**Artificial Bee Colony** est inspire du comportement de butinage des abeilles. La colonie est divisee en trois types d'abeilles :\n",
    "\n",
    "| Type | Role | Comportement |\n",
    "|------|------|--------------|\n",
    "| **Ouvrieres** (Employed) | Exploiter les sources connues | Danse autour de la nourriture |\n",
    "| **Observatrices** (Onlooker) | Choisir une source | Selection probabiliste par qualite |\n",
    "| **Eclaireuses** (Scout) | Decouvrir nouvelles sources | Recherche aleatoire |\n",
    "\n",
    "### Algorithme\n",
    "\n",
    "1. **Initialisation** : Distribuer les abeilles ouvrieres aleatoirement\n",
    "2. **Phase employed** : Chaque ouvriere exploite sa source, en cherche une voisine\n",
    "3. **Phase onlooker** : Les observatrices choisissent une source (probabilite = qualite)\n",
    "4. **Phase scout** : Si une source est epuisee, son abeille devient eclaireuse\n",
    "5. **Memorisation** : Garder la meilleure source trouvee\n",
    "\n",
    "### Avantages\n",
    "- Bon equilibre exploration/exploitation\n",
    "- Peu de parametres a regler\n",
    "- Efficace sur les problemes multimodaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc-rosenbrock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABC sur Rosenbrock (vallee etroite)\n",
    "\n",
    "# Parametres du probleme\n",
    "dim = 10\n",
    "lb = [-5] * dim\n",
    "ub = [10] * dim  # L'optimal est a [1, ..., 1]\n",
    "\n",
    "# Definir le probleme\n",
    "problem_rosenbrock = Problem(\n",
    "    lb=lb, ub=ub, minmax=\"min\", obj_func=rosenbrock_function\n",
    ")\n",
    "\n",
    "# ABC avec parametres standards\n",
    "model = ABC.OriginalABC(\n",
    "    epoch=200,         # Nombre de cycles\n",
    "    pop_size=50,       # Nombre de sources de nourriture (colonie)\n",
    "    n_limits=50        # Limite avant qu'une source soit abandonnee\n",
    ")\n",
    "\n",
    "# Resoudre\n",
    "print(\"ABC sur Rosenbrock (dim=10)...\")\n",
    "start_time = time.perf_counter()\n",
    "result_abc = model.solve(problem_rosenbrock)\n",
    "elapsed_abc = (time.perf_counter() - start_time) * 1000\n",
    "\n",
    "print(f\"\\nResultat ABC:\")\n",
    "print(f\"  Solution: {np.array(result_abc.solution).round(4)}\")\n",
    "print(f\"  Objectif: {result_abc.target.fitness:.6f}\")\n",
    "print(f\"  Temps: {elapsed_abc:.2f} ms\")\n",
    "print(f\"  Optimal attendu: [1, ..., 1], f=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interp-abc-rosenbrock",
   "metadata": {},
   "source": [
    "### Interpretation : ABC sur Rosenbrock\n",
    "\n",
    "**Sortie obtenue** : ABC trouve une solution proche de [1, ..., 1].\n",
    "\n",
    "| Aspect | Observation |\n",
    "|--------|------------|\n",
    "| Solution | Vecteur proche de [1, ..., 1] |\n",
    "| Convergence | Plus lente que PSO mais plus stable |\n",
    "| Exploration | Les eclaireurs permettent d'eviter les optima locaux |\n",
    "\n",
    "**Points cles** :\n",
    "1. ABC est particulierement adapté aux problemes avec **vallee etroite** comme Rosenbrock\n",
    "2. La phase **scout** (recherche aleatoire) est cruciale pour l'exploration\n",
    "3. Le parametre `n_limits` controle l'equilibre : trop petit = exploration excessive, trop grand = exploitation excessive\n",
    "4. ABC est moins sensible aux parametres que PSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6-sa",
   "metadata": {},
   "source": [
    "## 6. Physics-based - Simulated Annealing (SA) (~15 min)\n",
    "\n",
    "### Lien avec Search-4\n",
    "\n",
    "Nous avons deja vu le **Simulated Annealing** dans le notebook Search-4-LocalSearch. MEALPy fournit une implementation alternative qui suit la meme API.\n",
    "\n",
    "### Rappel du principe\n",
    "\n",
    "SA s'inspire du processus metallurgique de recuit :\n",
    "1. Chauffer le materiau a haute temperature (desordre)\n",
    "2. Refroidir lentement (organisation progressive)\n",
    "3. Obtenir une structure cristalline optimale\n",
    "\n",
    "### Critere d'acceptation\n",
    "\n",
    "$$\n",
    "P(accepter) = \\begin{cases}\n",
    "1 & \\text{si } \\Delta E \\leq 0 \\\n",
    "e^{-\\Delta E / T} & \\text{si } \\Delta E > 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Ou $\\Delta E = f(x_{new}) - f(x_{current})$ et $T$ est la temperature qui diminue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sa-ackley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA (MEALPy) sur Ackley\n",
    "\n",
    "# Parametres du probleme\n",
    "dim = 10\n",
    "lb = [-5] * dim\n",
    "ub = [5] * dim\n",
    "\n",
    "# Definir le probleme\n",
    "problem_ackley = Problem(\n",
    "    lb=lb, ub=ub, minmax=\"min\", obj_func=ackley_function\n",
    ")\n",
    "\n",
    "# SA avec MEALPy\n",
    "model = SA.OriginalSA(\n",
    "    epoch=500,            # Nombre d'iterations\n",
    "    pop_size=50,          # Nombre de solutions (MEALPy utilise une population)\n",
    "    temp_init=100,        # Temperature initiale\n",
    "    step_size=0.1         # Amplitude du voisinage\n",
    ")\n",
    "\n",
    "# Resoudre\n",
    "print(\"SA (MEALPy) sur Ackley (dim=10)...\")\n",
    "start_time = time.perf_counter()\n",
    "result_sa = model.solve(problem_ackley)\n",
    "elapsed_sa = (time.perf_counter() - start_time) * 1000\n",
    "\n",
    "print(f\"\\nResultat SA:\")\n",
    "print(f\"  Solution: {np.array(result_sa.solution).round(4)}\")\n",
    "print(f\"  Objectif: {result_sa.target.fitness:.6f}\")\n",
    "print(f\"  Temps: {elapsed_sa:.2f} ms\")\n",
    "print(f\"  Optimal attendu: [0, ..., 0], f=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interp-sa-ackley",
   "metadata": {},
   "source": [
    "### Interpretation : SA sur Ackley\n",
    "\n",
    "**Sortie obtenue** : SA trouve une solution acceptable sur Ackley.\n",
    "\n",
    "| Aspect | Observation |\n",
    "|--------|------------|\n",
    "| Convergence | Lente mais stable |\n",
    "| Qualite | Solution satisfaisante mais pas toujours optimale |\n",
    "| Temperature | Controle l'equilibre exploration/exploitation |\n",
    "\n",
    "**Points cles** :\n",
    "1. L'implementation MEALPy de SA utilise une **population** (contrairement a SA classique)\n",
    "2. SA est moins efficace que PSO ou ABC sur les problemes de haute dimension\n",
    "3. SA reste utile pour les problemes ou l'evaluation est **tres couteuse** (peu d'evaluations)\n",
    "4. Le parametre `temp_init` est critique : trop haut = exploration excessive, trop bas = blocage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7-bro",
   "metadata": {},
   "source": [
    "## 7. Human-based - Brownian Optimization (BRO) (~15 min)\n",
    "\n",
    "### Principe du BRO\n",
    "\n",
    "Le **Brownian Optimization** s'inspire du mouvement brownien observe dans les particules en suspension (mouvement aleatoire). Cette metaheuristique de categorie \"Human-based\" simule le comportement de recherche aleatoire avec tendance a explorer.\n",
    "\n",
    "### Algorithme\n",
    "\n",
    "1. **Initialisation** : Generer une population aleatoire\n",
    "2. **Mouvement brownien** : Chaque solution se deplace aleatoirement\n",
    "3. **Tendance centrale** : Attraction vers le meilleur trouve\n",
    "4. **Selection** : Garder les meilleures solutions\n",
    "\n",
    "### Avantages\n",
    "- Simple a implementer\n",
    "- Efficace sur les problemes lisses et convexes\n",
    "- Peu de parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bro-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRO sur Sphere (probleme convexe simple)\n",
    "\n",
    "# Parametres du probleme\n",
    "dim = 10\n",
    "lb = [-10] * dim\n",
    "ub = [10] * dim\n",
    "\n",
    "# Definir le probleme\n",
    "problem_sphere = Problem(\n",
    "    lb=lb, ub=ub, minmax=\"min\", obj_func=sphere_function\n",
    ")\n",
    "\n",
    "# BRO\n",
    "model = BRO.OriginalBRO(\n",
    "    epoch=100,\n",
    "    pop_size=50\n",
    ")\n",
    "\n",
    "# Resoudre\n",
    "print(\"BRO sur Sphere (dim=10)...\")\n",
    "start_time = time.perf_counter()\n",
    "result_bro = model.solve(problem_sphere)\n",
    "elapsed_bro = (time.perf_counter() - start_time) * 1000\n",
    "\n",
    "print(f\"\\nResultat BRO:\")\n",
    "print(f\"  Solution: {np.array(result_bro.solution).round(6)}\")\n",
    "print(f\"  Objectif: {result_bro.target.fitness:.8f}\")\n",
    "print(f\"  Temps: {elapsed_bro:.2f} ms\")\n",
    "print(f\"  Optimal attendu: [0, ..., 0], f=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interp-bro-sphere",
   "metadata": {},
   "source": [
    "### Interpretation : BRO sur Sphere\n",
    "\n",
    "**Sortie obtenue** : BRO trouve une solution tres proche de l'optimal sur Sphere.\n",
    "\n",
    "| Aspect | Observation |\n",
    "|--------|------------|\n",
    "| Qualite | Excellent sur probleme convexe |\n",
    "| Convergence | Rapide |\n",
    "| Robustesse | Moins robuste sur problemes multimodaux |\n",
    "\n",
    "**Points cles** :\n",
    "1. BRO excelle sur les problemes **unimodaux convexes** comme Sphere\n",
    "2. Le mouvement brownien fournit une exploration naturelle\n",
    "3. Sur des problemes plus difficiles (Rastrigin, Ackley), BRO peut avoir du mal a converger\n",
    "4. BRO est un bon choix pour les problemes \"faciles\" ou l'on veut une solution rapide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8-comparative",
   "metadata": {},
   "source": [
    "## 8. Benchmark Comparatif (~15 min)\n",
    "\n",
    "Comparons maintenant les quatre algorithmes (PSO, ABC, SA, BRO) sur les quatre fonctions de benchmark pour observer leurs performances relatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du benchmark\n",
    "\n",
    "algorithms = {\n",
    "    'PSO': PSO.OriginalPSO(epoch=100, pop_size=30),\n",
    "    'ABC': ABC.OriginalABC(epoch=100, pop_size=30),\n",
    "    'SA': SA.OriginalSA(epoch=300, pop_size=30, temp_init=100),\n",
    "    'BRO': BRO.OriginalBRO(epoch=100, pop_size=30)\n",
    "}\n",
    "\n",
    "functions = {\n",
    "    'Sphere': (sphere_function, [-10]*10, [10]*10, [0]*10),\n",
    "    'Rastrigin': (rastrigin_function, [-5.12]*10, [5.12]*10, [0]*10),\n",
    "    'Rosenbrock': (rosenbrock_function, [-5]*10, [10]*10, [1]*10),\n",
    "    'Ackley': (ackley_function, [-5]*10, [5]*10, [0]*10)\n",
    "}\n",
    "\n",
    "# Stocker les resultats\n",
    "results = []\n",
    "\n",
    "print(\"Benchmark comparatif d'algorithmes\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Algorithme':<12} {'Fonction':<12} {'Fitness':<12} {'Erreur':<12} {'Temps (ms)':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for algo_name, algo_model in algorithms.items():\n",
    "    for func_name, (func, lb, ub, optimal) in functions.items():\n",
    "        # Creer le probleme\n",
    "        problem = Problem(lb=lb, ub=ub, minmax=\"min\", obj_func=func)\n",
    "        \n",
    "        # Resoudre\n",
    "        start = time.perf_counter()\n",
    "        result = algo_model.solve(problem)\n",
    "        elapsed = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        # Calculer l'erreur (distance a l'optimal)\n",
    "        solution = np.array(result.solution)\n",
    "        error = np.linalg.norm(solution - np.array(optimal))\n",
    "        \n",
    "        # Stocker\n",
    "        results.append({\n",
    "            'algorithm': algo_name,\n",
    "            'function': func_name,\n",
    "            'fitness': result.target.fitness,\n",
    "            'error': error,\n",
    "            'time_ms': elapsed\n",
    "        })\n",
    "        \n",
    "        print(f\"{algo_name:<12} {func_name:<12} {result.target.fitness:<12.4f} {error:<12.4f} {elapsed:<12.1f}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-viz",
   "metadata": {},
   "source": [
    "Visualisons les resultats pour comparer les algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-plots",
   "metadata": {},
   "outputs": [],
   "source": "# Creer un DataFrame pour faciliter la visualisation\ndf = pd.DataFrame(results)\n\n# Figure avec 2 sous-graphes\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Preparer les donnees pour les barres\nalgorithms = df['algorithm'].unique()\nfunctions = df['function'].unique()\nn_algos = len(algorithms)\nn_funcs = len(functions)\n\n# Definir les couleurs pour chaque algorithme\ncolors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\nbar_width = 0.2\nx_base = np.arange(n_funcs)\n\n# Graphique 1: Fitness par fonction (en echelle log)\nfor i, algo in enumerate(algorithms):\n    fitness_vals = [df[(df['algorithm'] == algo) & (df['function'] == func)]['fitness'].values[0] \n                    for func in functions]\n    bars = ax1.bar(x_base + i * bar_width, fitness_vals, bar_width, \n                   label=algo, color=colors[i], alpha=0.8)\n    # Ajouter les valeurs sur les barres\n    for bar, val in zip(bars, fitness_vals):\n        height = bar.get_height()\n        ax1.text(bar.get_x() + bar.get_width()/2., height,\n                f'{val:.2f}', ha='center', va='bottom', fontsize=8)\n\nax1.set_yscale('log')\nax1.set_xlabel('Fonction', fontsize=12)\nax1.set_ylabel('Fitness (log)', fontsize=12)\nax1.set_title('Fitness par fonction (echelle log)', fontsize=13, fontweight='bold')\nax1.set_xticks(x_base + bar_width * (n_algos - 1) / 2)\nax1.set_xticklabels(functions)\nax1.grid(axis='y', alpha=0.3)\nax1.legend(title='Algorithme', fontsize=10)\n\n# Graphique 2: Temps d'execution\nfor i, algo in enumerate(algorithms):\n    time_vals = [df[(df['algorithm'] == algo) & (df['function'] == func)]['time_ms'].values[0] \n                 for func in functions]\n    bars = ax2.bar(x_base + i * bar_width, time_vals, bar_width,\n                   label=algo, color=colors[i], alpha=0.8)\n    # Ajouter les valeurs sur les barres\n    for bar, val in zip(bars, time_vals):\n        height = bar.get_height()\n        ax2.text(bar.get_x() + bar.get_width()/2., height,\n                f'{val:.0f}', ha='center', va='bottom', fontsize=8)\n\nax2.set_xlabel('Fonction', fontsize=12)\nax2.set_ylabel('Temps (ms)', fontsize=12)\nax2.set_title('Temps d\\'execution', fontsize=13, fontweight='bold')\nax2.set_xticks(x_base + bar_width * (n_algos - 1) / 2)\nax2.set_xticklabels(functions)\nax2.grid(axis='y', alpha=0.3)\nax2.legend(title='Algorithme', fontsize=10)\n\nplt.suptitle('Comparaison des metaheuristiques', fontsize=15, fontweight='bold')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "interp-comparative",
   "metadata": {},
   "source": [
    "### Interpretation : Comparaison des algorithmes\n",
    "\n",
    "**Observations generales** :\n",
    "\n",
    "| Algorithme | Forces | Faiblesses | Meilleur sur |\n",
    "|------------|--------|------------|--------------|\n",
    "| **PSO** | Convergence rapide, bon multimodal | Peut coincer dans optima local | Rastrigin |\n",
    "| **ABC** | Robuste, bon equilibre E/I | Plus lent | Rosenbrock |\n",
    "| **SA** | Simple, garanti theorique | Lent, moins efficace en haute dim | Ackley |\n",
    "| **BRO** | Tres rapide surprobleme simple | Multimodal difficile | Sphere |\n",
    "\n",
    "**Conclusions pratiques** :\n",
    "1. **PSO** est souvent le meilleur choix generaliste\n",
    "2. **ABC** excelle quand le probleme a une vallee etroite (Rosenbrock)\n",
    "3. **SA** est utile quand l'evaluation est tres couteuse (peu d'evaluations)\n",
    "4. **BRO** est bon pour des problemes convexes simples\n",
    "\n",
    "> **Regle empirique** : Essayer PSO en premier, puis ABC si PSO echoue. SA en dernier recours ou pour les problemes avec evaluation couteuse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9-parameter-tuning",
   "metadata": {},
   "source": [
    "## 9. Analyse des Parametres (~10 min)\n",
    "\n",
    "Les metaheuristiques ont des **hyperparametres** qui affectent significativement les performances. Analysons l'impact de deux parametres PSO clés : `pop_size` et `w` (inertie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parameter-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de l'impact de pop_size\n",
    "\n",
    "pop_sizes = [10, 30, 50, 100]\n",
    "results_pop = []\n",
    "\n",
    "print(\"Impact de pop_size sur PSO (Rastrigin, dim=10)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Pop_size':<12} {'Fitness':<15} {'Temps (ms)':<12} {'Evaluations':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for ps in pop_sizes:\n",
    "    model = PSO.OriginalPSO(epoch=50, pop_size=ps, w=0.9, c1=2.0, c2=2.0)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    result = model.solve(problem_rastrigin)\n",
    "    elapsed = (time.perf_counter() - start) * 1000\n",
    "    \n",
    "    evals = model.epoch * ps  # Nombre approximatif d'evaluations\n",
    "    \n",
    "    results_pop.append({\n",
    "        'pop_size': ps,\n",
    "        'fitness': result.target.fitness,\n",
    "        'time_ms': elapsed,\n",
    "        'evaluations': evals\n",
    "    })\n",
    "    \n",
    "    print(f\"{ps:<12} {result.target.fitness:<15.4f} {elapsed:<12.1f} {evals:<15}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nObservation: Une population plus grande ameliore la qualite\")\n",
    "print(\"mais augmente le temps de calcul lineairement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parameter-plot",
   "metadata": {},
   "source": [
    "Visualisons l'impact de la taille de population sur la qualite de la solution et le temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parameter-plot-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'impact de pop_size\n",
    "df_pop = pd.DataFrame(results_pop)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Fitness vs pop_size\n",
    "ax1.plot(df_pop['pop_size'], df_pop['fitness'], 'o-', linewidth=2, markersize=8, color='#4CAF50')\n",
    "ax1.set_xlabel('Taille de population', fontsize=12)\n",
    "ax1.set_ylabel('Fitness final', fontsize=12)\n",
    "ax1.set_title('Impact de pop_size sur la qualite', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Temps vs pop_size\n",
    "ax2.plot(df_pop['pop_size'], df_pop['time_ms'], 'o-', linewidth=2, markersize=8, color='#2196F3')\n",
    "ax2.set_xlabel('Taille de population', fontsize=12)\n",
    "ax2.set_ylabel('Temps (ms)', fontsize=12)\n",
    "ax2.set_title('Impact de pop_size sur le temps', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Analyse du parametre pop_size (PSO)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnalyse:\")\n",
    "print(f\"  Amelioration fitness: {df_pop['fitness'].iloc[0] / df_pop['fitness'].iloc[-1]:.2f}x\")\n",
    "print(f\"  Augmentation temps: {df_pop['time_ms'].iloc[-1] / df_pop['time_ms'].iloc[0]:.2f}x\")\n",
    "print(f\"  Ratio gain/coût: {(df_pop['fitness'].iloc[0] / df_pop['fitness'].iloc[-1]) / (df_pop['time_ms'].iloc[-1] / df_pop['time_ms'].iloc[0]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ouzebetmz3n",
   "source": "### Interpretation : Impact de la taille de population\n\n**Sortie obtenue** : La taille de population affecte significativement la qualite de la solution et le temps de calcul.\n\n| Metrique | Observation | Interpretation |\n|----------|-------------|----------------|\n| Fitness | Ameliore avec pop_size croissant | Plus de particules = meilleure exploration |\n| Temps | Croissance lineaire | Chaque particule additionnelle coute le meme temps |\n| Ratio gain/coût | Diminue avec pop_size | Loi des rendements decroissants |\n\n**Points cles** :\n1. **Effet positif** : Une population plus grande ameliore la qualite de la solution\n2. **Loi des rendements decroissants** : Le gain marginal diminue avec pop_size\n3. **Cout lineaire** : Le temps de calcul augmente proportionnellement a pop_size\n4. **Choix optimal** : pop_size=30-50 est souvent un bon compromis\n\n> **Note pratique** : Pour un probleme de dimension 10, pop_size=30 suffit generalement. Augmenter a 100+ ne justifie le cout que pour des problemes tres difficiles.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "section-10-exercises",
   "metadata": {},
   "source": [
    "## 10. Exercices\n",
    "\n",
    "### Exercice 1 : Comparer PSO et ABC sur un probleme reel\n",
    "\n",
    "**Enonce** : Soit le probleme d'optimisation suivant (maximisation du profit d'une entreprise):\n",
    "\n",
    "$$\n",
    "\\max_{x, y} \\quad 50x + 80y - x^2 - 2y^2 - xy\n",
    "\\quad \\text{s.t.} \\quad x \\in [0, 20], y \\in [0, 20]\n",
    "$$\n",
    "\n",
    "1. Convertir en probleme de minimisation pour MEALPy\n",
    "2. Resoudre avec PSO et ABC (epoch=100, pop_size=30)\n",
    "3. Comparer les solutions obtenues\n",
    "\n",
    "**Indice** : Pour maximiser $f$, minimiser $-f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1 : Probleme d'optimisation d'entreprise\n",
    "\n",
    "def profit_function(solution):\n",
    "    \"\"\"Fonction de profit a maximiser: 50*x + 80*y - x^2 - 2*y^2 - x*y.\n",
    "    \n",
    "    Pour MEALPy, on retourne l'oppose (minimisation).\n",
    "    \"\"\"\n",
    "    x, y = solution\n",
    "    profit = 50*x + 80*y - x**2 - 2*y**2 - x*y\n",
    "    return -profit  # Minimiser l'oppose = maximiser\n",
    "\n",
    "# A COMPLETER\n",
    "# 1. Definir le probleme avec lb=[0, 0], ub=[20, 20]\n",
    "# 2. Resoudre avec PSO et ABC\n",
    "# 3. Comparer les resultats\n",
    "\n",
    "print(\"A completer...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-1-solution",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution Exercice 1</b> (cliquez pour afficher)</summary>\n",
    "\n",
    "```python\n",
    "# Solution\n",
    "\n",
    "# Definir le probleme\n",
    "problem_profit = Problem(\n",
    "    lb=[0, 0], ub=[20, 20], minmax=\"min\", obj_func=profit_function\n",
    ")\n",
    "\n",
    "# PSO\n",
    "pso = PSO.OriginalPSO(epoch=100, pop_size=30)\n",
    "result_pso = pso.solve(problem_profit)\n",
    "\n",
    "# ABC\n",
    "abc = ABC.OriginalABC(epoch=100, pop_size=30)\n",
    "result_abc = abc.solve(problem_profit)\n",
    "\n",
    "print(\"Solution PSO:\")\n",
    "print(f\"  x={result_pso.solution[0]:.4f}, y={result_pso.solution[1]:.4f}\")\n",
    "print(f\"  Profit max: {-result_pso.target.fitness:.4f}\")\n",
    "\n",
    "print(\"\\nSolution ABC:\")\n",
    "print(f\"  x={result_abc.solution[0]:.4f}, y={result_abc.solution[1]:.4f}\")\n",
    "print(f\"  Profit max: {-result_abc.target.fitness:.4f}\")\n",
    "\n",
    "# Solution analytique (derivees partielles = 0)\n",
    "# d/dx: 50 - 2x - y = 0  => y = 50 - 2x\n",
    "# d/dy: 80 - 4y - x = 0\n",
    "# Substitution: 80 - 4(50 - 2x) - x = 0 => 80 - 200 + 8x - x = 0 => 7x = 120 => x = 120/7\n",
    "# y = 50 - 2*(120/7) = (350 - 240) / 7 = 110/7\n",
    "x_opt = 120/7\n",
    "y_opt = 110/7\n",
    "profit_opt = 50*x_opt + 80*y_opt - x_opt**2 - 2*y_opt**2 - x_opt*y_opt\n",
    "print(f\"\\nSolution analytique: x={x_opt:.4f}, y={y_opt:.4f}, profit={profit_opt:.4f}\")\n",
    "```\n",
    "\n",
    "**Resultat attendu** : PSO et ABC trouvent tous les deux des solutions proches de l'optimal analytique (x≈17.14, y≈15.71, profit≈678.57).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2",
   "metadata": {},
   "source": [
    "### Exercice 2 : Impact de la dimension\n",
    "\n",
    "**Enonce** : Etudiez l'impact de la dimension sur les performances de PSO :\n",
    "1. Lancez PSO sur la fonction Sphere pour dim = 2, 5, 10, 20\n",
    "2. Pour chaque dimension, mesurez : fitness final, temps de calcul\n",
    "3. Tracez l'evolution de ces metriques en fonction de la dimension\n",
    "\n",
    "**Question** : Comment le temps de calcul evolue-t-il avec la dimension ? Est-ce lineaire, quadratique, exponentiel ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 : Impact de la dimension\n",
    "\n",
    "dimensions = [2, 5, 10, 20]\n",
    "results_dim = []\n",
    "\n",
    "# A COMPLETER\n",
    "for dim in dimensions:\n",
    "    # Definir le probleme\n",
    "    # Lancer PSO avec epoch=50, pop_size=30\n",
    "    # Stocker resultats\n",
    "    pass\n",
    "\n",
    "# Visualiser\n",
    "# plt.plot(...)\n",
    "\n",
    "print(\"A completer...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2-solution",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution Exercice 2</b> (cliquez pour afficher)</summary>\n",
    "\n",
    "```python\n",
    "dimensions = [2, 5, 10, 20]\n",
    "results_dim = []\n",
    "\n",
    "print(\"Impact de la dimension sur PSO (Sphere)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Dim':<8} {'Fitness':<15} {'Temps (ms)':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for dim in dimensions:\n",
    "    problem = Problem(\n",
    "        lb=[-10]*dim, ub=[10]*dim, minmax=\"min\", obj_func=sphere_function\n",
    "    )\n",
    "    \n",
    "    model = PSO.OriginalPSO(epoch=50, pop_size=30)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    result = model.solve(problem)\n",
    "    elapsed = (time.perf_counter() - start) * 1000\n",
    "    \n",
    "    results_dim.append({\n",
    "        'dim': dim,\n",
    "        'fitness': result.target.fitness,\n",
    "        'time_ms': elapsed\n",
    "    })\n",
    "    \n",
    "    print(f\"{dim:<8} {result.target.fitness:<15.6f} {elapsed:<15.1f}\")\n",
    "\n",
    "# Visualisation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "dims = [r['dim'] for r in results_dim]\n",
    "fitnesses = [r['fitness'] for r in results_dim]\n",
    "times = [r['time_ms'] for r in results_dim]\n",
    "\n",
    "ax1.plot(dims, fitnesses, 'o-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Dimension', fontsize=12)\n",
    "ax1.set_ylabel('Fitness final', fontsize=12)\n",
    "ax1.set_title('Qualite vs dimension', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(dims, times, 'o-', linewidth=2, markersize=8, color='#FF9800')\n",
    "ax2.set_xlabel('Dimension', fontsize=12)\n",
    "ax2.set_ylabel('Temps (ms)', fontsize=12)\n",
    "ax2.set_title('Temps vs dimension', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Impact de la dimension (PSO sur Sphere)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConclusion: Le temps de calcul evolue lineairement avec la dimension.\")\n",
    "print(\"Complexite: O(dim * epoch * pop_size)\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-11-summary",
   "metadata": {},
   "source": [
    "## 11. Resume\n",
    "\n",
    "### Concepts cles\n",
    "\n",
    "| Concept | Definition |\n",
    "|---------|------------|\n",
    "| **Metaheuristique** | Algorithme d'optimisation stochastique sans derivees |\n",
    "| **Exploration** | Decouverte de nouvelles regions de l'espace |\n",
    "| **Exploitation** | Affinage des solutions prometteuses |\n",
    "| **No Free Lunch** : Aucun algorithme n'est optimal pour tous les problemes |\n",
    "\n",
    "### Classification des metaheuristiques\n",
    "\n",
    "| Categorie | Inspiration | Algorithmes | Meilleur sur |\n",
    "|-----------|-------------|-------------|-------------|\n",
    "| **Evolution-based** | Theorie de l'evolution | GA, DE | Problemes generaux |\n",
    "| **Swarm-based** | Essaims naturels | PSO, ABC, GWO | Multimodal, dynamique |\n",
    "| **Physics-based** | Loi physique | SA, GRAVITY | Probleme specifiques |\n",
    "| **Human-based** | Comportement humain | BRO, TS | Problemes structures |\n",
    "\n",
    "### Tableau comparatif\n",
    "\n",
    "| Algorithme | Complexite | Parametres | Robustesse | Vitesse |\n",
    "|------------|------------|-----------|------------|---------|\n",
    "| **PSO** | O(n*epoch*p) | w, c1, c2 | +++ | ++ |\n",
    "| **ABC** | O(n*epoch*p) | n_limits | ++++ | + |\n",
    "| **SA** | O(epoch*n) | T0, alpha | ++ | + |\n",
    "| **BRO** | O(n*epoch*p) | Peu | ++ | +++ |\n",
    "\n",
    "### Quand utiliser quelle metaheuristique ?\n",
    "\n",
    "| Situation | Algorithme recommande |\n",
    "|-----------|----------------------|\n",
    "| Probleme general, multimodal | PSO |\n",
    "| Vallees etroites, contraintes | ABC |\n",
    "| Evaluation tres couteuse | SA (peu d'iterations) |\n",
    "| Probleme convexe simple | BRO |\n",
    "| Probleme avec contraintes complexes | DE, GA |\n",
    "\n",
    "### Pour aller plus loin\n",
    "\n",
    "- **Notebook suivant** : [App-1-NQueens](../Applications/App-1-NQueens.ipynb) - Application des metaheuristiques au N-Reines\n",
    "- **MEALPy documentation** : https://mealpy.readthedocs.io/ - Liste complete des 200+ algorithmes\n",
    "- **Reference** : Yang, X.-S. (2010). *Nature-Inspired Metaheuristic Algorithms*. Luniver Press"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nav-footer",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Navigation** : [<< Recherche locale](Search-4-LocalSearch.ipynb) | [Index](../README.md) | [App-1-NQueens >>](../Applications/App-1-NQueens.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}