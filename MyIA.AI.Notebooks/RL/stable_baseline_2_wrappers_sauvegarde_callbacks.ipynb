{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26c3169",
   "metadata": {
    "papermill": {
     "duration": 0.002754,
     "end_time": "2026-02-20T08:48:53.357446",
     "exception": false,
     "start_time": "2026-02-20T08:48:53.354692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Notebook 2 – Wrappers Gym, Sauvegarde/Chargement, Multiprocessing, Callbacks et Environnements Personnalisés\n",
    "\n",
    "Ce notebook propose un survol des fonctionnalités avancées de la librairie [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3) :\n",
    "1. **Utilisation de wrappers Gym** (limitation du nombre d’étapes, normalisation des actions, etc.)\n",
    "2. **Sauvegarde et chargement de modèles**\n",
    "3. **Multiprocessing** et environnements vectorisés\n",
    "4. **Callbacks** : enregistrement automatique, traçage en temps réel, etc.\n",
    "5. **Création d’un environnement Gym personnalisé**\n",
    "\n",
    "Nous utilisons un environnement sous Windows, donc nous évitons certaines dépendances (`xvfb`, `freeglut3-dev`) et nous n’utilisons pas de commandes `apt-get`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f1487",
   "metadata": {
    "papermill": {
     "duration": 0.002014,
     "end_time": "2026-02-20T08:48:53.363435",
     "exception": false,
     "start_time": "2026-02-20T08:48:53.361421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installation et imports essentiels\n",
    "Dans un environnement Python classique, on installera Stable Baselines3 (et les dépendances gym) via :\n",
    "```\n",
    "pip install stable-baselines3[extra]\n",
    "```\n",
    "ou bien :\n",
    "```\n",
    "%pip install \"stable-baselines3[extra]>=2.0.0a4\"\n",
    "```\n",
    "si vous utilisez un notebook. \n",
    "\n",
    "Ensuite, on importe les principales classes dont on aura besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddff0be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T08:48:53.369338Z",
     "iopub.status.busy": "2026-02-20T08:48:53.368817Z",
     "iopub.status.idle": "2026-02-20T08:49:50.859300Z",
     "shell.execute_reply": "2026-02-20T08:49:50.858788Z"
    },
    "execution_count": null,
    "id": "InstallCell",
    "papermill": {
     "duration": 57.49518,
     "end_time": "2026-02-20T08:49:50.860305",
     "exception": false,
     "start_time": "2026-02-20T08:48:53.365125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3>=2.0.0a4 (from stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading stable_baselines3-2.8.0a2-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting gymnasium<1.3.0,>=0.29.1 (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading gymnasium-1.2.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.3.4)\n",
      "Collecting torch<3.0,>=2.3 (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading torch-2.10.0-cp311-cp311-win_amd64.whl.metadata (31 kB)\n",
      "Collecting cloudpickle (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.10.8)\n",
      "Collecting opencv-python (from stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading opencv_python-4.13.0.92-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting pygame (from stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading pygame-2.6.1-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (7.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (4.67.1)\n",
      "Collecting rich (from stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading rich-14.3.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting ale-py>=0.9.0 (from stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading ale_py-0.11.2-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a4) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (4.15.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium<1.3.0,>=0.29.1->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading absl_py-2.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.78.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading markdown-3.10.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (6.33.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (65.5.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.1.1)\n",
      "Collecting filelock (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Using cached filelock-3.24.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2026.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2025.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (2.19.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->stable-baselines3[extra]>=2.0.0a4) (0.4.6)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a4)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jsboi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.0.3)\n",
      "Downloading stable_baselines3-2.8.0a2-py3-none-any.whl (187 kB)\n",
      "   ---------------------------------------- 0.0/187.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 187.3/187.3 kB 11.1 MB/s eta 0:00:00\n",
      "Downloading ale_py-0.11.2-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.5/3.5 MB 73.6 MB/s eta 0:00:00\n",
      "Downloading gymnasium-1.2.3-py3-none-any.whl (952 kB)\n",
      "   ---------------------------------------- 0.0/952.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 952.1/952.1 kB 29.4 MB/s eta 0:00:00\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 3.6/5.5 MB 114.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 89.0 MB/s eta 0:00:00\n",
      "Using cached torch-2.10.0-cp311-cp311-win_amd64.whl (113.7 MB)\n",
      "Downloading opencv_python-4.13.0.92-cp37-abi3-win_amd64.whl (40.2 MB)\n",
      "   ---------------------------------------- 0.0/40.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 4.1/40.2 MB 132.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 7.4/40.2 MB 95.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 10.9/40.2 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 14.4/40.2 MB 81.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 17.8/40.2 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 21.4/40.2 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 24.7/40.2 MB 73.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 28.5/40.2 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 31.8/40.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.3/40.2 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.6/40.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.2/40.2 MB 73.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.2/40.2 MB 73.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.2/40.2 MB 46.9 MB/s eta 0:00:00\n",
      "Downloading pygame-2.6.1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/10.6 MB 50.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.8/10.6 MB 72.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 65.5 MB/s eta 0:00:00\n",
      "Downloading rich-14.3.3-py3-none-any.whl (310 kB)\n",
      "   ---------------------------------------- 0.0/310.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 310.5/310.5 kB 20.0 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.4.0-py3-none-any.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 135.8/135.8 kB 8.4 MB/s eta 0:00:00\n",
      "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading markdown-3.10.2-py3-none-any.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 108.2/108.2 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.3/87.3 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached filelock-3.24.3-py3-none-any.whl (24 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: farama-notifications, tensorboard-data-server, pygame, opencv-python, mdurl, markdown, filelock, cloudpickle, ale-py, absl-py, torch, tensorboard, markdown-it-py, gymnasium, stable-baselines3, rich\n",
      "Successfully installed absl-py-2.4.0 ale-py-0.11.2 cloudpickle-3.1.2 farama-notifications-0.0.4 filelock-3.24.3 gymnasium-1.2.3 markdown-3.10.2 markdown-it-py-4.0.0 mdurl-0.1.2 opencv-python-4.13.0.92 pygame-2.6.1 rich-14.3.3 stable-baselines3-2.8.0a2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 torch-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install \"stable-baselines3[extra]>=2.0.0a4\"  \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO, A2C, SAC, TD3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9d351",
   "metadata": {
    "papermill": {
     "duration": 0.008689,
     "end_time": "2026-02-20T08:49:50.877270",
     "exception": false,
     "start_time": "2026-02-20T08:49:50.868581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1) Wrappers Gym\n",
    "Les **Gym wrappers** permettent d’ajouter des transformations aux environnements (limiter la durée d’un épisode, normaliser les actions, etc.). Ci-dessous un exemple très condensé :\n",
    "\n",
    "**Autres wrappers utiles**  \n",
    "- `Monitor`: Enregistre automatiquement la récompense et la durée de chaque épisode, ce qui facilite l’analyse.  \n",
    "- `ClipAction`: S’assure que l’action est bien bornée à `[low, high]`.  \n",
    "- `FlattenObservation`: Convertit une observation complexe (dict, tuple, etc.) en un simple vecteur Numpy.\n",
    "\n",
    "*Exemple* : \n",
    "```python\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "env = Monitor(env)  # suivi auto des rewards, durées d’épisodes\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad188a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T08:49:50.894446Z",
     "iopub.status.busy": "2026-02-20T08:49:50.893447Z",
     "iopub.status.idle": "2026-02-20T08:49:50.905286Z",
     "shell.execute_reply": "2026-02-20T08:49:50.904597Z"
    },
    "execution_count": null,
    "id": "GymWrappersExample",
    "papermill": {
     "duration": 0.02203,
     "end_time": "2026-02-20T08:49:50.906380",
     "exception": false,
     "start_time": "2026-02-20T08:49:50.884350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "class LimitEpisodeSteps(gym.Wrapper):\n",
    "    def __init__(self, env, max_steps=100):\n",
    "        super().__init__(env)\n",
    "        self.max_steps = max_steps\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.current_step = 0\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= self.max_steps:\n",
    "            truncated = True\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "base_env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "wrapped_env = LimitEpisodeSteps(base_env, max_steps=50)\n",
    "\n",
    "obs, _ = wrapped_env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = wrapped_env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, _ = wrapped_env.step(action)\n",
    "    done = terminated or truncated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c271a",
   "metadata": {
    "papermill": {
     "duration": 0.00451,
     "end_time": "2026-02-20T08:49:50.915897",
     "exception": false,
     "start_time": "2026-02-20T08:49:50.911387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2) Sauvegarde et chargement de modèles\n",
    "Chaque algorithme de Stable-Baselines3 dispose de méthodes `.save(path)` et `.load(path)`. On peut ainsi conserver un modèle partiellement entraîné ou final, et le recharger pour continuer l’apprentissage ou faire de l’inférence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35776d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T08:49:50.927358Z",
     "iopub.status.busy": "2026-02-20T08:49:50.927358Z",
     "iopub.status.idle": "2026-02-20T08:50:00.458061Z",
     "shell.execute_reply": "2026-02-20T08:50:00.457057Z"
    },
    "execution_count": null,
    "id": "SaveLoadCell",
    "papermill": {
     "duration": 9.538162,
     "end_time": "2026-02-20T08:50:00.459061",
     "exception": false,
     "start_time": "2026-02-20T08:49:50.920899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsboi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:71: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprise du modèle chargé : récompense moyenne=248.60\n"
     ]
    }
   ],
   "source": [
    "# Entraînement basique sur CartPole\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "model = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "model.learn(5000)\n",
    "\n",
    "# Sauvegarde\n",
    "model.save(\"ppo_cartpole\")\n",
    "del model  # on supprime le modèle de la mémoire\n",
    "\n",
    "# Rechargement\n",
    "model = PPO.load(\"ppo_cartpole\", env=env)  # on précise l'env si on veut continuer\n",
    "# Test rapide\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Reprise du modèle chargé : récompense moyenne={mean_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d2f0c",
   "metadata": {
    "papermill": {
     "duration": 0.004507,
     "end_time": "2026-02-20T08:50:00.468106",
     "exception": false,
     "start_time": "2026-02-20T08:50:00.463599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "**Attention**  \n",
    "- `model.save(path)` enregistre uniquement les poids du réseau et l’architecture.  \n",
    "- Pour **off-policy** (DQN, SAC, TD3...), si vous voulez sauvegarder **la replay buffer** (mémoire d’expériences), il faut utiliser en plus `model.save_replay_buffer(path_replay)`.  \n",
    "- Cela peut s’avérer lourd en mémoire : prenez garde à la taille de `buffer_size` et à l’espace disque.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cc972",
   "metadata": {
    "papermill": {
     "duration": 0.003503,
     "end_time": "2026-02-20T08:50:00.475608",
     "exception": false,
     "start_time": "2026-02-20T08:50:00.472105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3) Multiprocessing\n",
    "Pour accélérer l’apprentissage ou pour avoir une meilleure exploration, on peut exécuter plusieurs environnements en parallèle. Cela se fait via `DummyVecEnv` (qui reste sur un seul process) ou `SubprocVecEnv` (plusieurs processus). Souvent, `DummyVecEnv` est plus rapide pour un petit nombre d’environnements, car la communication inter-processus coûte cher.\n",
    "\n",
    "On définit une fonction `make_env(env_id, rank, seed=0)` qui crée un environnement, puis on construit un `SubprocVecEnv` (ou un `DummyVecEnv`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bdaeba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T08:50:00.483148Z",
     "iopub.status.busy": "2026-02-20T08:50:00.483148Z",
     "iopub.status.idle": "2026-02-20T08:50:10.393469Z",
     "shell.execute_reply": "2026-02-20T08:50:10.392461Z"
    },
    "execution_count": null,
    "id": "MultiprocCell",
    "papermill": {
     "duration": 9.914321,
     "end_time": "2026-02-20T08:50:10.393469",
     "exception": false,
     "start_time": "2026-02-20T08:50:00.479148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récompense moyenne sur 10 épisodes: 500.0\n"
     ]
    }
   ],
   "source": [
    "def make_env(env_id, rank, seed=0):\n",
    "    def _init():\n",
    "        env = gym.make(env_id)\n",
    "        env.reset(seed=seed + rank)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "# Exemple : 4 environnements en parallèle\n",
    "n_procs = 4\n",
    "env_id = \"CartPole-v1\"\n",
    "\n",
    "vec_env = SubprocVecEnv([make_env(env_id, i) for i in range(n_procs)])\n",
    "\n",
    "model_mp = A2C(\"MlpPolicy\", vec_env, verbose=0)\n",
    "model_mp.learn(5000)\n",
    "\n",
    "# Évaluation finale sur un seul env\n",
    "test_env = gym.make(env_id)\n",
    "mean_reward, _ = evaluate_policy(model_mp, test_env, n_eval_episodes=10)\n",
    "print(\"Récompense moyenne sur 10 épisodes:\", mean_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7b4be",
   "metadata": {
    "papermill": {
     "duration": 0.003616,
     "end_time": "2026-02-20T08:50:10.402086",
     "exception": false,
     "start_time": "2026-02-20T08:50:10.398470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4) Callbacks\n",
    "Les **callbacks** permettent d’intervenir pendant l’entraînement (pour sauvegarder, tracer en temps réel, etc.). Ils héritent de `BaseCallback`. Quelques exemples :\n",
    "\n",
    "**Callbacks fournis par Stable-Baselines3**  \n",
    "- `EvalCallback`: évalue régulièrement le modèle sur un environnement de test (distinct de l’env d’entraînement).  \n",
    "- `CheckpointCallback`: sauvegarde périodiquement le modèle.  \n",
    "- `StopTrainingOnRewardThreshold`: arrête l’apprentissage si une récompense cible est atteinte.  \n",
    "\n",
    "*Tip* : En combinant `EvalCallback` et `CheckpointCallback`, vous pouvez automatiquement enregistrer le “meilleur” modèle selon une métrique d’évaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8119b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T08:50:10.412141Z",
     "iopub.status.busy": "2026-02-20T08:50:10.411626Z",
     "iopub.status.idle": "2026-02-20T08:50:10.435303Z",
     "shell.execute_reply": "2026-02-20T08:50:10.434248Z"
    },
    "execution_count": null,
    "id": "CallbacksCell",
    "papermill": {
     "duration": 0.030254,
     "end_time": "2026-02-20T08:50:10.436893",
     "exception": false,
     "start_time": "2026-02-20T08:50:10.406639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback: Première fois !\n",
      "Callback: Deuxième fois, on arrête l'entraînement.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x1642a268f10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class SimpleCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self._called_once = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if not self._called_once:\n",
    "            print(\"Callback: Première fois !\")\n",
    "            self._called_once = True\n",
    "            return True\n",
    "        print(\"Callback: Deuxième fois, on arrête l'entraînement.\")\n",
    "        return False  # on interrompt l'apprentissage\n",
    "\n",
    "# Exemple d'utilisation\n",
    "model_cb = SAC(\"MlpPolicy\", \"Pendulum-v1\", verbose=0)\n",
    "model_cb.learn(total_timesteps=2000, callback=SimpleCallback())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da2c1da",
   "metadata": {
    "papermill": {
     "duration": 0.005083,
     "end_time": "2026-02-20T08:50:10.447101",
     "exception": false,
     "start_time": "2026-02-20T08:50:10.442018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Exemple de callback pour sauvegarder le meilleur modèle\n",
    "On peut observer la récompense d’entraînement (monitor) et sauvegarder le modèle lorsqu’on obtient une récompense moyenne record. (Pour un usage plus robuste, on conseille d’utiliser un environnement d’évaluation séparé.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca01a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T08:50:10.458717Z",
     "iopub.status.busy": "2026-02-20T08:50:10.458189Z",
     "iopub.status.idle": "2026-02-20T08:50:20.578144Z",
     "shell.execute_reply": "2026-02-20T08:50:20.576560Z"
    },
    "execution_count": null,
    "id": "SaveBestCallbackCell",
    "papermill": {
     "duration": 10.12808,
     "end_time": "2026-02-20T08:50:20.579181",
     "exception": false,
     "start_time": "2026-02-20T08:50:10.451101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep: 1000\n",
      "Meilleur reward: -inf  |  Derniers 100 épisodes: 21.26\n",
      "Nouveau meilleur modèle! Sauvegarde...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep: 2000\n",
      "Meilleur reward: 21.26  |  Derniers 100 épisodes: 28.38\n",
      "Nouveau meilleur modèle! Sauvegarde...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep: 3000\n",
      "Meilleur reward: 28.38  |  Derniers 100 épisodes: 31.88\n",
      "Nouveau meilleur modèle! Sauvegarde...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep: 4000\n",
      "Meilleur reward: 31.88  |  Derniers 100 épisodes: 39.18\n",
      "Nouveau meilleur modèle! Sauvegarde...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep: 5000\n",
      "Meilleur reward: 39.18  |  Derniers 100 épisodes: 47.97\n",
      "Nouveau meilleur modèle! Sauvegarde...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x1642cbe8e10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "\n",
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, log_dir, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "            if len(x) > 0:\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Timestep: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"Meilleur reward: {self.best_mean_reward:.2f}  |  Derniers 100 épisodes: {mean_reward:.2f}\"\n",
    "                    )\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    if self.verbose > 0:\n",
    "                        print(\"Nouveau meilleur modèle! Sauvegarde...\")\n",
    "                    self.model.save(self.save_path)\n",
    "        return True\n",
    "\n",
    "# Exemple d'utilisation\n",
    "log_dir = \"./logs/\"  # dossier de logs\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "model_saver = A2C(\"MlpPolicy\", env, verbose=0)\n",
    "callback_saver = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
    "\n",
    "model_saver.learn(total_timesteps=5000, callback=callback_saver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c5c02",
   "metadata": {
    "papermill": {
     "duration": 0.00548,
     "end_time": "2026-02-20T08:50:20.590184",
     "exception": false,
     "start_time": "2026-02-20T08:50:20.584704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5) Créer un environnement Gym personnalisé\n",
    "Enfin, voici un **exemple minimal** d’environnement Gym personnalisé. Il faut définir :\n",
    "\n",
    "- `__init__`: définit `self.observation_space` et `self.action_space`.  \n",
    "- `reset()`: renvoie `(obs, info)` où `obs` ∈ `observation_space`.  \n",
    "- `step(action)`: renvoie `(obs, reward, terminated, truncated, info)`.  \n",
    "- Assurez-vous que `obs` respecte la forme indiquée par `observation_space`.  \n",
    "\n",
    "*Note* : Dans Gym 0.26+ et Gymnasium, on a deux indicateurs de fin : `terminated` et `truncated`.  \n",
    "- `terminated`: la tâche est terminée parce qu’on est allé au bout (victoire/défaite).  \n",
    "- `truncated`: la tâche s’arrête par limite de temps ou autre contrainte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2ea170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T08:50:20.603392Z",
     "iopub.status.busy": "2026-02-20T08:50:20.602877Z",
     "iopub.status.idle": "2026-02-20T08:50:23.305873Z",
     "shell.execute_reply": "2026-02-20T08:50:23.305370Z"
    },
    "execution_count": null,
    "id": "CustomEnvCell",
    "papermill": {
     "duration": 2.710723,
     "end_time": "2026-02-20T08:50:23.306876",
     "exception": false,
     "start_time": "2026-02-20T08:50:20.596153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récompense moyenne : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsboi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:71: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gymnasium import spaces\n",
    "\n",
    "class MyCustomEnv(gym.Env):\n",
    "    def __init__(self, grid_size=5):\n",
    "        super().__init__()\n",
    "        self.grid_size = grid_size\n",
    "        # On définit l'action_space et l'observation_space\n",
    "        self.action_space = spaces.Discrete(2)  # ex: 0 = gauche, 1 = droite\n",
    "        self.observation_space = spaces.Box(low=0, high=self.grid_size, shape=(1,), dtype=np.float32)\n",
    "        self.agent_pos = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed, options=options)\n",
    "        self.agent_pos = np.random.randint(low=0, high=self.grid_size)\n",
    "        return np.array([self.agent_pos], dtype=np.float32), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:  # gauche\n",
    "            self.agent_pos -= 1\n",
    "        else:            # droite\n",
    "            self.agent_pos += 1\n",
    "        self.agent_pos = np.clip(self.agent_pos, 0, self.grid_size)\n",
    "\n",
    "        reward = 1.0 if self.agent_pos == 0 else 0.0  # ex : on favorise d'aller à 0\n",
    "        terminated = bool(self.agent_pos == 0)\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        return np.array([self.agent_pos], dtype=np.float32), reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        pass  # Optionnel\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# Validation\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "env_custom = MyCustomEnv()\n",
    "check_env(env_custom, warn=True)\n",
    "\n",
    "# Test rapide\n",
    "model_custom = PPO(\"MlpPolicy\", env_custom, verbose=0)\n",
    "model_custom.learn(2000)\n",
    "mean_reward, _ = evaluate_policy(model_custom, env_custom, n_eval_episodes=10)\n",
    "print(\"Récompense moyenne :\", mean_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb1678",
   "metadata": {
    "papermill": {
     "duration": 0.006507,
     "end_time": "2026-02-20T08:50:23.319001",
     "exception": false,
     "start_time": "2026-02-20T08:50:23.312494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "Dans ce second notebook, nous avons parcouru :\n",
    "\n",
    "- L’usage de **wrappers Gym** pour modifier un environnement (limiter la durée, normaliser, etc.).\n",
    "- Les **fonctions de sauvegarde/chargement** de modèles (`.save()` / `.load()`).\n",
    "- Le **multiprocessing** via `SubprocVecEnv` ou `DummyVecEnv` pour accélérer (ou diversifier) l’apprentissage.\n",
    "- Les **callbacks**, permettant d’intervenir pendant l’entraînement (sauvegarde automatique du meilleur modèle, monitoring, etc.).\n",
    "- La **création d’un environnement Gym personnalisé**, validé ensuite par la fonction `check_env` et compatible avec tout algorithme Stable-Baselines3.\n",
    "\n",
    "Vous pouvez maintenant adapter et combiner ces techniques pour vos propres projets d’Apprentissage par Renforcement !"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2_wrappers_saving_loading_FR_synthesis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 93.000083,
   "end_time": "2026-02-20T08:50:24.434318",
   "environment_variables": {},
   "exception": null,
   "input_path": "MyIA.AI.Notebooks/RL/stable_baseline_2_wrappers_sauvegarde_callbacks.ipynb",
   "output_path": "MyIA.AI.Notebooks/RL/stable_baseline_2_wrappers_sauvegarde_callbacks.ipynb",
   "parameters": {},
   "start_time": "2026-02-20T08:48:51.434235",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}