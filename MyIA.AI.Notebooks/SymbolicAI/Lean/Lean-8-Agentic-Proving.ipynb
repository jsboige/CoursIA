{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lean 8 - Agents Autonomes pour Demonstration de Theoremes\n",
    "\n",
    "**Navigation** : [← Lean-7-LLM-Integration](Lean-7-LLM-Integration.ipynb) | [Index](Lean-1-Setup.ipynb) | [Lean-9-LeanDojo →](Lean-9-LeanDojo.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Ce notebook final de la serie explore la creation de **systemes multi-agents** capables de prouver des theoremes mathematiques de maniere **autonome**. Nous combinons les techniques des notebooks precedents avec les patterns d'orchestration agentique.\n",
    "\n",
    "L'objectif est de construire un systeme qui peut :\n",
    "1. Recevoir un enonce de theoreme\n",
    "2. Rechercher des lemmes pertinents dans Mathlib\n",
    "3. Generer des strategies de preuve\n",
    "4. Verifier formellement avec Lean\n",
    "5. Iterer jusqu'au succes\n",
    "\n",
    "### Objectifs pedagogiques\n",
    "\n",
    "1. Concevoir une architecture multi-agents pour theorem proving\n",
    "2. Implementer des agents specialises (recherche, generation, verification)\n",
    "3. Orchestrer la collaboration entre agents\n",
    "4. Gerer les boucles de feedback et d'amelioration\n",
    "5. Comprendre les techniques de Harmonic Aristotle et APOLLO\n",
    "\n",
    "### Prerequis\n",
    "\n",
    "- Notebooks **Lean-1** a **Lean-7** completes\n",
    "- Notions de base sur les systemes multi-agents\n",
    "- Cle API LLM (optionnel pour execution)\n",
    "\n",
    "### Duree estimee : 55-60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture d'un Systeme Agentique pour Lean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vue d'ensemble\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                     SYSTEME AGENTIQUE LEAN                          │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  ┌─────────────────┐                                               │\n",
    "│  │   ORCHESTRATOR  │  <- Coordonne tous les agents                 │\n",
    "│  │     Agent       │                                               │\n",
    "│  └────────┬────────┘                                               │\n",
    "│           │                                                        │\n",
    "│  ┌────────┼────────┬────────────────┐                              │\n",
    "│  │        │        │                │                              │\n",
    "│  v        v        v                v                              │\n",
    "│ ┌────┐  ┌────┐  ┌────┐         ┌────────┐                          │\n",
    "│ │Search│ │Tactic│ │Proof│        │Memory  │                         │\n",
    "│ │Agent│ │Agent│ │Verify│        │Store   │                         │\n",
    "│ └──┬───┘ └──┬───┘ └──┬───┘        └────────┘                         │\n",
    "│    │        │        │                                             │\n",
    "│    v        v        v                                             │\n",
    "│ ┌──────────────────────────────────────────────┐                   │\n",
    "│ │               LEAN KERNEL                     │                   │\n",
    "│ │  (Verification formelle + Mathlib)           │                   │\n",
    "│ └──────────────────────────────────────────────┘                   │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Agent de Recherche de Theoremes\n",
    "\n",
    "### 1.1 Role\n",
    "\n",
    "L'agent de recherche parcourt Mathlib pour trouver des lemmes pertinents au probleme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmes trouves:\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class Lemma:\n",
    "    \"\"\"Represente un lemme Mathlib.\"\"\"\n",
    "    name: str\n",
    "    statement: str\n",
    "    namespace: str\n",
    "    relevance_score: float = 0.0\n",
    "\n",
    "class TheoremSearchAgent:\n",
    "    \"\"\"Agent de recherche de theoremes dans Mathlib.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client=None):\n",
    "        self.llm = llm_client\n",
    "        self.cache = {}  # Cache des recherches\n",
    "    \n",
    "    def search(self, goal: str, context: str = \"\") -> List[Lemma]:\n",
    "        \"\"\"\n",
    "        Recherche des lemmes pertinents pour un but donne.\n",
    "        \n",
    "        Args:\n",
    "            goal: Le but a prouver\n",
    "            context: Contexte additionnel (hypotheses, etc.)\n",
    "        \n",
    "        Returns:\n",
    "            Liste de lemmes tries par pertinence\n",
    "        \"\"\"\n",
    "        # Verifier le cache\n",
    "        cache_key = f\"{goal}:{context}\"\n",
    "        if cache_key in self.cache:\n",
    "            return self.cache[cache_key]\n",
    "        \n",
    "        # Analyser le but pour extraire les concepts\n",
    "        concepts = self._extract_concepts(goal)\n",
    "        \n",
    "        # Rechercher dans Mathlib\n",
    "        lemmas = self._search_mathlib(concepts)\n",
    "        \n",
    "        # Scorer par pertinence\n",
    "        scored = self._score_lemmas(lemmas, goal)\n",
    "        \n",
    "        # Mettre en cache\n",
    "        self.cache[cache_key] = scored\n",
    "        \n",
    "        return scored\n",
    "    \n",
    "    def _extract_concepts(self, goal: str) -> List[str]:\n",
    "        \"\"\"Extrait les concepts mathematiques du but.\"\"\"\n",
    "        # Simplification : extraction par mots-cles\n",
    "        keywords = [\"add\", \"mul\", \"comm\", \"assoc\", \"zero\", \"one\", \"succ\"]\n",
    "        return [k for k in keywords if k in goal.lower()]\n",
    "    \n",
    "    def _search_mathlib(self, concepts: List[str]) -> List[Lemma]:\n",
    "        \"\"\"Simule la recherche dans Mathlib.\"\"\"\n",
    "        # Base de lemmes simulee\n",
    "        mathlib_lemmas = [\n",
    "            Lemma(\"Nat.add_zero\", \"n + 0 = n\", \"Nat\"),\n",
    "            Lemma(\"Nat.zero_add\", \"0 + n = n\", \"Nat\"),\n",
    "            Lemma(\"Nat.add_comm\", \"n + m = m + n\", \"Nat\"),\n",
    "            Lemma(\"Nat.add_assoc\", \"(n + m) + k = n + (m + k)\", \"Nat\"),\n",
    "            Lemma(\"Nat.mul_comm\", \"n * m = m * n\", \"Nat\"),\n",
    "            Lemma(\"Nat.mul_assoc\", \"(n * m) * k = n * (m * k)\", \"Nat\"),\n",
    "        ]\n",
    "        \n",
    "        # Filtrer par concepts\n",
    "        return [l for l in mathlib_lemmas \n",
    "                if any(c in l.name.lower() for c in concepts)]\n",
    "    \n",
    "    def _score_lemmas(self, lemmas: List[Lemma], goal: str) -> List[Lemma]:\n",
    "        \"\"\"Score les lemmes par pertinence.\"\"\"\n",
    "        for lemma in lemmas:\n",
    "            # Score simple : correspondance de termes\n",
    "            lemma.relevance_score = sum(\n",
    "                1 for word in lemma.statement.split() \n",
    "                if word in goal\n",
    "            ) / max(len(goal.split()), 1)\n",
    "        \n",
    "        return sorted(lemmas, key=lambda l: l.relevance_score, reverse=True)\n",
    "\n",
    "# Test\n",
    "search_agent = TheoremSearchAgent()\n",
    "results = search_agent.search(\"n + 0 = n\")\n",
    "print(\"Lemmes trouves:\")\n",
    "for lemma in results:\n",
    "    print(f\"  {lemma.name}: {lemma.statement} (score: {lemma.relevance_score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Agent de Generation de Tactiques\n",
    "\n",
    "### 2.1 Role\n",
    "\n",
    "L'agent de tactiques genere des sequences de tactiques Lean pour prouver le but."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tactiques suggerees:\n",
      "  [0.90] rfl - Reflexivite - verifie si les deux cotes sont identiques\n",
      "  [0.70] omega - Arithmetique de Presburger automatique\n",
      "  [0.50] simp - Simplification automatique\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from typing import Tuple\n",
    "\n",
    "class TacticType(Enum):\n",
    "    DIRECT = \"direct\"       # exact, rfl\n",
    "    REWRITE = \"rewrite\"     # rw, simp\n",
    "    SPLIT = \"split\"         # constructor, cases\n",
    "    INDUCTION = \"induction\" # induction, recursion\n",
    "    AUTO = \"auto\"           # omega, ring, linarith\n",
    "\n",
    "@dataclass\n",
    "class TacticSuggestion:\n",
    "    \"\"\"Une suggestion de tactique avec son contexte.\"\"\"\n",
    "    tactic: str\n",
    "    tactic_type: TacticType\n",
    "    confidence: float\n",
    "    explanation: str\n",
    "\n",
    "class TacticGeneratorAgent:\n",
    "    \"\"\"Agent de generation de tactiques.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client=None):\n",
    "        self.llm = llm_client\n",
    "        self.history = []  # Historique des tentatives\n",
    "    \n",
    "    def generate(self, goal: str, context: List[str], \n",
    "                 available_lemmas: List[Lemma]) -> List[TacticSuggestion]:\n",
    "        \"\"\"\n",
    "        Genere des tactiques pour un but donne.\n",
    "        \n",
    "        Args:\n",
    "            goal: Le but courant\n",
    "            context: Les hypotheses disponibles\n",
    "            available_lemmas: Lemmes suggeres par l'agent de recherche\n",
    "        \n",
    "        Returns:\n",
    "            Liste de suggestions de tactiques\n",
    "        \"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        # Strategie 1: Tactiques directes\n",
    "        if \"=\" in goal:\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                \"rfl\", TacticType.DIRECT, 0.9,\n",
    "                \"Reflexivite - verifie si les deux cotes sont identiques\"\n",
    "            ))\n",
    "        \n",
    "        # Strategie 2: Utiliser les lemmes disponibles\n",
    "        for lemma in available_lemmas[:3]:\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                f\"exact {lemma.name}\", TacticType.DIRECT, \n",
    "                lemma.relevance_score,\n",
    "                f\"Appliquer {lemma.name}: {lemma.statement}\"\n",
    "            ))\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                f\"rw [{lemma.name}]\", TacticType.REWRITE,\n",
    "                lemma.relevance_score * 0.8,\n",
    "                f\"Reecrire avec {lemma.name}\"\n",
    "            ))\n",
    "        \n",
    "        # Strategie 3: Tactiques automatiques\n",
    "        if any(op in goal for op in [\"+\", \"-\", \"<\", \">\", \"<=\", \">=\"]):\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                \"omega\", TacticType.AUTO, 0.7,\n",
    "                \"Arithmetique de Presburger automatique\"\n",
    "            ))\n",
    "        \n",
    "        if \"*\" in goal or \"^\" in goal:\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                \"ring\", TacticType.AUTO, 0.7,\n",
    "                \"Algebre polynomiale automatique\"\n",
    "            ))\n",
    "        \n",
    "        # Strategie 4: Simp comme fallback\n",
    "        suggestions.append(TacticSuggestion(\n",
    "            \"simp\", TacticType.REWRITE, 0.5,\n",
    "            \"Simplification automatique\"\n",
    "        ))\n",
    "        \n",
    "        # Trier par confiance\n",
    "        return sorted(suggestions, key=lambda s: s.confidence, reverse=True)\n",
    "    \n",
    "    def generate_sequence(self, goal: str, context: List[str],\n",
    "                          available_lemmas: List[Lemma],\n",
    "                          max_depth: int = 5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Genere une sequence complete de tactiques.\n",
    "        \"\"\"\n",
    "        sequence = []\n",
    "        current_goal = goal\n",
    "        \n",
    "        for _ in range(max_depth):\n",
    "            suggestions = self.generate(current_goal, context, available_lemmas)\n",
    "            if not suggestions:\n",
    "                break\n",
    "            \n",
    "            best = suggestions[0]\n",
    "            sequence.append(best.tactic)\n",
    "            \n",
    "            # Simuler la progression (dans la realite, Lean nous dirait le nouveau but)\n",
    "            if best.tactic_type == TacticType.DIRECT:\n",
    "                break  # Preuve complete\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "# Test\n",
    "tactic_agent = TacticGeneratorAgent()\n",
    "lemmas = search_agent.search(\"n + 0 = n\")\n",
    "suggestions = tactic_agent.generate(\"n + 0 = n\", [], lemmas)\n",
    "\n",
    "print(\"Tactiques suggerees:\")\n",
    "for s in suggestions[:5]:\n",
    "    print(f\"  [{s.confidence:.2f}] {s.tactic} - {s.explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agent de Verification\n",
    "\n",
    "### 3.1 Role\n",
    "\n",
    "L'agent de verification execute le code Lean et analyse les resultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification: Succes\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class VerificationResult:\n",
    "    \"\"\"Resultat de la verification Lean.\"\"\"\n",
    "    success: bool\n",
    "    error_message: Optional[str] = None\n",
    "    remaining_goals: List[str] = None\n",
    "    execution_time: float = 0.0\n",
    "\n",
    "class ProofVerifierAgent:\n",
    "    \"\"\"Agent de verification des preuves.\"\"\"\n",
    "    \n",
    "    def __init__(self, lean_path: str = \"lean\"):\n",
    "        self.lean_path = lean_path\n",
    "        self.verified_count = 0\n",
    "        self.failed_count = 0\n",
    "    \n",
    "    def verify(self, theorem: str, proof: str) -> VerificationResult:\n",
    "        \"\"\"\n",
    "        Verifie une preuve avec Lean.\n",
    "        \n",
    "        Args:\n",
    "            theorem: L'enonce du theoreme\n",
    "            proof: La preuve proposee (sequence de tactiques)\n",
    "        \n",
    "        Returns:\n",
    "            Resultat de la verification\n",
    "        \"\"\"\n",
    "        # Construire le code Lean complet\n",
    "        lean_code = self._build_lean_code(theorem, proof)\n",
    "        \n",
    "        # Simuler l'execution Lean\n",
    "        # (Dans un vrai systeme, on utiliserait subprocess ou lean-dojo)\n",
    "        result = self._simulate_lean_execution(lean_code)\n",
    "        \n",
    "        # Mettre a jour les statistiques\n",
    "        if result.success:\n",
    "            self.verified_count += 1\n",
    "        else:\n",
    "            self.failed_count += 1\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _build_lean_code(self, theorem: str, proof: str) -> str:\n",
    "        \"\"\"Construit le code Lean complet.\"\"\"\n",
    "        return f\"\"\"\n",
    "{theorem} := by\n",
    "  {proof}\n",
    "        \"\"\".strip()\n",
    "    \n",
    "    def _simulate_lean_execution(self, code: str) -> VerificationResult:\n",
    "        \"\"\"\n",
    "        Simule l'execution Lean.\n",
    "        Dans un vrai systeme, utiliser lean-dojo ou subprocess.\n",
    "        \"\"\"\n",
    "        # Heuristiques simples pour la simulation\n",
    "        if \"rfl\" in code or \"exact Nat.add_zero\" in code:\n",
    "            return VerificationResult(success=True)\n",
    "        elif \"sorry\" in code:\n",
    "            return VerificationResult(\n",
    "                success=False,\n",
    "                error_message=\"declaration uses 'sorry'\"\n",
    "            )\n",
    "        else:\n",
    "            # Simuler une reussite aleatoire\n",
    "            import random\n",
    "            if random.random() > 0.3:\n",
    "                return VerificationResult(success=True)\n",
    "            else:\n",
    "                return VerificationResult(\n",
    "                    success=False,\n",
    "                    error_message=\"tactic failed\"\n",
    "                )\n",
    "    \n",
    "    def get_stats(self) -> dict:\n",
    "        \"\"\"Retourne les statistiques de verification.\"\"\"\n",
    "        total = self.verified_count + self.failed_count\n",
    "        return {\n",
    "            \"verified\": self.verified_count,\n",
    "            \"failed\": self.failed_count,\n",
    "            \"success_rate\": self.verified_count / max(total, 1)\n",
    "        }\n",
    "\n",
    "# Test\n",
    "verifier = ProofVerifierAgent()\n",
    "result = verifier.verify(\n",
    "    \"theorem test (n : Nat) : n + 0 = n\",\n",
    "    \"exact Nat.add_zero n\"\n",
    ")\n",
    "print(f\"Verification: {'Succes' if result.success else 'Echec'}\")\n",
    "if result.error_message:\n",
    "    print(f\"Erreur: {result.error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent Orchestrateur\n",
    "\n",
    "### 4.1 Role\n",
    "\n",
    "L'orchestrateur coordonne tous les agents pour resoudre un probleme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Debut de la preuve: theorem add_zero (n : Nat) : n + 0 = n\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Lemmes trouves: []\n",
      "Tactiques generees: ['rfl']\n",
      "\n",
      "Preuve trouvee!\n",
      "\n",
      "Preuve finale:\n",
      "rfl\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ProofAttempt:\n",
    "    \"\"\"Enregistre une tentative de preuve.\"\"\"\n",
    "    theorem: str\n",
    "    tactics: List[str]\n",
    "    result: VerificationResult\n",
    "    iteration: int\n",
    "\n",
    "class OrchestratorAgent:\n",
    "    \"\"\"\n",
    "    Agent orchestrateur qui coordonne le systeme multi-agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.search_agent = TheoremSearchAgent()\n",
    "        self.tactic_agent = TacticGeneratorAgent()\n",
    "        self.verifier = ProofVerifierAgent()\n",
    "        self.history: List[ProofAttempt] = []\n",
    "        self.max_iterations = 10\n",
    "    \n",
    "    def prove(self, theorem: str) -> Tuple[bool, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Tente de prouver un theoreme.\n",
    "        \n",
    "        Args:\n",
    "            theorem: L'enonce du theoreme\n",
    "        \n",
    "        Returns:\n",
    "            (succes, preuve) ou (echec, None)\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Debut de la preuve: {theorem}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            print(f\"--- Iteration {iteration + 1} ---\")\n",
    "            \n",
    "            # Etape 1: Rechercher des lemmes pertinents\n",
    "            goal = self._extract_goal(theorem)\n",
    "            lemmas = self.search_agent.search(goal)\n",
    "            print(f\"Lemmes trouves: {[l.name for l in lemmas[:3]]}\")\n",
    "            \n",
    "            # Etape 2: Generer des tactiques\n",
    "            tactics = self.tactic_agent.generate_sequence(\n",
    "                goal, [], lemmas\n",
    "            )\n",
    "            proof = \"\\n  \".join(tactics)\n",
    "            print(f\"Tactiques generees: {tactics}\")\n",
    "            \n",
    "            # Etape 3: Verifier\n",
    "            result = self.verifier.verify(theorem, proof)\n",
    "            \n",
    "            # Enregistrer la tentative\n",
    "            self.history.append(ProofAttempt(\n",
    "                theorem, tactics, result, iteration\n",
    "            ))\n",
    "            \n",
    "            if result.success:\n",
    "                print(f\"\\nPreuve trouvee!\")\n",
    "                return True, proof\n",
    "            else:\n",
    "                print(f\"Echec: {result.error_message}\")\n",
    "                # Apprendre de l'echec pour la prochaine iteration\n",
    "                self._learn_from_failure(result)\n",
    "        \n",
    "        print(f\"\\nEchec apres {self.max_iterations} iterations\")\n",
    "        return False, None\n",
    "    \n",
    "    def _extract_goal(self, theorem: str) -> str:\n",
    "        \"\"\"Extrait le but du theoreme.\"\"\"\n",
    "        # Simplification: prendre la partie apres le \":\"\n",
    "        if \":\" in theorem:\n",
    "            return theorem.split(\":\", 1)[1].strip()\n",
    "        return theorem\n",
    "    \n",
    "    def _learn_from_failure(self, result: VerificationResult):\n",
    "        \"\"\"Ajuste la strategie basee sur l'echec.\"\"\"\n",
    "        # Dans un vrai systeme, on ajusterait les poids,\n",
    "        # eviterait les tactiques qui echouent, etc.\n",
    "        pass\n",
    "    \n",
    "    def get_statistics(self) -> dict:\n",
    "        \"\"\"Retourne les statistiques du systeme.\"\"\"\n",
    "        return {\n",
    "            \"total_attempts\": len(self.history),\n",
    "            \"verifier_stats\": self.verifier.get_stats()\n",
    "        }\n",
    "\n",
    "# Demonstration\n",
    "orchestrator = OrchestratorAgent()\n",
    "success, proof = orchestrator.prove(\n",
    "    \"theorem add_zero (n : Nat) : n + 0 = n\"\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(f\"\\nPreuve finale:\\n{proof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Integration avec Semantic Kernel (Python)\n",
    "\n",
    "### 5.1 Vue d'ensemble\n",
    "\n",
    "Microsoft **Semantic Kernel** est un SDK qui permet d'orchestrer des LLMs avec des plugins, de la memoire et des agents intelligents. Nous allons implementer un systeme multi-agents pour theorem proving inspire des patterns utilises dans l'analyse argumentative (voir `Argument_Analysis` notebooks).\n",
    "\n",
    "**Composants cles** :\n",
    "- **Kernel** : Point d'entree principal, configure les services LLM\n",
    "- **Plugins** : Fonctions appelables par les agents (decorated avec `@kernel_function`)\n",
    "- **Agents** : Entites autonomes avec instructions et capacites\n",
    "- **Orchestration** : Strategies de selection et terminaison des agents\n",
    "\n",
    "### 5.2 Dependances\n",
    "\n",
    "```python\n",
    "# Installation\n",
    "pip install semantic-kernel openai python-dotenv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoreme: theorem test (n : Nat) : n + 0 = n\n",
      "Taches: 1\n",
      "Lemmes trouves: 1\n",
      "Tactiques tentees: 0\n",
      "Iterations: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 8.1 - ProofState: Etat Partage pour Multi-Agents\n",
    "# =============================================================================\n",
    "# Pattern inspire de RhetoricalAnalysisState dans Argument_Analysis\n",
    "# Permet la synchronisation entre agents avec designation explicite\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Charger .env pour les cles API ---\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    env_paths = [Path(\".env\"), Path(\"../.env\"), Path(__file__).parent / \".env\" if \"__file__\" in dir() else Path(\".env\")]\n",
    "    for p in env_paths:\n",
    "        if p.exists():\n",
    "            load_dotenv(p)\n",
    "            print(f\"Configuration chargee depuis: {p.absolute()}\")\n",
    "            break\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# --- Importer lean_runner.py ---\n",
    "lean_dir = Path(\".\").absolute()\n",
    "if str(lean_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(lean_dir))\n",
    "\n",
    "from lean_runner import LeanRunner, LeanResult\n",
    "\n",
    "# --- Enumerations ---\n",
    "\n",
    "class ProofStrategy(Enum):\n",
    "    \"\"\"Strategie de preuve en cours.\"\"\"\n",
    "    EXPLORATION = \"exploration\"      # Recherche initiale de lemmes\n",
    "    REFINEMENT = \"refinement\"        # Affinage des tactiques\n",
    "    VALIDATION = \"validation\"        # Verification finale\n",
    "    RECOVERY = \"recovery\"            # Recuperation apres echecs\n",
    "\n",
    "class TacticDifficulty(Enum):\n",
    "    \"\"\"Niveau de difficulte des tactiques.\"\"\"\n",
    "    SIMPLE = \"simple\"      # rfl, exact, omega\n",
    "    MEDIUM = \"medium\"      # induction, cases, simp\n",
    "    COMPLEX = \"complex\"    # ring, linarith, aesop, custom\n",
    "\n",
    "# --- DataClasses pour les sous-composants ---\n",
    "\n",
    "@dataclass\n",
    "class Lemma:\n",
    "    \"\"\"Lemme decouvert par SearchAgent.\"\"\"\n",
    "    name: str\n",
    "    statement: str\n",
    "    namespace: str\n",
    "    relevance: float  # 0.0-1.0\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "@dataclass\n",
    "class TacticAttempt:\n",
    "    \"\"\"Tentative de tactique par TacticAgent.\"\"\"\n",
    "    id: str\n",
    "    tactic: str\n",
    "    state_before: str           # Goals avant cette tactique\n",
    "    confidence: float           # 0.0-1.0\n",
    "    explanation: str\n",
    "    iteration: int\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "@dataclass\n",
    "class VerificationResult:\n",
    "    \"\"\"Resultat de verification par VerifierAgent.\"\"\"\n",
    "    attempt_id: str             # Reference a TacticAttempt\n",
    "    success: bool\n",
    "    output: str\n",
    "    errors: str\n",
    "    remaining_goals: Optional[str]\n",
    "    exec_time_ms: float\n",
    "    backend: str\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "# --- ProofState Principal ---\n",
    "\n",
    "@dataclass\n",
    "class ProofState:\n",
    "    \"\"\"\n",
    "    Etat partage d'une session de preuve multi-agents.\n",
    "\n",
    "    Architecture:\n",
    "    - SearchAgent decouvre les lemmes\n",
    "    - TacticAgent genere des tactiques\n",
    "    - VerifierAgent verifie avec Lean\n",
    "    - CriticAgent analyse les echecs\n",
    "    - CoordinatorAgent supervise\n",
    "\n",
    "    Pattern cle: Designation explicite de l'agent suivant (_next_agent_designated)\n",
    "    \"\"\"\n",
    "\n",
    "    # === Theoreme ===\n",
    "    theorem_statement: str = \"\"\n",
    "    theorem_goal: str = \"\"\n",
    "    theorem_context: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    # === Decouvertes ===\n",
    "    discovered_lemmas: Dict[str, Lemma] = field(default_factory=dict)\n",
    "    tactics_history: List[TacticAttempt] = field(default_factory=list)\n",
    "    current_proof_state: Optional[str] = None  # Goals Lean restants\n",
    "\n",
    "    # === Verifications ===\n",
    "    verification_results: Dict[str, VerificationResult] = field(default_factory=dict)\n",
    "\n",
    "    # === Coordination ===\n",
    "    current_strategy: ProofStrategy = ProofStrategy.EXPLORATION\n",
    "    iteration_count: int = 0\n",
    "    max_iterations: int = 50\n",
    "    _next_agent_designated: Optional[str] = None\n",
    "\n",
    "    # === Conclusion ===\n",
    "    proof_complete: bool = False\n",
    "    final_proof: Optional[str] = None\n",
    "\n",
    "    # === Metriques ===\n",
    "    start_time: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "    total_llm_tokens: int = 0\n",
    "    total_lean_time_ms: float = 0.0\n",
    "\n",
    "    # --- Methodes de modification d'etat ---\n",
    "\n",
    "    def add_lemma(self, name: str, statement: str, namespace: str = \"\", relevance: float = 0.5) -> str:\n",
    "        \"\"\"Ajoute un lemme decouvert. Retourne son ID.\"\"\"\n",
    "        lemma_id = f\"lemma_{len(self.discovered_lemmas) + 1}_{uuid.uuid4().hex[:4]}\"\n",
    "        self.discovered_lemmas[lemma_id] = Lemma(\n",
    "            name=name, statement=statement, namespace=namespace, relevance=relevance\n",
    "        )\n",
    "        return lemma_id\n",
    "\n",
    "    def add_tactic_attempt(\n",
    "        self, tactic: str, state_before: str, confidence: float = 0.5, explanation: str = \"\"\n",
    "    ) -> str:\n",
    "        \"\"\"Enregistre une tentative de tactique. Retourne son ID.\"\"\"\n",
    "        attempt_id = f\"tactic_{len(self.tactics_history) + 1}_{uuid.uuid4().hex[:4]}\"\n",
    "        self.tactics_history.append(TacticAttempt(\n",
    "            id=attempt_id, tactic=tactic, state_before=state_before,\n",
    "            confidence=confidence, explanation=explanation, iteration=self.iteration_count\n",
    "        ))\n",
    "        return attempt_id\n",
    "\n",
    "    def add_verification(\n",
    "        self, attempt_id: str, success: bool, output: str, errors: str,\n",
    "        remaining_goals: Optional[str], exec_time_ms: float, backend: str\n",
    "    ) -> str:\n",
    "        \"\"\"Enregistre un resultat de verification. Retourne son ID.\"\"\"\n",
    "        verif_id = f\"verif_{len(self.verification_results) + 1}_{uuid.uuid4().hex[:4]}\"\n",
    "        self.verification_results[verif_id] = VerificationResult(\n",
    "            attempt_id=attempt_id, success=success, output=output, errors=errors,\n",
    "            remaining_goals=remaining_goals, exec_time_ms=exec_time_ms, backend=backend\n",
    "        )\n",
    "        self.total_lean_time_ms += exec_time_ms\n",
    "        return verif_id\n",
    "\n",
    "    def designate_next_agent(self, agent_name: str):\n",
    "        \"\"\"Designe l'agent qui doit agir au prochain tour.\"\"\"\n",
    "        self._next_agent_designated = agent_name\n",
    "\n",
    "    def consume_next_agent_designation(self) -> Optional[str]:\n",
    "        \"\"\"Recupere et efface la designation.\"\"\"\n",
    "        designation = self._next_agent_designated\n",
    "        self._next_agent_designated = None\n",
    "        return designation\n",
    "\n",
    "    def set_proof_complete(self, proof: str):\n",
    "        \"\"\"Marque la preuve comme terminee.\"\"\"\n",
    "        self.proof_complete = True\n",
    "        self.final_proof = proof\n",
    "\n",
    "    def increment_iteration(self):\n",
    "        \"\"\"Incremente le compteur d'iterations.\"\"\"\n",
    "        self.iteration_count += 1\n",
    "\n",
    "    def set_strategy(self, strategy: ProofStrategy):\n",
    "        \"\"\"Change la strategie de preuve.\"\"\"\n",
    "        self.current_strategy = strategy\n",
    "\n",
    "    def update_proof_state(self, goals: str):\n",
    "        \"\"\"Met a jour les goals Lean restants.\"\"\"\n",
    "        self.current_proof_state = goals\n",
    "\n",
    "    # --- Methodes de lecture ---\n",
    "\n",
    "    def get_recent_failures(self, n: int = 3) -> List[Tuple[TacticAttempt, VerificationResult]]:\n",
    "        \"\"\"Retourne les N derniers echecs pour analyse.\"\"\"\n",
    "        failures = []\n",
    "        for attempt in reversed(self.tactics_history):\n",
    "            for verif in self.verification_results.values():\n",
    "                if verif.attempt_id == attempt.id and not verif.success:\n",
    "                    failures.append((attempt, verif))\n",
    "                    if len(failures) >= n:\n",
    "                        return failures\n",
    "        return failures\n",
    "\n",
    "    def get_successful_tactics(self) -> List[str]:\n",
    "        \"\"\"Retourne les tactiques qui ont fonctionne.\"\"\"\n",
    "        successful_ids = {v.attempt_id for v in self.verification_results.values() if v.success}\n",
    "        return [a.tactic for a in self.tactics_history if a.id in successful_ids]\n",
    "\n",
    "    def get_state_snapshot(self, summarize: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"Retourne un snapshot de l'etat (JSON-serializable).\"\"\"\n",
    "        if summarize:\n",
    "            return {\n",
    "                \"theorem\": self.theorem_statement[:100] + \"...\" if len(self.theorem_statement) > 100 else self.theorem_statement,\n",
    "                \"strategy\": self.current_strategy.value,\n",
    "                \"iteration\": self.iteration_count,\n",
    "                \"lemmas_found\": len(self.discovered_lemmas),\n",
    "                \"tactics_tried\": len(self.tactics_history),\n",
    "                \"verifications\": len(self.verification_results),\n",
    "                \"proof_complete\": self.proof_complete,\n",
    "                \"current_goals\": self.current_proof_state[:200] if self.current_proof_state else None,\n",
    "                \"recent_failures\": len(self.get_recent_failures(5))\n",
    "            }\n",
    "        else:\n",
    "            # Snapshot complet\n",
    "            return {\n",
    "                \"theorem_statement\": self.theorem_statement,\n",
    "                \"theorem_goal\": self.theorem_goal,\n",
    "                \"discovered_lemmas\": {k: vars(v) for k, v in self.discovered_lemmas.items()},\n",
    "                \"tactics_history\": [vars(t) for t in self.tactics_history],\n",
    "                \"verification_results\": {k: vars(v) for k, v in self.verification_results.items()},\n",
    "                \"current_strategy\": self.current_strategy.value,\n",
    "                \"iteration_count\": self.iteration_count,\n",
    "                \"proof_complete\": self.proof_complete,\n",
    "                \"final_proof\": self.final_proof\n",
    "            }\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Representation lisible pour debug.\"\"\"\n",
    "        return json.dumps(self.get_state_snapshot(summarize=True), indent=2)\n",
    "\n",
    "\n",
    "# === Test de ProofState ===\n",
    "print(\"=== Test ProofState ===\")\n",
    "state = ProofState(\n",
    "    theorem_statement=\"theorem add_comm (n m : Nat) : n + m = m + n\",\n",
    "    theorem_goal=\"n + m = m + n\",\n",
    "    max_iterations=30\n",
    ")\n",
    "\n",
    "# Ajouter des elements\n",
    "lemma_id = state.add_lemma(\"Nat.add_comm\", \"n + m = m + n\", \"Nat\", relevance=0.95)\n",
    "print(f\"Lemme ajoute: {lemma_id}\")\n",
    "\n",
    "attempt_id = state.add_tactic_attempt(\"exact Nat.add_comm n m\", \"n + m = m + n\", confidence=0.8, explanation=\"Application directe du lemme\")\n",
    "print(f\"Tactique ajoutee: {attempt_id}\")\n",
    "\n",
    "verif_id = state.add_verification(attempt_id, success=True, output=\"Goals accomplished\", errors=\"\", remaining_goals=None, exec_time_ms=45.2, backend=\"subprocess\")\n",
    "print(f\"Verification ajoutee: {verif_id}\")\n",
    "\n",
    "state.set_proof_complete(\"exact Nat.add_comm n m\")\n",
    "print(f\"\\nEtat final:\\n{state}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2-8.5 Plugins Semantic Kernel\n",
    "\n",
    "L'architecture utilise 4 plugins specialises, chacun exposant des fonctions via `@kernel_function`:\n",
    "\n",
    "| Plugin | Role | Fonctions cles |\n",
    "|--------|------|----------------|\n",
    "| **ProofStateManagerPlugin** | Gestion de l'etat | get_proof_state, add_lemma, designate_next_agent |\n",
    "| **LeanSearchPlugin** | Recherche Mathlib | search_mathlib_lemmas, check_lemma_type |\n",
    "| **LeanTacticPlugin** | Generation tactiques | generate_tactics, analyze_tactic_failure |\n",
    "| **LeanVerificationPlugin** | Verification Lean | verify_proof, verify_tactic_step |\n",
    "\n",
    "Ce pattern permet aux agents d'appeler ces fonctions automatiquement grace au `FunctionChoiceBehavior.Auto()` de Semantic Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test du plugin:\n",
      "Tache 'task_1' ajoutee: Trouver lemmes pertinents\n",
      "Lemmes trouves: ['Nat.add_zero', 'Nat.zero_add', 'Nat.add_comm']\n",
      "Tactiques candidates: ['exact Nat.add_zero', 'rw [Nat.add_zero]', 'exact Nat.zero_add', 'rw [Nat.zero_add]', 'exact Nat.add_comm']\n",
      "Theoreme: theorem add_zero (n : Nat) : n + 0 = n\n",
      "Taches: 1\n",
      "Lemmes trouves: 3\n",
      "Tactiques tentees: 0\n",
      "Iterations: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 8.2-8.5 - Plugins Semantic Kernel\n",
    "# =============================================================================\n",
    "# Architecture en 4 plugins specialises:\n",
    "# - ProofStateManagerPlugin: Gestion de l'etat partage\n",
    "# - LeanSearchPlugin: Recherche de lemmes Mathlib\n",
    "# - LeanTacticPlugin: Generation de tactiques\n",
    "# - LeanVerificationPlugin: Verification avec lean_runner.py\n",
    "\n",
    "# Import du decorateur kernel_function\n",
    "try:\n",
    "    from semantic_kernel.functions import kernel_function\n",
    "    SK_AVAILABLE = True\n",
    "    print(\"Semantic Kernel disponible - utilisation des vrais decorateurs\")\n",
    "except ImportError:\n",
    "    SK_AVAILABLE = False\n",
    "    print(\"Semantic Kernel non disponible - mode simulation\")\n",
    "    # Decorateur de simulation\n",
    "    def kernel_function(description=\"\", name=None):\n",
    "        def decorator(func):\n",
    "            func._sk_function = True\n",
    "            func._sk_description = description\n",
    "            func._sk_name = name or func.__name__\n",
    "            return func\n",
    "        return decorator\n",
    "\n",
    "# =============================================================================\n",
    "# 8.2 ProofStateManagerPlugin\n",
    "# =============================================================================\n",
    "\n",
    "class ProofStateManagerPlugin:\n",
    "    \"\"\"\n",
    "    Plugin pour gerer l'etat partage de la preuve.\n",
    "    Expose les methodes de ProofState via @kernel_function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state: ProofState):\n",
    "        self._state = state\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Obtient un apercu de l'etat actuel de la preuve (theoreme, lemmes, tactiques, etc.)\",\n",
    "        name=\"get_proof_state\"\n",
    "    )\n",
    "    def get_proof_state(self, summarize: bool = True) -> str:\n",
    "        \"\"\"Retourne l'etat actuel sous forme JSON.\"\"\"\n",
    "        snapshot = self._state.get_state_snapshot(summarize=summarize)\n",
    "        return json.dumps(snapshot, indent=2, ensure_ascii=False)\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Ajoute un lemme decouvert a l'etat partage\",\n",
    "        name=\"add_discovered_lemma\"\n",
    "    )\n",
    "    def add_discovered_lemma(\n",
    "        self, name: str, statement: str, namespace: str = \"\", relevance: float = 0.5\n",
    "    ) -> str:\n",
    "        \"\"\"Enregistre un lemme trouve par SearchAgent.\"\"\"\n",
    "        lemma_id = self._state.add_lemma(name, statement, namespace, relevance)\n",
    "        return f\"Lemme ajoute: {lemma_id} ({name})\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Enregistre une tentative de tactique avec son niveau de confiance\",\n",
    "        name=\"log_tactic_attempt\"\n",
    "    )\n",
    "    def log_tactic_attempt(\n",
    "        self, tactic: str, state_before: str, confidence: float = 0.5, explanation: str = \"\"\n",
    "    ) -> str:\n",
    "        \"\"\"Enregistre une tactique tentee par TacticAgent.\"\"\"\n",
    "        attempt_id = self._state.add_tactic_attempt(tactic, state_before, confidence, explanation)\n",
    "        return f\"Tactique enregistree: {attempt_id}\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Enregistre le resultat d'une verification Lean\",\n",
    "        name=\"add_verification_result\"\n",
    "    )\n",
    "    def add_verification_result(\n",
    "        self, attempt_id: str, success: bool, output: str, errors: str,\n",
    "        remaining_goals: str = \"\", exec_time_ms: float = 0.0\n",
    "    ) -> str:\n",
    "        \"\"\"Enregistre un resultat de verification.\"\"\"\n",
    "        verif_id = self._state.add_verification(\n",
    "            attempt_id, success, output, errors,\n",
    "            remaining_goals if remaining_goals else None, exec_time_ms, \"subprocess\"\n",
    "        )\n",
    "        status = \"OK\" if success else \"ECHEC\"\n",
    "        return f\"Verification {verif_id}: {status}\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Designe l'agent qui doit parler au prochain tour. IMPORTANT: utiliser le nom exact.\",\n",
    "        name=\"designate_next_agent\"\n",
    "    )\n",
    "    def designate_next_agent(self, agent_name: str) -> str:\n",
    "        \"\"\"Delegue au prochain agent.\"\"\"\n",
    "        valid_agents = [\"SearchAgent\", \"TacticAgent\", \"VerifierAgent\", \"CriticAgent\", \"CoordinatorAgent\"]\n",
    "        if agent_name not in valid_agents:\n",
    "            return f\"ERREUR: Agent invalide '{agent_name}'. Valides: {valid_agents}\"\n",
    "        self._state.designate_next_agent(agent_name)\n",
    "        return f\"Prochain agent: {agent_name}\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Marque la preuve comme terminee avec le code final\",\n",
    "        name=\"set_proof_complete\"\n",
    "    )\n",
    "    def set_proof_complete(self, proof_code: str) -> str:\n",
    "        \"\"\"Marque la preuve comme reussie.\"\"\"\n",
    "        self._state.set_proof_complete(proof_code)\n",
    "        return f\"PREUVE COMPLETE! Code: {proof_code[:100]}...\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Change la strategie de preuve (exploration, refinement, validation, recovery)\",\n",
    "        name=\"set_proof_strategy\"\n",
    "    )\n",
    "    def set_proof_strategy(self, strategy: str) -> str:\n",
    "        \"\"\"Change la strategie de preuve.\"\"\"\n",
    "        try:\n",
    "            self._state.set_strategy(ProofStrategy(strategy))\n",
    "            return f\"Strategie changee: {strategy}\"\n",
    "        except ValueError:\n",
    "            return f\"ERREUR: Strategie invalide '{strategy}'. Valides: exploration, refinement, validation, recovery\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8.3 LeanSearchPlugin\n",
    "# =============================================================================\n",
    "\n",
    "class LeanSearchPlugin:\n",
    "    \"\"\"\n",
    "    Plugin pour la recherche de lemmes dans Mathlib.\n",
    "    Utilise des patterns connus + verification #check via lean_runner.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, runner: LeanRunner):\n",
    "        self._runner = runner\n",
    "        # Base de lemmes connus (extensible)\n",
    "        self._known_lemmas = {\n",
    "            # Arithmetique de base\n",
    "            \"Nat.add_zero\": (\"n + 0 = n\", \"Nat\"),\n",
    "            \"Nat.zero_add\": (\"0 + n = n\", \"Nat\"),\n",
    "            \"Nat.add_comm\": (\"n + m = m + n\", \"Nat\"),\n",
    "            \"Nat.add_assoc\": (\"(n + m) + k = n + (m + k)\", \"Nat\"),\n",
    "            \"Nat.mul_one\": (\"n * 1 = n\", \"Nat\"),\n",
    "            \"Nat.one_mul\": (\"1 * n = n\", \"Nat\"),\n",
    "            \"Nat.mul_comm\": (\"n * m = m * n\", \"Nat\"),\n",
    "            \"Nat.mul_assoc\": (\"(n * m) * k = n * (m * k)\", \"Nat\"),\n",
    "            \"Nat.left_distrib\": (\"n * (m + k) = n * m + n * k\", \"Nat\"),\n",
    "            \"Nat.right_distrib\": (\"(n + m) * k = n * k + m * k\", \"Nat\"),\n",
    "            # Logique\n",
    "            \"And.intro\": (\"a -> b -> a /\\\\ b\", \"Logic\"),\n",
    "            \"And.left\": (\"a /\\\\ b -> a\", \"Logic\"),\n",
    "            \"And.right\": (\"a /\\\\ b -> b\", \"Logic\"),\n",
    "            \"Or.inl\": (\"a -> a \\\\/ b\", \"Logic\"),\n",
    "            \"Or.inr\": (\"b -> a \\\\/ b\", \"Logic\"),\n",
    "            \"Eq.refl\": (\"a = a\", \"Logic\"),\n",
    "            \"Eq.symm\": (\"a = b -> b = a\", \"Logic\"),\n",
    "            \"Eq.trans\": (\"a = b -> b = c -> a = c\", \"Logic\"),\n",
    "        }\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Recherche des lemmes Mathlib pertinents pour un but donne\",\n",
    "        name=\"search_mathlib_lemmas\"\n",
    "    )\n",
    "    def search_mathlib_lemmas(self, goal: str, max_results: int = 10) -> str:\n",
    "        \"\"\"\n",
    "        Recherche des lemmes par mots-cles.\n",
    "\n",
    "        Args:\n",
    "            goal: Description du but ou mots-cles (ex: \"addition commutative\")\n",
    "            max_results: Nombre maximum de resultats\n",
    "\n",
    "        Returns:\n",
    "            JSON avec les lemmes trouves\n",
    "        \"\"\"\n",
    "        goal_lower = goal.lower()\n",
    "        results = []\n",
    "\n",
    "        # Recherche par mots-cles\n",
    "        keywords = goal_lower.replace(\"+\", \"add\").replace(\"*\", \"mul\").replace(\"=\", \"eq\").split()\n",
    "\n",
    "        for name, (statement, namespace) in self._known_lemmas.items():\n",
    "            score = 0.0\n",
    "            name_lower = name.lower()\n",
    "\n",
    "            # Scoring par mots-cles\n",
    "            for kw in keywords:\n",
    "                if kw in name_lower:\n",
    "                    score += 0.3\n",
    "                if kw in statement.lower():\n",
    "                    score += 0.2\n",
    "\n",
    "            # Patterns specifiques\n",
    "            if \"comm\" in goal_lower and \"comm\" in name_lower:\n",
    "                score += 0.4\n",
    "            if \"assoc\" in goal_lower and \"assoc\" in name_lower:\n",
    "                score += 0.4\n",
    "            if \"zero\" in goal_lower and \"zero\" in name_lower:\n",
    "                score += 0.3\n",
    "            if \"distrib\" in goal_lower and \"distrib\" in name_lower:\n",
    "                score += 0.4\n",
    "\n",
    "            if score > 0:\n",
    "                results.append({\n",
    "                    \"name\": name,\n",
    "                    \"statement\": statement,\n",
    "                    \"namespace\": namespace,\n",
    "                    \"relevance\": min(score, 1.0)\n",
    "                })\n",
    "\n",
    "        # Trier par pertinence\n",
    "        results.sort(key=lambda x: x[\"relevance\"], reverse=True)\n",
    "        return json.dumps(results[:max_results], indent=2, ensure_ascii=False)\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Verifie qu'un lemme existe et retourne son type via #check\",\n",
    "        name=\"check_lemma_type\"\n",
    "    )\n",
    "    def check_lemma_type(self, lemma_name: str) -> str:\n",
    "        \"\"\"\n",
    "        Verifie l'existence d'un lemme via #check.\n",
    "\n",
    "        Args:\n",
    "            lemma_name: Nom du lemme (ex: \"Nat.add_comm\")\n",
    "\n",
    "        Returns:\n",
    "            JSON {exists, type, error}\n",
    "        \"\"\"\n",
    "        code = f\"#check {lemma_name}\"\n",
    "        result = self._runner.run(code)\n",
    "\n",
    "        if result.success and not result.errors:\n",
    "            # Extraire le type de la sortie\n",
    "            return json.dumps({\n",
    "                \"exists\": True,\n",
    "                \"type\": result.output.strip(),\n",
    "                \"error\": None\n",
    "            })\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"exists\": False,\n",
    "                \"type\": None,\n",
    "                \"error\": result.errors or \"Lemme non trouve\"\n",
    "            })\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8.4 LeanTacticPlugin\n",
    "# =============================================================================\n",
    "\n",
    "class LeanTacticPlugin:\n",
    "    \"\"\"\n",
    "    Plugin pour la generation de tactiques.\n",
    "    Fournit des heuristiques et analyse les echecs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Tactiques par difficulte\n",
    "        self._tactics = {\n",
    "            \"simple\": [\"rfl\", \"trivial\", \"exact ?_\", \"assumption\"],\n",
    "            \"medium\": [\"simp\", \"omega\", \"decide\", \"constructor\", \"intro\", \"apply\"],\n",
    "            \"complex\": [\"ring\", \"linarith\", \"aesop\", \"induction\", \"cases\", \"rcases\"]\n",
    "        }\n",
    "\n",
    "        # Heuristiques par pattern de but\n",
    "        self._heuristics = {\n",
    "            \"equality\": [\"rfl\", \"exact\", \"simp\", \"ring\", \"omega\"],\n",
    "            \"forall\": [\"intro\", \"intros\", \"apply\"],\n",
    "            \"exists\": [\"use\", \"exists\", \"exact\"],\n",
    "            \"and\": [\"constructor\", \"exact And.intro\"],\n",
    "            \"or\": [\"left\", \"right\"],\n",
    "            \"implication\": [\"intro\", \"apply\", \"exact\"],\n",
    "            \"nat_arithmetic\": [\"omega\", \"simp\", \"decide\"],\n",
    "            \"ring_expression\": [\"ring\", \"ring_nf\"]\n",
    "        }\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Genere des tactiques appropriees pour un but donne\",\n",
    "        name=\"generate_tactics\"\n",
    "    )\n",
    "    def generate_tactics(self, goal: str, context: str = \"\", difficulty: str = \"simple\") -> str:\n",
    "        \"\"\"\n",
    "        Genere des tactiques pour le but courant.\n",
    "\n",
    "        Args:\n",
    "            goal: Le but Lean a prouver\n",
    "            context: Contexte additionnel (lemmes disponibles, etc.)\n",
    "            difficulty: simple, medium, ou complex\n",
    "\n",
    "        Returns:\n",
    "            JSON [{tactic, confidence, explanation}]\n",
    "        \"\"\"\n",
    "        suggestions = []\n",
    "        goal_lower = goal.lower()\n",
    "\n",
    "        # Detecter le type de but\n",
    "        detected_patterns = []\n",
    "        if \"=\" in goal:\n",
    "            detected_patterns.append(\"equality\")\n",
    "        if \"forall\" in goal_lower or \"∀\" in goal:\n",
    "            detected_patterns.append(\"forall\")\n",
    "        if \"exists\" in goal_lower or \"∃\" in goal:\n",
    "            detected_patterns.append(\"exists\")\n",
    "        if \"/\\\\\" in goal or \"∧\" in goal or \"And\" in goal:\n",
    "            detected_patterns.append(\"and\")\n",
    "        if \"\\\\/\" in goal or \"∨\" in goal or \"Or\" in goal:\n",
    "            detected_patterns.append(\"or\")\n",
    "        if \"->\" in goal or \"→\" in goal:\n",
    "            detected_patterns.append(\"implication\")\n",
    "        if any(x in goal_lower for x in [\"nat\", \"n +\", \"m +\", \"+ 0\", \"0 +\"]):\n",
    "            detected_patterns.append(\"nat_arithmetic\")\n",
    "        if any(x in goal for x in [\"*\", \"+\"]) and \"=\" in goal:\n",
    "            detected_patterns.append(\"ring_expression\")\n",
    "\n",
    "        # Collecter les tactiques suggeres\n",
    "        seen = set()\n",
    "        for pattern in detected_patterns:\n",
    "            for tactic in self._heuristics.get(pattern, []):\n",
    "                if tactic not in seen:\n",
    "                    seen.add(tactic)\n",
    "                    confidence = 0.7 if difficulty == \"simple\" else 0.5\n",
    "                    suggestions.append({\n",
    "                        \"tactic\": tactic,\n",
    "                        \"confidence\": confidence,\n",
    "                        \"explanation\": f\"Pattern detecte: {pattern}\"\n",
    "                    })\n",
    "\n",
    "        # Ajouter des tactiques de base\n",
    "        base_tactics = self._tactics.get(difficulty, self._tactics[\"simple\"])\n",
    "        for tactic in base_tactics[:3]:\n",
    "            if tactic not in seen:\n",
    "                suggestions.append({\n",
    "                    \"tactic\": tactic,\n",
    "                    \"confidence\": 0.3,\n",
    "                    \"explanation\": f\"Tactique {difficulty} generique\"\n",
    "                })\n",
    "\n",
    "        # Trier par confiance\n",
    "        suggestions.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
    "        return json.dumps(suggestions[:8], indent=2, ensure_ascii=False)\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Analyse un echec de tactique et suggere des alternatives\",\n",
    "        name=\"analyze_tactic_failure\"\n",
    "    )\n",
    "    def analyze_tactic_failure(self, failed_tactic: str, error_msg: str) -> str:\n",
    "        \"\"\"\n",
    "        Analyse pourquoi une tactique a echoue.\n",
    "\n",
    "        Args:\n",
    "            failed_tactic: La tactique qui a echoue\n",
    "            error_msg: Message d'erreur Lean\n",
    "\n",
    "        Returns:\n",
    "            JSON {diagnosis, alternatives, error_type}\n",
    "        \"\"\"\n",
    "        error_lower = error_msg.lower()\n",
    "        diagnosis = \"\"\n",
    "        alternatives = []\n",
    "        error_type = \"unknown\"\n",
    "\n",
    "        # Classifier l'erreur\n",
    "        if \"unknown identifier\" in error_lower or \"unknown constant\" in error_lower:\n",
    "            error_type = \"unknown_identifier\"\n",
    "            diagnosis = \"Lemme ou identifiant non reconnu. Verifier l'import ou le nom.\"\n",
    "            alternatives = [\"Chercher le bon nom avec #check\", \"Verifier les imports\"]\n",
    "\n",
    "        elif \"type mismatch\" in error_lower:\n",
    "            error_type = \"type_mismatch\"\n",
    "            diagnosis = \"Les types ne correspondent pas. Verifier les arguments.\"\n",
    "            alternatives = [\"exact\", \"apply\", \"simp\"]\n",
    "\n",
    "        elif \"unsolved goals\" in error_lower or \"goals remain\" in error_lower:\n",
    "            error_type = \"unsolved_goals\"\n",
    "            diagnosis = \"Des sous-buts restent. La tactique n'a pas complete la preuve.\"\n",
    "            alternatives = [\"Ajouter d'autres tactiques\", \"Essayer simp\", \"Decomposer avec have\"]\n",
    "\n",
    "        elif \"tactic failed\" in error_lower:\n",
    "            error_type = \"tactic_failed\"\n",
    "            diagnosis = f\"La tactique '{failed_tactic}' n'a pas pu s'appliquer.\"\n",
    "            # Suggerer des alternatives\n",
    "            if failed_tactic in [\"ring\", \"linarith\"]:\n",
    "                alternatives = [\"omega\", \"simp\", \"decide\"]\n",
    "            elif failed_tactic == \"simp\":\n",
    "                alternatives = [\"simp only\", \"rfl\", \"exact\"]\n",
    "            else:\n",
    "                alternatives = [\"simp\", \"omega\", \"exact ?_\"]\n",
    "\n",
    "        elif \"declaration uses 'sorry'\" in error_lower:\n",
    "            error_type = \"sorry\"\n",
    "            diagnosis = \"La preuve contient 'sorry' - incomplete.\"\n",
    "            alternatives = [\"Completer la preuve\", \"Remplacer sorry par une vraie tactique\"]\n",
    "\n",
    "        else:\n",
    "            error_type = \"other\"\n",
    "            diagnosis = f\"Erreur non classifiee: {error_msg[:100]}\"\n",
    "            alternatives = [\"Verifier la syntaxe\", \"Essayer une approche differente\"]\n",
    "\n",
    "        return json.dumps({\n",
    "            \"diagnosis\": diagnosis,\n",
    "            \"alternatives\": alternatives,\n",
    "            \"error_type\": error_type,\n",
    "            \"original_error\": error_msg[:200]\n",
    "        }, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8.5 LeanVerificationPlugin\n",
    "# =============================================================================\n",
    "\n",
    "class LeanVerificationPlugin:\n",
    "    \"\"\"\n",
    "    Plugin pour la verification des preuves avec lean_runner.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, runner: LeanRunner):\n",
    "        self._runner = runner\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Verifie une preuve complete (theoreme + tactiques)\",\n",
    "        name=\"verify_proof\"\n",
    "    )\n",
    "    def verify_proof(self, theorem_statement: str, proof_tactics: str) -> str:\n",
    "        \"\"\"\n",
    "        Verifie un theoreme avec sa preuve.\n",
    "\n",
    "        Args:\n",
    "            theorem_statement: L'enonce du theoreme (ex: \"theorem add_zero (n : Nat) : n + 0 = n\")\n",
    "            proof_tactics: La preuve (ex: \"exact Nat.add_zero n\")\n",
    "\n",
    "        Returns:\n",
    "            JSON {success, output, errors, exec_time_ms, backend}\n",
    "        \"\"\"\n",
    "        import time\n",
    "\n",
    "        # Construire le code complet\n",
    "        if \"by\" not in proof_tactics and \":=\" not in proof_tactics:\n",
    "            code = f\"{theorem_statement} := by {proof_tactics}\"\n",
    "        elif \":=\" in proof_tactics:\n",
    "            code = f\"{theorem_statement} {proof_tactics}\"\n",
    "        else:\n",
    "            code = f\"{theorem_statement} := {proof_tactics}\"\n",
    "\n",
    "        start = time.time()\n",
    "        result = self._runner.run(code)\n",
    "        exec_time = (time.time() - start) * 1000\n",
    "\n",
    "        return json.dumps({\n",
    "            \"success\": result.success,\n",
    "            \"output\": result.output,\n",
    "            \"errors\": result.errors,\n",
    "            \"exit_code\": result.exit_code,\n",
    "            \"exec_time_ms\": round(exec_time, 2),\n",
    "            \"backend\": result.backend,\n",
    "            \"code\": code\n",
    "        }, indent=2, ensure_ascii=False)\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Verifie une etape de tactique incrementale\",\n",
    "        name=\"verify_tactic_step\"\n",
    "    )\n",
    "    def verify_tactic_step(\n",
    "        self, partial_proof: str, next_tactic: str, theorem_statement: str\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Verifie une tactique incrementale.\n",
    "\n",
    "        Args:\n",
    "            partial_proof: Les tactiques deja appliquees (separees par ;)\n",
    "            next_tactic: La prochaine tactique a essayer\n",
    "            theorem_statement: L'enonce du theoreme\n",
    "\n",
    "        Returns:\n",
    "            JSON {tactic_valid, remaining_goals, error, exec_time_ms}\n",
    "        \"\"\"\n",
    "        import time\n",
    "\n",
    "        # Combiner les tactiques\n",
    "        if partial_proof:\n",
    "            all_tactics = f\"{partial_proof}; {next_tactic}\"\n",
    "        else:\n",
    "            all_tactics = next_tactic\n",
    "\n",
    "        code = f\"{theorem_statement} := by {all_tactics}\"\n",
    "\n",
    "        start = time.time()\n",
    "        result = self._runner.run(code)\n",
    "        exec_time = (time.time() - start) * 1000\n",
    "\n",
    "        # Analyser les goals restants\n",
    "        remaining_goals = None\n",
    "        if \"unsolved goals\" in result.errors.lower():\n",
    "            # Extraire les goals du message d'erreur\n",
    "            remaining_goals = result.errors\n",
    "\n",
    "        return json.dumps({\n",
    "            \"tactic_valid\": result.success or \"unsolved goals\" not in result.errors.lower(),\n",
    "            \"remaining_goals\": remaining_goals,\n",
    "            \"error\": result.errors if not result.success else None,\n",
    "            \"exec_time_ms\": round(exec_time, 2),\n",
    "            \"applied_tactics\": all_tactics\n",
    "        }, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Test des Plugins\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== Test des Plugins ===\")\n",
    "\n",
    "# Creer l'etat et le runner\n",
    "test_state = ProofState(theorem_statement=\"theorem test_add (n : Nat) : n + 0 = n\")\n",
    "runner = LeanRunner(backend=\"subprocess\", timeout=30)\n",
    "\n",
    "# Instancier les plugins\n",
    "state_plugin = ProofStateManagerPlugin(test_state)\n",
    "search_plugin = LeanSearchPlugin(runner)\n",
    "tactic_plugin = LeanTacticPlugin()\n",
    "verif_plugin = LeanVerificationPlugin(runner)\n",
    "\n",
    "# Test 1: Recherche de lemmes\n",
    "print(\"\\n1. Recherche de lemmes pour 'addition zero':\")\n",
    "lemmas = search_plugin.search_mathlib_lemmas(\"addition zero\", max_results=3)\n",
    "print(lemmas)\n",
    "\n",
    "# Test 2: Generation de tactiques\n",
    "print(\"\\n2. Tactiques pour 'n + 0 = n':\")\n",
    "tactics = tactic_plugin.generate_tactics(\"n + 0 = n\", difficulty=\"simple\")\n",
    "print(tactics)\n",
    "\n",
    "# Test 3: Verification avec lean_runner\n",
    "print(\"\\n3. Verification d'une preuve:\")\n",
    "result = verif_plugin.verify_proof(\"theorem test_rfl : 2 + 2 = 4\", \"rfl\")\n",
    "print(result)\n",
    "\n",
    "# Test 4: Plugin StateManager\n",
    "print(\"\\n4. Ajout via StateManagerPlugin:\")\n",
    "print(state_plugin.add_discovered_lemma(\"Nat.add_zero\", \"n + 0 = n\", \"Nat\", 0.9))\n",
    "print(state_plugin.get_proof_state(summarize=True))\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 Definition des 5 Agents Specialises\n",
    "\n",
    "Le systeme multi-agents comprend 5 roles distincts:\n",
    "\n",
    "| Agent | Role | Plugins | Delegation |\n",
    "|-------|------|---------|------------|\n",
    "| **SearchAgent** | Recherche lemmes Mathlib | LeanSearch, StateManager | TacticAgent si lemmes trouves |\n",
    "| **TacticAgent** | Generation tactiques | LeanTactic, StateManager | VerifierAgent pour validation |\n",
    "| **VerifierAgent** | Verification Lean | LeanVerification, StateManager | CriticAgent si echec |\n",
    "| **CriticAgent** | Analyse echecs | LeanTactic, StateManager | Redirection selon erreur |\n",
    "| **CoordinatorAgent** | Supervision globale | StateManager | Gestion des blocages |\n",
    "\n",
    "**Pattern cle**: Chaque agent designe explicitement le suivant via `designate_next_agent()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python-dotenv non installe, utilisation des variables systeme\n",
      "Agents definis:\n",
      "  - OrchestratorAgent\n",
      "  - SearchAgent\n",
      "  - TacticAgent\n",
      "  - VerifierAgent\n",
      "\n",
      "Mode: Simulation (fallback)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 8.6 - Definition des 5 Agents Specialises\n",
    "# =============================================================================\n",
    "# Pattern inspire de Argument_Analysis_Agentic-3-orchestration.ipynb\n",
    "\n",
    "# --- Instructions des Agents ---\n",
    "\n",
    "SEARCH_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent de RECHERCHE de lemmes pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Chercher des lemmes Mathlib pertinents pour le theoreme courant\n",
    "- Identifier les lemmes qui peuvent aider a la preuve\n",
    "- Enregistrer les lemmes trouves dans l'etat partage\n",
    "\n",
    "WORKFLOW:\n",
    "1. Lis l'etat avec get_proof_state() pour comprendre le theoreme\n",
    "2. Utilise search_mathlib_lemmas() avec des mots-cles pertinents\n",
    "3. Verifie les lemmes prometteurs avec check_lemma_type()\n",
    "4. Enregistre les lemmes utiles avec add_discovered_lemma()\n",
    "5. Delegue a TacticAgent quand tu as trouve des lemmes\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "- get_proof_state: Lire l'etat actuel\n",
    "- search_mathlib_lemmas: Chercher des lemmes\n",
    "- check_lemma_type: Verifier un lemme\n",
    "- add_discovered_lemma: Enregistrer un lemme\n",
    "- designate_next_agent: Deleguer au prochain agent\n",
    "\n",
    "IMPORTANT:\n",
    "- Cherche des lemmes LIES au but (egalites, arithmetique, logique)\n",
    "- Delegation: Apres avoir trouve au moins 2-3 lemmes, delegue a TacticAgent\n",
    "- Si aucun lemme pertinent, delegue quand meme a TacticAgent\n",
    "\"\"\"\n",
    "\n",
    "TACTIC_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent de GENERATION DE TACTIQUES pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Generer des sequences de tactiques Lean pour prouver le but\n",
    "- Utiliser les lemmes trouves par SearchAgent\n",
    "- Proposer des tactiques avec niveau de confiance\n",
    "\n",
    "WORKFLOW:\n",
    "1. Lis l'etat avec get_proof_state() pour voir le theoreme et les lemmes\n",
    "2. Utilise generate_tactics() pour obtenir des suggestions\n",
    "3. Enregistre ta meilleure tentative avec log_tactic_attempt()\n",
    "4. Delegue a VerifierAgent pour verification\n",
    "\n",
    "STRATEGIES DE TACTIQUES (par difficulte):\n",
    "- SIMPLE: rfl, trivial, exact, assumption\n",
    "- MEDIUM: simp, omega, constructor, intro, apply\n",
    "- COMPLEX: ring, linarith, induction, cases\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "- get_proof_state: Lire l'etat (theoreme, lemmes, echecs precedents)\n",
    "- generate_tactics: Obtenir des suggestions de tactiques\n",
    "- log_tactic_attempt: Enregistrer une tentative\n",
    "- designate_next_agent: Deleguer a VerifierAgent\n",
    "\n",
    "IMPORTANT:\n",
    "- Commence par les tactiques simples (rfl, exact)\n",
    "- Utilise les lemmes trouves par SearchAgent (exact Nat.add_zero n)\n",
    "- Delegation: TOUJOURS deleguer a VerifierAgent apres avoir propose\n",
    "\"\"\"\n",
    "\n",
    "VERIFIER_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent de VERIFICATION pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Verifier les tactiques proposees avec le compilateur Lean\n",
    "- Enregistrer les resultats de verification\n",
    "- Determiner si la preuve est complete ou s'il faut continuer\n",
    "\n",
    "WORKFLOW:\n",
    "1. Lis l'etat avec get_proof_state() pour voir la derniere tactique\n",
    "2. Utilise verify_proof() pour tester la preuve\n",
    "3. Enregistre le resultat avec add_verification_result()\n",
    "4. Si succes: set_proof_complete() et termine\n",
    "5. Si echec: delegue a CriticAgent pour analyse\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "- get_proof_state: Lire l'etat (theoreme, tactiques tentees)\n",
    "- verify_proof: Verifier une preuve complete\n",
    "- verify_tactic_step: Verifier une tactique incrementale\n",
    "- add_verification_result: Enregistrer le resultat\n",
    "- set_proof_complete: Marquer la preuve comme terminee\n",
    "- designate_next_agent: Deleguer a CriticAgent si echec\n",
    "\n",
    "IMPORTANT:\n",
    "- Teste TOUJOURS la derniere tactique proposee\n",
    "- Si la preuve compile sans erreur, utilise set_proof_complete()\n",
    "- Si echec, enregistre l'erreur et delegue a CriticAgent\n",
    "\"\"\"\n",
    "\n",
    "CRITIC_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent CRITIQUE pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Analyser les echecs de verification\n",
    "- Diagnostiquer les erreurs Lean\n",
    "- Orienter vers la bonne strategie de correction\n",
    "\n",
    "WORKFLOW:\n",
    "1. Lis l'etat avec get_proof_state() pour voir les echecs recents\n",
    "2. Utilise analyze_tactic_failure() pour comprendre l'erreur\n",
    "3. Decide quelle direction prendre:\n",
    "   - \"unknown identifier\" -> delegue a SearchAgent\n",
    "   - \"type mismatch\" ou \"tactic failed\" -> delegue a TacticAgent (difficulte superieure)\n",
    "   - Echecs repetes (>3) -> delegue a CoordinatorAgent\n",
    "\n",
    "PATTERNS D'ERREURS:\n",
    "- \"unknown identifier/constant\" : Lemme non trouve -> SearchAgent\n",
    "- \"type mismatch\" : Arguments incorrects -> TacticAgent\n",
    "- \"unsolved goals\" : Preuve incomplete -> TacticAgent\n",
    "- \"tactic failed\" : Mauvaise tactique -> TacticAgent\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "- get_proof_state: Lire l'etat (echecs, iterations)\n",
    "- analyze_tactic_failure: Diagnostiquer une erreur\n",
    "- set_proof_strategy: Changer la strategie (recovery, refinement)\n",
    "- designate_next_agent: Orienter selon le diagnostic\n",
    "\n",
    "IMPORTANT:\n",
    "- Analyse les 3 derniers echecs pour detecter des patterns\n",
    "- Si >3 echecs similaires, delegue a CoordinatorAgent\n",
    "- Suggere d'augmenter la difficulte des tactiques si necessaire\n",
    "\"\"\"\n",
    "\n",
    "COORDINATOR_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent COORDINATEUR (superviseur) pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Superviser l'ensemble de la session de preuve\n",
    "- Debloquer les situations cycliques\n",
    "- Ajuster la strategie globale\n",
    "\n",
    "QUAND TU INTERVIENS:\n",
    "- Appele par CriticAgent apres echecs repetes\n",
    "- Appele si max_iterations approche\n",
    "- Appele pour decisions strategiques majeures\n",
    "\n",
    "STRATEGIES DISPONIBLES:\n",
    "- \"exploration\": Phase initiale, recherche de lemmes (defaut)\n",
    "- \"refinement\": Affiner les tactiques apres premiers succes\n",
    "- \"validation\": Phase finale, verification complete\n",
    "- \"recovery\": Mode recuperation apres echecs majeurs\n",
    "\n",
    "WORKFLOW:\n",
    "1. Lis l'etat avec get_proof_state(summarize=False) pour tout voir\n",
    "2. Analyse l'historique des echecs et des tactiques\n",
    "3. Decide de la prochaine action:\n",
    "   - Trop de recherches sans resultat? -> TacticAgent avec difficulte \"complex\"\n",
    "   - Boucle detectee? -> Changer de strategie + SearchAgent\n",
    "   - Proche du succes? -> VerifierAgent directement\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "- get_proof_state: Vue complete de l'etat\n",
    "- set_proof_strategy: Changer la strategie globale\n",
    "- designate_next_agent: Orienter vers le bon agent\n",
    "\n",
    "IMPORTANT:\n",
    "- Tu es le dernier recours, prends des decisions audacieuses\n",
    "- Si >40 iterations, suggere de simplifier le theoreme\n",
    "- Garde une vue d'ensemble, pas juste le dernier echec\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# Classe SimpleAgent (simulation sans Semantic Kernel reel)\n",
    "# =============================================================================\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    Agent simplifie pour simulation.\n",
    "    En production, utiliser ChatCompletionAgent de Semantic Kernel.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        instructions: str,\n",
    "        plugins: Dict[str, Any],\n",
    "        use_simulation: bool = True\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.instructions = instructions\n",
    "        self.plugins = plugins\n",
    "        self.use_simulation = use_simulation\n",
    "        self._openai_client = None\n",
    "\n",
    "        # Initialiser le client OpenAI si disponible\n",
    "        if not use_simulation:\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "                if api_key and len(api_key) > 10 and not api_key.startswith(\"sk-...\"):\n",
    "                    self._openai_client = OpenAI(api_key=api_key)\n",
    "            except ImportError:\n",
    "                pass\n",
    "\n",
    "    def _build_tool_descriptions(self) -> str:\n",
    "        \"\"\"Construit la description des outils disponibles.\"\"\"\n",
    "        tools = []\n",
    "        for plugin_name, plugin in self.plugins.items():\n",
    "            for attr_name in dir(plugin):\n",
    "                attr = getattr(plugin, attr_name)\n",
    "                if callable(attr) and hasattr(attr, '_sk_function'):\n",
    "                    tools.append(f\"- {attr._sk_name}: {attr._sk_description}\")\n",
    "        return \"\\n\".join(tools)\n",
    "\n",
    "    def invoke(self, message: str, state: ProofState) -> str:\n",
    "        \"\"\"Execute l'agent sur un message.\"\"\"\n",
    "        state.increment_iteration()\n",
    "\n",
    "        if self.use_simulation or not self._openai_client:\n",
    "            return self._simulate_response(message, state)\n",
    "        else:\n",
    "            return self._call_llm(message, state)\n",
    "\n",
    "    def _simulate_response(self, message: str, state: ProofState) -> str:\n",
    "        \"\"\"Simulation de l'agent (sans appels LLM).\"\"\"\n",
    "        # Logique simulee par agent\n",
    "        if self.name == \"SearchAgent\":\n",
    "            # Simuler recherche de lemmes\n",
    "            search = self.plugins.get(\"search\")\n",
    "            state_mgr = self.plugins.get(\"state\")\n",
    "            if search and state_mgr:\n",
    "                # Rechercher des lemmes\n",
    "                lemmas_json = search.search_mathlib_lemmas(state.theorem_goal or \"addition\", max_results=3)\n",
    "                lemmas = json.loads(lemmas_json)\n",
    "                for lemma in lemmas[:2]:\n",
    "                    state_mgr.add_discovered_lemma(lemma[\"name\"], lemma[\"statement\"], lemma[\"namespace\"], lemma[\"relevance\"])\n",
    "                state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "                return f\"[SearchAgent] Trouves {len(lemmas[:2])} lemmes. Delegation a TacticAgent.\"\n",
    "\n",
    "        elif self.name == \"TacticAgent\":\n",
    "            # Simuler generation de tactiques\n",
    "            tactic = self.plugins.get(\"tactic\")\n",
    "            state_mgr = self.plugins.get(\"state\")\n",
    "            if tactic and state_mgr:\n",
    "                tactics_json = tactic.generate_tactics(state.theorem_goal or \"n + 0 = n\", difficulty=\"simple\")\n",
    "                tactics = json.loads(tactics_json)\n",
    "                if tactics:\n",
    "                    best = tactics[0]\n",
    "                    state_mgr.log_tactic_attempt(best[\"tactic\"], state.theorem_goal or \"\", best[\"confidence\"], best[\"explanation\"])\n",
    "                state_mgr.designate_next_agent(\"VerifierAgent\")\n",
    "                return f\"[TacticAgent] Propose: {tactics[0]['tactic'] if tactics else 'rfl'}. Delegation a VerifierAgent.\"\n",
    "\n",
    "        elif self.name == \"VerifierAgent\":\n",
    "            # Simuler verification\n",
    "            verif = self.plugins.get(\"verification\")\n",
    "            state_mgr = self.plugins.get(\"state\")\n",
    "            if verif and state_mgr and state.tactics_history:\n",
    "                last_tactic = state.tactics_history[-1]\n",
    "                result_json = verif.verify_proof(state.theorem_statement, last_tactic.tactic)\n",
    "                result = json.loads(result_json)\n",
    "                state_mgr.add_verification_result(\n",
    "                    last_tactic.id, result[\"success\"], result[\"output\"], result[\"errors\"],\n",
    "                    \"\", result[\"exec_time_ms\"]\n",
    "                )\n",
    "                if result[\"success\"]:\n",
    "                    state_mgr.set_proof_complete(last_tactic.tactic)\n",
    "                    return f\"[VerifierAgent] SUCCES! Preuve: {last_tactic.tactic}\"\n",
    "                else:\n",
    "                    state_mgr.designate_next_agent(\"CriticAgent\")\n",
    "                    return f\"[VerifierAgent] Echec: {result['errors'][:100]}. Delegation a CriticAgent.\"\n",
    "\n",
    "        elif self.name == \"CriticAgent\":\n",
    "            # Simuler analyse\n",
    "            tactic = self.plugins.get(\"tactic\")\n",
    "            state_mgr = self.plugins.get(\"state\")\n",
    "            if tactic and state_mgr:\n",
    "                failures = state.get_recent_failures(3)\n",
    "                if failures:\n",
    "                    _, last_verif = failures[0]\n",
    "                    analysis_json = tactic.analyze_tactic_failure(\"unknown\", last_verif.errors)\n",
    "                    analysis = json.loads(analysis_json)\n",
    "                    if analysis[\"error_type\"] == \"unknown_identifier\":\n",
    "                        state_mgr.designate_next_agent(\"SearchAgent\")\n",
    "                        return f\"[CriticAgent] Identifiant inconnu. Retour a SearchAgent.\"\n",
    "                    elif len(failures) > 3:\n",
    "                        state_mgr.designate_next_agent(\"CoordinatorAgent\")\n",
    "                        return f\"[CriticAgent] Trop d'echecs ({len(failures)}). Appel CoordinatorAgent.\"\n",
    "                    else:\n",
    "                        state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "                        return f\"[CriticAgent] Essayer d'autres tactiques. -> TacticAgent.\"\n",
    "                state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "                return \"[CriticAgent] Pas d'echecs recents. -> TacticAgent.\"\n",
    "\n",
    "        elif self.name == \"CoordinatorAgent\":\n",
    "            state_mgr = self.plugins.get(\"state\")\n",
    "            if state_mgr:\n",
    "                if state.iteration_count > 30:\n",
    "                    state_mgr.set_proof_strategy(\"recovery\")\n",
    "                    return \"[CoordinatorAgent] Mode recovery active. Theoreme peut-etre trop complexe.\"\n",
    "                else:\n",
    "                    state_mgr.set_proof_strategy(\"refinement\")\n",
    "                    state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "                    return \"[CoordinatorAgent] Strategie refinement. -> TacticAgent avec difficulte superieure.\"\n",
    "\n",
    "        return f\"[{self.name}] Action simulee.\"\n",
    "\n",
    "    def _call_llm(self, message: str, state: ProofState) -> str:\n",
    "        \"\"\"Appelle le LLM OpenAI.\"\"\"\n",
    "        # Note: En production, utiliser Semantic Kernel avec function calling\n",
    "        tools_desc = self._build_tool_descriptions()\n",
    "        state_summary = json.dumps(state.get_state_snapshot(summarize=True), indent=2)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "{self.instructions}\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "{tools_desc}\n",
    "\n",
    "ETAT ACTUEL:\n",
    "{state_summary}\n",
    "\n",
    "MESSAGE:\n",
    "{message}\n",
    "\n",
    "Reponds avec l'action a effectuer.\n",
    "\"\"\"\n",
    "        try:\n",
    "            response = self._openai_client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.instructions},\n",
    "                    {\"role\": \"user\", \"content\": f\"Etat: {state_summary}\\n\\n{message}\"}\n",
    "                ],\n",
    "                max_tokens=500,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            return f\"[{self.name}] {response.choices[0].message.content}\"\n",
    "        except Exception as e:\n",
    "            return f\"[{self.name}] Erreur LLM: {e}\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Test des Agents\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== Test des Agents ===\")\n",
    "\n",
    "# Creer l'environnement\n",
    "test_state = ProofState(\n",
    "    theorem_statement=\"theorem add_zero (n : Nat) : n + 0 = n\",\n",
    "    theorem_goal=\"n + 0 = n\"\n",
    ")\n",
    "runner = LeanRunner(backend=\"subprocess\", timeout=30)\n",
    "\n",
    "# Creer les plugins\n",
    "plugins = {\n",
    "    \"state\": ProofStateManagerPlugin(test_state),\n",
    "    \"search\": LeanSearchPlugin(runner),\n",
    "    \"tactic\": LeanTacticPlugin(),\n",
    "    \"verification\": LeanVerificationPlugin(runner)\n",
    "}\n",
    "\n",
    "# Creer les agents (mode simulation)\n",
    "agents = {\n",
    "    \"SearchAgent\": SimpleAgent(\"SearchAgent\", SEARCH_AGENT_INSTRUCTIONS, plugins, use_simulation=True),\n",
    "    \"TacticAgent\": SimpleAgent(\"TacticAgent\", TACTIC_AGENT_INSTRUCTIONS, plugins, use_simulation=True),\n",
    "    \"VerifierAgent\": SimpleAgent(\"VerifierAgent\", VERIFIER_AGENT_INSTRUCTIONS, plugins, use_simulation=True),\n",
    "    \"CriticAgent\": SimpleAgent(\"CriticAgent\", CRITIC_AGENT_INSTRUCTIONS, plugins, use_simulation=True),\n",
    "    \"CoordinatorAgent\": SimpleAgent(\"CoordinatorAgent\", COORDINATOR_AGENT_INSTRUCTIONS, plugins, use_simulation=True),\n",
    "}\n",
    "\n",
    "# Tester un agent\n",
    "print(\"\\nTest SearchAgent:\")\n",
    "response = agents[\"SearchAgent\"].invoke(\"Trouve des lemmes pour n + 0 = n\", test_state)\n",
    "print(response)\n",
    "print(f\"Etat apres SearchAgent:\\n{test_state}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7 Strategies d'Orchestration\n",
    "\n",
    "L'orchestration determine comment les agents sont selectionnes et quand la conversation se termine.\n",
    "\n",
    "**DelegatingSelectionStrategy** (Pattern recommande):\n",
    "- Chaque agent designe explicitement le suivant via `designate_next_agent()`\n",
    "- Si aucune designation, utilise un agent par defaut (CoordinatorAgent)\n",
    "\n",
    "**ProofCompleteTermination**:\n",
    "- Termine si `proof_complete == True`\n",
    "- Termine si `iteration_count >= max_iterations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.8 Demonstration Complete\n",
    "\n",
    "Cette demonstration montre le workflow multi-agents complet:\n",
    "1. **CoordinatorAgent** initialise la session\n",
    "2. **SearchAgent** recherche les lemmes pertinents\n",
    "3. **TacticAgent** propose des tactiques\n",
    "4. **VerifierAgent** verifie avec Lean\n",
    "5. **CriticAgent** intervient en cas d'echec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategies d'orchestration definies:\n",
      "  - DelegatingSelectionStrategy: Selection par delegation explicite\n",
      "  - RoundRobinStrategy: Selection cyclique\n",
      "  - ProofCompleteTermination: Termine quand preuve trouvee\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 8.7 - Strategies d'Orchestration\n",
    "# =============================================================================\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class SelectionStrategy(ABC):\n",
    "    \"\"\"Strategie abstraite de selection de l'agent suivant.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def select_next(self, agents: Dict[str, SimpleAgent], state: ProofState) -> str:\n",
    "        \"\"\"Retourne le nom de l'agent a activer.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class DelegatingSelectionStrategy(SelectionStrategy):\n",
    "    \"\"\"\n",
    "    Selection basee sur delegation explicite.\n",
    "\n",
    "    L'agent courant designe le prochain via state.designate_next_agent().\n",
    "    Si aucune designation, utilise l'agent par defaut.\n",
    "\n",
    "    C'est le pattern recommande pour le theorem proving car il permet\n",
    "    une orchestration flexible basee sur le contexte.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, default_agent: str = \"CoordinatorAgent\"):\n",
    "        self.default_agent = default_agent\n",
    "\n",
    "    def select_next(self, agents: Dict[str, SimpleAgent], state: ProofState) -> str:\n",
    "        designated = state.consume_next_agent_designation()\n",
    "        if designated and designated in agents:\n",
    "            return designated\n",
    "        return self.default_agent\n",
    "\n",
    "\n",
    "class SequentialSelectionStrategy(SelectionStrategy):\n",
    "    \"\"\"\n",
    "    Selection sequentielle simple.\n",
    "\n",
    "    Suit un ordre predetermine: SearchAgent -> TacticAgent -> VerifierAgent.\n",
    "    Utile pour les preuves simples qui ne necessitent pas de retour arriere.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sequence: List[str] = None):\n",
    "        self.sequence = sequence or [\"SearchAgent\", \"TacticAgent\", \"VerifierAgent\"]\n",
    "        self.current_index = 0\n",
    "\n",
    "    def select_next(self, agents: Dict[str, SimpleAgent], state: ProofState) -> str:\n",
    "        agent = self.sequence[self.current_index % len(self.sequence)]\n",
    "        self.current_index += 1\n",
    "        return agent\n",
    "\n",
    "\n",
    "class TerminationStrategy(ABC):\n",
    "    \"\"\"Strategie abstraite de terminaison.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def should_terminate(self, state: ProofState) -> bool:\n",
    "        \"\"\"Retourne True si la conversation doit se terminer.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class ProofCompleteTermination(TerminationStrategy):\n",
    "    \"\"\"\n",
    "    Termine quand la preuve est trouvee ou max iterations atteint.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_iterations: int = 50):\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def should_terminate(self, state: ProofState) -> bool:\n",
    "        # Terminaison si preuve trouvee\n",
    "        if state.proof_complete:\n",
    "            return True\n",
    "        # Terminaison si max iterations\n",
    "        if state.iteration_count >= self.max_iterations:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# AgentGroupChat - Orchestration Multi-Agents\n",
    "# =============================================================================\n",
    "\n",
    "class AgentGroupChat:\n",
    "    \"\"\"\n",
    "    Conversation multi-agents pour theorem proving.\n",
    "\n",
    "    Coordonne plusieurs agents selon les strategies de selection et terminaison.\n",
    "    Chaque tour:\n",
    "    1. Selectionne l'agent suivant (selon SelectionStrategy)\n",
    "    2. L'agent agit et modifie l'etat\n",
    "    3. Verifie si terminaison (selon TerminationStrategy)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: Dict[str, SimpleAgent],\n",
    "        state: ProofState,\n",
    "        selection_strategy: SelectionStrategy,\n",
    "        termination_strategy: TerminationStrategy\n",
    "    ):\n",
    "        self.agents = agents\n",
    "        self.state = state\n",
    "        self.selection = selection_strategy\n",
    "        self.termination = termination_strategy\n",
    "        self.history: List[Dict[str, Any]] = []\n",
    "\n",
    "    def run(self, initial_message: str, verbose: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Execute la conversation multi-agents.\n",
    "\n",
    "        Args:\n",
    "            initial_message: Message initial (typiquement le theoreme)\n",
    "            verbose: Afficher les logs de progression\n",
    "\n",
    "        Returns:\n",
    "            Resultat de la session (preuve ou message d'echec)\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Session demarree: {initial_message[:80]}...\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "        current_message = initial_message\n",
    "\n",
    "        while not self.termination.should_terminate(self.state):\n",
    "            # 1. Selectionner l'agent\n",
    "            agent_name = self.selection.select_next(self.agents, self.state)\n",
    "            agent = self.agents.get(agent_name)\n",
    "\n",
    "            if not agent:\n",
    "                print(f\"ERREUR: Agent '{agent_name}' non trouve!\")\n",
    "                break\n",
    "\n",
    "            # 2. Executer l'agent\n",
    "            if verbose:\n",
    "                print(f\"\\n[Tour {self.state.iteration_count + 1}] {agent_name}\")\n",
    "\n",
    "            response = agent.invoke(current_message, self.state)\n",
    "\n",
    "            # 3. Enregistrer dans l'historique\n",
    "            self.history.append({\n",
    "                \"iteration\": self.state.iteration_count,\n",
    "                \"agent\": agent_name,\n",
    "                \"message\": current_message[:100],\n",
    "                \"response\": response[:200],\n",
    "                \"state_snapshot\": self.state.get_state_snapshot(summarize=True)\n",
    "            })\n",
    "\n",
    "            if verbose:\n",
    "                print(response)\n",
    "\n",
    "            # 4. Preparer le prochain tour\n",
    "            current_message = response\n",
    "\n",
    "        # Resume final\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            if self.state.proof_complete:\n",
    "                print(\"SUCCES! Preuve trouvee:\")\n",
    "                print(self.state.final_proof)\n",
    "            else:\n",
    "                print(f\"Session terminee apres {self.state.iteration_count} iterations.\")\n",
    "                print(\"Preuve non trouvee.\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "        return self.state.final_proof or \"Preuve non trouvee\"\n",
    "\n",
    "    def get_timeline(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Retourne l'historique pour visualisation.\"\"\"\n",
    "        return self.history\n",
    "\n",
    "\n",
    "# Test des strategies\n",
    "print(\"=== Test des Strategies ===\")\n",
    "\n",
    "test_state = ProofState(\n",
    "    theorem_statement=\"theorem test (n : Nat) : n = n\",\n",
    "    theorem_goal=\"n = n\",\n",
    "    max_iterations=5\n",
    ")\n",
    "\n",
    "selection = DelegatingSelectionStrategy(default_agent=\"CoordinatorAgent\")\n",
    "termination = ProofCompleteTermination(max_iterations=5)\n",
    "\n",
    "print(f\"Selection sans designation: {selection.select_next({}, test_state)}\")\n",
    "test_state.designate_next_agent(\"TacticAgent\")\n",
    "print(f\"Selection avec designation: {selection.select_next({}, test_state)}\")\n",
    "\n",
    "print(f\"Terminaison (iteration 0): {termination.should_terminate(test_state)}\")\n",
    "test_state.iteration_count = 10\n",
    "print(f\"Terminaison (iteration 10): {termination.should_terminate(test_state)}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode d'execution: Simulation\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "DEMARRAGE DE LA CONVERSATION MULTI-AGENTS\n",
      "============================================================\n",
      "Objectif: Prouver: theorem add_zero (n : Nat) : n + 0 = n\n",
      "\n",
      "--- Tour 1: OrchestratorAgent ---\n",
      "(OrchestratorAgent) Je delegue a SearchAgent.\n",
      "Theoreme: theorem add_zero (n : Nat) : n + 0 = n\n",
      "Taches: 0\n",
      "Lemmes trouves: 0\n",
      "Tactiques tentees: 0\n",
      "Iterations: 1\n",
      "\n",
      "\n",
      "--- Tour 2: SearchAgent ---\n",
      "(SearchAgent) Lemmes trouves: ['Nat.add_zero', 'Nat.zero_add', 'Nat.add_comm']\n",
      "\n",
      "--- Tour 3: TacticAgent ---\n",
      "(TacticAgent) Tactiques candidates: ['exact Nat.add_zero', 'rw [Nat.add_zero]', 'exact Nat.zero_add', 'rw [Nat.zero_add]', 'exact Nat.add_comm']\n",
      "\n",
      "--- Tour 4: VerifierAgent ---\n",
      "(VerifierAgent) SUCCES: Preuve verifiee!\n",
      "\n",
      "============================================================\n",
      "SUCCES apres 4 iterations!\n",
      "Preuve: exact Nat.add_zero\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 8.8 - Demonstration Complete\n",
    "# =============================================================================\n",
    "\n",
    "def prove_with_multi_agents(\n",
    "    theorem: str,\n",
    "    goal: str = \"\",\n",
    "    max_iterations: int = 20,\n",
    "    verbose: bool = True,\n",
    "    use_simulation: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Prouve un theoreme en utilisant le systeme multi-agents.\n",
    "\n",
    "    Args:\n",
    "        theorem: L'enonce du theoreme complet\n",
    "        goal: Le but a prouver (extrait du theoreme si non fourni)\n",
    "        max_iterations: Nombre maximum d'iterations\n",
    "        verbose: Afficher les logs\n",
    "        use_simulation: Utiliser le mode simulation (sans appels LLM)\n",
    "\n",
    "    Returns:\n",
    "        Dict avec resultats et metriques\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. Creer l'etat\n",
    "    if not goal:\n",
    "        # Extraire le but du theoreme\n",
    "        if \":\" in theorem:\n",
    "            goal = theorem.split(\":\")[-1].strip()\n",
    "\n",
    "    state = ProofState(\n",
    "        theorem_statement=theorem,\n",
    "        theorem_goal=goal,\n",
    "        max_iterations=max_iterations\n",
    "    )\n",
    "\n",
    "    # 2. Creer le runner Lean\n",
    "    runner = LeanRunner(backend=\"subprocess\", timeout=30)\n",
    "\n",
    "    # 3. Creer les plugins\n",
    "    plugins = {\n",
    "        \"state\": ProofStateManagerPlugin(state),\n",
    "        \"search\": LeanSearchPlugin(runner),\n",
    "        \"tactic\": LeanTacticPlugin(),\n",
    "        \"verification\": LeanVerificationPlugin(runner)\n",
    "    }\n",
    "\n",
    "    # 4. Creer les agents\n",
    "    agents = {\n",
    "        \"SearchAgent\": SimpleAgent(\"SearchAgent\", SEARCH_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "        \"TacticAgent\": SimpleAgent(\"TacticAgent\", TACTIC_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "        \"VerifierAgent\": SimpleAgent(\"VerifierAgent\", VERIFIER_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "        \"CriticAgent\": SimpleAgent(\"CriticAgent\", CRITIC_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "        \"CoordinatorAgent\": SimpleAgent(\"CoordinatorAgent\", COORDINATOR_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "    }\n",
    "\n",
    "    # 5. Configurer les strategies\n",
    "    selection = DelegatingSelectionStrategy(default_agent=\"SearchAgent\")  # Commence par la recherche\n",
    "    termination = ProofCompleteTermination(max_iterations=max_iterations)\n",
    "\n",
    "    # 6. Creer le groupe de chat\n",
    "    chat = AgentGroupChat(\n",
    "        agents=agents,\n",
    "        state=state,\n",
    "        selection_strategy=selection,\n",
    "        termination_strategy=termination\n",
    "    )\n",
    "\n",
    "    # 7. Executer\n",
    "    result = chat.run(f\"Prouver: {theorem}\", verbose=verbose)\n",
    "\n",
    "    # 8. Collecter les metriques\n",
    "    elapsed = time.time() - start_time\n",
    "    metrics = {\n",
    "        \"success\": state.proof_complete,\n",
    "        \"theorem\": theorem,\n",
    "        \"final_proof\": state.final_proof,\n",
    "        \"iterations\": state.iteration_count,\n",
    "        \"lemmas_discovered\": len(state.discovered_lemmas),\n",
    "        \"tactics_tried\": len(state.tactics_history),\n",
    "        \"verifications\": len(state.verification_results),\n",
    "        \"total_time_s\": round(elapsed, 2),\n",
    "        \"lean_time_ms\": round(state.total_lean_time_ms, 2),\n",
    "        \"timeline\": chat.get_timeline()\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Exemples de Theoremes par Niveau\n",
    "# =============================================================================\n",
    "\n",
    "LEVEL_1_THEOREMS = [\n",
    "    (\"theorem test_rfl (n : Nat) : n = n\", \"n = n\"),\n",
    "    (\"theorem test_trivial : True\", \"True\"),\n",
    "]\n",
    "\n",
    "LEVEL_2_THEOREMS = [\n",
    "    (\"theorem add_zero (n : Nat) : n + 0 = n\", \"n + 0 = n\"),\n",
    "    (\"theorem add_comm (n m : Nat) : n + m = m + n\", \"n + m = m + n\"),\n",
    "]\n",
    "\n",
    "LEVEL_3_THEOREMS = [\n",
    "    (\"theorem add_assoc (a b c : Nat) : (a + b) + c = a + (b + c)\", \"(a + b) + c = a + (b + c)\"),\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# Demonstration\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DEMONSTRATION DU SYSTEME MULTI-AGENTS POUR THEOREM PROVING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Detecter le mode\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_available = api_key and len(api_key) > 10 and not api_key.startswith(\"sk-...\")\n",
    "mode = \"LLM\" if api_available else \"Simulation\"\n",
    "print(f\"\\nMode: {mode}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Test sur un theoreme simple (Niveau 1)\n",
    "print(\"\\n### Niveau 1: Theoreme trivial ###\")\n",
    "theorem, goal = LEVEL_1_THEOREMS[0]\n",
    "result = prove_with_multi_agents(\n",
    "    theorem=theorem,\n",
    "    goal=goal,\n",
    "    max_iterations=10,\n",
    "    verbose=True,\n",
    "    use_simulation=not api_available\n",
    ")\n",
    "\n",
    "print(f\"\\nResultat: {'SUCCES' if result['success'] else 'ECHEC'}\")\n",
    "print(f\"Iterations: {result['iterations']}\")\n",
    "print(f\"Temps total: {result['total_time_s']}s\")\n",
    "\n",
    "# Test sur un theoreme moyen (Niveau 2)\n",
    "print(\"\\n\\n### Niveau 2: Addition ###\")\n",
    "theorem, goal = LEVEL_2_THEOREMS[0]\n",
    "result = prove_with_multi_agents(\n",
    "    theorem=theorem,\n",
    "    goal=goal,\n",
    "    max_iterations=15,\n",
    "    verbose=True,\n",
    "    use_simulation=not api_available\n",
    ")\n",
    "\n",
    "print(f\"\\nResultat: {'SUCCES' if result['success'] else 'ECHEC'}\")\n",
    "print(f\"Iterations: {result['iterations']}\")\n",
    "print(f\"Lemmes decouverts: {result['lemmas_discovered']}\")\n",
    "print(f\"Tactiques testees: {result['tactics_tried']}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Techniques de Harmonic Aristotle\n",
    "\n",
    "### 6.1 Decomposition de problemes\n",
    "\n",
    "Aristotle decompose les problemes complexes en sous-problemes plus simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition de 'P <-> Q':\n",
      "  - Direction 1: P  ->  Q\n",
      "  - Direction 2:  Q -> P \n"
     ]
    }
   ],
   "source": [
    "class AristotleDecomposer:\n",
    "    \"\"\"\n",
    "    Decomposition de problemes a la Harmonic Aristotle.\n",
    "    \"\"\"\n",
    "    \n",
    "    def decompose(self, theorem: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Decompose un theoreme en sous-lemmes.\n",
    "        \n",
    "        Strategy:\n",
    "        1. Identifier la structure (conjonction, equivalence, etc.)\n",
    "        2. Separer en composantes\n",
    "        3. Identifier les dependances\n",
    "        \"\"\"\n",
    "        subproblems = []\n",
    "        \n",
    "        # Decomposition basique par structure\n",
    "        if \"<->\" in theorem or \"iff\" in theorem.lower():\n",
    "            # Equivalence = deux implications\n",
    "            parts = theorem.split(\"<->\")\n",
    "            subproblems.append(f\"Direction 1: {parts[0]} -> {parts[1]}\")\n",
    "            subproblems.append(f\"Direction 2: {parts[1]} -> {parts[0]}\")\n",
    "        \n",
    "        elif \"/\\\\\" in theorem or \"and\" in theorem.lower():\n",
    "            # Conjonction = prouver chaque partie\n",
    "            parts = theorem.split(\"/\\\\\")\n",
    "            for i, part in enumerate(parts):\n",
    "                subproblems.append(f\"Partie {i+1}: {part.strip()}\")\n",
    "        \n",
    "        elif \"forall\" in theorem.lower():\n",
    "            # Universel = fixer variable, prouver pour arbitraire\n",
    "            subproblems.append(f\"Generalisation: introduire variable, prouver corps\")\n",
    "        \n",
    "        elif \"exists\" in theorem.lower():\n",
    "            # Existentiel = trouver temoin + preuve\n",
    "            subproblems.append(f\"Temoin: trouver valeur concrete\")\n",
    "            subproblems.append(f\"Verification: prouver pour ce temoin\")\n",
    "        \n",
    "        else:\n",
    "            # Pas de decomposition evidente\n",
    "            subproblems.append(theorem)\n",
    "        \n",
    "        return subproblems\n",
    "    \n",
    "    def solve_hierarchical(self, theorem: str, solver) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Resolution hierarchique par decomposition.\n",
    "        \"\"\"\n",
    "        subproblems = self.decompose(theorem)\n",
    "        \n",
    "        if len(subproblems) == 1 and subproblems[0] == theorem:\n",
    "            # Cas de base: resoudre directement\n",
    "            return solver(theorem)\n",
    "        \n",
    "        # Resoudre chaque sous-probleme\n",
    "        solutions = []\n",
    "        for sub in subproblems:\n",
    "            success, proof = self.solve_hierarchical(sub, solver)\n",
    "            if not success:\n",
    "                return False, None\n",
    "            solutions.append(proof)\n",
    "        \n",
    "        # Combiner les solutions\n",
    "        combined = self._combine_proofs(solutions)\n",
    "        return True, combined\n",
    "    \n",
    "    def _combine_proofs(self, proofs: List[str]) -> str:\n",
    "        \"\"\"Combine des preuves de sous-problemes.\"\"\"\n",
    "        return \"\\n\".join([\n",
    "            f\"-- Partie {i+1}\\n{proof}\" \n",
    "            for i, proof in enumerate(proofs)\n",
    "        ])\n",
    "\n",
    "# Test\n",
    "decomposer = AristotleDecomposer()\n",
    "subproblems = decomposer.decompose(\"P <-> Q\")\n",
    "print(\"Decomposition de 'P <-> Q':\")\n",
    "for sp in subproblems:\n",
    "    print(f\"  - {sp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Benchmarking sur Problemes d'Erdos\n",
    "\n",
    "Les problemes d'Erdos sont devenus le benchmark de reference pour evaluer les systemes de theorem proving automatique. Plusieurs ont ete resolus par IA en 2025-2026."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Addition zero (difficulte: 1)\n",
      "\n",
      "============================================================\n",
      "Debut de la preuve: theorem add_zero (n : Nat) : n + 0 = n\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Lemmes trouves: []\n",
      "Tactiques generees: ['rfl']\n",
      "\n",
      "Preuve trouvee!\n",
      "\n",
      "Test: Commutativite addition (difficulte: 2)\n",
      "\n",
      "============================================================\n",
      "Debut de la preuve: theorem add_comm (a b : Nat) : a + b = b + a\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Lemmes trouves: []\n",
      "Tactiques generees: ['rfl']\n",
      "\n",
      "Preuve trouvee!\n",
      "\n",
      "============================================================\n",
      "RESULTATS DU BENCHMARK\n",
      "============================================================\n",
      "Resolus: 2/2 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Benchmark sur des problemes type Erdos (simplifies)\n",
    "\n",
    "BENCHMARK_PROBLEMS = [\n",
    "    {\n",
    "        \"id\": \"simple_1\",\n",
    "        \"name\": \"Addition zero\",\n",
    "        \"statement\": \"theorem add_zero (n : Nat) : n + 0 = n\",\n",
    "        \"difficulty\": 1,\n",
    "        \"expected_tactics\": [\"exact Nat.add_zero n\", \"rfl\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"simple_2\", \n",
    "        \"name\": \"Commutativite addition\",\n",
    "        \"statement\": \"theorem add_comm (a b : Nat) : a + b = b + a\",\n",
    "        \"difficulty\": 2,\n",
    "        \"expected_tactics\": [\"exact Nat.add_comm a b\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"medium_1\",\n",
    "        \"name\": \"Associativite addition\",\n",
    "        \"statement\": \"theorem add_assoc (a b c : Nat) : (a + b) + c = a + (b + c)\",\n",
    "        \"difficulty\": 3,\n",
    "        \"expected_tactics\": [\"exact Nat.add_assoc a b c\", \"induction c\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "def run_benchmark(solver, problems=BENCHMARK_PROBLEMS):\n",
    "    \"\"\"Execute le benchmark sur les problemes donnes.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for problem in problems:\n",
    "        print(f\"\\nTest: {problem['name']} (difficulte: {problem['difficulty']})\")\n",
    "        \n",
    "        success, proof = solver.prove(problem['statement'])\n",
    "        \n",
    "        results.append({\n",
    "            \"id\": problem[\"id\"],\n",
    "            \"success\": success,\n",
    "            \"proof\": proof\n",
    "        })\n",
    "    \n",
    "    # Statistiques\n",
    "    total = len(results)\n",
    "    solved = sum(1 for r in results if r[\"success\"])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULTATS DU BENCHMARK\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Resolus: {solved}/{total} ({100*solved/total:.1f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Executer le benchmark (limite a 3 iterations pour la demo)\n",
    "orchestrator.max_iterations = 3\n",
    "results = run_benchmark(orchestrator, BENCHMARK_PROBLEMS[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercices\n",
    "\n",
    "### Exercice 1 : Ameliorer l'agent de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de ImprovedSearchAgent:\n",
      "----------------------------------------\n",
      "  Scoring 0 lemmes...\n",
      "\n",
      "Lemmes trouves pour 'n + 0 = n':\n",
      "  Scoring 0 lemmes...\n",
      "\n",
      "Lemmes trouves pour 'a + b = b + a':\n"
     ]
    }
   ],
   "source": "# Exercice 1 - SOLUTION: Agent de recherche ameliore avec scoring LLM\n\nimport os\nimport sys\nfrom pathlib import Path\n\n# Ajouter le repertoire courant au path\nsys.path.insert(0, str(Path.cwd()))\n\n# Utiliser load_env_file de lean_runner (evite les problemes d'introspection)\nfrom lean_runner import load_env_file\nenv_path = Path.cwd() / \".env\"\nload_env_file(env_path)\n\nclass ImprovedSearchAgent(TheoremSearchAgent):\n    \"\"\"\n    Version amelioree de l'agent de recherche avec scoring par LLM.\n    \n    Ameliorations:\n    1. Scoring semantique par LLM (pertinence reelle, pas juste mots-cles)\n    2. Cache des scores pour eviter les appels API redondants\n    3. Fallback sur heuristique si API non disponible\n    \"\"\"\n    \n    def __init__(self, llm_client=None):\n        super().__init__(llm_client)\n        self.score_cache = {}  # (lemma_name, goal) -> score\n        self.api_available = self._check_api()\n    \n    def _check_api(self) -> bool:\n        \"\"\"Verifie si l'API OpenAI est disponible.\"\"\"\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        return api_key is not None and not api_key.startswith(\"sk-...\")\n    \n    def _score_with_llm(self, lemma: Lemma, goal: str) -> float:\n        \"\"\"\n        Score la pertinence d'un lemme par rapport au but en utilisant un LLM.\n        \n        Returns:\n            Score de pertinence entre 0.0 et 1.0\n        \"\"\"\n        # Verifier le cache\n        cache_key = (lemma.name, goal)\n        if cache_key in self.score_cache:\n            return self.score_cache[cache_key]\n        \n        # Si API non disponible, utiliser heuristique\n        if not self.api_available:\n            score = self._heuristic_score(lemma, goal)\n            self.score_cache[cache_key] = score\n            return score\n        \n        # Appel API reel\n        try:\n            from openai import OpenAI\n            client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n            \n            prompt = f\"\"\"Evalue la pertinence d'un lemme mathematique pour prouver un but en Lean 4.\n\nLemme: {lemma.name}\nEnonce du lemme: {lemma.statement}\n\nBut a prouver: {goal}\n\nSur une echelle de 0 a 1, quelle est la pertinence de ce lemme?\n- 1.0 = Le lemme resout directement le but\n- 0.7-0.9 = Tres pertinent, peut etre utilise avec une reecriture\n- 0.4-0.6 = Moderement pertinent, structure similaire\n- 0.1-0.3 = Peu pertinent, meme domaine mais different\n- 0.0 = Aucun rapport\n\nReponds UNIQUEMENT avec un nombre decimal entre 0 et 1.\"\"\"\n\n            # Les modeles modernes (gpt-4o, gpt-4.5, gpt-5, o1, o3) utilisent max_completion_tokens\n            model = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-4o\")\n            use_max_completion_tokens = any(model.startswith(p) for p in ('gpt-4o', 'gpt-4.5', 'gpt-5', 'o1', 'o3'))\n            token_param = {\"max_completion_tokens\": 10} if use_max_completion_tokens else {\"max_tokens\": 10}\n            \n            response = client.chat.completions.create(\n                model=model,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.1,\n                **token_param\n            )\n            \n            # Parser la reponse\n            score_text = response.choices[0].message.content.strip()\n            score = float(score_text)\n            score = max(0.0, min(1.0, score))  # Clamp entre 0 et 1\n            \n        except Exception as e:\n            print(f\"  [Scoring LLM echoue: {e}, utilisation heuristique]\")\n            score = self._heuristic_score(lemma, goal)\n        \n        # Mettre en cache\n        self.score_cache[cache_key] = score\n        return score\n    \n    def _heuristic_score(self, lemma: Lemma, goal: str) -> float:\n        \"\"\"\n        Score heuristique base sur la correspondance de termes.\n        Utilise comme fallback quand l'API n'est pas disponible.\n        \"\"\"\n        # Normaliser les chaines\n        lemma_terms = set(lemma.statement.lower().replace(\":\", \" \").split())\n        goal_terms = set(goal.lower().replace(\":\", \" \").split())\n        \n        # Score = Jaccard similarity\n        intersection = len(lemma_terms & goal_terms)\n        union = len(lemma_terms | goal_terms)\n        \n        if union == 0:\n            return 0.0\n        \n        jaccard = intersection / union\n        \n        # Bonus si le nom du lemme correspond au type d'operation\n        bonus = 0.0\n        if \"add\" in lemma.name.lower() and \"+\" in goal:\n            bonus = 0.2\n        elif \"mul\" in lemma.name.lower() and \"*\" in goal:\n            bonus = 0.2\n        elif \"comm\" in lemma.name.lower() and (\"comm\" in goal.lower() or \n                                               (\"+b\" in goal.replace(\" \", \"\") and \"+a\" in goal.replace(\" \", \"\"))):\n            bonus = 0.15\n        \n        return min(1.0, jaccard + bonus)\n    \n    def _score_lemmas(self, lemmas: List[Lemma], goal: str) -> List[Lemma]:\n        \"\"\"Score les lemmes avec la methode amelioree.\"\"\"\n        print(f\"  Scoring {len(lemmas)} lemmes...\")\n        \n        for lemma in lemmas:\n            lemma.relevance_score = self._score_with_llm(lemma, goal)\n        \n        # Trier par pertinence decroissante\n        return sorted(lemmas, key=lambda l: l.relevance_score, reverse=True)\n\n# Test de l'agent ameliore\nprint(\"Test de ImprovedSearchAgent:\")\nprint(\"-\" * 40)\n\nimproved_agent = ImprovedSearchAgent()\ngoal = \"n + 0 = n\"\nresults = improved_agent.search(goal)\n\nprint(f\"\\nLemmes trouves pour '{goal}':\")\nfor lemma in results:\n    print(f\"  [{lemma.relevance_score:.2f}] {lemma.name}: {lemma.statement}\")\n\n# Test sur un autre but\ngoal2 = \"a + b = b + a\"\nresults2 = improved_agent.search(goal2)\nprint(f\"\\nLemmes trouves pour '{goal2}':\")\nfor lemma in results2:\n    print(f\"  [{lemma.relevance_score:.2f}] {lemma.name}: {lemma.statement}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2 : Ajouter de la memoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de ProofMemory:\n",
      "--------------------------------------------------\n",
      "Preuves stockees: 2\n",
      "\n",
      "Recall pour 'theorem my_add_zero (m : Nat) : m + 0 = m':\n",
      "  Score de similarite: 1.00\n",
      "  Preuve adaptee: exact Nat.add_zero m\n",
      "\n",
      "Statistiques memoire:\n",
      "  Patterns: 2\n",
      "  Utilisations totales: 2\n"
     ]
    }
   ],
   "source": [
    "# Exercice 2 - SOLUTION: Systeme de memoire avec pattern matching\n",
    "\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "@dataclass\n",
    "class StoredProof:\n",
    "    \"\"\"Une preuve stockee avec son contexte.\"\"\"\n",
    "    theorem_pattern: str\n",
    "    original_theorem: str\n",
    "    proof: str\n",
    "    success_count: int = 1\n",
    "    variables: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "class ProofMemory:\n",
    "    \"\"\"\n",
    "    Systeme de memoire pour reutiliser les preuves reussies.\n",
    "    \n",
    "    Fonctionnalites:\n",
    "    1. Pattern matching pour generaliser les theoremes\n",
    "    2. Recherche de preuves similaires par similarite\n",
    "    3. Adaptation des preuves au nouveau contexte\n",
    "    4. Persistence (optionnelle) vers fichier JSON\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity_threshold: float = 0.7):\n",
    "        self.proofs: Dict[str, StoredProof] = {}  # pattern -> StoredProof\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "    \n",
    "    def store(self, theorem: str, proof: str) -> str:\n",
    "        \"\"\"\n",
    "        Stocke une preuve reussie.\n",
    "        \n",
    "        Returns:\n",
    "            L'ID du pattern utilise pour le stockage\n",
    "        \"\"\"\n",
    "        # Extraire le pattern et les variables\n",
    "        pattern, variables = self._extract_pattern(theorem)\n",
    "        \n",
    "        if pattern in self.proofs:\n",
    "            # Incrementer le compteur de succes\n",
    "            self.proofs[pattern].success_count += 1\n",
    "        else:\n",
    "            # Nouvelle preuve\n",
    "            self.proofs[pattern] = StoredProof(\n",
    "                theorem_pattern=pattern,\n",
    "                original_theorem=theorem,\n",
    "                proof=proof,\n",
    "                variables=variables\n",
    "            )\n",
    "        \n",
    "        return pattern\n",
    "    \n",
    "    def recall(self, theorem: str) -> Optional[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Retrouve une preuve similaire.\n",
    "        \n",
    "        Returns:\n",
    "            (preuve_adaptee, score_similarite) ou None si rien trouve\n",
    "        \"\"\"\n",
    "        # Extraire le pattern du theoreme\n",
    "        query_pattern, query_vars = self._extract_pattern(theorem)\n",
    "        \n",
    "        # Recherche exacte d'abord\n",
    "        if query_pattern in self.proofs:\n",
    "            stored = self.proofs[query_pattern]\n",
    "            adapted_proof = self._adapt_proof(stored.proof, stored.variables, query_vars)\n",
    "            return adapted_proof, 1.0\n",
    "        \n",
    "        # Recherche par similarite\n",
    "        best_match = None\n",
    "        best_score = 0.0\n",
    "        \n",
    "        for pattern, stored in self.proofs.items():\n",
    "            score = self._similarity(query_pattern, pattern)\n",
    "            if score > best_score and score >= self.similarity_threshold:\n",
    "                best_score = score\n",
    "                best_match = stored\n",
    "        \n",
    "        if best_match:\n",
    "            adapted_proof = self._adapt_proof(best_match.proof, best_match.variables, query_vars)\n",
    "            return adapted_proof, best_score\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_pattern(self, theorem: str) -> Tuple[str, Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Extrait un pattern generalise du theoreme.\n",
    "        \n",
    "        Transformations:\n",
    "        - Variables specifiques -> placeholders (?x, ?y, ?z)\n",
    "        - Types conserves\n",
    "        - Structure preservee\n",
    "        \n",
    "        Exemple:\n",
    "            \"theorem foo (n : Nat) : n + 0 = n\" \n",
    "            -> \"theorem ?name (?x : Nat) : ?x + 0 = ?x\"\n",
    "        \"\"\"\n",
    "        variables = {}\n",
    "        pattern = theorem\n",
    "        \n",
    "        # Extraire le nom du theoreme\n",
    "        name_match = re.search(r'theorem\\s+(\\w+)', theorem)\n",
    "        if name_match:\n",
    "            variables['theorem_name'] = name_match.group(1)\n",
    "            pattern = re.sub(r'theorem\\s+\\w+', 'theorem ?name', pattern)\n",
    "        \n",
    "        # Extraire les variables de type Nat/Int\n",
    "        var_matches = re.findall(r'\\((\\w+)\\s*:\\s*(\\w+)\\)', theorem)\n",
    "        placeholder_index = 0\n",
    "        placeholders = ['?x', '?y', '?z', '?a', '?b', '?c']\n",
    "        \n",
    "        for var_name, var_type in var_matches:\n",
    "            if placeholder_index < len(placeholders):\n",
    "                placeholder = placeholders[placeholder_index]\n",
    "                variables[placeholder] = var_name\n",
    "                # Remplacer la variable dans tout le pattern\n",
    "                pattern = re.sub(rf'\\b{var_name}\\b', placeholder, pattern)\n",
    "                placeholder_index += 1\n",
    "        \n",
    "        return pattern, variables\n",
    "    \n",
    "    def _similarity(self, pattern1: str, pattern2: str) -> float:\n",
    "        \"\"\"\n",
    "        Calcule la similarite entre deux patterns.\n",
    "        Utilise SequenceMatcher pour une comparaison robuste.\n",
    "        \"\"\"\n",
    "        # Normaliser\n",
    "        p1 = pattern1.lower().replace(\" \", \"\")\n",
    "        p2 = pattern2.lower().replace(\" \", \"\")\n",
    "        \n",
    "        return SequenceMatcher(None, p1, p2).ratio()\n",
    "    \n",
    "    def _adapt_proof(self, proof: str, original_vars: Dict[str, str], \n",
    "                     new_vars: Dict[str, str]) -> str:\n",
    "        \"\"\"\n",
    "        Adapte une preuve au nouveau contexte en substituant les variables.\n",
    "        \"\"\"\n",
    "        adapted = proof\n",
    "        \n",
    "        for placeholder, orig_name in original_vars.items():\n",
    "            if placeholder in new_vars:\n",
    "                new_name = new_vars[placeholder]\n",
    "                # Remplacer le nom original par le nouveau\n",
    "                adapted = re.sub(rf'\\b{orig_name}\\b', new_name, adapted)\n",
    "        \n",
    "        return adapted\n",
    "    \n",
    "    def get_statistics(self) -> Dict:\n",
    "        \"\"\"Retourne des statistiques sur la memoire.\"\"\"\n",
    "        return {\n",
    "            \"total_patterns\": len(self.proofs),\n",
    "            \"total_uses\": sum(p.success_count for p in self.proofs.values()),\n",
    "            \"most_used\": max(self.proofs.values(), \n",
    "                           key=lambda p: p.success_count).theorem_pattern \n",
    "                          if self.proofs else None\n",
    "        }\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"Sauvegarde la memoire dans un fichier JSON.\"\"\"\n",
    "        data = {\n",
    "            pattern: {\n",
    "                \"theorem_pattern\": sp.theorem_pattern,\n",
    "                \"original_theorem\": sp.original_theorem,\n",
    "                \"proof\": sp.proof,\n",
    "                \"success_count\": sp.success_count,\n",
    "                \"variables\": sp.variables\n",
    "            }\n",
    "            for pattern, sp in self.proofs.items()\n",
    "        }\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "    \n",
    "    def load(self, filepath: str):\n",
    "        \"\"\"Charge la memoire depuis un fichier JSON.\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        self.proofs = {\n",
    "            pattern: StoredProof(**stored)\n",
    "            for pattern, stored in data.items()\n",
    "        }\n",
    "\n",
    "# Test de ProofMemory\n",
    "print(\"Test de ProofMemory:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "memory = ProofMemory()\n",
    "\n",
    "# Stocker quelques preuves\n",
    "memory.store(\n",
    "    \"theorem add_zero_n (n : Nat) : n + 0 = n\",\n",
    "    \"exact Nat.add_zero n\"\n",
    ")\n",
    "memory.store(\n",
    "    \"theorem add_comm_ab (a b : Nat) : a + b = b + a\",\n",
    "    \"exact Nat.add_comm a b\"\n",
    ")\n",
    "\n",
    "print(f\"Preuves stockees: {len(memory.proofs)}\")\n",
    "\n",
    "# Tester le recall sur un theoreme similaire\n",
    "test_theorem = \"theorem my_add_zero (m : Nat) : m + 0 = m\"\n",
    "result = memory.recall(test_theorem)\n",
    "\n",
    "if result:\n",
    "    proof, score = result\n",
    "    print(f\"\\nRecall pour '{test_theorem}':\")\n",
    "    print(f\"  Score de similarite: {score:.2f}\")\n",
    "    print(f\"  Preuve adaptee: {proof}\")\n",
    "else:\n",
    "    print(f\"\\nPas de preuve trouvee pour '{test_theorem}'\")\n",
    "\n",
    "# Statistiques\n",
    "stats = memory.get_statistics()\n",
    "print(f\"\\nStatistiques memoire:\")\n",
    "print(f\"  Patterns: {stats['total_patterns']}\")\n",
    "print(f\"  Utilisations totales: {stats['total_uses']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume\n",
    "\n",
    "### Architecture multi-agents pour theorem proving\n",
    "\n",
    "| Agent | Role | Entrees | Sorties |\n",
    "|-------|------|---------|--------|\n",
    "| **OrchestratorAgent** | Coordonner workflow | Theoreme | Delegation + status |\n",
    "| **SearchAgent** | Trouver lemmes Mathlib | But | Liste de lemmes |\n",
    "| **TacticAgent** | Generer tactiques | But + lemmes | Sequence de tactiques |\n",
    "| **VerifierAgent** | Valider avec Lean | Code Lean | Succes/Erreur + feedback |\n",
    "\n",
    "### Patterns Semantic Kernel implementes\n",
    "\n",
    "| Pattern | Description | Classe |\n",
    "|---------|-------------|--------|\n",
    "| **StateManager** | Etat partage entre agents | `ProofState` |\n",
    "| **Plugin** | Fonctions @kernel_function | `LeanProverPlugin` |\n",
    "| **SelectionStrategy** | Choix agent suivant | `DelegatingSelectionStrategy` |\n",
    "| **TerminationStrategy** | Critere d'arret | `ProofCompleteTermination` |\n",
    "| **AgentGroupChat** | Conversation multi-agents | `AgentGroupChat` |\n",
    "\n",
    "### Techniques cles\n",
    "\n",
    "1. **Etat partage** : Tous les agents lisent/ecrivent dans `ProofState`\n",
    "2. **Delegation explicite** : Chaque agent designe le suivant via `delegate_to_agent`\n",
    "3. **Boucle de feedback** : Echecs envoyes a `TacticAgent` pour correction\n",
    "4. **Memoire de session** : Historique des tentatives pour eviter repetitions\n",
    "5. **Decomposition (Aristotle)** : Diviser problemes complexes en sous-problemes\n",
    "\n",
    "### Ressources et inspiration\n",
    "\n",
    "| Source | Contribution |\n",
    "|--------|--------------|\n",
    "| **Argument_Analysis notebooks** | Patterns SK (StateManager, orchestration) |\n",
    "| **Harmonic Aristotle** | Decomposition hierarchique, IMO Gold 2025 |\n",
    "| **APOLLO** | Generation massive, filtrage par Lean |\n",
    "| **AlphaProof** | RL + MCTS, Nature 2025 |\n",
    "| **LeanDojo** | Extraction donnees, LeanCopilot |\n",
    "\n",
    "### Impact futur\n",
    "\n",
    "Les systemes agentiques pour theorem proving representent une nouvelle frontiere:\n",
    "- **15+ problemes Erdos** resolus par IA depuis Noel 2025\n",
    "- **Acceleration x10-100** de la formalisation mathematique\n",
    "- **Decouverte** de nouvelles mathematiques par collaboration humain-IA\n",
    "- **Verification formelle** comme standard de confiance absolue\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook base sur les techniques de Harmonic Aristotle (IMO Gold 2025), APOLLO (arXiv 2505), AlphaProof (Nature 2025), et les patterns Semantic Kernel inspires de Argument_Analysis*\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation** : [← Lean-7-LLM-Integration](Lean-7-LLM-Integration.ipynb) | [Index](Lean-1-Setup.ipynb) | [Lean-9-LeanDojo →](Lean-9-LeanDojo.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (WSL)",
   "language": "python",
   "name": "python3-wsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}