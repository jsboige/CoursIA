{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lean 8 - Agents Autonomes pour Demonstration de Theoremes\n",
    "\n",
    "**Navigation** : [← Lean-7-LLM-Integration](Lean-7-LLM-Integration.ipynb) | [Index](Lean-1-Setup.ipynb) | [Lean-9-LeanDojo →](Lean-9-LeanDojo.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Ce notebook final de la serie explore la creation de **systemes multi-agents** capables de prouver des theoremes mathematiques de maniere **autonome**. Nous combinons les techniques des notebooks precedents avec les patterns d'orchestration agentique.\n",
    "\n",
    "L'objectif est de construire un systeme qui peut :\n",
    "1. Recevoir un enonce de theoreme\n",
    "2. Rechercher des lemmes pertinents dans Mathlib\n",
    "3. Generer des strategies de preuve\n",
    "4. Verifier formellement avec Lean\n",
    "5. Iterer jusqu'au succes\n",
    "\n",
    "### Objectifs pedagogiques\n",
    "\n",
    "1. Concevoir une architecture multi-agents pour theorem proving\n",
    "2. Implementer des agents specialises (recherche, generation, verification)\n",
    "3. Orchestrer la collaboration entre agents\n",
    "4. Gerer les boucles de feedback et d'amelioration\n",
    "5. Comprendre les techniques de Harmonic Aristotle et APOLLO\n",
    "\n",
    "### Prerequis\n",
    "\n",
    "- Notebooks **Lean-1** a **Lean-7** completes\n",
    "- Notions de base sur les systemes multi-agents\n",
    "- Cle API LLM (optionnel pour execution)\n",
    "\n",
    "### Duree estimee : 55-60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture d'un Systeme Agentique pour Lean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vue d'ensemble\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                     SYSTEME AGENTIQUE LEAN                          │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  ┌─────────────────┐                                               │\n",
    "│  │   ORCHESTRATOR  │  <- Coordonne tous les agents                 │\n",
    "│  │     Agent       │                                               │\n",
    "│  └────────┬────────┘                                               │\n",
    "│           │                                                        │\n",
    "│  ┌────────┼────────┬────────────────┐                              │\n",
    "│  │        │        │                │                              │\n",
    "│  v        v        v                v                              │\n",
    "│ ┌────┐  ┌────┐  ┌────┐         ┌────────┐                          │\n",
    "│ │Search│ │Tactic│ │Proof│        │Memory  │                         │\n",
    "│ │Agent│ │Agent│ │Verify│        │Store   │                         │\n",
    "│ └──┬───┘ └──┬───┘ └──┬───┘        └────────┘                         │\n",
    "│    │        │        │                                             │\n",
    "│    v        v        v                                             │\n",
    "│ ┌──────────────────────────────────────────────┐                   │\n",
    "│ │               LEAN KERNEL                     │                   │\n",
    "│ │  (Verification formelle + Mathlib)           │                   │\n",
    "│ └──────────────────────────────────────────────┘                   │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Agent de Recherche de Theoremes\n",
    "\n",
    "### 1.1 Role\n",
    "\n",
    "L'agent de recherche parcourt Mathlib pour trouver des lemmes pertinents au probleme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmes trouves:\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class Lemma:\n",
    "    \"\"\"Represente un lemme Mathlib.\"\"\"\n",
    "    name: str\n",
    "    statement: str\n",
    "    namespace: str\n",
    "    relevance_score: float = 0.0\n",
    "\n",
    "class TheoremSearchAgent:\n",
    "    \"\"\"Agent de recherche de theoremes dans Mathlib.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client=None):\n",
    "        self.llm = llm_client\n",
    "        self.cache = {}  # Cache des recherches\n",
    "    \n",
    "    def search(self, goal: str, context: str = \"\") -> List[Lemma]:\n",
    "        \"\"\"\n",
    "        Recherche des lemmes pertinents pour un but donne.\n",
    "        \n",
    "        Args:\n",
    "            goal: Le but a prouver\n",
    "            context: Contexte additionnel (hypotheses, etc.)\n",
    "        \n",
    "        Returns:\n",
    "            Liste de lemmes tries par pertinence\n",
    "        \"\"\"\n",
    "        # Verifier le cache\n",
    "        cache_key = f\"{goal}:{context}\"\n",
    "        if cache_key in self.cache:\n",
    "            return self.cache[cache_key]\n",
    "        \n",
    "        # Analyser le but pour extraire les concepts\n",
    "        concepts = self._extract_concepts(goal)\n",
    "        \n",
    "        # Rechercher dans Mathlib\n",
    "        lemmas = self._search_mathlib(concepts)\n",
    "        \n",
    "        # Scorer par pertinence\n",
    "        scored = self._score_lemmas(lemmas, goal)\n",
    "        \n",
    "        # Mettre en cache\n",
    "        self.cache[cache_key] = scored\n",
    "        \n",
    "        return scored\n",
    "    \n",
    "    def _extract_concepts(self, goal: str) -> List[str]:\n",
    "        \"\"\"Extrait les concepts mathematiques du but.\"\"\"\n",
    "        # Simplification : extraction par mots-cles\n",
    "        keywords = [\"add\", \"mul\", \"comm\", \"assoc\", \"zero\", \"one\", \"succ\"]\n",
    "        return [k for k in keywords if k in goal.lower()]\n",
    "    \n",
    "    def _search_mathlib(self, concepts: List[str]) -> List[Lemma]:\n",
    "        \"\"\"Simule la recherche dans Mathlib.\"\"\"\n",
    "        # Base de lemmes simulee\n",
    "        mathlib_lemmas = [\n",
    "            Lemma(\"Nat.add_zero\", \"n + 0 = n\", \"Nat\"),\n",
    "            Lemma(\"Nat.zero_add\", \"0 + n = n\", \"Nat\"),\n",
    "            Lemma(\"Nat.add_comm\", \"n + m = m + n\", \"Nat\"),\n",
    "            Lemma(\"Nat.add_assoc\", \"(n + m) + k = n + (m + k)\", \"Nat\"),\n",
    "            Lemma(\"Nat.mul_comm\", \"n * m = m * n\", \"Nat\"),\n",
    "            Lemma(\"Nat.mul_assoc\", \"(n * m) * k = n * (m * k)\", \"Nat\"),\n",
    "        ]\n",
    "        \n",
    "        # Filtrer par concepts\n",
    "        return [l for l in mathlib_lemmas \n",
    "                if any(c in l.name.lower() for c in concepts)]\n",
    "    \n",
    "    def _score_lemmas(self, lemmas: List[Lemma], goal: str) -> List[Lemma]:\n",
    "        \"\"\"Score les lemmes par pertinence.\"\"\"\n",
    "        for lemma in lemmas:\n",
    "            # Score simple : correspondance de termes\n",
    "            lemma.relevance_score = sum(\n",
    "                1 for word in lemma.statement.split() \n",
    "                if word in goal\n",
    "            ) / max(len(goal.split()), 1)\n",
    "        \n",
    "        return sorted(lemmas, key=lambda l: l.relevance_score, reverse=True)\n",
    "\n",
    "# Test\n",
    "search_agent = TheoremSearchAgent()\n",
    "results = search_agent.search(\"n + 0 = n\")\n",
    "print(\"Lemmes trouves:\")\n",
    "for lemma in results:\n",
    "    print(f\"  {lemma.name}: {lemma.statement} (score: {lemma.relevance_score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Agent de Generation de Tactiques\n",
    "\n",
    "### 2.1 Role\n",
    "\n",
    "L'agent de tactiques genere des sequences de tactiques Lean pour prouver le but."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tactiques suggerees:\n",
      "  [0.90] rfl - Reflexivite - verifie si les deux cotes sont identiques\n",
      "  [0.70] omega - Arithmetique de Presburger automatique\n",
      "  [0.50] simp - Simplification automatique\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from typing import Tuple\n",
    "\n",
    "class TacticType(Enum):\n",
    "    DIRECT = \"direct\"       # exact, rfl\n",
    "    REWRITE = \"rewrite\"     # rw, simp\n",
    "    SPLIT = \"split\"         # constructor, cases\n",
    "    INDUCTION = \"induction\" # induction, recursion\n",
    "    AUTO = \"auto\"           # omega, ring, linarith\n",
    "\n",
    "@dataclass\n",
    "class TacticSuggestion:\n",
    "    \"\"\"Une suggestion de tactique avec son contexte.\"\"\"\n",
    "    tactic: str\n",
    "    tactic_type: TacticType\n",
    "    confidence: float\n",
    "    explanation: str\n",
    "\n",
    "class TacticGeneratorAgent:\n",
    "    \"\"\"Agent de generation de tactiques.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client=None):\n",
    "        self.llm = llm_client\n",
    "        self.history = []  # Historique des tentatives\n",
    "    \n",
    "    def generate(self, goal: str, context: List[str], \n",
    "                 available_lemmas: List[Lemma]) -> List[TacticSuggestion]:\n",
    "        \"\"\"\n",
    "        Genere des tactiques pour un but donne.\n",
    "        \n",
    "        Args:\n",
    "            goal: Le but courant\n",
    "            context: Les hypotheses disponibles\n",
    "            available_lemmas: Lemmes suggeres par l'agent de recherche\n",
    "        \n",
    "        Returns:\n",
    "            Liste de suggestions de tactiques\n",
    "        \"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        # Strategie 1: Tactiques directes\n",
    "        if \"=\" in goal:\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                \"rfl\", TacticType.DIRECT, 0.9,\n",
    "                \"Reflexivite - verifie si les deux cotes sont identiques\"\n",
    "            ))\n",
    "        \n",
    "        # Strategie 2: Utiliser les lemmes disponibles\n",
    "        for lemma in available_lemmas[:3]:\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                f\"exact {lemma.name}\", TacticType.DIRECT, \n",
    "                lemma.relevance_score,\n",
    "                f\"Appliquer {lemma.name}: {lemma.statement}\"\n",
    "            ))\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                f\"rw [{lemma.name}]\", TacticType.REWRITE,\n",
    "                lemma.relevance_score * 0.8,\n",
    "                f\"Reecrire avec {lemma.name}\"\n",
    "            ))\n",
    "        \n",
    "        # Strategie 3: Tactiques automatiques\n",
    "        if any(op in goal for op in [\"+\", \"-\", \"<\", \">\", \"<=\", \">=\"]):\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                \"omega\", TacticType.AUTO, 0.7,\n",
    "                \"Arithmetique de Presburger automatique\"\n",
    "            ))\n",
    "        \n",
    "        if \"*\" in goal or \"^\" in goal:\n",
    "            suggestions.append(TacticSuggestion(\n",
    "                \"ring\", TacticType.AUTO, 0.7,\n",
    "                \"Algebre polynomiale automatique\"\n",
    "            ))\n",
    "        \n",
    "        # Strategie 4: Simp comme fallback\n",
    "        suggestions.append(TacticSuggestion(\n",
    "            \"simp\", TacticType.REWRITE, 0.5,\n",
    "            \"Simplification automatique\"\n",
    "        ))\n",
    "        \n",
    "        # Trier par confiance\n",
    "        return sorted(suggestions, key=lambda s: s.confidence, reverse=True)\n",
    "    \n",
    "    def generate_sequence(self, goal: str, context: List[str],\n",
    "                          available_lemmas: List[Lemma],\n",
    "                          max_depth: int = 5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Genere une sequence complete de tactiques.\n",
    "        \"\"\"\n",
    "        sequence = []\n",
    "        current_goal = goal\n",
    "        \n",
    "        for _ in range(max_depth):\n",
    "            suggestions = self.generate(current_goal, context, available_lemmas)\n",
    "            if not suggestions:\n",
    "                break\n",
    "            \n",
    "            best = suggestions[0]\n",
    "            sequence.append(best.tactic)\n",
    "            \n",
    "            # Simuler la progression (dans la realite, Lean nous dirait le nouveau but)\n",
    "            if best.tactic_type == TacticType.DIRECT:\n",
    "                break  # Preuve complete\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "# Test\n",
    "tactic_agent = TacticGeneratorAgent()\n",
    "lemmas = search_agent.search(\"n + 0 = n\")\n",
    "suggestions = tactic_agent.generate(\"n + 0 = n\", [], lemmas)\n",
    "\n",
    "print(\"Tactiques suggerees:\")\n",
    "for s in suggestions[:5]:\n",
    "    print(f\"  [{s.confidence:.2f}] {s.tactic} - {s.explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agent de Verification\n",
    "\n",
    "### 3.1 Role\n",
    "\n",
    "L'agent de verification execute le code Lean et analyse les resultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification: Succes\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class VerificationResult:\n",
    "    \"\"\"Resultat de la verification Lean.\"\"\"\n",
    "    success: bool\n",
    "    error_message: Optional[str] = None\n",
    "    remaining_goals: List[str] = None\n",
    "    execution_time: float = 0.0\n",
    "\n",
    "class ProofVerifierAgent:\n",
    "    \"\"\"Agent de verification des preuves.\"\"\"\n",
    "    \n",
    "    def __init__(self, lean_path: str = \"lean\"):\n",
    "        self.lean_path = lean_path\n",
    "        self.verified_count = 0\n",
    "        self.failed_count = 0\n",
    "    \n",
    "    def verify(self, theorem: str, proof: str) -> VerificationResult:\n",
    "        \"\"\"\n",
    "        Verifie une preuve avec Lean.\n",
    "        \n",
    "        Args:\n",
    "            theorem: L'enonce du theoreme\n",
    "            proof: La preuve proposee (sequence de tactiques)\n",
    "        \n",
    "        Returns:\n",
    "            Resultat de la verification\n",
    "        \"\"\"\n",
    "        # Construire le code Lean complet\n",
    "        lean_code = self._build_lean_code(theorem, proof)\n",
    "        \n",
    "        # Simuler l'execution Lean\n",
    "        # (Dans un vrai systeme, on utiliserait subprocess ou lean-dojo)\n",
    "        result = self._simulate_lean_execution(lean_code)\n",
    "        \n",
    "        # Mettre a jour les statistiques\n",
    "        if result.success:\n",
    "            self.verified_count += 1\n",
    "        else:\n",
    "            self.failed_count += 1\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _build_lean_code(self, theorem: str, proof: str) -> str:\n",
    "        \"\"\"Construit le code Lean complet.\"\"\"\n",
    "        return f\"\"\"\n",
    "{theorem} := by\n",
    "  {proof}\n",
    "        \"\"\".strip()\n",
    "    \n",
    "    def _simulate_lean_execution(self, code: str) -> VerificationResult:\n",
    "        \"\"\"\n",
    "        Simule l'execution Lean.\n",
    "        Dans un vrai systeme, utiliser lean-dojo ou subprocess.\n",
    "        \"\"\"\n",
    "        # Heuristiques simples pour la simulation\n",
    "        if \"rfl\" in code or \"exact Nat.add_zero\" in code:\n",
    "            return VerificationResult(success=True)\n",
    "        elif \"sorry\" in code:\n",
    "            return VerificationResult(\n",
    "                success=False,\n",
    "                error_message=\"declaration uses 'sorry'\"\n",
    "            )\n",
    "        else:\n",
    "            # Simuler une reussite aleatoire\n",
    "            import random\n",
    "            if random.random() > 0.3:\n",
    "                return VerificationResult(success=True)\n",
    "            else:\n",
    "                return VerificationResult(\n",
    "                    success=False,\n",
    "                    error_message=\"tactic failed\"\n",
    "                )\n",
    "    \n",
    "    def get_stats(self) -> dict:\n",
    "        \"\"\"Retourne les statistiques de verification.\"\"\"\n",
    "        total = self.verified_count + self.failed_count\n",
    "        return {\n",
    "            \"verified\": self.verified_count,\n",
    "            \"failed\": self.failed_count,\n",
    "            \"success_rate\": self.verified_count / max(total, 1)\n",
    "        }\n",
    "\n",
    "# Test\n",
    "verifier = ProofVerifierAgent()\n",
    "result = verifier.verify(\n",
    "    \"theorem test (n : Nat) : n + 0 = n\",\n",
    "    \"exact Nat.add_zero n\"\n",
    ")\n",
    "print(f\"Verification: {'Succes' if result.success else 'Echec'}\")\n",
    "if result.error_message:\n",
    "    print(f\"Erreur: {result.error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent Orchestrateur\n",
    "\n",
    "### 4.1 Role\n",
    "\n",
    "L'orchestrateur coordonne tous les agents pour resoudre un probleme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Debut de la preuve: theorem add_zero (n : Nat) : n + 0 = n\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Lemmes trouves: []\n",
      "Tactiques generees: ['rfl']\n",
      "\n",
      "Preuve trouvee!\n",
      "\n",
      "Preuve finale:\n",
      "rfl\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ProofAttempt:\n",
    "    \"\"\"Enregistre une tentative de preuve.\"\"\"\n",
    "    theorem: str\n",
    "    tactics: List[str]\n",
    "    result: VerificationResult\n",
    "    iteration: int\n",
    "\n",
    "class OrchestratorAgent:\n",
    "    \"\"\"\n",
    "    Agent orchestrateur qui coordonne le systeme multi-agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.search_agent = TheoremSearchAgent()\n",
    "        self.tactic_agent = TacticGeneratorAgent()\n",
    "        self.verifier = ProofVerifierAgent()\n",
    "        self.history: List[ProofAttempt] = []\n",
    "        self.max_iterations = 10\n",
    "    \n",
    "    def prove(self, theorem: str) -> Tuple[bool, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Tente de prouver un theoreme.\n",
    "        \n",
    "        Args:\n",
    "            theorem: L'enonce du theoreme\n",
    "        \n",
    "        Returns:\n",
    "            (succes, preuve) ou (echec, None)\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Debut de la preuve: {theorem}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            print(f\"--- Iteration {iteration + 1} ---\")\n",
    "            \n",
    "            # Etape 1: Rechercher des lemmes pertinents\n",
    "            goal = self._extract_goal(theorem)\n",
    "            lemmas = self.search_agent.search(goal)\n",
    "            print(f\"Lemmes trouves: {[l.name for l in lemmas[:3]]}\")\n",
    "            \n",
    "            # Etape 2: Generer des tactiques\n",
    "            tactics = self.tactic_agent.generate_sequence(\n",
    "                goal, [], lemmas\n",
    "            )\n",
    "            proof = \"\\n  \".join(tactics)\n",
    "            print(f\"Tactiques generees: {tactics}\")\n",
    "            \n",
    "            # Etape 3: Verifier\n",
    "            result = self.verifier.verify(theorem, proof)\n",
    "            \n",
    "            # Enregistrer la tentative\n",
    "            self.history.append(ProofAttempt(\n",
    "                theorem, tactics, result, iteration\n",
    "            ))\n",
    "            \n",
    "            if result.success:\n",
    "                print(f\"\\nPreuve trouvee!\")\n",
    "                return True, proof\n",
    "            else:\n",
    "                print(f\"Echec: {result.error_message}\")\n",
    "                # Apprendre de l'echec pour la prochaine iteration\n",
    "                self._learn_from_failure(result)\n",
    "        \n",
    "        print(f\"\\nEchec apres {self.max_iterations} iterations\")\n",
    "        return False, None\n",
    "    \n",
    "    def _extract_goal(self, theorem: str) -> str:\n",
    "        \"\"\"Extrait le but du theoreme.\"\"\"\n",
    "        # Simplification: prendre la partie apres le \":\"\n",
    "        if \":\" in theorem:\n",
    "            return theorem.split(\":\", 1)[1].strip()\n",
    "        return theorem\n",
    "    \n",
    "    def _learn_from_failure(self, result: VerificationResult):\n",
    "        \"\"\"Ajuste la strategie basee sur l'echec.\"\"\"\n",
    "        # Dans un vrai systeme, on ajusterait les poids,\n",
    "        # eviterait les tactiques qui echouent, etc.\n",
    "        pass\n",
    "    \n",
    "    def get_statistics(self) -> dict:\n",
    "        \"\"\"Retourne les statistiques du systeme.\"\"\"\n",
    "        return {\n",
    "            \"total_attempts\": len(self.history),\n",
    "            \"verifier_stats\": self.verifier.get_stats()\n",
    "        }\n",
    "\n",
    "# Demonstration\n",
    "orchestrator = OrchestratorAgent()\n",
    "success, proof = orchestrator.prove(\n",
    "    \"theorem add_zero (n : Nat) : n + 0 = n\"\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(f\"\\nPreuve finale:\\n{proof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Integration avec Semantic Kernel (Python)\n",
    "\n",
    "### 5.1 Vue d'ensemble\n",
    "\n",
    "Microsoft **Semantic Kernel** est un SDK qui permet d'orchestrer des LLMs avec des plugins, de la memoire et des agents intelligents. Nous allons implementer un systeme multi-agents pour theorem proving inspire des patterns utilises dans l'analyse argumentative (voir `Argument_Analysis` notebooks).\n",
    "\n",
    "**Composants cles** :\n",
    "- **Kernel** : Point d'entree principal, configure les services LLM\n",
    "- **Plugins** : Fonctions appelables par les agents (decorated avec `@kernel_function`)\n",
    "- **Agents** : Entites autonomes avec instructions et capacites\n",
    "- **Orchestration** : Strategies de selection et terminaison des agents\n",
    "\n",
    "### 5.2 Dependances\n",
    "\n",
    "```python\n",
    "# Installation\n",
    "pip install semantic-kernel openai python-dotenv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoreme: theorem test (n : Nat) : n + 0 = n\n",
      "Taches: 1\n",
      "Lemmes trouves: 1\n",
      "Tactiques tentees: 0\n",
      "Iterations: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration Semantic Kernel pour Lean Theorem Proving\n",
    "# Pattern inspire de Argument_Analysis_Agentic notebooks\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Any\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# --- GESTION D'ETAT (Pattern StateManager) ---\n",
    "\n",
    "@dataclass\n",
    "class ProofState:\n",
    "    \"\"\"\n",
    "    Represente l'etat partage d'une session de preuve collaborative.\n",
    "    \n",
    "    Ce pattern est inspire de RhetoricalAnalysisState dans Argument_Analysis.\n",
    "    Il permet a plusieurs agents de partager et modifier un etat commun.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Theoreme initial\n",
    "    theorem_statement: str = \"\"\n",
    "    \n",
    "    # Taches de preuve identifiees\n",
    "    proof_tasks: Dict[str, str] = field(default_factory=dict)\n",
    "    \n",
    "    # Lemmes trouves par l'agent de recherche\n",
    "    discovered_lemmas: Dict[str, Dict[str, str]] = field(default_factory=dict)\n",
    "    \n",
    "    # Tactiques tentees\n",
    "    attempted_tactics: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    \n",
    "    # Resultat de verification (si disponible)\n",
    "    verification_result: Optional[Dict[str, Any]] = None\n",
    "    \n",
    "    # Preuve finale (si trouvee)\n",
    "    final_proof: Optional[str] = None\n",
    "    \n",
    "    # Agent designe pour la prochaine action\n",
    "    _next_agent_designated: Optional[str] = None\n",
    "    \n",
    "    # Compteur d'iterations\n",
    "    iteration_count: int = 0\n",
    "    \n",
    "    def add_task(self, description: str) -> str:\n",
    "        \"\"\"Ajoute une tache de preuve et retourne son ID.\"\"\"\n",
    "        task_id = f\"task_{len(self.proof_tasks) + 1}\"\n",
    "        self.proof_tasks[task_id] = description\n",
    "        return task_id\n",
    "    \n",
    "    def add_lemma(self, name: str, statement: str, namespace: str = \"\") -> str:\n",
    "        \"\"\"Enregistre un lemme decouvert.\"\"\"\n",
    "        lemma_id = f\"lemma_{len(self.discovered_lemmas) + 1}\"\n",
    "        self.discovered_lemmas[lemma_id] = {\n",
    "            \"name\": name,\n",
    "            \"statement\": statement,\n",
    "            \"namespace\": namespace,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        return lemma_id\n",
    "    \n",
    "    def record_tactic_attempt(self, tactic: str, success: bool, error: Optional[str] = None):\n",
    "        \"\"\"Enregistre une tentative de tactique.\"\"\"\n",
    "        self.attempted_tactics.append({\n",
    "            \"tactic\": tactic,\n",
    "            \"success\": success,\n",
    "            \"error\": error,\n",
    "            \"iteration\": self.iteration_count\n",
    "        })\n",
    "    \n",
    "    def designate_next_agent(self, agent_name: str):\n",
    "        \"\"\"Designe l'agent suivant (pour orchestration).\"\"\"\n",
    "        self._next_agent_designated = agent_name\n",
    "    \n",
    "    def consume_next_agent_designation(self) -> Optional[str]:\n",
    "        \"\"\"Recupere et efface la designation d'agent.\"\"\"\n",
    "        designation = self._next_agent_designated\n",
    "        self._next_agent_designated = None\n",
    "        return designation\n",
    "    \n",
    "    def get_summary(self) -> str:\n",
    "        \"\"\"Resume l'etat actuel pour le contexte des agents.\"\"\"\n",
    "        summary = f\"Theoreme: {self.theorem_statement}\\n\"\n",
    "        summary += f\"Taches: {len(self.proof_tasks)}\\n\"\n",
    "        summary += f\"Lemmes trouves: {len(self.discovered_lemmas)}\\n\"\n",
    "        summary += f\"Tactiques tentees: {len(self.attempted_tactics)}\\n\"\n",
    "        summary += f\"Iterations: {self.iteration_count}\\n\"\n",
    "        if self.final_proof:\n",
    "            summary += f\"Statut: PROUVE\\n\"\n",
    "        return summary\n",
    "\n",
    "# Test\n",
    "state = ProofState(theorem_statement=\"theorem test (n : Nat) : n + 0 = n\")\n",
    "state.add_task(\"Rechercher lemmes sur addition\")\n",
    "state.add_lemma(\"Nat.add_zero\", \"n + 0 = n\", \"Nat\")\n",
    "print(state.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Plugin Pattern avec @kernel_function\n",
    "\n",
    "Les plugins exposent des fonctions que les agents peuvent appeler. Chaque fonction est decoree avec `@kernel_function` pour etre decouvrable par Semantic Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test du plugin:\n",
      "Tache 'task_1' ajoutee: Trouver lemmes pertinents\n",
      "Lemmes trouves: ['Nat.add_zero', 'Nat.zero_add', 'Nat.add_comm']\n",
      "Tactiques candidates: ['exact Nat.add_zero', 'rw [Nat.add_zero]', 'exact Nat.zero_add', 'rw [Nat.zero_add]', 'exact Nat.add_comm']\n",
      "Theoreme: theorem add_zero (n : Nat) : n + 0 = n\n",
      "Taches: 1\n",
      "Lemmes trouves: 3\n",
      "Tactiques tentees: 0\n",
      "Iterations: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- PLUGIN LEAN THEOREM PROVER ---\n",
    "\n",
    "# Note: Ce code est une simulation du pattern Semantic Kernel.\n",
    "# En production, utiliser le vrai SDK semantic-kernel\n",
    "\n",
    "def kernel_function(description=\"\", name=None):\n",
    "    \"\"\"Decorateur simulant @kernel_function de Semantic Kernel.\"\"\"\n",
    "    def decorator(func):\n",
    "        func._sk_function = True\n",
    "        func._sk_description = description\n",
    "        func._sk_name = name or func.__name__\n",
    "        return func\n",
    "    return decorator\n",
    "\n",
    "class LeanProverPlugin:\n",
    "    \"\"\"\n",
    "    Plugin Semantic Kernel pour le theorem proving en Lean.\n",
    "    \n",
    "    Ce plugin expose les fonctionnalites aux agents:\n",
    "    - Gestion des taches de preuve\n",
    "    - Recherche de lemmes\n",
    "    - Generation de tactiques\n",
    "    - Verification de preuves\n",
    "    - Delegation entre agents\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state: ProofState):\n",
    "        self._state = state\n",
    "    \n",
    "    # --- Gestion des taches ---\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Ajoute une nouvelle tache de preuve a accomplir\",\n",
    "        name=\"add_proof_task\"\n",
    "    )\n",
    "    def add_proof_task(self, description: str) -> str:\n",
    "        \"\"\"Enregistre une tache de preuve.\"\"\"\n",
    "        task_id = self._state.add_task(description)\n",
    "        return f\"Tache '{task_id}' ajoutee: {description}\"\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Liste toutes les taches de preuve en cours\",\n",
    "        name=\"list_proof_tasks\"\n",
    "    )\n",
    "    def list_proof_tasks(self) -> str:\n",
    "        \"\"\"Retourne la liste des taches.\"\"\"\n",
    "        if not self._state.proof_tasks:\n",
    "            return \"Aucune tache enregistree.\"\n",
    "        tasks = \"\\n\".join([\n",
    "            f\"- {tid}: {desc}\" \n",
    "            for tid, desc in self._state.proof_tasks.items()\n",
    "        ])\n",
    "        return f\"Taches de preuve:\\n{tasks}\"\n",
    "    \n",
    "    # --- Recherche de lemmes ---\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Recherche des lemmes Mathlib pertinents pour le but courant\",\n",
    "        name=\"search_mathlib_lemmas\"\n",
    "    )\n",
    "    def search_mathlib_lemmas(self, goal: str) -> str:\n",
    "        \"\"\"\n",
    "        Recherche dans Mathlib (simulation).\n",
    "        En production, appellerait Loogle ou Moogle.\n",
    "        \"\"\"\n",
    "        # Simulation de recherche\n",
    "        results = [\n",
    "            (\"Nat.add_zero\", \"n + 0 = n\"),\n",
    "            (\"Nat.zero_add\", \"0 + n = n\"),\n",
    "            (\"Nat.add_comm\", \"n + m = m + n\"),\n",
    "        ]\n",
    "        \n",
    "        # Filtrer par pertinence\n",
    "        relevant = [(n, s) for n, s in results if any(\n",
    "            word in goal.lower() for word in s.lower().split()\n",
    "        )]\n",
    "        \n",
    "        # Enregistrer dans l'etat\n",
    "        for name, stmt in relevant:\n",
    "            self._state.add_lemma(name, stmt, \"Nat\")\n",
    "        \n",
    "        return f\"Lemmes trouves: {[n for n, _ in relevant]}\"\n",
    "    \n",
    "    # --- Generation de tactiques ---\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Genere des tactiques candidates pour le but courant\",\n",
    "        name=\"generate_tactics\"\n",
    "    )\n",
    "    def generate_tactics(self, goal: str, lemmas_context: str = \"\") -> str:\n",
    "        \"\"\"\n",
    "        Genere des tactiques basees sur le but et le contexte.\n",
    "        \"\"\"\n",
    "        tactics = []\n",
    "        \n",
    "        # Tactiques basees sur les lemmes decouverts\n",
    "        for lemma_id, lemma in self._state.discovered_lemmas.items():\n",
    "            tactics.append(f\"exact {lemma['name']}\")\n",
    "            tactics.append(f\"rw [{lemma['name']}]\")\n",
    "        \n",
    "        # Tactiques automatiques\n",
    "        if \"+\" in goal or \"-\" in goal:\n",
    "            tactics.append(\"omega\")\n",
    "        if \"*\" in goal:\n",
    "            tactics.append(\"ring\")\n",
    "        \n",
    "        # Fallback\n",
    "        tactics.extend([\"simp\", \"rfl\"])\n",
    "        \n",
    "        return f\"Tactiques candidates: {tactics[:5]}\"\n",
    "    \n",
    "    # --- Verification ---\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Verifie une preuve avec Lean et retourne le resultat\",\n",
    "        name=\"verify_lean_proof\"\n",
    "    )\n",
    "    def verify_lean_proof(self, lean_code: str) -> str:\n",
    "        \"\"\"\n",
    "        Verifie le code Lean (simulation).\n",
    "        En production, utiliserait lean-dojo ou subprocess.\n",
    "        \"\"\"\n",
    "        # Simulation de verification\n",
    "        import random\n",
    "        success = random.random() > 0.3 or \"exact Nat\" in lean_code or \"rfl\" in lean_code\n",
    "        \n",
    "        result = {\n",
    "            \"success\": success,\n",
    "            \"error\": None if success else \"tactic failed\",\n",
    "        }\n",
    "        \n",
    "        self._state.verification_result = result\n",
    "        self._state.record_tactic_attempt(lean_code, success, result.get(\"error\"))\n",
    "        \n",
    "        if success:\n",
    "            self._state.final_proof = lean_code\n",
    "            return f\"SUCCES: Preuve verifiee!\"\n",
    "        else:\n",
    "            return f\"ECHEC: {result['error']}\"\n",
    "    \n",
    "    # --- Delegation entre agents ---\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Delegue la prochaine action a un agent specifique\",\n",
    "        name=\"delegate_to_agent\"\n",
    "    )\n",
    "    def delegate_to_agent(self, agent_name: str, reason: str = \"\") -> str:\n",
    "        \"\"\"\n",
    "        Designe l'agent qui doit agir ensuite.\n",
    "        Agents disponibles: SearchAgent, TacticAgent, VerifierAgent\n",
    "        \"\"\"\n",
    "        valid_agents = [\"SearchAgent\", \"TacticAgent\", \"VerifierAgent\", \"OrchestratorAgent\"]\n",
    "        if agent_name not in valid_agents:\n",
    "            return f\"Agent inconnu. Choisir parmi: {valid_agents}\"\n",
    "        \n",
    "        self._state.designate_next_agent(agent_name)\n",
    "        return f\"Agent '{agent_name}' designe pour la prochaine action. Raison: {reason}\"\n",
    "    \n",
    "    # --- Utilitaires ---\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Obtient un resume de l'etat actuel de la preuve\",\n",
    "        name=\"get_proof_status\"\n",
    "    )\n",
    "    def get_proof_status(self) -> str:\n",
    "        \"\"\"Retourne le statut de la session de preuve.\"\"\"\n",
    "        return self._state.get_summary()\n",
    "\n",
    "# Test du plugin\n",
    "state = ProofState(theorem_statement=\"theorem add_zero (n : Nat) : n + 0 = n\")\n",
    "plugin = LeanProverPlugin(state)\n",
    "\n",
    "print(\"Test du plugin:\")\n",
    "print(plugin.add_proof_task(\"Trouver lemmes pertinents\"))\n",
    "print(plugin.search_mathlib_lemmas(\"n + 0 = n\"))\n",
    "print(plugin.generate_tactics(\"n + 0 = n\"))\n",
    "print(plugin.get_proof_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Definition des Agents Specialises\n",
    "\n",
    "Chaque agent a un role specifique et des instructions qui guident son comportement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agents definis:\n",
      "  - OrchestratorAgent\n",
      "  - SearchAgent\n",
      "  - TacticAgent\n",
      "  - VerifierAgent\n"
     ]
    }
   ],
   "source": [
    "# --- DEFINITIONS DES AGENTS ---\n",
    "\n",
    "# Instructions pour chaque agent (inspirees de Argument_Analysis)\n",
    "\n",
    "ORCHESTRATOR_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent orchestrateur pour le theorem proving en Lean.\n",
    "\n",
    "TON ROLE:\n",
    "- Coordonner les autres agents pour prouver un theoreme\n",
    "- Decomposer le probleme en sous-taches\n",
    "- Decider quel agent doit agir ensuite\n",
    "- Verifier que la preuve est complete\n",
    "\n",
    "WORKFLOW:\n",
    "1. Analyser le theoreme initial\n",
    "2. Deleguer a SearchAgent pour trouver des lemmes\n",
    "3. Deleguer a TacticAgent pour generer des tactiques\n",
    "4. Deleguer a VerifierAgent pour verifier la preuve\n",
    "5. Si echec, iterer avec feedback\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "- add_proof_task: Creer une nouvelle tache\n",
    "- delegate_to_agent: Passer le controle a un agent\n",
    "- get_proof_status: Obtenir le statut actuel\n",
    "\n",
    "Tu DOIS deleguer aux agents specialises, pas tout faire toi-meme.\n",
    "\"\"\"\n",
    "\n",
    "SEARCH_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent de recherche de lemmes pour le theorem proving.\n",
    "\n",
    "TON ROLE:\n",
    "- Chercher des lemmes pertinents dans Mathlib\n",
    "- Identifier les dependances necessaires\n",
    "- Fournir du contexte pour la generation de tactiques\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "- search_mathlib_lemmas: Rechercher dans Mathlib\n",
    "- add_proof_task: Noter des sous-problemes identifies\n",
    "\n",
    "Quand tu as termine ta recherche, utilise delegate_to_agent pour\n",
    "passer a TacticAgent avec les lemmes trouves.\n",
    "\"\"\"\n",
    "\n",
    "TACTIC_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent de generation de tactiques Lean.\n",
    "\n",
    "TON ROLE:\n",
    "- Generer des sequences de tactiques pour le but courant\n",
    "- Utiliser les lemmes fournis par SearchAgent\n",
    "- Proposer plusieurs strategies (directe, recurrence, auto)\n",
    "\n",
    "STRATEGIES DE PREUVE:\n",
    "1. Direct: exact, rfl, apply\n",
    "2. Reecriture: rw, simp\n",
    "3. Automatique: omega, ring, linarith\n",
    "4. Structurel: constructor, cases, induction\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "- generate_tactics: Generer des candidates\n",
    "- list_proof_tasks: Voir les taches en cours\n",
    "\n",
    "Quand tu as genere des tactiques, delegue a VerifierAgent.\n",
    "\"\"\"\n",
    "\n",
    "VERIFIER_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent de verification des preuves Lean.\n",
    "\n",
    "TON ROLE:\n",
    "- Executer le code Lean pour verifier les preuves\n",
    "- Analyser les erreurs si la preuve echoue\n",
    "- Fournir du feedback constructif\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "- verify_lean_proof: Verifier du code Lean\n",
    "- get_proof_status: Voir l'historique des tentatives\n",
    "\n",
    "Si la preuve echoue, analyse l'erreur et delegue a TacticAgent\n",
    "avec des suggestions d'amelioration.\n",
    "Si la preuve reussit, delegue a OrchestratorAgent pour conclure.\n",
    "\"\"\"\n",
    "\n",
    "# Classe Agent simplifiee (simulation de ChatCompletionAgent)\n",
    "class SimpleAgent:\n",
    "    \"\"\"Agent simplifie simulant le comportement de ChatCompletionAgent.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, instructions: str, plugin: LeanProverPlugin):\n",
    "        self.name = name\n",
    "        self.instructions = instructions\n",
    "        self.plugin = plugin\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def invoke(self, message: str) -> str:\n",
    "        \"\"\"\n",
    "        Traite un message et retourne une reponse.\n",
    "        En production, cela appellerait un LLM avec le plugin.\n",
    "        \"\"\"\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        # Simulation: logique basee sur le nom de l'agent\n",
    "        if self.name == \"OrchestratorAgent\":\n",
    "            response = self._orchestrate(message)\n",
    "        elif self.name == \"SearchAgent\":\n",
    "            response = self._search(message)\n",
    "        elif self.name == \"TacticAgent\":\n",
    "            response = self._generate_tactics(message)\n",
    "        elif self.name == \"VerifierAgent\":\n",
    "            response = self._verify(message)\n",
    "        else:\n",
    "            response = f\"Agent {self.name}: Message recu.\"\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "    \n",
    "    def _orchestrate(self, message: str) -> str:\n",
    "        \"\"\"Logique de l'orchestrateur.\"\"\"\n",
    "        status = self.plugin.get_proof_status()\n",
    "        if \"PROUVE\" in status:\n",
    "            return \"Preuve complete! Mission accomplie.\"\n",
    "        \n",
    "        # Deleguer a SearchAgent\n",
    "        self.plugin.delegate_to_agent(\"SearchAgent\", \"Rechercher des lemmes\")\n",
    "        return f\"Orchestrateur: Je delegue a SearchAgent.\\n{status}\"\n",
    "    \n",
    "    def _search(self, message: str) -> str:\n",
    "        \"\"\"Logique de recherche.\"\"\"\n",
    "        goal = self.plugin._state.theorem_statement.split(\":\")[-1].strip()\n",
    "        result = self.plugin.search_mathlib_lemmas(goal)\n",
    "        self.plugin.delegate_to_agent(\"TacticAgent\", \"Generer tactiques avec lemmes\")\n",
    "        return f\"SearchAgent: {result}\"\n",
    "    \n",
    "    def _generate_tactics(self, message: str) -> str:\n",
    "        \"\"\"Logique de generation.\"\"\"\n",
    "        goal = self.plugin._state.theorem_statement.split(\":\")[-1].strip()\n",
    "        result = self.plugin.generate_tactics(goal)\n",
    "        self.plugin.delegate_to_agent(\"VerifierAgent\", \"Verifier la tactique\")\n",
    "        return f\"TacticAgent: {result}\"\n",
    "    \n",
    "    def _verify(self, message: str) -> str:\n",
    "        \"\"\"Logique de verification.\"\"\"\n",
    "        # Prendre la premiere tactique disponible\n",
    "        if self.plugin._state.discovered_lemmas:\n",
    "            lemma = list(self.plugin._state.discovered_lemmas.values())[0]\n",
    "            code = f\"exact {lemma['name']}\"\n",
    "            result = self.plugin.verify_lean_proof(code)\n",
    "            if \"SUCCES\" in result:\n",
    "                self.plugin.delegate_to_agent(\"OrchestratorAgent\", \"Preuve complete\")\n",
    "            else:\n",
    "                self.plugin.delegate_to_agent(\"TacticAgent\", \"Essayer autre tactique\")\n",
    "            return f\"VerifierAgent: {result}\"\n",
    "        return \"VerifierAgent: Pas de tactique a verifier.\"\n",
    "\n",
    "# Creer les agents\n",
    "def create_agents(state: ProofState) -> Dict[str, SimpleAgent]:\n",
    "    \"\"\"Cree l'ensemble des agents.\"\"\"\n",
    "    plugin = LeanProverPlugin(state)\n",
    "    return {\n",
    "        \"OrchestratorAgent\": SimpleAgent(\"OrchestratorAgent\", ORCHESTRATOR_INSTRUCTIONS, plugin),\n",
    "        \"SearchAgent\": SimpleAgent(\"SearchAgent\", SEARCH_AGENT_INSTRUCTIONS, plugin),\n",
    "        \"TacticAgent\": SimpleAgent(\"TacticAgent\", TACTIC_AGENT_INSTRUCTIONS, plugin),\n",
    "        \"VerifierAgent\": SimpleAgent(\"VerifierAgent\", VERIFIER_AGENT_INSTRUCTIONS, plugin),\n",
    "    }\n",
    "\n",
    "print(\"Agents definis:\")\n",
    "for name in [\"OrchestratorAgent\", \"SearchAgent\", \"TacticAgent\", \"VerifierAgent\"]:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Strategies d'Orchestration\n",
    "\n",
    "L'orchestration determine comment les agents sont selectionnes et quand la conversation se termine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Demonstration Complete\n",
    "\n",
    "Cette demonstration montre le workflow complet : l'orchestrateur coordonne les agents specialises, chacun contribuant a une partie de la preuve avec verification Lean a chaque etape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategies d'orchestration definies:\n",
      "  - DelegatingSelectionStrategy: Selection par delegation explicite\n",
      "  - RoundRobinStrategy: Selection cyclique\n",
      "  - ProofCompleteTermination: Termine quand preuve trouvee\n"
     ]
    }
   ],
   "source": [
    "# --- STRATEGIES D'ORCHESTRATION ---\n",
    "# Pattern inspire de Argument_Analysis_Agentic-3-orchestration.ipynb\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class SelectionStrategy(ABC):\n",
    "    \"\"\"Strategie de selection de l'agent suivant.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def select_next(self, agents: Dict[str, SimpleAgent], state: ProofState) -> str:\n",
    "        \"\"\"Retourne le nom de l'agent a activer.\"\"\"\n",
    "        pass\n",
    "\n",
    "class DelegatingSelectionStrategy(SelectionStrategy):\n",
    "    \"\"\"\n",
    "    Strategie de selection basee sur la delegation explicite.\n",
    "    \n",
    "    L'agent courant designe le prochain via delegate_to_agent.\n",
    "    Si aucune designation, utilise un agent par defaut.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, default_agent: str = \"OrchestratorAgent\"):\n",
    "        self.default_agent = default_agent\n",
    "    \n",
    "    def select_next(self, agents: Dict[str, SimpleAgent], state: ProofState) -> str:\n",
    "        designated = state.consume_next_agent_designation()\n",
    "        if designated and designated in agents:\n",
    "            return designated\n",
    "        return self.default_agent\n",
    "\n",
    "class RoundRobinStrategy(SelectionStrategy):\n",
    "    \"\"\"Strategie round-robin simple (pour comparaison).\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_order: List[str]):\n",
    "        self.agent_order = agent_order\n",
    "        self.current_index = 0\n",
    "    \n",
    "    def select_next(self, agents: Dict[str, SimpleAgent], state: ProofState) -> str:\n",
    "        agent = self.agent_order[self.current_index % len(self.agent_order)]\n",
    "        self.current_index += 1\n",
    "        return agent\n",
    "\n",
    "class TerminationStrategy(ABC):\n",
    "    \"\"\"Strategie de terminaison de la conversation.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def should_terminate(self, state: ProofState, iteration: int) -> bool:\n",
    "        \"\"\"Retourne True si la conversation doit se terminer.\"\"\"\n",
    "        pass\n",
    "\n",
    "class ProofCompleteTermination(TerminationStrategy):\n",
    "    \"\"\"Termine quand la preuve est trouvee ou max iterations atteint.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_iterations: int = 10):\n",
    "        self.max_iterations = max_iterations\n",
    "    \n",
    "    def should_terminate(self, state: ProofState, iteration: int) -> bool:\n",
    "        # Terminaison si preuve trouvee\n",
    "        if state.final_proof is not None:\n",
    "            return True\n",
    "        # Terminaison si max iterations\n",
    "        if iteration >= self.max_iterations:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "# --- AGENT GROUP CHAT ---\n",
    "\n",
    "class AgentGroupChat:\n",
    "    \"\"\"\n",
    "    Conversation multi-agents pour le theorem proving.\n",
    "    \n",
    "    Pattern inspire de AgentGroupChat dans Semantic Kernel.\n",
    "    Coordonne plusieurs agents selon des strategies configurables.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        agents: Dict[str, SimpleAgent],\n",
    "        state: ProofState,\n",
    "        selection_strategy: SelectionStrategy,\n",
    "        termination_strategy: TerminationStrategy\n",
    "    ):\n",
    "        self.agents = agents\n",
    "        self.state = state\n",
    "        self.selection = selection_strategy\n",
    "        self.termination = termination_strategy\n",
    "        self.history = []\n",
    "    \n",
    "    def run(self, initial_message: str) -> str:\n",
    "        \"\"\"\n",
    "        Execute la conversation multi-agents.\n",
    "        \n",
    "        Args:\n",
    "            initial_message: Le message initial (theoreme a prouver)\n",
    "        \n",
    "        Returns:\n",
    "            La preuve finale ou un message d'echec\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"DEMARRAGE DE LA CONVERSATION MULTI-AGENTS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Objectif: {initial_message}\\n\")\n",
    "        \n",
    "        iteration = 0\n",
    "        current_message = initial_message\n",
    "        \n",
    "        while not self.termination.should_terminate(self.state, iteration):\n",
    "            # Selectionner l'agent suivant\n",
    "            agent_name = self.selection.select_next(self.agents, self.state)\n",
    "            agent = self.agents[agent_name]\n",
    "            \n",
    "            # Incrementer l'iteration\n",
    "            self.state.iteration_count = iteration + 1\n",
    "            \n",
    "            print(f\"--- Tour {iteration + 1}: {agent_name} ---\")\n",
    "            \n",
    "            # Invoquer l'agent\n",
    "            response = agent.invoke(current_message)\n",
    "            print(f\"{response}\\n\")\n",
    "            \n",
    "            # Enregistrer dans l'historique\n",
    "            self.history.append({\n",
    "                \"iteration\": iteration,\n",
    "                \"agent\": agent_name,\n",
    "                \"message\": current_message,\n",
    "                \"response\": response\n",
    "            })\n",
    "            \n",
    "            # Preparer le message suivant\n",
    "            current_message = response\n",
    "            iteration += 1\n",
    "        \n",
    "        # Resultat final\n",
    "        print(f\"{'='*60}\")\n",
    "        if self.state.final_proof:\n",
    "            print(f\"SUCCES apres {iteration} iterations!\")\n",
    "            print(f\"Preuve: {self.state.final_proof}\")\n",
    "            return self.state.final_proof\n",
    "        else:\n",
    "            print(f\"ECHEC apres {iteration} iterations.\")\n",
    "            return \"Preuve non trouvee.\"\n",
    "\n",
    "# Demonstration\n",
    "print(\"Strategies d'orchestration definies:\")\n",
    "print(\"  - DelegatingSelectionStrategy: Selection par delegation explicite\")\n",
    "print(\"  - RoundRobinStrategy: Selection cyclique\")\n",
    "print(\"  - ProofCompleteTermination: Termine quand preuve trouvee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEMARRAGE DE LA CONVERSATION MULTI-AGENTS\n",
      "============================================================\n",
      "Objectif: Prouver: theorem add_zero (n : Nat) : n + 0 = n\n",
      "\n",
      "--- Tour 1: OrchestratorAgent ---\n",
      "Orchestrateur: Je delegue a SearchAgent.\n",
      "Theoreme: theorem add_zero (n : Nat) : n + 0 = n\n",
      "Taches: 0\n",
      "Lemmes trouves: 0\n",
      "Tactiques tentees: 0\n",
      "Iterations: 1\n",
      "\n",
      "\n",
      "--- Tour 2: SearchAgent ---\n",
      "SearchAgent: Lemmes trouves: ['Nat.add_zero', 'Nat.zero_add', 'Nat.add_comm']\n",
      "\n",
      "--- Tour 3: TacticAgent ---\n",
      "TacticAgent: Tactiques candidates: ['exact Nat.add_zero', 'rw [Nat.add_zero]', 'exact Nat.zero_add', 'rw [Nat.zero_add]', 'exact Nat.add_comm']\n",
      "\n",
      "--- Tour 4: VerifierAgent ---\n",
      "VerifierAgent: SUCCES: Preuve verifiee!\n",
      "\n",
      "============================================================\n",
      "SUCCES apres 4 iterations!\n",
      "Preuve: exact Nat.add_zero\n"
     ]
    }
   ],
   "source": [
    "# --- DEMONSTRATION COMPLETE ---\n",
    "\n",
    "def prove_with_agents(theorem: str, max_iterations: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Prouve un theoreme en utilisant le systeme multi-agents.\n",
    "    \n",
    "    Args:\n",
    "        theorem: L'enonce du theoreme\n",
    "        max_iterations: Nombre max d'iterations\n",
    "    \n",
    "    Returns:\n",
    "        La preuve ou un message d'echec\n",
    "    \"\"\"\n",
    "    # 1. Creer l'etat\n",
    "    state = ProofState(theorem_statement=theorem)\n",
    "    \n",
    "    # 2. Creer le plugin\n",
    "    plugin = LeanProverPlugin(state)\n",
    "    \n",
    "    # 3. Creer les agents (tous partagent le meme plugin/etat)\n",
    "    agents = {\n",
    "        \"OrchestratorAgent\": SimpleAgent(\"OrchestratorAgent\", ORCHESTRATOR_INSTRUCTIONS, plugin),\n",
    "        \"SearchAgent\": SimpleAgent(\"SearchAgent\", SEARCH_AGENT_INSTRUCTIONS, plugin),\n",
    "        \"TacticAgent\": SimpleAgent(\"TacticAgent\", TACTIC_AGENT_INSTRUCTIONS, plugin),\n",
    "        \"VerifierAgent\": SimpleAgent(\"VerifierAgent\", VERIFIER_AGENT_INSTRUCTIONS, plugin),\n",
    "    }\n",
    "    \n",
    "    # 4. Configurer les strategies\n",
    "    selection = DelegatingSelectionStrategy(default_agent=\"OrchestratorAgent\")\n",
    "    termination = ProofCompleteTermination(max_iterations=max_iterations)\n",
    "    \n",
    "    # 5. Creer le groupe de chat\n",
    "    chat = AgentGroupChat(\n",
    "        agents=agents,\n",
    "        state=state,\n",
    "        selection_strategy=selection,\n",
    "        termination_strategy=termination\n",
    "    )\n",
    "    \n",
    "    # 6. Executer\n",
    "    return chat.run(f\"Prouver: {theorem}\")\n",
    "\n",
    "# Test sur un theoreme simple\n",
    "theorem = \"theorem add_zero (n : Nat) : n + 0 = n\"\n",
    "result = prove_with_agents(theorem, max_iterations=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Techniques de Harmonic Aristotle\n",
    "\n",
    "### 6.1 Decomposition de problemes\n",
    "\n",
    "Aristotle decompose les problemes complexes en sous-problemes plus simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition de 'P <-> Q':\n",
      "  - Direction 1: P  ->  Q\n",
      "  - Direction 2:  Q -> P \n"
     ]
    }
   ],
   "source": [
    "class AristotleDecomposer:\n",
    "    \"\"\"\n",
    "    Decomposition de problemes a la Harmonic Aristotle.\n",
    "    \"\"\"\n",
    "    \n",
    "    def decompose(self, theorem: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Decompose un theoreme en sous-lemmes.\n",
    "        \n",
    "        Strategy:\n",
    "        1. Identifier la structure (conjonction, equivalence, etc.)\n",
    "        2. Separer en composantes\n",
    "        3. Identifier les dependances\n",
    "        \"\"\"\n",
    "        subproblems = []\n",
    "        \n",
    "        # Decomposition basique par structure\n",
    "        if \"<->\" in theorem or \"iff\" in theorem.lower():\n",
    "            # Equivalence = deux implications\n",
    "            parts = theorem.split(\"<->\")\n",
    "            subproblems.append(f\"Direction 1: {parts[0]} -> {parts[1]}\")\n",
    "            subproblems.append(f\"Direction 2: {parts[1]} -> {parts[0]}\")\n",
    "        \n",
    "        elif \"/\\\\\" in theorem or \"and\" in theorem.lower():\n",
    "            # Conjonction = prouver chaque partie\n",
    "            parts = theorem.split(\"/\\\\\")\n",
    "            for i, part in enumerate(parts):\n",
    "                subproblems.append(f\"Partie {i+1}: {part.strip()}\")\n",
    "        \n",
    "        elif \"forall\" in theorem.lower():\n",
    "            # Universel = fixer variable, prouver pour arbitraire\n",
    "            subproblems.append(f\"Generalisation: introduire variable, prouver corps\")\n",
    "        \n",
    "        elif \"exists\" in theorem.lower():\n",
    "            # Existentiel = trouver temoin + preuve\n",
    "            subproblems.append(f\"Temoin: trouver valeur concrete\")\n",
    "            subproblems.append(f\"Verification: prouver pour ce temoin\")\n",
    "        \n",
    "        else:\n",
    "            # Pas de decomposition evidente\n",
    "            subproblems.append(theorem)\n",
    "        \n",
    "        return subproblems\n",
    "    \n",
    "    def solve_hierarchical(self, theorem: str, solver) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Resolution hierarchique par decomposition.\n",
    "        \"\"\"\n",
    "        subproblems = self.decompose(theorem)\n",
    "        \n",
    "        if len(subproblems) == 1 and subproblems[0] == theorem:\n",
    "            # Cas de base: resoudre directement\n",
    "            return solver(theorem)\n",
    "        \n",
    "        # Resoudre chaque sous-probleme\n",
    "        solutions = []\n",
    "        for sub in subproblems:\n",
    "            success, proof = self.solve_hierarchical(sub, solver)\n",
    "            if not success:\n",
    "                return False, None\n",
    "            solutions.append(proof)\n",
    "        \n",
    "        # Combiner les solutions\n",
    "        combined = self._combine_proofs(solutions)\n",
    "        return True, combined\n",
    "    \n",
    "    def _combine_proofs(self, proofs: List[str]) -> str:\n",
    "        \"\"\"Combine des preuves de sous-problemes.\"\"\"\n",
    "        return \"\\n\".join([\n",
    "            f\"-- Partie {i+1}\\n{proof}\" \n",
    "            for i, proof in enumerate(proofs)\n",
    "        ])\n",
    "\n",
    "# Test\n",
    "decomposer = AristotleDecomposer()\n",
    "subproblems = decomposer.decompose(\"P <-> Q\")\n",
    "print(\"Decomposition de 'P <-> Q':\")\n",
    "for sp in subproblems:\n",
    "    print(f\"  - {sp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Benchmarking sur Problemes d'Erdos\n",
    "\n",
    "Les problemes d'Erdos sont devenus le benchmark de reference pour evaluer les systemes de theorem proving automatique. Plusieurs ont ete resolus par IA en 2025-2026."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Addition zero (difficulte: 1)\n",
      "\n",
      "============================================================\n",
      "Debut de la preuve: theorem add_zero (n : Nat) : n + 0 = n\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Lemmes trouves: []\n",
      "Tactiques generees: ['rfl']\n",
      "\n",
      "Preuve trouvee!\n",
      "\n",
      "Test: Commutativite addition (difficulte: 2)\n",
      "\n",
      "============================================================\n",
      "Debut de la preuve: theorem add_comm (a b : Nat) : a + b = b + a\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Lemmes trouves: []\n",
      "Tactiques generees: ['rfl']\n",
      "\n",
      "Preuve trouvee!\n",
      "\n",
      "============================================================\n",
      "RESULTATS DU BENCHMARK\n",
      "============================================================\n",
      "Resolus: 2/2 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Benchmark sur des problemes type Erdos (simplifies)\n",
    "\n",
    "BENCHMARK_PROBLEMS = [\n",
    "    {\n",
    "        \"id\": \"simple_1\",\n",
    "        \"name\": \"Addition zero\",\n",
    "        \"statement\": \"theorem add_zero (n : Nat) : n + 0 = n\",\n",
    "        \"difficulty\": 1,\n",
    "        \"expected_tactics\": [\"exact Nat.add_zero n\", \"rfl\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"simple_2\", \n",
    "        \"name\": \"Commutativite addition\",\n",
    "        \"statement\": \"theorem add_comm (a b : Nat) : a + b = b + a\",\n",
    "        \"difficulty\": 2,\n",
    "        \"expected_tactics\": [\"exact Nat.add_comm a b\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"medium_1\",\n",
    "        \"name\": \"Associativite addition\",\n",
    "        \"statement\": \"theorem add_assoc (a b c : Nat) : (a + b) + c = a + (b + c)\",\n",
    "        \"difficulty\": 3,\n",
    "        \"expected_tactics\": [\"exact Nat.add_assoc a b c\", \"induction c\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "def run_benchmark(solver, problems=BENCHMARK_PROBLEMS):\n",
    "    \"\"\"Execute le benchmark sur les problemes donnes.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for problem in problems:\n",
    "        print(f\"\\nTest: {problem['name']} (difficulte: {problem['difficulty']})\")\n",
    "        \n",
    "        success, proof = solver.prove(problem['statement'])\n",
    "        \n",
    "        results.append({\n",
    "            \"id\": problem[\"id\"],\n",
    "            \"success\": success,\n",
    "            \"proof\": proof\n",
    "        })\n",
    "    \n",
    "    # Statistiques\n",
    "    total = len(results)\n",
    "    solved = sum(1 for r in results if r[\"success\"])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULTATS DU BENCHMARK\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Resolus: {solved}/{total} ({100*solved/total:.1f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Executer le benchmark (limite a 3 iterations pour la demo)\n",
    "orchestrator.max_iterations = 3\n",
    "results = run_benchmark(orchestrator, BENCHMARK_PROBLEMS[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercices\n",
    "\n",
    "### Exercice 1 : Ameliorer l'agent de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de ImprovedSearchAgent:\n",
      "----------------------------------------\n",
      "  Scoring 0 lemmes...\n",
      "\n",
      "Lemmes trouves pour 'n + 0 = n':\n",
      "  Scoring 0 lemmes...\n",
      "\n",
      "Lemmes trouves pour 'a + b = b + a':\n"
     ]
    }
   ],
   "source": [
    "# Exercice 1 - SOLUTION: Agent de recherche ameliore avec scoring LLM\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajouter le repertoire courant au path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "class ImprovedSearchAgent(TheoremSearchAgent):\n",
    "    \"\"\"\n",
    "    Version amelioree de l'agent de recherche avec scoring par LLM.\n",
    "    \n",
    "    Ameliorations:\n",
    "    1. Scoring semantique par LLM (pertinence reelle, pas juste mots-cles)\n",
    "    2. Cache des scores pour eviter les appels API redondants\n",
    "    3. Fallback sur heuristique si API non disponible\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client=None):\n",
    "        super().__init__(llm_client)\n",
    "        self.score_cache = {}  # (lemma_name, goal) -> score\n",
    "        self.api_available = self._check_api()\n",
    "    \n",
    "    def _check_api(self) -> bool:\n",
    "        \"\"\"Verifie si l'API OpenAI est disponible.\"\"\"\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        return api_key is not None and not api_key.startswith(\"sk-...\")\n",
    "    \n",
    "    def _score_with_llm(self, lemma: Lemma, goal: str) -> float:\n",
    "        \"\"\"\n",
    "        Score la pertinence d'un lemme par rapport au but en utilisant un LLM.\n",
    "        \n",
    "        Returns:\n",
    "            Score de pertinence entre 0.0 et 1.0\n",
    "        \"\"\"\n",
    "        # Verifier le cache\n",
    "        cache_key = (lemma.name, goal)\n",
    "        if cache_key in self.score_cache:\n",
    "            return self.score_cache[cache_key]\n",
    "        \n",
    "        # Si API non disponible, utiliser heuristique\n",
    "        if not self.api_available:\n",
    "            score = self._heuristic_score(lemma, goal)\n",
    "            self.score_cache[cache_key] = score\n",
    "            return score\n",
    "        \n",
    "        # Appel API reel\n",
    "        try:\n",
    "            from openai import OpenAI\n",
    "            client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "            \n",
    "            prompt = f\"\"\"Evalue la pertinence d'un lemme mathematique pour prouver un but en Lean 4.\n",
    "\n",
    "Lemme: {lemma.name}\n",
    "Enonce du lemme: {lemma.statement}\n",
    "\n",
    "But a prouver: {goal}\n",
    "\n",
    "Sur une echelle de 0 a 1, quelle est la pertinence de ce lemme?\n",
    "- 1.0 = Le lemme resout directement le but\n",
    "- 0.7-0.9 = Tres pertinent, peut etre utilise avec une reecriture\n",
    "- 0.4-0.6 = Moderement pertinent, structure similaire\n",
    "- 0.1-0.3 = Peu pertinent, meme domaine mais different\n",
    "- 0.0 = Aucun rapport\n",
    "\n",
    "Reponds UNIQUEMENT avec un nombre decimal entre 0 et 1.\"\"\"\n",
    "\n",
    "            # Les modeles modernes (gpt-4o, gpt-4.5, gpt-5, o1, o3) utilisent max_completion_tokens\n",
    "            model = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-4o\")\n",
    "            use_max_completion_tokens = any(model.startswith(p) for p in ('gpt-4o', 'gpt-4.5', 'gpt-5', 'o1', 'o3'))\n",
    "            token_param = {\"max_completion_tokens\": 10} if use_max_completion_tokens else {\"max_tokens\": 10}\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.1,\n",
    "                **token_param\n",
    "            )\n",
    "            \n",
    "            # Parser la reponse\n",
    "            score_text = response.choices[0].message.content.strip()\n",
    "            score = float(score_text)\n",
    "            score = max(0.0, min(1.0, score))  # Clamp entre 0 et 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  [Scoring LLM echoue: {e}, utilisation heuristique]\")\n",
    "            score = self._heuristic_score(lemma, goal)\n",
    "        \n",
    "        # Mettre en cache\n",
    "        self.score_cache[cache_key] = score\n",
    "        return score\n",
    "    \n",
    "    def _heuristic_score(self, lemma: Lemma, goal: str) -> float:\n",
    "        \"\"\"\n",
    "        Score heuristique base sur la correspondance de termes.\n",
    "        Utilise comme fallback quand l'API n'est pas disponible.\n",
    "        \"\"\"\n",
    "        # Normaliser les chaines\n",
    "        lemma_terms = set(lemma.statement.lower().replace(\":\", \" \").split())\n",
    "        goal_terms = set(goal.lower().replace(\":\", \" \").split())\n",
    "        \n",
    "        # Score = Jaccard similarity\n",
    "        intersection = len(lemma_terms & goal_terms)\n",
    "        union = len(lemma_terms | goal_terms)\n",
    "        \n",
    "        if union == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        jaccard = intersection / union\n",
    "        \n",
    "        # Bonus si le nom du lemme correspond au type d'operation\n",
    "        bonus = 0.0\n",
    "        if \"add\" in lemma.name.lower() and \"+\" in goal:\n",
    "            bonus = 0.2\n",
    "        elif \"mul\" in lemma.name.lower() and \"*\" in goal:\n",
    "            bonus = 0.2\n",
    "        elif \"comm\" in lemma.name.lower() and (\"comm\" in goal.lower() or \n",
    "                                               (\"+b\" in goal.replace(\" \", \"\") and \"+a\" in goal.replace(\" \", \"\"))):\n",
    "            bonus = 0.15\n",
    "        \n",
    "        return min(1.0, jaccard + bonus)\n",
    "    \n",
    "    def _score_lemmas(self, lemmas: List[Lemma], goal: str) -> List[Lemma]:\n",
    "        \"\"\"Score les lemmes avec la methode amelioree.\"\"\"\n",
    "        print(f\"  Scoring {len(lemmas)} lemmes...\")\n",
    "        \n",
    "        for lemma in lemmas:\n",
    "            lemma.relevance_score = self._score_with_llm(lemma, goal)\n",
    "        \n",
    "        # Trier par pertinence decroissante\n",
    "        return sorted(lemmas, key=lambda l: l.relevance_score, reverse=True)\n",
    "\n",
    "# Test de l'agent ameliore\n",
    "print(\"Test de ImprovedSearchAgent:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "improved_agent = ImprovedSearchAgent()\n",
    "goal = \"n + 0 = n\"\n",
    "results = improved_agent.search(goal)\n",
    "\n",
    "print(f\"\\nLemmes trouves pour '{goal}':\")\n",
    "for lemma in results:\n",
    "    print(f\"  [{lemma.relevance_score:.2f}] {lemma.name}: {lemma.statement}\")\n",
    "\n",
    "# Test sur un autre but\n",
    "goal2 = \"a + b = b + a\"\n",
    "results2 = improved_agent.search(goal2)\n",
    "print(f\"\\nLemmes trouves pour '{goal2}':\")\n",
    "for lemma in results2:\n",
    "    print(f\"  [{lemma.relevance_score:.2f}] {lemma.name}: {lemma.statement}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2 : Ajouter de la memoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de ProofMemory:\n",
      "--------------------------------------------------\n",
      "Preuves stockees: 2\n",
      "\n",
      "Recall pour 'theorem my_add_zero (m : Nat) : m + 0 = m':\n",
      "  Score de similarite: 1.00\n",
      "  Preuve adaptee: exact Nat.add_zero m\n",
      "\n",
      "Statistiques memoire:\n",
      "  Patterns: 2\n",
      "  Utilisations totales: 2\n"
     ]
    }
   ],
   "source": [
    "# Exercice 2 - SOLUTION: Systeme de memoire avec pattern matching\n",
    "\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "@dataclass\n",
    "class StoredProof:\n",
    "    \"\"\"Une preuve stockee avec son contexte.\"\"\"\n",
    "    theorem_pattern: str\n",
    "    original_theorem: str\n",
    "    proof: str\n",
    "    success_count: int = 1\n",
    "    variables: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "class ProofMemory:\n",
    "    \"\"\"\n",
    "    Systeme de memoire pour reutiliser les preuves reussies.\n",
    "    \n",
    "    Fonctionnalites:\n",
    "    1. Pattern matching pour generaliser les theoremes\n",
    "    2. Recherche de preuves similaires par similarite\n",
    "    3. Adaptation des preuves au nouveau contexte\n",
    "    4. Persistence (optionnelle) vers fichier JSON\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity_threshold: float = 0.7):\n",
    "        self.proofs: Dict[str, StoredProof] = {}  # pattern -> StoredProof\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "    \n",
    "    def store(self, theorem: str, proof: str) -> str:\n",
    "        \"\"\"\n",
    "        Stocke une preuve reussie.\n",
    "        \n",
    "        Returns:\n",
    "            L'ID du pattern utilise pour le stockage\n",
    "        \"\"\"\n",
    "        # Extraire le pattern et les variables\n",
    "        pattern, variables = self._extract_pattern(theorem)\n",
    "        \n",
    "        if pattern in self.proofs:\n",
    "            # Incrementer le compteur de succes\n",
    "            self.proofs[pattern].success_count += 1\n",
    "        else:\n",
    "            # Nouvelle preuve\n",
    "            self.proofs[pattern] = StoredProof(\n",
    "                theorem_pattern=pattern,\n",
    "                original_theorem=theorem,\n",
    "                proof=proof,\n",
    "                variables=variables\n",
    "            )\n",
    "        \n",
    "        return pattern\n",
    "    \n",
    "    def recall(self, theorem: str) -> Optional[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Retrouve une preuve similaire.\n",
    "        \n",
    "        Returns:\n",
    "            (preuve_adaptee, score_similarite) ou None si rien trouve\n",
    "        \"\"\"\n",
    "        # Extraire le pattern du theoreme\n",
    "        query_pattern, query_vars = self._extract_pattern(theorem)\n",
    "        \n",
    "        # Recherche exacte d'abord\n",
    "        if query_pattern in self.proofs:\n",
    "            stored = self.proofs[query_pattern]\n",
    "            adapted_proof = self._adapt_proof(stored.proof, stored.variables, query_vars)\n",
    "            return adapted_proof, 1.0\n",
    "        \n",
    "        # Recherche par similarite\n",
    "        best_match = None\n",
    "        best_score = 0.0\n",
    "        \n",
    "        for pattern, stored in self.proofs.items():\n",
    "            score = self._similarity(query_pattern, pattern)\n",
    "            if score > best_score and score >= self.similarity_threshold:\n",
    "                best_score = score\n",
    "                best_match = stored\n",
    "        \n",
    "        if best_match:\n",
    "            adapted_proof = self._adapt_proof(best_match.proof, best_match.variables, query_vars)\n",
    "            return adapted_proof, best_score\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_pattern(self, theorem: str) -> Tuple[str, Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Extrait un pattern generalise du theoreme.\n",
    "        \n",
    "        Transformations:\n",
    "        - Variables specifiques -> placeholders (?x, ?y, ?z)\n",
    "        - Types conserves\n",
    "        - Structure preservee\n",
    "        \n",
    "        Exemple:\n",
    "            \"theorem foo (n : Nat) : n + 0 = n\" \n",
    "            -> \"theorem ?name (?x : Nat) : ?x + 0 = ?x\"\n",
    "        \"\"\"\n",
    "        variables = {}\n",
    "        pattern = theorem\n",
    "        \n",
    "        # Extraire le nom du theoreme\n",
    "        name_match = re.search(r'theorem\\s+(\\w+)', theorem)\n",
    "        if name_match:\n",
    "            variables['theorem_name'] = name_match.group(1)\n",
    "            pattern = re.sub(r'theorem\\s+\\w+', 'theorem ?name', pattern)\n",
    "        \n",
    "        # Extraire les variables de type Nat/Int\n",
    "        var_matches = re.findall(r'\\((\\w+)\\s*:\\s*(\\w+)\\)', theorem)\n",
    "        placeholder_index = 0\n",
    "        placeholders = ['?x', '?y', '?z', '?a', '?b', '?c']\n",
    "        \n",
    "        for var_name, var_type in var_matches:\n",
    "            if placeholder_index < len(placeholders):\n",
    "                placeholder = placeholders[placeholder_index]\n",
    "                variables[placeholder] = var_name\n",
    "                # Remplacer la variable dans tout le pattern\n",
    "                pattern = re.sub(rf'\\b{var_name}\\b', placeholder, pattern)\n",
    "                placeholder_index += 1\n",
    "        \n",
    "        return pattern, variables\n",
    "    \n",
    "    def _similarity(self, pattern1: str, pattern2: str) -> float:\n",
    "        \"\"\"\n",
    "        Calcule la similarite entre deux patterns.\n",
    "        Utilise SequenceMatcher pour une comparaison robuste.\n",
    "        \"\"\"\n",
    "        # Normaliser\n",
    "        p1 = pattern1.lower().replace(\" \", \"\")\n",
    "        p2 = pattern2.lower().replace(\" \", \"\")\n",
    "        \n",
    "        return SequenceMatcher(None, p1, p2).ratio()\n",
    "    \n",
    "    def _adapt_proof(self, proof: str, original_vars: Dict[str, str], \n",
    "                     new_vars: Dict[str, str]) -> str:\n",
    "        \"\"\"\n",
    "        Adapte une preuve au nouveau contexte en substituant les variables.\n",
    "        \"\"\"\n",
    "        adapted = proof\n",
    "        \n",
    "        for placeholder, orig_name in original_vars.items():\n",
    "            if placeholder in new_vars:\n",
    "                new_name = new_vars[placeholder]\n",
    "                # Remplacer le nom original par le nouveau\n",
    "                adapted = re.sub(rf'\\b{orig_name}\\b', new_name, adapted)\n",
    "        \n",
    "        return adapted\n",
    "    \n",
    "    def get_statistics(self) -> Dict:\n",
    "        \"\"\"Retourne des statistiques sur la memoire.\"\"\"\n",
    "        return {\n",
    "            \"total_patterns\": len(self.proofs),\n",
    "            \"total_uses\": sum(p.success_count for p in self.proofs.values()),\n",
    "            \"most_used\": max(self.proofs.values(), \n",
    "                           key=lambda p: p.success_count).theorem_pattern \n",
    "                          if self.proofs else None\n",
    "        }\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"Sauvegarde la memoire dans un fichier JSON.\"\"\"\n",
    "        data = {\n",
    "            pattern: {\n",
    "                \"theorem_pattern\": sp.theorem_pattern,\n",
    "                \"original_theorem\": sp.original_theorem,\n",
    "                \"proof\": sp.proof,\n",
    "                \"success_count\": sp.success_count,\n",
    "                \"variables\": sp.variables\n",
    "            }\n",
    "            for pattern, sp in self.proofs.items()\n",
    "        }\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "    \n",
    "    def load(self, filepath: str):\n",
    "        \"\"\"Charge la memoire depuis un fichier JSON.\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        self.proofs = {\n",
    "            pattern: StoredProof(**stored)\n",
    "            for pattern, stored in data.items()\n",
    "        }\n",
    "\n",
    "# Test de ProofMemory\n",
    "print(\"Test de ProofMemory:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "memory = ProofMemory()\n",
    "\n",
    "# Stocker quelques preuves\n",
    "memory.store(\n",
    "    \"theorem add_zero_n (n : Nat) : n + 0 = n\",\n",
    "    \"exact Nat.add_zero n\"\n",
    ")\n",
    "memory.store(\n",
    "    \"theorem add_comm_ab (a b : Nat) : a + b = b + a\",\n",
    "    \"exact Nat.add_comm a b\"\n",
    ")\n",
    "\n",
    "print(f\"Preuves stockees: {len(memory.proofs)}\")\n",
    "\n",
    "# Tester le recall sur un theoreme similaire\n",
    "test_theorem = \"theorem my_add_zero (m : Nat) : m + 0 = m\"\n",
    "result = memory.recall(test_theorem)\n",
    "\n",
    "if result:\n",
    "    proof, score = result\n",
    "    print(f\"\\nRecall pour '{test_theorem}':\")\n",
    "    print(f\"  Score de similarite: {score:.2f}\")\n",
    "    print(f\"  Preuve adaptee: {proof}\")\n",
    "else:\n",
    "    print(f\"\\nPas de preuve trouvee pour '{test_theorem}'\")\n",
    "\n",
    "# Statistiques\n",
    "stats = memory.get_statistics()\n",
    "print(f\"\\nStatistiques memoire:\")\n",
    "print(f\"  Patterns: {stats['total_patterns']}\")\n",
    "print(f\"  Utilisations totales: {stats['total_uses']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume\n",
    "\n",
    "### Architecture multi-agents pour theorem proving\n",
    "\n",
    "| Agent | Role | Entrees | Sorties |\n",
    "|-------|------|---------|--------|\n",
    "| **OrchestratorAgent** | Coordonner workflow | Theoreme | Delegation + status |\n",
    "| **SearchAgent** | Trouver lemmes Mathlib | But | Liste de lemmes |\n",
    "| **TacticAgent** | Generer tactiques | But + lemmes | Sequence de tactiques |\n",
    "| **VerifierAgent** | Valider avec Lean | Code Lean | Succes/Erreur + feedback |\n",
    "\n",
    "### Patterns Semantic Kernel implementes\n",
    "\n",
    "| Pattern | Description | Classe |\n",
    "|---------|-------------|--------|\n",
    "| **StateManager** | Etat partage entre agents | `ProofState` |\n",
    "| **Plugin** | Fonctions @kernel_function | `LeanProverPlugin` |\n",
    "| **SelectionStrategy** | Choix agent suivant | `DelegatingSelectionStrategy` |\n",
    "| **TerminationStrategy** | Critere d'arret | `ProofCompleteTermination` |\n",
    "| **AgentGroupChat** | Conversation multi-agents | `AgentGroupChat` |\n",
    "\n",
    "### Techniques cles\n",
    "\n",
    "1. **Etat partage** : Tous les agents lisent/ecrivent dans `ProofState`\n",
    "2. **Delegation explicite** : Chaque agent designe le suivant via `delegate_to_agent`\n",
    "3. **Boucle de feedback** : Echecs envoyes a `TacticAgent` pour correction\n",
    "4. **Memoire de session** : Historique des tentatives pour eviter repetitions\n",
    "5. **Decomposition (Aristotle)** : Diviser problemes complexes en sous-problemes\n",
    "\n",
    "### Ressources et inspiration\n",
    "\n",
    "| Source | Contribution |\n",
    "|--------|--------------|\n",
    "| **Argument_Analysis notebooks** | Patterns SK (StateManager, orchestration) |\n",
    "| **Harmonic Aristotle** | Decomposition hierarchique, IMO Gold 2025 |\n",
    "| **APOLLO** | Generation massive, filtrage par Lean |\n",
    "| **AlphaProof** | RL + MCTS, Nature 2025 |\n",
    "| **LeanDojo** | Extraction donnees, LeanCopilot |\n",
    "\n",
    "### Impact futur\n",
    "\n",
    "Les systemes agentiques pour theorem proving representent une nouvelle frontiere:\n",
    "- **15+ problemes Erdos** resolus par IA depuis Noel 2025\n",
    "- **Acceleration x10-100** de la formalisation mathematique\n",
    "- **Decouverte** de nouvelles mathematiques par collaboration humain-IA\n",
    "- **Verification formelle** comme standard de confiance absolue\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook base sur les techniques de Harmonic Aristotle (IMO Gold 2025), APOLLO (arXiv 2505), AlphaProof (Nature 2025), et les patterns Semantic Kernel inspires de Argument_Analysis*\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation** : [← Lean-7-LLM-Integration](Lean-7-LLM-Integration.ipynb) | [Index](Lean-1-Setup.ipynb) | [Lean-9-LeanDojo →](Lean-9-LeanDojo.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (WSL)",
   "language": "python",
   "name": "python3-wsl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
