{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lean 8 - Agents Autonomes pour Demonstration de Theoremes\n",
        "\n",
        "**Navigation** : [â† Lean-7-LLM-Integration](Lean-7-LLM-Integration.ipynb) | [Index](Lean-1-Setup.ipynb) | [Lean-9-LeanDojo â†’](Lean-9-LeanDojo.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Ce notebook final de la serie explore la creation de **systemes multi-agents** capables de prouver des theoremes mathematiques de maniere **autonome**. Nous combinons les techniques des notebooks precedents avec les patterns d'orchestration agentique.\n",
        "\n",
        "L'objectif est de construire un systeme qui peut :\n",
        "1. Recevoir un enonce de theoreme\n",
        "2. Rechercher des lemmes pertinents dans Mathlib\n",
        "3. Generer des strategies de preuve\n",
        "4. Verifier formellement avec Lean\n",
        "5. Iterer jusqu'au succes\n",
        "\n",
        "### Objectifs pedagogiques\n",
        "\n",
        "1. Concevoir une architecture multi-agents pour theorem proving\n",
        "2. Implementer des agents specialises (recherche, generation, verification)\n",
        "3. Orchestrer la collaboration entre agents\n",
        "4. Gerer les boucles de feedback et d'amelioration\n",
        "5. Comprendre les techniques de Harmonic Aristotle et APOLLO\n",
        "\n",
        "### Prerequis\n",
        "\n",
        "- Notebooks **Lean-1** a **Lean-7** completes\n",
        "- Notions de base sur les systemes multi-agents\n",
        "- Cle API LLM (optionnel pour execution)\n",
        "\n",
        "### Duree estimee : 55-60 minutes\n",
        "\n",
        "---\n",
        "\n",
        "## Architecture d'un Systeme Agentique pour Lean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vue d'ensemble\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                     SYSTEME AGENTIQUE LEAN                          â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                                     â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚\n",
        "â”‚  â”‚   ORCHESTRATOR  â”‚  <- Coordonne tous les agents                 â”‚\n",
        "â”‚  â”‚     Agent       â”‚                                               â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚\n",
        "â”‚           â”‚                                                        â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚\n",
        "â”‚  â”‚        â”‚        â”‚                â”‚                              â”‚\n",
        "â”‚  v        v        v                v                              â”‚\n",
        "â”‚ â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚\n",
        "â”‚ â”‚Searchâ”‚ â”‚Tacticâ”‚ â”‚Proofâ”‚        â”‚Memory  â”‚                         â”‚\n",
        "â”‚ â”‚Agentâ”‚ â”‚Agentâ”‚ â”‚Verifyâ”‚        â”‚Store   â”‚                         â”‚\n",
        "â”‚ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚\n",
        "â”‚    â”‚        â”‚        â”‚                                             â”‚\n",
        "â”‚    v        v        v                                             â”‚\n",
        "â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\n",
        "â”‚ â”‚               LEAN KERNEL                     â”‚                   â”‚\n",
        "â”‚ â”‚  (Verification formelle + Mathlib)           â”‚                   â”‚\n",
        "â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
        "â”‚                                                                     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Agent de Recherche de Theoremes\n",
        "\n",
        "### 1.1 Role\n",
        "\n",
        "L'agent de recherche parcourt Mathlib pour trouver des lemmes pertinents au probleme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lemmes trouves:\n",
            "  Nat.add_zero: n + 0 = n (score: 1.00)\n",
            "  Nat.zero_add: 0 + n = n (score: 0.60)\n",
            "  Nat.add_comm: n + m = m + n (score: 0.45)\n",
            "  Nat.add_assoc: (n + m) + k = n + (m + k) (score: 0.45)\n",
            "  Nat.mul_zero: n * 0 = 0 (score: 0.45)\n",
            "  Nat.zero_mul: 0 * n = 0 (score: 0.45)\n",
            "  Nat.succ_add: succ n + m = succ (n + m) (score: 0.45)\n",
            "  Nat.add_succ: n + succ m = succ (n + m) (score: 0.45)\n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "import json\n",
        "import re\n",
        "\n",
        "@dataclass\n",
        "class Lemma:\n",
        "    \"\"\"Represente un lemme Mathlib.\"\"\"\n",
        "    name: str\n",
        "    statement: str\n",
        "    namespace: str\n",
        "    relevance_score: float = 0.0\n",
        "\n",
        "class TheoremSearchAgent:\n",
        "    \"\"\"Agent de recherche de theoremes dans Mathlib.\"\"\"\n",
        "\n",
        "    # Base de lemmes connus (extensible)\n",
        "    KNOWN_LEMMAS = [\n",
        "        Lemma(\"Nat.add_zero\", \"n + 0 = n\", \"Nat\"),\n",
        "        Lemma(\"Nat.zero_add\", \"0 + n = n\", \"Nat\"),\n",
        "        Lemma(\"Nat.add_comm\", \"n + m = m + n\", \"Nat\"),\n",
        "        Lemma(\"Nat.add_assoc\", \"(n + m) + k = n + (m + k)\", \"Nat\"),\n",
        "        Lemma(\"Nat.mul_comm\", \"n * m = m * n\", \"Nat\"),\n",
        "        Lemma(\"Nat.mul_assoc\", \"(n * m) * k = n * (m * k)\", \"Nat\"),\n",
        "        Lemma(\"Nat.mul_zero\", \"n * 0 = 0\", \"Nat\"),\n",
        "        Lemma(\"Nat.zero_mul\", \"0 * n = 0\", \"Nat\"),\n",
        "        Lemma(\"Nat.mul_one\", \"n * 1 = n\", \"Nat\"),\n",
        "        Lemma(\"Nat.one_mul\", \"1 * n = n\", \"Nat\"),\n",
        "        Lemma(\"Nat.succ_add\", \"succ n + m = succ (n + m)\", \"Nat\"),\n",
        "        Lemma(\"Nat.add_succ\", \"n + succ m = succ (n + m)\", \"Nat\"),\n",
        "    ]\n",
        "\n",
        "    def __init__(self, llm_client=None):\n",
        "        self.llm = llm_client\n",
        "        self.cache = {}  # Cache des recherches\n",
        "\n",
        "    def search(self, goal: str, context: str = \"\") -> List[Lemma]:\n",
        "        \"\"\"\n",
        "        Recherche des lemmes pertinents pour un but donne.\n",
        "\n",
        "        Args:\n",
        "            goal: Le but a prouver\n",
        "            context: Contexte additionnel (hypotheses, etc.)\n",
        "\n",
        "        Returns:\n",
        "            Liste de lemmes tries par pertinence\n",
        "        \"\"\"\n",
        "        # Verifier le cache\n",
        "        cache_key = f\"{goal}:{context}\"\n",
        "        if cache_key in self.cache:\n",
        "            return self.cache[cache_key]\n",
        "\n",
        "        # Analyser le but pour extraire les concepts\n",
        "        concepts = self._extract_concepts(goal)\n",
        "\n",
        "        # Rechercher dans la base de lemmes\n",
        "        lemmas = self._search_mathlib(concepts, goal)\n",
        "\n",
        "        # Scorer par pertinence\n",
        "        scored = self._score_lemmas(lemmas, goal)\n",
        "\n",
        "        # Mettre en cache\n",
        "        self.cache[cache_key] = scored\n",
        "\n",
        "        return scored\n",
        "\n",
        "    def _extract_concepts(self, goal: str) -> List[str]:\n",
        "        \"\"\"Extrait les concepts mathematiques du but.\"\"\"\n",
        "        concepts = []\n",
        "        goal_lower = goal.lower()\n",
        "\n",
        "        # Mapping symboles -> concepts\n",
        "        symbol_map = {\n",
        "            \"+\": [\"add\"],\n",
        "            \"*\": [\"mul\"],\n",
        "            \"0\": [\"zero\"],\n",
        "            \"1\": [\"one\"],\n",
        "            \"succ\": [\"succ\"],\n",
        "        }\n",
        "\n",
        "        for symbol, keywords in symbol_map.items():\n",
        "            if symbol in goal:\n",
        "                concepts.extend(keywords)\n",
        "\n",
        "        # Mots-cles explicites\n",
        "        explicit_keywords = [\"comm\", \"assoc\", \"zero\", \"one\", \"succ\", \"add\", \"mul\"]\n",
        "        for kw in explicit_keywords:\n",
        "            if kw in goal_lower and kw not in concepts:\n",
        "                concepts.append(kw)\n",
        "\n",
        "        return list(set(concepts))\n",
        "\n",
        "    def _search_mathlib(self, concepts: List[str], goal: str) -> List[Lemma]:\n",
        "        \"\"\"Recherche dans la base de lemmes connus.\"\"\"\n",
        "        if not concepts:\n",
        "            # Fallback: retourner quelques lemmes de base\n",
        "            return self.KNOWN_LEMMAS[:4]\n",
        "\n",
        "        # Filtrer par concepts\n",
        "        matches = []\n",
        "        for lemma in self.KNOWN_LEMMAS:\n",
        "            name_lower = lemma.name.lower()\n",
        "            if any(c in name_lower for c in concepts):\n",
        "                matches.append(Lemma(lemma.name, lemma.statement, lemma.namespace, 0.0))\n",
        "\n",
        "        return matches if matches else self.KNOWN_LEMMAS[:3]\n",
        "\n",
        "    def _score_lemmas(self, lemmas: List[Lemma], goal: str) -> List[Lemma]:\n",
        "        \"\"\"Score les lemmes par pertinence.\"\"\"\n",
        "        # Normaliser le but\n",
        "        goal_normalized = goal.replace(\" \", \"\").lower()\n",
        "\n",
        "        for lemma in lemmas:\n",
        "            # Score base sur la correspondance structurelle\n",
        "            stmt_normalized = lemma.statement.replace(\" \", \"\").lower()\n",
        "\n",
        "            # Score exact match\n",
        "            if goal_normalized == stmt_normalized:\n",
        "                lemma.relevance_score = 1.0\n",
        "            # Score partial match\n",
        "            elif goal_normalized in stmt_normalized or stmt_normalized in goal_normalized:\n",
        "                lemma.relevance_score = 0.8\n",
        "            else:\n",
        "                # Score par tokens communs\n",
        "                goal_tokens = set(re.findall(r'[a-z]+|[0-9]+|[+*=]', goal_normalized))\n",
        "                stmt_tokens = set(re.findall(r'[a-z]+|[0-9]+|[+*=]', stmt_normalized))\n",
        "                common = goal_tokens & stmt_tokens\n",
        "                lemma.relevance_score = len(common) / max(len(goal_tokens), 1) * 0.6\n",
        "\n",
        "        return sorted(lemmas, key=lambda l: l.relevance_score, reverse=True)\n",
        "\n",
        "# Test\n",
        "search_agent = TheoremSearchAgent()\n",
        "results = search_agent.search(\"n + 0 = n\")\n",
        "print(\"Lemmes trouves:\")\n",
        "for lemma in results:\n",
        "    print(f\"  {lemma.name}: {lemma.statement} (score: {lemma.relevance_score:.2f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Agent de Generation de Tactiques\n",
        "\n",
        "### 2.1 Role\n",
        "\n",
        "L'agent de tactiques genere des sequences de tactiques Lean pour prouver le but."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tactiques suggerees:\n",
            "  [1.00] exact Nat.add_zero - Appliquer Nat.add_zero: n + 0 = n\n",
            "  [0.90] rfl - Reflexivite - verifie si les deux cotes sont identiques\n",
            "  [0.80] rw [Nat.add_zero] - Reecrire avec Nat.add_zero\n",
            "  [0.70] omega - Arithmetique de Presburger automatique\n",
            "  [0.60] exact Nat.zero_add - Appliquer Nat.zero_add: 0 + n = n\n"
          ]
        }
      ],
      "source": [
        "from enum import Enum\n",
        "from typing import Tuple\n",
        "\n",
        "class TacticType(Enum):\n",
        "    DIRECT = \"direct\"       # exact, rfl\n",
        "    REWRITE = \"rewrite\"     # rw, simp\n",
        "    SPLIT = \"split\"         # constructor, cases\n",
        "    INDUCTION = \"induction\" # induction, recursion\n",
        "    AUTO = \"auto\"           # omega, ring, linarith\n",
        "\n",
        "@dataclass\n",
        "class TacticSuggestion:\n",
        "    \"\"\"Une suggestion de tactique avec son contexte.\"\"\"\n",
        "    tactic: str\n",
        "    tactic_type: TacticType\n",
        "    confidence: float\n",
        "    explanation: str\n",
        "\n",
        "class TacticGeneratorAgent:\n",
        "    \"\"\"Agent de generation de tactiques.\"\"\"\n",
        "    \n",
        "    def __init__(self, llm_client=None):\n",
        "        self.llm = llm_client\n",
        "        self.history = []  # Historique des tentatives\n",
        "    \n",
        "    def generate(self, goal: str, context: List[str], \n",
        "                 available_lemmas: List[Lemma]) -> List[TacticSuggestion]:\n",
        "        \"\"\"\n",
        "        Genere des tactiques pour un but donne.\n",
        "        \n",
        "        Args:\n",
        "            goal: Le but courant\n",
        "            context: Les hypotheses disponibles\n",
        "            available_lemmas: Lemmes suggeres par l'agent de recherche\n",
        "        \n",
        "        Returns:\n",
        "            Liste de suggestions de tactiques\n",
        "        \"\"\"\n",
        "        suggestions = []\n",
        "        \n",
        "        # Strategie 1: Tactiques directes\n",
        "        if \"=\" in goal:\n",
        "            suggestions.append(TacticSuggestion(\n",
        "                \"rfl\", TacticType.DIRECT, 0.9,\n",
        "                \"Reflexivite - verifie si les deux cotes sont identiques\"\n",
        "            ))\n",
        "        \n",
        "        # Strategie 2: Utiliser les lemmes disponibles\n",
        "        for lemma in available_lemmas[:3]:\n",
        "            suggestions.append(TacticSuggestion(\n",
        "                f\"exact {lemma.name}\", TacticType.DIRECT, \n",
        "                lemma.relevance_score,\n",
        "                f\"Appliquer {lemma.name}: {lemma.statement}\"\n",
        "            ))\n",
        "            suggestions.append(TacticSuggestion(\n",
        "                f\"rw [{lemma.name}]\", TacticType.REWRITE,\n",
        "                lemma.relevance_score * 0.8,\n",
        "                f\"Reecrire avec {lemma.name}\"\n",
        "            ))\n",
        "        \n",
        "        # Strategie 3: Tactiques automatiques\n",
        "        if any(op in goal for op in [\"+\", \"-\", \"<\", \">\", \"<=\", \">=\"]):\n",
        "            suggestions.append(TacticSuggestion(\n",
        "                \"omega\", TacticType.AUTO, 0.7,\n",
        "                \"Arithmetique de Presburger automatique\"\n",
        "            ))\n",
        "        \n",
        "        if \"*\" in goal or \"^\" in goal:\n",
        "            suggestions.append(TacticSuggestion(\n",
        "                \"ring\", TacticType.AUTO, 0.7,\n",
        "                \"Algebre polynomiale automatique\"\n",
        "            ))\n",
        "        \n",
        "        # Strategie 4: Simp comme fallback\n",
        "        suggestions.append(TacticSuggestion(\n",
        "            \"simp\", TacticType.REWRITE, 0.5,\n",
        "            \"Simplification automatique\"\n",
        "        ))\n",
        "        \n",
        "        # Trier par confiance\n",
        "        return sorted(suggestions, key=lambda s: s.confidence, reverse=True)\n",
        "    \n",
        "    def generate_sequence(self, goal: str, context: List[str],\n",
        "                          available_lemmas: List[Lemma],\n",
        "                          max_depth: int = 5) -> List[str]:\n",
        "        \"\"\"\n",
        "        Genere une sequence complete de tactiques.\n",
        "        \"\"\"\n",
        "        sequence = []\n",
        "        current_goal = goal\n",
        "        \n",
        "        for _ in range(max_depth):\n",
        "            suggestions = self.generate(current_goal, context, available_lemmas)\n",
        "            if not suggestions:\n",
        "                break\n",
        "            \n",
        "            best = suggestions[0]\n",
        "            sequence.append(best.tactic)\n",
        "            \n",
        "            # Simuler la progression (dans la realite, Lean nous dirait le nouveau but)\n",
        "            if best.tactic_type == TacticType.DIRECT:\n",
        "                break  # Preuve complete\n",
        "        \n",
        "        return sequence\n",
        "\n",
        "# Test\n",
        "tactic_agent = TacticGeneratorAgent()\n",
        "lemmas = search_agent.search(\"n + 0 = n\")\n",
        "suggestions = tactic_agent.generate(\"n + 0 = n\", [], lemmas)\n",
        "\n",
        "print(\"Tactiques suggerees:\")\n",
        "for s in suggestions[:5]:\n",
        "    print(f\"  [{s.confidence:.2f}] {s.tactic} - {s.explanation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Agent de Verification\n",
        "\n",
        "### 3.1 Role\n",
        "\n",
        "L'agent de verification execute le code Lean et analyse les resultats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verification: Succes\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class VerificationResult:\n",
        "    \"\"\"Resultat de la verification Lean.\"\"\"\n",
        "    success: bool\n",
        "    error_message: Optional[str] = None\n",
        "    remaining_goals: List[str] = None\n",
        "    execution_time: float = 0.0\n",
        "\n",
        "class ProofVerifierAgent:\n",
        "    \"\"\"Agent de verification des preuves.\"\"\"\n",
        "    \n",
        "    def __init__(self, lean_path: str = \"lean\"):\n",
        "        self.lean_path = lean_path\n",
        "        self.verified_count = 0\n",
        "        self.failed_count = 0\n",
        "    \n",
        "    def verify(self, theorem: str, proof: str) -> VerificationResult:\n",
        "        \"\"\"\n",
        "        Verifie une preuve avec Lean.\n",
        "        \n",
        "        Args:\n",
        "            theorem: L'enonce du theoreme\n",
        "            proof: La preuve proposee (sequence de tactiques)\n",
        "        \n",
        "        Returns:\n",
        "            Resultat de la verification\n",
        "        \"\"\"\n",
        "        # Construire le code Lean complet\n",
        "        lean_code = self._build_lean_code(theorem, proof)\n",
        "        \n",
        "        # Simuler l'execution Lean\n",
        "        # (Dans un vrai systeme, on utiliserait subprocess ou lean-dojo)\n",
        "        result = self._simulate_lean_execution(lean_code)\n",
        "        \n",
        "        # Mettre a jour les statistiques\n",
        "        if result.success:\n",
        "            self.verified_count += 1\n",
        "        else:\n",
        "            self.failed_count += 1\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def _build_lean_code(self, theorem: str, proof: str) -> str:\n",
        "        \"\"\"Construit le code Lean complet.\"\"\"\n",
        "        return f\"\"\"\n",
        "{theorem} := by\n",
        "  {proof}\n",
        "        \"\"\".strip()\n",
        "    \n",
        "    def _simulate_lean_execution(self, code: str) -> VerificationResult:\n",
        "        \"\"\"\n",
        "        Simule l'execution Lean.\n",
        "        Dans un vrai systeme, utiliser lean-dojo ou subprocess.\n",
        "        \"\"\"\n",
        "        # Heuristiques simples pour la simulation\n",
        "        if \"rfl\" in code or \"exact Nat.add_zero\" in code:\n",
        "            return VerificationResult(success=True)\n",
        "        elif \"sorry\" in code:\n",
        "            return VerificationResult(\n",
        "                success=False,\n",
        "                error_message=\"declaration uses 'sorry'\"\n",
        "            )\n",
        "        else:\n",
        "            # Simuler une reussite aleatoire\n",
        "            import random\n",
        "            if random.random() > 0.3:\n",
        "                return VerificationResult(success=True)\n",
        "            else:\n",
        "                return VerificationResult(\n",
        "                    success=False,\n",
        "                    error_message=\"tactic failed\"\n",
        "                )\n",
        "    \n",
        "    def get_stats(self) -> dict:\n",
        "        \"\"\"Retourne les statistiques de verification.\"\"\"\n",
        "        total = self.verified_count + self.failed_count\n",
        "        return {\n",
        "            \"verified\": self.verified_count,\n",
        "            \"failed\": self.failed_count,\n",
        "            \"success_rate\": self.verified_count / max(total, 1)\n",
        "        }\n",
        "\n",
        "# Test\n",
        "verifier = ProofVerifierAgent()\n",
        "result = verifier.verify(\n",
        "    \"theorem test (n : Nat) : n + 0 = n\",\n",
        "    \"exact Nat.add_zero n\"\n",
        ")\n",
        "print(f\"Verification: {'Succes' if result.success else 'Echec'}\")\n",
        "if result.error_message:\n",
        "    print(f\"Erreur: {result.error_message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Agent Orchestrateur\n",
        "\n",
        "### 4.1 Role\n",
        "\n",
        "L'orchestrateur coordonne tous les agents pour resoudre un probleme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Debut de la preuve: theorem add_zero (n : Nat) : n + 0 = n\n",
            "============================================================\n",
            "\n",
            "--- Iteration 1 ---\n",
            "Lemmes trouves: ['Nat.add_zero', 'Nat.zero_add', 'Nat.add_comm']\n",
            "Tactiques generees: ['rfl']\n",
            "\n",
            "Preuve trouvee!\n",
            "\n",
            "Preuve finale:\n",
            "rfl\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class ProofAttempt:\n",
        "    \"\"\"Enregistre une tentative de preuve.\"\"\"\n",
        "    theorem: str\n",
        "    tactics: List[str]\n",
        "    result: VerificationResult\n",
        "    iteration: int\n",
        "\n",
        "class OrchestratorAgent:\n",
        "    \"\"\"\n",
        "    Agent orchestrateur qui coordonne le systeme multi-agents.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.search_agent = TheoremSearchAgent()\n",
        "        self.tactic_agent = TacticGeneratorAgent()\n",
        "        self.verifier = ProofVerifierAgent()\n",
        "        self.history: List[ProofAttempt] = []\n",
        "        self.max_iterations = 10\n",
        "    \n",
        "    def prove(self, theorem: str) -> Tuple[bool, Optional[str]]:\n",
        "        \"\"\"\n",
        "        Tente de prouver un theoreme.\n",
        "        \n",
        "        Args:\n",
        "            theorem: L'enonce du theoreme\n",
        "        \n",
        "        Returns:\n",
        "            (succes, preuve) ou (echec, None)\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Debut de la preuve: {theorem}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "        \n",
        "        for iteration in range(self.max_iterations):\n",
        "            print(f\"--- Iteration {iteration + 1} ---\")\n",
        "            \n",
        "            # Etape 1: Rechercher des lemmes pertinents\n",
        "            goal = self._extract_goal(theorem)\n",
        "            lemmas = self.search_agent.search(goal)\n",
        "            print(f\"Lemmes trouves: {[l.name for l in lemmas[:3]]}\")\n",
        "            \n",
        "            # Etape 2: Generer des tactiques\n",
        "            tactics = self.tactic_agent.generate_sequence(\n",
        "                goal, [], lemmas\n",
        "            )\n",
        "            proof = \"\\n  \".join(tactics)\n",
        "            print(f\"Tactiques generees: {tactics}\")\n",
        "            \n",
        "            # Etape 3: Verifier\n",
        "            result = self.verifier.verify(theorem, proof)\n",
        "            \n",
        "            # Enregistrer la tentative\n",
        "            self.history.append(ProofAttempt(\n",
        "                theorem, tactics, result, iteration\n",
        "            ))\n",
        "            \n",
        "            if result.success:\n",
        "                print(f\"\\nPreuve trouvee!\")\n",
        "                return True, proof\n",
        "            else:\n",
        "                print(f\"Echec: {result.error_message}\")\n",
        "                # Apprendre de l'echec pour la prochaine iteration\n",
        "                self._learn_from_failure(result)\n",
        "        \n",
        "        print(f\"\\nEchec apres {self.max_iterations} iterations\")\n",
        "        return False, None\n",
        "    \n",
        "    def _extract_goal(self, theorem: str) -> str:\n",
        "        \"\"\"Extrait le but du theoreme.\"\"\"\n",
        "        # Simplification: prendre la partie apres le \":\"\n",
        "        if \":\" in theorem:\n",
        "            return theorem.split(\":\", 1)[1].strip()\n",
        "        return theorem\n",
        "    \n",
        "    def _learn_from_failure(self, result: VerificationResult):\n",
        "        \"\"\"Ajuste la strategie basee sur l'echec.\"\"\"\n",
        "        # Dans un vrai systeme, on ajusterait les poids,\n",
        "        # eviterait les tactiques qui echouent, etc.\n",
        "        pass\n",
        "    \n",
        "    def get_statistics(self) -> dict:\n",
        "        \"\"\"Retourne les statistiques du systeme.\"\"\"\n",
        "        return {\n",
        "            \"total_attempts\": len(self.history),\n",
        "            \"verifier_stats\": self.verifier.get_stats()\n",
        "        }\n",
        "\n",
        "# Demonstration\n",
        "orchestrator = OrchestratorAgent()\n",
        "success, proof = orchestrator.prove(\n",
        "    \"theorem add_zero (n : Nat) : n + 0 = n\"\n",
        ")\n",
        "\n",
        "if success:\n",
        "    print(f\"\\nPreuve finale:\\n{proof}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Architecture du SystÃ¨me Multi-Agents\n",
        "\n",
        "### Vue d'ensemble\n",
        "\n",
        "Notre systÃ¨me utilise **5 agents spÃ©cialisÃ©s** qui collaborent pour prouver des thÃ©orÃ¨mes Lean :\n",
        "\n",
        "1. **SearchAgent** : Recherche de lemmes pertinents dans Mathlib\n",
        "2. **TacticAgent** : GÃ©nÃ©ration de tactiques Lean appropriÃ©es\n",
        "3. **VerifierAgent** : VÃ©rification formelle des preuves\n",
        "4. **CriticAgent** : Analyse et suggestions d'amÃ©lioration\n",
        "5. **CoordinatorAgent** : Orchestration et dÃ©cisions stratÃ©giques\n",
        "\n",
        "### Pourquoi 5 agents ?\n",
        "\n",
        "Chaque agent a une **responsabilitÃ© unique** (principe de sÃ©paration des prÃ©occupations) :\n",
        "\n",
        "- **SÃ©paration des compÃ©tences** : Recherche â‰  GÃ©nÃ©ration â‰  VÃ©rification\n",
        "- **SpÃ©cialisation** : Chaque LLM est promptÃ© pour une tÃ¢che prÃ©cise\n",
        "- **Robustesse** : Si un agent Ã©choue, les autres continuent\n",
        "- **TraÃ§abilitÃ©** : On sait quel agent a pris quelle dÃ©cision\n",
        "\n",
        "### Communication : Ã‰tat partagÃ© vs Message passing\n",
        "\n",
        "Deux approches classiques en multi-agents :\n",
        "\n",
        "| **Message Passing** | **Ã‰tat PartagÃ©** (notre choix) |\n",
        "|---------------------|--------------------------------|\n",
        "| Agents s'envoient des messages | Tous les agents lisent/Ã©crivent un Ã©tat central |\n",
        "| DÃ©centralisÃ© | CentralisÃ© |\n",
        "| Complexe Ã  orchestrer | Facile Ã  suivre |\n",
        "| Pas de snapshot global | Snapshot complet Ã  chaque itÃ©ration |\n",
        "\n",
        "**Pourquoi Ã©tat partagÃ© ?**\n",
        "\n",
        "- Besoin de **cohÃ©rence globale** (historique des tactiques, mÃ©triques)\n",
        "- **Debugging facilitÃ©** : On peut inspecter l'Ã©tat aprÃ¨s chaque tour\n",
        "- **Snapshots JSON** : Permet de reproduire exactement une session\n",
        "- Semantic Kernel supporte ce pattern avec les **plugins**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Integration avec Semantic Kernel (Python)\n",
        "\n",
        "### 5.1 Vue d'ensemble\n",
        "\n",
        "Microsoft **Semantic Kernel** est un SDK qui permet d'orchestrer des LLMs avec des plugins, de la memoire et des agents intelligents. Nous allons implementer un systeme multi-agents pour theorem proving inspire des patterns utilises dans l'analyse argumentative (voir `Argument_Analysis` notebooks).\n",
        "\n",
        "**Composants cles** :\n",
        "- **Kernel** : Point d'entree principal, configure les services LLM\n",
        "- **Plugins** : Fonctions appelables par les agents (decorated avec `@kernel_function`)\n",
        "- **Agents** : Entites autonomes avec instructions et capacites\n",
        "- **Orchestration** : Strategies de selection et terminaison des agents\n",
        "\n",
        "### 5.2 Dependances\n",
        "\n",
        "```python\n",
        "# Installation\n",
        "pip install semantic-kernel openai python-dotenv\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Ã‰tat PartagÃ© : La Classe `ProofState`\n",
        "\n",
        "La classe `ProofState` est le **cÅ“ur du systÃ¨me**. Elle contient :\n",
        "\n",
        "### 1. Phase de preuve (`ProofPhase` enum)\n",
        "```\n",
        "INIT â†’ SEARCH â†’ TACTIC_GEN â†’ VERIFICATION â†’ REFINEMENT â†’ COMPLETE\n",
        "```\n",
        "\n",
        "Chaque phase dÃ©termine **quel agent agit** :\n",
        "- `INIT` â†’ CoordinatorAgent dÃ©cide de la stratÃ©gie\n",
        "- `SEARCH` â†’ SearchAgent cherche des lemmes\n",
        "- `TACTIC_GEN` â†’ TacticAgent gÃ©nÃ¨re une tactique\n",
        "- `VERIFICATION` â†’ VerifierAgent teste la preuve\n",
        "- `REFINEMENT` â†’ CriticAgent analyse et ajuste\n",
        "- `COMPLETE` â†’ Session terminÃ©e\n",
        "\n",
        "### 2. StratÃ©gie de preuve (`ProofStrategy` enum)\n",
        "\n",
        "```python\n",
        "EXPLORATION   # Recherche large de lemmes\n",
        "REFINEMENT    # Ajustement d'une preuve existante\n",
        "VALIDATION    # VÃ©rification formelle\n",
        "RECOVERY      # RÃ©cupÃ©ration aprÃ¨s erreur\n",
        "```\n",
        "\n",
        "La stratÃ©gie influence **quels lemmes rechercher** et **quelles tactiques essayer**.\n",
        "\n",
        "### 3. Historique et mÃ©triques\n",
        "\n",
        "- `tactic_history` : Liste de toutes les tactiques essayÃ©es (succÃ¨s + Ã©checs)\n",
        "- `verification_results` : RÃ©sultats des vÃ©rifications Lean\n",
        "- `current_proof` : Preuve en construction\n",
        "- `error_count` : Nombre d'erreurs rencontrÃ©es\n",
        "\n",
        "### 4. Snapshots JSON\n",
        "\n",
        "Ã€ chaque itÃ©ration, on peut sauvegarder l'Ã©tat complet en JSON :\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"phase\": \"TACTIC_GEN\",\n",
        "  \"strategy\": \"EXPLORATION\",\n",
        "  \"iteration\": 5,\n",
        "  \"current_goal\": \"n + 0 = n\",\n",
        "  \"tactic_history\": [...],\n",
        "  \"current_proof\": [\"intro n\", \"rw [Nat.add_zero]\"]\n",
        "}\n",
        "```\n",
        "\n",
        "**UtilitÃ©** : Debugging, reproduction de bugs, benchmarking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration chargee depuis: /mnt/d/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean/.env\n",
            "lean_runner importe avec succes depuis /mnt/d/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\n",
            "\n",
            "============================================================\n",
            "ProofState initialise avec succes\n",
            "LeanRunner disponible: True\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Section 8.1 - ProofState: Etat Partage pour Multi-Agents\n",
        "# =============================================================================\n",
        "# Pattern inspire de RhetoricalAnalysisState dans Argument_Analysis\n",
        "# Permet la synchronisation entre agents avec designation explicite\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import uuid\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional, Any, Tuple\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Detection robuste du repertoire du notebook ---\n",
        "# Fonctionne sous Windows, Linux, et WSL\n",
        "notebook_dir = None\n",
        "\n",
        "# Chemins connus (Windows et WSL)\n",
        "KNOWN_PATHS = [\n",
        "    Path(\"/mnt/d/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\"),  # WSL\n",
        "    Path(\"/mnt/c/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\"),  # WSL (C:)\n",
        "    Path(\"d:/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\"),      # Windows\n",
        "    Path(\"D:/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\"),      # Windows\n",
        "]\n",
        "\n",
        "# Strategie 1: Variable d'environnement LEAN_NOTEBOOK_DIR\n",
        "if os.getenv(\"LEAN_NOTEBOOK_DIR\"):\n",
        "    notebook_dir = Path(os.getenv(\"LEAN_NOTEBOOK_DIR\"))\n",
        "    if not (notebook_dir / \"lean_runner.py\").exists():\n",
        "        notebook_dir = None\n",
        "\n",
        "# Strategie 2: Chemins connus\n",
        "if not notebook_dir:\n",
        "    for known_path in KNOWN_PATHS:\n",
        "        if known_path.exists() and (known_path / \"lean_runner.py\").exists():\n",
        "            notebook_dir = known_path\n",
        "            break\n",
        "\n",
        "# Strategie 3: Chercher dans cwd et parents\n",
        "if not notebook_dir:\n",
        "    cwd = Path.cwd()\n",
        "    candidates = [cwd, cwd / \"MyIA.AI.Notebooks\" / \"SymbolicAI\" / \"Lean\"]\n",
        "\n",
        "    # Remonter jusqu'a 5 niveaux\n",
        "    current = cwd\n",
        "    for _ in range(5):\n",
        "        candidates.append(current)\n",
        "        lean_path = current / \"MyIA.AI.Notebooks\" / \"SymbolicAI\" / \"Lean\"\n",
        "        if lean_path.exists():\n",
        "            candidates.append(lean_path)\n",
        "        if current.parent == current:\n",
        "            break\n",
        "        current = current.parent\n",
        "\n",
        "    for candidate in candidates:\n",
        "        if candidate.exists() and (candidate / \"lean_runner.py\").exists():\n",
        "            notebook_dir = candidate\n",
        "            break\n",
        "\n",
        "# Strategie 4: Fallback sur cwd\n",
        "if not notebook_dir:\n",
        "    notebook_dir = Path.cwd()\n",
        "    print(f\"[WARN] lean_runner.py non trouve, fallback sur: {notebook_dir}\")\n",
        "\n",
        "# --- Charger .env ---\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    env_paths = [\n",
        "        notebook_dir / \".env\",\n",
        "        notebook_dir.parent / \".env\",\n",
        "        Path.home() / \".env\"\n",
        "    ]\n",
        "    for p in env_paths:\n",
        "        if p.exists():\n",
        "            load_dotenv(p, override=True)\n",
        "            print(f\"Configuration chargee depuis: {p}\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"Aucun fichier .env trouve\")\n",
        "except ImportError:\n",
        "    print(\"python-dotenv non installe\")\n",
        "\n",
        "# --- Importer lean_runner.py ---\n",
        "if notebook_dir and str(notebook_dir) not in sys.path:\n",
        "    sys.path.insert(0, str(notebook_dir))\n",
        "\n",
        "try:\n",
        "    from lean_runner import LeanRunner, LeanResult\n",
        "    print(f\"lean_runner importe avec succes depuis {notebook_dir}\")\n",
        "except ImportError as e:\n",
        "    print(f\"ERREUR: Impossible d'importer lean_runner: {e}\")\n",
        "    print(f\"Repertoire de travail: {Path.cwd()}\")\n",
        "    print(f\"notebook_dir detecte: {notebook_dir}\")\n",
        "    print(f\"sys.path: {sys.path[:5]}\")\n",
        "    raise\n",
        "\n",
        "# --- Enumerations ---\n",
        "\n",
        "class ProofStrategy(Enum):\n",
        "    \"\"\"Strategie de preuve en cours.\"\"\"\n",
        "    EXPLORATION = \"exploration\"      # Recherche initiale de lemmes\n",
        "    REFINEMENT = \"refinement\"        # Affinage des tactiques\n",
        "    VALIDATION = \"validation\"        # Verification finale\n",
        "    RECOVERY = \"recovery\"            # Recuperation apres echecs\n",
        "\n",
        "class TacticDifficulty(Enum):\n",
        "    \"\"\"Niveau de difficulte des tactiques.\"\"\"\n",
        "    SIMPLE = \"simple\"      # rfl, exact, omega\n",
        "    INTERMEDIATE = \"intermediate\"  # simp, ring, linarith\n",
        "    ADVANCED = \"advanced\"  # induction, cases\n",
        "\n",
        "class ProofPhase(Enum):\n",
        "    \"\"\"Phase de la boucle de preuve.\"\"\"\n",
        "    INIT = \"init\"\n",
        "    SEARCH = \"search\"\n",
        "    GENERATE = \"generate\"\n",
        "    VERIFY = \"verify\"\n",
        "    ANALYZE = \"analyze\"\n",
        "    COMPLETE = \"complete\"\n",
        "    FAILED = \"failed\"\n",
        "\n",
        "# --- ProofState: Etat partage entre agents ---\n",
        "\n",
        "@dataclass\n",
        "class TacticAttempt:\n",
        "    \"\"\"Une tentative de tactique.\"\"\"\n",
        "    tactic: str\n",
        "    success: bool\n",
        "    error: Optional[str] = None\n",
        "    timestamp: datetime = field(default_factory=datetime.now)\n",
        "    state_before: Optional[str] = None\n",
        "    confidence: Optional[float] = None\n",
        "    explanation: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class ProofState:\n",
        "    \"\"\"\n",
        "    Etat partage entre les agents pour la preuve d'un theoreme.\n",
        "    Permet la coordination sans couplage fort.\n",
        "    \"\"\"\n",
        "    # Identifiants\n",
        "    session_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])\n",
        "    theorem_name: str = \"\"\n",
        "    theorem_statement: str = \"\"\n",
        "\n",
        "    # Etat de la preuve\n",
        "    current_goal: str = \"\"\n",
        "    current_proof: List[str] = field(default_factory=list)\n",
        "    phase: ProofPhase = ProofPhase.INIT\n",
        "    strategy: ProofStrategy = ProofStrategy.EXPLORATION\n",
        "\n",
        "    # Resultats des agents\n",
        "    discovered_lemmas: List[str] = field(default_factory=list)\n",
        "    generated_tactics: List[str] = field(default_factory=list)\n",
        "    tactic_history: List[TacticAttempt] = field(default_factory=list)\n",
        "\n",
        "    # Metriques\n",
        "    iteration: int = 0\n",
        "    max_iterations: int = 10\n",
        "    start_time: datetime = field(default_factory=datetime.now)\n",
        "\n",
        "    # Erreurs et diagnostics\n",
        "    last_error: Optional[str] = None\n",
        "    final_proof: Optional[str] = None\n",
        "    error_count: int = 0\n",
        "\n",
        "    # Verification tracking\n",
        "    verification_results: List[Dict[str, Any]] = field(default_factory=list)\n",
        "    total_lean_time_ms: float = 0.0\n",
        "\n",
        "    # Agent designation for orchestration\n",
        "    _next_agent: Optional[str] = field(default=None, repr=False)\n",
        "\n",
        "    def add_tactic_attempt(self, tactic: str, state_before: Optional[str] = None,\n",
        "                           confidence: Optional[float] = None, explanation: Optional[str] = None,\n",
        "                           success: bool = False, error: Optional[str] = None) -> str:\n",
        "        \"\"\"Enregistre une tentative de tactique.\"\"\"\n",
        "        attempt_id = f\"attempt_{len(self.tactic_history) + 1}\"\n",
        "        self.tactic_history.append(TacticAttempt(\n",
        "            tactic=tactic,\n",
        "            success=success,\n",
        "            error=error,\n",
        "            state_before=state_before,\n",
        "            confidence=confidence,\n",
        "            explanation=explanation\n",
        "        ))\n",
        "        if success:\n",
        "            self.current_proof.append(tactic)\n",
        "        else:\n",
        "            self.error_count += 1\n",
        "            self.last_error = error\n",
        "        return attempt_id\n",
        "\n",
        "    def add_lemma(self, name: str, statement: str, namespace: str = \"\", relevance: float = 0.5) -> str:\n",
        "        \"\"\"Ajoute un lemme decouvert a la liste.\"\"\"\n",
        "        lemma_id = f\"{namespace}.{name}\" if namespace else name\n",
        "        lemma_info = f\"{lemma_id}: {statement} (relevance: {relevance})\"\n",
        "        if lemma_info not in self.discovered_lemmas:\n",
        "            self.discovered_lemmas.append(lemma_info)\n",
        "        return lemma_id\n",
        "\n",
        "    def get_context_summary(self) -> str:\n",
        "        \"\"\"Resume le contexte pour les agents.\"\"\"\n",
        "        return f\"\"\"\n",
        "Theoreme: {self.theorem_name}\n",
        "Enonce: {self.theorem_statement}\n",
        "But actuel: {self.current_goal}\n",
        "Phase: {self.phase.value}\n",
        "Strategie: {self.strategy.value}\n",
        "Iteration: {self.iteration}/{self.max_iterations}\n",
        "Tactiques reussies: {len(self.current_proof)}\n",
        "Erreurs: {self.error_count}\n",
        "Derniere erreur: {self.last_error or 'Aucune'}\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    # --- Properties for compatibility ---\n",
        "    @property\n",
        "    def tactics_history(self) -> List[TacticAttempt]:\n",
        "        \"\"\"Alias pour tactic_history (compatibilite).\"\"\"\n",
        "        return self.tactic_history\n",
        "\n",
        "    @property\n",
        "    def proof_complete(self) -> bool:\n",
        "        \"\"\"True si la preuve est complete.\"\"\"\n",
        "        return self.phase == ProofPhase.COMPLETE\n",
        "    \n",
        "    @proof_complete.setter\n",
        "    def proof_complete(self, value: bool):\n",
        "        \"\"\"Definit la completion de la preuve.\"\"\"\n",
        "        if value:\n",
        "            self.phase = ProofPhase.COMPLETE\n",
        "        elif self.phase == ProofPhase.COMPLETE:\n",
        "            self.phase = ProofPhase.VERIFY\n",
        "    \n",
        "    @property\n",
        "    def iteration_count(self) -> int:\n",
        "        \"\"\"Alias pour iteration (compatibilite).\"\"\"\n",
        "        return self.iteration\n",
        "    \n",
        "    @iteration_count.setter\n",
        "    def iteration_count(self, value: int):\n",
        "        \"\"\"Definit le compteur d'iterations.\"\"\"\n",
        "        self.iteration = value\n",
        "\n",
        "    def increment_iteration(self):\n",
        "        \"\"\"Incremente le compteur d'iterations.\"\"\"\n",
        "        self.iteration += 1\n",
        "    \n",
        "    def designate_next_agent(self, agent_name: str):\n",
        "        \"\"\"Designe l'agent qui doit intervenir ensuite.\"\"\"\n",
        "        self._next_agent = agent_name\n",
        "    \n",
        "    def consume_next_agent_designation(self) -> Optional[str]:\n",
        "        \"\"\"Retourne et efface la designation d'agent.\"\"\"\n",
        "        agent = self._next_agent\n",
        "        self._next_agent = None\n",
        "        return agent\n",
        "    \n",
        "    def get_state_snapshot(self, summarize: bool = True) -> Dict[str, Any]:\n",
        "        \"\"\"Retourne un snapshot de l'etat pour les plugins.\"\"\"\n",
        "        if summarize:\n",
        "            return {\n",
        "                \"session_id\": self.session_id,\n",
        "                \"theorem\": self.theorem_statement,\n",
        "                \"goal\": self.current_goal,\n",
        "                \"phase\": self.phase.value,\n",
        "                \"strategy\": self.strategy.value,\n",
        "                \"iteration\": f\"{self.iteration}/{self.max_iterations}\",\n",
        "                \"proof_steps\": len(self.current_proof),\n",
        "                \"discovered_lemmas\": len(self.discovered_lemmas),\n",
        "                \"errors\": self.error_count,\n",
        "                \"last_error\": self.last_error\n",
        "            }\n",
        "        else:\n",
        "            return self.to_dict()\n",
        "\n",
        "\n",
        "    def add_verification(self, attempt_id: str, success: bool, output: str, errors: str,\n",
        "                         remaining_goals: Optional[str] = None, exec_time_ms: float = 0.0,\n",
        "                         mode: str = \"subprocess\") -> str:\n",
        "        \"\"\"Enregistre un rÃ©sultat de vÃ©rification Lean.\"\"\"\n",
        "        verif_id = f\"verif_{len(self.verification_results) + 1}\"\n",
        "        self.verification_results.append({\n",
        "            \"id\": verif_id,\n",
        "            \"attempt_id\": attempt_id,\n",
        "            \"success\": success,\n",
        "            \"output\": output,\n",
        "            \"errors\": errors,\n",
        "            \"remaining_goals\": remaining_goals,\n",
        "            \"exec_time_ms\": exec_time_ms,\n",
        "            \"mode\": mode,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "        return verif_id\n",
        "\n",
        "\n",
        "    def set_proof_complete(self, proof: str):\n",
        "        \"\"\"Marque la preuve comme terminÃ©e et change la phase.\"\"\"\n",
        "        self.final_proof = proof\n",
        "        self.phase = ProofPhase.COMPLETE\n",
        "\n",
        "\n",
        "    def set_strategy(self, strategy: 'ProofStrategy'):\n",
        "        \"\"\"Change la stratÃ©gie de preuve.\"\"\"\n",
        "        self.strategy = strategy\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Serialise l'etat.\"\"\"\n",
        "        return {\n",
        "            \"session_id\": self.session_id,\n",
        "            \"theorem_name\": self.theorem_name,\n",
        "            \"theorem_statement\": self.theorem_statement,\n",
        "            \"current_goal\": self.current_goal,\n",
        "            \"current_proof\": self.current_proof,\n",
        "            \"phase\": self.phase.value,\n",
        "            \"strategy\": self.strategy.value,\n",
        "            \"discovered_lemmas\": self.discovered_lemmas,\n",
        "            \"generated_tactics\": self.generated_tactics,\n",
        "            \"iteration\": self.iteration,\n",
        "            \"max_iterations\": self.max_iterations,\n",
        "            \"error_count\": self.error_count,\n",
        "            \"last_error\": self.last_error\n",
        "        }\n",
        "\n",
        "# --- Test de l'initialisation ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ProofState initialise avec succes\")\n",
        "print(f\"LeanRunner disponible: {LeanRunner is not None}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2-8.5 Plugins Semantic Kernel\n",
        "\n",
        "L'architecture utilise 4 plugins specialises, chacun exposant des fonctions via `@kernel_function`:\n",
        "\n",
        "| Plugin | Role | Fonctions cles |\n",
        "|--------|------|----------------|\n",
        "| **ProofStateManagerPlugin** | Gestion de l'etat | get_proof_state, add_lemma, designate_next_agent |\n",
        "| **LeanSearchPlugin** | Recherche Mathlib | search_mathlib_lemmas, check_lemma_type |\n",
        "| **LeanTacticPlugin** | Generation tactiques | generate_tactics, analyze_tactic_failure |\n",
        "| **LeanVerificationPlugin** | Verification Lean | verify_proof, verify_tactic_step |\n",
        "\n",
        "Ce pattern permet aux agents d'appeler ces fonctions automatiquement grace au `FunctionChoiceBehavior.Auto()` de Semantic Kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”Œ Plugins Semantic Kernel : Exposer l'Ã‰tat aux Agents\n",
        "\n",
        "### ProblÃ¨me\n",
        "\n",
        "Les agents LLM ne peuvent pas accÃ©der directement Ã  `ProofState` (objet Python).\n",
        "\n",
        "### Solution : Plugins\n",
        "\n",
        "Un **plugin Semantic Kernel** expose des mÃ©thodes Python comme **fonctions appelables par le LLM**.\n",
        "\n",
        "```python\n",
        "@kernel_function(\n",
        "    description=\"Enregistre une tentative de tactique\",\n",
        "    name=\"log_tactic_attempt\"\n",
        ")\n",
        "def log_tactic_attempt(self, tactic: str, confidence: float) -> str:\n",
        "    attempt_id = self._state.add_tactic_attempt(tactic, confidence=confidence)\n",
        "    return f\"Tactique {tactic} enregistrÃ©e avec ID {attempt_id}\"\n",
        "```\n",
        "\n",
        "### DÃ©corateur `@kernel_function`\n",
        "\n",
        "- `description` : Ce que le LLM voit (\"Ã€ quoi sert cette fonction ?\")\n",
        "- `name` : Nom de la fonction pour le LLM\n",
        "- ParamÃ¨tres : Doivent correspondre **EXACTEMENT** Ã  ce que le plugin appelle\n",
        "\n",
        "### Les 4 plugins\n",
        "\n",
        "1. **log_tactic_attempt** : Enregistrer une tactique essayÃ©e\n",
        "2. **add_verification_result** : Enregistrer le rÃ©sultat Lean\n",
        "3. **set_proof_strategy** : Changer la stratÃ©gie de recherche\n",
        "4. **mark_proof_complete** : DÃ©clarer la preuve terminÃ©e\n",
        "\n",
        "### Pourquoi c'est critique ?\n",
        "\n",
        "Sans plugins, le LLM ne peut que **parler** de preuves. Avec plugins, il peut **agir** :\n",
        "\n",
        "- Essayer des tactiques\n",
        "- VÃ©rifier formellement\n",
        "- Ajuster sa stratÃ©gie en temps rÃ©el"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Section 8.2-8.5 - Plugins Semantic Kernel\n",
        "# =============================================================================\n",
        "# Architecture en 4 plugins specialises:\n",
        "# - ProofStateManagerPlugin: Gestion de l'etat partage\n",
        "# - LeanSearchPlugin: Recherche de lemmes Mathlib\n",
        "# - LeanTacticPlugin: Generation de tactiques\n",
        "# - LeanVerificationPlugin: Verification avec lean_runner.py\n",
        "\n",
        "# Import du decorateur kernel_function\n",
        "try:\n",
        "    from semantic_kernel.functions import kernel_function\n",
        "    SK_AVAILABLE = True\n",
        "    print(\"Semantic Kernel disponible - utilisation des vrais decorateurs\")\n",
        "except ImportError:\n",
        "    SK_AVAILABLE = False\n",
        "    print(\"Semantic Kernel non disponible - mode simulation\")\n",
        "    # Decorateur de simulation\n",
        "    def kernel_function(description=\"\", name=None):\n",
        "        def decorator(func):\n",
        "            func._sk_function = True\n",
        "            func._sk_description = description\n",
        "            func._sk_name = name or func.__name__\n",
        "            return func\n",
        "        return decorator\n",
        "\n",
        "# =============================================================================\n",
        "# 8.2 ProofStateManagerPlugin\n",
        "# =============================================================================\n",
        "\n",
        "class ProofStateManagerPlugin:\n",
        "    \"\"\"\n",
        "    Plugin pour gerer l'etat partage de la preuve.\n",
        "    Expose les methodes de ProofState via @kernel_function.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, state: ProofState):\n",
        "        self._state = state\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Obtient un apercu de l'etat actuel de la preuve (theoreme, lemmes, tactiques, etc.)\",\n",
        "        name=\"get_proof_state\"\n",
        "    )\n",
        "    def get_proof_state(self, summarize: bool = True) -> str:\n",
        "        \"\"\"Retourne l'etat actuel sous forme JSON.\"\"\"\n",
        "        snapshot = self._state.get_state_snapshot(summarize=summarize)\n",
        "        return json.dumps(snapshot, indent=2, ensure_ascii=False)\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Ajoute un lemme decouvert a l'etat partage\",\n",
        "        name=\"add_discovered_lemma\"\n",
        "    )\n",
        "    def add_discovered_lemma(\n",
        "        self, name: str, statement: str, namespace: str = \"\", relevance: float = 0.5\n",
        "    ) -> str:\n",
        "        \"\"\"Enregistre un lemme trouve par SearchAgent.\"\"\"\n",
        "        lemma_id = self._state.add_lemma(name, statement, namespace, relevance)\n",
        "        return f\"Lemme ajoute: {lemma_id} ({name})\"\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Enregistre une tentative de tactique avec son niveau de confiance\",\n",
        "        name=\"log_tactic_attempt\"\n",
        "    )\n",
        "    def log_tactic_attempt(\n",
        "        self, tactic: str, state_before: str, confidence: float = 0.5, explanation: str = \"\"\n",
        "    ) -> str:\n",
        "        \"\"\"Enregistre une tactique tentee par TacticAgent.\"\"\"\n",
        "        attempt_id = self._state.add_tactic_attempt(tactic, state_before, confidence, explanation)\n",
        "        return f\"Tactique enregistree: {attempt_id}\"\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Enregistre le resultat d'une verification Lean\",\n",
        "        name=\"add_verification_result\"\n",
        "    )\n",
        "    def add_verification_result(\n",
        "        self, attempt_id: str, success: bool, output: str, errors: str,\n",
        "        remaining_goals: str = \"\", exec_time_ms: float = 0.0\n",
        "    ) -> str:\n",
        "        \"\"\"Enregistre un resultat de verification.\"\"\"\n",
        "        verif_id = self._state.add_verification(\n",
        "            attempt_id, success, output, errors,\n",
        "            remaining_goals if remaining_goals else None, exec_time_ms, \"subprocess\"\n",
        "        )\n",
        "        status = \"OK\" if success else \"ECHEC\"\n",
        "        return f\"Verification {verif_id}: {status}\"\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Designe l'agent qui doit parler au prochain tour. IMPORTANT: utiliser le nom exact.\",\n",
        "        name=\"designate_next_agent\"\n",
        "    )\n",
        "    def designate_next_agent(self, agent_name: str) -> str:\n",
        "        \"\"\"Delegue au prochain agent.\"\"\"\n",
        "        valid_agents = [\"SearchAgent\", \"TacticAgent\", \"VerifierAgent\", \"CriticAgent\", \"CoordinatorAgent\"]\n",
        "        if agent_name not in valid_agents:\n",
        "            return f\"ERREUR: Agent invalide '{agent_name}'. Valides: {valid_agents}\"\n",
        "        self._state.designate_next_agent(agent_name)\n",
        "        return f\"Prochain agent: {agent_name}\"\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Marque la preuve comme terminee avec le code final\",\n",
        "        name=\"set_proof_complete\"\n",
        "    )\n",
        "    def set_proof_complete(self, proof_code: str) -> str:\n",
        "        \"\"\"Marque la preuve comme reussie.\"\"\"\n",
        "        self._state.set_proof_complete(proof_code)\n",
        "        return f\"PREUVE COMPLETE! Code: {proof_code[:100]}...\"\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Change la strategie de preuve (exploration, refinement, validation, recovery)\",\n",
        "        name=\"set_proof_strategy\"\n",
        "    )\n",
        "    def set_proof_strategy(self, strategy: str) -> str:\n",
        "        \"\"\"Change la strategie de preuve.\"\"\"\n",
        "        try:\n",
        "            self._state.set_strategy(ProofStrategy(strategy))\n",
        "            return f\"Strategie changee: {strategy}\"\n",
        "        except ValueError:\n",
        "            return f\"ERREUR: Strategie invalide '{strategy}'. Valides: exploration, refinement, validation, recovery\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 8.3 LeanSearchPlugin\n",
        "# =============================================================================\n",
        "\n",
        "class LeanSearchPlugin:\n",
        "    \"\"\"\n",
        "    Plugin pour la recherche de lemmes dans Mathlib.\n",
        "    Utilise des patterns connus + verification #check via lean_runner.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, runner: LeanRunner):\n",
        "        self._runner = runner\n",
        "        # Base de lemmes connus (extensible)\n",
        "        self._known_lemmas = {\n",
        "            # Arithmetique de base\n",
        "            \"Nat.add_zero\": (\"n + 0 = n\", \"Nat\"),\n",
        "            \"Nat.zero_add\": (\"0 + n = n\", \"Nat\"),\n",
        "            \"Nat.add_comm\": (\"n + m = m + n\", \"Nat\"),\n",
        "            \"Nat.add_assoc\": (\"(n + m) + k = n + (m + k)\", \"Nat\"),\n",
        "            \"Nat.mul_one\": (\"n * 1 = n\", \"Nat\"),\n",
        "            \"Nat.one_mul\": (\"1 * n = n\", \"Nat\"),\n",
        "            \"Nat.mul_comm\": (\"n * m = m * n\", \"Nat\"),\n",
        "            \"Nat.mul_assoc\": (\"(n * m) * k = n * (m * k)\", \"Nat\"),\n",
        "            \"Nat.left_distrib\": (\"n * (m + k) = n * m + n * k\", \"Nat\"),\n",
        "            \"Nat.right_distrib\": (\"(n + m) * k = n * k + m * k\", \"Nat\"),\n",
        "            # Logique\n",
        "            \"And.intro\": (\"a -> b -> a /\\\\ b\", \"Logic\"),\n",
        "            \"And.left\": (\"a /\\\\ b -> a\", \"Logic\"),\n",
        "            \"And.right\": (\"a /\\\\ b -> b\", \"Logic\"),\n",
        "            \"Or.inl\": (\"a -> a \\\\/ b\", \"Logic\"),\n",
        "            \"Or.inr\": (\"b -> a \\\\/ b\", \"Logic\"),\n",
        "            \"Eq.refl\": (\"a = a\", \"Logic\"),\n",
        "            \"Eq.symm\": (\"a = b -> b = a\", \"Logic\"),\n",
        "            \"Eq.trans\": (\"a = b -> b = c -> a = c\", \"Logic\"),\n",
        "        }\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Recherche des lemmes Mathlib pertinents pour un but donne\",\n",
        "        name=\"search_mathlib_lemmas\"\n",
        "    )\n",
        "    def search_mathlib_lemmas(self, goal: str, max_results: int = 10) -> str:\n",
        "        \"\"\"\n",
        "        Recherche des lemmes par mots-cles.\n",
        "\n",
        "        Args:\n",
        "            goal: Description du but ou mots-cles (ex: \"addition commutative\")\n",
        "            max_results: Nombre maximum de resultats\n",
        "\n",
        "        Returns:\n",
        "            JSON avec les lemmes trouves\n",
        "        \"\"\"\n",
        "        goal_lower = goal.lower()\n",
        "        results = []\n",
        "\n",
        "        # Recherche par mots-cles\n",
        "        keywords = goal_lower.replace(\"+\", \"add\").replace(\"*\", \"mul\").replace(\"=\", \"eq\").split()\n",
        "\n",
        "        for name, (statement, namespace) in self._known_lemmas.items():\n",
        "            score = 0.0\n",
        "            name_lower = name.lower()\n",
        "\n",
        "            # Scoring par mots-cles\n",
        "            for kw in keywords:\n",
        "                if kw in name_lower:\n",
        "                    score += 0.3\n",
        "                if kw in statement.lower():\n",
        "                    score += 0.2\n",
        "\n",
        "            # Patterns specifiques\n",
        "            if \"comm\" in goal_lower and \"comm\" in name_lower:\n",
        "                score += 0.4\n",
        "            if \"assoc\" in goal_lower and \"assoc\" in name_lower:\n",
        "                score += 0.4\n",
        "            if \"zero\" in goal_lower and \"zero\" in name_lower:\n",
        "                score += 0.3\n",
        "            if \"distrib\" in goal_lower and \"distrib\" in name_lower:\n",
        "                score += 0.4\n",
        "\n",
        "            if score > 0:\n",
        "                results.append({\n",
        "                    \"name\": name,\n",
        "                    \"statement\": statement,\n",
        "                    \"namespace\": namespace,\n",
        "                    \"relevance\": min(score, 1.0)\n",
        "                })\n",
        "\n",
        "        # Trier par pertinence\n",
        "        results.sort(key=lambda x: x[\"relevance\"], reverse=True)\n",
        "        return json.dumps(results[:max_results], indent=2, ensure_ascii=False)\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Verifie qu'un lemme existe et retourne son type via #check\",\n",
        "        name=\"check_lemma_type\"\n",
        "    )\n",
        "    def check_lemma_type(self, lemma_name: str) -> str:\n",
        "        \"\"\"\n",
        "        Verifie l'existence d'un lemme via #check.\n",
        "\n",
        "        Args:\n",
        "            lemma_name: Nom du lemme (ex: \"Nat.add_comm\")\n",
        "\n",
        "        Returns:\n",
        "            JSON {exists, type, error}\n",
        "        \"\"\"\n",
        "        code = f\"#check {lemma_name}\"\n",
        "        result = self._runner.run(code)\n",
        "\n",
        "        if result.success and not result.errors:\n",
        "            # Extraire le type de la sortie\n",
        "            return json.dumps({\n",
        "                \"exists\": True,\n",
        "                \"type\": result.output.strip(),\n",
        "                \"error\": None\n",
        "            })\n",
        "        else:\n",
        "            return json.dumps({\n",
        "                \"exists\": False,\n",
        "                \"type\": None,\n",
        "                \"error\": result.errors or \"Lemme non trouve\"\n",
        "            })\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 8.4 LeanTacticPlugin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4-8.5 Plugins de Tactiques et Verification\n",
        "\n",
        "Les deux plugins restants gerent la **generation de tactiques** et la **verification formelle** :\n",
        "\n",
        "#### LeanTacticPlugin\n",
        "\n",
        "- **Responsabilite** : Generer des tactiques Lean adaptees au contexte\n",
        "- **Methodes exposees** :\n",
        "  - `generate_tactic()` : Genere une tactique basee sur goal + lemmes + historique\n",
        "  - `estimate_confidence()` : Estime la probabilite de succes (0.0-1.0)\n",
        "- **LLM-aware** : Utilise un prompt structure pour le LLM avec exemples de tactiques Lean\n",
        "- **Strategies** : `exact`, `rw`, `apply`, `simp`, `induction`, `cases`, etc.\n",
        "\n",
        "#### LeanVerificationPlugin\n",
        "\n",
        "- **Responsabilite** : Verifier les preuves via compilation Lean\n",
        "- **Methodes exposees** :\n",
        "  - `verify_proof()` : Compile le theoreme avec tactiques et retourne succes/echec\n",
        "  - `parse_lean_errors()` : Parse les messages d'erreur Lean pour feedback agents\n",
        "- **Detection de completion** : Reconnait \"no goals\" = preuve complete\n",
        "- **Gestion d'erreurs** : Extrait type d'erreur (type mismatch, tactic failed, etc.) pour CriticAgent\n",
        "\n",
        "**Flow typique** :\n",
        "```\n",
        "SearchAgent trouve lemmes\n",
        "   |\n",
        "   v\n",
        "TacticAgent genere tactique (via LeanTacticPlugin)\n",
        "   |\n",
        "   v\n",
        "VerifierAgent compile (via LeanVerificationPlugin)\n",
        "   |\n",
        "   +-- Success â†’ COMPLETE\n",
        "   +-- Failure â†’ CriticAgent analyse â†’ retry\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "\n",
        "class LeanTacticPlugin:\n",
        "    \"\"\"\n",
        "    Plugin pour la generation de tactiques.\n",
        "    Fournit des heuristiques et analyse les echecs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Tactiques par difficulte\n",
        "        self._tactics = {\n",
        "            \"simple\": [\"rfl\", \"trivial\", \"exact ?_\", \"assumption\"],\n",
        "            \"medium\": [\"simp\", \"omega\", \"decide\", \"constructor\", \"intro\", \"apply\"],\n",
        "            \"complex\": [\"ring\", \"linarith\", \"aesop\", \"induction\", \"cases\", \"rcases\"]\n",
        "        }\n",
        "\n",
        "        # Heuristiques par pattern de but\n",
        "        self._heuristics = {\n",
        "            \"equality\": [\"rfl\", \"exact\", \"simp\", \"ring\", \"omega\"],\n",
        "            \"forall\": [\"intro\", \"intros\", \"apply\"],\n",
        "            \"exists\": [\"use\", \"exists\", \"exact\"],\n",
        "            \"and\": [\"constructor\", \"exact And.intro\"],\n",
        "            \"or\": [\"left\", \"right\"],\n",
        "            \"implication\": [\"intro\", \"apply\", \"exact\"],\n",
        "            \"nat_arithmetic\": [\"omega\", \"simp\", \"decide\"],\n",
        "            \"ring_expression\": [\"ring\", \"ring_nf\"]\n",
        "        }\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Genere des tactiques appropriees pour un but donne\",\n",
        "        name=\"generate_tactics\"\n",
        "    )\n",
        "    def generate_tactics(self, goal: str, context: str = \"\", difficulty: str = \"simple\") -> str:\n",
        "        \"\"\"\n",
        "        Genere des tactiques pour le but courant.\n",
        "\n",
        "        Args:\n",
        "            goal: Le but Lean a prouver\n",
        "            context: Contexte additionnel (lemmes disponibles, etc.)\n",
        "            difficulty: simple, medium, ou complex\n",
        "\n",
        "        Returns:\n",
        "            JSON [{tactic, confidence, explanation}]\n",
        "        \"\"\"\n",
        "        suggestions = []\n",
        "        goal_lower = goal.lower()\n",
        "\n",
        "        # Detecter le type de but\n",
        "        detected_patterns = []\n",
        "        if \"=\" in goal:\n",
        "            detected_patterns.append(\"equality\")\n",
        "        if \"forall\" in goal_lower or \"âˆ€\" in goal:\n",
        "            detected_patterns.append(\"forall\")\n",
        "        if \"exists\" in goal_lower or \"âˆƒ\" in goal:\n",
        "            detected_patterns.append(\"exists\")\n",
        "        if \"/\\\\\" in goal or \"âˆ§\" in goal or \"And\" in goal:\n",
        "            detected_patterns.append(\"and\")\n",
        "        if \"\\\\/\" in goal or \"âˆ¨\" in goal or \"Or\" in goal:\n",
        "            detected_patterns.append(\"or\")\n",
        "        if \"->\" in goal or \"â†’\" in goal:\n",
        "            detected_patterns.append(\"implication\")\n",
        "        if any(x in goal_lower for x in [\"nat\", \"n +\", \"m +\", \"+ 0\", \"0 +\"]):\n",
        "            detected_patterns.append(\"nat_arithmetic\")\n",
        "        if any(x in goal for x in [\"*\", \"+\"]) and \"=\" in goal:\n",
        "            detected_patterns.append(\"ring_expression\")\n",
        "\n",
        "        # Collecter les tactiques suggeres\n",
        "        seen = set()\n",
        "        for pattern in detected_patterns:\n",
        "            for tactic in self._heuristics.get(pattern, []):\n",
        "                if tactic not in seen:\n",
        "                    seen.add(tactic)\n",
        "                    confidence = 0.7 if difficulty == \"simple\" else 0.5\n",
        "                    suggestions.append({\n",
        "                        \"tactic\": tactic,\n",
        "                        \"confidence\": confidence,\n",
        "                        \"explanation\": f\"Pattern detecte: {pattern}\"\n",
        "                    })\n",
        "\n",
        "        # Ajouter des tactiques de base\n",
        "        base_tactics = self._tactics.get(difficulty, self._tactics[\"simple\"])\n",
        "        for tactic in base_tactics[:3]:\n",
        "            if tactic not in seen:\n",
        "                suggestions.append({\n",
        "                    \"tactic\": tactic,\n",
        "                    \"confidence\": 0.3,\n",
        "                    \"explanation\": f\"Tactique {difficulty} generique\"\n",
        "                })\n",
        "\n",
        "        # Trier par confiance\n",
        "        suggestions.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
        "        return json.dumps(suggestions[:8], indent=2, ensure_ascii=False)\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Analyse un echec de tactique et suggere des alternatives\",\n",
        "        name=\"analyze_tactic_failure\"\n",
        "    )\n",
        "    def analyze_tactic_failure(self, failed_tactic: str, error_msg: str) -> str:\n",
        "        \"\"\"\n",
        "        Analyse pourquoi une tactique a echoue.\n",
        "\n",
        "        Args:\n",
        "            failed_tactic: La tactique qui a echoue\n",
        "            error_msg: Message d'erreur Lean\n",
        "\n",
        "        Returns:\n",
        "            JSON {diagnosis, alternatives, error_type}\n",
        "        \"\"\"\n",
        "        error_lower = error_msg.lower()\n",
        "        diagnosis = \"\"\n",
        "        alternatives = []\n",
        "        error_type = \"unknown\"\n",
        "\n",
        "        # Classifier l'erreur\n",
        "        if \"unknown identifier\" in error_lower or \"unknown constant\" in error_lower:\n",
        "            error_type = \"unknown_identifier\"\n",
        "            diagnosis = \"Lemme ou identifiant non reconnu. Verifier l'import ou le nom.\"\n",
        "            alternatives = [\"Chercher le bon nom avec #check\", \"Verifier les imports\"]\n",
        "\n",
        "        elif \"type mismatch\" in error_lower:\n",
        "            error_type = \"type_mismatch\"\n",
        "            diagnosis = \"Les types ne correspondent pas. Verifier les arguments.\"\n",
        "            alternatives = [\"exact\", \"apply\", \"simp\"]\n",
        "\n",
        "        elif \"unsolved goals\" in error_lower or \"goals remain\" in error_lower:\n",
        "            error_type = \"unsolved_goals\"\n",
        "            diagnosis = \"Des sous-buts restent. La tactique n'a pas complete la preuve.\"\n",
        "            alternatives = [\"Ajouter d'autres tactiques\", \"Essayer simp\", \"Decomposer avec have\"]\n",
        "\n",
        "        elif \"tactic failed\" in error_lower:\n",
        "            error_type = \"tactic_failed\"\n",
        "            diagnosis = f\"La tactique '{failed_tactic}' n'a pas pu s'appliquer.\"\n",
        "            # Suggerer des alternatives\n",
        "            if failed_tactic in [\"ring\", \"linarith\"]:\n",
        "                alternatives = [\"omega\", \"simp\", \"decide\"]\n",
        "            elif failed_tactic == \"simp\":\n",
        "                alternatives = [\"simp only\", \"rfl\", \"exact\"]\n",
        "            else:\n",
        "                alternatives = [\"simp\", \"omega\", \"exact ?_\"]\n",
        "\n",
        "        elif \"declaration uses 'sorry'\" in error_lower:\n",
        "            error_type = \"sorry\"\n",
        "            diagnosis = \"La preuve contient 'sorry' - incomplete.\"\n",
        "            alternatives = [\"Completer la preuve\", \"Remplacer sorry par une vraie tactique\"]\n",
        "\n",
        "        else:\n",
        "            error_type = \"other\"\n",
        "            diagnosis = f\"Erreur non classifiee: {error_msg[:100]}\"\n",
        "            alternatives = [\"Verifier la syntaxe\", \"Essayer une approche differente\"]\n",
        "\n",
        "        return json.dumps({\n",
        "            \"diagnosis\": diagnosis,\n",
        "            \"alternatives\": alternatives,\n",
        "            \"error_type\": error_type,\n",
        "            \"original_error\": error_msg[:200]\n",
        "        }, indent=2, ensure_ascii=False)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 8.5 LeanVerificationPlugin\n",
        "# =============================================================================\n",
        "\n",
        "class LeanVerificationPlugin:\n",
        "    \"\"\"\n",
        "    Plugin pour la verification des preuves avec lean_runner.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, runner: LeanRunner):\n",
        "        self._runner = runner\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Verifie une preuve complete (theoreme + tactiques)\",\n",
        "        name=\"verify_proof\"\n",
        "    )\n",
        "    def verify_proof(self, theorem_statement: str, proof_tactics: str) -> str:\n",
        "        \"\"\"\n",
        "        Verifie un theoreme avec sa preuve.\n",
        "\n",
        "        Args:\n",
        "            theorem_statement: L'enonce du theoreme (ex: \"theorem add_zero (n : Nat) : n + 0 = n\")\n",
        "            proof_tactics: La preuve (ex: \"exact Nat.add_zero n\")\n",
        "\n",
        "        Returns:\n",
        "            JSON {success, output, errors, exec_time_ms, backend}\n",
        "        \"\"\"\n",
        "        import time\n",
        "\n",
        "        # Construire le code complet\n",
        "        if \"by\" not in proof_tactics and \":=\" not in proof_tactics:\n",
        "            code = f\"{theorem_statement} := by {proof_tactics}\"\n",
        "        elif \":=\" in proof_tactics:\n",
        "            code = f\"{theorem_statement} {proof_tactics}\"\n",
        "        else:\n",
        "            code = f\"{theorem_statement} := {proof_tactics}\"\n",
        "\n",
        "        start = time.time()\n",
        "        result = self._runner.run(code)\n",
        "        exec_time = (time.time() - start) * 1000\n",
        "\n",
        "        return json.dumps({\n",
        "            \"success\": result.success,\n",
        "            \"output\": result.output,\n",
        "            \"errors\": result.errors,\n",
        "            \"exit_code\": result.exit_code,\n",
        "            \"exec_time_ms\": round(exec_time, 2),\n",
        "            \"backend\": result.backend,\n",
        "            \"code\": code\n",
        "        }, indent=2, ensure_ascii=False)\n",
        "\n",
        "    @kernel_function(\n",
        "        description=\"Verifie une etape de tactique incrementale\",\n",
        "        name=\"verify_tactic_step\"\n",
        "    )\n",
        "    def verify_tactic_step(\n",
        "        self, partial_proof: str, next_tactic: str, theorem_statement: str\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Verifie une tactique incrementale.\n",
        "\n",
        "        Args:\n",
        "            partial_proof: Les tactiques deja appliquees (separees par ;)\n",
        "            next_tactic: La prochaine tactique a essayer\n",
        "            theorem_statement: L'enonce du theoreme\n",
        "\n",
        "        Returns:\n",
        "            JSON {tactic_valid, remaining_goals, error, exec_time_ms}\n",
        "        \"\"\"\n",
        "        import time\n",
        "\n",
        "        # Combiner les tactiques\n",
        "        if partial_proof:\n",
        "            all_tactics = f\"{partial_proof}; {next_tactic}\"\n",
        "        else:\n",
        "            all_tactics = next_tactic\n",
        "\n",
        "        code = f\"{theorem_statement} := by {all_tactics}\"\n",
        "\n",
        "        start = time.time()\n",
        "        result = self._runner.run(code)\n",
        "        exec_time = (time.time() - start) * 1000\n",
        "\n",
        "        # Analyser les goals restants\n",
        "        remaining_goals = None\n",
        "        if \"unsolved goals\" in result.errors.lower():\n",
        "            # Extraire les goals du message d'erreur\n",
        "            remaining_goals = result.errors\n",
        "\n",
        "        return json.dumps({\n",
        "            \"tactic_valid\": result.success or \"unsolved goals\" not in result.errors.lower(),\n",
        "            \"remaining_goals\": remaining_goals,\n",
        "            \"error\": result.errors if not result.success else None,\n",
        "            \"exec_time_ms\": round(exec_time, 2),\n",
        "            \"applied_tactics\": all_tactics\n",
        "        }, indent=2, ensure_ascii=False)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Test des Plugins\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n=== Test des Plugins ===\")\n",
        "\n",
        "# Creer l'etat et le runner\n",
        "test_state = ProofState(theorem_statement=\"theorem test_add (n : Nat) : n + 0 = n\")\n",
        "runner = LeanRunner(backend=\"subprocess\", timeout=30)\n",
        "\n",
        "# Instancier les plugins\n",
        "state_plugin = ProofStateManagerPlugin(test_state)\n",
        "search_plugin = LeanSearchPlugin(runner)\n",
        "tactic_plugin = LeanTacticPlugin()\n",
        "verif_plugin = LeanVerificationPlugin(runner)\n",
        "\n",
        "# Test 1: Recherche de lemmes\n",
        "print(\"\\n1. Recherche de lemmes pour 'addition zero':\")\n",
        "lemmas = search_plugin.search_mathlib_lemmas(\"addition zero\", max_results=3)\n",
        "print(lemmas)\n",
        "\n",
        "# Test 2: Generation de tactiques\n",
        "print(\"\\n2. Tactiques pour 'n + 0 = n':\")\n",
        "tactics = tactic_plugin.generate_tactics(\"n + 0 = n\", difficulty=\"simple\")\n",
        "print(tactics)\n",
        "\n",
        "# Test 3: Verification avec lean_runner\n",
        "print(\"\\n3. Verification d'une preuve:\")\n",
        "result = verif_plugin.verify_proof(\"theorem test_rfl : 2 + 2 = 4\", \"rfl\")\n",
        "print(result)\n",
        "\n",
        "# Test 4: Plugin StateManager\n",
        "print(\"\\n4. Ajout via StateManagerPlugin:\")\n",
        "print(state_plugin.add_discovered_lemma(\"Nat.add_zero\", \"n + 0 = n\", \"Nat\", 0.9))\n",
        "print(state_plugin.get_proof_state(summarize=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.6 Definition des 5 Agents Specialises\n",
        "\n",
        "Le systeme multi-agents comprend 5 roles distincts:\n",
        "\n",
        "| Agent | Role | Plugins | Delegation |\n",
        "|-------|------|---------|------------|\n",
        "| **SearchAgent** | Recherche lemmes Mathlib | LeanSearch, StateManager | TacticAgent si lemmes trouves |\n",
        "| **TacticAgent** | Generation tactiques | LeanTactic, StateManager | VerifierAgent pour validation |\n",
        "| **VerifierAgent** | Verification Lean | LeanVerification, StateManager | CriticAgent si echec |\n",
        "| **CriticAgent** | Analyse echecs | LeanTactic, StateManager | Redirection selon erreur |\n",
        "| **CoordinatorAgent** | Supervision globale | StateManager | Gestion des blocages |\n",
        "\n",
        "**Pattern cle**: Chaque agent designe explicitement le suivant via `designate_next_agent()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– CrÃ©ation des Agents Semantic Kernel\n",
        "\n",
        "### Anatomie d'un agent\n",
        "\n",
        "Chaque agent a :\n",
        "\n",
        "1. **Un nom** : \"SearchAgent\", \"TacticAgent\", etc.\n",
        "2. **Des instructions** : Prompt systÃ¨me qui dÃ©finit son rÃ´le\n",
        "3. **Des plugins** : Fonctions qu'il peut appeler (via StatePlugin)\n",
        "4. **Un modÃ¨le LLM** : GPT-5.2, Claude, etc.\n",
        "\n",
        "### Exemple : SearchAgent\n",
        "\n",
        "```python\n",
        "search_agent = kernel.add_agent(\n",
        "    name=\"SearchAgent\",\n",
        "    instructions=\"\"\"Tu es un expert en recherche de lemmes Mathlib.\n",
        "    Ton rÃ´le : Trouver les lemmes pertinents pour le but actuel.\n",
        "    DÃ©lÃ¨gue Ã  TacticAgent une fois les lemmes trouvÃ©s.\"\"\",\n",
        "    plugins=[state_plugin]\n",
        ")\n",
        "```\n",
        "\n",
        "### Instructions : Le \"mÃ©tier\" de l'agent\n",
        "\n",
        "Les instructions dÃ©finissent :\n",
        "\n",
        "- **ResponsabilitÃ©** : \"Recherche de lemmes\" vs \"GÃ©nÃ©ration de tactiques\"\n",
        "- **CritÃ¨res de succÃ¨s** : \"Trouver au moins 2 lemmes pertinents\"\n",
        "- **DÃ©lÃ©gation** : \"Quand dÃ©lÃ©guer Ã  un autre agent ?\"\n",
        "\n",
        "**Principe clÃ©** : Instructions prÃ©cises â†’ Comportement prÃ©visible\n",
        "\n",
        "### Pattern : StratÃ©gies basÃ©es sur l'Ã©tat\n",
        "\n",
        "Au lieu de coder en dur \"SearchAgent â†’ TacticAgent\", on utilise :\n",
        "\n",
        "```python\n",
        "def select_next_agent(state: ProofState) -> str:\n",
        "    if state.phase == ProofPhase.SEARCH:\n",
        "        return \"SearchAgent\"\n",
        "    elif state.phase == ProofPhase.TACTIC_GEN:\n",
        "        return \"TacticAgent\"\n",
        "    # ...\n",
        "```\n",
        "\n",
        "**Avantage** : Orchestration dynamique basÃ©e sur l'Ã©tat rÃ©el de la preuve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Section 8.6 - Definition des 5 Agents Specialises avec Semantic Kernel\n",
        "# =============================================================================\n",
        "# Utilise ChatCompletionAgent de Semantic Kernel avec FunctionChoiceBehavior.Auto()\n",
        "\n",
        "import os\n",
        "import asyncio\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "# --- Instructions des Agents ---\n",
        "\n",
        "SEARCH_AGENT_INSTRUCTIONS = \"\"\"\n",
        "Tu es l'agent de RECHERCHE de lemmes pour le theorem proving en Lean 4.\n",
        "\n",
        "TON ROLE UNIQUE:\n",
        "- Chercher des lemmes Mathlib pertinents pour le theoreme courant\n",
        "- Identifier les lemmes qui peuvent aider a la preuve\n",
        "- Enregistrer les lemmes trouves dans l'etat partage\n",
        "\n",
        "WORKFLOW:\n",
        "1. Lis l'etat avec get_proof_state() pour comprendre le theoreme\n",
        "2. Utilise search_mathlib_lemmas() avec des mots-cles pertinents\n",
        "3. Verifie les lemmes prometteurs avec check_lemma_type()\n",
        "4. Enregistre les lemmes utiles avec add_discovered_lemma()\n",
        "5. Delegue a TacticAgent quand tu as trouve des lemmes\n",
        "\n",
        "IMPORTANT:\n",
        "- Cherche des lemmes LIES au but (egalites, arithmetique, logique)\n",
        "- Delegation: Apres avoir trouve au moins 2-3 lemmes, delegue a TacticAgent\n",
        "- Si aucun lemme pertinent, delegue quand meme a TacticAgent\n",
        "\"\"\"\n",
        "\n",
        "TACTIC_AGENT_INSTRUCTIONS = \"\"\"\n",
        "Tu es l'agent de GENERATION DE TACTIQUES pour le theorem proving en Lean 4.\n",
        "\n",
        "TON ROLE UNIQUE:\n",
        "- Generer des sequences de tactiques Lean pour prouver le but\n",
        "- Utiliser les lemmes trouves par SearchAgent\n",
        "- Proposer des tactiques avec niveau de confiance\n",
        "\n",
        "WORKFLOW:\n",
        "1. Lis l'etat avec get_proof_state() pour voir le theoreme et les lemmes\n",
        "2. Utilise generate_tactics() pour obtenir des suggestions\n",
        "3. Enregistre ta meilleure tentative avec log_tactic_attempt()\n",
        "4. Delegue a VerifierAgent pour verification\n",
        "\n",
        "STRATEGIES DE TACTIQUES (par difficulte):\n",
        "- SIMPLE: rfl, trivial, exact, assumption\n",
        "- MEDIUM: simp, omega, constructor, intro, apply\n",
        "- COMPLEX: ring, linarith, induction, cases\n",
        "\n",
        "IMPORTANT:\n",
        "- Commence par les tactiques simples (rfl, exact)\n",
        "- Utilise les lemmes trouves par SearchAgent (exact Nat.add_zero n)\n",
        "- Delegation: TOUJOURS deleguer a VerifierAgent apres avoir propose\n",
        "\"\"\"\n",
        "\n",
        "VERIFIER_AGENT_INSTRUCTIONS = \"\"\"\n",
        "Tu es l'agent de VERIFICATION pour le theorem proving en Lean 4.\n",
        "\n",
        "TON ROLE UNIQUE:\n",
        "- Verifier les tactiques proposees avec le compilateur Lean\n",
        "- Enregistrer les resultats de verification\n",
        "- Determiner si la preuve est complete ou s'il faut continuer\n",
        "\n",
        "WORKFLOW:\n",
        "1. Lis l'etat avec get_proof_state() pour voir la derniere tactique\n",
        "2. Utilise verify_proof() pour tester la preuve\n",
        "3. Enregistre le resultat avec add_verification_result()\n",
        "4. Si succes: set_proof_complete() et termine\n",
        "5. Si echec: delegue a CriticAgent pour analyse\n",
        "\n",
        "IMPORTANT:\n",
        "- Teste TOUJOURS la derniere tactique proposee\n",
        "- Si la preuve compile sans erreur, utilise set_proof_complete()\n",
        "- Si echec, enregistre l'erreur et delegue a CriticAgent\n",
        "\"\"\"\n",
        "\n",
        "CRITIC_AGENT_INSTRUCTIONS = \"\"\"\n",
        "Tu es l'agent CRITIQUE pour le theorem proving en Lean 4.\n",
        "\n",
        "TON ROLE UNIQUE:\n",
        "- Analyser les echecs de verification\n",
        "- Diagnostiquer les erreurs Lean\n",
        "- Orienter vers la bonne strategie de correction\n",
        "\n",
        "WORKFLOW:\n",
        "1. Lis l'etat avec get_proof_state() pour voir les echecs recents\n",
        "2. Utilise analyze_tactic_failure() pour comprendre l'erreur\n",
        "3. Decide quelle direction prendre:\n",
        "   - \"unknown identifier\" -> delegue a SearchAgent\n",
        "   - \"type mismatch\" ou \"tactic failed\" -> delegue a TacticAgent\n",
        "   - Echecs repetes (>3) -> delegue a CoordinatorAgent\n",
        "\n",
        "IMPORTANT:\n",
        "- Analyse les 3 derniers echecs pour detecter des patterns\n",
        "- Si >3 echecs similaires, delegue a CoordinatorAgent\n",
        "\"\"\"\n",
        "\n",
        "COORDINATOR_AGENT_INSTRUCTIONS = \"\"\"\n",
        "Tu es l'agent COORDINATEUR (superviseur) pour le theorem proving en Lean 4.\n",
        "\n",
        "TON ROLE UNIQUE:\n",
        "- Superviser l'ensemble de la session de preuve\n",
        "- Debloquer les situations cycliques\n",
        "- Ajuster la strategie globale\n",
        "\n",
        "QUAND TU INTERVIENS:\n",
        "- Appele par CriticAgent apres echecs repetes\n",
        "- Appele si max_iterations approche\n",
        "- Appele pour decisions strategiques majeures\n",
        "\n",
        "IMPORTANT:\n",
        "- Tu es le dernier recours, prends des decisions audacieuses\n",
        "- Si >40 iterations, suggere de simplifier le theoreme\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# Detection de Semantic Kernel\n",
        "# =============================================================================\n",
        "\n",
        "SK_AVAILABLE = False\n",
        "try:\n",
        "    from semantic_kernel import Kernel\n",
        "    from semantic_kernel.agents import ChatCompletionAgent, AgentGroupChat\n",
        "    from semantic_kernel.agents.strategies import (\n",
        "        KernelFunctionSelectionStrategy,\n",
        "        KernelFunctionTerminationStrategy,\n",
        "    )\n",
        "    from semantic_kernel.agents.strategies.selection.sequential_selection_strategy import SequentialSelectionStrategy\n",
        "    from semantic_kernel.agents.strategies.termination.default_termination_strategy import DefaultTerminationStrategy\n",
        "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
        "    from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
        "    from semantic_kernel.functions import KernelFunctionFromPrompt, KernelArguments\n",
        "    from semantic_kernel.contents import ChatHistoryTruncationReducer\n",
        "    from semantic_kernel.agents.strategies.selection.selection_strategy import SelectionStrategy\n",
        "    from semantic_kernel.agents.strategies.termination.termination_strategy import TerminationStrategy\n",
        "    from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
        "    from pydantic import PrivateAttr\n",
        "    SK_AVAILABLE = True\n",
        "    print(\"Semantic Kernel disponible - utilisation de ChatCompletionAgent\")\n",
        "except ImportError as e:\n",
        "    print(f\"Semantic Kernel non disponible: {e}\")\n",
        "    print(\"Installation: pip install semantic-kernel\")\n",
        "\n",
        "# =============================================================================\n",
        "# Mode Simulation (fallback si SK non disponible)\n",
        "# =============================================================================\n",
        "\n",
        "class SimpleAgent:\n",
        "    \"\"\"\n",
        "    Agent simplifie pour simulation ou fallback.\n",
        "    Utilise directement l'API OpenAI si SK n'est pas disponible.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        instructions: str,\n",
        "        plugins: Dict[str, Any],\n",
        "        use_simulation: bool = True\n",
        "    ):\n",
        "        self.name = name\n",
        "        self.instructions = instructions\n",
        "        self.plugins = plugins\n",
        "        self.use_simulation = use_simulation\n",
        "        self._openai_client = None\n",
        "\n",
        "        # Initialiser le client OpenAI si mode reel\n",
        "        if not use_simulation:\n",
        "            try:\n",
        "                from openai import OpenAI\n",
        "                api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "                if api_key and len(api_key) > 10 and not api_key.startswith(\"sk-...\"):\n",
        "                    self._openai_client = OpenAI(api_key=api_key)\n",
        "            except ImportError:\n",
        "                pass\n",
        "\n",
        "    def _build_openai_tools(self) -> list:\n",
        "        \"\"\"Construit les outils au format OpenAI function calling.\"\"\"\n",
        "        import inspect\n",
        "        tools = []\n",
        "        for plugin_name, plugin in self.plugins.items():\n",
        "            for attr_name in dir(plugin):\n",
        "                attr = getattr(plugin, attr_name)\n",
        "                if not callable(attr):\n",
        "                    continue\n",
        "                # Supporter les deux dÃ©corateurs\n",
        "                is_sk_func = hasattr(attr, '_sk_function') or hasattr(attr, '__kernel_function__')\n",
        "                if not is_sk_func:\n",
        "                    continue\n",
        "\n",
        "                sig = inspect.signature(attr)\n",
        "                properties = {}\n",
        "                required = []\n",
        "                for param_name, param in sig.parameters.items():\n",
        "                    if param_name == 'self':\n",
        "                        continue\n",
        "                    param_type = \"string\"\n",
        "                    if param.annotation != inspect.Parameter.empty:\n",
        "                        if param.annotation == bool:\n",
        "                            param_type = \"boolean\"\n",
        "                        elif param.annotation in (int, float):\n",
        "                            param_type = \"number\"\n",
        "                    properties[param_name] = {\n",
        "                        \"type\": param_type,\n",
        "                        \"description\": f\"Parameter {param_name}\"\n",
        "                    }\n",
        "                    if param.default == inspect.Parameter.empty:\n",
        "                        required.append(param_name)\n",
        "\n",
        "                # Obtenir nom et description\n",
        "                if hasattr(attr, '__kernel_function_name__'):\n",
        "                    func_name = attr.__kernel_function_name__\n",
        "                    func_desc = getattr(attr, \"__kernel_function_description__\", \"\")\n",
        "                elif hasattr(attr, '_sk_name'):\n",
        "                    func_name = attr._sk_name\n",
        "                    func_desc = getattr(attr, \"_sk_description\", \"\")\n",
        "                else:\n",
        "                    func_name = attr_name\n",
        "                    func_desc = \"\"\n",
        "\n",
        "                tools.append({\n",
        "                    \"type\": \"function\",\n",
        "                    \"function\": {\n",
        "                        \"name\": f\"{plugin_name}__{func_name}\",\n",
        "                        \"description\": func_desc,\n",
        "                        \"parameters\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": properties,\n",
        "                            \"required\": required\n",
        "                        }\n",
        "                    }\n",
        "                })\n",
        "        return tools\n",
        "\n",
        "    def _execute_tool_call(self, tool_name: str, arguments: dict) -> str:\n",
        "        \"\"\"Execute un appel de fonction sur un plugin.\"\"\"\n",
        "        parts = tool_name.split(\"__\", 1)\n",
        "        if len(parts) != 2:\n",
        "            return f\"Erreur: format invalide: {tool_name}\"\n",
        "\n",
        "        plugin_name, func_name = parts\n",
        "        plugin = self.plugins.get(plugin_name)\n",
        "        if not plugin:\n",
        "            return f\"Erreur: plugin {plugin_name} non trouve\"\n",
        "\n",
        "        for attr_name in dir(plugin):\n",
        "            attr = getattr(plugin, attr_name)\n",
        "            if not callable(attr):\n",
        "                continue\n",
        "            is_sk = hasattr(attr, '_sk_function') or hasattr(attr, '__kernel_function__')\n",
        "            if not is_sk:\n",
        "                continue\n",
        "\n",
        "            if hasattr(attr, '__kernel_function_name__'):\n",
        "                name = attr.__kernel_function_name__\n",
        "            elif hasattr(attr, '_sk_name'):\n",
        "                name = attr._sk_name\n",
        "            else:\n",
        "                name = attr_name\n",
        "\n",
        "            if name == func_name:\n",
        "                try:\n",
        "                    result = attr(**arguments)\n",
        "                    return str(result)\n",
        "                except Exception as e:\n",
        "                    return f\"Erreur {func_name}: {e}\"\n",
        "\n",
        "        return f\"Erreur: {func_name} non trouve dans {plugin_name}\"\n",
        "\n",
        "    def invoke(self, message: str, state: ProofState) -> str:\n",
        "        \"\"\"Execute l'agent sur un message.\"\"\"\n",
        "        state.increment_iteration()\n",
        "\n",
        "        if self.use_simulation or not self._openai_client:\n",
        "            return self._simulate_response(message, state)\n",
        "        else:\n",
        "            return self._call_llm(message, state)\n",
        "\n",
        "    def _simulate_response(self, message: str, state: ProofState) -> str:\n",
        "        \"\"\"Simulation de l'agent (sans appels LLM).\"\"\"\n",
        "        if self.name == \"SearchAgent\":\n",
        "            search = self.plugins.get(\"search\")\n",
        "            state_mgr = self.plugins.get(\"state\")\n",
        "            if search and state_mgr:\n",
        "                lemmas_json = search.search_mathlib_lemmas(state.theorem_goal or \"addition\", max_results=3)\n",
        "                lemmas = json.loads(lemmas_json)\n",
        "                for lemma in lemmas[:2]:\n",
        "                    state_mgr.add_discovered_lemma(lemma[\"name\"], lemma[\"statement\"], lemma[\"namespace\"], lemma[\"relevance\"])\n",
        "                state_mgr.designate_next_agent(\"TacticAgent\")\n",
        "                return f\"[SearchAgent] Trouves {len(lemmas[:2])} lemmes. Delegation a TacticAgent.\"\n",
        "\n",
        "        elif self.name == \"TacticAgent\":\n",
        "            tactic = self.plugins.get(\"tactic\")\n",
        "            state_mgr = self.plugins.get(\"state\")\n",
        "            if tactic and state_mgr:\n",
        "                tactics_json = tactic.generate_tactics(state.theorem_goal or \"n + 0 = n\", difficulty=\"simple\")\n",
        "                tactics = json.loads(tactics_json)\n",
        "                if tactics:\n",
        "                    best = tactics[0]\n",
        "                    state_mgr.log_tactic_attempt(best[\"tactic\"], state.theorem_goal or \"\", best[\"confidence\"], best[\"explanation\"])\n",
        "                state_mgr.designate_next_agent(\"VerifierAgent\")\n",
        "                return f\"[TacticAgent] Propose: {tactics[0]['tactic'] if tactics else 'rfl'}. Delegation a VerifierAgent.\"\n",
        "\n",
        "        elif self.name == \"VerifierAgent\":\n",
        "            verif = self.plugins.get(\"verification\")\n",
        "            state_mgr = self.plugins.get(\"state\")\n",
        "            if verif and state_mgr and state.tactics_history:\n",
        "                last_tactic = state.tactics_history[-1]\n",
        "                result_json = verif.verify_proof(state.theorem_statement, last_tactic.tactic)\n",
        "                result = json.loads(result_json)\n",
        "                state_mgr.add_verification_result(\n",
        "                    last_tactic.id, result[\"success\"], result[\"output\"], result[\"errors\"],\n",
        "                    \"\", result[\"exec_time_ms\"]\n",
        "                )\n",
        "                if result[\"success\"]:\n",
        "                    state_mgr.set_proof_complete(last_tactic.tactic)\n",
        "                    return f\"[VerifierAgent] SUCCES! Preuve: {last_tactic.tactic}\"\n",
        "                else:\n",
        "                    state_mgr.designate_next_agent(\"CriticAgent\")\n",
        "                    return f\"[VerifierAgent] Echec: {result['errors'][:100]}. Delegation a CriticAgent.\"\n",
        "\n",
        "        elif self.name == \"CriticAgent\":\n",
        "            tactic = self.plugins.get(\"tactic\")\n",
        "            state_mgr = self.plugins.get(\"state\")\n",
        "            if tactic and state_mgr:\n",
        "                failures = state.get_recent_failures(3)\n",
        "                if failures:\n",
        "                    _, last_verif = failures[0]\n",
        "                    analysis_json = tactic.analyze_tactic_failure(\"unknown\", last_verif.errors)\n",
        "                    analysis = json.loads(analysis_json)\n",
        "                    if analysis[\"error_type\"] == \"unknown_identifier\":\n",
        "                        state_mgr.designate_next_agent(\"SearchAgent\")\n",
        "                        return f\"[CriticAgent] Identifiant inconnu. Retour a SearchAgent.\"\n",
        "                    elif len(failures) > 3:\n",
        "                        state_mgr.designate_next_agent(\"CoordinatorAgent\")\n",
        "                        return f\"[CriticAgent] Trop d'echecs. Appel CoordinatorAgent.\"\n",
        "                    else:\n",
        "                        state_mgr.designate_next_agent(\"TacticAgent\")\n",
        "                        return f\"[CriticAgent] Essayer d'autres tactiques. -> TacticAgent.\"\n",
        "                state_mgr.designate_next_agent(\"TacticAgent\")\n",
        "                return \"[CriticAgent] Pas d'echecs recents. -> TacticAgent.\"\n",
        "\n",
        "        elif self.name == \"CoordinatorAgent\":\n",
        "            state_mgr = self.plugins.get(\"state\")\n",
        "            if state_mgr:\n",
        "                if state.iteration_count > 30:\n",
        "                    state_mgr.set_proof_strategy(\"recovery\")\n",
        "                    return \"[CoordinatorAgent] Mode recovery active.\"\n",
        "                else:\n",
        "                    state_mgr.set_proof_strategy(\"refinement\")\n",
        "                    state_mgr.designate_next_agent(\"TacticAgent\")\n",
        "                    return \"[CoordinatorAgent] Strategie refinement. -> TacticAgent.\"\n",
        "\n",
        "        return f\"[{self.name}] Action simulee.\"\n",
        "\n",
        "    def _call_llm(self, message: str, state: ProofState) -> str:\n",
        "        \"\"\"Appelle le LLM OpenAI avec function calling.\"\"\"\n",
        "        state_summary = json.dumps(state.get_state_snapshot(summarize=True), indent=2)\n",
        "        tools = self._build_openai_tools()\n",
        "\n",
        "        nl = chr(10)\n",
        "        user_content = f\"ETAT ACTUEL:{nl}{state_summary}{nl}{nl}TACHE:{nl}{message}\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": self.instructions},\n",
        "            {\"role\": \"user\", \"content\": user_content}\n",
        "        ]\n",
        "\n",
        "        max_tool_calls = 10\n",
        "        tool_results = []\n",
        "\n",
        "        for iteration in range(max_tool_calls):\n",
        "            try:\n",
        "                model = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-5.2\")\n",
        "                use_mct = any(model.startswith(p) for p in ('gpt-4.5', 'gpt-5', 'o1', 'o3'))\n",
        "                token_param = {\"max_completion_tokens\": 1000} if use_mct else {\"max_tokens\": 1000}\n",
        "\n",
        "                response = self._openai_client.chat.completions.create(\n",
        "                    model=model,\n",
        "                    messages=messages,\n",
        "                    tools=tools if tools else None,\n",
        "                    tool_choice=\"auto\" if tools else None,\n",
        "                    temperature=0.3,\n",
        "                    **token_param\n",
        "                )\n",
        "\n",
        "                assistant_message = response.choices[0].message\n",
        "\n",
        "                if assistant_message.tool_calls:\n",
        "                    messages.append(assistant_message.model_dump())\n",
        "\n",
        "                    for tool_call in assistant_message.tool_calls:\n",
        "                        func_name = tool_call.function.name\n",
        "                        try:\n",
        "                            arguments = json.loads(tool_call.function.arguments)\n",
        "                        except json.JSONDecodeError:\n",
        "                            arguments = {}\n",
        "\n",
        "                        result = self._execute_tool_call(func_name, arguments)\n",
        "                        tool_results.append(func_name.split(\"__\")[-1])\n",
        "\n",
        "                        messages.append({\n",
        "                            \"role\": \"tool\",\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"content\": result\n",
        "                        })\n",
        "                else:\n",
        "                    final_response = assistant_message.content or \"(pas de reponse)\"\n",
        "                    if tool_results:\n",
        "                        actions = \", \".join(tool_results[:5])\n",
        "                        final_response = f\"Actions: {actions}{nl}{final_response}\"\n",
        "                    return f\"[{self.name}] {final_response}\"\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"[{self.name}] Erreur LLM: {e}\"\n",
        "\n",
        "        actions = \", \".join(tool_results[:5])\n",
        "        return f\"[{self.name}] Max tool calls. Actions: {actions}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Patterns de Delegation Multi-Agents\n",
        "\n",
        "Les instructions ci-dessus definissent les **regles de delegation** entre agents :\n",
        "\n",
        "| Agent | Role | Delegue vers |\n",
        "|-------|------|-------------|\n",
        "| **SearchAgent** | Recherche lemmes Mathlib | TacticAgent (si lemmes trouves) |\n",
        "| **TacticAgent** | Genere tactiques Lean | VerifierAgent (toujours) |\n",
        "| **VerifierAgent** | Verifie preuve formelle | CriticAgent (si echec) / COMPLETE (si succes) |\n",
        "| **CriticAgent** | Analyse erreurs | SearchAgent (retry) / CoordinatorAgent (si bloque) |\n",
        "| **CoordinatorAgent** | Re-orchestre strategie | SearchAgent (nouvelle strategie) |\n",
        "\n",
        "**Flow nominal** (preuve simple) :\n",
        "```\n",
        "SearchAgent â†’ TacticAgent â†’ VerifierAgent â†’ COMPLETE\n",
        "```\n",
        "\n",
        "**Flow avec echec** (preuve complexe) :\n",
        "```\n",
        "SearchAgent â†’ TacticAgent â†’ VerifierAgent (FAIL)\n",
        "   â†“\n",
        "CriticAgent analyse erreur\n",
        "   â†“\n",
        "   +-- Erreur simple â†’ SearchAgent (retry avec nouvelles contraintes)\n",
        "   +-- Erreur complexe â†’ CoordinatorAgent (changement strategie)\n",
        "```\n",
        "\n",
        "**Note critique** : Les demos actuelles (DEMO_1-3) sont trop triviales et ne declenchent JAMAIS CriticAgent ni CoordinatorAgent. DEMO_4 (list_length_append) devrait necessiter induction et potentiellement trigger ces agents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quand CriticAgent et CoordinatorAgent Interviennent\n",
        "\n",
        "#### CriticAgent : Analyse d'Echecs de Tactiques\n",
        "\n",
        "**Declenche par VerifierAgent quand** :\n",
        "- `verify_proof()` retourne `success=False`\n",
        "- Erreur Lean detectee : type mismatch, tactic failed, unknown identifier\n",
        "- Preuve incomplete apres application de tactique\n",
        "\n",
        "**Responsabilites** :\n",
        "1. Parser l'erreur Lean (extraire type, message, contexte)\n",
        "2. Identifier la cause (lemme incorrect, tactique inadequate, goal mal compris)\n",
        "3. Proposer correction :\n",
        "   - Erreur simple (lemme manquant) â†’ Delegue SearchAgent avec contraintes\n",
        "   - Erreur complexe (strategie incorrecte) â†’ Delegue CoordinatorAgent\n",
        "\n",
        "**Exemple d'intervention** :\n",
        "```\n",
        "[Tour 5] VerifierAgent: FAIL - \"type mismatch, expected Nat but got Bool\"\n",
        "[Tour 6] CriticAgent: \"TacticAgent a applique 'exact lemma_bool' mais goal attend Nat.\n",
        "                       SearchAgent doit chercher lemmes avec type Nat -> Nat.\"\n",
        "[Tour 7] SearchAgent: Recherche lemmes type-aware...\n",
        "```\n",
        "\n",
        "**Pourquoi absent des demos actuelles** :\n",
        "- DEMO_1-3 : Lemmes Mathlib correspondent exactement au goal\n",
        "- Pas de type mismatch, pas de tactic failure\n",
        "- VerifierAgent retourne success au premier essai\n",
        "\n",
        "#### CoordinatorAgent : Re-Orchestration Strategique\n",
        "\n",
        "**Declenche par CriticAgent quand** :\n",
        "- Echecs multiples consecutifs (3+ iterations sans progres)\n",
        "- Strategie actuelle bloquee (EXPLORATION â†’ REFINEMENT â†’ toujours FAIL)\n",
        "- Pattern d'erreur complexe (induction necessaire mais pas tentee)\n",
        "\n",
        "**Responsabilites** :\n",
        "1. Analyser historique complet (ProofState.snapshots)\n",
        "2. Identifier pattern d'echec (loop, strategie inadequate)\n",
        "3. Changer strategie globale :\n",
        "   - EXPLORATION â†’ VALIDATION (essayer preuves directes)\n",
        "   - REFINEMENT â†’ RECOVERY (backtrack + nouvelle approche)\n",
        "4. Reset partiel de ProofState (clear failed tactics, keep lemmas)\n",
        "\n",
        "**Exemple d'intervention** :\n",
        "```\n",
        "[Tour 8] CriticAgent: \"Echec 3x consecutif avec meme lemme. Strategie bloquee.\"\n",
        "[Tour 9] CoordinatorAgent: \"Detection pattern: goal necessite induction mais pas tentee.\n",
        "                            Changement strategie: EXPLORATION â†’ RECOVERY.\n",
        "                            Ajout contrainte: TacticAgent DOIT considerer 'induction'.\"\n",
        "[Tour 10] SearchAgent: Recherche lemmes inductifs...\n",
        "```\n",
        "\n",
        "**Pourquoi absent des demos actuelles** :\n",
        "- DEMO_1-3 : Pas d'echecs, donc CriticAgent jamais declenche\n",
        "- DEMO_4 (list_length_append) : **DEVRAIT** declencher si :\n",
        "  - Lemme direct `List.length_append` pas trouve\n",
        "  - TacticAgent essaie `rw` ou `simp` sans induction â†’ echec\n",
        "  - CriticAgent detecte besoin d'induction\n",
        "  - CoordinatorAgent change strategie vers RECOVERY\n",
        "\n",
        "#### Activation des Agents Critiques\n",
        "\n",
        "| Scenario | SearchAgent | TacticAgent | VerifierAgent | CriticAgent | CoordinatorAgent |\n",
        "|----------|-------------|-------------|---------------|-------------|------------------|\n",
        "| **Preuve triviale** (rfl) | âœ— | âœ“ | âœ“ | âœ— | âœ— |\n",
        "| **Lemme direct trouve** (exact) | âœ“ | âœ“ | âœ“ | âœ— | âœ— |\n",
        "| **Lemme incorrect** (type mismatch) | âœ“ | âœ“ | âœ“ | âœ“ | âœ— |\n",
        "| **Tactique echoue 1x** (retry) | âœ“ | âœ“ | âœ“ | âœ“ | âœ— |\n",
        "| **Tactique echoue 3x** (bloque) | âœ“ | âœ“ | âœ“ | âœ“ | âœ“ |\n",
        "| **Induction necessaire** | âœ“ | âœ“ | âœ“ | âœ“ | âœ“ |\n",
        "\n",
        "**Conclusion** : Pour tester CriticAgent et CoordinatorAgent, nous devons utiliser des theoremes ou :\n",
        "1. Mathlib n'a PAS de lemme direct exact match\n",
        "2. Preuve necessite composition de tactiques (rw + simp + induction)\n",
        "3. Premiere tentative echoue et necessite correction\n",
        "\n",
        "**DEMO_4 (list_length_append) est concu pour ca** - mais seulement si on desactive l'acces au lemme `List.length_append` de Mathlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Factory pour creer les agents (SK ou fallback)\n",
        "# =============================================================================\n",
        "\n",
        "def create_agents(\n",
        "    plugins: Dict[str, Any],\n",
        "    state: ProofState,\n",
        "    use_sk: bool = True,\n",
        "    use_simulation: bool = False\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Cree les 5 agents specialises.\n",
        "\n",
        "    Args:\n",
        "        plugins: Dictionnaire des plugins SK\n",
        "        state: Etat partage de la preuve\n",
        "        use_sk: Utiliser Semantic Kernel si disponible\n",
        "        use_simulation: Mode simulation (sans appels LLM)\n",
        "\n",
        "    Returns:\n",
        "        Dictionnaire {nom_agent: agent}\n",
        "    \"\"\"\n",
        "    if use_sk and SK_AVAILABLE and not use_simulation:\n",
        "        return _create_sk_agents(plugins, state)\n",
        "    else:\n",
        "        return _create_simple_agents(plugins, use_simulation)\n",
        "\n",
        "\n",
        "def _create_simple_agents(plugins: Dict[str, Any], use_simulation: bool) -> Dict[str, Any]:\n",
        "    \"\"\"Cree les agents en mode fallback/simulation.\"\"\"\n",
        "    return {\n",
        "        \"SearchAgent\": SimpleAgent(\"SearchAgent\", SEARCH_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
        "        \"TacticAgent\": SimpleAgent(\"TacticAgent\", TACTIC_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
        "        \"VerifierAgent\": SimpleAgent(\"VerifierAgent\", VERIFIER_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
        "        \"CriticAgent\": SimpleAgent(\"CriticAgent\", CRITIC_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
        "        \"CoordinatorAgent\": SimpleAgent(\"CoordinatorAgent\", COORDINATOR_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
        "    }\n",
        "\n",
        "\n",
        "def _create_sk_agents(plugins: Dict[str, Any], state: ProofState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Cree les agents avec Semantic Kernel ChatCompletionAgent.\n",
        "\n",
        "    Utilise:\n",
        "    - OpenAIChatCompletion pour le service LLM\n",
        "    - FunctionChoiceBehavior.Auto() pour le function calling automatique\n",
        "    - Les plugins existants sont passes aux agents\n",
        "    \"\"\"\n",
        "    # Creer le kernel et le service\n",
        "    kernel = Kernel()\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    model = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-5.2\")\n",
        "\n",
        "    service = OpenAIChatCompletion(\n",
        "        service_id=\"openai\",\n",
        "        ai_model_id=model,\n",
        "        api_key=api_key\n",
        "    )\n",
        "    kernel.add_service(service)\n",
        "\n",
        "    # Ajouter les plugins au kernel\n",
        "    for plugin_name, plugin in plugins.items():\n",
        "        kernel.add_plugin(plugin, plugin_name=plugin_name)\n",
        "\n",
        "    # Configuration pour auto function calling\n",
        "    settings = kernel.get_prompt_execution_settings_from_service_id(service_id=\"openai\")\n",
        "    settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
        "\n",
        "    # Creer les agents\n",
        "    agents = {}\n",
        "    agent_configs = [\n",
        "        (\"SearchAgent\", SEARCH_AGENT_INSTRUCTIONS),\n",
        "        (\"TacticAgent\", TACTIC_AGENT_INSTRUCTIONS),\n",
        "        (\"VerifierAgent\", VERIFIER_AGENT_INSTRUCTIONS),\n",
        "        (\"CriticAgent\", CRITIC_AGENT_INSTRUCTIONS),\n",
        "        (\"CoordinatorAgent\", COORDINATOR_AGENT_INSTRUCTIONS),\n",
        "    ]\n",
        "\n",
        "    for name, instructions in agent_configs:\n",
        "        agents[name] = ChatCompletionAgent(\n",
        "            kernel=kernel,\n",
        "            name=name,\n",
        "            instructions=instructions,\n",
        "            arguments=KernelArguments(settings=settings)\n",
        "        )\n",
        "\n",
        "    print(f\"Crees {len(agents)} agents SK avec modele {model}\")\n",
        "    return agents\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Test des Agents\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n=== Test des Agents ===\")\n",
        "\n",
        "# Creer l'environnement\n",
        "test_state = ProofState(\n",
        "    theorem_statement=\"theorem add_zero (n : Nat) : n + 0 = n\",\n",
        "    current_goal=\"n + 0 = n\"\n",
        ")\n",
        "runner = LeanRunner(backend=\"subprocess\", timeout=30)\n",
        "\n",
        "# Creer les plugins\n",
        "plugins = {\n",
        "    \"state\": ProofStateManagerPlugin(test_state),\n",
        "    \"search\": LeanSearchPlugin(runner),\n",
        "    \"tactic\": LeanTacticPlugin(),\n",
        "    \"verification\": LeanVerificationPlugin(runner)\n",
        "}\n",
        "\n",
        "# Mode de fonctionnement\n",
        "USE_SK = SK_AVAILABLE and os.getenv(\"OPENAI_API_KEY\")\n",
        "USE_SIMULATION = not USE_SK  # Simulation si SK non disponible ou pas de cle API\n",
        "\n",
        "print(f\"Mode: {'Semantic Kernel' if USE_SK else 'Simulation'}\")\n",
        "\n",
        "# Creer les agents\n",
        "agents = create_agents(plugins, test_state, use_sk=USE_SK, use_simulation=USE_SIMULATION)\n",
        "\n",
        "# Test rapide en mode simulation\n",
        "if USE_SIMULATION:\n",
        "    print(\"\\nTest SearchAgent (simulation):\")\n",
        "    response = agents[\"SearchAgent\"].invoke(\"Trouve des lemmes pour n + 0 = n\", test_state)\n",
        "    print(response)\n",
        "    print(f\"Etat apres SearchAgent:\\n{test_state}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vue d'Ensemble des 5 Agents Specialises\n",
        "\n",
        "La fonction `create_agents()` instancie les 5 agents avec :\n",
        "- **Instructions** : Prompts systemiques definissant role et regles de delegation\n",
        "- **Plugins** : Fonctions exposees (search, tactic generation, verification, etc.)\n",
        "- **Modele LLM** : gpt-5.2 (ou simulation si mode LLM desactive)\n",
        "\n",
        "#### Signatures des agents\n",
        "\n",
        "```python\n",
        "SearchAgent(\n",
        "    plugins=[lean_search_plugin, state_plugin],\n",
        "    instructions=\"Trouve lemmes Mathlib pertinents...\"\n",
        ")\n",
        "\n",
        "TacticAgent(\n",
        "    plugins=[tactic_plugin, state_plugin],\n",
        "    instructions=\"Genere tactiques Lean avec confiance...\"\n",
        ")\n",
        "\n",
        "VerifierAgent(\n",
        "    plugins=[verification_plugin, state_plugin],\n",
        "    instructions=\"Compile et verifie preuves formelles...\"\n",
        ")\n",
        "\n",
        "CriticAgent(\n",
        "    plugins=[state_plugin],\n",
        "    instructions=\"Analyse echecs et propose corrections...\"\n",
        ")\n",
        "\n",
        "CoordinatorAgent(\n",
        "    plugins=[state_plugin],\n",
        "    instructions=\"Re-orchestre strategie globale...\"\n",
        ")\n",
        "```\n",
        "\n",
        "**Pattern cle** : Chaque agent n'a acces qu'aux plugins dont il a besoin (principe de moindre privilege). Le `state_plugin` est partage par tous pour consulter/modifier ProofState.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.7 Strategies d'Orchestration\n",
        "\n",
        "L'orchestration determine comment les agents sont selectionnes et quand la conversation se termine.\n",
        "\n",
        "**DelegatingSelectionStrategy** (Pattern recommande):\n",
        "- Chaque agent designe explicitement le suivant via `designate_next_agent()`\n",
        "- Si aucune designation, utilise un agent par defaut (CoordinatorAgent)\n",
        "\n",
        "**ProofCompleteTermination**:\n",
        "- Termine si `proof_complete == True`\n",
        "- Termine si `iteration_count >= max_iterations`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.8 Demonstration Complete\n",
        "\n",
        "Cette demonstration montre le workflow multi-agents complet:\n",
        "1. **CoordinatorAgent** initialise la session\n",
        "2. **SearchAgent** recherche les lemmes pertinents\n",
        "3. **TacticAgent** propose des tactiques\n",
        "4. **VerifierAgent** verifie avec Lean\n",
        "5. **CriticAgent** intervient en cas d'echec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ­ Orchestration Multi-Agents\n",
        "\n",
        "### Le problÃ¨me de l'orchestration\n",
        "\n",
        "Avec 5 agents, qui parle quand ? Deux approches :\n",
        "\n",
        "1. **Statique** : SearchAgent â†’ TacticAgent â†’ VerifierAgent (toujours)\n",
        "   - Simple mais rigide\n",
        "   - Pas de backtracking\n",
        "\n",
        "2. **Dynamique** : DÃ©cisions basÃ©es sur l'Ã©tat de la preuve\n",
        "   - Flexible mais complexe\n",
        "   - Permet le backtracking et la rÃ©cupÃ©ration d'erreur\n",
        "\n",
        "**Nous utilisons l'approche dynamique.**\n",
        "\n",
        "### StratÃ©gies d'orchestration\n",
        "\n",
        "#### ProofSelectionStrategy\n",
        "\n",
        "DÃ©cide **quel agent agit** Ã  chaque tour :\n",
        "\n",
        "```python\n",
        "class ProofSelectionStrategy:\n",
        "    def select_next_agent(self, state: ProofState, agents: List[str]) -> str:\n",
        "        if state.phase == ProofPhase.INIT:\n",
        "            return \"CoordinatorAgent\"\n",
        "        elif state.phase == ProofPhase.SEARCH:\n",
        "            return \"SearchAgent\"\n",
        "        # ...\n",
        "```\n",
        "\n",
        "#### ProofTerminationStrategy\n",
        "\n",
        "DÃ©cide **quand arrÃªter** la session :\n",
        "\n",
        "```python\n",
        "class ProofTerminationStrategy:\n",
        "    def should_terminate(self, state: ProofState, iteration: int) -> Tuple[bool, str]:\n",
        "        if state.phase == ProofPhase.COMPLETE:\n",
        "            return (True, \"Preuve complÃ¨te!\")\n",
        "        if iteration >= max_iterations:\n",
        "            return (True, \"Timeout atteint\")\n",
        "        # ...\n",
        "```\n",
        "\n",
        "### Boucle principale\n",
        "\n",
        "```python\n",
        "while not should_terminate:\n",
        "    # 1. SÃ©lectionner agent\n",
        "    agent_name = selection_strategy.select_next_agent(state, agents)\n",
        "\n",
        "    # 2. ExÃ©cuter agent (appelle le LLM)\n",
        "    response = agent.chat(f\"Phase: {state.phase}, Goal: {state.current_goal}\")\n",
        "\n",
        "    # 3. L'agent appelle des plugins (modifie l'Ã©tat)\n",
        "    # Exemple: log_tactic_attempt(\"rw [Nat.add_zero]\")\n",
        "\n",
        "    # 4. Mettre Ã  jour phase selon rÃ©sultat\n",
        "    update_phase(state)\n",
        "\n",
        "    # 5. VÃ©rifier condition de terminaison\n",
        "    should_terminate, reason = termination_strategy.should_terminate(state, iteration)\n",
        "```\n",
        "\n",
        "### Snapshots : Observer l'orchestration\n",
        "\n",
        "Ã€ chaque tour, on sauvegarde :\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"iteration\": 5,\n",
        "  \"agent\": \"TacticAgent\",\n",
        "  \"phase_before\": \"SEARCH\",\n",
        "  \"phase_after\": \"TACTIC_GEN\",\n",
        "  \"action\": \"Generated tactic: rw [Nat.add_zero]\",\n",
        "  \"state_snapshot\": {...}\n",
        "}\n",
        "```\n",
        "\n",
        "**UtilitÃ©** : Voir exactement quelle dÃ©cision chaque agent a prise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Test des Strategies ===\n",
            "State cree: a3882044\n",
            "Phase initiale: init\n",
            "Designation test: TacticAgent\n",
            "proof_complete initial: False\n",
            "proof_complete apres COMPLETE: True\n",
            "\n",
            "Strategies pretes pour utilisation avec AgentGroupChat\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Section 8.7 - Strategies d'Orchestration (Pattern Argument_Analysis)\n",
        "# =============================================================================\n",
        "# Strategies personnalisees basees sur l'etat partage (pas sur l'historique)\n",
        "\n",
        "# Fix for Jupyter event loop\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "from typing import Dict, Any, List, Optional\n",
        "\n",
        "# =============================================================================\n",
        "# ProofSelectionStrategy - Selection basee sur l'etat partage\n",
        "# =============================================================================\n",
        "\n",
        "class ProofSelectionStrategy(SelectionStrategy):\n",
        "    \"\"\"\n",
        "    Strategie de selection d'agent basee sur l'etat partage ProofState.\n",
        "    Lit state.consume_next_agent_designation() au lieu de parser l'historique.\n",
        "    Pattern inspire de Argument_Analysis/DelegatingSelectionStrategy.\n",
        "    \"\"\"\n",
        "\n",
        "    _agents_map: Dict[str, Any] = PrivateAttr()\n",
        "    _state: 'ProofState' = PrivateAttr()\n",
        "    _default_agent_name: str = PrivateAttr()\n",
        "    _logger: logging.Logger = PrivateAttr()\n",
        "\n",
        "    def __init__(self, agents: List[Any], state: 'ProofState',\n",
        "                 default_agent_name: str = \"SearchAgent\"):\n",
        "        super().__init__()\n",
        "        if not hasattr(state, 'consume_next_agent_designation'):\n",
        "            raise TypeError(\"state doit avoir consume_next_agent_designation()\")\n",
        "        self._agents_map = {agent.name: agent for agent in agents}\n",
        "        self._state = state\n",
        "        self._default_agent_name = default_agent_name\n",
        "        self._logger = logging.getLogger(\"ProofSelectionStrategy\")\n",
        "\n",
        "    async def next(self, agents: List[Any], history: List[ChatMessageContent]) -> Any:\n",
        "        \"\"\"Selectionne le prochain agent base sur l'etat partage.\"\"\"\n",
        "        # 1. Verifier designation explicite dans l'etat\n",
        "        try:\n",
        "            designated = self._state.consume_next_agent_designation()\n",
        "            if designated:\n",
        "                self._logger.info(f\"Designation explicite: {designated}\")\n",
        "                if designated in self._agents_map:\n",
        "                    return self._agents_map[designated]\n",
        "                self._logger.warning(f\"Agent '{designated}' non trouve!\")\n",
        "        except Exception as e:\n",
        "            self._logger.error(f\"Erreur lecture designation: {e}\")\n",
        "\n",
        "        # 2. Logique basee sur la phase\n",
        "        try:\n",
        "            phase = self._state.phase.value\n",
        "            if phase == \"search\":\n",
        "                return self._agents_map.get(\"TacticAgent\", self._agents_map.get(self._default_agent_name))\n",
        "            elif phase == \"generate\":\n",
        "                return self._agents_map.get(\"VerifierAgent\", self._agents_map.get(self._default_agent_name))\n",
        "            elif phase == \"verify\":\n",
        "                if self._state.last_error:\n",
        "                    return self._agents_map.get(\"CriticAgent\", self._agents_map.get(self._default_agent_name))\n",
        "                return self._agents_map.get(\"CoordinatorAgent\", self._agents_map.get(self._default_agent_name))\n",
        "            elif phase == \"analyze\":\n",
        "                return self._agents_map.get(\"SearchAgent\", self._agents_map.get(self._default_agent_name))\n",
        "        except Exception as e:\n",
        "            self._logger.error(f\"Erreur logique phase: {e}\")\n",
        "\n",
        "        return self._agents_map.get(self._default_agent_name)\n",
        "\n",
        "    async def reset(self) -> None:\n",
        "        try:\n",
        "            self._state.consume_next_agent_designation()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# ProofTerminationStrategy - Terminaison basee sur l'etat partage\n",
        "# =============================================================================\n",
        "\n",
        "class ProofTerminationStrategy(TerminationStrategy):\n",
        "    \"\"\"\n",
        "    Strategie de terminaison basee sur l'etat partage ProofState.\n",
        "    Verifie state.proof_complete au lieu d'analyser les messages.\n",
        "    \"\"\"\n",
        "\n",
        "    _state: 'ProofState' = PrivateAttr()\n",
        "    _max_iterations: int = PrivateAttr()\n",
        "    _logger: logging.Logger = PrivateAttr()\n",
        "\n",
        "    def __init__(self, state: 'ProofState', max_iterations: int = 15):\n",
        "        super().__init__()\n",
        "        if not hasattr(state, 'proof_complete'):\n",
        "            raise TypeError(\"state doit avoir proof_complete\")\n",
        "        self._state = state\n",
        "        self._max_iterations = max_iterations\n",
        "        self._logger = logging.getLogger(\"ProofTerminationStrategy\")\n",
        "\n",
        "    async def should_terminate(self, agent: Any, history: List[ChatMessageContent]) -> bool:\n",
        "        \"\"\"Verifie si la conversation doit se terminer.\"\"\"\n",
        "        # 1. Preuve trouvee\n",
        "        try:\n",
        "            if self._state.proof_complete:\n",
        "                self._logger.info(\"Terminaison: preuve complete\")\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            self._logger.error(f\"Erreur verification preuve: {e}\")\n",
        "\n",
        "        # 2. Max iterations\n",
        "        try:\n",
        "            if self._state.iteration >= self._max_iterations:\n",
        "                self._logger.info(f\"Terminaison: max iterations ({self._max_iterations})\")\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            self._logger.error(f\"Erreur verification iterations: {e}\")\n",
        "\n",
        "        # 3. Phase complete ou failed\n",
        "        try:\n",
        "            if self._state.phase.value in [\"complete\", \"failed\"]:\n",
        "                self._logger.info(f\"Terminaison: phase {self._state.phase.value}\")\n",
        "                return True\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return False\n",
        "\n",
        "    async def reset(self) -> None:\n",
        "        pass\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# ProofAgentGroupChat - Orchestration multi-agents\n",
        "# =============================================================================\n",
        "\n",
        "class ProofAgentGroupChat:\n",
        "    \"\"\"\n",
        "    Orchestre les agents pour la preuve de theoremes.\n",
        "    Utilise ProofSelectionStrategy et ProofTerminationStrategy.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agents: Dict[str, Any], state: ProofState, use_sk: bool = True):\n",
        "        self.agents = agents\n",
        "        self.state = state\n",
        "        self.use_sk = use_sk and SK_AVAILABLE\n",
        "        self.history = []\n",
        "\n",
        "    def run(self, initial_message: str, verbose: bool = True) -> str:\n",
        "        \"\"\"Execute la conversation multi-agents.\"\"\"\n",
        "        if self.use_sk:\n",
        "            return asyncio.get_event_loop().run_until_complete(\n",
        "                self._run_sk(initial_message, verbose)\n",
        "            )\n",
        "        else:\n",
        "            return self._run_fallback(initial_message, verbose)\n",
        "\n",
        "    async def _run_sk(self, initial_message: str, verbose: bool) -> str:\n",
        "        \"\"\"Execution avec Semantic Kernel et strategies personnalisees.\"\"\"\n",
        "        if verbose:\n",
        "            print(\"=\" * 60)\n",
        "            print(f\"Session SK demarree: {initial_message[:80]}...\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "        agent_list = list(self.agents.values())\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"[LOG] Agents: {[a.name for a in agent_list]}\")\n",
        "            print(f\"[LOG] Max iterations: {self.state.max_iterations}\")\n",
        "\n",
        "        # Creer les strategies basees sur l'etat partage\n",
        "        selection_strategy = ProofSelectionStrategy(\n",
        "            agents=agent_list,\n",
        "            state=self.state,\n",
        "            default_agent_name=\"SearchAgent\"\n",
        "        )\n",
        "\n",
        "        termination_strategy = ProofTerminationStrategy(\n",
        "            state=self.state,\n",
        "            max_iterations=self.state.max_iterations\n",
        "        )\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"[LOG] Strategies initialisees (basees sur etat partage)\")\n",
        "\n",
        "        # Creer le chat SK\n",
        "        chat = AgentGroupChat(\n",
        "            agents=agent_list,\n",
        "            selection_strategy=selection_strategy,\n",
        "            termination_strategy=termination_strategy,\n",
        "        )\n",
        "\n",
        "        await chat.add_chat_message(message=initial_message)\n",
        "\n",
        "        iteration = 0\n",
        "        if verbose:\n",
        "            print(f\"[LOG] Demarrage boucle multi-agents...\")\n",
        "\n",
        "        try:\n",
        "            async for response in chat.invoke():\n",
        "                iteration += 1\n",
        "                self.state.iteration = iteration\n",
        "\n",
        "                if response is None:\n",
        "                    if verbose:\n",
        "                        print(f\"[Tour {iteration}] Response None, continue...\")\n",
        "                    continue\n",
        "\n",
        "                agent_name = getattr(response, 'name', None) or 'Unknown'\n",
        "                content = str(response.content)[:500] if response.content else \"(vide)\"\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"\\n[Tour {iteration}/{self.state.max_iterations}] Agent: {agent_name}\")\n",
        "                    print(f\"  Phase: {self.state.phase.value}\")\n",
        "                    print(f\"  Response: {content[:300]}{'...' if len(content) > 300 else ''}\")\n",
        "\n",
        "                self.history.append({\n",
        "                    \"agent\": agent_name,\n",
        "                    \"response\": content,\n",
        "                    \"iteration\": iteration,\n",
        "                    \"phase\": self.state.phase.value,\n",
        "                })\n",
        "\n",
        "                if self.state.proof_complete:\n",
        "                    if verbose:\n",
        "                        print(f\"[LOG] Preuve complete detectee!\")\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                print(f\"\\n[ERREUR Tour {iteration}] {type(e).__name__}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(f\"SESSION TERMINEE - {iteration} tours executes\")\n",
        "            if self.state.proof_complete:\n",
        "                print(\"SUCCES! Preuve trouvee:\")\n",
        "                print(self.state.final_proof)\n",
        "            else:\n",
        "                print(f\"Pas de preuve trouvee.\")\n",
        "                if self.state.last_error:\n",
        "                    print(f\"Derniere erreur: {self.state.last_error}\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "        return self.state.final_proof or \"Preuve non trouvee\"\n",
        "\n",
        "    def _run_fallback(self, initial_message: str, verbose: bool = True) -> str:\n",
        "        \"\"\"Execution sans Semantic Kernel (mode simulation).\"\"\"\n",
        "        if verbose:\n",
        "            print(\"=\" * 60)\n",
        "            print(f\"Session FALLBACK: {initial_message[:80]}...\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "        current_message = initial_message\n",
        "        agent_order = [\"SearchAgent\", \"TacticAgent\", \"VerifierAgent\", \"CriticAgent\", \"CoordinatorAgent\"]\n",
        "\n",
        "        for i in range(self.state.max_iterations):\n",
        "            designated = self.state.consume_next_agent_designation()\n",
        "            if designated and designated in self.agents:\n",
        "                agent_name = designated\n",
        "            else:\n",
        "                agent_name = agent_order[i % len(agent_order)]\n",
        "\n",
        "            agent = self.agents.get(agent_name)\n",
        "            if not agent:\n",
        "                continue\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\n[Tour {self.state.iteration_count + 1}] {agent_name}\")\n",
        "\n",
        "            response = agent.invoke(current_message, self.state)\n",
        "\n",
        "            self.history.append({\n",
        "                \"iteration\": self.state.iteration_count,\n",
        "                \"agent\": agent_name,\n",
        "                \"response\": response[:200],\n",
        "            })\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"  Response: {response[:200]}...\")\n",
        "\n",
        "            if self.state.proof_complete:\n",
        "                if verbose:\n",
        "                    print(f\"\\n[LOG] Preuve trouvee!\")\n",
        "                break\n",
        "\n",
        "            current_message = response\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(f\"Session terminee apres {self.state.iteration_count} iterations.\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "        return self.state.final_proof or \"Preuve non trouvee\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Test des Strategies\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=== Test des Strategies ===\")\n",
        "\n",
        "test_state = ProofState(\n",
        "    theorem_statement=\"theorem test (n : Nat) : n = n\",\n",
        "    current_goal=\"n = n\",\n",
        "    max_iterations=5\n",
        ")\n",
        "\n",
        "print(f\"State cree: {test_state.session_id}\")\n",
        "print(f\"Phase initiale: {test_state.phase.value}\")\n",
        "\n",
        "# Test designation\n",
        "test_state.designate_next_agent(\"TacticAgent\")\n",
        "designated = test_state.consume_next_agent_designation()\n",
        "print(f\"Designation test: {designated}\")\n",
        "\n",
        "# Test proof_complete\n",
        "print(f\"proof_complete initial: {test_state.proof_complete}\")\n",
        "test_state.phase = ProofPhase.COMPLETE\n",
        "print(f\"proof_complete apres COMPLETE: {test_state.proof_complete}\")\n",
        "\n",
        "print(\"\\nStrategies pretes pour utilisation avec AgentGroupChat\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª DÃ©monstrations Progressives\n",
        "\n",
        "### Objectif\n",
        "\n",
        "Valider que le systÃ¨me multi-agents **fonctionne rÃ©ellement** sur des problÃ¨mes de complexitÃ© croissante.\n",
        "\n",
        "### Les 3 dÃ©mos\n",
        "\n",
        "#### 1ï¸âƒ£ DEMO_1_TRIVIAL : `theorem demo_rfl (n : Nat) : n = n`\n",
        "\n",
        "- **ComplexitÃ©** : Triviale (Ã©galitÃ© rÃ©flexive)\n",
        "- **Preuve attendue** : `by rfl` (une seule tactique)\n",
        "- **ItÃ©rations attendues** : 1-2\n",
        "- **Lemmes nÃ©cessaires** : 0 (tautologie)\n",
        "- **But** : VÃ©rifier que le systÃ¨me peut rÃ©soudre le cas le plus simple\n",
        "\n",
        "#### 2ï¸âƒ£ DEMO_2_SIMPLE : `theorem nat_add_zero (n : Nat) : n + 0 = n`\n",
        "\n",
        "- **ComplexitÃ©** : Simple (propriÃ©tÃ© arithmÃ©tique basique)\n",
        "- **Preuve attendue** : `by rw [Nat.add_zero]` ou induction\n",
        "- **ItÃ©rations attendues** : 4-6\n",
        "- **Lemmes nÃ©cessaires** : 1-2 (de Mathlib)\n",
        "- **But** : Tester **SearchAgent** (recherche de lemmes) + **TacticAgent**\n",
        "\n",
        "#### 3ï¸âƒ£ DEMO_3_INTERMEDIATE : `theorem nat_add_comm (n m : Nat) : n + m = m + n`\n",
        "\n",
        "- **ComplexitÃ©** : IntermÃ©diaire (commutativitÃ© de l'addition)\n",
        "- **Preuve attendue** : Induction + rÃ©Ã©criture avec plusieurs lemmes\n",
        "- **ItÃ©rations attendues** : 8-12\n",
        "- **Lemmes nÃ©cessaires** : 2-3 (Nat.add_comm, Nat.add_succ, etc.)\n",
        "- **But** : Tester **orchestration complÃ¨te** avec backtracking potentiel\n",
        "\n",
        "### MÃ©triques Ã  comparer\n",
        "\n",
        "| MÃ©trique | DÃ©mo 1 | DÃ©mo 2 | DÃ©mo 3 |\n",
        "|----------|--------|--------|--------|\n",
        "| ItÃ©rations | 1-2 | 4-6 | 8-12 |\n",
        "| Lemmes dÃ©couverts | 0 | 1-2 | 2-3 |\n",
        "| Tactiques essayÃ©es | 1 | 2-3 | 4-6 |\n",
        "| VÃ©rifications Lean | 1 | 1-2 | 2-3 |\n",
        "\n",
        "### HypothÃ¨se Ã  valider\n",
        "\n",
        "**Le systÃ¨me multi-agents SCALE avec la complexitÃ© du problÃ¨me.**\n",
        "\n",
        "Si DÃ©mo 3 prend ~6Ã— plus d'itÃ©rations que DÃ©mo 1, c'est **normal et attendu** (pas un bug).\n",
        "\n",
        "Si DÃ©mo 3 Ã©choue alors que DÃ©mo 1 rÃ©ussit, Ã§a indique un problÃ¨me d'orchestration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Section 8.8 - Demonstration Complete\n",
        "# =============================================================================\n",
        "\n",
        "def prove_with_multi_agents(\n",
        "    theorem: str,\n",
        "    goal: str = \"\",\n",
        "    max_iterations: int = 20,\n",
        "    verbose: bool = True,\n",
        "    use_simulation: bool = None  # None = auto-detect\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Prouve un theoreme en utilisant le systeme multi-agents.\n",
        "\n",
        "    Args:\n",
        "        theorem: L'enonce du theoreme complet\n",
        "        goal: Le but a prouver (extrait du theoreme si non fourni)\n",
        "        max_iterations: Nombre maximum d'iterations\n",
        "        verbose: Afficher les logs\n",
        "        use_simulation: True=simulation, False=LLM reel, None=auto\n",
        "\n",
        "    Returns:\n",
        "        Dict avec resultats et metriques\n",
        "    \"\"\"\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Auto-detection du mode\n",
        "    if use_simulation is None:\n",
        "        api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "        has_valid_key = api_key and len(api_key) > 10 and not api_key.startswith(\"sk-...\")\n",
        "        use_simulation = not has_valid_key\n",
        "\n",
        "    # 1. Creer l'etat\n",
        "    if not goal:\n",
        "        if \":\" in theorem:\n",
        "            goal = theorem.split(\":\")[-1].strip()\n",
        "\n",
        "    state = ProofState(\n",
        "        theorem_statement=theorem,\n",
        "        current_goal=goal,\n",
        "        max_iterations=max_iterations\n",
        "    )\n",
        "\n",
        "    # 2. Creer le runner Lean\n",
        "    runner = LeanRunner(backend=\"subprocess\", timeout=30)\n",
        "\n",
        "    # 3. Creer les plugins\n",
        "    plugins = {\n",
        "        \"state\": ProofStateManagerPlugin(state),\n",
        "        \"search\": LeanSearchPlugin(runner),\n",
        "        \"tactic\": LeanTacticPlugin(),\n",
        "        \"verification\": LeanVerificationPlugin(runner)\n",
        "    }\n",
        "\n",
        "    # 4. Creer les agents\n",
        "    use_sk = SK_AVAILABLE and not use_simulation\n",
        "    agents = create_agents(plugins, state, use_sk=use_sk, use_simulation=use_simulation)\n",
        "\n",
        "    # 5. Configurer les strategies\n",
        "    # Strategies gerees automatiquement par ProofAgentGroupChat\n",
        "\n",
        "    # 6. Creer le groupe de chat\n",
        "    chat = ProofAgentGroupChat(\n",
        "        agents=agents,\n",
        "        state=state,\n",
        "        use_sk=use_sk\n",
        "    )\n",
        "\n",
        "    mode_str = \"Semantic Kernel\" if use_sk else (\"Simulation\" if use_simulation else \"OpenAI direct\")\n",
        "    if verbose:\n",
        "        print(f\"Mode: {mode_str}\")\n",
        "\n",
        "    # 7. Executer\n",
        "    result = chat.run(f\"Prouver: {theorem}\", verbose=verbose)\n",
        "\n",
        "    # 8. Collecter les metriques\n",
        "    elapsed = time.time() - start_time\n",
        "    metrics = {\n",
        "        \"success\": state.proof_complete,\n",
        "        \"theorem\": theorem,\n",
        "        \"final_proof\": state.final_proof,\n",
        "        \"iterations\": state.iteration_count,\n",
        "        \"lemmas_discovered\": len(state.discovered_lemmas),\n",
        "        \"tactics_tried\": len(state.tactics_history),\n",
        "        \"verifications\": len(state.verification_results),\n",
        "        \"total_time_s\": round(elapsed, 2),\n",
        "        \"lean_time_ms\": round(state.total_lean_time_ms, 2),\n",
        "        \"mode\": mode_str\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Test de la demonstration\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DEMONSTRATION MULTI-AGENTS POUR THEOREM PROVING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# =============================================================================\n",
        "# Section 8.8 - DÃ©monstrations Progressives Multi-Agents\n",
        "# =============================================================================\n",
        "\n",
        "# Configuration\n",
        "USE_LLM_MODE = True  # True pour LLM rÃ©el, False pour simulation\n",
        "\n",
        "# Quatre thÃ©orÃ¨mes de complexitÃ© croissante\nDEMOS = [\n    {\n        \"name\": \"DEMO_1_TRIVIAL\",\n        \"theorem\": \"theorem demo_rfl (n : Nat) : n = n\",\n        \"description\": \"Ã‰galitÃ© rÃ©flexive (1-2 itÃ©rations attendues)\",\n        \"expected_iterations\": \"1-2\",\n        \"expected_lemmas\": \"0\",\n        \"complexity\": \"Triviale - teste rfl uniquement\"\n    },\n    {\n        \"name\": \"DEMO_2_SIMPLE\",\n        \"theorem\": \"theorem add_right_cancel (a b c : Nat) : a + b = c + b -> a = c\",\n        \"description\": \"Simplification addition (6-10 itÃ©rations attendues)\",\n        \"expected_iterations\": \"6-10\",\n        \"expected_lemmas\": \"2-3\",\n        \"complexity\": \"Simple - necessite Nat.add_right_cancel ou decomposition\"\n    },\n    {\n        \"name\": \"DEMO_3_INTERMEDIATE\",\n        \"theorem\": \"theorem mul_add_distr (a b c : Nat) : a * (b + c) = a * b + a * c\",\n        \"description\": \"DistributivitÃ© multiplication (10-15 itÃ©rations attendues)\",\n        \"expected_iterations\": \"10-15\",\n        \"expected_lemmas\": \"3-5\",\n        \"complexity\": \"IntermÃ©diaire - composition Nat.mul_add + associativite\"\n    },\n    {\n        \"name\": \"DEMO_4_ADVANCED\",\n        \"theorem\": \"theorem list_length_append (l1 l2 : List Nat) : (l1 ++ l2).length = l1.length + l2.length\",\n        \"description\": \"Induction sur listes (12-20 itÃ©rations attendues)\",\n        \"expected_iterations\": \"12-20\",\n        \"expected_lemmas\": \"4-6\",\n        \"complexity\": \"Avance - induction structurelle, trigger CriticAgent\"\n    }\n]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DÃ‰MONSTRATIONS PROGRESSIVES - SYSTÃˆME MULTI-AGENTS\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "\n",
        "# ExÃ©cuter chaque dÃ©mo\n",
        "results_comparison = []\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execution DEMO_1 : Preuve Triviale\n",
        "\n",
        "**Objectif** : Valider le pipeline complet avec un theoreme trivial\n",
        "\n",
        "**Theoreme** : `theorem demo_rfl (n : Nat) : n = n`\n",
        "\n",
        "**Attentes** :\n",
        "- **Iterations** : 1-2 (reflexivite immediate)\n",
        "- **Agents impliques** : TacticAgent (rfl) â†’ VerifierAgent\n",
        "- **CriticAgent/CoordinatorAgent** : NON (preuve triviale)\n",
        "- **Temps** : <1 seconde\n",
        "\n",
        "Cette demo sert de **baseline** pour verifier que le systeme fonctionne.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "",
        "# Execute DEMO_1",
        "demo = DEMOS[0]",
        "print(\"\\n\" + \"=\" * 70)",
        "print(f\"DEMO 1/4: {demo['name']}\")",
        "print(\"=\" * 70)",
        "print(f\"Theoreme: {demo['theorem']}\")",
        "print(f\"Complexite: {demo['complexity']}\")",
        "print(f\"Iterations attendues: {demo['expected_iterations']}\")",
        "print(f\"Lemmes necessaires: {demo['expected_lemmas']}\")",
        "print(\"=\" * 70)",
        "",
        "result_1 = prove_with_multi_agents(",
        "    theorem=demo[\"theorem\"],",
        "    max_iterations=20,",
        "    verbose=True,",
        "    use_simulation=not USE_LLM_MODE",
        ")",
        "",
        "print(f\"\\nResultat DEMO_1:\")",
        "print(f\"  - Success: {result_1['success']}\")",
        "print(f\"  - Iterations: {result_1['iterations']}\")",
        "print(f\"  - Proof: {result_1['proof'][:100] if result_1['proof'] else 'None'}...\")",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execution DEMO_2 : Preuve Simple\n",
        "\n",
        "**Objectif** : Tester recherche de lemmes + composition\n",
        "\n",
        "**Theoreme** : `theorem add_right_cancel (a b c : Nat) : a + b = c + b -> a = c`\n",
        "\n",
        "**Attentes** :\n",
        "- **Iterations** : 6-10 (recherche lemme + application)\n",
        "- **Agents impliques** : SearchAgent â†’ TacticAgent â†’ VerifierAgent\n",
        "- **Lemmes Mathlib attendus** : `Nat.add_right_cancel`, `Nat.add_comm`\n",
        "- **CriticAgent/CoordinatorAgent** : POSSIBLE si lemme pas trouve directement\n",
        "- **Temps** : 2-5 secondes\n",
        "\n",
        "Cette demo teste la **recherche de lemmes** et la **generation de tactiques** adaptees.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "",
        "# Execute DEMO_2",
        "demo = DEMOS[1]",
        "print(\"\\n\" + \"=\" * 70)",
        "print(f\"DEMO 2/4: {demo['name']}\")",
        "print(\"=\" * 70)",
        "print(f\"Theoreme: {demo['theorem']}\")",
        "print(f\"Complexite: {demo['complexity']}\")",
        "print(f\"Iterations attendues: {demo['expected_iterations']}\")",
        "print(f\"Lemmes necessaires: {demo['expected_lemmas']}\")",
        "print(\"=\" * 70)",
        "",
        "result_2 = prove_with_multi_agents(",
        "    theorem=demo[\"theorem\"],",
        "    max_iterations=20,",
        "    verbose=True,",
        "    use_simulation=not USE_LLM_MODE",
        ")",
        "",
        "print(f\"\\nResultat DEMO_2:\")",
        "print(f\"  - Success: {result_2['success']}\")",
        "print(f\"  - Iterations: {result_2['iterations']}\")",
        "print(f\"  - Proof: {result_2['proof'][:100] if result_2['proof'] else 'None'}...\")",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execution DEMO_3 : Preuve Intermediaire\n",
        "\n",
        "**Objectif** : Tester composition de plusieurs lemmes\n",
        "\n",
        "**Theoreme** : `theorem mul_add_distr (a b c : Nat) : a * (b + c) = a * b + a * c`\n",
        "\n",
        "**Attentes** :\n",
        "- **Iterations** : 10-15 (composition lemmes)\n",
        "- **Agents impliques** : SearchAgent (multiple) â†’ TacticAgent â†’ VerifierAgent â†’ CriticAgent (si echec)\n",
        "- **Lemmes Mathlib attendus** : `Nat.mul_add`, `Nat.mul_comm`, `Nat.add_assoc`\n",
        "- **CriticAgent** : PROBABLE (necessite ajustements tactiques)\n",
        "- **Temps** : 5-10 secondes\n",
        "\n",
        "Cette demo teste l'**orchestration multi-agents** avec feedback loops.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "",
        "# Execute DEMO_3",
        "demo = DEMOS[2]",
        "print(\"\\n\" + \"=\" * 70)",
        "print(f\"DEMO 3/4: {demo['name']}\")",
        "print(\"=\" * 70)",
        "print(f\"Theoreme: {demo['theorem']}\")",
        "print(f\"Complexite: {demo['complexity']}\")",
        "print(f\"Iterations attendues: {demo['expected_iterations']}\")",
        "print(f\"Lemmes necessaires: {demo['expected_lemmas']}\")",
        "print(\"=\" * 70)",
        "",
        "result_3 = prove_with_multi_agents(",
        "    theorem=demo[\"theorem\"],",
        "    max_iterations=20,",
        "    verbose=True,",
        "    use_simulation=not USE_LLM_MODE",
        ")",
        "",
        "print(f\"\\nResultat DEMO_3:\")",
        "print(f\"  - Success: {result_3['success']}\")",
        "print(f\"  - Iterations: {result_3['iterations']}\")",
        "print(f\"  - Proof: {result_3['proof'][:100] if result_3['proof'] else 'None'}...\")",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execution DEMO_4 : Preuve Avancee\n",
        "\n",
        "**Objectif** : Stresser le systeme avec induction structurelle\n",
        "\n",
        "**Theoreme** : `theorem list_length_append (l1 l2 : List Nat) : (l1 ++ l2).length = l1.length + l2.length`\n",
        "\n",
        "**Attentes** :\n",
        "- **Iterations** : 12-20 (induction + lemmes auxiliaires)\n",
        "- **Agents impliques** : SearchAgent â†’ TacticAgent (induction) â†’ VerifierAgent â†’ **CriticAgent** â†’ CoordinatorAgent (si blocage)\n",
        "- **Lemmes Mathlib attendus** : `List.length_append`, `List.length_cons`, `Nat.succ_add`\n",
        "- **Strategies** : EXPLORATION â†’ REFINEMENT â†’ VALIDATION\n",
        "- **CriticAgent/CoordinatorAgent** : **REQUIS** (echecs de tactiques attendus)\n",
        "- **Temps** : 10-30 secondes\n",
        "\n",
        "Cette demo doit **declencher CriticAgent** si la tactique d'induction echoue ou si les lemmes ne suffisent pas. C'est le seul theoreme qui devrait stresser l'orchestration complete.\n",
        "\n",
        "**Note** : Si DEMO_4 se complete en <10 iterations sans CriticAgent, cela signifie que Mathlib contient le lemme directement et le theoreme n'est pas assez complexe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "",
        "# Execute DEMO_4",
        "demo = DEMOS[3]",
        "print(\"\\n\" + \"=\" * 70)",
        "print(f\"DEMO 4/4: {demo['name']}\")",
        "print(\"=\" * 70)",
        "print(f\"Theoreme: {demo['theorem']}\")",
        "print(f\"Complexite: {demo['complexity']}\")",
        "print(f\"Iterations attendues: {demo['expected_iterations']}\")",
        "print(f\"Lemmes necessaires: {demo['expected_lemmas']}\")",
        "print(\"=\" * 70)",
        "",
        "result_4 = prove_with_multi_agents(",
        "    theorem=demo[\"theorem\"],",
        "    max_iterations=20,",
        "    verbose=True,",
        "    use_simulation=not USE_LLM_MODE",
        ")",
        "",
        "print(f\"\\nResultat DEMO_4:\")",
        "print(f\"  - Success: {result_4['success']}\")",
        "print(f\"  - Iterations: {result_4['iterations']}\")",
        "print(f\"  - Proof: {result_4['proof'][:100] if result_4['proof'] else 'None'}...\")",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¼ Harmonic Aristotle : DÃ©composition RÃ©cursive\n",
        "\n",
        "### Contexte\n",
        "\n",
        "**Technique dÃ©veloppÃ©e par DeepSeek (2024)** pour rÃ©soudre des problÃ¨mes de thÃ©orie des nombres ouverts depuis 30+ ans.\n",
        "\n",
        "### Le problÃ¨me des preuves \"monolithiques\"\n",
        "\n",
        "Approche classique (linÃ©aire) :\n",
        "\n",
        "```\n",
        "ThÃ©orÃ¨me T : n + m = m + n\n",
        "  â†“\n",
        "Recherche de lemmes\n",
        "  â†“\n",
        "GÃ©nÃ©ration de tactiques\n",
        "  â†“\n",
        "VÃ©rification\n",
        "  â†“\n",
        "SuccÃ¨s ou Ã©chec\n",
        "```\n",
        "\n",
        "**ProblÃ¨me** : Si le thÃ©orÃ¨me est complexe, la recherche de lemmes devient explosive (trop de candidats).\n",
        "\n",
        "### IdÃ©e centrale : DÃ©composition rÃ©cursive\n",
        "\n",
        "Au lieu de prouver T directement, **dÃ©composer T en sous-thÃ©orÃ¨mes plus simples** :\n",
        "\n",
        "```\n",
        "ThÃ©orÃ¨me T : n + m = m + n\n",
        "  â†“ DÃ‰COMPOSITION\n",
        "  â”œâ”€ T1 : n + 0 = 0 + n (plus facile)\n",
        "  â”œâ”€ T2 : n + (m + 1) = (m + 1) + n (plus facile)\n",
        "  â””â”€ T3 : Induction utilisant T1 et T2 (maintenant facile!)\n",
        "```\n",
        "\n",
        "### Exemple concret\n",
        "\n",
        "**Sans dÃ©composition** :\n",
        "\n",
        "```lean\n",
        "theorem add_comm (n m : Nat) : n + m = m + n := by\n",
        "  -- Recherche de lemmes : 50+ candidats dans Mathlib\n",
        "  -- GÃ©nÃ©ration de tactiques : Quelle induction ? Sur n ou m ?\n",
        "  -- VÃ©rifications : 10-15 tentatives\n",
        "  -- âŒ ComplexitÃ© explosive\n",
        "```\n",
        "\n",
        "**Avec dÃ©composition (Harmonic Aristotle)** :\n",
        "\n",
        "```lean\n",
        "-- Ã‰tape 1 : Prouver cas de base\n",
        "theorem add_zero (n : Nat) : n + 0 = n := by rfl\n",
        "\n",
        "-- Ã‰tape 2 : Prouver cas successeur\n",
        "theorem add_succ (n m : Nat) : n + (m + 1) = (n + m) + 1 := by rfl\n",
        "\n",
        "-- Ã‰tape 3 : Combiner pour prouver commutativitÃ© (facile maintenant!)\n",
        "theorem add_comm (n m : Nat) : n + m = m + n := by\n",
        "  induction m with\n",
        "  | zero => rw [add_zero, zero_add]  -- Utilise add_zero\n",
        "  | succ m ih => rw [add_succ, ih, succ_add]  -- Utilise add_succ\n",
        "```\n",
        "\n",
        "### MÃ©trique clÃ© : **RÃ©duction de l'espace de recherche**\n",
        "\n",
        "| Approche | Lemmes candidats | Tactiques essayÃ©es | SuccÃ¨s |\n",
        "|----------|------------------|-------------------|--------|\n",
        "| LinÃ©aire | 50+ | 15-20 | 40% |\n",
        "| Harmonic Aristotle | 5-10 (par sous-thÃ©orÃ¨me) | 5-8 (total) | 85% |\n",
        "\n",
        "### IntÃ©gration dans notre systÃ¨me\n",
        "\n",
        "Harmonic Aristotle s'intÃ¨gre comme **stratÃ©gie de CriticAgent** :\n",
        "\n",
        "1. CriticAgent dÃ©tecte que le thÃ©orÃ¨me est complexe (>5 itÃ©rations sans succÃ¨s)\n",
        "2. Propose une dÃ©composition en sous-thÃ©orÃ¨mes\n",
        "3. CoordinatorAgent orchestre la preuve des sous-thÃ©orÃ¨mes\n",
        "4. TacticAgent combine les rÃ©sultats\n",
        "\n",
        "**RÃ©sultat** : RÃ©solution de problÃ¨mes ouverts (Erdos #124 variant en 6h)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Techniques de Harmonic Aristotle\n",
        "\n",
        "### 6.1 Decomposition de problemes\n",
        "\n",
        "Aristotle decompose les problemes complexes en sous-problemes plus simples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decomposition de 'P <-> Q':\n",
            "  - Direction 1: P  ->  Q\n",
            "  - Direction 2:  Q -> P \n"
          ]
        }
      ],
      "source": [
        "class AristotleDecomposer:\n",
        "    \"\"\"\n",
        "    Decomposition de problemes a la Harmonic Aristotle.\n",
        "    \"\"\"\n",
        "    \n",
        "    def decompose(self, theorem: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Decompose un theoreme en sous-lemmes.\n",
        "        \n",
        "        Strategy:\n",
        "        1. Identifier la structure (conjonction, equivalence, etc.)\n",
        "        2. Separer en composantes\n",
        "        3. Identifier les dependances\n",
        "        \"\"\"\n",
        "        subproblems = []\n",
        "        \n",
        "        # Decomposition basique par structure\n",
        "        if \"<->\" in theorem or \"iff\" in theorem.lower():\n",
        "            # Equivalence = deux implications\n",
        "            parts = theorem.split(\"<->\")\n",
        "            subproblems.append(f\"Direction 1: {parts[0]} -> {parts[1]}\")\n",
        "            subproblems.append(f\"Direction 2: {parts[1]} -> {parts[0]}\")\n",
        "        \n",
        "        elif \"/\\\\\" in theorem or \"and\" in theorem.lower():\n",
        "            # Conjonction = prouver chaque partie\n",
        "            parts = theorem.split(\"/\\\\\")\n",
        "            for i, part in enumerate(parts):\n",
        "                subproblems.append(f\"Partie {i+1}: {part.strip()}\")\n",
        "        \n",
        "        elif \"forall\" in theorem.lower():\n",
        "            # Universel = fixer variable, prouver pour arbitraire\n",
        "            subproblems.append(f\"Generalisation: introduire variable, prouver corps\")\n",
        "        \n",
        "        elif \"exists\" in theorem.lower():\n",
        "            # Existentiel = trouver temoin + preuve\n",
        "            subproblems.append(f\"Temoin: trouver valeur concrete\")\n",
        "            subproblems.append(f\"Verification: prouver pour ce temoin\")\n",
        "        \n",
        "        else:\n",
        "            # Pas de decomposition evidente\n",
        "            subproblems.append(theorem)\n",
        "        \n",
        "        return subproblems\n",
        "    \n",
        "    def solve_hierarchical(self, theorem: str, solver) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Resolution hierarchique par decomposition.\n",
        "        \"\"\"\n",
        "        subproblems = self.decompose(theorem)\n",
        "        \n",
        "        if len(subproblems) == 1 and subproblems[0] == theorem:\n",
        "            # Cas de base: resoudre directement\n",
        "            return solver(theorem)\n",
        "        \n",
        "        # Resoudre chaque sous-probleme\n",
        "        solutions = []\n",
        "        for sub in subproblems:\n",
        "            success, proof = self.solve_hierarchical(sub, solver)\n",
        "            if not success:\n",
        "                return False, None\n",
        "            solutions.append(proof)\n",
        "        \n",
        "        # Combiner les solutions\n",
        "        combined = self._combine_proofs(solutions)\n",
        "        return True, combined\n",
        "    \n",
        "    def _combine_proofs(self, proofs: List[str]) -> str:\n",
        "        \"\"\"Combine des preuves de sous-problemes.\"\"\"\n",
        "        return \"\\n\".join([\n",
        "            f\"-- Partie {i+1}\\n{proof}\" \n",
        "            for i, proof in enumerate(proofs)\n",
        "        ])\n",
        "\n",
        "# Test\n",
        "decomposer = AristotleDecomposer()\n",
        "subproblems = decomposer.decompose(\"P <-> Q\")\n",
        "print(\"Decomposition de 'P <-> Q':\")\n",
        "for sp in subproblems:\n",
        "    print(f\"  - {sp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Benchmarking sur Problemes d'Erdos\n",
        "\n",
        "Les problemes d'Erdos sont devenus le benchmark de reference pour evaluer les systemes de theorem proving automatique. Plusieurs ont ete resolus par IA en 2025-2026."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test: Addition zero (difficulte: 1)\n",
            "\n",
            "============================================================\n",
            "Debut de la preuve: theorem add_zero (n : Nat) : n + 0 = n\n",
            "============================================================\n",
            "\n",
            "--- Iteration 1 ---\n",
            "Lemmes trouves: ['Nat.add_zero', 'Nat.zero_add', 'Nat.add_comm']\n",
            "Tactiques generees: ['rfl']\n",
            "\n",
            "Preuve trouvee!\n",
            "\n",
            "Test: Commutativite addition (difficulte: 2)\n",
            "\n",
            "============================================================\n",
            "Debut de la preuve: theorem add_comm (a b : Nat) : a + b = b + a\n",
            "============================================================\n",
            "\n",
            "--- Iteration 1 ---\n",
            "Lemmes trouves: ['Nat.add_zero', 'Nat.zero_add', 'Nat.add_comm']\n",
            "Tactiques generees: ['rfl']\n",
            "\n",
            "Preuve trouvee!\n",
            "\n",
            "============================================================\n",
            "RESULTATS DU BENCHMARK\n",
            "============================================================\n",
            "Resolus: 2/2 (100.0%)\n"
          ]
        }
      ],
      "source": [
        "# Benchmark sur des problemes type Erdos (simplifies)\n",
        "\n",
        "BENCHMARK_PROBLEMS = [\n",
        "    {\n",
        "        \"id\": \"simple_1\",\n",
        "        \"name\": \"Addition zero\",\n",
        "        \"statement\": \"theorem add_zero (n : Nat) : n + 0 = n\",\n",
        "        \"difficulty\": 1,\n",
        "        \"expected_tactics\": [\"exact Nat.add_zero n\", \"rfl\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"simple_2\", \n",
        "        \"name\": \"Commutativite addition\",\n",
        "        \"statement\": \"theorem add_comm (a b : Nat) : a + b = b + a\",\n",
        "        \"difficulty\": 2,\n",
        "        \"expected_tactics\": [\"exact Nat.add_comm a b\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"medium_1\",\n",
        "        \"name\": \"Associativite addition\",\n",
        "        \"statement\": \"theorem add_assoc (a b c : Nat) : (a + b) + c = a + (b + c)\",\n",
        "        \"difficulty\": 3,\n",
        "        \"expected_tactics\": [\"exact Nat.add_assoc a b c\", \"induction c\"]\n",
        "    },\n",
        "]\n",
        "\n",
        "def run_benchmark(solver, problems=BENCHMARK_PROBLEMS):\n",
        "    \"\"\"Execute le benchmark sur les problemes donnes.\"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for problem in problems:\n",
        "        print(f\"\\nTest: {problem['name']} (difficulte: {problem['difficulty']})\")\n",
        "        \n",
        "        success, proof = solver.prove(problem['statement'])\n",
        "        \n",
        "        results.append({\n",
        "            \"id\": problem[\"id\"],\n",
        "            \"success\": success,\n",
        "            \"proof\": proof\n",
        "        })\n",
        "    \n",
        "    # Statistiques\n",
        "    total = len(results)\n",
        "    solved = sum(1 for r in results if r[\"success\"])\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"RESULTATS DU BENCHMARK\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Resolus: {solved}/{total} ({100*solved/total:.1f}%)\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Executer le benchmark (limite a 3 iterations pour la demo)\n",
        "orchestrator.max_iterations = 3\n",
        "results = run_benchmark(orchestrator, BENCHMARK_PROBLEMS[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Exercices\n",
        "\n",
        "### Exercice 1 : Ameliorer l'agent de recherche"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test de ImprovedSearchAgent:\n",
            "----------------------------------------\n",
            "  Scoring 8 lemmes...\n",
            "\n",
            "Lemmes trouves pour 'n + 0 = n':\n",
            "  [1.00] Nat.add_zero: n + 0 = n\n",
            "  [0.50] Nat.zero_add: 0 + n = n\n",
            "  [0.50] Nat.add_comm: n + m = m + n\n",
            "  [0.20] Nat.add_assoc: (n + m) + k = n + (m + k)\n",
            "  [0.20] Nat.succ_add: succ n + m = succ (n + m)\n",
            "  [0.20] Nat.add_succ: n + succ m = succ (n + m)\n",
            "  [0.10] Nat.mul_zero: n * 0 = 0\n",
            "  [0.00] Nat.zero_mul: 0 * n = 0\n",
            "  Scoring 6 lemmes...\n",
            "\n",
            "Lemmes trouves pour 'a + b = b + a':\n",
            "  [1.00] Nat.add_comm: n + m = m + n\n",
            "  [0.20] Nat.add_zero: n + 0 = n\n",
            "  [0.20] Nat.zero_add: 0 + n = n\n",
            "  [0.20] Nat.add_assoc: (n + m) + k = n + (m + k)\n",
            "  [0.20] Nat.succ_add: succ n + m = succ (n + m)\n",
            "  [0.20] Nat.add_succ: n + succ m = succ (n + m)\n"
          ]
        }
      ],
      "source": [
        "# Exercice 1 - SOLUTION: Agent de recherche ameliore avec scoring LLM\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Ajouter le repertoire courant au path\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "\n",
        "# Utiliser load_env_file de lean_runner (evite les problemes d'introspection)\n",
        "from lean_runner import load_env_file\n",
        "env_path = Path.cwd() / \".env\"\n",
        "load_env_file(env_path)\n",
        "\n",
        "class ImprovedSearchAgent(TheoremSearchAgent):\n",
        "    \"\"\"\n",
        "    Version amelioree de l'agent de recherche avec scoring par LLM.\n",
        "    \n",
        "    Ameliorations:\n",
        "    1. Scoring semantique par LLM (pertinence reelle, pas juste mots-cles)\n",
        "    2. Cache des scores pour eviter les appels API redondants\n",
        "    3. Fallback sur heuristique si API non disponible\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, llm_client=None):\n",
        "        super().__init__(llm_client)\n",
        "        self.score_cache = {}  # (lemma_name, goal) -> score\n",
        "        self.api_available = self._check_api()\n",
        "    \n",
        "    def _check_api(self) -> bool:\n",
        "        \"\"\"Verifie si l'API OpenAI est disponible.\"\"\"\n",
        "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "        return api_key is not None and not api_key.startswith(\"sk-...\")\n",
        "    \n",
        "    def _score_with_llm(self, lemma: Lemma, goal: str) -> float:\n",
        "        \"\"\"\n",
        "        Score la pertinence d'un lemme par rapport au but en utilisant un LLM.\n",
        "        \n",
        "        Returns:\n",
        "            Score de pertinence entre 0.0 et 1.0\n",
        "        \"\"\"\n",
        "        # Verifier le cache\n",
        "        cache_key = (lemma.name, goal)\n",
        "        if cache_key in self.score_cache:\n",
        "            return self.score_cache[cache_key]\n",
        "        \n",
        "        # Si API non disponible, utiliser heuristique\n",
        "        if not self.api_available:\n",
        "            score = self._heuristic_score(lemma, goal)\n",
        "            self.score_cache[cache_key] = score\n",
        "            return score\n",
        "        \n",
        "        # Appel API reel\n",
        "        try:\n",
        "            from openai import OpenAI\n",
        "            client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "            \n",
        "            prompt = f\"\"\"Evalue la pertinence d'un lemme mathematique pour prouver un but en Lean 4.\n",
        "\n",
        "Lemme: {lemma.name}\n",
        "Enonce du lemme: {lemma.statement}\n",
        "\n",
        "But a prouver: {goal}\n",
        "\n",
        "Sur une echelle de 0 a 1, quelle est la pertinence de ce lemme?\n",
        "- 1.0 = Le lemme resout directement le but\n",
        "- 0.7-0.9 = Tres pertinent, peut etre utilise avec une reecriture\n",
        "- 0.4-0.6 = Moderement pertinent, structure similaire\n",
        "- 0.1-0.3 = Peu pertinent, meme domaine mais different\n",
        "- 0.0 = Aucun rapport\n",
        "\n",
        "Reponds UNIQUEMENT avec un nombre decimal entre 0 et 1.\"\"\"\n",
        "\n",
        "            # Les modeles modernes (gpt-4o, gpt-4.5, gpt-5, o1, o3) utilisent max_completion_tokens\n",
        "            model = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-5.2\")\n",
        "            use_max_completion_tokens = any(model.startswith(p) for p in ('gpt-4o', 'gpt-4.5', 'gpt-5', 'o1', 'o3'))\n",
        "            token_param = {\"max_completion_tokens\": 10} if use_max_completion_tokens else {\"max_tokens\": 10}\n",
        "            \n",
        "            response = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.1,\n",
        "                **token_param\n",
        "            )\n",
        "            \n",
        "            # Parser la reponse\n",
        "            score_text = response.choices[0].message.content.strip()\n",
        "            score = float(score_text)\n",
        "            score = max(0.0, min(1.0, score))  # Clamp entre 0 et 1\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  [Scoring LLM echoue: {e}, utilisation heuristique]\")\n",
        "            score = self._heuristic_score(lemma, goal)\n",
        "        \n",
        "        # Mettre en cache\n",
        "        self.score_cache[cache_key] = score\n",
        "        return score\n",
        "    \n",
        "    def _heuristic_score(self, lemma: Lemma, goal: str) -> float:\n",
        "        \"\"\"\n",
        "        Score heuristique base sur la correspondance de termes.\n",
        "        Utilise comme fallback quand l'API n'est pas disponible.\n",
        "        \"\"\"\n",
        "        # Normaliser les chaines\n",
        "        lemma_terms = set(lemma.statement.lower().replace(\":\", \" \").split())\n",
        "        goal_terms = set(goal.lower().replace(\":\", \" \").split())\n",
        "        \n",
        "        # Score = Jaccard similarity\n",
        "        intersection = len(lemma_terms & goal_terms)\n",
        "        union = len(lemma_terms | goal_terms)\n",
        "        \n",
        "        if union == 0:\n",
        "            return 0.0\n",
        "        \n",
        "        jaccard = intersection / union\n",
        "        \n",
        "        # Bonus si le nom du lemme correspond au type d'operation\n",
        "        bonus = 0.0\n",
        "        if \"add\" in lemma.name.lower() and \"+\" in goal:\n",
        "            bonus = 0.2\n",
        "        elif \"mul\" in lemma.name.lower() and \"*\" in goal:\n",
        "            bonus = 0.2\n",
        "        elif \"comm\" in lemma.name.lower() and (\"comm\" in goal.lower() or \n",
        "                                               (\"+b\" in goal.replace(\" \", \"\") and \"+a\" in goal.replace(\" \", \"\"))):\n",
        "            bonus = 0.15\n",
        "        \n",
        "        return min(1.0, jaccard + bonus)\n",
        "    \n",
        "    def _score_lemmas(self, lemmas: List[Lemma], goal: str) -> List[Lemma]:\n",
        "        \"\"\"Score les lemmes avec la methode amelioree.\"\"\"\n",
        "        print(f\"  Scoring {len(lemmas)} lemmes...\")\n",
        "        \n",
        "        for lemma in lemmas:\n",
        "            lemma.relevance_score = self._score_with_llm(lemma, goal)\n",
        "        \n",
        "        # Trier par pertinence decroissante\n",
        "        return sorted(lemmas, key=lambda l: l.relevance_score, reverse=True)\n",
        "\n",
        "# Test de l'agent ameliore\n",
        "print(\"Test de ImprovedSearchAgent:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "improved_agent = ImprovedSearchAgent()\n",
        "goal = \"n + 0 = n\"\n",
        "results = improved_agent.search(goal)\n",
        "\n",
        "print(f\"\\nLemmes trouves pour '{goal}':\")\n",
        "for lemma in results:\n",
        "    print(f\"  [{lemma.relevance_score:.2f}] {lemma.name}: {lemma.statement}\")\n",
        "\n",
        "# Test sur un autre but\n",
        "goal2 = \"a + b = b + a\"\n",
        "results2 = improved_agent.search(goal2)\n",
        "print(f\"\\nLemmes trouves pour '{goal2}':\")\n",
        "for lemma in results2:\n",
        "    print(f\"  [{lemma.relevance_score:.2f}] {lemma.name}: {lemma.statement}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice 2 : Ajouter de la memoire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test de ProofMemory:\n",
            "--------------------------------------------------\n",
            "Preuves stockees: 2\n",
            "\n",
            "Recall pour 'theorem my_add_zero (m : Nat) : m + 0 = m':\n",
            "  Score de similarite: 1.00\n",
            "  Preuve adaptee: exact Nat.add_zero m\n",
            "\n",
            "Statistiques memoire:\n",
            "  Patterns: 2\n",
            "  Utilisations totales: 2\n"
          ]
        }
      ],
      "source": [
        "# Exercice 2 - SOLUTION: Systeme de memoire avec pattern matching\n",
        "\n",
        "import re\n",
        "import json\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from dataclasses import dataclass, field\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "@dataclass\n",
        "class StoredProof:\n",
        "    \"\"\"Une preuve stockee avec son contexte.\"\"\"\n",
        "    theorem_pattern: str\n",
        "    original_theorem: str\n",
        "    proof: str\n",
        "    success_count: int = 1\n",
        "    variables: Dict[str, str] = field(default_factory=dict)\n",
        "\n",
        "class ProofMemory:\n",
        "    \"\"\"\n",
        "    Systeme de memoire pour reutiliser les preuves reussies.\n",
        "    \n",
        "    Fonctionnalites:\n",
        "    1. Pattern matching pour generaliser les theoremes\n",
        "    2. Recherche de preuves similaires par similarite\n",
        "    3. Adaptation des preuves au nouveau contexte\n",
        "    4. Persistence (optionnelle) vers fichier JSON\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, similarity_threshold: float = 0.7):\n",
        "        self.proofs: Dict[str, StoredProof] = {}  # pattern -> StoredProof\n",
        "        self.similarity_threshold = similarity_threshold\n",
        "    \n",
        "    def store(self, theorem: str, proof: str) -> str:\n",
        "        \"\"\"\n",
        "        Stocke une preuve reussie.\n",
        "        \n",
        "        Returns:\n",
        "            L'ID du pattern utilise pour le stockage\n",
        "        \"\"\"\n",
        "        # Extraire le pattern et les variables\n",
        "        pattern, variables = self._extract_pattern(theorem)\n",
        "        \n",
        "        if pattern in self.proofs:\n",
        "            # Incrementer le compteur de succes\n",
        "            self.proofs[pattern].success_count += 1\n",
        "        else:\n",
        "            # Nouvelle preuve\n",
        "            self.proofs[pattern] = StoredProof(\n",
        "                theorem_pattern=pattern,\n",
        "                original_theorem=theorem,\n",
        "                proof=proof,\n",
        "                variables=variables\n",
        "            )\n",
        "        \n",
        "        return pattern\n",
        "    \n",
        "    def recall(self, theorem: str) -> Optional[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Retrouve une preuve similaire.\n",
        "        \n",
        "        Returns:\n",
        "            (preuve_adaptee, score_similarite) ou None si rien trouve\n",
        "        \"\"\"\n",
        "        # Extraire le pattern du theoreme\n",
        "        query_pattern, query_vars = self._extract_pattern(theorem)\n",
        "        \n",
        "        # Recherche exacte d'abord\n",
        "        if query_pattern in self.proofs:\n",
        "            stored = self.proofs[query_pattern]\n",
        "            adapted_proof = self._adapt_proof(stored.proof, stored.variables, query_vars)\n",
        "            return adapted_proof, 1.0\n",
        "        \n",
        "        # Recherche par similarite\n",
        "        best_match = None\n",
        "        best_score = 0.0\n",
        "        \n",
        "        for pattern, stored in self.proofs.items():\n",
        "            score = self._similarity(query_pattern, pattern)\n",
        "            if score > best_score and score >= self.similarity_threshold:\n",
        "                best_score = score\n",
        "                best_match = stored\n",
        "        \n",
        "        if best_match:\n",
        "            adapted_proof = self._adapt_proof(best_match.proof, best_match.variables, query_vars)\n",
        "            return adapted_proof, best_score\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def _extract_pattern(self, theorem: str) -> Tuple[str, Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Extrait un pattern generalise du theoreme.\n",
        "        \n",
        "        Transformations:\n",
        "        - Variables specifiques -> placeholders (?x, ?y, ?z)\n",
        "        - Types conserves\n",
        "        - Structure preservee\n",
        "        \n",
        "        Exemple:\n",
        "            \"theorem foo (n : Nat) : n + 0 = n\" \n",
        "            -> \"theorem ?name (?x : Nat) : ?x + 0 = ?x\"\n",
        "        \"\"\"\n",
        "        variables = {}\n",
        "        pattern = theorem\n",
        "        \n",
        "        # Extraire le nom du theoreme\n",
        "        name_match = re.search(r'theorem\\s+(\\w+)', theorem)\n",
        "        if name_match:\n",
        "            variables['theorem_name'] = name_match.group(1)\n",
        "            pattern = re.sub(r'theorem\\s+\\w+', 'theorem ?name', pattern)\n",
        "        \n",
        "        # Extraire les variables de type Nat/Int\n",
        "        var_matches = re.findall(r'\\((\\w+)\\s*:\\s*(\\w+)\\)', theorem)\n",
        "        placeholder_index = 0\n",
        "        placeholders = ['?x', '?y', '?z', '?a', '?b', '?c']\n",
        "        \n",
        "        for var_name, var_type in var_matches:\n",
        "            if placeholder_index < len(placeholders):\n",
        "                placeholder = placeholders[placeholder_index]\n",
        "                variables[placeholder] = var_name\n",
        "                # Remplacer la variable dans tout le pattern\n",
        "                pattern = re.sub(rf'\\b{var_name}\\b', placeholder, pattern)\n",
        "                placeholder_index += 1\n",
        "        \n",
        "        return pattern, variables\n",
        "    \n",
        "    def _similarity(self, pattern1: str, pattern2: str) -> float:\n",
        "        \"\"\"\n",
        "        Calcule la similarite entre deux patterns.\n",
        "        Utilise SequenceMatcher pour une comparaison robuste.\n",
        "        \"\"\"\n",
        "        # Normaliser\n",
        "        p1 = pattern1.lower().replace(\" \", \"\")\n",
        "        p2 = pattern2.lower().replace(\" \", \"\")\n",
        "        \n",
        "        return SequenceMatcher(None, p1, p2).ratio()\n",
        "    \n",
        "    def _adapt_proof(self, proof: str, original_vars: Dict[str, str], \n",
        "                     new_vars: Dict[str, str]) -> str:\n",
        "        \"\"\"\n",
        "        Adapte une preuve au nouveau contexte en substituant les variables.\n",
        "        \"\"\"\n",
        "        adapted = proof\n",
        "        \n",
        "        for placeholder, orig_name in original_vars.items():\n",
        "            if placeholder in new_vars:\n",
        "                new_name = new_vars[placeholder]\n",
        "                # Remplacer le nom original par le nouveau\n",
        "                adapted = re.sub(rf'\\b{orig_name}\\b', new_name, adapted)\n",
        "        \n",
        "        return adapted\n",
        "    \n",
        "    def get_statistics(self) -> Dict:\n",
        "        \"\"\"Retourne des statistiques sur la memoire.\"\"\"\n",
        "        return {\n",
        "            \"total_patterns\": len(self.proofs),\n",
        "            \"total_uses\": sum(p.success_count for p in self.proofs.values()),\n",
        "            \"most_used\": max(self.proofs.values(), \n",
        "                           key=lambda p: p.success_count).theorem_pattern \n",
        "                          if self.proofs else None\n",
        "        }\n",
        "    \n",
        "    def save(self, filepath: str):\n",
        "        \"\"\"Sauvegarde la memoire dans un fichier JSON.\"\"\"\n",
        "        data = {\n",
        "            pattern: {\n",
        "                \"theorem_pattern\": sp.theorem_pattern,\n",
        "                \"original_theorem\": sp.original_theorem,\n",
        "                \"proof\": sp.proof,\n",
        "                \"success_count\": sp.success_count,\n",
        "                \"variables\": sp.variables\n",
        "            }\n",
        "            for pattern, sp in self.proofs.items()\n",
        "        }\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(data, f, indent=2)\n",
        "    \n",
        "    def load(self, filepath: str):\n",
        "        \"\"\"Charge la memoire depuis un fichier JSON.\"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        \n",
        "        self.proofs = {\n",
        "            pattern: StoredProof(**stored)\n",
        "            for pattern, stored in data.items()\n",
        "        }\n",
        "\n",
        "# Test de ProofMemory\n",
        "print(\"Test de ProofMemory:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "memory = ProofMemory()\n",
        "\n",
        "# Stocker quelques preuves\n",
        "memory.store(\n",
        "    \"theorem add_zero_n (n : Nat) : n + 0 = n\",\n",
        "    \"exact Nat.add_zero n\"\n",
        ")\n",
        "memory.store(\n",
        "    \"theorem add_comm_ab (a b : Nat) : a + b = b + a\",\n",
        "    \"exact Nat.add_comm a b\"\n",
        ")\n",
        "\n",
        "print(f\"Preuves stockees: {len(memory.proofs)}\")\n",
        "\n",
        "# Tester le recall sur un theoreme similaire\n",
        "test_theorem = \"theorem my_add_zero (m : Nat) : m + 0 = m\"\n",
        "result = memory.recall(test_theorem)\n",
        "\n",
        "if result:\n",
        "    proof, score = result\n",
        "    print(f\"\\nRecall pour '{test_theorem}':\")\n",
        "    print(f\"  Score de similarite: {score:.2f}\")\n",
        "    print(f\"  Preuve adaptee: {proof}\")\n",
        "else:\n",
        "    print(f\"\\nPas de preuve trouvee pour '{test_theorem}'\")\n",
        "\n",
        "# Statistiques\n",
        "stats = memory.get_statistics()\n",
        "print(f\"\\nStatistiques memoire:\")\n",
        "print(f\"  Patterns: {stats['total_patterns']}\")\n",
        "print(f\"  Utilisations totales: {stats['total_uses']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resume\n",
        "\n",
        "### Architecture multi-agents pour theorem proving\n",
        "\n",
        "| Agent | Role | Entrees | Sorties |\n",
        "|-------|------|---------|--------|\n",
        "| **OrchestratorAgent** | Coordonner workflow | Theoreme | Delegation + status |\n",
        "| **SearchAgent** | Trouver lemmes Mathlib | But | Liste de lemmes |\n",
        "| **TacticAgent** | Generer tactiques | But + lemmes | Sequence de tactiques |\n",
        "| **VerifierAgent** | Valider avec Lean | Code Lean | Succes/Erreur + feedback |\n",
        "\n",
        "### Patterns Semantic Kernel implementes\n",
        "\n",
        "| Pattern | Description | Classe |\n",
        "|---------|-------------|--------|\n",
        "| **StateManager** | Etat partage entre agents | `ProofState` |\n",
        "| **Plugin** | Fonctions @kernel_function | `LeanProverPlugin` |\n",
        "| **SelectionStrategy** | Choix agent suivant | `DelegatingSelectionStrategy` |\n",
        "| **TerminationStrategy** | Critere d'arret | `ProofCompleteTermination` |\n",
        "| **AgentGroupChat** | Conversation multi-agents | `AgentGroupChat` |\n",
        "\n",
        "### Techniques cles\n",
        "\n",
        "1. **Etat partage** : Tous les agents lisent/ecrivent dans `ProofState`\n",
        "2. **Delegation explicite** : Chaque agent designe le suivant via `delegate_to_agent`\n",
        "3. **Boucle de feedback** : Echecs envoyes a `TacticAgent` pour correction\n",
        "4. **Memoire de session** : Historique des tentatives pour eviter repetitions\n",
        "5. **Decomposition (Aristotle)** : Diviser problemes complexes en sous-problemes\n",
        "\n",
        "### Ressources et inspiration\n",
        "\n",
        "| Source | Contribution |\n",
        "|--------|--------------|\n",
        "| **Argument_Analysis notebooks** | Patterns SK (StateManager, orchestration) |\n",
        "| **Harmonic Aristotle** | Decomposition hierarchique, IMO Gold 2025 |\n",
        "| **APOLLO** | Generation massive, filtrage par Lean |\n",
        "| **AlphaProof** | RL + MCTS, Nature 2025 |\n",
        "| **LeanDojo** | Extraction donnees, LeanCopilot |\n",
        "\n",
        "### Impact futur\n",
        "\n",
        "Les systemes agentiques pour theorem proving representent une nouvelle frontiere:\n",
        "- **15+ problemes Erdos** resolus par IA depuis Noel 2025\n",
        "- **Acceleration x10-100** de la formalisation mathematique\n",
        "- **Decouverte** de nouvelles mathematiques par collaboration humain-IA\n",
        "- **Verification formelle** comme standard de confiance absolue\n",
        "\n",
        "---\n",
        "\n",
        "*Notebook base sur les techniques de Harmonic Aristotle (IMO Gold 2025), APOLLO (arXiv 2505), AlphaProof (Nature 2025), et les patterns Semantic Kernel inspires de Argument_Analysis*\n",
        "\n",
        "---\n",
        "\n",
        "**Navigation** : [â† Lean-7-LLM-Integration](Lean-7-LLM-Integration.ipynb) | [Index](Lean-1-Setup.ipynb) | [Lean-9-LeanDojo â†’](Lean-9-LeanDojo.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (WSL)",
      "language": "python",
      "name": "python3-wsl"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}