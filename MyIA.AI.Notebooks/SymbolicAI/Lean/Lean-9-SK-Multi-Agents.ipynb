{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Navigation** : [‚Üê Lean-8-Agentic-Proving](Lean-8-Agentic-Proving.ipynb) | [Index](Lean-1-Setup.ipynb) | [Lean-10-LeanDojo ‚Üí](Lean-10-LeanDojo.ipynb)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lean 9 : Multi-Agents avec Semantic Kernel\n",
    "\n",
    "## üéØ Architecture du Syst√®me Multi-Agents\n",
    "\n",
    "### Vue d'ensemble\n",
    "\n",
    "Notre syst√®me utilise **5 agents sp√©cialis√©s** qui collaborent pour prouver des th√©or√®mes Lean :\n",
    "\n",
    "1. **SearchAgent** : Recherche de lemmes pertinents dans Mathlib\n",
    "2. **TacticAgent** : G√©n√©ration de tactiques Lean appropri√©es\n",
    "3. **VerifierAgent** : V√©rification formelle des preuves\n",
    "4. **CriticAgent** : Analyse et suggestions d'am√©lioration\n",
    "5. **CoordinatorAgent** : Orchestration et d√©cisions strat√©giques\n",
    "\n",
    "### Pourquoi 5 agents ?\n",
    "\n",
    "Chaque agent a une **responsabilit√© unique** (principe de s√©paration des pr√©occupations) :\n",
    "\n",
    "- **S√©paration des comp√©tences** : Recherche ‚â† G√©n√©ration ‚â† V√©rification\n",
    "- **Sp√©cialisation** : Chaque LLM est prompt√© pour une t√¢che pr√©cise\n",
    "- **Robustesse** : Si un agent √©choue, les autres continuent\n",
    "- **Tra√ßabilit√©** : On sait quel agent a pris quelle d√©cision\n",
    "\n",
    "### Communication : √âtat partag√© vs Message passing\n",
    "\n",
    "Deux approches classiques en multi-agents :\n",
    "\n",
    "| **Message Passing** | **√âtat Partag√©** (notre choix) |\n",
    "|---------------------|--------------------------------|\n",
    "| Agents s'envoient des messages | Tous les agents lisent/√©crivent un √©tat central |\n",
    "| D√©centralis√© | Centralis√© |\n",
    "| Complexe √† orchestrer | Facile √† suivre |\n",
    "| Pas de snapshot global | Snapshot complet √† chaque it√©ration |\n",
    "\n",
    "**Pourquoi √©tat partag√© ?**\n",
    "\n",
    "- Besoin de **coh√©rence globale** (historique des tactiques, m√©triques)\n",
    "- **Debugging facilit√©** : On peut inspecter l'√©tat apr√®s chaque tour\n",
    "- **Snapshots JSON** : Permet de reproduire exactement une session\n",
    "- Semantic Kernel supporte ce pattern avec les **plugins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction : Semantic Kernel pour Preuves (Python)\n",
    "\n",
    "### 5.1 Vue d'ensemble\n",
    "\n",
    "Microsoft **Semantic Kernel** est un SDK qui permet d'orchestrer des LLMs avec des plugins, de la memoire et des agents intelligents. Nous allons implementer un systeme multi-agents pour theorem proving inspire des patterns utilises dans l'analyse argumentative (voir `Argument_Analysis` notebooks).\n",
    "\n",
    "**Composants cles** :\n",
    "- **Kernel** : Point d'entree principal, configure les services LLM\n",
    "- **Plugins** : Fonctions appelables par les agents (decorated avec `@kernel_function`)\n",
    "- **Agents** : Entites autonomes avec instructions et capacites\n",
    "- **Orchestration** : Strategies de selection et terminaison des agents\n",
    "\n",
    "### 5.2 Dependances\n",
    "\n",
    "```python\n",
    "# Installation\n",
    "pip install semantic-kernel openai python-dotenv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä √âtat Partag√© : La Classe `ProofState`\n",
    "\n",
    "La classe `ProofState` est le **c≈ìur du syst√®me**. Elle contient :\n",
    "\n",
    "### 1. Phase de preuve (`ProofPhase` enum)\n",
    "```\n",
    "INIT ‚Üí SEARCH ‚Üí TACTIC_GEN ‚Üí VERIFICATION ‚Üí REFINEMENT ‚Üí COMPLETE\n",
    "```\n",
    "\n",
    "Chaque phase d√©termine **quel agent agit** :\n",
    "- `INIT` ‚Üí CoordinatorAgent d√©cide de la strat√©gie\n",
    "- `SEARCH` ‚Üí SearchAgent cherche des lemmes\n",
    "- `TACTIC_GEN` ‚Üí TacticAgent g√©n√®re une tactique\n",
    "- `VERIFICATION` ‚Üí VerifierAgent teste la preuve\n",
    "- `REFINEMENT` ‚Üí CriticAgent analyse et ajuste\n",
    "- `COMPLETE` ‚Üí Session termin√©e\n",
    "\n",
    "### 2. Strat√©gie de preuve (`ProofStrategy` enum)\n",
    "\n",
    "```python\n",
    "EXPLORATION   # Recherche large de lemmes\n",
    "REFINEMENT    # Ajustement d'une preuve existante\n",
    "VALIDATION    # V√©rification formelle\n",
    "RECOVERY      # R√©cup√©ration apr√®s erreur\n",
    "```\n",
    "\n",
    "La strat√©gie influence **quels lemmes rechercher** et **quelles tactiques essayer**.\n",
    "\n",
    "### 3. Historique et m√©triques\n",
    "\n",
    "- `tactic_history` : Liste de toutes les tactiques essay√©es (succ√®s + √©checs)\n",
    "- `verification_results` : R√©sultats des v√©rifications Lean\n",
    "- `current_proof` : Preuve en construction\n",
    "- `error_count` : Nombre d'erreurs rencontr√©es\n",
    "\n",
    "### 4. Snapshots JSON\n",
    "\n",
    "√Ä chaque it√©ration, on peut sauvegarder l'√©tat complet en JSON :\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"phase\": \"TACTIC_GEN\",\n",
    "  \"strategy\": \"EXPLORATION\",\n",
    "  \"iteration\": 5,\n",
    "  \"current_goal\": \"n + 0 = n\",\n",
    "  \"tactic_history\": [...],\n",
    "  \"current_proof\": [\"intro n\", \"rw [Nat.add_zero]\"]\n",
    "}\n",
    "```\n",
    "\n",
    "**Utilit√©** : Debugging, reproduction de bugs, benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration chargee depuis: /mnt/d/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean/.env\n",
      "lean_runner importe avec succes depuis /mnt/d/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\n",
      "\n",
      "============================================================\n",
      "ProofState initialise avec succes\n",
      "LeanRunner disponible: True\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 8.1 - ProofState: Etat Partage pour Multi-Agents\n",
    "# =============================================================================\n",
    "# Pattern inspire de RhetoricalAnalysisState dans Argument_Analysis\n",
    "# Permet la synchronisation entre agents avec designation explicite\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Detection robuste du repertoire du notebook ---\n",
    "# Fonctionne sous Windows, Linux, et WSL\n",
    "notebook_dir = None\n",
    "\n",
    "# Chemins connus (Windows et WSL)\n",
    "KNOWN_PATHS = [\n",
    "    Path(\"/mnt/d/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\"),  # WSL\n",
    "    Path(\"/mnt/c/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\"),  # WSL (C:)\n",
    "    Path(\"d:/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\"),      # Windows\n",
    "    Path(\"D:/dev/CoursIA/MyIA.AI.Notebooks/SymbolicAI/Lean\"),      # Windows\n",
    "]\n",
    "\n",
    "# Strategie 1: Variable d'environnement LEAN_NOTEBOOK_DIR\n",
    "if os.getenv(\"LEAN_NOTEBOOK_DIR\"):\n",
    "    notebook_dir = Path(os.getenv(\"LEAN_NOTEBOOK_DIR\"))\n",
    "    if not (notebook_dir / \"lean_runner.py\").exists():\n",
    "        notebook_dir = None\n",
    "\n",
    "# Strategie 2: Chemins connus\n",
    "if not notebook_dir:\n",
    "    for known_path in KNOWN_PATHS:\n",
    "        if known_path.exists() and (known_path / \"lean_runner.py\").exists():\n",
    "            notebook_dir = known_path\n",
    "            break\n",
    "\n",
    "# Strategie 3: Chercher dans cwd et parents\n",
    "if not notebook_dir:\n",
    "    cwd = Path.cwd()\n",
    "    candidates = [cwd, cwd / \"MyIA.AI.Notebooks\" / \"SymbolicAI\" / \"Lean\"]\n",
    "\n",
    "    # Remonter jusqu'a 5 niveaux\n",
    "    current = cwd\n",
    "    for _ in range(5):\n",
    "        candidates.append(current)\n",
    "        lean_path = current / \"MyIA.AI.Notebooks\" / \"SymbolicAI\" / \"Lean\"\n",
    "        if lean_path.exists():\n",
    "            candidates.append(lean_path)\n",
    "        if current.parent == current:\n",
    "            break\n",
    "        current = current.parent\n",
    "\n",
    "    for candidate in candidates:\n",
    "        if candidate.exists() and (candidate / \"lean_runner.py\").exists():\n",
    "            notebook_dir = candidate\n",
    "            break\n",
    "\n",
    "# Strategie 4: Fallback sur cwd\n",
    "if not notebook_dir:\n",
    "    notebook_dir = Path.cwd()\n",
    "    print(f\"[WARN] lean_runner.py non trouve, fallback sur: {notebook_dir}\")\n",
    "\n",
    "# --- Charger .env ---\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    env_paths = [\n",
    "        notebook_dir / \".env\",\n",
    "        notebook_dir.parent / \".env\",\n",
    "        Path.home() / \".env\"\n",
    "    ]\n",
    "    for p in env_paths:\n",
    "        if p.exists():\n",
    "            load_dotenv(p, override=True)\n",
    "            print(f\"Configuration chargee depuis: {p}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Aucun fichier .env trouve\")\n",
    "except ImportError:\n",
    "    print(\"python-dotenv non installe\")\n",
    "\n",
    "# --- Importer lean_runner.py ---\n",
    "if notebook_dir and str(notebook_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(notebook_dir))\n",
    "\n",
    "try:\n",
    "    from lean_runner import LeanRunner, LeanResult\n",
    "    print(f\"lean_runner importe avec succes depuis {notebook_dir}\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERREUR: Impossible d'importer lean_runner: {e}\")\n",
    "    print(f\"Repertoire de travail: {Path.cwd()}\")\n",
    "    print(f\"notebook_dir detecte: {notebook_dir}\")\n",
    "    print(f\"sys.path: {sys.path[:5]}\")\n",
    "    raise\n",
    "\n",
    "# --- Enumerations ---\n",
    "\n",
    "class ProofStrategy(Enum):\n",
    "    \"\"\"Strategie de preuve en cours.\"\"\"\n",
    "    EXPLORATION = \"exploration\"      # Recherche initiale de lemmes\n",
    "    REFINEMENT = \"refinement\"        # Affinage des tactiques\n",
    "    VALIDATION = \"validation\"        # Verification finale\n",
    "    RECOVERY = \"recovery\"            # Recuperation apres echecs\n",
    "\n",
    "class TacticDifficulty(Enum):\n",
    "    \"\"\"Niveau de difficulte des tactiques.\"\"\"\n",
    "    SIMPLE = \"simple\"      # rfl, exact, omega\n",
    "    INTERMEDIATE = \"intermediate\"  # simp, ring, linarith\n",
    "    ADVANCED = \"advanced\"  # induction, cases\n",
    "\n",
    "class ProofPhase(Enum):\n",
    "    \"\"\"Phase de la boucle de preuve.\"\"\"\n",
    "    INIT = \"init\"\n",
    "    SEARCH = \"search\"\n",
    "    GENERATE = \"generate\"\n",
    "    VERIFY = \"verify\"\n",
    "    ANALYZE = \"analyze\"\n",
    "    COMPLETE = \"complete\"\n",
    "    FAILED = \"failed\"\n",
    "\n",
    "# --- ProofState: Etat partage entre agents ---\n",
    "\n",
    "@dataclass\n",
    "class TacticAttempt:\n",
    "    \"\"\"Une tentative de tactique.\"\"\"\n",
    "    tactic: str\n",
    "    success: bool\n",
    "    error: Optional[str] = None\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    state_before: Optional[str] = None\n",
    "    confidence: Optional[float] = None\n",
    "    explanation: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class ProofState:\n",
    "    \"\"\"\n",
    "    Etat partage entre les agents pour la preuve d'un theoreme.\n",
    "    Permet la coordination sans couplage fort.\n",
    "    \"\"\"\n",
    "    # Identifiants\n",
    "    session_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])\n",
    "    theorem_name: str = \"\"\n",
    "    theorem_statement: str = \"\"\n",
    "\n",
    "    # Etat de la preuve\n",
    "    current_goal: str = \"\"\n",
    "    current_proof: List[str] = field(default_factory=list)\n",
    "    phase: ProofPhase = ProofPhase.INIT\n",
    "    strategy: ProofStrategy = ProofStrategy.EXPLORATION\n",
    "\n",
    "    # Resultats des agents\n",
    "    discovered_lemmas: List[str] = field(default_factory=list)\n",
    "    generated_tactics: List[str] = field(default_factory=list)\n",
    "    tactic_history: List[TacticAttempt] = field(default_factory=list)\n",
    "\n",
    "    # Metriques\n",
    "    iteration: int = 0\n",
    "    max_iterations: int = 10\n",
    "    start_time: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "    # Erreurs et diagnostics\n",
    "    last_error: Optional[str] = None\n",
    "    final_proof: Optional[str] = None\n",
    "    error_count: int = 0\n",
    "\n",
    "    # Verification tracking\n",
    "    verification_results: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    total_lean_time_ms: float = 0.0\n",
    "\n",
    "    # Agent designation for orchestration\n",
    "    _next_agent: Optional[str] = field(default=None, repr=False)\n",
    "\n",
    "    def add_tactic_attempt(self, tactic: str, state_before: Optional[str] = None,\n",
    "                           confidence: Optional[float] = None, explanation: Optional[str] = None,\n",
    "                           success: bool = False, error: Optional[str] = None) -> str:\n",
    "        \"\"\"Enregistre une tentative de tactique.\"\"\"\n",
    "        attempt_id = f\"attempt_{len(self.tactic_history) + 1}\"\n",
    "        self.tactic_history.append(TacticAttempt(\n",
    "            tactic=tactic,\n",
    "            success=success,\n",
    "            error=error,\n",
    "            state_before=state_before,\n",
    "            confidence=confidence,\n",
    "            explanation=explanation\n",
    "        ))\n",
    "        if success:\n",
    "            self.current_proof.append(tactic)\n",
    "        else:\n",
    "            self.error_count += 1\n",
    "            self.last_error = error\n",
    "        return attempt_id\n",
    "\n",
    "    def add_lemma(self, name: str, statement: str, namespace: str = \"\", relevance: float = 0.5) -> str:\n",
    "        \"\"\"Ajoute un lemme decouvert a la liste.\"\"\"\n",
    "        lemma_id = f\"{namespace}.{name}\" if namespace else name\n",
    "        lemma_info = f\"{lemma_id}: {statement} (relevance: {relevance})\"\n",
    "        if lemma_info not in self.discovered_lemmas:\n",
    "            self.discovered_lemmas.append(lemma_info)\n",
    "        return lemma_id\n",
    "\n",
    "    def get_context_summary(self) -> str:\n",
    "        \"\"\"Resume le contexte pour les agents.\"\"\"\n",
    "        return f\"\"\"\n",
    "Theoreme: {self.theorem_name}\n",
    "Enonce: {self.theorem_statement}\n",
    "But actuel: {self.current_goal}\n",
    "Phase: {self.phase.value}\n",
    "Strategie: {self.strategy.value}\n",
    "Iteration: {self.iteration}/{self.max_iterations}\n",
    "Tactiques reussies: {len(self.current_proof)}\n",
    "Erreurs: {self.error_count}\n",
    "Derniere erreur: {self.last_error or 'Aucune'}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # --- Properties for compatibility ---\n",
    "    @property\n",
    "    def tactics_history(self) -> List[TacticAttempt]:\n",
    "        \"\"\"Alias pour tactic_history (compatibilite).\"\"\"\n",
    "        return self.tactic_history\n",
    "\n",
    "    @property\n",
    "    def proof_complete(self) -> bool:\n",
    "        \"\"\"True si la preuve est complete.\"\"\"\n",
    "        return self.phase == ProofPhase.COMPLETE\n",
    "    \n",
    "    @proof_complete.setter\n",
    "    def proof_complete(self, value: bool):\n",
    "        \"\"\"Definit la completion de la preuve.\"\"\"\n",
    "        if value:\n",
    "            self.phase = ProofPhase.COMPLETE\n",
    "        elif self.phase == ProofPhase.COMPLETE:\n",
    "            self.phase = ProofPhase.VERIFY\n",
    "    \n",
    "    @property\n",
    "    def iteration_count(self) -> int:\n",
    "        \"\"\"Alias pour iteration (compatibilite).\"\"\"\n",
    "        return self.iteration\n",
    "    \n",
    "    @iteration_count.setter\n",
    "    def iteration_count(self, value: int):\n",
    "        \"\"\"Definit le compteur d'iterations.\"\"\"\n",
    "        self.iteration = value\n",
    "\n",
    "    def increment_iteration(self):\n",
    "        \"\"\"Incremente le compteur d'iterations.\"\"\"\n",
    "        self.iteration += 1\n",
    "    \n",
    "    def designate_next_agent(self, agent_name: str):\n",
    "        \"\"\"Designe l'agent qui doit intervenir ensuite.\"\"\"\n",
    "        self._next_agent = agent_name\n",
    "    \n",
    "    def consume_next_agent_designation(self) -> Optional[str]:\n",
    "        \"\"\"Retourne et efface la designation d'agent.\"\"\"\n",
    "        agent = self._next_agent\n",
    "        self._next_agent = None\n",
    "        return agent\n",
    "    \n",
    "    def get_state_snapshot(self, summarize: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"Retourne un snapshot de l'etat pour les plugins.\"\"\"\n",
    "        if summarize:\n",
    "            return {\n",
    "                \"session_id\": self.session_id,\n",
    "                \"theorem\": self.theorem_statement,\n",
    "                \"goal\": self.current_goal,\n",
    "                \"phase\": self.phase.value,\n",
    "                \"strategy\": self.strategy.value,\n",
    "                \"iteration\": f\"{self.iteration}/{self.max_iterations}\",\n",
    "                \"proof_steps\": len(self.current_proof),\n",
    "                \"discovered_lemmas\": len(self.discovered_lemmas),\n",
    "                \"errors\": self.error_count,\n",
    "                \"last_error\": self.last_error\n",
    "            }\n",
    "        else:\n",
    "            return self.to_dict()\n",
    "\n",
    "\n",
    "    def add_verification(self, attempt_id: str, success: bool, output: str, errors: str,\n",
    "                         remaining_goals: Optional[str] = None, exec_time_ms: float = 0.0,\n",
    "                         mode: str = \"subprocess\") -> str:\n",
    "        \"\"\"Enregistre un r√©sultat de v√©rification Lean.\"\"\"\n",
    "        verif_id = f\"verif_{len(self.verification_results) + 1}\"\n",
    "        self.verification_results.append({\n",
    "            \"id\": verif_id,\n",
    "            \"attempt_id\": attempt_id,\n",
    "            \"success\": success,\n",
    "            \"output\": output,\n",
    "            \"errors\": errors,\n",
    "            \"remaining_goals\": remaining_goals,\n",
    "            \"exec_time_ms\": exec_time_ms,\n",
    "            \"mode\": mode,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        return verif_id\n",
    "\n",
    "\n",
    "    def set_proof_complete(self, proof: str):\n",
    "        \"\"\"Marque la preuve comme termin√©e et change la phase.\"\"\"\n",
    "        self.final_proof = proof\n",
    "        self.phase = ProofPhase.COMPLETE\n",
    "\n",
    "\n",
    "    def set_strategy(self, strategy: 'ProofStrategy'):\n",
    "        \"\"\"Change la strat√©gie de preuve.\"\"\"\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Serialise l'etat.\"\"\"\n",
    "        return {\n",
    "            \"session_id\": self.session_id,\n",
    "            \"theorem_name\": self.theorem_name,\n",
    "            \"theorem_statement\": self.theorem_statement,\n",
    "            \"current_goal\": self.current_goal,\n",
    "            \"current_proof\": self.current_proof,\n",
    "            \"phase\": self.phase.value,\n",
    "            \"strategy\": self.strategy.value,\n",
    "            \"discovered_lemmas\": self.discovered_lemmas,\n",
    "            \"generated_tactics\": self.generated_tactics,\n",
    "            \"iteration\": self.iteration,\n",
    "            \"max_iterations\": self.max_iterations,\n",
    "            \"error_count\": self.error_count,\n",
    "            \"last_error\": self.last_error\n",
    "        }\n",
    "\n",
    "# --- Test de l'initialisation ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ProofState initialise avec succes\")\n",
    "print(f\"LeanRunner disponible: {LeanRunner is not None}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Vue d'ensemble des Plugins\n",
    "\n",
    "L'architecture utilise 4 plugins specialises, chacun exposant des fonctions via `@kernel_function`:\n",
    "\n",
    "| Plugin | Role | Fonctions cles |\n",
    "|--------|------|----------------|\n",
    "| **ProofStateManagerPlugin** | Gestion de l'etat | get_proof_state, add_lemma, designate_next_agent |\n",
    "| **LeanSearchPlugin** | Recherche Mathlib | search_mathlib_lemmas, check_lemma_type |\n",
    "| **LeanTacticPlugin** | Generation tactiques | generate_tactics, analyze_tactic_failure |\n",
    "| **LeanVerificationPlugin** | Verification Lean | verify_proof, verify_tactic_step |\n",
    "\n",
    "Ce pattern permet aux agents d'appeler ces fonctions automatiquement grace au `FunctionChoiceBehavior.Auto()` de Semantic Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Plugins Semantic Kernel : Exposer l'√âtat aux Agents\n",
    "\n",
    "### Probl√®me\n",
    "\n",
    "Les agents LLM ne peuvent pas acc√©der directement √† `ProofState` (objet Python).\n",
    "\n",
    "### Solution : Plugins\n",
    "\n",
    "Un **plugin Semantic Kernel** expose des m√©thodes Python comme **fonctions appelables par le LLM**.\n",
    "\n",
    "```python\n",
    "@kernel_function(\n",
    "    description=\"Enregistre une tentative de tactique\",\n",
    "    name=\"log_tactic_attempt\"\n",
    ")\n",
    "def log_tactic_attempt(self, tactic: str, confidence: float) -> str:\n",
    "    attempt_id = self._state.add_tactic_attempt(tactic, confidence=confidence)\n",
    "    return f\"Tactique {tactic} enregistr√©e avec ID {attempt_id}\"\n",
    "```\n",
    "\n",
    "### D√©corateur `@kernel_function`\n",
    "\n",
    "- `description` : Ce que le LLM voit (\"√Ä quoi sert cette fonction ?\")\n",
    "- `name` : Nom de la fonction pour le LLM\n",
    "- Param√®tres : Doivent correspondre **EXACTEMENT** √† ce que le plugin appelle\n",
    "\n",
    "### Les 4 plugins\n",
    "\n",
    "1. **log_tactic_attempt** : Enregistrer une tactique essay√©e\n",
    "2. **add_verification_result** : Enregistrer le r√©sultat Lean\n",
    "3. **set_proof_strategy** : Changer la strat√©gie de recherche\n",
    "4. **mark_proof_complete** : D√©clarer la preuve termin√©e\n",
    "\n",
    "### Pourquoi c'est critique ?\n",
    "\n",
    "Sans plugins, le LLM ne peut que **parler** de preuves. Avec plugins, il peut **agir** :\n",
    "\n",
    "- Essayer des tactiques\n",
    "- V√©rifier formellement\n",
    "- Ajuster sa strat√©gie en temps r√©el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Kernel disponible - utilisation des vrais decorateurs\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 8.2-8.5 - Plugins Semantic Kernel\n",
    "# =============================================================================\n",
    "# Architecture en 4 plugins specialises:\n",
    "# - ProofStateManagerPlugin: Gestion de l'etat partage\n",
    "# - LeanSearchPlugin: Recherche de lemmes Mathlib\n",
    "# - LeanTacticPlugin: Generation de tactiques\n",
    "# - LeanVerificationPlugin: Verification avec lean_runner.py\n",
    "\n",
    "# Import du decorateur kernel_function\n",
    "try:\n",
    "    from semantic_kernel.functions import kernel_function\n",
    "    SK_AVAILABLE = True\n",
    "    print(\"Semantic Kernel disponible - utilisation des vrais decorateurs\")\n",
    "except ImportError:\n",
    "    SK_AVAILABLE = False\n",
    "    print(\"Semantic Kernel non disponible - mode simulation\")\n",
    "    # Decorateur de simulation\n",
    "    def kernel_function(description=\"\", name=None):\n",
    "        def decorator(func):\n",
    "            func._sk_function = True\n",
    "            func._sk_description = description\n",
    "            func._sk_name = name or func.__name__\n",
    "            return func\n",
    "        return decorator\n",
    "\n",
    "# =============================================================================\n",
    "# 8.2 ProofStateManagerPlugin\n",
    "# =============================================================================\n",
    "\n",
    "class ProofStateManagerPlugin:\n",
    "    \"\"\"\n",
    "    Plugin pour gerer l'etat partage de la preuve.\n",
    "    Expose les methodes de ProofState via @kernel_function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state: ProofState):\n",
    "        self._state = state\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Obtient un apercu de l'etat actuel de la preuve (theoreme, lemmes, tactiques, etc.)\",\n",
    "        name=\"get_proof_state\"\n",
    "    )\n",
    "    def get_proof_state(self, summarize: bool = True) -> str:\n",
    "        \"\"\"Retourne l'etat actuel sous forme JSON.\"\"\"\n",
    "        snapshot = self._state.get_state_snapshot(summarize=summarize)\n",
    "        return json.dumps(snapshot, indent=2, ensure_ascii=False)\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Ajoute un lemme decouvert a l'etat partage\",\n",
    "        name=\"add_discovered_lemma\"\n",
    "    )\n",
    "    def add_discovered_lemma(\n",
    "        self, name: str, statement: str, namespace: str = \"\", relevance: float = 0.5\n",
    "    ) -> str:\n",
    "        \"\"\"Enregistre un lemme trouve par SearchAgent.\"\"\"\n",
    "        lemma_id = self._state.add_lemma(name, statement, namespace, relevance)\n",
    "        return f\"Lemme ajoute: {lemma_id} ({name})\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Enregistre une tentative de tactique avec son niveau de confiance\",\n",
    "        name=\"log_tactic_attempt\"\n",
    "    )\n",
    "    def log_tactic_attempt(\n",
    "        self, tactic: str, state_before: str, confidence: float = 0.5, explanation: str = \"\"\n",
    "    ) -> str:\n",
    "        \"\"\"Enregistre une tactique tentee par TacticAgent.\"\"\"\n",
    "        attempt_id = self._state.add_tactic_attempt(tactic, state_before, confidence, explanation)\n",
    "        return f\"Tactique enregistree: {attempt_id}\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Enregistre le resultat d'une verification Lean\",\n",
    "        name=\"add_verification_result\"\n",
    "    )\n",
    "    def add_verification_result(\n",
    "        self, attempt_id: str, success: bool, output: str, errors: str,\n",
    "        remaining_goals: str = \"\", exec_time_ms: float = 0.0\n",
    "    ) -> str:\n",
    "        \"\"\"Enregistre un resultat de verification.\"\"\"\n",
    "        verif_id = self._state.add_verification(\n",
    "            attempt_id, success, output, errors,\n",
    "            remaining_goals if remaining_goals else None, exec_time_ms, \"subprocess\"\n",
    "        )\n",
    "        status = \"OK\" if success else \"ECHEC\"\n",
    "        return f\"Verification {verif_id}: {status}\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Designe l'agent qui doit parler au prochain tour. IMPORTANT: utiliser le nom exact.\",\n",
    "        name=\"designate_next_agent\"\n",
    "    )\n",
    "    def designate_next_agent(self, agent_name: str) -> str:\n",
    "        \"\"\"Delegue au prochain agent.\"\"\"\n",
    "        valid_agents = [\"SearchAgent\", \"TacticAgent\", \"VerifierAgent\", \"CriticAgent\", \"CoordinatorAgent\"]\n",
    "        if agent_name not in valid_agents:\n",
    "            return f\"ERREUR: Agent invalide '{agent_name}'. Valides: {valid_agents}\"\n",
    "        self._state.designate_next_agent(agent_name)\n",
    "        return f\"Prochain agent: {agent_name}\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Marque la preuve comme terminee avec le code final\",\n",
    "        name=\"set_proof_complete\"\n",
    "    )\n",
    "    def set_proof_complete(self, proof_code: str) -> str:\n",
    "        \"\"\"Marque la preuve comme reussie.\"\"\"\n",
    "        self._state.set_proof_complete(proof_code)\n",
    "        return f\"PREUVE COMPLETE! Code: {proof_code[:100]}...\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Change la strategie de preuve (exploration, refinement, validation, recovery)\",\n",
    "        name=\"set_proof_strategy\"\n",
    "    )\n",
    "    def set_proof_strategy(self, strategy: str) -> str:\n",
    "        \"\"\"Change la strategie de preuve.\"\"\"\n",
    "        try:\n",
    "            self._state.set_strategy(ProofStrategy(strategy))\n",
    "            return f\"Strategie changee: {strategy}\"\n",
    "        except ValueError:\n",
    "            return f\"ERREUR: Strategie invalide '{strategy}'. Valides: exploration, refinement, validation, recovery\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. LeanSearchPlugin : Recherche de Lemmes Mathlib\n",
    "\n",
    "**Plugin exposant les m√©thodes de recherche** pour SearchAgent.\n",
    "\n",
    "#### M√©thodes Expos√©es\n",
    "\n",
    "```python\n",
    "@kernel_function\n",
    "def search_lemmas(goal: str, keywords: List[str]) -> List[Lemma]:\n",
    "    # Recherche dans Mathlib par keywords\n",
    "    # Retourne lemmes tri√©s par pertinence\n",
    "```\n",
    "\n",
    "**Pattern** : SearchAgent appelle ce plugin pour trouver lemmes Mathlib pertinents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8.3 LeanSearchPlugin\n",
    "# =============================================================================\n",
    "\n",
    "class LeanSearchPlugin:\n",
    "    \"\"\"\n",
    "    Plugin pour la recherche de lemmes dans Mathlib.\n",
    "    Utilise des patterns connus + verification #check via lean_runner.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, runner: LeanRunner):\n",
    "        self._runner = runner\n",
    "        # Base de lemmes connus (extensible)\n",
    "        self._known_lemmas = {\n",
    "            # Arithmetique de base\n",
    "            \"Nat.add_zero\": (\"n + 0 = n\", \"Nat\"),\n",
    "            \"Nat.zero_add\": (\"0 + n = n\", \"Nat\"),\n",
    "            \"Nat.add_comm\": (\"n + m = m + n\", \"Nat\"),\n",
    "            \"Nat.add_assoc\": (\"(n + m) + k = n + (m + k)\", \"Nat\"),\n",
    "            \"Nat.mul_one\": (\"n * 1 = n\", \"Nat\"),\n",
    "            \"Nat.one_mul\": (\"1 * n = n\", \"Nat\"),\n",
    "            \"Nat.mul_comm\": (\"n * m = m * n\", \"Nat\"),\n",
    "            \"Nat.mul_assoc\": (\"(n * m) * k = n * (m * k)\", \"Nat\"),\n",
    "            \"Nat.left_distrib\": (\"n * (m + k) = n * m + n * k\", \"Nat\"),\n",
    "            \"Nat.right_distrib\": (\"(n + m) * k = n * k + m * k\", \"Nat\"),\n",
    "            # Logique\n",
    "            \"And.intro\": (\"a -> b -> a /\\\\ b\", \"Logic\"),\n",
    "            \"And.left\": (\"a /\\\\ b -> a\", \"Logic\"),\n",
    "            \"And.right\": (\"a /\\\\ b -> b\", \"Logic\"),\n",
    "            \"Or.inl\": (\"a -> a \\\\/ b\", \"Logic\"),\n",
    "            \"Or.inr\": (\"b -> a \\\\/ b\", \"Logic\"),\n",
    "            \"Eq.refl\": (\"a = a\", \"Logic\"),\n",
    "            \"Eq.symm\": (\"a = b -> b = a\", \"Logic\"),\n",
    "            \"Eq.trans\": (\"a = b -> b = c -> a = c\", \"Logic\"),\n",
    "        }\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Recherche des lemmes Mathlib pertinents pour un but donne\",\n",
    "        name=\"search_mathlib_lemmas\"\n",
    "    )\n",
    "    def search_mathlib_lemmas(self, goal: str, max_results: int = 10) -> str:\n",
    "        \"\"\"\n",
    "        Recherche des lemmes par mots-cles.\n",
    "\n",
    "        Args:\n",
    "            goal: Description du but ou mots-cles (ex: \"addition commutative\")\n",
    "            max_results: Nombre maximum de resultats\n",
    "\n",
    "        Returns:\n",
    "            JSON avec les lemmes trouves\n",
    "        \"\"\"\n",
    "        goal_lower = goal.lower()\n",
    "        results = []\n",
    "\n",
    "        # Recherche par mots-cles\n",
    "        keywords = goal_lower.replace(\"+\", \"add\").replace(\"*\", \"mul\").replace(\"=\", \"eq\").split()\n",
    "\n",
    "        for name, (statement, namespace) in self._known_lemmas.items():\n",
    "            score = 0.0\n",
    "            name_lower = name.lower()\n",
    "\n",
    "            # Scoring par mots-cles\n",
    "            for kw in keywords:\n",
    "                if kw in name_lower:\n",
    "                    score += 0.3\n",
    "                if kw in statement.lower():\n",
    "                    score += 0.2\n",
    "\n",
    "            # Patterns specifiques\n",
    "            if \"comm\" in goal_lower and \"comm\" in name_lower:\n",
    "                score += 0.4\n",
    "            if \"assoc\" in goal_lower and \"assoc\" in name_lower:\n",
    "                score += 0.4\n",
    "            if \"zero\" in goal_lower and \"zero\" in name_lower:\n",
    "                score += 0.3\n",
    "            if \"distrib\" in goal_lower and \"distrib\" in name_lower:\n",
    "                score += 0.4\n",
    "\n",
    "            if score > 0:\n",
    "                results.append({\n",
    "                    \"name\": name,\n",
    "                    \"statement\": statement,\n",
    "                    \"namespace\": namespace,\n",
    "                    \"relevance\": min(score, 1.0)\n",
    "                })\n",
    "\n",
    "        # Trier par pertinence\n",
    "        results.sort(key=lambda x: x[\"relevance\"], reverse=True)\n",
    "        return json.dumps(results[:max_results], indent=2, ensure_ascii=False)\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Verifie qu'un lemme existe et retourne son type via #check\",\n",
    "        name=\"check_lemma_type\"\n",
    "    )\n",
    "    def check_lemma_type(self, lemma_name: str) -> str:\n",
    "        \"\"\"\n",
    "        Verifie l'existence d'un lemme via #check.\n",
    "\n",
    "        Args:\n",
    "            lemma_name: Nom du lemme (ex: \"Nat.add_comm\")\n",
    "\n",
    "        Returns:\n",
    "            JSON {exists, type, error}\n",
    "        \"\"\"\n",
    "        code = f\"#check {lemma_name}\"\n",
    "        result = self._runner.run(code)\n",
    "\n",
    "        if result.success and not result.errors:\n",
    "            # Extraire le type de la sortie\n",
    "            return json.dumps({\n",
    "                \"exists\": True,\n",
    "                \"type\": result.output.strip(),\n",
    "                \"error\": None\n",
    "            })\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"exists\": False,\n",
    "                \"type\": None,\n",
    "                \"error\": result.errors or \"Lemme non trouve\"\n",
    "            })\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8.4 LeanTacticPlugin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Plugins de Tactiques et Verification\n",
    "\n",
    "Les deux plugins restants gerent la **generation de tactiques** et la **verification formelle** :\n",
    "\n",
    "#### LeanTacticPlugin\n",
    "\n",
    "- **Responsabilite** : Generer des tactiques Lean adaptees au contexte\n",
    "- **Methodes exposees** :\n",
    "  - `generate_tactic()` : Genere une tactique basee sur goal + lemmes + historique\n",
    "  - `estimate_confidence()` : Estime la probabilite de succes (0.0-1.0)\n",
    "- **LLM-aware** : Utilise un prompt structure pour le LLM avec exemples de tactiques Lean\n",
    "- **Strategies** : `exact`, `rw`, `apply`, `simp`, `induction`, `cases`, etc.\n",
    "\n",
    "#### LeanVerificationPlugin\n",
    "\n",
    "- **Responsabilite** : Verifier les preuves via compilation Lean\n",
    "- **Methodes exposees** :\n",
    "  - `verify_proof()` : Compile le theoreme avec tactiques et retourne succes/echec\n",
    "  - `parse_lean_errors()` : Parse les messages d'erreur Lean pour feedback agents\n",
    "- **Detection de completion** : Reconnait \"no goals\" = preuve complete\n",
    "- **Gestion d'erreurs** : Extrait type d'erreur (type mismatch, tactic failed, etc.) pour CriticAgent\n",
    "\n",
    "**Flow typique** :\n",
    "```\n",
    "SearchAgent trouve lemmes\n",
    "   |\n",
    "   v\n",
    "TacticAgent genere tactique (via LeanTacticPlugin)\n",
    "   |\n",
    "   v\n",
    "VerifierAgent compile (via LeanVerificationPlugin)\n",
    "   |\n",
    "   +-- Success ‚Üí COMPLETE\n",
    "   +-- Failure ‚Üí CriticAgent analyse ‚Üí retry\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "\n",
    "class LeanTacticPlugin:\n",
    "    \"\"\"\n",
    "    Plugin pour la generation de tactiques.\n",
    "    Fournit des heuristiques et analyse les echecs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Tactiques par difficulte\n",
    "        self._tactics = {\n",
    "            \"simple\": [\"rfl\", \"trivial\", \"exact ?_\", \"assumption\"],\n",
    "            \"medium\": [\"simp\", \"omega\", \"decide\", \"constructor\", \"intro\", \"apply\"],\n",
    "            \"complex\": [\"ring\", \"linarith\", \"aesop\", \"induction\", \"cases\", \"rcases\"]\n",
    "        }\n",
    "\n",
    "        # Heuristiques par pattern de but\n",
    "        self._heuristics = {\n",
    "            \"equality\": [\"rfl\", \"exact\", \"simp\", \"ring\", \"omega\"],\n",
    "            \"forall\": [\"intro\", \"intros\", \"apply\"],\n",
    "            \"exists\": [\"use\", \"exists\", \"exact\"],\n",
    "            \"and\": [\"constructor\", \"exact And.intro\"],\n",
    "            \"or\": [\"left\", \"right\"],\n",
    "            \"implication\": [\"intro\", \"apply\", \"exact\"],\n",
    "            \"nat_arithmetic\": [\"omega\", \"simp\", \"decide\"],\n",
    "            \"ring_expression\": [\"ring\", \"ring_nf\"]\n",
    "        }\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Genere des tactiques appropriees pour un but donne\",\n",
    "        name=\"generate_tactics\"\n",
    "    )\n",
    "    def generate_tactics(self, goal: str, context: str = \"\", difficulty: str = \"simple\") -> str:\n",
    "        \"\"\"\n",
    "        Genere des tactiques pour le but courant.\n",
    "\n",
    "        Args:\n",
    "            goal: Le but Lean a prouver\n",
    "            context: Contexte additionnel (lemmes disponibles, etc.)\n",
    "            difficulty: simple, medium, ou complex\n",
    "\n",
    "        Returns:\n",
    "            JSON [{tactic, confidence, explanation}]\n",
    "        \"\"\"\n",
    "        suggestions = []\n",
    "        goal_lower = goal.lower()\n",
    "\n",
    "        # Detecter le type de but\n",
    "        detected_patterns = []\n",
    "        if \"=\" in goal:\n",
    "            detected_patterns.append(\"equality\")\n",
    "        if \"forall\" in goal_lower or \"‚àÄ\" in goal:\n",
    "            detected_patterns.append(\"forall\")\n",
    "        if \"exists\" in goal_lower or \"‚àÉ\" in goal:\n",
    "            detected_patterns.append(\"exists\")\n",
    "        if \"/\\\\\" in goal or \"‚àß\" in goal or \"And\" in goal:\n",
    "            detected_patterns.append(\"and\")\n",
    "        if \"\\\\/\" in goal or \"‚à®\" in goal or \"Or\" in goal:\n",
    "            detected_patterns.append(\"or\")\n",
    "        if \"->\" in goal or \"‚Üí\" in goal:\n",
    "            detected_patterns.append(\"implication\")\n",
    "        if any(x in goal_lower for x in [\"nat\", \"n +\", \"m +\", \"+ 0\", \"0 +\"]):\n",
    "            detected_patterns.append(\"nat_arithmetic\")\n",
    "        if any(x in goal for x in [\"*\", \"+\"]) and \"=\" in goal:\n",
    "            detected_patterns.append(\"ring_expression\")\n",
    "\n",
    "        # Collecter les tactiques suggeres\n",
    "        seen = set()\n",
    "        for pattern in detected_patterns:\n",
    "            for tactic in self._heuristics.get(pattern, []):\n",
    "                if tactic not in seen:\n",
    "                    seen.add(tactic)\n",
    "                    confidence = 0.7 if difficulty == \"simple\" else 0.5\n",
    "                    suggestions.append({\n",
    "                        \"tactic\": tactic,\n",
    "                        \"confidence\": confidence,\n",
    "                        \"explanation\": f\"Pattern detecte: {pattern}\"\n",
    "                    })\n",
    "\n",
    "        # Ajouter des tactiques de base\n",
    "        base_tactics = self._tactics.get(difficulty, self._tactics[\"simple\"])\n",
    "        for tactic in base_tactics[:3]:\n",
    "            if tactic not in seen:\n",
    "                suggestions.append({\n",
    "                    \"tactic\": tactic,\n",
    "                    \"confidence\": 0.3,\n",
    "                    \"explanation\": f\"Tactique {difficulty} generique\"\n",
    "                })\n",
    "\n",
    "        # Trier par confiance\n",
    "        suggestions.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
    "        return json.dumps(suggestions[:8], indent=2, ensure_ascii=False)\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Analyse un echec de tactique et suggere des alternatives\",\n",
    "        name=\"analyze_tactic_failure\"\n",
    "    )\n",
    "    def analyze_tactic_failure(self, failed_tactic: str, error_msg: str) -> str:\n",
    "        \"\"\"\n",
    "        Analyse pourquoi une tactique a echoue.\n",
    "\n",
    "        Args:\n",
    "            failed_tactic: La tactique qui a echoue\n",
    "            error_msg: Message d'erreur Lean\n",
    "\n",
    "        Returns:\n",
    "            JSON {diagnosis, alternatives, error_type}\n",
    "        \"\"\"\n",
    "        error_lower = error_msg.lower()\n",
    "        diagnosis = \"\"\n",
    "        alternatives = []\n",
    "        error_type = \"unknown\"\n",
    "\n",
    "        # Classifier l'erreur\n",
    "        if \"unknown identifier\" in error_lower or \"unknown constant\" in error_lower:\n",
    "            error_type = \"unknown_identifier\"\n",
    "            diagnosis = \"Lemme ou identifiant non reconnu. Verifier l'import ou le nom.\"\n",
    "            alternatives = [\"Chercher le bon nom avec #check\", \"Verifier les imports\"]\n",
    "\n",
    "        elif \"type mismatch\" in error_lower:\n",
    "            error_type = \"type_mismatch\"\n",
    "            diagnosis = \"Les types ne correspondent pas. Verifier les arguments.\"\n",
    "            alternatives = [\"exact\", \"apply\", \"simp\"]\n",
    "\n",
    "        elif \"unsolved goals\" in error_lower or \"goals remain\" in error_lower:\n",
    "            error_type = \"unsolved_goals\"\n",
    "            diagnosis = \"Des sous-buts restent. La tactique n'a pas complete la preuve.\"\n",
    "            alternatives = [\"Ajouter d'autres tactiques\", \"Essayer simp\", \"Decomposer avec have\"]\n",
    "\n",
    "        elif \"tactic failed\" in error_lower:\n",
    "            error_type = \"tactic_failed\"\n",
    "            diagnosis = f\"La tactique '{failed_tactic}' n'a pas pu s'appliquer.\"\n",
    "            # Suggerer des alternatives\n",
    "            if failed_tactic in [\"ring\", \"linarith\"]:\n",
    "                alternatives = [\"omega\", \"simp\", \"decide\"]\n",
    "            elif failed_tactic == \"simp\":\n",
    "                alternatives = [\"simp only\", \"rfl\", \"exact\"]\n",
    "            else:\n",
    "                alternatives = [\"simp\", \"omega\", \"exact ?_\"]\n",
    "\n",
    "        elif \"declaration uses 'sorry'\" in error_lower:\n",
    "            error_type = \"sorry\"\n",
    "            diagnosis = \"La preuve contient 'sorry' - incomplete.\"\n",
    "            alternatives = [\"Completer la preuve\", \"Remplacer sorry par une vraie tactique\"]\n",
    "\n",
    "        else:\n",
    "            error_type = \"other\"\n",
    "            diagnosis = f\"Erreur non classifiee: {error_msg[:100]}\"\n",
    "            alternatives = [\"Verifier la syntaxe\", \"Essayer une approche differente\"]\n",
    "\n",
    "        return json.dumps({\n",
    "            \"diagnosis\": diagnosis,\n",
    "            \"alternatives\": alternatives,\n",
    "            \"error_type\": error_type,\n",
    "            \"original_error\": error_msg[:200]\n",
    "        }, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. LeanVerificationPlugin : Compilation et V√©rification\n",
    "\n",
    "**Plugin exposant les m√©thodes de v√©rification** pour VerifierAgent.\n",
    "\n",
    "#### M√©thodes Expos√©es\n",
    "\n",
    "```python\n",
    "@kernel_function\n",
    "def verify_proof(theorem: str, tactics: str) -> VerificationResult:\n",
    "    # Compile le th√©or√®me avec tactiques\n",
    "    # Parse output Lean (success/errors)\n",
    "    # D√©tecte \"no goals\" = preuve compl√®te\n",
    "```\n",
    "\n",
    "**Pattern** : VerifierAgent appelle ce plugin pour compiler preuves avec LeanRunner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test des Plugins ===\n",
      "\n",
      "1. Recherche de lemmes pour 'addition zero':\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Nat.add_zero\",\n",
      "    \"statement\": \"n + 0 = n\",\n",
      "    \"namespace\": \"Nat\",\n",
      "    \"relevance\": 0.6\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Nat.zero_add\",\n",
      "    \"statement\": \"0 + n = n\",\n",
      "    \"namespace\": \"Nat\",\n",
      "    \"relevance\": 0.6\n",
      "  }\n",
      "]\n",
      "\n",
      "2. Tactiques pour 'n + 0 = n':\n",
      "[\n",
      "  {\n",
      "    \"tactic\": \"rfl\",\n",
      "    \"confidence\": 0.7,\n",
      "    \"explanation\": \"Pattern detecte: equality\"\n",
      "  },\n",
      "  {\n",
      "    \"tactic\": \"exact\",\n",
      "    \"confidence\": 0.7,\n",
      "    \"explanation\": \"Pattern detecte: equality\"\n",
      "  },\n",
      "  {\n",
      "    \"tactic\": \"simp\",\n",
      "    \"confidence\": 0.7,\n",
      "    \"explanation\": \"Pattern detecte: equality\"\n",
      "  },\n",
      "  {\n",
      "    \"tactic\": \"ring\",\n",
      "    \"confidence\": 0.7,\n",
      "    \"explanation\": \"Pattern detecte: equality\"\n",
      "  },\n",
      "  {\n",
      "    \"tactic\": \"omega\",\n",
      "    \"confidence\": 0.7,\n",
      "    \"explanation\": \"Pattern detecte: equality\"\n",
      "  },\n",
      "  {\n",
      "    \"tactic\": \"decide\",\n",
      "    \"confidence\": 0.7,\n",
      "    \"explanation\": \"Pattern detecte: nat_arithmetic\"\n",
      "  },\n",
      "  {\n",
      "    \"tactic\": \"ring_nf\",\n",
      "    \"confidence\": 0.7,\n",
      "    \"explanation\": \"Pattern detecte: ring_expression\"\n",
      "  },\n",
      "  {\n",
      "    \"tactic\": \"trivial\",\n",
      "    \"confidence\": 0.3,\n",
      "    \"explanation\": \"Tactique simple generique\"\n",
      "  }\n",
      "]\n",
      "\n",
      "3. Verification d'une preuve:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"output\": \"\",\n",
      "  \"errors\": \"\",\n",
      "  \"exit_code\": 0,\n",
      "  \"exec_time_ms\": 714.52,\n",
      "  \"backend\": \"subprocess\",\n",
      "  \"code\": \"theorem test_rfl : 2 + 2 = 4 := by rfl\"\n",
      "}\n",
      "\n",
      "4. Ajout via StateManagerPlugin:\n",
      "Lemme ajoute: Nat.Nat.add_zero (Nat.add_zero)\n",
      "{\n",
      "  \"session_id\": \"2be38934\",\n",
      "  \"theorem\": \"theorem test_add (n : Nat) : n + 0 = n\",\n",
      "  \"goal\": \"\",\n",
      "  \"phase\": \"init\",\n",
      "  \"strategy\": \"exploration\",\n",
      "  \"iteration\": \"0/10\",\n",
      "  \"proof_steps\": 0,\n",
      "  \"discovered_lemmas\": 1,\n",
      "  \"errors\": 0,\n",
      "  \"last_error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8.5 LeanVerificationPlugin\n",
    "# =============================================================================\n",
    "\n",
    "class LeanVerificationPlugin:\n",
    "    \"\"\"\n",
    "    Plugin pour la verification des preuves avec lean_runner.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, runner: LeanRunner):\n",
    "        self._runner = runner\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Verifie une preuve complete (theoreme + tactiques)\",\n",
    "        name=\"verify_proof\"\n",
    "    )\n",
    "    def verify_proof(self, theorem_statement: str, proof_tactics: str) -> str:\n",
    "        \"\"\"\n",
    "        Verifie un theoreme avec sa preuve.\n",
    "\n",
    "        Args:\n",
    "            theorem_statement: L'enonce du theoreme (ex: \"theorem add_zero (n : Nat) : n + 0 = n\")\n",
    "            proof_tactics: La preuve (ex: \"exact Nat.add_zero n\")\n",
    "\n",
    "        Returns:\n",
    "            JSON {success, output, errors, exec_time_ms, backend}\n",
    "        \"\"\"\n",
    "        import time\n",
    "\n",
    "        # Construire le code complet\n",
    "        if \"by\" not in proof_tactics and \":=\" not in proof_tactics:\n",
    "            code = f\"{theorem_statement} := by {proof_tactics}\"\n",
    "        elif \":=\" in proof_tactics:\n",
    "            code = f\"{theorem_statement} {proof_tactics}\"\n",
    "        else:\n",
    "            code = f\"{theorem_statement} := {proof_tactics}\"\n",
    "\n",
    "        start = time.time()\n",
    "        result = self._runner.run(code)\n",
    "        exec_time = (time.time() - start) * 1000\n",
    "\n",
    "        return json.dumps({\n",
    "            \"success\": result.success,\n",
    "            \"output\": result.output,\n",
    "            \"errors\": result.errors,\n",
    "            \"exit_code\": result.exit_code,\n",
    "            \"exec_time_ms\": round(exec_time, 2),\n",
    "            \"backend\": result.backend,\n",
    "            \"code\": code\n",
    "        }, indent=2, ensure_ascii=False)\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Verifie une etape de tactique incrementale\",\n",
    "        name=\"verify_tactic_step\"\n",
    "    )\n",
    "    def verify_tactic_step(\n",
    "        self, partial_proof: str, next_tactic: str, theorem_statement: str\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Verifie une tactique incrementale.\n",
    "\n",
    "        Args:\n",
    "            partial_proof: Les tactiques deja appliquees (separees par ;)\n",
    "            next_tactic: La prochaine tactique a essayer\n",
    "            theorem_statement: L'enonce du theoreme\n",
    "\n",
    "        Returns:\n",
    "            JSON {tactic_valid, remaining_goals, error, exec_time_ms}\n",
    "        \"\"\"\n",
    "        import time\n",
    "\n",
    "        # Combiner les tactiques\n",
    "        if partial_proof:\n",
    "            all_tactics = f\"{partial_proof}; {next_tactic}\"\n",
    "        else:\n",
    "            all_tactics = next_tactic\n",
    "\n",
    "        code = f\"{theorem_statement} := by {all_tactics}\"\n",
    "\n",
    "        start = time.time()\n",
    "        result = self._runner.run(code)\n",
    "        exec_time = (time.time() - start) * 1000\n",
    "\n",
    "        # Analyser les goals restants\n",
    "        remaining_goals = None\n",
    "        if \"unsolved goals\" in result.errors.lower():\n",
    "            # Extraire les goals du message d'erreur\n",
    "            remaining_goals = result.errors\n",
    "\n",
    "        return json.dumps({\n",
    "            \"tactic_valid\": result.success or \"unsolved goals\" not in result.errors.lower(),\n",
    "            \"remaining_goals\": remaining_goals,\n",
    "            \"error\": result.errors if not result.success else None,\n",
    "            \"exec_time_ms\": round(exec_time, 2),\n",
    "            \"applied_tactics\": all_tactics\n",
    "        }, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Test des Plugins\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== Test des Plugins ===\")\n",
    "\n",
    "# Creer l'etat et le runner\n",
    "test_state = ProofState(theorem_statement=\"theorem test_add (n : Nat) : n + 0 = n\")\n",
    "runner = LeanRunner(backend=\"subprocess\", timeout=30)\n",
    "\n",
    "# Instancier les plugins\n",
    "state_plugin = ProofStateManagerPlugin(test_state)\n",
    "search_plugin = LeanSearchPlugin(runner)\n",
    "tactic_plugin = LeanTacticPlugin()\n",
    "verif_plugin = LeanVerificationPlugin(runner)\n",
    "\n",
    "# Test 1: Recherche de lemmes\n",
    "print(\"\\n1. Recherche de lemmes pour 'addition zero':\")\n",
    "lemmas = search_plugin.search_mathlib_lemmas(\"addition zero\", max_results=3)\n",
    "print(lemmas)\n",
    "\n",
    "# Test 2: Generation de tactiques\n",
    "print(\"\\n2. Tactiques pour 'n + 0 = n':\")\n",
    "tactics = tactic_plugin.generate_tactics(\"n + 0 = n\", difficulty=\"simple\")\n",
    "print(tactics)\n",
    "\n",
    "# Test 3: Verification avec lean_runner\n",
    "print(\"\\n3. Verification d'une preuve:\")\n",
    "result = verif_plugin.verify_proof(\"theorem test_rfl : 2 + 2 = 4\", \"rfl\")\n",
    "print(result)\n",
    "\n",
    "# Test 4: Plugin StateManager\n",
    "print(\"\\n4. Ajout via StateManagerPlugin:\")\n",
    "print(state_plugin.add_discovered_lemma(\"Nat.add_zero\", \"n + 0 = n\", \"Nat\", 0.9))\n",
    "print(state_plugin.get_proof_state(summarize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Architecture : 5 Agents Specialises\n",
    "\n",
    "Le systeme multi-agents comprend 5 roles distincts:\n",
    "\n",
    "| Agent | Role | Plugins | Delegation |\n",
    "|-------|------|---------|------------|\n",
    "| **SearchAgent** | Recherche lemmes Mathlib | LeanSearch, StateManager | TacticAgent si lemmes trouves |\n",
    "| **TacticAgent** | Generation tactiques | LeanTactic, StateManager | VerifierAgent pour validation |\n",
    "| **VerifierAgent** | Verification Lean | LeanVerification, StateManager | CriticAgent si echec |\n",
    "| **CriticAgent** | Analyse echecs | LeanTactic, StateManager | Redirection selon erreur |\n",
    "| **CoordinatorAgent** | Supervision globale | StateManager | Gestion des blocages |\n",
    "\n",
    "**Pattern cle**: Chaque agent designe explicitement le suivant via `designate_next_agent()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Cr√©ation des Agents Semantic Kernel\n",
    "\n",
    "### Anatomie d'un agent\n",
    "\n",
    "Chaque agent a :\n",
    "\n",
    "1. **Un nom** : \"SearchAgent\", \"TacticAgent\", etc.\n",
    "2. **Des instructions** : Prompt syst√®me qui d√©finit son r√¥le\n",
    "3. **Des plugins** : Fonctions qu'il peut appeler (via StatePlugin)\n",
    "4. **Un mod√®le LLM** : GPT-5.2, Claude, etc.\n",
    "\n",
    "### Exemple : SearchAgent\n",
    "\n",
    "```python\n",
    "search_agent = kernel.add_agent(\n",
    "    name=\"SearchAgent\",\n",
    "    instructions=\"\"\"Tu es un expert en recherche de lemmes Mathlib.\n",
    "    Ton r√¥le : Trouver les lemmes pertinents pour le but actuel.\n",
    "    D√©l√®gue √† TacticAgent une fois les lemmes trouv√©s.\"\"\",\n",
    "    plugins=[state_plugin]\n",
    ")\n",
    "```\n",
    "\n",
    "### Instructions : Le \"m√©tier\" de l'agent\n",
    "\n",
    "Les instructions d√©finissent :\n",
    "\n",
    "- **Responsabilit√©** : \"Recherche de lemmes\" vs \"G√©n√©ration de tactiques\"\n",
    "- **Crit√®res de succ√®s** : \"Trouver au moins 2 lemmes pertinents\"\n",
    "- **D√©l√©gation** : \"Quand d√©l√©guer √† un autre agent ?\"\n",
    "\n",
    "**Principe cl√©** : Instructions pr√©cises ‚Üí Comportement pr√©visible\n",
    "\n",
    "### Pattern : Strat√©gies bas√©es sur l'√©tat\n",
    "\n",
    "Au lieu de coder en dur \"SearchAgent ‚Üí TacticAgent\", on utilise :\n",
    "\n",
    "```python\n",
    "def select_next_agent(state: ProofState) -> str:\n",
    "    if state.phase == ProofPhase.SEARCH:\n",
    "        return \"SearchAgent\"\n",
    "    elif state.phase == ProofPhase.TACTIC_GEN:\n",
    "        return \"TacticAgent\"\n",
    "    # ...\n",
    "```\n",
    "\n",
    "**Avantage** : Orchestration dynamique bas√©e sur l'√©tat r√©el de la preuve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Kernel disponible - utilisation de ChatCompletionAgent\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 8.6 - Definition des 5 Agents Specialises avec Semantic Kernel\n",
    "# =============================================================================\n",
    "# Utilise ChatCompletionAgent de Semantic Kernel avec FunctionChoiceBehavior.Auto()\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "# --- Instructions des Agents ---\n",
    "\n",
    "SEARCH_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent de RECHERCHE de lemmes pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Chercher des lemmes Mathlib pertinents pour le theoreme courant\n",
    "- Identifier les lemmes qui peuvent aider a la preuve\n",
    "- Enregistrer les lemmes trouves dans l'etat partage\n",
    "\n",
    "WORKFLOW:\n",
    "1. Lis l'etat avec get_proof_state() pour comprendre le theoreme\n",
    "2. Utilise search_mathlib_lemmas() avec des mots-cles pertinents\n",
    "3. Verifie les lemmes prometteurs avec check_lemma_type()\n",
    "4. Enregistre les lemmes utiles avec add_discovered_lemma()\n",
    "5. Delegue a TacticAgent quand tu as trouve des lemmes\n",
    "\n",
    "IMPORTANT:\n",
    "- Cherche des lemmes LIES au but (egalites, arithmetique, logique)\n",
    "- Delegation: Apres avoir trouve au moins 2-3 lemmes, delegue a TacticAgent\n",
    "- Si aucun lemme pertinent, delegue quand meme a TacticAgent\n",
    "\"\"\"\n",
    "\n",
    "TACTIC_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent de GENERATION DE TACTIQUES pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Generer des sequences de tactiques Lean pour prouver le but\n",
    "- Utiliser les lemmes trouves par SearchAgent\n",
    "- Proposer des tactiques avec niveau de confiance\n",
    "\n",
    "WORKFLOW:\n",
    "1. Lis l'etat avec get_proof_state() pour voir le theoreme et les lemmes\n",
    "2. Utilise generate_tactics() pour obtenir des suggestions\n",
    "3. Enregistre ta meilleure tentative avec log_tactic_attempt()\n",
    "4. Delegue a VerifierAgent pour verification\n",
    "\n",
    "STRATEGIES DE TACTIQUES (par difficulte):\n",
    "- SIMPLE: rfl, trivial, exact, assumption\n",
    "- MEDIUM: simp, omega, constructor, intro, apply\n",
    "- COMPLEX: ring, linarith, induction, cases\n",
    "\n",
    "IMPORTANT:\n",
    "- Commence par les tactiques simples (rfl, exact)\n",
    "- Utilise les lemmes trouves par SearchAgent (exact Nat.add_zero n)\n",
    "- Delegation: TOUJOURS deleguer a VerifierAgent apres avoir propose\n",
    "\"\"\"\n",
    "\n",
    "VERIFIER_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent de VERIFICATION pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Verifier les tactiques proposees avec le compilateur Lean\n",
    "- Enregistrer les resultats de verification\n",
    "- Determiner si la preuve est complete ou s'il faut continuer\n",
    "\n",
    "WORKFLOW:\n",
    "1. Lis l'etat avec get_proof_state() pour voir la derniere tactique\n",
    "2. Utilise verify_proof() pour tester la preuve\n",
    "3. Enregistre le resultat avec add_verification_result()\n",
    "4. Si succes: set_proof_complete() et termine\n",
    "5. Si echec: delegue a CriticAgent pour analyse\n",
    "\n",
    "IMPORTANT:\n",
    "- Teste TOUJOURS la derniere tactique proposee\n",
    "- Si la preuve compile sans erreur, utilise set_proof_complete()\n",
    "- Si echec, enregistre l'erreur et delegue a CriticAgent\n",
    "\"\"\"\n",
    "\n",
    "CRITIC_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent CRITIQUE pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Analyser les echecs de verification\n",
    "- Diagnostiquer les erreurs Lean\n",
    "- Orienter vers la bonne strategie de correction\n",
    "\n",
    "WORKFLOW:\n",
    "1. Lis l'etat avec get_proof_state() pour voir les echecs recents\n",
    "2. Utilise analyze_tactic_failure() pour comprendre l'erreur\n",
    "3. Decide quelle direction prendre:\n",
    "   - \"unknown identifier\" -> delegue a SearchAgent\n",
    "   - \"type mismatch\" ou \"tactic failed\" -> delegue a TacticAgent\n",
    "   - Echecs repetes (>3) -> delegue a CoordinatorAgent\n",
    "\n",
    "IMPORTANT:\n",
    "- Analyse les 3 derniers echecs pour detecter des patterns\n",
    "- Si >3 echecs similaires, delegue a CoordinatorAgent\n",
    "\"\"\"\n",
    "\n",
    "COORDINATOR_AGENT_INSTRUCTIONS = \"\"\"\n",
    "Tu es l'agent COORDINATEUR (superviseur) pour le theorem proving en Lean 4.\n",
    "\n",
    "TON ROLE UNIQUE:\n",
    "- Superviser l'ensemble de la session de preuve\n",
    "- Debloquer les situations cycliques\n",
    "- Ajuster la strategie globale\n",
    "\n",
    "QUAND TU INTERVIENS:\n",
    "- Appele par CriticAgent apres echecs repetes\n",
    "- Appele si max_iterations approche\n",
    "- Appele pour decisions strategiques majeures\n",
    "\n",
    "IMPORTANT:\n",
    "- Tu es le dernier recours, prends des decisions audacieuses\n",
    "- Si >40 iterations, suggere de simplifier le theoreme\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# Detection de Semantic Kernel\n",
    "# =============================================================================\n",
    "\n",
    "SK_AVAILABLE = False\n",
    "try:\n",
    "    from semantic_kernel import Kernel\n",
    "    from semantic_kernel.agents import ChatCompletionAgent, AgentGroupChat\n",
    "    from semantic_kernel.agents.strategies import (\n",
    "        KernelFunctionSelectionStrategy,\n",
    "        KernelFunctionTerminationStrategy,\n",
    "    )\n",
    "    from semantic_kernel.agents.strategies.selection.sequential_selection_strategy import SequentialSelectionStrategy\n",
    "    from semantic_kernel.agents.strategies.termination.default_termination_strategy import DefaultTerminationStrategy\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "    from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "    from semantic_kernel.functions import KernelFunctionFromPrompt, KernelArguments\n",
    "    from semantic_kernel.contents import ChatHistoryTruncationReducer\n",
    "    from semantic_kernel.agents.strategies.selection.selection_strategy import SelectionStrategy\n",
    "    from semantic_kernel.agents.strategies.termination.termination_strategy import TerminationStrategy\n",
    "    from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "    from pydantic import PrivateAttr\n",
    "    SK_AVAILABLE = True\n",
    "    print(\"Semantic Kernel disponible - utilisation de ChatCompletionAgent\")\n",
    "except ImportError as e:\n",
    "    print(f\"Semantic Kernel non disponible: {e}\")\n",
    "    print(\"Installation: pip install semantic-kernel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. SimpleAgent : Agent Fallback : Agent Fallback (Simulation)\n",
    "\n",
    "**Classe de secours** pour simuler agents quand Semantic Kernel non disponible.\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "```python\n",
    "class SimpleAgent:\n",
    "    def __init__(self, name: str, instructions: str):\n",
    "        self.name = name\n",
    "        self.instructions = instructions\n",
    "    \n",
    "    def invoke(self, message: str) -> str:\n",
    "        # Simulation simple bas√©e sur r√®gles\n",
    "        # Utilis√© en mode fallback si OpenAI API indisponible\n",
    "```\n",
    "\n",
    "**Usage** : Mode simulation pour tests sans LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Mode Simulation (fallback si SK non disponible)\n",
    "# =============================================================================\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    Agent simplifie pour simulation ou fallback.\n",
    "    Utilise directement l'API OpenAI si SK n'est pas disponible.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        instructions: str,\n",
    "        plugins: Dict[str, Any],\n",
    "        use_simulation: bool = True\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.instructions = instructions\n",
    "        self.plugins = plugins\n",
    "        self.use_simulation = use_simulation\n",
    "        self._openai_client = None\n",
    "\n",
    "        # Initialiser le client OpenAI si mode reel\n",
    "        if not use_simulation:\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "                if api_key and len(api_key) > 10 and not api_key.startswith(\"sk-...\"):\n",
    "                    self._openai_client = OpenAI(api_key=api_key)\n",
    "            except ImportError:\n",
    "                pass\n",
    "\n",
    "    def _build_openai_tools(self) -> list:\n",
    "        \"\"\"Construit les outils au format OpenAI function calling.\"\"\"\n",
    "        import inspect\n",
    "        tools = []\n",
    "        for plugin_name, plugin in self.plugins.items():\n",
    "            for attr_name in dir(plugin):\n",
    "                attr = getattr(plugin, attr_name)\n",
    "                if not callable(attr):\n",
    "                    continue\n",
    "                # Supporter les deux d√©corateurs\n",
    "                is_sk_func = hasattr(attr, '_sk_function') or hasattr(attr, '__kernel_function__')\n",
    "                if not is_sk_func:\n",
    "                    continue\n",
    "\n",
    "                sig = inspect.signature(attr)\n",
    "                properties = {}\n",
    "                required = []\n",
    "                for param_name, param in sig.parameters.items():\n",
    "                    if param_name == 'self':\n",
    "                        continue\n",
    "                    param_type = \"string\"\n",
    "                    if param.annotation != inspect.Parameter.empty:\n",
    "                        if param.annotation == bool:\n",
    "                            param_type = \"boolean\"\n",
    "                        elif param.annotation in (int, float):\n",
    "                            param_type = \"number\"\n",
    "                    properties[param_name] = {\n",
    "                        \"type\": param_type,\n",
    "                        \"description\": f\"Parameter {param_name}\"\n",
    "                    }\n",
    "                    if param.default == inspect.Parameter.empty:\n",
    "                        required.append(param_name)\n",
    "\n",
    "                # Obtenir nom et description\n",
    "                if hasattr(attr, '__kernel_function_name__'):\n",
    "                    func_name = attr.__kernel_function_name__\n",
    "                    func_desc = getattr(attr, \"__kernel_function_description__\", \"\")\n",
    "                elif hasattr(attr, '_sk_name'):\n",
    "                    func_name = attr._sk_name\n",
    "                    func_desc = getattr(attr, \"_sk_description\", \"\")\n",
    "                else:\n",
    "                    func_name = attr_name\n",
    "                    func_desc = \"\"\n",
    "\n",
    "                tools.append({\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": f\"{plugin_name}__{func_name}\",\n",
    "                        \"description\": func_desc,\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": properties,\n",
    "                            \"required\": required\n",
    "                        }\n",
    "                    }\n",
    "                })\n",
    "        return tools\n",
    "\n",
    "    def _execute_tool_call(self, tool_name: str, arguments: dict) -> str:\n",
    "        \"\"\"Execute un appel de fonction sur un plugin.\"\"\"\n",
    "        parts = tool_name.split(\"__\", 1)\n",
    "        if len(parts) != 2:\n",
    "            return f\"Erreur: format invalide: {tool_name}\"\n",
    "\n",
    "        plugin_name, func_name = parts\n",
    "        plugin = self.plugins.get(plugin_name)\n",
    "        if not plugin:\n",
    "            return f\"Erreur: plugin {plugin_name} non trouve\"\n",
    "\n",
    "        for attr_name in dir(plugin):\n",
    "            attr = getattr(plugin, attr_name)\n",
    "            if not callable(attr):\n",
    "                continue\n",
    "            is_sk = hasattr(attr, '_sk_function') or hasattr(attr, '__kernel_function__')\n",
    "            if not is_sk:\n",
    "                continue\n",
    "\n",
    "            if hasattr(attr, '__kernel_function_name__'):\n",
    "                name = attr.__kernel_function_name__\n",
    "            elif hasattr(attr, '_sk_name'):\n",
    "                name = attr._sk_name\n",
    "            else:\n",
    "                name = attr_name\n",
    "\n",
    "            if name == func_name:\n",
    "                try:\n",
    "                    result = attr(**arguments)\n",
    "                    return str(result)\n",
    "                except Exception as e:\n",
    "                    return f\"Erreur {func_name}: {e}\"\n",
    "\n",
    "        return f\"Erreur: {func_name} non trouve dans {plugin_name}\"\n",
    "\n",
    "    def invoke(self, message: str, state: ProofState) -> str:\n",
    "        \"\"\"Execute l'agent sur un message.\"\"\"\n",
    "        state.increment_iteration()\n",
    "\n",
    "        if self.use_simulation or not self._openai_client:\n",
    "            return self._simulate_response(message, state)\n",
    "        else:\n",
    "            return self._call_llm(message, state)\n",
    "\n",
    "    def _simulate_response(self, message: str, state: ProofState) -> str:\n",
    "        \"\"\"\n",
    "        Simulation realiste basee sur l'analyse du theoreme.\n",
    "        La complexite vient du nombre de lemmes necessaires.\n",
    "        \"\"\"\n",
    "        theorem = state.theorem_statement.lower()\n",
    "        goal = state.current_goal or \"\"\n",
    "\n",
    "        if self.name == \"SearchAgent\":\n",
    "            return self._do_search(state, theorem, goal)\n",
    "        elif self.name == \"TacticAgent\":\n",
    "            return self._do_tactic(state, theorem, goal)\n",
    "        elif self.name == \"VerifierAgent\":\n",
    "            return self._do_verify(state, theorem, goal)\n",
    "        elif self.name == \"CriticAgent\":\n",
    "            return self._do_critic(state, theorem)\n",
    "        elif self.name == \"CoordinatorAgent\":\n",
    "            return self._do_coordinate(state, theorem)\n",
    "\n",
    "        return f\"[{self.name}] Action simulee.\"\n",
    "\n",
    "    def _do_search(self, state: ProofState, theorem: str, goal: str) -> str:\n",
    "        \"\"\"Recherche de lemmes basee sur le theoreme.\"\"\"\n",
    "        search = self.plugins.get(\"search\")\n",
    "        state_mgr = self.plugins.get(\"state\")\n",
    "\n",
    "        if not search or not state_mgr:\n",
    "            return \"[SearchAgent] Plugins manquants.\"\n",
    "\n",
    "        lemmas_found = []\n",
    "\n",
    "        if \"n = n\" in theorem or goal.strip() == \"n = n\":\n",
    "            state_mgr.add_discovered_lemma(\"Eq.refl\", \"a = a\", \"Logic\", 1.0)\n",
    "            lemmas_found.append(\"Eq.refl\")\n",
    "\n",
    "        if \"+ 0\" in theorem or \"0 +\" in theorem:\n",
    "            state_mgr.add_discovered_lemma(\"Nat.add_zero\", \"n + 0 = n\", \"Nat\", 0.9)\n",
    "            lemmas_found.append(\"Nat.add_zero\")\n",
    "\n",
    "        if \"+\" in theorem and (\"m + n\" in theorem or \"n + m\" in theorem or \"b + a\" in theorem or \"d + c\" in theorem):\n",
    "            state_mgr.add_discovered_lemma(\"Nat.add_comm\", \"n + m = m + n\", \"Nat\", 0.85)\n",
    "            lemmas_found.append(\"Nat.add_comm\")\n",
    "\n",
    "        if theorem.count(\"+\") >= 2:\n",
    "            state_mgr.add_discovered_lemma(\"Nat.add_assoc\", \"(n + m) + k = n + (m + k)\", \"Nat\", 0.8)\n",
    "            lemmas_found.append(\"Nat.add_assoc\")\n",
    "\n",
    "        if \"*\" in theorem and \"+\" in theorem:\n",
    "            state_mgr.add_discovered_lemma(\"Nat.right_distrib\", \"(n + m) * k = n * k + m * k\", \"Nat\", 0.9)\n",
    "            lemmas_found.append(\"Nat.right_distrib\")\n",
    "\n",
    "        state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "        return f\"[SearchAgent] Lemmes: {', '.join(lemmas_found[:3])}. -> TacticAgent\"\n",
    "\n",
    "    def _do_tactic(self, state: ProofState, theorem: str, goal: str) -> str:\n",
    "        \"\"\"Generation de tactiques.\"\"\"\n",
    "        state_mgr = self.plugins.get(\"state\")\n",
    "        if not state_mgr:\n",
    "            return \"[TacticAgent] Plugin manquant.\"\n",
    "\n",
    "        tactics_tried = len(state.tactics_history)\n",
    "\n",
    "        # DEMO_1\n",
    "        if \"n = n\" in theorem:\n",
    "            state_mgr.log_tactic_attempt(\"rfl\", goal, 1.0, \"Reflexivite\")\n",
    "            state_mgr.designate_next_agent(\"VerifierAgent\")\n",
    "            return \"[TacticAgent] Tactique: rfl. -> VerifierAgent\"\n",
    "\n",
    "        # DEMO_2\n",
    "        if \"n + m + 0 = m + n\" in theorem:\n",
    "            if tactics_tried == 0:\n",
    "                state_mgr.log_tactic_attempt(\"simp [Nat.add_zero]\", goal, 0.6, \"Etape 1\")\n",
    "                state_mgr.designate_next_agent(\"VerifierAgent\")\n",
    "                return \"[TacticAgent] Etape 1: simp [Nat.add_zero]. -> VerifierAgent\"\n",
    "            else:\n",
    "                state_mgr.log_tactic_attempt(\"simp [Nat.add_zero, Nat.add_comm]\", goal, 0.95, \"Complete\")\n",
    "                state_mgr.designate_next_agent(\"VerifierAgent\")\n",
    "                return \"[TacticAgent] Tactique: simp [Nat.add_zero, Nat.add_comm]. -> VerifierAgent\"\n",
    "\n",
    "        # DEMO_3\n",
    "        if \"quad_comm\" in theorem:\n",
    "            if tactics_tried < 3:\n",
    "                tactic = [\"rw [Nat.add_comm c d]\", \"rw [Nat.add_comm a b]\", \"rw [Nat.add_comm]\"][min(tactics_tried, 2)]\n",
    "                state_mgr.log_tactic_attempt(tactic, goal, 0.5 + tactics_tried * 0.1, f\"Etape {tactics_tried+1}\")\n",
    "                state_mgr.designate_next_agent(\"VerifierAgent\")\n",
    "                return f\"[TacticAgent] Etape {tactics_tried+1}/4: {tactic}. -> VerifierAgent\"\n",
    "            else:\n",
    "                state_mgr.log_tactic_attempt(\"simp only [Nat.add_comm, Nat.add_assoc, Nat.add_left_comm]\", goal, 0.95, \"AC norm\")\n",
    "                state_mgr.designate_next_agent(\"VerifierAgent\")\n",
    "                return \"[TacticAgent] Tactique finale: AC normalization. -> VerifierAgent\"\n",
    "\n",
    "        # DEMO_4\n",
    "        if \"distrib_both\" in theorem:\n",
    "            tactics = [\"rw [Nat.right_distrib]\", \"rw [Nat.add_assoc]\", \"rw [Nat.add_comm (a*c)]\", \"rw [<-Nat.add_assoc]\", \"ring\"]\n",
    "            if tactics_tried < len(tactics):\n",
    "                t = tactics[tactics_tried]\n",
    "                state_mgr.log_tactic_attempt(t, goal, 0.5 + tactics_tried * 0.1, f\"Etape {tactics_tried+1}\")\n",
    "                state_mgr.designate_next_agent(\"VerifierAgent\")\n",
    "                return f\"[TacticAgent] Etape {tactics_tried+1}/5: {t}. -> VerifierAgent\"\n",
    "            else:\n",
    "                state_mgr.log_tactic_attempt(\"ring\", goal, 0.95, \"Solveur\")\n",
    "                state_mgr.designate_next_agent(\"VerifierAgent\")\n",
    "                return \"[TacticAgent] Tactique finale: ring. -> VerifierAgent\"\n",
    "\n",
    "        state_mgr.log_tactic_attempt(\"simp\", goal, 0.3, \"Fallback\")\n",
    "        state_mgr.designate_next_agent(\"VerifierAgent\")\n",
    "        return \"[TacticAgent] simp. -> VerifierAgent\"\n",
    "\n",
    "    def _do_verify(self, state: ProofState, theorem: str, goal: str) -> str:\n",
    "        \"\"\"Verification.\"\"\"\n",
    "        state_mgr = self.plugins.get(\"state\")\n",
    "        if not state_mgr or not state.tactics_history:\n",
    "            return \"[VerifierAgent] Rien a verifier.\"\n",
    "\n",
    "        last = state.tactics_history[-1]\n",
    "        n = len(state.tactics_history)\n",
    "        attempt_id = f\"attempt_{n}\"\n",
    "\n",
    "        # DEMO_1\n",
    "        if \"rfl\" in last.tactic and \"n = n\" in theorem:\n",
    "            state_mgr.add_verification_result(attempt_id, True, \"OK\", \"\", \"\", 50.0)\n",
    "            state_mgr.set_proof_complete(last.tactic)\n",
    "            return f\"[VerifierAgent] SUCCES! {last.tactic}\"\n",
    "\n",
    "        # DEMO_2\n",
    "        if \"n + m + 0 = m + n\" in theorem:\n",
    "            if n == 1:\n",
    "                state_mgr.add_verification_result(attempt_id, False, \"n+m = m+n\", \"not closed\", \"\", 80.0)\n",
    "                state_mgr.designate_next_agent(\"CriticAgent\")\n",
    "                return \"[VerifierAgent] Progres. But restant. -> CriticAgent\"\n",
    "            else:\n",
    "                state_mgr.add_verification_result(attempt_id, True, \"OK\", \"\", \"\", 100.0)\n",
    "                state_mgr.set_proof_complete(last.tactic)\n",
    "                return f\"[VerifierAgent] SUCCES apres {n} etapes!\"\n",
    "\n",
    "        # DEMO_3\n",
    "        if \"quad_comm\" in theorem:\n",
    "            if n < 4:\n",
    "                state_mgr.add_verification_result(attempt_id, False, f\"{n}/4\", \"continue\", \"\", 100.0)\n",
    "                state_mgr.designate_next_agent(\"CriticAgent\")\n",
    "                return f\"[VerifierAgent] Etape {n}/4 OK. -> CriticAgent\"\n",
    "            else:\n",
    "                state_mgr.add_verification_result(attempt_id, True, \"OK\", \"\", \"\", 150.0)\n",
    "                state_mgr.set_proof_complete(last.tactic)\n",
    "                return f\"[VerifierAgent] SUCCES apres {n} reecritures!\"\n",
    "\n",
    "        # DEMO_4\n",
    "        if \"distrib_both\" in theorem:\n",
    "            if n < 5:\n",
    "                state_mgr.add_verification_result(attempt_id, False, f\"{n}/5\", \"continue\", \"\", 120.0)\n",
    "                state_mgr.designate_next_agent(\"CriticAgent\")\n",
    "                return f\"[VerifierAgent] Etape {n}/5. -> CriticAgent\"\n",
    "            else:\n",
    "                state_mgr.add_verification_result(attempt_id, True, \"OK\", \"\", \"\", 200.0)\n",
    "                state_mgr.set_proof_complete(last.tactic)\n",
    "                return f\"[VerifierAgent] SUCCES apres {n} etapes!\"\n",
    "\n",
    "        state_mgr.add_verification_result(attempt_id, False, \"\", \"error\", \"\", 50.0)\n",
    "        state_mgr.designate_next_agent(\"CriticAgent\")\n",
    "        return \"[VerifierAgent] Echec. -> CriticAgent\"\n",
    "\n",
    "    def _do_critic(self, state: ProofState, theorem: str) -> str:\n",
    "        \"\"\"Analyse critique.\"\"\"\n",
    "        state_mgr = self.plugins.get(\"state\")\n",
    "        if not state_mgr:\n",
    "            return \"[CriticAgent] Plugin manquant.\"\n",
    "\n",
    "        n = len(state.tactics_history)\n",
    "\n",
    "        if \"n + m + 0 = m + n\" in theorem:\n",
    "            state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "            return \"[CriticAgent] add_zero OK, besoin add_comm. -> TacticAgent\"\n",
    "\n",
    "        if \"quad_comm\" in theorem:\n",
    "            if n < 3:\n",
    "                state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "                return f\"[CriticAgent] Continuer reecritures ({n}/4). -> TacticAgent\"\n",
    "            else:\n",
    "                state_mgr.designate_next_agent(\"CoordinatorAgent\")\n",
    "                return \"[CriticAgent] Besoin strategie globale. -> CoordinatorAgent\"\n",
    "\n",
    "        if \"distrib_both\" in theorem:\n",
    "            if n < 4:\n",
    "                state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "                return f\"[CriticAgent] Continuer decomposition ({n}/5). -> TacticAgent\"\n",
    "            else:\n",
    "                state_mgr.designate_next_agent(\"CoordinatorAgent\")\n",
    "                return \"[CriticAgent] Finaliser. -> CoordinatorAgent\"\n",
    "\n",
    "        state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "        return \"[CriticAgent] Reessayer. -> TacticAgent\"\n",
    "\n",
    "    def _do_coordinate(self, state: ProofState, theorem: str) -> str:\n",
    "        \"\"\"Coordination.\"\"\"\n",
    "        state_mgr = self.plugins.get(\"state\")\n",
    "        if not state_mgr:\n",
    "            return \"[CoordinatorAgent] Plugin manquant.\"\n",
    "\n",
    "        if \"quad_comm\" in theorem:\n",
    "            state_mgr.set_proof_strategy(\"ac_normalization\")\n",
    "            state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "            return \"[CoordinatorAgent] Strategie: AC normalization. -> TacticAgent\"\n",
    "\n",
    "        if \"distrib_both\" in theorem:\n",
    "            state_mgr.set_proof_strategy(\"ring_solver\")\n",
    "            state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "            return \"[CoordinatorAgent] Strategie: ring solver. -> TacticAgent\"\n",
    "\n",
    "        state_mgr.designate_next_agent(\"TacticAgent\")\n",
    "        return \"[CoordinatorAgent] Default. -> TacticAgent\"\n",
    "\n",
    "\n",
    "    def _call_llm(self, message: str, state: ProofState) -> str:\n",
    "        \"\"\"Appelle le LLM OpenAI avec function calling.\"\"\"\n",
    "        state_summary = json.dumps(state.get_state_snapshot(summarize=True), indent=2)\n",
    "        tools = self._build_openai_tools()\n",
    "\n",
    "        nl = chr(10)\n",
    "        user_content = f\"ETAT ACTUEL:{nl}{state_summary}{nl}{nl}TACHE:{nl}{message}\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.instructions},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "        ]\n",
    "\n",
    "        max_tool_calls = 10\n",
    "        tool_results = []\n",
    "\n",
    "        for iteration in range(max_tool_calls):\n",
    "            try:\n",
    "                model = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-5.2\")\n",
    "                use_mct = any(model.startswith(p) for p in ('gpt-4.5', 'gpt-5', 'o1', 'o3'))\n",
    "                token_param = {\"max_completion_tokens\": 1000} if use_mct else {\"max_tokens\": 1000}\n",
    "\n",
    "                response = self._openai_client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    tools=tools if tools else None,\n",
    "                    tool_choice=\"auto\" if tools else None,\n",
    "                    temperature=0.3,\n",
    "                    **token_param\n",
    "                )\n",
    "\n",
    "                assistant_message = response.choices[0].message\n",
    "\n",
    "                if assistant_message.tool_calls:\n",
    "                    messages.append(assistant_message.model_dump())\n",
    "\n",
    "                    for tool_call in assistant_message.tool_calls:\n",
    "                        func_name = tool_call.function.name\n",
    "                        try:\n",
    "                            arguments = json.loads(tool_call.function.arguments)\n",
    "                        except json.JSONDecodeError:\n",
    "                            arguments = {}\n",
    "\n",
    "                        result = self._execute_tool_call(func_name, arguments)\n",
    "                        tool_results.append(func_name.split(\"__\")[-1])\n",
    "\n",
    "                        messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"content\": result\n",
    "                        })\n",
    "                else:\n",
    "                    final_response = assistant_message.content or \"(pas de reponse)\"\n",
    "                    if tool_results:\n",
    "                        actions = \", \".join(tool_results[:5])\n",
    "                        final_response = f\"Actions: {actions}{nl}{final_response}\"\n",
    "                    return f\"[{self.name}] {final_response}\"\n",
    "\n",
    "            except Exception as e:\n",
    "                return f\"[{self.name}] Erreur LLM: {e}\"\n",
    "\n",
    "        actions = \", \".join(tool_results[:5])\n",
    "        return f\"[{self.name}] Max tool calls. Actions: {actions}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Patterns de Delegation Multi-Agents\n",
    "\n",
    "Les instructions ci-dessus definissent les **regles de delegation** entre agents :\n",
    "\n",
    "| Agent | Role | Delegue vers |\n",
    "|-------|------|-------------|\n",
    "| **SearchAgent** | Recherche lemmes Mathlib | TacticAgent (si lemmes trouves) |\n",
    "| **TacticAgent** | Genere tactiques Lean | VerifierAgent (toujours) |\n",
    "| **VerifierAgent** | Verifie preuve formelle | CriticAgent (si echec) / COMPLETE (si succes) |\n",
    "| **CriticAgent** | Analyse erreurs | SearchAgent (retry) / CoordinatorAgent (si bloque) |\n",
    "| **CoordinatorAgent** | Re-orchestre strategie | SearchAgent (nouvelle strategie) |\n",
    "\n",
    "**Flow nominal** (preuve simple) :\n",
    "```\n",
    "SearchAgent ‚Üí TacticAgent ‚Üí VerifierAgent ‚Üí COMPLETE\n",
    "```\n",
    "\n",
    "**Flow avec echec** (preuve complexe) :\n",
    "```\n",
    "SearchAgent ‚Üí TacticAgent ‚Üí VerifierAgent (FAIL)\n",
    "   ‚Üì\n",
    "CriticAgent analyse erreur\n",
    "   ‚Üì\n",
    "   +-- Erreur simple ‚Üí SearchAgent (retry avec nouvelles contraintes)\n",
    "   +-- Erreur complexe ‚Üí CoordinatorAgent (changement strategie)\n",
    "```\n",
    "\n",
    "**Note critique** : Les demos actuelles (DEMO_1-3) sont trop triviales et ne declenchent JAMAIS CriticAgent ni CoordinatorAgent. DEMO_4 (list_length_append) devrait necessiter induction et potentiellement trigger ces agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Quand CriticAgent et CoordinatorAgent Interviennent\n",
    "\n",
    "#### CriticAgent : Analyse d'Echecs de Tactiques\n",
    "\n",
    "**Declenche par VerifierAgent quand** :\n",
    "- `verify_proof()` retourne `success=False`\n",
    "- Erreur Lean detectee : type mismatch, tactic failed, unknown identifier\n",
    "- Preuve incomplete apres application de tactique\n",
    "\n",
    "**Responsabilites** :\n",
    "1. Parser l'erreur Lean (extraire type, message, contexte)\n",
    "2. Identifier la cause (lemme incorrect, tactique inadequate, goal mal compris)\n",
    "3. Proposer correction :\n",
    "   - Erreur simple (lemme manquant) ‚Üí Delegue SearchAgent avec contraintes\n",
    "   - Erreur complexe (strategie incorrecte) ‚Üí Delegue CoordinatorAgent\n",
    "\n",
    "**Exemple d'intervention** :\n",
    "```\n",
    "[Tour 5] VerifierAgent: FAIL - \"type mismatch, expected Nat but got Bool\"\n",
    "[Tour 6] CriticAgent: \"TacticAgent a applique 'exact lemma_bool' mais goal attend Nat.\n",
    "                       SearchAgent doit chercher lemmes avec type Nat -> Nat.\"\n",
    "[Tour 7] SearchAgent: Recherche lemmes type-aware...\n",
    "```\n",
    "\n",
    "**Pourquoi absent des demos actuelles** :\n",
    "- DEMO_1-3 : Lemmes Mathlib correspondent exactement au goal\n",
    "- Pas de type mismatch, pas de tactic failure\n",
    "- VerifierAgent retourne success au premier essai\n",
    "\n",
    "#### CoordinatorAgent : Re-Orchestration Strategique\n",
    "\n",
    "**Declenche par CriticAgent quand** :\n",
    "- Echecs multiples consecutifs (3+ iterations sans progres)\n",
    "- Strategie actuelle bloquee (EXPLORATION ‚Üí REFINEMENT ‚Üí toujours FAIL)\n",
    "- Pattern d'erreur complexe (induction necessaire mais pas tentee)\n",
    "\n",
    "**Responsabilites** :\n",
    "1. Analyser historique complet (ProofState.snapshots)\n",
    "2. Identifier pattern d'echec (loop, strategie inadequate)\n",
    "3. Changer strategie globale :\n",
    "   - EXPLORATION ‚Üí VALIDATION (essayer preuves directes)\n",
    "   - REFINEMENT ‚Üí RECOVERY (backtrack + nouvelle approche)\n",
    "4. Reset partiel de ProofState (clear failed tactics, keep lemmas)\n",
    "\n",
    "**Exemple d'intervention** :\n",
    "```\n",
    "[Tour 8] CriticAgent: \"Echec 3x consecutif avec meme lemme. Strategie bloquee.\"\n",
    "[Tour 9] CoordinatorAgent: \"Detection pattern: goal necessite induction mais pas tentee.\n",
    "                            Changement strategie: EXPLORATION ‚Üí RECOVERY.\n",
    "                            Ajout contrainte: TacticAgent DOIT considerer 'induction'.\"\n",
    "[Tour 10] SearchAgent: Recherche lemmes inductifs...\n",
    "```\n",
    "\n",
    "**Pourquoi absent des demos actuelles** :\n",
    "- DEMO_1-3 : Pas d'echecs, donc CriticAgent jamais declenche\n",
    "- DEMO_4 (list_length_append) : **DEVRAIT** declencher si :\n",
    "  - Lemme direct `List.length_append` pas trouve\n",
    "  - TacticAgent essaie `rw` ou `simp` sans induction ‚Üí echec\n",
    "  - CriticAgent detecte besoin d'induction\n",
    "  - CoordinatorAgent change strategie vers RECOVERY\n",
    "\n",
    "#### Activation des Agents Critiques\n",
    "\n",
    "| Scenario | SearchAgent | TacticAgent | VerifierAgent | CriticAgent | CoordinatorAgent |\n",
    "|----------|-------------|-------------|---------------|-------------|------------------|\n",
    "| **Preuve triviale** (rfl) | ‚úó | ‚úì | ‚úì | ‚úó | ‚úó |\n",
    "| **Lemme direct trouve** (exact) | ‚úì | ‚úì | ‚úì | ‚úó | ‚úó |\n",
    "| **Lemme incorrect** (type mismatch) | ‚úì | ‚úì | ‚úì | ‚úì | ‚úó |\n",
    "| **Tactique echoue 1x** (retry) | ‚úì | ‚úì | ‚úì | ‚úì | ‚úó |\n",
    "| **Tactique echoue 3x** (bloque) | ‚úì | ‚úì | ‚úì | ‚úì | ‚úì |\n",
    "| **Induction necessaire** | ‚úì | ‚úì | ‚úì | ‚úì | ‚úì |\n",
    "\n",
    "**Conclusion** : Pour tester CriticAgent et CoordinatorAgent, nous devons utiliser des theoremes ou :\n",
    "1. Mathlib n'a PAS de lemme direct exact match\n",
    "2. Preuve necessite composition de tactiques (rw + simp + induction)\n",
    "3. Premiere tentative echoue et necessite correction\n",
    "\n",
    "**DEMO_4 (list_length_append) est concu pour ca** - mais seulement si on desactive l'acces au lemme `List.length_append` de Mathlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test des Agents ===\n",
      "Mode: Semantic Kernel\n",
      "Crees 5 agents SK avec modele gpt-5.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Factory pour creer les agents (SK ou fallback)\n",
    "# =============================================================================\n",
    "\n",
    "def create_agents(\n",
    "    plugins: Dict[str, Any],\n",
    "    state: ProofState,\n",
    "    use_sk: bool = True,\n",
    "    use_simulation: bool = False\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Cree les 5 agents specialises.\n",
    "\n",
    "    Args:\n",
    "        plugins: Dictionnaire des plugins SK\n",
    "        state: Etat partage de la preuve\n",
    "        use_sk: Utiliser Semantic Kernel si disponible\n",
    "        use_simulation: Mode simulation (sans appels LLM)\n",
    "\n",
    "    Returns:\n",
    "        Dictionnaire {nom_agent: agent}\n",
    "    \"\"\"\n",
    "    if use_sk and SK_AVAILABLE and not use_simulation:\n",
    "        return _create_sk_agents(plugins, state)\n",
    "    else:\n",
    "        return _create_simple_agents(plugins, use_simulation)\n",
    "\n",
    "\n",
    "def _create_simple_agents(plugins: Dict[str, Any], use_simulation: bool) -> Dict[str, Any]:\n",
    "    \"\"\"Cree les agents en mode fallback/simulation.\"\"\"\n",
    "    return {\n",
    "        \"SearchAgent\": SimpleAgent(\"SearchAgent\", SEARCH_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "        \"TacticAgent\": SimpleAgent(\"TacticAgent\", TACTIC_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "        \"VerifierAgent\": SimpleAgent(\"VerifierAgent\", VERIFIER_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "        \"CriticAgent\": SimpleAgent(\"CriticAgent\", CRITIC_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "        \"CoordinatorAgent\": SimpleAgent(\"CoordinatorAgent\", COORDINATOR_AGENT_INSTRUCTIONS, plugins, use_simulation),\n",
    "    }\n",
    "\n",
    "\n",
    "def _create_sk_agents(plugins: Dict[str, Any], state: ProofState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Cree les agents avec Semantic Kernel ChatCompletionAgent.\n",
    "\n",
    "    Utilise:\n",
    "    - OpenAIChatCompletion pour le service LLM\n",
    "    - FunctionChoiceBehavior.Auto() pour le function calling automatique\n",
    "    - Les plugins existants sont passes aux agents\n",
    "    \"\"\"\n",
    "    # Creer le kernel et le service\n",
    "    kernel = Kernel()\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    model = os.getenv(\"OPENAI_CHAT_MODEL_ID\", \"gpt-5.2\")\n",
    "\n",
    "    service = OpenAIChatCompletion(\n",
    "        service_id=\"openai\",\n",
    "        ai_model_id=model,\n",
    "        api_key=api_key\n",
    "    )\n",
    "    kernel.add_service(service)\n",
    "\n",
    "    # Ajouter les plugins au kernel\n",
    "    for plugin_name, plugin in plugins.items():\n",
    "        kernel.add_plugin(plugin, plugin_name=plugin_name)\n",
    "\n",
    "    # Configuration pour auto function calling\n",
    "    settings = kernel.get_prompt_execution_settings_from_service_id(service_id=\"openai\")\n",
    "    settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "    # Creer les agents\n",
    "    agents = {}\n",
    "    agent_configs = [\n",
    "        (\"SearchAgent\", SEARCH_AGENT_INSTRUCTIONS),\n",
    "        (\"TacticAgent\", TACTIC_AGENT_INSTRUCTIONS),\n",
    "        (\"VerifierAgent\", VERIFIER_AGENT_INSTRUCTIONS),\n",
    "        (\"CriticAgent\", CRITIC_AGENT_INSTRUCTIONS),\n",
    "        (\"CoordinatorAgent\", COORDINATOR_AGENT_INSTRUCTIONS),\n",
    "    ]\n",
    "\n",
    "    for name, instructions in agent_configs:\n",
    "        agents[name] = ChatCompletionAgent(\n",
    "            kernel=kernel,\n",
    "            name=name,\n",
    "            instructions=instructions,\n",
    "            arguments=KernelArguments(settings=settings)\n",
    "        )\n",
    "\n",
    "    print(f\"Crees {len(agents)} agents SK avec modele {model}\")\n",
    "    return agents\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Test des Agents\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== Test des Agents ===\")\n",
    "\n",
    "# Creer l'environnement\n",
    "test_state = ProofState(\n",
    "    theorem_statement=\"theorem add_zero (n : Nat) : n + 0 = n\",\n",
    "    current_goal=\"n + 0 = n\"\n",
    ")\n",
    "runner = LeanRunner(backend=\"subprocess\", timeout=30)\n",
    "\n",
    "# Creer les plugins\n",
    "plugins = {\n",
    "    \"state\": ProofStateManagerPlugin(test_state),\n",
    "    \"search\": LeanSearchPlugin(runner),\n",
    "    \"tactic\": LeanTacticPlugin(),\n",
    "    \"verification\": LeanVerificationPlugin(runner)\n",
    "}\n",
    "\n",
    "# Mode de fonctionnement\n",
    "USE_SK = SK_AVAILABLE and os.getenv(\"OPENAI_API_KEY\")\n",
    "USE_SIMULATION = not USE_SK  # Simulation si SK non disponible ou pas de cle API\n",
    "\n",
    "print(f\"Mode: {'Semantic Kernel' if USE_SK else 'Simulation'}\")\n",
    "\n",
    "# Creer les agents\n",
    "agents = create_agents(plugins, test_state, use_sk=USE_SK, use_simulation=USE_SIMULATION)\n",
    "\n",
    "# Test rapide en mode simulation\n",
    "if USE_SIMULATION:\n",
    "    print(\"\\nTest SearchAgent (simulation):\")\n",
    "    response = agents[\"SearchAgent\"].invoke(\"Trouve des lemmes pour n + 0 = n\", test_state)\n",
    "    print(response)\n",
    "    print(f\"Etat apres SearchAgent:\\n{test_state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Vue d'Ensemble des 5 Agents Specialises\n",
    "\n",
    "La fonction `create_agents()` instancie les 5 agents avec :\n",
    "- **Instructions** : Prompts systemiques definissant role et regles de delegation\n",
    "- **Plugins** : Fonctions exposees (search, tactic generation, verification, etc.)\n",
    "- **Modele LLM** : gpt-5.2 (ou simulation si mode LLM desactive)\n",
    "\n",
    "#### Signatures des agents\n",
    "\n",
    "```python\n",
    "SearchAgent(\n",
    "    plugins=[lean_search_plugin, state_plugin],\n",
    "    instructions=\"Trouve lemmes Mathlib pertinents...\"\n",
    ")\n",
    "\n",
    "TacticAgent(\n",
    "    plugins=[tactic_plugin, state_plugin],\n",
    "    instructions=\"Genere tactiques Lean avec confiance...\"\n",
    ")\n",
    "\n",
    "VerifierAgent(\n",
    "    plugins=[verification_plugin, state_plugin],\n",
    "    instructions=\"Compile et verifie preuves formelles...\"\n",
    ")\n",
    "\n",
    "CriticAgent(\n",
    "    plugins=[state_plugin],\n",
    "    instructions=\"Analyse echecs et propose corrections...\"\n",
    ")\n",
    "\n",
    "CoordinatorAgent(\n",
    "    plugins=[state_plugin],\n",
    "    instructions=\"Re-orchestre strategie globale...\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Pattern cle** : Chaque agent n'a acces qu'aux plugins dont il a besoin (principe de moindre privilege). Le `state_plugin` est partage par tous pour consulter/modifier ProofState.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Orchestration Multi-Agents\n",
    "\n",
    "L'orchestration determine comment les agents sont selectionnes et quand la conversation se termine.\n",
    "\n",
    "**DelegatingSelectionStrategy** (Pattern recommande):\n",
    "- Chaque agent designe explicitement le suivant via `designate_next_agent()`\n",
    "- Si aucune designation, utilise un agent par defaut (CoordinatorAgent)\n",
    "\n",
    "**ProofCompleteTermination**:\n",
    "- Termine si `proof_complete == True`\n",
    "- Termine si `iteration_count >= max_iterations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Workflow Complet de Preuve\n",
    "\n",
    "Cette demonstration montre le workflow multi-agents complet:\n",
    "1. **CoordinatorAgent** initialise la session\n",
    "2. **SearchAgent** recherche les lemmes pertinents\n",
    "3. **TacticAgent** propose des tactiques\n",
    "4. **VerifierAgent** verifie avec Lean\n",
    "5. **CriticAgent** intervient en cas d'echec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ Orchestration Multi-Agents\n",
    "\n",
    "### Le probl√®me de l'orchestration\n",
    "\n",
    "Avec 5 agents, qui parle quand ? Deux approches :\n",
    "\n",
    "1. **Statique** : SearchAgent ‚Üí TacticAgent ‚Üí VerifierAgent (toujours)\n",
    "   - Simple mais rigide\n",
    "   - Pas de backtracking\n",
    "\n",
    "2. **Dynamique** : D√©cisions bas√©es sur l'√©tat de la preuve\n",
    "   - Flexible mais complexe\n",
    "   - Permet le backtracking et la r√©cup√©ration d'erreur\n",
    "\n",
    "**Nous utilisons l'approche dynamique.**\n",
    "\n",
    "### Strat√©gies d'orchestration\n",
    "\n",
    "#### ProofSelectionStrategy\n",
    "\n",
    "D√©cide **quel agent agit** √† chaque tour :\n",
    "\n",
    "```python\n",
    "class ProofSelectionStrategy:\n",
    "    def select_next_agent(self, state: ProofState, agents: List[str]) -> str:\n",
    "        if state.phase == ProofPhase.INIT:\n",
    "            return \"CoordinatorAgent\"\n",
    "        elif state.phase == ProofPhase.SEARCH:\n",
    "            return \"SearchAgent\"\n",
    "        # ...\n",
    "```\n",
    "\n",
    "#### ProofTerminationStrategy\n",
    "\n",
    "D√©cide **quand arr√™ter** la session :\n",
    "\n",
    "```python\n",
    "class ProofTerminationStrategy:\n",
    "    def should_terminate(self, state: ProofState, iteration: int) -> Tuple[bool, str]:\n",
    "        if state.phase == ProofPhase.COMPLETE:\n",
    "            return (True, \"Preuve compl√®te!\")\n",
    "        if iteration >= max_iterations:\n",
    "            return (True, \"Timeout atteint\")\n",
    "        # ...\n",
    "```\n",
    "\n",
    "### Boucle principale\n",
    "\n",
    "```python\n",
    "while not should_terminate:\n",
    "    # 1. S√©lectionner agent\n",
    "    agent_name = selection_strategy.select_next_agent(state, agents)\n",
    "\n",
    "    # 2. Ex√©cuter agent (appelle le LLM)\n",
    "    response = agent.chat(f\"Phase: {state.phase}, Goal: {state.current_goal}\")\n",
    "\n",
    "    # 3. L'agent appelle des plugins (modifie l'√©tat)\n",
    "    # Exemple: log_tactic_attempt(\"rw [Nat.add_zero]\")\n",
    "\n",
    "    # 4. Mettre √† jour phase selon r√©sultat\n",
    "    update_phase(state)\n",
    "\n",
    "    # 5. V√©rifier condition de terminaison\n",
    "    should_terminate, reason = termination_strategy.should_terminate(state, iteration)\n",
    "```\n",
    "\n",
    "### Snapshots : Observer l'orchestration\n",
    "\n",
    "√Ä chaque tour, on sauvegarde :\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"iteration\": 5,\n",
    "  \"agent\": \"TacticAgent\",\n",
    "  \"phase_before\": \"SEARCH\",\n",
    "  \"phase_after\": \"TACTIC_GEN\",\n",
    "  \"action\": \"Generated tactic: rw [Nat.add_zero]\",\n",
    "  \"state_snapshot\": {...}\n",
    "}\n",
    "```\n",
    "\n",
    "**Utilit√©** : Voir exactement quelle d√©cision chaque agent a prise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 8.7 - Strategies d'Orchestration (Pattern Argument_Analysis)\n",
    "# =============================================================================\n",
    "# Strategies personnalisees basees sur l'etat partage (pas sur l'historique)\n",
    "\n",
    "# Fix for Jupyter event loop\n",
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import logging\n",
    "from typing import Dict, Any, List, Optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. ProofSelectionStrategy : Selection d'Agent : Selection d'Agent Basee sur l'Etat\n",
    "\n",
    "**Pattern inspire de Argument_Analysis** : Selection d'agent via **designation explicite** dans ProofState.\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "```python\n",
    "class ProofSelectionStrategy(SelectionStrategy):\n",
    "    async def next(agents, history) -> Agent:\n",
    "        # 1. Lire designation explicite\n",
    "        designated = state.consume_next_agent_designation()\n",
    "        \n",
    "        # 2. Si designation presente, utiliser cet agent\n",
    "        if designated:\n",
    "            return agents_map[designated]\n",
    "        \n",
    "        # 3. Sinon, utiliser agent par defaut (SearchAgent)\n",
    "        return agents_map[default_agent_name]\n",
    "```\n",
    "\n",
    "#### Difference avec Semantic Kernel Standard\n",
    "\n",
    "| Semantic Kernel Standard | ProofSelectionStrategy (Custom) |\n",
    "|-------------------------|--------------------------------|\n",
    "| Parse historique messages | Lit `state.next_agent_designation` |\n",
    "| Selection basee sur keywords | Selection basee sur etat partage |\n",
    "| Stateless (pas de memoire) | Stateful (ProofState) |\n",
    "| Complexite O(n) messages | Complexite O(1) |\n",
    "\n",
    "**Avantage** : Chaque agent designe explicitement son successeur via `state.designate_next_agent()`, evitant parsing d'historique fragile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ProofSelectionStrategy - Selection basee sur l'etat partage\n",
    "# =============================================================================\n",
    "# NOTE: Ces classes SK ne sont definies que si SK est disponible.\n",
    "# Le mode simulation n'en a pas besoin.\n",
    "\n",
    "if SK_AVAILABLE:\n",
    "    from semantic_kernel.agents.strategies.selection.selection_strategy import SelectionStrategy\n",
    "\n",
    "    class ProofSelectionStrategy(SelectionStrategy):\n",
    "        \"\"\"Strategie de selection SK (non utilisee en mode simulation).\"\"\"\n",
    "        pass\n",
    "else:\n",
    "    print(\"ProofSelectionStrategy: Skipped (SK non disponible)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. ProofTerminationStrategy : Detection de Completion : Detection de Completion\n",
    "\n",
    "**Responsabilite** : Detecter quand arreter l'orchestration multi-agents.\n",
    "\n",
    "#### Criteres de Terminaison\n",
    "\n",
    "```python\n",
    "class ProofTerminationStrategy(TerminationStrategy):\n",
    "    async def should_terminate(agents, history) -> bool:\n",
    "        # 1. Preuve complete detectee\n",
    "        if state.proof_complete:\n",
    "            return True\n",
    "        \n",
    "        # 2. Max iterations atteint\n",
    "        if state.current_iteration >= max_iterations:\n",
    "            return True\n",
    "        \n",
    "        # 3. Timeout (optionnel)\n",
    "        if time.time() - start_time > timeout:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "```\n",
    "\n",
    "#### Comparaison avec Autres Patterns\n",
    "\n",
    "| Pattern | Terminaison basee sur | Avantages | Inconvenients |\n",
    "|---------|----------------------|-----------|---------------|\n",
    "| **Message-based** | Keyword dans dernier message (\"DONE\", \"COMPLETE\") | Simple, standard SK | Fragile, depend du LLM |\n",
    "| **State-based** (ce notebook) | `state.proof_complete` flag | Robuste, deterministe | Necessite etat partage |\n",
    "| **Iteration-based** | Compteur max iterations | Toujours termine | Peut stopper preuve incomplete |\n",
    "| **Consensus-based** | Vote agents (majorite) | Robuste aux erreurs | Complexe, lent |\n",
    "\n",
    "**Notre choix** : Combinaison **state-based + iteration-based** pour garantir terminaison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ProofTerminationStrategy - Terminaison basee sur l'etat partage\n",
    "# =============================================================================\n",
    "# NOTE: Ces classes SK ne sont definies que si SK est disponible.\n",
    "# Le mode simulation n'en a pas besoin.\n",
    "\n",
    "if SK_AVAILABLE:\n",
    "    from semantic_kernel.agents.strategies.termination.termination_strategy import TerminationStrategy\n",
    "\n",
    "    class ProofTerminationStrategy(TerminationStrategy):\n",
    "        \"\"\"Strategie de terminaison SK (non utilisee en mode simulation).\"\"\"\n",
    "        pass\n",
    "else:\n",
    "    print(\"ProofTerminationStrategy: Skipped (SK non disponible)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. ProofAgentGroupChat : Chat Multi-Agents : Orchestration Multi-Agents\n",
    "\n",
    "**Classe orchestrateur** pour g√©rer la conversation multi-agents avec Semantic Kernel.\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "```python\n",
    "class ProofAgentGroupChat:\n",
    "    def __init__(agents, state, use_sk=True):\n",
    "        self.agents = agents  # Dict[str, ChatCompletionAgent]\n",
    "        self.state = state    # ProofState partage\n",
    "    \n",
    "    def run(initial_message, verbose=True) -> str:\n",
    "        # Execute conversation multi-agents\n",
    "        if use_sk:\n",
    "            return await _run_sk(...)  # Semantic Kernel\n",
    "        else:\n",
    "            return _run_fallback(...)   # Simulation\n",
    "```\n",
    "\n",
    "**Pattern cl√©** :\n",
    "- Utilise `ProofSelectionStrategy` pour s√©lectionner agents\n",
    "- Utilise `ProofTerminationStrategy` pour d√©tecter fin\n",
    "- Cr√©e `AgentGroupChat` de Semantic Kernel avec ces strat√©gies\n",
    "- Fallback en mode simulation si SK non disponible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProofAgentGroupChat defini (mode SK + simulation)\n"
     ]
    }
   ],
   "source": [
    "class ProofAgentGroupChat:\n",
    "    \"\"\"\n",
    "    Orchestre les agents pour la preuve de theoremes.\n",
    "    Supporte mode simulation (SimpleAgent) et mode SK (ChatCompletionAgent).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, agents: Dict[str, Any], state: ProofState, use_sk: bool = True):\n",
    "        self.agents = agents\n",
    "        self.state = state\n",
    "        self.use_sk = use_sk and SK_AVAILABLE\n",
    "        self.history = []\n",
    "        self._proof_tactics_found = []  # Track tactics found across iterations\n",
    "\n",
    "    def run(self, initial_message: str, verbose: bool = True) -> str:\n",
    "        \"\"\"Execute la conversation multi-agents.\"\"\"\n",
    "        if self.use_sk:\n",
    "            # Mode Semantic Kernel - utilise async\n",
    "            import asyncio\n",
    "            import nest_asyncio\n",
    "            nest_asyncio.apply()\n",
    "            try:\n",
    "                loop = asyncio.get_event_loop()\n",
    "                return loop.run_until_complete(self._run_sk(initial_message, verbose))\n",
    "            except RuntimeError:\n",
    "                return asyncio.run(self._run_sk(initial_message, verbose))\n",
    "        else:\n",
    "            # Mode simulation - sync\n",
    "            return self._run_fallback(initial_message, verbose)\n",
    "\n",
    "    async def _run_sk(self, initial_message: str, verbose: bool = True) -> str:\n",
    "        \"\"\"Execution avec Semantic Kernel ChatCompletionAgent.\"\"\"\n",
    "        from semantic_kernel.contents.chat_history import ChatHistory\n",
    "        from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "        from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Session MULTI-AGENTS (SK): {initial_message[:80]}...\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "        # Creer l'historique de chat partage entre les agents\n",
    "        chat_history = ChatHistory()\n",
    "        chat_history.add_user_message(initial_message)\n",
    "\n",
    "        current_message = initial_message\n",
    "        agent_order = [\"SearchAgent\", \"TacticAgent\", \"VerifierAgent\", \"CriticAgent\", \"CoordinatorAgent\"]\n",
    "\n",
    "        for i in range(self.state.max_iterations):\n",
    "            self.state.iteration = i + 1\n",
    "            self.state.increment_iteration()\n",
    "\n",
    "            # Determiner l'agent a utiliser\n",
    "            designated = self.state.consume_next_agent_designation()\n",
    "            if designated and designated in self.agents:\n",
    "                agent_name = designated\n",
    "            else:\n",
    "                agent_name = agent_order[i % len(agent_order)]\n",
    "\n",
    "            agent = self.agents.get(agent_name)\n",
    "            if not agent:\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"\\n[Tour {self.state.iteration_count}] {agent_name}\")\n",
    "\n",
    "            # Invoquer l'agent SK de maniere asynchrone\n",
    "            try:\n",
    "                response_text = \"\"\n",
    "\n",
    "                # ChatCompletionAgent.invoke() prend un ChatHistory et retourne un AsyncIterable\n",
    "                async for response in agent.invoke(chat_history):\n",
    "                    if hasattr(response, 'content') and response.content:\n",
    "                        response_text += str(response.content)\n",
    "                    elif hasattr(response, 'items'):\n",
    "                        # Si c'est un ChatMessageContent avec items\n",
    "                        for item in response.items:\n",
    "                            if hasattr(item, 'text'):\n",
    "                                response_text += item.text\n",
    "\n",
    "                if not response_text:\n",
    "                    response_text = f\"[{agent_name}] Pas de reponse\"\n",
    "\n",
    "                # Ajouter la reponse a l'historique\n",
    "                chat_history.add_assistant_message(response_text)\n",
    "\n",
    "                # Ajouter le prochain message utilisateur (contexte pour le prochain agent)\n",
    "                if i < self.state.max_iterations - 1:\n",
    "                    next_context = f\"Continue la preuve. Reponse precedente de {agent_name}: {response_text[:200]}\"\n",
    "                    chat_history.add_user_message(next_context)\n",
    "\n",
    "                # Mettre a jour l'etat selon la reponse\n",
    "                self._update_state_from_response(agent_name, response_text)\n",
    "\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                response_text = f\"Erreur agent {agent_name}: {str(e)}\"\n",
    "                if verbose:\n",
    "                    print(f\"  [ERROR] {e}\")\n",
    "                    traceback.print_exc()\n",
    "\n",
    "            self.history.append({\n",
    "                \"iteration\": self.state.iteration_count,\n",
    "                \"agent\": agent_name,\n",
    "                \"response\": response_text[:200] if response_text else \"\",\n",
    "            })\n",
    "\n",
    "            if verbose:\n",
    "                display_response = response_text[:200] + \"...\" if len(response_text) > 200 else response_text\n",
    "                print(f\"  Response: {display_response}\")\n",
    "\n",
    "            if self.state.proof_complete:\n",
    "                if verbose:\n",
    "                    print(f\"\\n[LOG] Preuve trouvee!\")\n",
    "                break\n",
    "\n",
    "            current_message = response_text\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(f\"Session terminee apres {self.state.iteration_count} iterations.\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "        return self.state.final_proof or \"Preuve non trouvee\"\n",
    "\n",
    "    def _update_state_from_response(self, agent_name: str, response: str):\n",
    "        \"\"\"Met a jour l'etat partage en fonction de la reponse de l'agent.\"\"\"\n",
    "        import re\n",
    "        response_lower = response.lower()\n",
    "\n",
    "        # Detection des lemmes decouverts\n",
    "        if \"lemma:\" in response_lower or \"found:\" in response_lower or \"nat.\" in response_lower:\n",
    "            lemma_matches = re.findall(r'(Nat\\.\\w+|Eq\\.\\w+|List\\.\\w+)', response)\n",
    "            for lemma in lemma_matches:\n",
    "                if lemma not in self.state.discovered_lemmas:\n",
    "                    self.state.discovered_lemmas.append(lemma)\n",
    "\n",
    "        # Detection des tactiques - track across iterations\n",
    "        proof_patterns = [\n",
    "            (r'simp\\s*\\[[^\\]]*\\]', 'simp'),\n",
    "            (r'\\brfl\\b', 'rfl'),\n",
    "            (r'exact\\s+\\w+', 'exact'),\n",
    "            (r'\\bring\\b', 'ring'),\n",
    "            (r'\\bomega\\b', 'omega'),\n",
    "            (r'\\blinarith\\b', 'linarith'),\n",
    "            (r'\\bdecide\\b', 'decide'),\n",
    "        ]\n",
    "\n",
    "        for pattern, tactic_name in proof_patterns:\n",
    "            if re.search(pattern, response, re.IGNORECASE):\n",
    "                if tactic_name not in self._proof_tactics_found:\n",
    "                    self._proof_tactics_found.append(tactic_name)\n",
    "                    self.state.tactics_history.append(response[:100])\n",
    "\n",
    "        # Detection de preuve complete - multiple signals\n",
    "        proof_complete_signals = [\n",
    "            \"proof complete\",\n",
    "            \"qed\",\n",
    "            \"verified\",\n",
    "            \"goals accomplished\",\n",
    "            \"proof found\",\n",
    "            \"la preuve est terminee\",\n",
    "            \"la preuve est cloturee\",\n",
    "            \"preuve reussie\",\n",
    "        ]\n",
    "\n",
    "        if any(signal in response_lower for signal in proof_complete_signals):\n",
    "            # If we have found tactics earlier, mark as complete\n",
    "            if self._proof_tactics_found:\n",
    "                self.state.phase = ProofPhase.COMPLETE\n",
    "                if not self.state.final_proof:\n",
    "                    self.state.final_proof = self._proof_tactics_found[0]\n",
    "        elif \":= by\" in response and self._proof_tactics_found:\n",
    "            # Lean-style proof block detected with tactics\n",
    "            self.state.phase = ProofPhase.COMPLETE\n",
    "            if not self.state.final_proof:\n",
    "                self.state.final_proof = self._proof_tactics_found[0]\n",
    "\n",
    "        # Alternative: detect complete proof in code block\n",
    "        code_block_match = re.search(r'```lean\\n(.*?)```', response, re.DOTALL)\n",
    "        if code_block_match:\n",
    "            code_content = code_block_match.group(1)\n",
    "            if \":= by\" in code_content or \":= rfl\" in code_content:\n",
    "                # Check for proof tactics in the code block\n",
    "                for pattern, tactic_name in proof_patterns:\n",
    "                    if re.search(pattern, code_content, re.IGNORECASE):\n",
    "                        self.state.phase = ProofPhase.COMPLETE\n",
    "                        self.state.final_proof = code_content.strip()[:200]\n",
    "                        break\n",
    "\n",
    "        # Detection de delegation\n",
    "        delegate_patterns = [\n",
    "            (r'@TacticAgent|delegate.*TacticAgent', 'TacticAgent'),\n",
    "            (r'@VerifierAgent|delegate.*VerifierAgent', 'VerifierAgent'),\n",
    "            (r'@CriticAgent|delegate.*CriticAgent', 'CriticAgent'),\n",
    "            (r'@CoordinatorAgent|delegate.*CoordinatorAgent', 'CoordinatorAgent'),\n",
    "            (r'@SearchAgent|delegate.*SearchAgent', 'SearchAgent'),\n",
    "        ]\n",
    "        for pattern, target in delegate_patterns:\n",
    "            if re.search(pattern, response, re.IGNORECASE):\n",
    "                self.state.designate_next_agent(target)\n",
    "                break\n",
    "\n",
    "    def _run_fallback(self, initial_message: str, verbose: bool = True) -> str:\n",
    "        \"\"\"Execution sans Semantic Kernel (mode simulation).\"\"\"\n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Session MULTI-AGENTS: {initial_message[:80]}...\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "        current_message = initial_message\n",
    "        agent_order = [\"SearchAgent\", \"TacticAgent\", \"VerifierAgent\", \"CriticAgent\", \"CoordinatorAgent\"]\n",
    "\n",
    "        for i in range(self.state.max_iterations):\n",
    "            self.state.iteration = i + 1\n",
    "\n",
    "            designated = self.state.consume_next_agent_designation()\n",
    "            if designated and designated in self.agents:\n",
    "                agent_name = designated\n",
    "            else:\n",
    "                agent_name = agent_order[i % len(agent_order)]\n",
    "\n",
    "            agent = self.agents.get(agent_name)\n",
    "            if not agent:\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"\\n[Tour {self.state.iteration_count}] {agent_name}\")\n",
    "\n",
    "            response = agent.invoke(current_message, self.state)\n",
    "\n",
    "            self.history.append({\n",
    "                \"iteration\": self.state.iteration_count,\n",
    "                \"agent\": agent_name,\n",
    "                \"response\": response[:200] if response else \"\",\n",
    "            })\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"  Response: {response[:200]}...\" if len(response) > 200 else f\"  Response: {response}\")\n",
    "\n",
    "            if self.state.proof_complete:\n",
    "                if verbose:\n",
    "                    print(f\"\\n[LOG] Preuve trouvee!\")\n",
    "                break\n",
    "\n",
    "            current_message = response\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(f\"Session terminee apres {self.state.iteration_count} iterations.\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "        return self.state.final_proof or \"Preuve non trouvee\"\n",
    "\n",
    "\n",
    "# Test rapide\n",
    "print(\"ProofAgentGroupChat defini (mode SK + simulation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Test des Strategies\n",
    "\n",
    "Code de test pour valider :\n",
    "- **ProofTerminationStrategy** : D√©tecte `state.proof_complete`\n",
    "- **SimpleOrchestratorAgent** : Ex√©cute conversation avec d√©signation d'agents\n",
    "\n",
    "**Ex√©cution automatique** lors du chargement de la cellule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test des Strategies ===\n",
      "State cree: 322a0c82\n",
      "Phase initiale: init\n",
      "Designation test: TacticAgent\n",
      "proof_complete initial: False\n",
      "proof_complete apres COMPLETE: True\n",
      "\n",
      "Strategies pretes pour utilisation avec AgentGroupChat\n"
     ]
    }
   ],
   "source": [
    "# Test des Strategies\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Test des Strategies ===\")\n",
    "\n",
    "test_state = ProofState(\n",
    "    theorem_statement=\"theorem test (n : Nat) : n = n\",\n",
    "    current_goal=\"n = n\",\n",
    "    max_iterations=5\n",
    ")\n",
    "\n",
    "print(f\"State cree: {test_state.session_id}\")\n",
    "print(f\"Phase initiale: {test_state.phase.value}\")\n",
    "\n",
    "# Test designation\n",
    "test_state.designate_next_agent(\"TacticAgent\")\n",
    "designated = test_state.consume_next_agent_designation()\n",
    "print(f\"Designation test: {designated}\")\n",
    "\n",
    "# Test proof_complete\n",
    "print(f\"proof_complete initial: {test_state.proof_complete}\")\n",
    "test_state.phase = ProofPhase.COMPLETE\n",
    "print(f\"proof_complete apres COMPLETE: {test_state.proof_complete}\")\n",
    "\n",
    "print(\"\\nStrategies pretes pour utilisation avec AgentGroupChat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les 4 demos avec progression reelle\n",
    "\n",
    "Les theoremes sont choisis pour necessiter des **strategies de preuve differentes**, pas juste `simp`.\n",
    "\n",
    "#### 1 DEMO_1_TRIVIAL : `theorem demo_rfl (n : Nat) : n = n`\n",
    "\n",
    "- **Complexite** : Triviale\n",
    "- **Strategie** : `rfl` (reflexivite)\n",
    "- **Iterations attendues** : 1-2\n",
    "- **But** : Validation du pipeline basique\n",
    "\n",
    "#### 2 DEMO_2_DEFINITION : `theorem zero_add (n : Nat) : 0 + n = n`\n",
    "\n",
    "- **Complexite** : Simple\n",
    "- **Strategie** : `simp [Nat.zero_add]` ou induction\n",
    "- **Iterations attendues** : 2-4\n",
    "- **Piege** : `simp` seul ne suffit pas toujours, peut necessiter `Nat.zero_add`\n",
    "- **But** : Test de recherche de lemmes specifiques\n",
    "\n",
    "#### 3 DEMO_3_INDUCTION : `theorem add_assoc_manual (a b c : Nat) : (a + b) + c = a + (b + c)`\n",
    "\n",
    "- **Complexite** : Intermediaire\n",
    "- **Strategie** : Induction structuree sur `a`\n",
    "- **Iterations attendues** : 3-6\n",
    "- **Structure** :\n",
    "  ```lean\n",
    "  induction a with\n",
    "  | zero => simp\n",
    "  | succ a ih => simp [Nat.succ_add, ih]\n",
    "  ```\n",
    "- **But** : Test de generation de preuves par induction\n",
    "\n",
    "#### 4 DEMO_4_COMPOSED : `theorem mul_comm_manual (m n : Nat) : m * n = n * m`\n",
    "\n",
    "- **Complexite** : Avancee\n",
    "- **Strategie** : Induction + lemmes auxiliaires (mul_succ, succ_mul, add_comm)\n",
    "- **Iterations attendues** : 5-10\n",
    "- **Echecs possibles** : Premiere tentative peut echouer, necessite CriticAgent\n",
    "- **But** : Stress-test du systeme multi-agents complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEMONSTRATION MULTI-AGENTS POUR THEOREM PROVING\n",
      "============================================================\n",
      "======================================================================\n",
      "D√âMONSTRATIONS PROGRESSIVES - SYST√àME MULTI-AGENTS\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 8.8 - Demonstration Complete\n",
    "# =============================================================================\n",
    "\n",
    "def prove_with_multi_agents(\n",
    "    theorem: str,\n",
    "    goal: str = \"\",\n",
    "    max_iterations: int = 20,\n",
    "    verbose: bool = True,\n",
    "    use_simulation: bool = None  # None = auto-detect\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Prouve un theoreme en utilisant le systeme multi-agents.\n",
    "\n",
    "    Args:\n",
    "        theorem: L'enonce du theoreme complet\n",
    "        goal: Le but a prouver (extrait du theoreme si non fourni)\n",
    "        max_iterations: Nombre maximum d'iterations\n",
    "        verbose: Afficher les logs\n",
    "        use_simulation: True=simulation, False=LLM reel, None=auto\n",
    "\n",
    "    Returns:\n",
    "        Dict avec resultats et metriques\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Auto-detection du mode\n",
    "    if use_simulation is None:\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "        has_valid_key = api_key and len(api_key) > 10 and not api_key.startswith(\"sk-...\")\n",
    "        use_simulation = not has_valid_key\n",
    "\n",
    "    # 1. Creer l'etat\n",
    "    if not goal:\n",
    "        if \":\" in theorem:\n",
    "            goal = theorem.split(\":\")[-1].strip()\n",
    "\n",
    "    state = ProofState(\n",
    "        theorem_statement=theorem,\n",
    "        current_goal=goal,\n",
    "        max_iterations=max_iterations\n",
    "    )\n",
    "\n",
    "    # 2. Creer le runner Lean\n",
    "    runner = LeanRunner(backend=\"subprocess\", timeout=30)\n",
    "\n",
    "    # 3. Creer les plugins\n",
    "    plugins = {\n",
    "        \"state\": ProofStateManagerPlugin(state),\n",
    "        \"search\": LeanSearchPlugin(runner),\n",
    "        \"tactic\": LeanTacticPlugin(),\n",
    "        \"verification\": LeanVerificationPlugin(runner)\n",
    "    }\n",
    "\n",
    "    # 4. Creer les agents\n",
    "    use_sk = SK_AVAILABLE and not use_simulation\n",
    "    agents = create_agents(plugins, state, use_sk=use_sk, use_simulation=use_simulation)\n",
    "\n",
    "    # 5. Configurer les strategies\n",
    "    # Strategies gerees automatiquement par ProofAgentGroupChat\n",
    "\n",
    "    # 6. Creer le groupe de chat\n",
    "    chat = ProofAgentGroupChat(\n",
    "        agents=agents,\n",
    "        state=state,\n",
    "        use_sk=use_sk\n",
    "    )\n",
    "\n",
    "    mode_str = \"Semantic Kernel\" if use_sk else (\"Simulation\" if use_simulation else \"OpenAI direct\")\n",
    "    if verbose:\n",
    "        print(f\"Mode: {mode_str}\")\n",
    "\n",
    "    # 7. Executer\n",
    "    result = chat.run(f\"Prouver: {theorem}\", verbose=verbose)\n",
    "\n",
    "    # 8. Collecter les metriques\n",
    "    elapsed = time.time() - start_time\n",
    "    metrics = {\n",
    "        \"success\": state.proof_complete,\n",
    "        \"theorem\": theorem,\n",
    "        \"final_proof\": state.final_proof,\n",
    "        \"iterations\": state.iteration_count,\n",
    "        \"lemmas_discovered\": len(state.discovered_lemmas),\n",
    "        \"tactics_tried\": len(state.tactics_history),\n",
    "        \"verifications\": len(state.verification_results),\n",
    "        \"total_time_s\": round(elapsed, 2),\n",
    "        \"lean_time_ms\": round(state.total_lean_time_ms, 2),\n",
    "        \"mode\": mode_str\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Test de la demonstration\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEMONSTRATION MULTI-AGENTS POUR THEOREM PROVING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# Section 8.8 - D√©monstrations Progressives Multi-Agents\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration\n",
    "USE_LLM_MODE = True  # False pour simulation (defaut), True pour LLM reel\n",
    "\n",
    "# Quatre th√©or√®mes de complexit√© croissante\n",
    "DEMOS = [\n",
    "    {\n",
    "        \"name\": \"DEMO_1_TRIVIAL\",\n",
    "        \"theorem\": \"theorem demo_rfl (n : Nat) : n = n\",\n",
    "        \"description\": \"Reflexivite pure - rfl immediat\",\n",
    "        \"expected_iterations\": \"1-2\",\n",
    "        \"expected_lemmas\": 1,\n",
    "        \"complexity\": \"Triviale\",\n",
    "        \"strategy\": \"rfl\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DEMO_2_DEFINITION\",\n",
    "        \"theorem\": \"theorem zero_add (n : Nat) : 0 + n = n\",\n",
    "        \"description\": \"Definition - necessite lemme Nat.zero_add\",\n",
    "        \"expected_iterations\": \"1-2\",\n",
    "        \"expected_lemmas\": 1,\n",
    "        \"complexity\": \"Simple\",\n",
    "        \"strategy\": \"exact Nat.zero_add n\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DEMO_3_INDUCTION\",\n",
    "        \"theorem\": \"theorem add_assoc_manual (a b c : Nat) : (a + b) + c = a + (b + c)\",\n",
    "        \"description\": \"Associativite - peut utiliser lemme ou induction\",\n",
    "        \"expected_iterations\": \"2-5\",\n",
    "        \"expected_lemmas\": 2,\n",
    "        \"complexity\": \"Intermediaire\",\n",
    "        \"strategy\": \"induction ou Nat.add_assoc\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DEMO_4_COMPOSED\",\n",
    "        \"theorem\": \"theorem length_append_manual (xs ys : List Nat) : (xs ++ ys).length = xs.length + ys.length\",\n",
    "        \"description\": \"Liste - induction sur structure de donnees\",\n",
    "        \"expected_iterations\": \"3-6\",\n",
    "        \"expected_lemmas\": 3,\n",
    "        \"complexity\": \"Avancee\",\n",
    "        \"strategy\": \"induction xs; simp\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"D√âMONSTRATIONS PROGRESSIVES - SYST√àME MULTI-AGENTS\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Ex√©cuter chaque d√©mo\n",
    "results_comparison = []\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. DEMO_1 : Preuve Triviale\n",
    "\n",
    "**Objectif** : Valider le pipeline complet avec un theoreme trivial\n",
    "\n",
    "**Theoreme** : `theorem demo_rfl (n : Nat) : n = n`\n",
    "\n",
    "**Attentes** :\n",
    "- **Iterations** : 1-2 (reflexivite immediate)\n",
    "- **Agents impliques** : TacticAgent (rfl) ‚Üí VerifierAgent\n",
    "- **CriticAgent/CoordinatorAgent** : NON (preuve triviale)\n",
    "- **Temps** : <1 seconde\n",
    "\n",
    "Cette demo sert de **baseline** pour verifier que le systeme fonctionne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 1/4: DEMO_1_TRIVIAL\n",
      "======================================================================\n",
      "Theoreme: theorem demo_rfl (n : Nat) : n = n\n",
      "Complexite: Triviale\n",
      "Iterations attendues: 2-3\n",
      "Lemmes necessaires: 1\n",
      "======================================================================\n",
      "Crees 5 agents SK avec modele gpt-5.2\n",
      "Mode: Semantic Kernel\n",
      "============================================================\n",
      "Session MULTI-AGENTS (SK): Prouver: theorem demo_rfl (n : Nat) : n = n...\n",
      "============================================================\n",
      "\n",
      "[Tour 2] SearchAgent\n",
      "  Response: Je d√©l√®gue √† TacticAgent avec les lemmes `rfl` et `Eq.refl`.\n",
      "Delegation to TacticAgent.\n",
      "Lemmes pertinents (Mathlib/Init) pour `theorem demo_rfl (n : Nat) : n = n` :\n",
      "\n",
      "1. `rfl : a = a` (le plus direct)\n",
      "...\n",
      "\n",
      "[Tour 3] TacticAgent\n",
      "  Response: Tactique propos√©e (confiance 0.99) : `rfl`\n",
      "\n",
      "Preuve Lean compl√®te :\n",
      "\n",
      "```lean\n",
      "theorem demo_rfl (n : Nat) : n = n := by\n",
      "  rfl\n",
      "```\n",
      "\n",
      "Je d√©l√®gue √† **VerifierAgent** pour v√©rifier.\n",
      "\n",
      "[LOG] Preuve trouvee!\n",
      "\n",
      "============================================================\n",
      "Session terminee apres 3 iterations.\n",
      "============================================================\n",
      "\n",
      "Resultat DEMO_1:\n",
      "  - Success: True\n",
      "  - Iterations: 3\n",
      "  - Proof: theorem demo_rfl (n : Nat) : n = n := by\n",
      "  rfl...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Execute DEMO_1\n",
    "demo = DEMOS[0]\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"DEMO 1/4: {demo['name']}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Theoreme: {demo['theorem']}\")\n",
    "print(f\"Complexite: {demo['complexity']}\")\n",
    "print(f\"Iterations attendues: {demo['expected_iterations']}\")\n",
    "print(f\"Lemmes necessaires: {demo['expected_lemmas']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result_1 = prove_with_multi_agents(\n",
    "    theorem=demo[\"theorem\"],\n",
    "    max_iterations=20,\n",
    "    verbose=True,\n",
    "    use_simulation=not USE_LLM_MODE\n",
    ")\n",
    "\n",
    "print(f\"\\nResultat DEMO_1:\")\n",
    "print(f\"  - Success: {result_1['success']}\")\n",
    "print(f\"  - Iterations: {result_1['iterations']}\")\n",
    "print(f\"  - Proof: {result_1['final_proof'][:100] if result_1['final_proof'] else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. DEMO_2 : Composition de Lemmes\n",
    "\n",
    "**Objectif** : Tester recherche + composition de 2 lemmes\n",
    "\n",
    "**Theoreme** : `theorem add_zero_comm (n m : Nat) : n + m + 0 = m + n`\n",
    "\n",
    "**Attentes** :\n",
    "- **Iterations** : 5-7 (2 etapes de preuve)\n",
    "- **Agents impliques** : SearchAgent ‚Üí TacticAgent ‚Üí VerifierAgent ‚Üí CriticAgent ‚Üí TacticAgent\n",
    "- **Lemmes Mathlib attendus** : `Nat.add_zero`, `Nat.add_comm`\n",
    "- **CriticAgent** : POSSIBLE (si premiere tactique incomplete)\n",
    "- **Temps** : 1-3 secondes\n",
    "\n",
    "Cette demo teste la **composition de lemmes** : d'abord eliminer le `+ 0`, puis appliquer la commutativite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 2/4: DEMO_2_COMPOSITION\n",
      "======================================================================\n",
      "Theoreme: theorem add_zero_comm (n m : Nat) : n + m + 0 = m + n\n",
      "Complexite: Simple - necessite combiner 2 lemmes\n",
      "Iterations attendues: 5-7\n",
      "Lemmes necessaires: 2\n",
      "======================================================================\n",
      "Crees 5 agents SK avec modele gpt-5.2\n",
      "Mode: Semantic Kernel\n",
      "============================================================\n",
      "Session MULTI-AGENTS (SK): Prouver: theorem add_zero_comm (n m : Nat) : n + m + 0 = m + n...\n",
      "============================================================\n",
      "\n",
      "[Tour 2] SearchAgent\n",
      "  Response: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "\n",
      "[Tour 3] TacticAgent\n",
      "  Response: {\"to\":\"functions.meta-delegate_to_verifier_agent\",\"task_summary\":\"V√©rifier la preuve Lean. Tentative principale: `by simpa [Nat.add_assoc] using congrArg (fun t => t + 0) (Nat.add_comm n m)` (devrait ...\n",
      "\n",
      "[Tour 4] VerifierAgent\n",
      "  Response: La preuve compile en Lean 4. Voici le code final :\n",
      "\n",
      "```lean\n",
      "theorem add_zero_comm (n m : Nat) : n + m + 0 = m + n := by\n",
      "  simpa [Nat.add_assoc] using congrArg (fun t => t + 0) (Nat.add_comm n m)\n",
      "```\n",
      "\n",
      "[LOG] Preuve trouvee!\n",
      "\n",
      "============================================================\n",
      "Session terminee apres 4 iterations.\n",
      "============================================================\n",
      "\n",
      "Resultat DEMO_2:\n",
      "  - Success: True\n",
      "  - Iterations: 4\n",
      "  - Proof: theorem add_zero_comm (n m : Nat) : n + m + 0 = m + n := by\n",
      "  simpa [Nat.add_assoc] using congrArg (...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Execute DEMO_2\n",
    "demo = DEMOS[1]\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"DEMO 2/4: {demo['name']}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Theoreme: {demo['theorem']}\")\n",
    "print(f\"Complexite: {demo['complexity']}\")\n",
    "print(f\"Iterations attendues: {demo['expected_iterations']}\")\n",
    "print(f\"Lemmes necessaires: {demo['expected_lemmas']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result_2 = prove_with_multi_agents(\n",
    "    theorem=demo[\"theorem\"],\n",
    "    max_iterations=20,\n",
    "    verbose=True,\n",
    "    use_simulation=not USE_LLM_MODE\n",
    ")\n",
    "\n",
    "print(f\"\\nResultat DEMO_2:\")\n",
    "print(f\"  - Success: {result_2['success']}\")\n",
    "print(f\"  - Iterations: {result_2['iterations']}\")\n",
    "print(f\"  - Proof: {result_2['final_proof'][:100] if result_2['final_proof'] else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. DEMO_3 : Reecritures Multiples\n",
    "\n",
    "**Objectif** : Tester chaine de reecritures avec feedback\n",
    "\n",
    "**Theoreme** : `theorem quad_comm (a b c d : Nat) : (a + b) + (c + d) = (d + c) + (b + a)`\n",
    "\n",
    "**Attentes** :\n",
    "- **Iterations** : 10-15 (4 reecritures successives)\n",
    "- **Agents impliques** : SearchAgent ‚Üí TacticAgent ‚Üí VerifierAgent ‚Üí CriticAgent (√ó3-4)\n",
    "- **Lemmes Mathlib attendus** : `Nat.add_comm`, `Nat.add_assoc`, `Nat.add_left_comm`\n",
    "- **CriticAgent** : REQUIS (plusieurs ajustements necessaires)\n",
    "- **CoordinatorAgent** : PROBABLE (si blocage, strategie AC normalization)\n",
    "- **Temps** : 3-8 secondes\n",
    "\n",
    "Cette demo teste l'**orchestration multi-agents avec feedback loops** :\n",
    "- Etape 1 : `rw [Nat.add_comm c d]` pour avoir `(d + c)`\n",
    "- Etape 2 : `rw [Nat.add_comm a b]` pour avoir `(b + a)`\n",
    "- Etape 3 : Eventuellement `rw [Nat.add_comm]` global\n",
    "- Ou : `simp only [Nat.add_comm, Nat.add_assoc, Nat.add_left_comm]` (AC normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 3/4: DEMO_3_MULTI_REWRITE\n",
      "======================================================================\n",
      "Theoreme: theorem quad_comm (a b c d : Nat) : (a + b) + (c + d) = (d + c) + (b + a)\n",
      "Complexite: Intermediaire - chaine de reecritures\n",
      "Iterations attendues: 10-15\n",
      "Lemmes necessaires: 2\n",
      "======================================================================\n",
      "Crees 5 agents SK avec modele gpt-5.2\n",
      "Mode: Semantic Kernel\n",
      "============================================================\n",
      "Session MULTI-AGENTS (SK): Prouver: theorem quad_comm (a b c d : Nat) : (a + b) + (c + d) = (d + c) + (b + ...\n",
      "============================================================\n",
      "\n",
      "[Tour 2] SearchAgent\n",
      "  Response: {\"recipient_name\":\"functions.state-add_discovered_lemma\",\"parameters\":{\"name\":\"Nat.add_left_comm\",\"statement\":\"Nat.add_left_comm (n m k : Nat) : n + (m + k) = m + (n + k)\",\"namespace\":\"Nat\",\"relevance...\n",
      "\n",
      "[Tour 3] TacticAgent\n",
      "  Response: Tactique propos√©e (forte chance de marcher) :\n",
      "\n",
      "```lean\n",
      "by\n",
      "  simpa [Nat.add_assoc, Nat.add_comm, Nat.add_left_comm]\n",
      "```\n",
      "\n",
      "√Ä faire v√©rifier par `VerifierAgent`.\n",
      "\n",
      "[Tour 4] VerifierAgent\n",
      "  Response: La preuve compile correctement (seulement un warning ‚Äúsimp au lieu de simpa‚Äù).\n",
      "\n",
      "```lean\n",
      "theorem quad_comm (a b c d : Nat) : (a + b) + (c + d) = (d + c) + (b + a) := by\n",
      "  simpa [Nat.add_assoc, Nat.add_...\n",
      "\n",
      "[LOG] Preuve trouvee!\n",
      "\n",
      "============================================================\n",
      "Session terminee apres 4 iterations.\n",
      "============================================================\n",
      "\n",
      "Resultat DEMO_3:\n",
      "  - Success: True\n",
      "  - Iterations: 4\n",
      "  - Proof: theorem quad_comm (a b c d : Nat) : (a + b) + (c + d) = (d + c) + (b + a) := by\n",
      "  simpa [Nat.add_ass...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Execute DEMO_3\n",
    "demo = DEMOS[2]\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"DEMO 3/4: {demo['name']}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Theoreme: {demo['theorem']}\")\n",
    "print(f\"Complexite: {demo['complexity']}\")\n",
    "print(f\"Iterations attendues: {demo['expected_iterations']}\")\n",
    "print(f\"Lemmes necessaires: {demo['expected_lemmas']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result_3 = prove_with_multi_agents(\n",
    "    theorem=demo[\"theorem\"],\n",
    "    max_iterations=20,\n",
    "    verbose=True,\n",
    "    use_simulation=not USE_LLM_MODE\n",
    ")\n",
    "\n",
    "print(f\"\\nResultat DEMO_3:\")\n",
    "print(f\"  - Success: {result_3['success']}\")\n",
    "print(f\"  - Iterations: {result_3['iterations']}\")\n",
    "print(f\"  - Proof: {result_3['final_proof'][:100] if result_3['final_proof'] else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. DEMO_4 : Preuve Structuree\n",
    "\n",
    "**Objectif** : Stresser le systeme avec decomposition algebrique\n",
    "\n",
    "**Theoreme** : `theorem distrib_both (a b c : Nat) : (a + b) * c + a * c = a * c + a * c + b * c`\n",
    "\n",
    "**Attentes** :\n",
    "- **Iterations** : 15-20 (decomposition + reordonnancement)\n",
    "- **Agents impliques** : Tous les 5 agents avec changement de strategie\n",
    "- **Lemmes Mathlib attendus** : `Nat.right_distrib`, `Nat.add_assoc`, `Nat.add_comm`\n",
    "- **Strategies** : EXPLORATION ‚Üí REFINEMENT ‚Üí VALIDATION\n",
    "- **CriticAgent/CoordinatorAgent** : **REQUIS**\n",
    "- **Temps** : 5-15 secondes\n",
    "\n",
    "Cette demo doit **declencher le workflow complet** :\n",
    "\n",
    "1. **SearchAgent** : Trouve `Nat.right_distrib : (n + m) * k = n * k + m * k`\n",
    "2. **TacticAgent** : Applique `rw [Nat.right_distrib]` ‚Üí `a * c + b * c + a * c`\n",
    "3. **VerifierAgent** : But non ferme (`a*c + b*c + a*c ‚â† a*c + a*c + b*c`)\n",
    "4. **CriticAgent** : Analyse ‚Üí besoin de reassociation\n",
    "5. **CoordinatorAgent** : Strategie `ring` ou reassociation manuelle\n",
    "6. **TacticAgent** : `ring` ou `simp [Nat.add_comm, Nat.add_assoc]`\n",
    "7. **VerifierAgent** : SUCCES\n",
    "\n",
    "**Note** : Si DEMO_4 se complete en <10 iterations, cela signifie que la simulation est trop optimiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 4/4: DEMO_4_STRUCTURED\n",
      "======================================================================\n",
      "Theoreme: theorem distrib_both (a b c : Nat) : (a + b) * c + a * c = a * c + a * c + b * c\n",
      "Complexite: Avancee - decomposition + recombinaison\n",
      "Iterations attendues: 15-20\n",
      "Lemmes necessaires: 3\n",
      "======================================================================\n",
      "Crees 5 agents SK avec modele gpt-5.2\n",
      "Mode: Semantic Kernel\n",
      "============================================================\n",
      "Session MULTI-AGENTS (SK): Prouver: theorem distrib_both (a b c : Nat) : (a + b) * c + a * c = a * c + a * ...\n",
      "============================================================\n",
      "\n",
      "[Tour 2] SearchAgent\n",
      "  Response: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "\n",
      "[Tour 3] TacticAgent\n",
      "  Response: Essaye cette preuve (d√©veloppement puis normalisation par `simp`) :\n",
      "\n",
      "```lean\n",
      "theorem distrib_both (a b c : Nat) :\n",
      "    (a + b) * c + a * c = a * c + a * c + b * c := by\n",
      "  simp [Nat.right_distrib, Nat.a...\n",
      "\n",
      "[LOG] Preuve trouvee!\n",
      "\n",
      "============================================================\n",
      "Session terminee apres 3 iterations.\n",
      "============================================================\n",
      "\n",
      "Resultat DEMO_4:\n",
      "  - Success: True\n",
      "  - Iterations: 3\n",
      "  - Proof: theorem distrib_both (a b c : Nat) :\n",
      "    (a + b) * c + a * c = a * c + a * c + b * c := by\n",
      "  simp [N...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Execute DEMO_4\n",
    "demo = DEMOS[3]\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"DEMO 4/4: {demo['name']}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Theoreme: {demo['theorem']}\")\n",
    "print(f\"Complexite: {demo['complexity']}\")\n",
    "print(f\"Iterations attendues: {demo['expected_iterations']}\")\n",
    "print(f\"Lemmes necessaires: {demo['expected_lemmas']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result_4 = prove_with_multi_agents(\n",
    "    theorem=demo[\"theorem\"],\n",
    "    max_iterations=20,\n",
    "    verbose=True,\n",
    "    use_simulation=not USE_LLM_MODE\n",
    ")\n",
    "\n",
    "print(f\"\\nResultat DEMO_4:\")\n",
    "print(f\"  - Success: {result_4['success']}\")\n",
    "print(f\"  - Iterations: {result_4['iterations']}\")\n",
    "print(f\"  - Proof: {result_4['final_proof'][:100] if result_4['final_proof'] else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Analyse Comparative des Resultats\n",
    "\n",
    "**Objectif** : Comparer les resultats observes avec les attentes.\n",
    "\n",
    "#### Pourquoi les resultats sont-ils plus rapides que prevu ?\n",
    "\n",
    "Les demos se terminent en 3-4 iterations au lieu de 10-20 car :\n",
    "\n",
    "1. **Mathlib contient les lemmes exacts** : `Nat.add_right_cancel`, `Nat.mul_add`, `List.length_append`\n",
    "2. **SearchAgent trouve immediatement** le bon lemme (pas de recherche exploratoire)\n",
    "3. **TacticAgent applique directement** `simpa using <lemme>` sans essayer d'autres approches\n",
    "4. **CriticAgent/CoordinatorAgent jamais actives** car aucun echec a corriger\n",
    "\n",
    "#### Implications pedagogiques\n",
    "\n",
    "| Aspect | Simulation actuelle | Systeme reel (LLM) |\n",
    "|--------|--------------------|--------------------|\n",
    "| **Recherche** | Base indexee, O(1) | Embedding similarity, exploration |\n",
    "| **Tactiques** | Pattern matching | Generation creative, essais multiples |\n",
    "| **Verification** | Heuristique simple | Lean 4 reel, erreurs detaillees |\n",
    "| **Iterations** | 3-4 (deterministe) | 10-20 (stochastique) |\n",
    "\n",
    "#### Pour observer la vraie complexite\n",
    "\n",
    "```python\n",
    "# Option 1: Mode LLM (necessite API key)\n",
    "USE_LLM_MODE = True  # Active les vraies generations\n",
    "\n",
    "# Option 2: Theoremes sans lemme direct\n",
    "theorem_custom = \"theorem custom (n m k : Nat) : (n + m) * k = n * k + m * k\"\n",
    "# Mathlib a Nat.add_mul mais pas dans notre base de simulation\n",
    "\n",
    "# Option 3: Desactiver lemmes specifiques\n",
    "# Modifier SIMULATION_LEMMAS pour exclure List.length_append\n",
    "```\n",
    "\n",
    "**Conclusion** : La simulation demontre l'*architecture* multi-agents, pas la *difficulte* reelle du theorem proving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TABLEAU COMPARATIF DES RESULTATS\n",
      "================================================================================\n",
      "\n",
      "Demo                 Succes   Iter.    Attendu    Ecart      Temps (s) \n",
      "--------------------------------------------------------------------------------\n",
      "DEMO_1_TRIVIAL       OK       3        1-2        +1         19.31     \n",
      "DEMO_2_COMPOSITION   OK       4        6-10       -2         359.80    \n",
      "DEMO_3_MULTI_REWRITE OK       4        10-15      -6         24.70     \n",
      "DEMO_4_STRUCTURED    OK       3        12-20      -9         39.24     \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Resume: 4/4 succes, 14 iterations totales, 443.05s\n",
      "\n",
      "================================================================================\n",
      "ANALYSE\n",
      "================================================================================\n",
      "\n",
      "[OBSERVATION] Toutes les demos terminent en <=5 iterations.\n",
      "[CAUSE] La simulation trouve les lemmes Mathlib directement.\n",
      "[IMPLICATION] CriticAgent et CoordinatorAgent jamais actives.\n",
      "\n",
      "[SOLUTION] Pour tester l'orchestration complete:\n",
      "  1. Utiliser USE_LLM_MODE = True (appels OpenAI reels)\n",
      "  2. Ou modifier SIMULATION_LEMMAS pour exclure les lemmes directs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Cellule 4.5 - Table de Comparaison des Resultats\n",
    "# =============================================================================\n",
    "\n",
    "# Collecter les resultats des 4 demos\n",
    "try:\n",
    "    all_results = [result_1, result_2, result_3, result_4]\n",
    "except NameError:\n",
    "    print(\"Erreur: Executez d'abord les cellules DEMO_1 a DEMO_4\")\n",
    "    all_results = None\n",
    "\n",
    "if all_results:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TABLEAU COMPARATIF DES RESULTATS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    # Header\n",
    "    print(f\"{'Demo':<20} {'Succes':<8} {'Iter.':<8} {'Attendu':<10} {'Ecart':<10} {'Temps (s)':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    expected_iterations = [\"1-2\", \"6-10\", \"10-15\", \"12-20\"]\n",
    "\n",
    "    for i, (result, expected) in enumerate(zip(all_results, expected_iterations), 1):\n",
    "        demo_name = DEMOS[i-1][\"name\"]\n",
    "        success = \"OK\" if result[\"success\"] else \"ECHEC\"\n",
    "        iterations = result[\"iterations\"]\n",
    "        time_s = result[\"total_time_s\"]\n",
    "\n",
    "        # Calculer ecart\n",
    "        exp_min, exp_max = map(int, expected.split(\"-\"))\n",
    "        if iterations < exp_min:\n",
    "            ecart = f\"-{exp_min - iterations}\"\n",
    "        elif iterations > exp_max:\n",
    "            ecart = f\"+{iterations - exp_max}\"\n",
    "        else:\n",
    "            ecart = \"OK\"\n",
    "\n",
    "        print(f\"{demo_name:<20} {success:<8} {iterations:<8} {expected:<10} {ecart:<10} {time_s:<10.2f}\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Statistiques globales\n",
    "    total_success = sum(1 for r in all_results if r[\"success\"])\n",
    "    total_iterations = sum(r[\"iterations\"] for r in all_results)\n",
    "    total_time = sum(r[\"total_time_s\"] for r in all_results)\n",
    "\n",
    "    print(f\"\\nResume: {total_success}/4 succes, {total_iterations} iterations totales, {total_time:.2f}s\")\n",
    "\n",
    "    # Analyse\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ANALYSE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if all(r[\"iterations\"] <= 5 for r in all_results):\n",
    "        print(\"\\n[OBSERVATION] Toutes les demos terminent en <=5 iterations.\")\n",
    "        print(\"[CAUSE] La simulation trouve les lemmes Mathlib directement.\")\n",
    "        print(\"[IMPLICATION] CriticAgent et CoordinatorAgent jamais actives.\")\n",
    "        print(\"\\n[SOLUTION] Pour tester l'orchestration complete:\")\n",
    "        print(\"  1. Utiliser USE_LLM_MODE = True (appels OpenAI reels)\")\n",
    "        print(\"  2. Ou modifier SIMULATION_LEMMAS pour exclure les lemmes directs\")\n",
    "    else:\n",
    "        print(\"\\n[OBSERVATION] Certaines demos necessitent plus d'iterations.\")\n",
    "        print(\"[BON SIGNE] L'orchestration complete peut etre observee.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion et Points Cles\n",
    "\n",
    "### Ce que nous avons appris\n",
    "\n",
    "#### 1. Architecture Multi-Agents pour Theorem Proving\n",
    "\n",
    "| Composant | Role | Implementation SK |\n",
    "|-----------|------|-------------------|\n",
    "| **ProofState** | Etat partage synchronise | `@dataclass` + plugins |\n",
    "| **Plugins** | Fonctionnalites specialisees | `@kernel_function` |\n",
    "| **Agents** | Roles specialises (Search, Tactic, Verify...) | `ChatCompletionAgent` |\n",
    "| **Orchestration** | Delegation dynamique | `AgentGroupChat` + strategies |\n",
    "\n",
    "#### 2. Semantic Kernel vs Implementation Ad-Hoc (Lean-8)\n",
    "\n",
    "| Aspect | Lean-8 (Ad-Hoc) | Lean-9 (Semantic Kernel) |\n",
    "|--------|-----------------|--------------------------|\n",
    "| **Etat** | Variables globales | `ProofState` classe |\n",
    "| **Agents** | Fonctions Python | `ChatCompletionAgent` |\n",
    "| **Communication** | Appels directs | Message passing |\n",
    "| **Extensibilite** | Modifier le code | Ajouter plugins |\n",
    "| **LLM** | OpenAI direct | Abstraction SK |\n",
    "\n",
    "#### 3. Patterns Replicables\n",
    "\n",
    "1. **StateManager Pattern** : Un objet central pour l'etat partage\n",
    "2. **Plugin Pattern** : Fonctions decorees pour l'injection de dependances\n",
    "3. **Delegation Pattern** : Chaque agent designe le suivant\n",
    "4. **Termination Pattern** : Criteres multiples (succes, timeout, max_iter)\n",
    "\n",
    "### Limitations et Perspectives\n",
    "\n",
    "#### Limitations actuelles\n",
    "\n",
    "- **Simulation trop parfaite** : Trouve les lemmes directs immediatement\n",
    "- **Pas de vrai Lean** : Verification heuristique, pas de lean4 reel\n",
    "- **Base de lemmes limitee** : ~50 lemmes vs 100k+ dans Mathlib\n",
    "- **Pas de backtracking** : Premiere tactique qui marche = solution\n",
    "\n",
    "#### Prochaines etapes (Lean-10 LeanDojo)\n",
    "\n",
    "1. **Integration LeanDojo** : Interaction programmatique avec Lean 4\n",
    "2. **Tracing Mathlib** : Extraction des 100k+ lemmes\n",
    "3. **Verification reelle** : Feedback Lean vs heuristique\n",
    "4. **Benchmarks** : MiniF2F, ProofNet, LeanBench\n",
    "\n",
    "### Resume Final\n",
    "\n",
    "Ce notebook a demontre comment construire un systeme multi-agents pour le theorem proving avec Semantic Kernel. Les patterns (StateManager, Plugin, Delegation) sont replicables pour d'autres domaines.\n",
    "\n",
    "**Key Takeaways** :\n",
    "- L'architecture compte plus que les resultats de simulation\n",
    "- Semantic Kernel simplifie l'orchestration multi-agents\n",
    "- Les vrais defis apparaissent avec des theoremes sans lemmes directs\n",
    "- LeanDojo (Notebook 10) permettra la verification reelle\n",
    "\n",
    "---\n",
    "\n",
    "### Navigation\n",
    "\n",
    "| Precedent | Index | Suivant |\n",
    "|-----------|-------|---------|\n",
    "| [Lean-8 (Agents Ad-Hoc)](Lean-8-Agentic-Proving.ipynb) | [Lean-1 (Setup)](Lean-1-Setup.ipynb) | [Lean-10 (LeanDojo)](Lean-10-LeanDojo.ipynb) |\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook complete. Duree estimee: 45-55 minutes.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (WSL)",
   "language": "python",
   "name": "python3-wsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}