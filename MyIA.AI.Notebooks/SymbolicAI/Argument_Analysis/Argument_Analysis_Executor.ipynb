{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10996590",
   "metadata": {},
   "source": [
    "# üöÄ Analyse Rh√©torique Collaborative par Agents IA - Ex√©cuteur Principal\n",
    "\n",
    "**Objectif:** Ce notebook orchestre et ex√©cute une analyse rh√©torique multi-agents sur un texte donn√©. Il sert de point d'entr√©e principal pour lancer le processus.\n",
    "\n",
    "**Structure Modulaire:**\n",
    "1.  `Argument_Analysis_UI_configuration.ipynb` : G√®re l'interface utilisateur pour s√©lectionner/pr√©parer le texte √† analyser (incluant sources pr√©d√©finies, URL, fichier, texte direct, et extraction) et charge/sauvegarde la configuration des sources.\n",
    "2.  `Argument_Analysis_Agentic-0-init.ipynb`: Configuration initiale (d√©pendances, LLM, JVM), d√©finition de l'√©tat partag√© (`RhetoricalAnalysisState`) et du gestionnaire d'√©tat (`StateManagerPlugin`).\n",
    "3.  `Argument_Analysis_Agentic-1-informal_agent.ipynb`: D√©finition de l'`InformalAnalysisAgent`.\n",
    "4.  `Argument_Analysis_Agentic-2-pl_agent.ipynb`: D√©finition du `PropositionalLogicAgent`.\n",
    "5.  `Argument_Analysis_Agentic-3-orchestration.ipynb`: D√©finition des strat√©gies d'orchestration et de la fonction principale `run_analysis_conversation`.\n",
    "\n",
    "**Pr√©requis:**\n",
    "* Un fichier `.env` √† la racine contenant les cl√©s API, configurations LLM, et la cl√© de chiffrement `TEXT_CONFIG_KEY`.\n",
    "* Un environnement Java Development Kit (JDK >= 11) correctement install√© et configur√© (`JAVA_HOME`).\n",
    "* Les d√©pendances Python install√©es (`ipywidgets`, `requests`, `jupyter-ui-poll`, `python-dotenv`, `semantic-kernel`, `pandas`, `jpype1`, `cryptography`).\n",
    "* Les JARs Tweety plac√©s dans le dossier `libs/`.\n",
    "* Le fichier `extract_sources.json.gz.enc` (s'il existe d√©j√†) contenant les d√©finitions des sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763bbbf",
   "metadata": {},
   "source": [
    "## 1. Chargement de l'Environnement\n",
    "\n",
    "Chargement des variables depuis le fichier `.env` (cl√©s API, cl√© de chiffrement, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c82597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".env charg√©: True\n"
     ]
    }
   ],
   "source": [
    "# Charger les variables d'environnement\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "loaded_env = load_dotenv(find_dotenv(), override=True)\n",
    "print(f\".env charg√©: {loaded_env}\") # Affiche True si le .env a √©t√© trouv√© et charg√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41046be8",
   "metadata": {},
   "source": [
    "## 2. Chargement de l'Interface Utilisateur\n",
    "\n",
    "Ex√©cution du notebook `UI_Configuration.ipynb` pour d√©finir la fonction `configure_analysis_task()`. C'est ce notebook qui contient d√©sormais toute la logique de l'interface graphique, du cache fichier et de la gestion de la configuration chiffr√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b3b3380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode BATCH detecte (BATCH_MODE=true dans .env)\n",
      "   -> Skip du chargement UI_configuration.ipynb (widgets non compatibles)\n",
      "   -> Le texte sera fourni directement dans la cellule suivante\n"
     ]
    }
   ],
   "source": [
    "# Mode batch contr√¥l√© par variable d'environnement\n",
    "# Si BATCH_MODE=true dans .env, on skip l'UI interactive (widgets bloquants)\n",
    "import os\n",
    "BATCH_MODE = os.getenv(\"BATCH_MODE\", \"false\").lower() in (\"true\", \"1\", \"yes\")\n",
    "\n",
    "if BATCH_MODE:\n",
    "    print(\"Mode BATCH detecte (BATCH_MODE=true dans .env)\")\n",
    "    print(\"   -> Skip du chargement UI_configuration.ipynb (widgets non compatibles)\")\n",
    "    print(\"   -> Le texte sera fourni directement dans la cellule suivante\")\n",
    "else:\n",
    "    # Ex√©cuter le notebook UI pour d√©finir la fonction configure_analysis_task\n",
    "    # Assurez-vous que le fichier UI_Configuration.ipynb est dans le m√™me r√©pertoire\n",
    "    print(\"Ex√©cution de Argument_Analysis_UI_configuration.ipynb...\")\n",
    "    %run ./Argument_Analysis_UI_configuration.ipynb\n",
    "    print(\"Ex√©cution de Argument_Analysis_UI_configuration.ipynb termin√©e.\")\n",
    "\n",
    "    # V√©rification que la fonction est bien d√©finie apr√®s l'ex√©cution\n",
    "    if 'configure_analysis_task' not in locals():\n",
    "        print(\"ERREUR CRITIQUE : La fonction configure_analysis_task n'a pas √©t√© d√©finie par UI_Configuration.ipynb !\")\n",
    "    else:\n",
    "        print(\"Fonction configure_analysis_task trouv√©e.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438236c",
   "metadata": {},
   "source": [
    "## 3. Configuration de la T√¢che et R√©cup√©ration du Texte\n",
    "\n",
    "Appel de la fonction `configure_analysis_task()` d√©finie dans le notebook UI. Cela affichera l'interface utilisateur. S√©lectionnez votre source, pr√©parez le texte, puis cliquez sur **\"Lancer l'Analyse\"**. Le texte pr√©par√© sera retourn√© et stock√© pour l'√©tape suivante. La cellule attendra la fin de votre interaction avec l'UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eed71c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode BATCH - Configuration automatique du texte\n",
      "Texte d'exemple par defaut utilise (386 caracteres)\n",
      "\n",
      "Extrait du texte:\n",
      "Les reseaux sociaux ont transforme notre facon de communiquer. \n",
      "D'un cote, ils permettent de rester en contact avec nos proches, de partager nos exper...\n",
      "\n",
      "Texte pret pour l'analyse (longueur: 386). Passage au chargement des agents.\n"
     ]
    }
   ],
   "source": [
    "# Configuration du texte pour l'analyse\n",
    "# En mode BATCH : utilise BATCH_TEXT (variable d'env) ou le texte d'exemple\n",
    "# En mode interactif : appelle configure_analysis_task() (si disponible)\n",
    "\n",
    "texte_pour_analyse = None\n",
    "\n",
    "# Texte d'exemple par d√©faut pour le mode batch\n",
    "TEXTE_EXEMPLE_BATCH = \"\"\"Les reseaux sociaux ont transforme notre facon de communiquer. \n",
    "D'un cote, ils permettent de rester en contact avec nos proches, de partager nos experiences et de decouvrir de nouvelles perspectives. \n",
    "D'un autre cote, ils peuvent creer une dependance, favoriser la desinformation et nuire a notre bien-etre mental. \n",
    "Il est donc essentiel de les utiliser avec moderation et discernement.\"\"\"\n",
    "\n",
    "if BATCH_MODE:\n",
    "    # === MODE BATCH ===\n",
    "    print(\"Mode BATCH - Configuration automatique du texte\")\n",
    "    \n",
    "    # Priorit√© 1: Variable d'environnement BATCH_TEXT\n",
    "    batch_text_env = os.getenv(\"BATCH_TEXT\", \"\")\n",
    "    if batch_text_env:\n",
    "        texte_pour_analyse = batch_text_env\n",
    "        print(f\"Texte charge depuis BATCH_TEXT ({len(texte_pour_analyse)} caracteres)\")\n",
    "    else:\n",
    "        # Priorit√© 2: Texte d'exemple par d√©faut\n",
    "        texte_pour_analyse = TEXTE_EXEMPLE_BATCH\n",
    "        print(f\"Texte d'exemple par defaut utilise ({len(texte_pour_analyse)} caracteres)\")\n",
    "    \n",
    "    print(f\"\\nExtrait du texte:\\n{texte_pour_analyse[:150]}...\")\n",
    "\n",
    "else:\n",
    "    # === MODE INTERACTIF ===\n",
    "    print(\"Mode INTERACTIF - Lancement de l'interface de configuration\")\n",
    "    \n",
    "    if 'configure_analysis_task' in locals():\n",
    "        try:\n",
    "            texte_pour_analyse = configure_analysis_task()\n",
    "            print(f\"Texte recupere via l'interface ({len(texte_pour_analyse) if texte_pour_analyse else 0} caracteres)\")\n",
    "        except Exception as e_ui:\n",
    "            print(f\"Erreur lors de la configuration UI : {e_ui}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"Fonction configure_analysis_task non disponible - verifiez le chargement de UI_configuration.ipynb\")\n",
    "\n",
    "# V√©rification finale\n",
    "if not texte_pour_analyse:\n",
    "    print(\"\\nAucun texte prepare. L'analyse ne peut pas continuer.\")\n",
    "else:\n",
    "    print(f\"\\nTexte pret pour l'analyse (longueur: {len(texte_pour_analyse)}). Passage au chargement des agents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183031e3",
   "metadata": {},
   "source": [
    "## 4. Chargement des D√©finitions des Agents et de l'Orchestration\n",
    "\n",
    "Maintenant que le texte est pr√™t (si l'√©tape pr√©c√©dente a r√©ussi), nous chargeons les d√©finitions des agents, des plugins, des strat√©gies et de la fonction d'orchestration `run_analysis_conversation` en ex√©cutant les notebooks enfants d√©di√©s.\n",
    "\n",
    "**Rappel:** Le notebook `Argument_Analysis_Agentic-0-init.ipynb` **ne doit plus d√©finir** la variable `raw_text_input` et le notebook `Argument_Analysis_Agentic-3-orchestration.ipynb` **doit d√©finir** `run_analysis_conversation(texte_a_analyser)` acceptant un argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7674a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chargement des d√©finitions des agents et de l'orchestration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:12:26 [INFO] [Orchestration.Setup] --- V√©rification des d√©pendances ---\n",
      "11:12:26 [INFO] [Orchestration.Setup] ‚úîÔ∏è D√©pendance 'jpype' trouv√©e.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: semantic-kernel in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (1.39.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (1.2.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (8.1.8)\n",
      "Requirement already satisfied: jpype1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (1.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\miniconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (2.3.3)\n",
      "Requirement already satisfied: azure-ai-projects~=1.0.0b12 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.0.0)\n",
      "Requirement already satisfied: azure-ai-agents>=1.2.0b3 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.2.0b3)\n",
      "Requirement already satisfied: aiohttp~=3.8 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (3.12.15)\n",
      "Requirement already satisfied: cloudevents~=1.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.12.0)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from semantic-kernel) (2.11.7)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from semantic-kernel) (2.11.0)\n",
      "Requirement already satisfied: defusedxml~=0.7 in c:\\programdata\\miniconda3\\lib\\site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: azure-identity>=1.13 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.24.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (2.2.6)\n",
      "Requirement already satisfied: openai<2,>=1.98.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.106.1)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (0.19.5)\n",
      "Requirement already satisfied: websockets<16,>=13 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (15.0.1)\n",
      "Requirement already satisfied: aiortc>=1.9.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.13.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.36.0)\n",
      "Requirement already satisfied: prance<25.4.9,>=23.6.21 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from semantic-kernel) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.15.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (1.16.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (6.31.1)\n",
      "Requirement already satisfied: typing-extensions>=4.13 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from semantic-kernel) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp~=3.8->semantic-kernel) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp~=3.8->semantic-kernel) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp~=3.8->semantic-kernel) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.20.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (1.35.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (12.26.0)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\miniconda3\\lib\\site-packages (from deprecation<3.0,>=2.0->cloudevents~=1.0->semantic-kernel) (24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\miniconda3\\lib\\site-packages (from openai<2,>=1.98.0->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\miniconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2,>=1.98.0->semantic-kernel) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2,>=1.98.0->semantic-kernel) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2,>=1.98.0->semantic-kernel) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2,>=1.98.0->semantic-kernel) (0.16.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.25.1)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.8.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: parse in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug<3.1.2 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\miniconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\miniconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.27.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.3)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.12.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.57b0)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\programdata\\miniconda3\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (0.18.10)\n",
      "Requirement already satisfied: six~=1.15 in c:\\programdata\\miniconda3\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (1.17.0)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.4.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.10.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiortc>=1.9.0->semantic-kernel) (0.10.1)\n",
      "Requirement already satisfied: av<15.0.0,>=14.0.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiortc>=1.9.0->semantic-kernel) (14.4.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=44.0.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (45.0.3)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiortc>=1.9.0->semantic-kernel) (1.7.1)\n",
      "Requirement already satisfied: pyee>=13.0.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiortc>=1.9.0->semantic-kernel) (13.0.0)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiortc>=1.9.0->semantic-kernel) (0.12.0)\n",
      "Requirement already satisfied: pyopenssl>=25.0.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aiortc>=1.9.0->semantic-kernel) (25.1.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel) (2.7.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel) (0.2.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from azure-identity>=1.13->semantic-kernel) (1.33.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from azure-identity>=1.13->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\miniconda3\\lib\\site-packages (from cffi>=1.0.0->aiortc>=1.9.0->semantic-kernel) (2.21)\n",
      "Requirement already satisfied: decorator in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity>=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\jsboi\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:12:28 [INFO] [Orchestration.Setup] ‚úîÔ∏è D√©pendance 'semantic_kernel' trouv√©e.\n",
      "11:12:28 [INFO] [Orchestration.Setup] ‚úîÔ∏è D√©pendance 'dotenv' trouv√©e.\n",
      "11:12:28 [INFO] [Orchestration.Setup] ‚úîÔ∏è D√©pendance 'pandas' trouv√©e.\n",
      "11:12:28 [INFO] [Orchestration.Setup] ‚úîÔ∏è D√©pendance 'requests' trouv√©e.\n",
      "11:12:28 [INFO] [Orchestration.Setup] \n",
      "‚úÖ D√©pendances principales v√©rifi√©es.\n",
      "11:12:28 [INFO] [Orchestration.Setup] --- Chargement Configuration LLM ---\n",
      "11:12:28 [INFO] [Orchestration.Setup] ‚úÖ Configuration OpenAI standard d√©tect√©e (Mod√®le: gpt-4o-mini). Org ID: Non fourni.\n",
      "11:12:28 [INFO] [Orchestration.Setup] --- Fin Configuration Initiale ---\n",
      "11:12:28 [INFO] [Orchestration.Config] ‚úÖ Configuration OpenAI standard charg√©e (Mod√®le: gpt-4o-mini). Org ID: Non fourni.\n",
      "11:12:29 [INFO] [Orchestration.JPype] \n",
      "--- Configuration Auto-Suffisante de la JVM (Option B - Embarqu√©e) ---\n",
      "11:12:29 [INFO] [Orchestration.JPype] üîç Recherche JDK portable dans l'arborescence projet...\n",
      "11:12:29 [INFO] [Orchestration.JPype] ‚úÖ JDK portable trouv√©: d:\\dev\\CoursIA\\MyIA.AI.Notebooks\\SymbolicAI\\Argument_Analysis\\jdk-17-portable\\zulu17.50.19-ca-jdk17.0.11-win_x64\n",
      "11:12:29 [INFO] [Orchestration.JPype] üè† JAVA_HOME configur√© dynamiquement: d:\\dev\\CoursIA\\MyIA.AI.Notebooks\\SymbolicAI\\Argument_Analysis\\jdk-17-portable\\zulu17.50.19-ca-jdk17.0.11-win_x64\n",
      "11:12:29 [INFO] [Orchestration.JPype] üì¶ Construction du classpath Tweety...\n",
      "11:12:29 [INFO] [Orchestration.JPype]   Scan des JARs dans: libs\n",
      "11:12:29 [INFO] [Orchestration.JPype]   ‚úÖ 34 JARs trouv√©s dans libs\n",
      "11:12:29 [INFO] [Orchestration.JPype] ‚úÖ Classpath construit: 34 JARs Tweety\n",
      "11:12:29 [INFO] [Orchestration.JPype] üöÄ D√©marrage JVM avec 34 JARs Tweety...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration OpenAI standard charg√©e (Mod√®le: gpt-4o-mini). Org ID: Non fourni.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:12:29 [INFO] [Orchestration.JPype] ‚úÖ JVM d√©marr√©e avec succ√®s et domaines enregistr√©s\n",
      "11:12:29 [INFO] [Orchestration.JPype] ‚òï Java 17.0.11 op√©rationnel\n",
      "11:12:29 [INFO] [Orchestration.JPype] üéØ Test des classes critiques Tweety...\n",
      "11:12:29 [INFO] [Orchestration.JPype]   ‚úÖ InformationObject: Accessible\n",
      "11:12:29 [INFO] [Orchestration.JPype]   ‚úÖ PlParser: Accessible\n",
      "11:12:29 [INFO] [Orchestration.JPype]   ‚úÖ PlFormula: Accessible\n",
      "11:12:29 [INFO] [Orchestration.JPype]   ‚úÖ BaseRevisionOperator: Accessible\n",
      "11:12:29 [INFO] [Orchestration.JPype] üèÜ Test Tweety R√âUSSI: 4/4 classes accessibles\n",
      "11:12:29 [INFO] [Orchestration.JPype] \n",
      "üéâ üèÜ SUCC√àS TOTAL - INFRASTRUCTURE TWEETY AUTO-SUFFISANTE! üèÜ üéâ\n",
      "11:12:29 [INFO] [Orchestration.JPype] ‚úÖ PropositionalLogicAgent pr√™t pour ex√©cution native\n",
      "11:12:29 [INFO] [Orchestration.JPype] ‚úÖ Pipeline argumentatif avec int√©gration formelle/informelle op√©rationnel\n",
      "11:12:29 [INFO] [Orchestration.JPype] \n",
      "üü¢ STATUT FINAL: JVM + Tweety OP√âRATIONNELS\n",
      "11:12:29 [INFO] [Orchestration.JPype]    Pipeline peut atteindre son potentiel maximal (8/10)\n",
      "11:12:29 [INFO] [Orchestration.JPype] --- Fin Configuration JPype Auto-Suffisante ---\n",
      "11:12:29 [INFO] [Orchestration.JPype] ‚úÖ Tweety op√©rationnel - PropositionalLogicAgent en mode natif\n",
      "11:12:29 [INFO] [root] Classe RhetoricalAnalysisState d√©finie.\n",
      "11:12:29 [INFO] [root] Classe StateManagerPlugin d√©finie.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'omit' from 'openai._types' (C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_types.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_75968\\2997935909.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIChatCompletion, AzureChatCompletion\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# R√©cup√©rer loggers et variables de config (suppos√©s d√©finis)\u001b[39;00m\n\u001b[32m      9\u001b[39m llm_logger = logging.getLogger(\u001b[33m\"\u001b[39m\u001b[33mOrchestration.LLM\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\__init__.py:37\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompt_execution_settings\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai_text_to_audio_execution_settings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     32\u001b[39m     OpenAITextToAudioExecutionSettings,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompt_execution_settings\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai_text_to_image_execution_settings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     35\u001b[39m     OpenAITextToImageExecutionSettings,\n\u001b[32m     36\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_open_ai_realtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ListenEvents, SendEvents\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mazure_audio_to_text\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureAudioToText\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mazure_chat_completion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatCompletion\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\_open_ai_realtime.py:50\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunction_choice_behavior\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionChoiceType\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompt_execution_settings\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai_realtime_execution_settings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     OpenAIRealtimeExecutionSettings,\n\u001b[32m     49\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai_handler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIHandler\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompt_execution_settings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptExecutionSettings\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrealtime_client_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RealtimeClientBase\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Union\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncOpenAI, AsyncStream, BadRequestError, _legacy_response\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileTypes, Omit, omit\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_parsing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_completions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_to_response_format_param\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Completion, CreateEmbeddingResponse\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'omit' from 'openai._types' (C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_types.py)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Une erreur est survenue lors de l'ex√©cution des notebooks enfants : cannot import name 'omit' from 'openai._types' (C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_types.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Local\\Temp\\ipykernel_75968\\1655313075.py\", line 6, in <module>\n",
      "    get_ipython().run_line_magic('run', './Argument_Analysis_Agentic-0-init.ipynb')\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py\", line 2504, in run_line_magic\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\magics\\execution.py\", line 749, in run\n",
      "    self.shell.safe_execfile_ipy(filename, raise_exceptions=True)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in safe_execfile_ipy\n",
      "    result.raise_error()\n",
      "    ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py\", line 326, in raise_error\n",
      "    raise self.error_in_exec\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Local\\Temp\\ipykernel_75968\\2997935909.py\", line 6, in <module>\n",
      "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, AzureChatCompletion\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\__init__.py\", line 37, in <module>\n",
      "    from semantic_kernel.connectors.ai.open_ai.services._open_ai_realtime import ListenEvents, SendEvents\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\_open_ai_realtime.py\", line 50, in <module>\n",
      "    from semantic_kernel.connectors.ai.open_ai.services.open_ai_handler import OpenAIHandler\n",
      "  File \"C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py\", line 8, in <module>\n",
      "    from openai._types import FileTypes, Omit, omit\n",
      "ImportError: cannot import name 'omit' from 'openai._types' (C:\\Users\\jsboi\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_types.py). Did you mean: 'Omit'?\n"
     ]
    }
   ],
   "source": [
    "# Ex√©cuter les notebooks enfants pour charger les d√©finitions\n",
    "# Seulement si un texte a √©t√© pr√©par√© avec succ√®s\n",
    "if 'texte_pour_analyse' in locals() and texte_pour_analyse:\n",
    "    print(\"\\nChargement des d√©finitions des agents et de l'orchestration...\")\n",
    "    try:\n",
    "        %run ./Argument_Analysis_Agentic-0-init.ipynb\n",
    "        %run ./Argument_Analysis_Agentic-1-informal_agent.ipynb\n",
    "        %run ./Argument_Analysis_Agentic-2-pl_agent.ipynb\n",
    "        %run ./Argument_Analysis_Agentic-3-orchestration.ipynb  # D√©finit run_analysis_conversation(texte_a_analyser)\n",
    "        print(\"‚úÖ D√©finitions charg√©es.\")\n",
    "        # V√©rifier que la fonction d'orchestration est charg√©e\n",
    "        if 'run_analysis_conversation' not in locals():\n",
    "             print(\"‚ùå ERREUR CRITIQUE: La fonction run_analysis_conversation n'a pas √©t√© d√©finie apr√®s l'ex√©cution des notebooks agents!\")\n",
    "             # raise NameError(\"run_analysis_conversation non d√©finie\")\n",
    "    except Exception as e_run:\n",
    "        print(f\"\\n‚ùå Une erreur est survenue lors de l'ex√©cution des notebooks enfants : {e_run}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Emp√™cher la suite si le chargement √©choue\n",
    "        texte_pour_analyse = None\n",
    "else:\n",
    "    print(\"\\nSkipping agent definition loading because no text was prepared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60ae64",
   "metadata": {},
   "source": [
    "## 5. Ex√©cution de l'Analyse Collaborative\n",
    "\n",
    "Si toutes les √©tapes pr√©c√©dentes se sont bien d√©roul√©es et que nous avons un texte √† analyser, cette cellule lance l'analyse collaborative.\n",
    "\n",
    "*Note :* `nest_asyncio` est appliqu√© pour la compatibilit√© avec l'environnement asynchrone de Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689bf30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Analyse non lanc√©e : aucun texte n'a √©t√© pr√©par√© ou une erreur est survenue avant.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Lancer seulement si on a obtenu un texte valide ET que les d√©finitions sont charg√©es\n",
    "if 'texte_pour_analyse' in locals() and texte_pour_analyse and 'run_analysis_conversation' in locals():\n",
    "    print(\"\\nüöÄ Lancement de l'ex√©cution asynchrone de l'analyse...\")\n",
    "    nest_asyncio.apply()\n",
    "    try:\n",
    "        # Passer le texte pr√©par√©\n",
    "        await run_analysis_conversation(texte_pour_analyse)\n",
    "        print(\"\\nüèÅ Analyse termin√©e.\")\n",
    "    except Exception as e_analysis:\n",
    "        print(f\"\\n‚ùå Une erreur est survenue pendant l'ex√©cution de l'analyse : {e_analysis}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "elif 'texte_pour_analyse' not in locals() or not texte_pour_analyse:\n",
    "    print(\"\\n Analyse non lanc√©e : aucun texte n'a √©t√© pr√©par√© ou une erreur est survenue avant.\")\n",
    "else: # Implique que run_analysis_conversation n'a pas √©t√© charg√©e\n",
    "     print(\"\\n Analyse non lanc√©e : la fonction d'orchestration n'a pas pu √™tre charg√©e.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mf35rz46kvk",
   "source": "## 5bis. Rapport de Validation de l'Analyse\n\nCette cellule genere un rapport structure validant la completude de l'analyse rhetorique.\nElle verifie les criteres suivants:\n- Arguments identifies\n- Sophismes analyses\n- Belief Sets PL crees\n- Requetes logiques executees\n- Conclusion generee\n\nLe rapport est exporte en JSON pour utilisation ulterieure.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "pug0jcknsij",
   "source": "# === CELLULE DE VALIDATION FINALE ===\n# Genere un rapport JSON structure avec cross-validation\n\nimport json\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\n\ndef generate_validated_analysis_report(state) -> Dict[str, Any]:\n    \"\"\"Genere rapport JSON structure avec cross-validation.\"\"\"\n    \n    report = {\n        \"metadata\": {\n            \"timestamp\": datetime.now().isoformat(),\n            \"version\": \"2.0-validated\",\n            \"text_length\": len(state.raw_text) if state.raw_text else 0,\n            \"text_snippet\": (state.raw_text[:150] + \"...\") if state.raw_text and len(state.raw_text) > 150 else (state.raw_text or \"\")\n        },\n        \"informal_analysis\": {\n            \"arguments\": [],\n            \"fallacies\": [],\n            \"taxonomy_families_used\": set()\n        },\n        \"formal_analysis\": {\n            \"belief_sets\": [],\n            \"query_results\": [],\n            \"consistency_checked\": False\n        },\n        \"cross_validation\": {\n            \"validation_status\": \"INCOMPLETE\",\n            \"confidence_score\": 0.0,\n            \"checks_passed\": [],\n            \"issues\": []\n        },\n        \"conclusion\": {\n            \"summary\": state.final_conclusion if hasattr(state, 'final_conclusion') else None,\n            \"is_complete\": hasattr(state, 'final_conclusion') and state.final_conclusion is not None\n        }\n    }\n    \n    # Populate arguments\n    if hasattr(state, 'identified_arguments'):\n        for arg_id, arg_desc in state.identified_arguments.items():\n            has_fallacy = False\n            if hasattr(state, 'identified_fallacies'):\n                has_fallacy = any(\n                    f.get('target_argument_id') == arg_id\n                    for f in state.identified_fallacies.values()\n                )\n            report[\"informal_analysis\"][\"arguments\"].append({\n                \"id\": arg_id, \"description\": str(arg_desc)[:200], \"has_fallacy\": has_fallacy\n            })\n    \n    # Populate fallacies\n    if hasattr(state, 'identified_fallacies'):\n        for f_id, f_data in state.identified_fallacies.items():\n            fallacy_type = f_data.get('type', 'Unknown') if isinstance(f_data, dict) else str(f_data)\n            report[\"informal_analysis\"][\"fallacies\"].append({\n                \"id\": f_id,\n                \"type\": fallacy_type,\n                \"justification\": f_data.get('justification', '') if isinstance(f_data, dict) else '',\n                \"target_id\": f_data.get('target_argument_id') if isinstance(f_data, dict) else None,\n                \"severity\": \"HIGH\" if any(kw in str(fallacy_type).lower() for kw in ['manipulation', 'tromperie']) else \"MEDIUM\"\n            })\n            # Track taxonomy families\n            if isinstance(fallacy_type, str) and '/' in fallacy_type:\n                report[\"informal_analysis\"][\"taxonomy_families_used\"].add(fallacy_type.split('/')[0])\n    \n    report[\"informal_analysis\"][\"taxonomy_families_used\"] = list(report[\"informal_analysis\"][\"taxonomy_families_used\"])\n    \n    # Populate belief sets\n    if hasattr(state, 'belief_sets'):\n        for bs_id, bs_data in state.belief_sets.items():\n            content = bs_data.get('content', '') if isinstance(bs_data, dict) else str(bs_data)\n            report[\"formal_analysis\"][\"belief_sets\"].append({\n                \"id\": bs_id,\n                \"logic_type\": bs_data.get('logic_type', 'PL') if isinstance(bs_data, dict) else 'PL',\n                \"formula_count\": content.count('\\n') + 1 if content else 0,\n                \"is_consistent\": \"NOT_CHECKED\"\n            })\n    \n    # Populate query results\n    if hasattr(state, 'query_log'):\n        for qlog in state.query_log:\n            raw_result = qlog.get('raw_result', '') if isinstance(qlog, dict) else ''\n            status = \"UNKNOWN\"\n            if \"ACCEPTED\" in str(raw_result): status = \"ACCEPTED\"\n            elif \"REJECTED\" in str(raw_result): status = \"REJECTED\"\n            elif \"FUNC_ERROR\" in str(raw_result): status = \"ERROR\"\n            \n            report[\"formal_analysis\"][\"query_results\"].append({\n                \"log_id\": qlog.get('log_id', '') if isinstance(qlog, dict) else '',\n                \"belief_set_id\": qlog.get('belief_set_id', '') if isinstance(qlog, dict) else '',\n                \"query\": qlog.get('query', '') if isinstance(qlog, dict) else '',\n                \"status\": status\n            })\n    \n    # === CROSS-VALIDATION LOGIC ===\n    checks = []\n    issues = []\n    \n    # Check 1: Arguments identified\n    if len(report[\"informal_analysis\"][\"arguments\"]) > 0:\n        checks.append(\"ARGUMENTS_IDENTIFIED\")\n    else:\n        issues.append(\"Aucun argument identifie\")\n    \n    # Check 2: Fallacy analysis attempted\n    if len(report[\"informal_analysis\"][\"fallacies\"]) > 0:\n        checks.append(\"FALLACIES_ANALYZED\")\n    elif hasattr(state, 'answers') and any(\"sophisme\" in str(v).lower() for v in state.answers.values()):\n        checks.append(\"FALLACY_ANALYSIS_ATTEMPTED\")\n    else:\n        issues.append(\"Analyse sophismes non effectuee\")\n    \n    # Check 3: Formal logic translation\n    if len(report[\"formal_analysis\"][\"belief_sets\"]) > 0:\n        checks.append(\"BELIEF_SET_CREATED\")\n    else:\n        issues.append(\"Aucun Belief Set PL cree\")\n    \n    # Check 4: Queries executed\n    if len(report[\"formal_analysis\"][\"query_results\"]) > 0:\n        checks.append(\"QUERIES_EXECUTED\")\n        accepted = sum(1 for q in report[\"formal_analysis\"][\"query_results\"] if q[\"status\"] == \"ACCEPTED\")\n        rejected = sum(1 for q in report[\"formal_analysis\"][\"query_results\"] if q[\"status\"] == \"REJECTED\")\n        if accepted > 0 or rejected > 0:\n            checks.append(\"QUERIES_MEANINGFUL\")\n    else:\n        issues.append(\"Aucune requete PL executee\")\n    \n    # Check 5: Conclusion generated\n    if report[\"conclusion\"][\"is_complete\"]:\n        checks.append(\"CONCLUSION_GENERATED\")\n    else:\n        issues.append(\"Conclusion finale non generee\")\n    \n    # Calculate confidence score\n    max_checks = 6  # ARGUMENTS, FALLACIES, BELIEF_SET, QUERIES, QUERIES_MEANINGFUL, CONCLUSION\n    confidence = len(checks) / max_checks\n    report[\"cross_validation\"][\"confidence_score\"] = round(confidence, 2)\n    report[\"cross_validation\"][\"checks_passed\"] = checks\n    report[\"cross_validation\"][\"issues\"] = issues\n    \n    # Determine validation status\n    if confidence >= 0.8:\n        report[\"cross_validation\"][\"validation_status\"] = \"COMPLETE_VALIDATED\"\n    elif confidence >= 0.5:\n        report[\"cross_validation\"][\"validation_status\"] = \"PARTIAL_VALIDATED\"\n    elif confidence >= 0.3:\n        report[\"cross_validation\"][\"validation_status\"] = \"MINIMAL\"\n    else:\n        report[\"cross_validation\"][\"validation_status\"] = \"INCOMPLETE\"\n    \n    return report\n\n\ndef display_validation_summary(report: Dict[str, Any]) -> str:\n    \"\"\"Affiche resume lisible du rapport de validation.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"          RAPPORT D'ANALYSE RHETORIQUE VALIDEE\")\n    print(\"=\"*70)\n    \n    cv = report[\"cross_validation\"]\n    status_symbols = {\n        \"COMPLETE_VALIDATED\": \"[OK]\",\n        \"PARTIAL_VALIDATED\": \"[PARTIEL]\",\n        \"MINIMAL\": \"[MINIMAL]\",\n        \"INCOMPLETE\": \"[INCOMPLET]\"\n    }\n    \n    print(f\"\\n  STATUT: {status_symbols.get(cv['validation_status'], '?')} {cv['validation_status']}\")\n    print(f\"  CONFIANCE: {cv['confidence_score']*100:.0f}%\")\n    \n    print(f\"\\n  [ANALYSE INFORMELLE]\")\n    print(f\"    Arguments: {len(report['informal_analysis']['arguments'])}\")\n    print(f\"    Sophismes: {len(report['informal_analysis']['fallacies'])}\")\n    \n    print(f\"\\n  [ANALYSE FORMELLE]\")\n    print(f\"    Belief Sets: {len(report['formal_analysis']['belief_sets'])}\")\n    print(f\"    Requetes: {len(report['formal_analysis']['query_results'])}\")\n    \n    print(f\"\\n  [VALIDATIONS PASSEES]\")\n    for check in cv['checks_passed']:\n        print(f\"    [+] {check}\")\n    \n    if cv['issues']:\n        print(f\"\\n  [PROBLEMES DETECTES]\")\n        for issue in cv['issues']:\n            print(f\"    [-] {issue}\")\n    \n    print(f\"\\n  [CONCLUSION]\")\n    if report['conclusion']['is_complete']:\n        conclusion_preview = str(report['conclusion']['summary'])[:200]\n        print(f\"    {conclusion_preview}...\")\n    else:\n        print(\"    (Non generee)\")\n    \n    print(\"\\n\" + \"=\"*70)\n    \n    return cv['validation_status']\n\n\n# === EXECUTION DE LA VALIDATION ===\nprint(\"\\n--- Generation du Rapport d'Analyse Validee ---\")\n\n# Chercher l'etat local_state defini par l'orchestration\nif 'local_state' in dir() and local_state is not None:\n    # Generate report\n    final_report = generate_validated_analysis_report(local_state)\n    \n    # Display summary\n    validation_status = display_validation_summary(final_report)\n    \n    # Export JSON\n    output_path = \"output/analysis_report.json\"\n    try:\n        import os\n        os.makedirs(\"output\", exist_ok=True)\n        with open(output_path, 'w', encoding='utf-8') as f:\n            json.dump(final_report, f, indent=2, ensure_ascii=False, default=str)\n        print(f\"\\nRapport JSON exporte vers: {output_path}\")\n    except Exception as e:\n        print(f\"Erreur export JSON: {e}\")\n    \n    # Afficher JSON complet\n    print(\"\\n--- RAPPORT JSON COMPLET ---\")\n    print(json.dumps(final_report, indent=2, ensure_ascii=False, default=str))\n    \n    # Final verdict\n    print(\"\\n--- VERDICT FINAL ---\")\n    if validation_status == \"COMPLETE_VALIDATED\":\n        print(\"[SUCCESS] ANALYSE RHETORIQUE VALIDEE COMPLETE\")\n        print(\"  Tous les criteres de validation sont satisfaits.\")\n    elif validation_status == \"PARTIAL_VALIDATED\":\n        print(\"[PARTIEL] Analyse partiellement validee\")\n        print(\"  Certaines etapes manquent pour une validation complete.\")\n    else:\n        print(f\"[{validation_status}] Analyse incomplete\")\n        print(\"  Verifiez les problemes detectes ci-dessus.\")\n\nelse:\n    print(\"[INFO] Etat d'analyse (local_state) non disponible.\")\n    print(\"  Executez d'abord les cellules precedentes pour lancer l'analyse.\")\n    print(\"  Ou l'analyse n'a pas ete executee (mode batch sans erreur?)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7abbf986",
   "metadata": {},
   "source": [
    "## 6. R√©sultats et Conclusion\n",
    "\n",
    "V√©rifiez les logs et l'√©tat final JSON affich√©s par l'ex√©cution pr√©c√©dente pour voir le r√©sultat de l'analyse collaborative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a37b89",
   "metadata": {},
   "source": [
    "## 7. üèÅ Pistes d'Am√©lioration Futures\n",
    "\n",
    "*(Repris de `3-orchestration-...ipynb`)*\n",
    "\n",
    "**Prochaines √©tapes possibles :**\n",
    "* **Activer & Finaliser PL:** Impl√©menter r√©ellement les appels JPype/Tweety dans `PropositionalLogicPlugin._internal_execute_query` et tester de bout en bout l'ex√©cution des requ√™tes logiques (parsing, query, interpr√©tation).\n",
    "* **Affiner Analyse Sophismes:** Am√©liorer les instructions de `InformalAnalysisAgent` pour une exploration plus fine de la taxonomie (gestion de la profondeur, choix des branches) ou l'attribution de sophismes sp√©cifiques bas√©e sur les d√©tails r√©cup√©r√©s (`get_fallacy_details`).\n",
    "* **Externaliser Prompts & Config:** D√©placer les prompts et configurations (ex: noms agents, constantes) hors du code Python vers des fichiers d√©di√©s (YAML, JSON, .env) pour une meilleure maintenabilit√©. Utiliser `kernel.import_plugin_from_directory`.\n",
    "* **Gestion Erreurs Agents:** Renforcer la capacit√© des agents √† g√©rer les erreurs retourn√©es par les outils (`FUNC_ERROR:`) et √† adapter leur plan (ex: demander une clarification, r√©essayer, passer √† autre chose).\n",
    "* **Nouveaux Agents/Capacit√©s:** Impl√©menter des agents pour d'autres logiques (FOL, Modale), d'autres t√¢ches (r√©sum√©, extraction d'entit√©s) ou d'autres outils (recherche web, base de donn√©es).\n",
    "* **√âtat RDF/KG:** Explorer le passage √† une structure d'√©tat plus riche et s√©mantiquement structur√©e en utilisant RDF/KG (avec `rdflib` ou une base de graphe) pour repr√©senter les arguments, relations, et m√©tadonn√©es de mani√®re plus formelle.\n",
    "* **Interface Utilisateur:** Cr√©er une interface (ex: avec Gradio, Streamlit) pour faciliter l'interaction et la visualisation de l'analyse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}