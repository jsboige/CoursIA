{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10996590",
   "metadata": {},
   "source": [
    "# üöÄ Analyse Rh√©torique Collaborative par Agents IA - Ex√©cuteur Principal\n",
    "\n",
    "**Objectif:** Ce notebook orchestre et ex√©cute une analyse rh√©torique multi-agents sur un texte donn√©. Il sert de point d'entr√©e principal pour lancer le processus.\n",
    "\n",
    "**Structure Modulaire:**\n",
    "1.  `Argument_Analysis_UI_configuration.ipynb` : G√®re l'interface utilisateur pour s√©lectionner/pr√©parer le texte √† analyser (incluant sources pr√©d√©finies, URL, fichier, texte direct, et extraction) et charge/sauvegarde la configuration des sources.\n",
    "2.  `Argument_Analysis_Agentic-0-init.ipynb`: Configuration initiale (d√©pendances, LLM, JVM), d√©finition de l'√©tat partag√© (`RhetoricalAnalysisState`) et du gestionnaire d'√©tat (`StateManagerPlugin`).\n",
    "3.  `Argument_Analysis_Agentic-1-informal_agent.ipynb`: D√©finition de l'`InformalAnalysisAgent`.\n",
    "4.  `Argument_Analysis_Agentic-2-pl_agent.ipynb`: D√©finition du `PropositionalLogicAgent`.\n",
    "5.  `Argument_Analysis_Agentic-3-orchestration.ipynb`: D√©finition des strat√©gies d'orchestration et de la fonction principale `run_analysis_conversation`.\n",
    "\n",
    "**Pr√©requis:**\n",
    "* Un fichier `.env` √† la racine contenant les cl√©s API, configurations LLM, et la cl√© de chiffrement `TEXT_CONFIG_KEY`.\n",
    "* Un environnement Java Development Kit (JDK >= 11) correctement install√© et configur√© (`JAVA_HOME`).\n",
    "* Les d√©pendances Python install√©es (`ipywidgets`, `requests`, `jupyter-ui-poll`, `python-dotenv`, `semantic-kernel`, `pandas`, `jpype1`, `cryptography`).\n",
    "* Les JARs Tweety plac√©s dans le dossier `libs/`.\n",
    "* Le fichier `extract_sources.json.gz.enc` (s'il existe d√©j√†) contenant les d√©finitions des sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763bbbf",
   "metadata": {},
   "source": [
    "## 1. Chargement de l'Environnement\n",
    "\n",
    "Chargement des variables depuis le fichier `.env` (cl√©s API, cl√© de chiffrement, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c82597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les variables d'environnement\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "loaded_env = load_dotenv(find_dotenv(), override=True)\n",
    "print(f\".env charg√©: {loaded_env}\") # Affiche True si le .env a √©t√© trouv√© et charg√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41046be8",
   "metadata": {},
   "source": [
    "## 2. Chargement de l'Interface Utilisateur\n",
    "\n",
    "Ex√©cution du notebook `UI_Configuration.ipynb` pour d√©finir la fonction `configure_analysis_task()`. C'est ce notebook qui contient d√©sormais toute la logique de l'interface graphique, du cache fichier et de la gestion de la configuration chiffr√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode batch contr√¥l√© par variable d'environnement\n",
    "# Si BATCH_MODE=true dans .env, on skip l'UI interactive (widgets bloquants)\n",
    "import os\n",
    "BATCH_MODE = os.getenv(\"BATCH_MODE\", \"false\").lower() in (\"true\", \"1\", \"yes\")\n",
    "\n",
    "if BATCH_MODE:\n",
    "    print(\"Mode BATCH detecte (BATCH_MODE=true dans .env)\")\n",
    "    print(\"   -> Skip du chargement UI_configuration.ipynb (widgets non compatibles)\")\n",
    "    print(\"   -> Le texte sera fourni directement dans la cellule suivante\")\n",
    "else:\n",
    "    # Ex√©cuter le notebook UI pour d√©finir la fonction configure_analysis_task\n",
    "    # Assurez-vous que le fichier UI_Configuration.ipynb est dans le m√™me r√©pertoire\n",
    "    print(\"Ex√©cution de Argument_Analysis_UI_configuration.ipynb...\")\n",
    "    %run ./Argument_Analysis_UI_configuration.ipynb\n",
    "    print(\"Ex√©cution de Argument_Analysis_UI_configuration.ipynb termin√©e.\")\n",
    "\n",
    "    # V√©rification que la fonction est bien d√©finie apr√®s l'ex√©cution\n",
    "    if 'configure_analysis_task' not in locals():\n",
    "        print(\"ERREUR CRITIQUE : La fonction configure_analysis_task n'a pas √©t√© d√©finie par UI_Configuration.ipynb !\")\n",
    "    else:\n",
    "        print(\"Fonction configure_analysis_task trouv√©e.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438236c",
   "metadata": {},
   "source": [
    "## 3. Configuration de la T√¢che et R√©cup√©ration du Texte\n",
    "\n",
    "Appel de la fonction `configure_analysis_task()` d√©finie dans le notebook UI. Cela affichera l'interface utilisateur. S√©lectionnez votre source, pr√©parez le texte, puis cliquez sur **\"Lancer l'Analyse\"**. Le texte pr√©par√© sera retourn√© et stock√© pour l'√©tape suivante. La cellule attendra la fin de votre interaction avec l'UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du texte pour l'analyse\n",
    "# En mode BATCH : utilise BATCH_TEXT (variable d'env) ou le texte d'exemple\n",
    "# En mode interactif : appelle configure_analysis_task() (si disponible)\n",
    "\n",
    "texte_pour_analyse = None\n",
    "\n",
    "# Texte d'exemple enrichi pour le mode batch - contient des arguments complexes et des sophismes\n",
    "TEXTE_EXEMPLE_BATCH = \"\"\"Le debat sur la transition energetique en France revele des enjeux majeurs pour notre avenir.\n",
    "\n",
    "ARGUMENTS EN FAVEUR DES ENERGIES RENOUVELABLES:\n",
    "Les energies renouvelables sont essentielles pour lutter contre le changement climatique. La France s'est engagee a reduire ses emissions de CO2 de 40% d'ici 2030, ce qui necessite un investissement massif dans le solaire et l'eolien. D'ailleurs, l'Allemagne a deja prouve que c'etait possible en produisant 46% de son electricite a partir de sources renouvelables en 2023.\n",
    "\n",
    "De plus, les energies renouvelables creent des emplois locaux non delocalisables. Selon l'ADEME, le secteur emploie deja plus de 150 000 personnes en France et pourrait en creer 500 000 supplementaires d'ici 2050. Quiconque s'oppose a cette transition est donc contre la creation d'emplois.\n",
    "\n",
    "ARGUMENTS CONTRE LE DEVELOPPEMENT MASSIF DES RENOUVELABLES:\n",
    "Cependant, les ecologistes veulent nous ramener a l'age de pierre en supprimant le nucleaire, qui fournit pourtant 70% de notre electricite. Sans le nucleaire, nous serions obliges de choisir entre des coupures d'electricite massives ou une dependance totale au gaz russe.\n",
    "\n",
    "Le cout de la transition est exorbitant. Tout le monde sait que les eoliennes sont inefficaces car elles ne tournent que 25% du temps. Mon voisin Jean-Pierre, qui est ingenieur a EDF, m'a dit que les renouvelables ne pourront jamais remplacer le nucleaire. C'est un expert, donc il a forcemment raison.\n",
    "\n",
    "De plus, les panneaux solaires sont fabriques en Chine avec du charbon, ce qui annule completement leur benefice ecologique. Donc investir dans le solaire revient a financer la pollution chinoise.\n",
    "\n",
    "CONCLUSION:\n",
    "Il faut arreter de debattre et agir. Soit on accepte une transition energetique complete vers 100% de renouvelables d'ici 2040, soit on condamne nos enfants a vivre sur une planete inhabitable. Des milliers de scientifiques ont signe une petition pour le climat, ce qui prouve definitivement que nous avons raison de promouvoir les energies vertes. Les climatosceptiques sont finances par les lobbies petroliers et ne meritent pas qu'on ecoute leurs arguments.\n",
    "\n",
    "En conclusion, bien que certains arguments des deux cotes aient du merite, la question necessite une analyse nuancee des compromis entre independance energetique, impact environnemental, cout economique et faisabilite technique.\"\"\"\n",
    "\n",
    "if BATCH_MODE:\n",
    "    # === MODE BATCH ===\n",
    "    print(\"Mode BATCH - Configuration automatique du texte\")\n",
    "    \n",
    "    # Priorite 1: Variable d'environnement BATCH_TEXT\n",
    "    batch_text_env = os.getenv(\"BATCH_TEXT\", \"\")\n",
    "    if batch_text_env:\n",
    "        texte_pour_analyse = batch_text_env\n",
    "        print(f\"Texte charge depuis BATCH_TEXT ({len(texte_pour_analyse)} caracteres)\")\n",
    "    else:\n",
    "        # Priorite 2: Texte d'exemple par defaut\n",
    "        texte_pour_analyse = TEXTE_EXEMPLE_BATCH\n",
    "        print(f\"Texte d'exemple enrichi utilise ({len(texte_pour_analyse)} caracteres)\")\n",
    "    \n",
    "    print(f\"\\nExtrait du texte:\\n{texte_pour_analyse[:200]}...\")\n",
    "\n",
    "else:\n",
    "    # === MODE INTERACTIF ===\n",
    "    print(\"Mode INTERACTIF - Lancement de l'interface de configuration\")\n",
    "    \n",
    "    if 'configure_analysis_task' in locals():\n",
    "        try:\n",
    "            texte_pour_analyse = configure_analysis_task()\n",
    "            print(f\"Texte recupere via l'interface ({len(texte_pour_analyse) if texte_pour_analyse else 0} caracteres)\")\n",
    "        except Exception as e_ui:\n",
    "            print(f\"Erreur lors de la configuration UI : {e_ui}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"Fonction configure_analysis_task non disponible - verifiez le chargement de UI_configuration.ipynb\")\n",
    "\n",
    "# Verification finale\n",
    "if not texte_pour_analyse:\n",
    "    print(\"\\nAucun texte prepare. L'analyse ne peut pas continuer.\")\n",
    "else:\n",
    "    print(f\"\\nTexte pret pour l'analyse (longueur: {len(texte_pour_analyse)}). Passage au chargement des agents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183031e3",
   "metadata": {},
   "source": [
    "## 4. Chargement des D√©finitions des Agents et de l'Orchestration\n",
    "\n",
    "Maintenant que le texte est pr√™t (si l'√©tape pr√©c√©dente a r√©ussi), nous chargeons les d√©finitions des agents, des plugins, des strat√©gies et de la fonction d'orchestration `run_analysis_conversation` en ex√©cutant les notebooks enfants d√©di√©s.\n",
    "\n",
    "**Rappel:** Le notebook `Argument_Analysis_Agentic-0-init.ipynb` **ne doit plus d√©finir** la variable `raw_text_input` et le notebook `Argument_Analysis_Agentic-3-orchestration.ipynb` **doit d√©finir** `run_analysis_conversation(texte_a_analyser)` acceptant un argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cuter les notebooks enfants pour charger les d√©finitions\n",
    "# Seulement si un texte a √©t√© pr√©par√© avec succ√®s\n",
    "if 'texte_pour_analyse' in locals() and texte_pour_analyse:\n",
    "    print(\"\\nChargement des d√©finitions des agents et de l'orchestration...\")\n",
    "    try:\n",
    "        %run ./Argument_Analysis_Agentic-0-init.ipynb\n",
    "        %run ./Argument_Analysis_Agentic-1-informal_agent.ipynb\n",
    "        %run ./Argument_Analysis_Agentic-2-pl_agent.ipynb\n",
    "        %run ./Argument_Analysis_Agentic-3-orchestration.ipynb  # D√©finit run_analysis_conversation(texte_a_analyser)\n",
    "        print(\"‚úÖ D√©finitions charg√©es.\")\n",
    "        # V√©rifier que la fonction d'orchestration est charg√©e\n",
    "        if 'run_analysis_conversation' not in locals():\n",
    "             print(\"‚ùå ERREUR CRITIQUE: La fonction run_analysis_conversation n'a pas √©t√© d√©finie apr√®s l'ex√©cution des notebooks agents!\")\n",
    "             # raise NameError(\"run_analysis_conversation non d√©finie\")\n",
    "    except Exception as e_run:\n",
    "        print(f\"\\n‚ùå Une erreur est survenue lors de l'ex√©cution des notebooks enfants : {e_run}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Emp√™cher la suite si le chargement √©choue\n",
    "        texte_pour_analyse = None\n",
    "else:\n",
    "    print(\"\\nSkipping agent definition loading because no text was prepared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60ae64",
   "metadata": {},
   "source": [
    "## 5. Ex√©cution de l'Analyse Collaborative\n",
    "\n",
    "Si toutes les √©tapes pr√©c√©dentes se sont bien d√©roul√©es et que nous avons un texte √† analyser, cette cellule lance l'analyse collaborative.\n",
    "\n",
    "*Note :* `nest_asyncio` est appliqu√© pour la compatibilit√© avec l'environnement asynchrone de Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Lancer seulement si on a obtenu un texte valide ET que les d√©finitions sont charg√©es\n",
    "if 'texte_pour_analyse' in locals() and texte_pour_analyse and 'run_analysis_conversation' in locals():\n",
    "    print(\"\\nüöÄ Lancement de l'ex√©cution asynchrone de l'analyse...\")\n",
    "    nest_asyncio.apply()\n",
    "    try:\n",
    "        # Passer le texte pr√©par√©\n",
    "        local_state = await run_analysis_conversation(texte_pour_analyse)\n",
    "        print(\"\\nüèÅ Analyse termin√©e.\")\n",
    "    except Exception as e_analysis:\n",
    "        print(f\"\\n‚ùå Une erreur est survenue pendant l'ex√©cution de l'analyse : {e_analysis}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "elif 'texte_pour_analyse' not in locals() or not texte_pour_analyse:\n",
    "    print(\"\\n Analyse non lanc√©e : aucun texte n'a √©t√© pr√©par√© ou une erreur est survenue avant.\")\n",
    "else: # Implique que run_analysis_conversation n'a pas √©t√© charg√©e\n",
    "     print(\"\\n Analyse non lanc√©e : la fonction d'orchestration n'a pas pu √™tre charg√©e.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mf35rz46kvk",
   "metadata": {},
   "source": [
    "## 5bis. Rapport de Validation de l'Analyse\n",
    "\n",
    "Cette cellule genere un rapport structure validant la completude de l'analyse rhetorique.\n",
    "Elle verifie les criteres suivants:\n",
    "- Arguments identifies\n",
    "- Sophismes analyses\n",
    "- Belief Sets PL crees\n",
    "- Requetes logiques executees\n",
    "- Conclusion generee\n",
    "\n",
    "Le rapport est exporte en JSON pour utilisation ulterieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pug0jcknsij",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELLULE DE VALIDATION FINALE ===\n",
    "# Genere un rapport JSON structure avec cross-validation\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "def generate_validated_analysis_report(state) -> Dict[str, Any]:\n",
    "    \"\"\"Genere rapport JSON structure avec cross-validation.\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"version\": \"2.0-validated\",\n",
    "            \"text_length\": len(state.raw_text) if state.raw_text else 0,\n",
    "            \"text_snippet\": (state.raw_text[:150] + \"...\") if state.raw_text and len(state.raw_text) > 150 else (state.raw_text or \"\")\n",
    "        },\n",
    "        \"informal_analysis\": {\n",
    "            \"arguments\": [],\n",
    "            \"fallacies\": [],\n",
    "            \"taxonomy_families_used\": set()\n",
    "        },\n",
    "        \"formal_analysis\": {\n",
    "            \"belief_sets\": [],\n",
    "            \"query_results\": [],\n",
    "            \"consistency_checked\": False\n",
    "        },\n",
    "        \"cross_validation\": {\n",
    "            \"validation_status\": \"INCOMPLETE\",\n",
    "            \"confidence_score\": 0.0,\n",
    "            \"checks_passed\": [],\n",
    "            \"issues\": []\n",
    "        },\n",
    "        \"conclusion\": {\n",
    "            \"summary\": state.final_conclusion if hasattr(state, 'final_conclusion') else None,\n",
    "            \"is_complete\": hasattr(state, 'final_conclusion') and state.final_conclusion is not None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Populate arguments\n",
    "    if hasattr(state, 'identified_arguments'):\n",
    "        for arg_id, arg_desc in state.identified_arguments.items():\n",
    "            has_fallacy = False\n",
    "            if hasattr(state, 'identified_fallacies'):\n",
    "                has_fallacy = any(\n",
    "                    f.get('target_argument_id') == arg_id\n",
    "                    for f in state.identified_fallacies.values()\n",
    "                )\n",
    "            report[\"informal_analysis\"][\"arguments\"].append({\n",
    "                \"id\": arg_id, \"description\": str(arg_desc)[:200], \"has_fallacy\": has_fallacy\n",
    "            })\n",
    "    \n",
    "    # Populate fallacies\n",
    "    if hasattr(state, 'identified_fallacies'):\n",
    "        for f_id, f_data in state.identified_fallacies.items():\n",
    "            fallacy_type = f_data.get('type', 'Unknown') if isinstance(f_data, dict) else str(f_data)\n",
    "            report[\"informal_analysis\"][\"fallacies\"].append({\n",
    "                \"id\": f_id,\n",
    "                \"type\": fallacy_type,\n",
    "                \"justification\": f_data.get('justification', '') if isinstance(f_data, dict) else '',\n",
    "                \"target_id\": f_data.get('target_argument_id') if isinstance(f_data, dict) else None,\n",
    "                \"severity\": \"HIGH\" if any(kw in str(fallacy_type).lower() for kw in ['manipulation', 'tromperie']) else \"MEDIUM\"\n",
    "            })\n",
    "            # Track taxonomy families\n",
    "            if isinstance(fallacy_type, str) and '/' in fallacy_type:\n",
    "                report[\"informal_analysis\"][\"taxonomy_families_used\"].add(fallacy_type.split('/')[0])\n",
    "    \n",
    "    report[\"informal_analysis\"][\"taxonomy_families_used\"] = list(report[\"informal_analysis\"][\"taxonomy_families_used\"])\n",
    "    \n",
    "    # Populate belief sets\n",
    "    if hasattr(state, 'belief_sets'):\n",
    "        for bs_id, bs_data in state.belief_sets.items():\n",
    "            content = bs_data.get('content', '') if isinstance(bs_data, dict) else str(bs_data)\n",
    "            report[\"formal_analysis\"][\"belief_sets\"].append({\n",
    "                \"id\": bs_id,\n",
    "                \"logic_type\": bs_data.get('logic_type', 'PL') if isinstance(bs_data, dict) else 'PL',\n",
    "                \"formula_count\": content.count('\\n') + 1 if content else 0,\n",
    "                \"is_consistent\": \"NOT_CHECKED\"\n",
    "            })\n",
    "    \n",
    "    # Populate query results\n",
    "    if hasattr(state, 'query_log'):\n",
    "        for qlog in state.query_log:\n",
    "            raw_result = qlog.get('raw_result', '') if isinstance(qlog, dict) else ''\n",
    "            status = \"UNKNOWN\"\n",
    "            if \"ACCEPTED\" in str(raw_result): status = \"ACCEPTED\"\n",
    "            elif \"REJECTED\" in str(raw_result): status = \"REJECTED\"\n",
    "            elif \"FUNC_ERROR\" in str(raw_result): status = \"ERROR\"\n",
    "            \n",
    "            report[\"formal_analysis\"][\"query_results\"].append({\n",
    "                \"log_id\": qlog.get('log_id', '') if isinstance(qlog, dict) else '',\n",
    "                \"belief_set_id\": qlog.get('belief_set_id', '') if isinstance(qlog, dict) else '',\n",
    "                \"query\": qlog.get('query', '') if isinstance(qlog, dict) else '',\n",
    "                \"status\": status\n",
    "            })\n",
    "    \n",
    "    # === CROSS-VALIDATION LOGIC ===\n",
    "    checks = []\n",
    "    issues = []\n",
    "    \n",
    "    # Check 1: Arguments identified\n",
    "    if len(report[\"informal_analysis\"][\"arguments\"]) > 0:\n",
    "        checks.append(\"ARGUMENTS_IDENTIFIED\")\n",
    "    else:\n",
    "        issues.append(\"Aucun argument identifie\")\n",
    "    \n",
    "    # Check 2: Fallacy analysis attempted\n",
    "    if len(report[\"informal_analysis\"][\"fallacies\"]) > 0:\n",
    "        checks.append(\"FALLACIES_ANALYZED\")\n",
    "    elif hasattr(state, 'answers') and any(\"sophisme\" in str(v).lower() for v in state.answers.values()):\n",
    "        checks.append(\"FALLACY_ANALYSIS_ATTEMPTED\")\n",
    "    else:\n",
    "        issues.append(\"Analyse sophismes non effectuee\")\n",
    "    \n",
    "    # Check 3: Formal logic translation\n",
    "    if len(report[\"formal_analysis\"][\"belief_sets\"]) > 0:\n",
    "        checks.append(\"BELIEF_SET_CREATED\")\n",
    "    else:\n",
    "        issues.append(\"Aucun Belief Set PL cree\")\n",
    "    \n",
    "    # Check 4: Queries executed\n",
    "    if len(report[\"formal_analysis\"][\"query_results\"]) > 0:\n",
    "        checks.append(\"QUERIES_EXECUTED\")\n",
    "        accepted = sum(1 for q in report[\"formal_analysis\"][\"query_results\"] if q[\"status\"] == \"ACCEPTED\")\n",
    "        rejected = sum(1 for q in report[\"formal_analysis\"][\"query_results\"] if q[\"status\"] == \"REJECTED\")\n",
    "        if accepted > 0 or rejected > 0:\n",
    "            checks.append(\"QUERIES_MEANINGFUL\")\n",
    "    else:\n",
    "        issues.append(\"Aucune requete PL executee\")\n",
    "    \n",
    "    # Check 5: Conclusion generated\n",
    "    if report[\"conclusion\"][\"is_complete\"]:\n",
    "        checks.append(\"CONCLUSION_GENERATED\")\n",
    "    else:\n",
    "        issues.append(\"Conclusion finale non generee\")\n",
    "    \n",
    "    # Calculate confidence score\n",
    "    max_checks = 6  # ARGUMENTS, FALLACIES, BELIEF_SET, QUERIES, QUERIES_MEANINGFUL, CONCLUSION\n",
    "    confidence = len(checks) / max_checks\n",
    "    report[\"cross_validation\"][\"confidence_score\"] = round(confidence, 2)\n",
    "    report[\"cross_validation\"][\"checks_passed\"] = checks\n",
    "    report[\"cross_validation\"][\"issues\"] = issues\n",
    "    \n",
    "    # Determine validation status\n",
    "    if confidence >= 0.8:\n",
    "        report[\"cross_validation\"][\"validation_status\"] = \"COMPLETE_VALIDATED\"\n",
    "    elif confidence >= 0.5:\n",
    "        report[\"cross_validation\"][\"validation_status\"] = \"PARTIAL_VALIDATED\"\n",
    "    elif confidence >= 0.3:\n",
    "        report[\"cross_validation\"][\"validation_status\"] = \"MINIMAL\"\n",
    "    else:\n",
    "        report[\"cross_validation\"][\"validation_status\"] = \"INCOMPLETE\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "def display_validation_summary(report: Dict[str, Any]) -> str:\n",
    "    \"\"\"Affiche resume lisible du rapport de validation.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"          RAPPORT D'ANALYSE RHETORIQUE VALIDEE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    cv = report[\"cross_validation\"]\n",
    "    status_symbols = {\n",
    "        \"COMPLETE_VALIDATED\": \"[OK]\",\n",
    "        \"PARTIAL_VALIDATED\": \"[PARTIEL]\",\n",
    "        \"MINIMAL\": \"[MINIMAL]\",\n",
    "        \"INCOMPLETE\": \"[INCOMPLET]\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  STATUT: {status_symbols.get(cv['validation_status'], '?')} {cv['validation_status']}\")\n",
    "    print(f\"  CONFIANCE: {cv['confidence_score']*100:.0f}%\")\n",
    "    \n",
    "    print(f\"\\n  [ANALYSE INFORMELLE]\")\n",
    "    print(f\"    Arguments: {len(report['informal_analysis']['arguments'])}\")\n",
    "    print(f\"    Sophismes: {len(report['informal_analysis']['fallacies'])}\")\n",
    "    \n",
    "    print(f\"\\n  [ANALYSE FORMELLE]\")\n",
    "    print(f\"    Belief Sets: {len(report['formal_analysis']['belief_sets'])}\")\n",
    "    print(f\"    Requetes: {len(report['formal_analysis']['query_results'])}\")\n",
    "    \n",
    "    print(f\"\\n  [VALIDATIONS PASSEES]\")\n",
    "    for check in cv['checks_passed']:\n",
    "        print(f\"    [+] {check}\")\n",
    "    \n",
    "    if cv['issues']:\n",
    "        print(f\"\\n  [PROBLEMES DETECTES]\")\n",
    "        for issue in cv['issues']:\n",
    "            print(f\"    [-] {issue}\")\n",
    "    \n",
    "    print(f\"\\n  [CONCLUSION]\")\n",
    "    if report['conclusion']['is_complete']:\n",
    "        conclusion_preview = str(report['conclusion']['summary'])[:200]\n",
    "        print(f\"    {conclusion_preview}...\")\n",
    "    else:\n",
    "        print(\"    (Non generee)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    return cv['validation_status']\n",
    "\n",
    "\n",
    "# === EXECUTION DE LA VALIDATION ===\n",
    "print(\"\\n--- Generation du Rapport d'Analyse Validee ---\")\n",
    "\n",
    "# Chercher l'etat local_state defini par l'orchestration\n",
    "if 'local_state' in dir() and local_state is not None:\n",
    "    # Generate report\n",
    "    final_report = generate_validated_analysis_report(local_state)\n",
    "    \n",
    "    # Display summary\n",
    "    validation_status = display_validation_summary(final_report)\n",
    "    \n",
    "    # Export JSON\n",
    "    output_path = \"output/analysis_report.json\"\n",
    "    try:\n",
    "        import os\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_report, f, indent=2, ensure_ascii=False, default=str)\n",
    "        print(f\"\\nRapport JSON exporte vers: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur export JSON: {e}\")\n",
    "    \n",
    "    # Afficher JSON complet\n",
    "    print(\"\\n--- RAPPORT JSON COMPLET ---\")\n",
    "    print(json.dumps(final_report, indent=2, ensure_ascii=False, default=str))\n",
    "    \n",
    "    # Final verdict\n",
    "    print(\"\\n--- VERDICT FINAL ---\")\n",
    "    if validation_status == \"COMPLETE_VALIDATED\":\n",
    "        print(\"[SUCCESS] ANALYSE RHETORIQUE VALIDEE COMPLETE\")\n",
    "        print(\"  Tous les criteres de validation sont satisfaits.\")\n",
    "    elif validation_status == \"PARTIAL_VALIDATED\":\n",
    "        print(\"[PARTIEL] Analyse partiellement validee\")\n",
    "        print(\"  Certaines etapes manquent pour une validation complete.\")\n",
    "    else:\n",
    "        print(f\"[{validation_status}] Analyse incomplete\")\n",
    "        print(\"  Verifiez les problemes detectes ci-dessus.\")\n",
    "\n",
    "else:\n",
    "    print(\"[INFO] Etat d'analyse (local_state) non disponible.\")\n",
    "    print(\"  Executez d'abord les cellules precedentes pour lancer l'analyse.\")\n",
    "    print(\"  Ou l'analyse n'a pas ete executee (mode batch sans erreur?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abbf986",
   "metadata": {},
   "source": [
    "## 6. R√©sultats et Conclusion\n",
    "\n",
    "V√©rifiez les logs et l'√©tat final JSON affich√©s par l'ex√©cution pr√©c√©dente pour voir le r√©sultat de l'analyse collaborative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a37b89",
   "metadata": {},
   "source": [
    "## 7. üèÅ Pistes d'Am√©lioration Futures\n",
    "\n",
    "*(Repris de `3-orchestration-...ipynb`)*\n",
    "\n",
    "**Prochaines √©tapes possibles :**\n",
    "* **Activer & Finaliser PL:** Impl√©menter r√©ellement les appels JPype/Tweety dans `PropositionalLogicPlugin._internal_execute_query` et tester de bout en bout l'ex√©cution des requ√™tes logiques (parsing, query, interpr√©tation).\n",
    "* **Affiner Analyse Sophismes:** Am√©liorer les instructions de `InformalAnalysisAgent` pour une exploration plus fine de la taxonomie (gestion de la profondeur, choix des branches) ou l'attribution de sophismes sp√©cifiques bas√©e sur les d√©tails r√©cup√©r√©s (`get_fallacy_details`).\n",
    "* **Externaliser Prompts & Config:** D√©placer les prompts et configurations (ex: noms agents, constantes) hors du code Python vers des fichiers d√©di√©s (YAML, JSON, .env) pour une meilleure maintenabilit√©. Utiliser `kernel.import_plugin_from_directory`.\n",
    "* **Gestion Erreurs Agents:** Renforcer la capacit√© des agents √† g√©rer les erreurs retourn√©es par les outils (`FUNC_ERROR:`) et √† adapter leur plan (ex: demander une clarification, r√©essayer, passer √† autre chose).\n",
    "* **Nouveaux Agents/Capacit√©s:** Impl√©menter des agents pour d'autres logiques (FOL, Modale), d'autres t√¢ches (r√©sum√©, extraction d'entit√©s) ou d'autres outils (recherche web, base de donn√©es).\n",
    "* **√âtat RDF/KG:** Explorer le passage √† une structure d'√©tat plus riche et s√©mantiquement structur√©e en utilisant RDF/KG (avec `rdflib` ou une base de graphe) pour repr√©senter les arguments, relations, et m√©tadonn√©es de mani√®re plus formelle.\n",
    "* **Interface Utilisateur:** Cr√©er une interface (ex: avec Gradio, Streamlit) pour faciliter l'interaction et la visualisation de l'analyse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
