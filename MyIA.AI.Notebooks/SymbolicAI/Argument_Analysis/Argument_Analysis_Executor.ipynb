{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10996590",
   "metadata": {},
   "source": [
    "# üöÄ Analyse Rh√©torique Collaborative par Agents IA - Ex√©cuteur Principal\n",
    "\n",
    "**Objectif:** Ce notebook orchestre et ex√©cute une analyse rh√©torique multi-agents sur un texte donn√©. Il sert de point d'entr√©e principal pour lancer le processus.\n",
    "\n",
    "**Structure Modulaire:**\n",
    "1.  `Argument_Analysis_UI_configuration.ipynb` : G√®re l'interface utilisateur pour s√©lectionner/pr√©parer le texte √† analyser (incluant sources pr√©d√©finies, URL, fichier, texte direct, et extraction) et charge/sauvegarde la configuration des sources.\n",
    "2.  `Argument_Analysis_Agentic-0-init.ipynb`: Configuration initiale (d√©pendances, LLM, JVM), d√©finition de l'√©tat partag√© (`RhetoricalAnalysisState`) et du gestionnaire d'√©tat (`StateManagerPlugin`).\n",
    "3.  `Argument_Analysis_Agentic-1-informal_agent.ipynb`: D√©finition de l'`InformalAnalysisAgent`.\n",
    "4.  `Argument_Analysis_Agentic-2-pl_agent.ipynb`: D√©finition du `PropositionalLogicAgent`.\n",
    "5.  `Argument_Analysis_Agentic-3-orchestration.ipynb`: D√©finition des strat√©gies d'orchestration et de la fonction principale `run_analysis_conversation`.\n",
    "\n",
    "**Pr√©requis:**\n",
    "* Un fichier `.env` √† la racine contenant les cl√©s API, configurations LLM, et la cl√© de chiffrement `TEXT_CONFIG_KEY`.\n",
    "* Un environnement Java Development Kit (JDK >= 11) correctement install√© et configur√© (`JAVA_HOME`).\n",
    "* Les d√©pendances Python install√©es (`ipywidgets`, `requests`, `jupyter-ui-poll`, `python-dotenv`, `semantic-kernel`, `pandas`, `jpype1`, `cryptography`).\n",
    "* Les JARs Tweety plac√©s dans le dossier `libs/`.\n",
    "* Le fichier `extract_sources.json.gz.enc` (s'il existe d√©j√†) contenant les d√©finitions des sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63m99jijcx4",
   "source": "## Pr√©sentation g√©n√©rale du syst√®me\n\n### Objectifs p√©dagogiques\n\nCe notebook illustre une architecture d'**agents collaboratifs multi-modaux** pour l'analyse rh√©torique automatis√©e. Les √©tudiants d√©couvriront:\n\n1. **Orchestration d'agents IA** (Semantic Kernel)\n2. **Analyse hybride**: LLM (compr√©hension naturelle) + Logique formelle (preuve)\n3. **√âtat partag√©** pour communication inter-agents\n4. **Validation structur√©e** avec m√©triques de confiance\n\n### Architecture du syst√®me\n\nLe syst√®me combine deux paradigmes d'IA compl√©mentaires:\n\n| Composant | Technologie | R√¥le |\n|-----------|-------------|------|\n| **InformalAnalysisAgent** | LLM (GPT-4/Claude) | Comprend langage naturel, identifie arguments/sophismes |\n| **PropositionalLogicAgent** | Tweety (biblioth√®que Java) | Formalise en logique PL, prouve coh√©rence/implications |\n| **StateManager** | Dataclass Python | M√©moire partag√©e entre agents |\n| **Orchestration** | Semantic Kernel | Coordination des appels d'agents |\n\n### Workflow en 3 phases\n\n```\nPhase 1: ANALYSE INFORMELLE\n‚îú‚îÄ D√©tection arguments (pr√©misses, conclusions)\n‚îú‚îÄ Identification sophismes (taxonomie hi√©rarchique)\n‚îî‚îÄ Stockage √©tat (JSON structur√©)\n\nPhase 2: FORMALISATION LOGIQUE\n‚îú‚îÄ Traduction propositions en PL\n‚îú‚îÄ Cr√©ation Belief Sets (Tweety)\n‚îú‚îÄ Requ√™tes logiques (coh√©rence, implication)\n‚îî‚îÄ Stockage preuves formelles\n\nPhase 3: VALIDATION & SYNTH√àSE\n‚îú‚îÄ Cross-validation (6 crit√®res)\n‚îú‚îÄ Calcul score de confiance\n‚îú‚îÄ G√©n√©ration conclusion synth√©tique\n‚îî‚îÄ Export rapport JSON\n```\n\n> **Cas d'usage r√©el**: Ce syst√®me peut analyser des d√©bats politiques, d√©tecter la manipulation rh√©torique, ou servir d'outil p√©dagogique pour l'enseignement de la pens√©e critique.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "6763bbbf",
   "metadata": {},
   "source": "## 1. Chargement de l'Environnement\n\nChargement des variables depuis le fichier `.env` (cl√©s API, cl√© de chiffrement, etc.).\n\n### R√¥le du fichier .env\n\nLe fichier `.env` centralise toutes les configurations sensibles et param√®tres du syst√®me:\n\n| Variable | Fonction |\n|----------|----------|\n| `OPENAI_API_KEY` | Authentification API OpenAI pour les LLMs |\n| `ANTHROPIC_API_KEY` | Authentification API Anthropic (optionnel) |\n| `TEXT_CONFIG_KEY` | Cl√© de chiffrement pour la config s√©curis√©e |\n| `BATCH_MODE` | Active le mode non-interactif pour tests automatis√©s |\n| `BATCH_TEXT` | Texte personnalis√© pour mode batch (optionnel) |\n\n> **Note de s√©curit√©**: Le fichier `.env` ne doit jamais √™tre versionn√© avec Git. Utilisez `.env.example` comme template."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c82597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les variables d'environnement\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "loaded_env = load_dotenv(find_dotenv(), override=True)\n",
    "print(f\".env charg√©: {loaded_env}\") # Affiche True si le .env a √©t√© trouv√© et charg√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6olkjrtk9p",
   "source": "### Interpr√©tation du r√©sultat\n\n**Sortie attendue**: `.env charg√©: True`\n\nSi vous obtenez `False`, cela signifie:\n- Le fichier `.env` n'existe pas dans le r√©pertoire courant ou ses parents\n- Les variables d'environnement doivent √™tre d√©finies manuellement\n\n**Actions correctives**:\n1. Copier `.env.example` vers `.env`\n2. Remplir les valeurs manquantes (cl√©s API)\n3. Relancer cette cellule",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "b76958om00a",
   "source": "### V√©rification des d√©pendances\n\nAvant de continuer, assurez-vous que les d√©pendances suivantes sont satisfaites:\n\n**D√©pendances Python**:\n```bash\npip install python-dotenv semantic-kernel pandas jpype1 cryptography\npip install ipywidgets requests jupyter-ui-poll  # Pour mode interactif\n```\n\n**D√©pendances syst√®me**:\n- **JDK 11+** (pour Tweety via JPype): `JAVA_HOME` doit √™tre configur√©\n- **Biblioth√®que Tweety**: JARs dans `libs/` (t√©l√©chargement automatique via `Tweety-1-Setup.ipynb`)\n\n**Fichiers requis**:\n| Fichier | R√¥le | Cr√©ation |\n|---------|------|----------|\n| `.env` | Variables d'environnement (cl√©s API) | Copier depuis `.env.example` |\n| `libs/*.jar` | Biblioth√®que Tweety Java | T√©l√©chargement auto |\n| `data/logical_fallacies_taxonomy.json` | Taxonomie sophismes | Fourni |\n\n> **Astuce**: Si JPype √©choue √† s'initialiser, le syst√®me basculera en mode \"fallback\" (sans logique formelle). L'analyse informelle fonctionnera toujours.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "41046be8",
   "metadata": {},
   "source": [
    "## 2. Chargement de l'Interface Utilisateur\n",
    "\n",
    "Ex√©cution du notebook `UI_Configuration.ipynb` pour d√©finir la fonction `configure_analysis_task()`. C'est ce notebook qui contient d√©sormais toute la logique de l'interface graphique, du cache fichier et de la gestion de la configuration chiffr√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode batch contr√¥l√© par variable d'environnement\n",
    "# Si BATCH_MODE=true dans .env, on skip l'UI interactive (widgets bloquants)\n",
    "import os\n",
    "BATCH_MODE = os.getenv(\"BATCH_MODE\", \"false\").lower() in (\"true\", \"1\", \"yes\")\n",
    "\n",
    "if BATCH_MODE:\n",
    "    print(\"Mode BATCH detecte (BATCH_MODE=true dans .env)\")\n",
    "    print(\"   -> Skip du chargement UI_configuration.ipynb (widgets non compatibles)\")\n",
    "    print(\"   -> Le texte sera fourni directement dans la cellule suivante\")\n",
    "else:\n",
    "    # Ex√©cuter le notebook UI pour d√©finir la fonction configure_analysis_task\n",
    "    # Assurez-vous que le fichier UI_Configuration.ipynb est dans le m√™me r√©pertoire\n",
    "    print(\"Ex√©cution de Argument_Analysis_UI_configuration.ipynb...\")\n",
    "    %run ./Argument_Analysis_UI_configuration.ipynb\n",
    "    print(\"Ex√©cution de Argument_Analysis_UI_configuration.ipynb termin√©e.\")\n",
    "\n",
    "    # V√©rification que la fonction est bien d√©finie apr√®s l'ex√©cution\n",
    "    if 'configure_analysis_task' not in locals():\n",
    "        print(\"ERREUR CRITIQUE : La fonction configure_analysis_task n'a pas √©t√© d√©finie par UI_Configuration.ipynb !\")\n",
    "    else:\n",
    "        print(\"Fonction configure_analysis_task trouv√©e.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2m4gumr177r",
   "source": "### Modes d'ex√©cution: Batch vs Interactif\n\nLe notebook supporte deux modes d'ex√©cution distincts:\n\n| Mode | Activation | Usage | Interface |\n|------|------------|-------|-----------|\n| **Interactif** | `BATCH_MODE=false` (d√©faut) | D√©monstration, exploration | Widgets Jupyter (ipywidgets) |\n| **Batch** | `BATCH_MODE=true` dans `.env` | Tests automatis√©s, CI/CD, Papermill | Texte pr√©d√©fini sans interaction |\n\n**Pourquoi le mode batch?**\n\nLes widgets Jupyter (`ipywidgets`) utilisent des boucles de polling bloquantes incompatibles avec:\n- L'ex√©cution Papermill\n- Les MCP (Model Context Protocol) Jupyter\n- Les pipelines CI/CD automatis√©s\n\nLe mode batch permet de contourner ces limitations en sautant le chargement de `UI_configuration.ipynb` et en utilisant directement un texte source.\n\n> **Note technique**: En mode batch, le texte est fourni via `BATCH_TEXT` (variable d'environnement) ou via le texte d'exemple enrichi d√©fini dans la cellule suivante.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "4438236c",
   "metadata": {},
   "source": "## 3. Configuration de la T√¢che et R√©cup√©ration du Texte\n\n### S√©lection du texte √† analyser\n\nCette √©tape configure le texte source selon le mode d'ex√©cution:\n\n**Mode Interactif**:\n- Interface graphique avec widgets Jupyter\n- Choix entre sources pr√©d√©finies, URL, fichier, ou texte direct\n- Extraction de contenu (HTML, PDF, etc.)\n- Configuration chiffr√©e sauvegard√©e (`extract_sources.json.gz.enc`)\n\n**Mode Batch**:\n- Texte fourni via variable d'environnement `BATCH_TEXT`\n- Ou texte d'exemple pr√©d√©fini (d√©bat sur transition √©nerg√©tique)\n- Pas d'interaction utilisateur requise\n\n> **Attention**: En mode interactif, la cellule suivante attendra que vous cliquiez sur \"Lancer l'Analyse\" dans l'interface. Ne passez pas √† la suite avant d'avoir s√©lectionn√© un texte."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du texte pour l'analyse\n",
    "# En mode BATCH : utilise BATCH_TEXT (variable d'env) ou le texte d'exemple\n",
    "# En mode interactif : appelle configure_analysis_task() (si disponible)\n",
    "\n",
    "texte_pour_analyse = None\n",
    "\n",
    "# Texte d'exemple enrichi pour le mode batch - contient des arguments complexes et des sophismes\n",
    "TEXTE_EXEMPLE_BATCH = \"\"\"Le debat sur la transition energetique en France revele des enjeux majeurs pour notre avenir.\n",
    "\n",
    "ARGUMENTS EN FAVEUR DES ENERGIES RENOUVELABLES:\n",
    "Les energies renouvelables sont essentielles pour lutter contre le changement climatique. La France s'est engagee a reduire ses emissions de CO2 de 40% d'ici 2030, ce qui necessite un investissement massif dans le solaire et l'eolien. D'ailleurs, l'Allemagne a deja prouve que c'etait possible en produisant 46% de son electricite a partir de sources renouvelables en 2023.\n",
    "\n",
    "De plus, les energies renouvelables creent des emplois locaux non delocalisables. Selon l'ADEME, le secteur emploie deja plus de 150 000 personnes en France et pourrait en creer 500 000 supplementaires d'ici 2050. Quiconque s'oppose a cette transition est donc contre la creation d'emplois.\n",
    "\n",
    "ARGUMENTS CONTRE LE DEVELOPPEMENT MASSIF DES RENOUVELABLES:\n",
    "Cependant, les ecologistes veulent nous ramener a l'age de pierre en supprimant le nucleaire, qui fournit pourtant 70% de notre electricite. Sans le nucleaire, nous serions obliges de choisir entre des coupures d'electricite massives ou une dependance totale au gaz russe.\n",
    "\n",
    "Le cout de la transition est exorbitant. Tout le monde sait que les eoliennes sont inefficaces car elles ne tournent que 25% du temps. Mon voisin Jean-Pierre, qui est ingenieur a EDF, m'a dit que les renouvelables ne pourront jamais remplacer le nucleaire. C'est un expert, donc il a forcemment raison.\n",
    "\n",
    "De plus, les panneaux solaires sont fabriques en Chine avec du charbon, ce qui annule completement leur benefice ecologique. Donc investir dans le solaire revient a financer la pollution chinoise.\n",
    "\n",
    "CONCLUSION:\n",
    "Il faut arreter de debattre et agir. Soit on accepte une transition energetique complete vers 100% de renouvelables d'ici 2040, soit on condamne nos enfants a vivre sur une planete inhabitable. Des milliers de scientifiques ont signe une petition pour le climat, ce qui prouve definitivement que nous avons raison de promouvoir les energies vertes. Les climatosceptiques sont finances par les lobbies petroliers et ne meritent pas qu'on ecoute leurs arguments.\n",
    "\n",
    "En conclusion, bien que certains arguments des deux cotes aient du merite, la question necessite une analyse nuancee des compromis entre independance energetique, impact environnemental, cout economique et faisabilite technique.\"\"\"\n",
    "\n",
    "if BATCH_MODE:\n",
    "    # === MODE BATCH ===\n",
    "    print(\"Mode BATCH - Configuration automatique du texte\")\n",
    "    \n",
    "    # Priorite 1: Variable d'environnement BATCH_TEXT\n",
    "    batch_text_env = os.getenv(\"BATCH_TEXT\", \"\")\n",
    "    if batch_text_env:\n",
    "        texte_pour_analyse = batch_text_env\n",
    "        print(f\"Texte charge depuis BATCH_TEXT ({len(texte_pour_analyse)} caracteres)\")\n",
    "    else:\n",
    "        # Priorite 2: Texte d'exemple par defaut\n",
    "        texte_pour_analyse = TEXTE_EXEMPLE_BATCH\n",
    "        print(f\"Texte d'exemple enrichi utilise ({len(texte_pour_analyse)} caracteres)\")\n",
    "    \n",
    "    print(f\"\\nExtrait du texte:\\n{texte_pour_analyse[:200]}...\")\n",
    "\n",
    "else:\n",
    "    # === MODE INTERACTIF ===\n",
    "    print(\"Mode INTERACTIF - Lancement de l'interface de configuration\")\n",
    "    \n",
    "    if 'configure_analysis_task' in locals():\n",
    "        try:\n",
    "            texte_pour_analyse = configure_analysis_task()\n",
    "            print(f\"Texte recupere via l'interface ({len(texte_pour_analyse) if texte_pour_analyse else 0} caracteres)\")\n",
    "        except Exception as e_ui:\n",
    "            print(f\"Erreur lors de la configuration UI : {e_ui}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"Fonction configure_analysis_task non disponible - verifiez le chargement de UI_configuration.ipynb\")\n",
    "\n",
    "# Verification finale\n",
    "if not texte_pour_analyse:\n",
    "    print(\"\\nAucun texte prepare. L'analyse ne peut pas continuer.\")\n",
    "else:\n",
    "    print(f\"\\nTexte pret pour l'analyse (longueur: {len(texte_pour_analyse)}). Passage au chargement des agents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wm7k26ldwt",
   "source": "### Interpr√©tation de la configuration du texte\n\n**R√©sultat attendu (Mode Batch)**:\n```\nMode BATCH - Configuration automatique du texte\nTexte charge depuis BATCH_TEXT (XXX caracteres)\nou\nTexte d'exemple enrichi utilise (XXX caracteres)\n```\n\n**R√©sultat attendu (Mode Interactif)**:\n```\nMode INTERACTIF - Lancement de l'interface de configuration\nTexte recupere via l'interface (XXX caracteres)\n```\n\n**Structure du texte d'exemple**:\n\nLe texte d'exemple enrichi contient intentionnellement plusieurs sophismes pour d√©monstration:\n\n| Sophisme | Exemple dans le texte |\n|----------|----------------------|\n| Faux dilemme | \"Soit 100% renouvelables, soit plan√®te inhabitable\" |\n| Appel √† l'autorit√© | \"Mon voisin ing√©nieur EDF dit que...\" |\n| Ad hominem | \"Climatosceptiques financ√©s par lobbies p√©troliers\" |\n| G√©n√©ralisation h√¢tive | \"Tout le monde sait que les √©oliennes...\" |\n| Pente glissante | \"Les √©cologistes veulent nous ramener √† l'√¢ge de pierre\" |\n\n> **Conseil p√©dagogique**: Le texte d'exemple est con√ßu pour tester la robustesse de l'analyse rh√©torique multi-agents. Utilisez-le pour comprendre comment les agents d√©tectent les arguments fallacieux.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "183031e3",
   "metadata": {},
   "source": "## 4. Chargement des D√©finitions des Agents et de l'Orchestration\n\n### Architecture modulaire par notebooks\n\nLe syst√®me est structur√© en **4 notebooks enfants** charg√©s dynamiquement via `%run`:\n\n**Avantages de cette architecture**:\n1. **S√©paration des responsabilit√©s**: Chaque agent dans son propre fichier\n2. **R√©utilisabilit√©**: Les agents peuvent √™tre charg√©s individuellement\n3. **Maintenabilit√©**: Modification d'un agent sans toucher aux autres\n4. **Testabilit√©**: Tests unitaires par agent\n\n**Ordre de chargement critique**:\n\n```\n0-init.ipynb           (√âtat + Config LLM + JVM)\n    ‚Üì\n1-informal_agent.ipynb (D√©pend de RhetoricalAnalysisState)\n    ‚Üì\n2-pl_agent.ipynb       (D√©pend de RhetoricalAnalysisState + JVM)\n    ‚Üì\n3-orchestration.ipynb  (D√©pend de tous les agents)\n```\n\n> **Note technique**: `%run` ex√©cute le notebook dans le namespace courant. Toutes les variables d√©finies dans les notebooks enfants (classes, fonctions) deviennent disponibles ici."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cuter les notebooks enfants pour charger les d√©finitions\n",
    "# Seulement si un texte a √©t√© pr√©par√© avec succ√®s\n",
    "if 'texte_pour_analyse' in locals() and texte_pour_analyse:\n",
    "    print(\"\\nChargement des d√©finitions des agents et de l'orchestration...\")\n",
    "    try:\n",
    "        %run ./Argument_Analysis_Agentic-0-init.ipynb\n",
    "        %run ./Argument_Analysis_Agentic-1-informal_agent.ipynb\n",
    "        %run ./Argument_Analysis_Agentic-2-pl_agent.ipynb\n",
    "        %run ./Argument_Analysis_Agentic-3-orchestration.ipynb  # D√©finit run_analysis_conversation(texte_a_analyser)\n",
    "        print(\"‚úÖ D√©finitions charg√©es.\")\n",
    "        # V√©rifier que la fonction d'orchestration est charg√©e\n",
    "        if 'run_analysis_conversation' not in locals():\n",
    "             print(\"‚ùå ERREUR CRITIQUE: La fonction run_analysis_conversation n'a pas √©t√© d√©finie apr√®s l'ex√©cution des notebooks agents!\")\n",
    "             # raise NameError(\"run_analysis_conversation non d√©finie\")\n",
    "    except Exception as e_run:\n",
    "        print(f\"\\n‚ùå Une erreur est survenue lors de l'ex√©cution des notebooks enfants : {e_run}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Emp√™cher la suite si le chargement √©choue\n",
    "        texte_pour_analyse = None\n",
    "else:\n",
    "    print(\"\\nSkipping agent definition loading because no text was prepared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rh30f4ohrsa",
   "source": "### Architecture modulaire charg√©e\n\n**Notebooks charg√©s et leurs responsabilit√©s**:\n\n| Notebook | Composants d√©finis | R√¥le |\n|----------|-------------------|------|\n| `Agentic-0-init.ipynb` | `RhetoricalAnalysisState`, `StateManagerPlugin`, kernel SK | √âtat partag√©, configuration LLM, JVM Tweety |\n| `Agentic-1-informal_agent.ipynb` | `InformalAnalysisAgent` | Analyse arguments et sophismes (taxonomie) |\n| `Agentic-2-pl_agent.ipynb` | `PropositionalLogicAgent`, `PropositionalLogicPlugin` | Formalisation en logique propositionnelle |\n| `Agentic-3-orchestration.ipynb` | `run_analysis_conversation()` | Orchestration collaborative des agents |\n\n**Architecture technique**:\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Semantic Kernel (orchestration)                ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n‚îÇ  ‚îÇ Informal     ‚îÇ  ‚îÇ Propositional Logic    ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ Analysis     ‚îÇ‚îÄ‚ñ∂‚îÇ Agent (Tweety/JPype)   ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ Agent        ‚îÇ  ‚îÇ                        ‚îÇ  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n‚îÇ         ‚îÇ                     ‚îÇ                 ‚îÇ\n‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ\n‚îÇ                   ‚ñº                             ‚îÇ\n‚îÇ        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ\n‚îÇ        ‚îÇ StateManager       ‚îÇ                   ‚îÇ\n‚îÇ        ‚îÇ Plugin             ‚îÇ                   ‚îÇ\n‚îÇ        ‚îÇ (√©tat partag√©)     ‚îÇ                   ‚îÇ\n‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n> **Note d'impl√©mentation**: L'√©tat partag√© (`RhetoricalAnalysisState`) permet aux agents de communiquer leurs r√©sultats via un contexte commun plut√¥t que par messages directs.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "6b60ae64",
   "metadata": {},
   "source": "## 5. Ex√©cution de l'Analyse Collaborative\n\n### Orchestration asynchrone avec Semantic Kernel\n\nCette cellule lance le processus d'analyse multi-agents. L'orchestration fonctionne en **mode asynchrone** pour g√©rer efficacement les appels API LLM.\n\n**Composants techniques**:\n\n| Composant | R√¥le |\n|-----------|------|\n| `nest_asyncio.apply()` | Permet `await` dans Jupyter (normalement synchrone) |\n| `run_analysis_conversation(texte)` | Fonction d'orchestration principale |\n| `local_state` | Objet `RhetoricalAnalysisState` retourn√© |\n\n**√âtapes d'ex√©cution internes**:\n\n1. **Initialisation**: Cr√©ation kernel SK, chargement plugins\n2. **Tour 1 - Analyse informelle**: Agent LLM identifie arguments/sophismes\n3. **Tour 2 - Formalisation**: Agent PL traduit en logique, ex√©cute requ√™tes\n4. **Synth√®se**: G√©n√©ration conclusion bas√©e sur analyse hybride\n5. **Retour**: √âtat final JSON avec tous les r√©sultats\n\n> **Note performance**: L'ex√©cution prend 90-150s selon la complexit√© du texte et la latence des API OpenAI/Anthropic. Surveillez les logs pour suivre la progression."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Lancer seulement si on a obtenu un texte valide ET que les d√©finitions sont charg√©es\n",
    "if 'texte_pour_analyse' in locals() and texte_pour_analyse and 'run_analysis_conversation' in locals():\n",
    "    print(\"\\nüöÄ Lancement de l'ex√©cution asynchrone de l'analyse...\")\n",
    "    nest_asyncio.apply()\n",
    "    try:\n",
    "        # Passer le texte pr√©par√©\n",
    "        local_state = await run_analysis_conversation(texte_pour_analyse)\n",
    "        print(\"\\nüèÅ Analyse termin√©e.\")\n",
    "    except Exception as e_analysis:\n",
    "        print(f\"\\n‚ùå Une erreur est survenue pendant l'ex√©cution de l'analyse : {e_analysis}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "elif 'texte_pour_analyse' not in locals() or not texte_pour_analyse:\n",
    "    print(\"\\n Analyse non lanc√©e : aucun texte n'a √©t√© pr√©par√© ou une erreur est survenue avant.\")\n",
    "else: # Implique que run_analysis_conversation n'a pas √©t√© charg√©e\n",
    "     print(\"\\n Analyse non lanc√©e : la fonction d'orchestration n'a pas pu √™tre charg√©e.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j4vej6eunq",
   "source": "### Interpr√©tation du processus d'analyse\n\n**√âtapes d'ex√©cution observables**:\n\n1. **Analyse informelle** (InformalAnalysisAgent):\n   - Identification des arguments principaux\n   - D√©tection des sophismes via taxonomie\n   - Stockage dans `local_state.identified_arguments` et `identified_fallacies`\n\n2. **Formalisation logique** (PropositionalLogicAgent):\n   - Traduction des arguments en propositions PL\n   - Cr√©ation de Belief Sets Tweety\n   - Ex√©cution de requ√™tes logiques (coh√©rence, implication)\n\n3. **Synth√®se collaborative**:\n   - Combinaison des r√©sultats informels et formels\n   - G√©n√©ration de la conclusion finale\n   - Stockage dans `local_state.final_conclusion`\n\n**Dur√©e typique**: 90-150 secondes (selon complexit√© du texte et latence API)\n\n**Logs √† surveiller**:\n\n| Message | Signification |\n|---------|---------------|\n| `[InformalAnalysisAgent] Processing...` | Analyse rh√©torique en cours |\n| `[PropositionalLogicAgent] Creating belief set...` | Formalisation PL |\n| `FUNC_ERROR: JPype not initialized` | Tweety non disponible (fallback mode) |\n| `Final state:` | Affichage JSON de l'√©tat final |\n\n> **Note de performance**: En mode batch, l'ex√©cution compl√®te prend environ 122 secondes sur le texte d'exemple enrichi.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "mf35rz46kvk",
   "metadata": {},
   "source": "## 5bis. Rapport de Validation de l'Analyse\n\n### Validation structur√©e avec m√©triques de confiance\n\nCette section g√©n√®re un **rapport de validation cross-valid√©** qui v√©rifie la compl√©tude et la coh√©rence de l'analyse rh√©torique.\n\n**Objectif p√©dagogique**: D√©montrer l'importance de la validation automatis√©e dans les syst√®mes d'IA, en particulier pour:\n- D√©tecter les analyses incompl√®tes\n- Calculer un score de confiance quantitatif\n- Identifier les composants manquants\n- Fournir un rapport exploitable (JSON)\n\n**M√©thode de validation**:\n\nLa validation cross-check v√©rifie 6 crit√®res ind√©pendants:\n\n| Crit√®re | Validation | Poids |\n|---------|------------|-------|\n| `ARGUMENTS_IDENTIFIED` | `len(identified_arguments) > 0` | 1/6 |\n| `FALLACIES_ANALYZED` | `len(identified_fallacies) > 0` | 1/6 |\n| `BELIEF_SET_CREATED` | `len(belief_sets) > 0` | 1/6 |\n| `QUERIES_EXECUTED` | `len(query_log) > 0` | 1/6 |\n| `QUERIES_MEANINGFUL` | Au moins 1 r√©sultat ACCEPTED/REJECTED | 1/6 |\n| `CONCLUSION_GENERATED` | `final_conclusion is not None` | 1/6 |\n\n**Score de confiance**: `confidence = nombre_crit√®res_valid√©s / 6`\n\n> **Application pratique**: Ce type de validation est essentiel dans les syst√®mes de production pour garantir la qualit√© des analyses automatis√©es. Le rapport JSON peut alimenter des tableaux de bord de monitoring."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pug0jcknsij",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELLULE DE VALIDATION FINALE ===\n",
    "# Genere un rapport JSON structure avec cross-validation\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "def generate_validated_analysis_report(state) -> Dict[str, Any]:\n",
    "    \"\"\"Genere rapport JSON structure avec cross-validation.\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"version\": \"2.0-validated\",\n",
    "            \"text_length\": len(state.raw_text) if state.raw_text else 0,\n",
    "            \"text_snippet\": (state.raw_text[:150] + \"...\") if state.raw_text and len(state.raw_text) > 150 else (state.raw_text or \"\")\n",
    "        },\n",
    "        \"informal_analysis\": {\n",
    "            \"arguments\": [],\n",
    "            \"fallacies\": [],\n",
    "            \"taxonomy_families_used\": set()\n",
    "        },\n",
    "        \"formal_analysis\": {\n",
    "            \"belief_sets\": [],\n",
    "            \"query_results\": [],\n",
    "            \"consistency_checked\": False\n",
    "        },\n",
    "        \"cross_validation\": {\n",
    "            \"validation_status\": \"INCOMPLETE\",\n",
    "            \"confidence_score\": 0.0,\n",
    "            \"checks_passed\": [],\n",
    "            \"issues\": []\n",
    "        },\n",
    "        \"conclusion\": {\n",
    "            \"summary\": state.final_conclusion if hasattr(state, 'final_conclusion') else None,\n",
    "            \"is_complete\": hasattr(state, 'final_conclusion') and state.final_conclusion is not None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Populate arguments\n",
    "    if hasattr(state, 'identified_arguments'):\n",
    "        for arg_id, arg_desc in state.identified_arguments.items():\n",
    "            has_fallacy = False\n",
    "            if hasattr(state, 'identified_fallacies'):\n",
    "                has_fallacy = any(\n",
    "                    f.get('target_argument_id') == arg_id\n",
    "                    for f in state.identified_fallacies.values()\n",
    "                )\n",
    "            report[\"informal_analysis\"][\"arguments\"].append({\n",
    "                \"id\": arg_id, \"description\": str(arg_desc)[:200], \"has_fallacy\": has_fallacy\n",
    "            })\n",
    "    \n",
    "    # Populate fallacies\n",
    "    if hasattr(state, 'identified_fallacies'):\n",
    "        for f_id, f_data in state.identified_fallacies.items():\n",
    "            fallacy_type = f_data.get('type', 'Unknown') if isinstance(f_data, dict) else str(f_data)\n",
    "            report[\"informal_analysis\"][\"fallacies\"].append({\n",
    "                \"id\": f_id,\n",
    "                \"type\": fallacy_type,\n",
    "                \"justification\": f_data.get('justification', '') if isinstance(f_data, dict) else '',\n",
    "                \"target_id\": f_data.get('target_argument_id') if isinstance(f_data, dict) else None,\n",
    "                \"severity\": \"HIGH\" if any(kw in str(fallacy_type).lower() for kw in ['manipulation', 'tromperie']) else \"MEDIUM\"\n",
    "            })\n",
    "            # Track taxonomy families\n",
    "            if isinstance(fallacy_type, str) and '/' in fallacy_type:\n",
    "                report[\"informal_analysis\"][\"taxonomy_families_used\"].add(fallacy_type.split('/')[0])\n",
    "    \n",
    "    report[\"informal_analysis\"][\"taxonomy_families_used\"] = list(report[\"informal_analysis\"][\"taxonomy_families_used\"])\n",
    "    \n",
    "    # Populate belief sets\n",
    "    if hasattr(state, 'belief_sets'):\n",
    "        for bs_id, bs_data in state.belief_sets.items():\n",
    "            content = bs_data.get('content', '') if isinstance(bs_data, dict) else str(bs_data)\n",
    "            report[\"formal_analysis\"][\"belief_sets\"].append({\n",
    "                \"id\": bs_id,\n",
    "                \"logic_type\": bs_data.get('logic_type', 'PL') if isinstance(bs_data, dict) else 'PL',\n",
    "                \"formula_count\": content.count('\\n') + 1 if content else 0,\n",
    "                \"is_consistent\": \"NOT_CHECKED\"\n",
    "            })\n",
    "    \n",
    "    # Populate query results\n",
    "    if hasattr(state, 'query_log'):\n",
    "        for qlog in state.query_log:\n",
    "            raw_result = qlog.get('raw_result', '') if isinstance(qlog, dict) else ''\n",
    "            status = \"UNKNOWN\"\n",
    "            if \"ACCEPTED\" in str(raw_result): status = \"ACCEPTED\"\n",
    "            elif \"REJECTED\" in str(raw_result): status = \"REJECTED\"\n",
    "            elif \"FUNC_ERROR\" in str(raw_result): status = \"ERROR\"\n",
    "            \n",
    "            report[\"formal_analysis\"][\"query_results\"].append({\n",
    "                \"log_id\": qlog.get('log_id', '') if isinstance(qlog, dict) else '',\n",
    "                \"belief_set_id\": qlog.get('belief_set_id', '') if isinstance(qlog, dict) else '',\n",
    "                \"query\": qlog.get('query', '') if isinstance(qlog, dict) else '',\n",
    "                \"status\": status\n",
    "            })\n",
    "    \n",
    "    # === CROSS-VALIDATION LOGIC ===\n",
    "    checks = []\n",
    "    issues = []\n",
    "    \n",
    "    # Check 1: Arguments identified\n",
    "    if len(report[\"informal_analysis\"][\"arguments\"]) > 0:\n",
    "        checks.append(\"ARGUMENTS_IDENTIFIED\")\n",
    "    else:\n",
    "        issues.append(\"Aucun argument identifie\")\n",
    "    \n",
    "    # Check 2: Fallacy analysis attempted\n",
    "    if len(report[\"informal_analysis\"][\"fallacies\"]) > 0:\n",
    "        checks.append(\"FALLACIES_ANALYZED\")\n",
    "    elif hasattr(state, 'answers') and any(\"sophisme\" in str(v).lower() for v in state.answers.values()):\n",
    "        checks.append(\"FALLACY_ANALYSIS_ATTEMPTED\")\n",
    "    else:\n",
    "        issues.append(\"Analyse sophismes non effectuee\")\n",
    "    \n",
    "    # Check 3: Formal logic translation\n",
    "    if len(report[\"formal_analysis\"][\"belief_sets\"]) > 0:\n",
    "        checks.append(\"BELIEF_SET_CREATED\")\n",
    "    else:\n",
    "        issues.append(\"Aucun Belief Set PL cree\")\n",
    "    \n",
    "    # Check 4: Queries executed\n",
    "    if len(report[\"formal_analysis\"][\"query_results\"]) > 0:\n",
    "        checks.append(\"QUERIES_EXECUTED\")\n",
    "        accepted = sum(1 for q in report[\"formal_analysis\"][\"query_results\"] if q[\"status\"] == \"ACCEPTED\")\n",
    "        rejected = sum(1 for q in report[\"formal_analysis\"][\"query_results\"] if q[\"status\"] == \"REJECTED\")\n",
    "        if accepted > 0 or rejected > 0:\n",
    "            checks.append(\"QUERIES_MEANINGFUL\")\n",
    "    else:\n",
    "        issues.append(\"Aucune requete PL executee\")\n",
    "    \n",
    "    # Check 5: Conclusion generated\n",
    "    if report[\"conclusion\"][\"is_complete\"]:\n",
    "        checks.append(\"CONCLUSION_GENERATED\")\n",
    "    else:\n",
    "        issues.append(\"Conclusion finale non generee\")\n",
    "    \n",
    "    # Calculate confidence score\n",
    "    max_checks = 6  # ARGUMENTS, FALLACIES, BELIEF_SET, QUERIES, QUERIES_MEANINGFUL, CONCLUSION\n",
    "    confidence = len(checks) / max_checks\n",
    "    report[\"cross_validation\"][\"confidence_score\"] = round(confidence, 2)\n",
    "    report[\"cross_validation\"][\"checks_passed\"] = checks\n",
    "    report[\"cross_validation\"][\"issues\"] = issues\n",
    "    \n",
    "    # Determine validation status\n",
    "    if confidence >= 0.8:\n",
    "        report[\"cross_validation\"][\"validation_status\"] = \"COMPLETE_VALIDATED\"\n",
    "    elif confidence >= 0.5:\n",
    "        report[\"cross_validation\"][\"validation_status\"] = \"PARTIAL_VALIDATED\"\n",
    "    elif confidence >= 0.3:\n",
    "        report[\"cross_validation\"][\"validation_status\"] = \"MINIMAL\"\n",
    "    else:\n",
    "        report[\"cross_validation\"][\"validation_status\"] = \"INCOMPLETE\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "def display_validation_summary(report: Dict[str, Any]) -> str:\n",
    "    \"\"\"Affiche resume lisible du rapport de validation.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"          RAPPORT D'ANALYSE RHETORIQUE VALIDEE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    cv = report[\"cross_validation\"]\n",
    "    status_symbols = {\n",
    "        \"COMPLETE_VALIDATED\": \"[OK]\",\n",
    "        \"PARTIAL_VALIDATED\": \"[PARTIEL]\",\n",
    "        \"MINIMAL\": \"[MINIMAL]\",\n",
    "        \"INCOMPLETE\": \"[INCOMPLET]\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  STATUT: {status_symbols.get(cv['validation_status'], '?')} {cv['validation_status']}\")\n",
    "    print(f\"  CONFIANCE: {cv['confidence_score']*100:.0f}%\")\n",
    "    \n",
    "    print(f\"\\n  [ANALYSE INFORMELLE]\")\n",
    "    print(f\"    Arguments: {len(report['informal_analysis']['arguments'])}\")\n",
    "    print(f\"    Sophismes: {len(report['informal_analysis']['fallacies'])}\")\n",
    "    \n",
    "    print(f\"\\n  [ANALYSE FORMELLE]\")\n",
    "    print(f\"    Belief Sets: {len(report['formal_analysis']['belief_sets'])}\")\n",
    "    print(f\"    Requetes: {len(report['formal_analysis']['query_results'])}\")\n",
    "    \n",
    "    print(f\"\\n  [VALIDATIONS PASSEES]\")\n",
    "    for check in cv['checks_passed']:\n",
    "        print(f\"    [+] {check}\")\n",
    "    \n",
    "    if cv['issues']:\n",
    "        print(f\"\\n  [PROBLEMES DETECTES]\")\n",
    "        for issue in cv['issues']:\n",
    "            print(f\"    [-] {issue}\")\n",
    "    \n",
    "    print(f\"\\n  [CONCLUSION]\")\n",
    "    if report['conclusion']['is_complete']:\n",
    "        conclusion_preview = str(report['conclusion']['summary'])[:200]\n",
    "        print(f\"    {conclusion_preview}...\")\n",
    "    else:\n",
    "        print(\"    (Non generee)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    return cv['validation_status']\n",
    "\n",
    "\n",
    "# === EXECUTION DE LA VALIDATION ===\n",
    "print(\"\\n--- Generation du Rapport d'Analyse Validee ---\")\n",
    "\n",
    "# Chercher l'etat local_state defini par l'orchestration\n",
    "if 'local_state' in dir() and local_state is not None:\n",
    "    # Generate report\n",
    "    final_report = generate_validated_analysis_report(local_state)\n",
    "    \n",
    "    # Display summary\n",
    "    validation_status = display_validation_summary(final_report)\n",
    "    \n",
    "    # Export JSON\n",
    "    output_path = \"output/analysis_report.json\"\n",
    "    try:\n",
    "        import os\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_report, f, indent=2, ensure_ascii=False, default=str)\n",
    "        print(f\"\\nRapport JSON exporte vers: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur export JSON: {e}\")\n",
    "    \n",
    "    # Afficher JSON complet\n",
    "    print(\"\\n--- RAPPORT JSON COMPLET ---\")\n",
    "    print(json.dumps(final_report, indent=2, ensure_ascii=False, default=str))\n",
    "    \n",
    "    # Final verdict\n",
    "    print(\"\\n--- VERDICT FINAL ---\")\n",
    "    if validation_status == \"COMPLETE_VALIDATED\":\n",
    "        print(\"[SUCCESS] ANALYSE RHETORIQUE VALIDEE COMPLETE\")\n",
    "        print(\"  Tous les criteres de validation sont satisfaits.\")\n",
    "    elif validation_status == \"PARTIAL_VALIDATED\":\n",
    "        print(\"[PARTIEL] Analyse partiellement validee\")\n",
    "        print(\"  Certaines etapes manquent pour une validation complete.\")\n",
    "    else:\n",
    "        print(f\"[{validation_status}] Analyse incomplete\")\n",
    "        print(\"  Verifiez les problemes detectes ci-dessus.\")\n",
    "\n",
    "else:\n",
    "    print(\"[INFO] Etat d'analyse (local_state) non disponible.\")\n",
    "    print(\"  Executez d'abord les cellules precedentes pour lancer l'analyse.\")\n",
    "    print(\"  Ou l'analyse n'a pas ete executee (mode batch sans erreur?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x3xq7uxfe4",
   "source": "### Interpr√©tation du rapport de validation\n\n**Statuts de validation possibles**:\n\n| Statut | Score | Crit√®res |\n|--------|-------|----------|\n| `COMPLETE_VALIDATED` | ‚â•80% | Tous les composants critiques pr√©sents |\n| `PARTIAL_VALIDATED` | ‚â•50% | Analyse fonctionnelle mais incompl√®te |\n| `MINIMAL` | ‚â•30% | Quelques √©l√©ments d√©tect√©s |\n| `INCOMPLETE` | <30% | √âchec de l'analyse |\n\n**Crit√®res de validation**:\n\n1. **ARGUMENTS_IDENTIFIED**: Au moins un argument d√©tect√©\n2. **FALLACIES_ANALYZED**: Au moins un sophisme identifi√©\n3. **BELIEF_SET_CREATED**: Au moins un Belief Set PL g√©n√©r√©\n4. **QUERIES_EXECUTED**: Au moins une requ√™te logique lanc√©e\n5. **QUERIES_MEANINGFUL**: R√©sultat ACCEPTED ou REJECTED obtenu\n6. **CONCLUSION_GENERATED**: Conclusion finale pr√©sente\n\n**Exemple d'analyse r√©ussie**:\n\n```json\n{\n  \"cross_validation\": {\n    \"validation_status\": \"COMPLETE_VALIDATED\",\n    \"confidence_score\": 0.83,\n    \"checks_passed\": [\n      \"ARGUMENTS_IDENTIFIED\",\n      \"FALLACIES_ANALYZED\",\n      \"BELIEF_SET_CREATED\",\n      \"QUERIES_EXECUTED\",\n      \"CONCLUSION_GENERATED\"\n    ],\n    \"issues\": []\n  }\n}\n```\n\n> **Utilit√© du rapport JSON**: Le fichier `output/analysis_report.json` peut √™tre utilis√© pour:\n> - Tests automatis√©s (CI/CD)\n> - M√©triques de qualit√© d'analyse\n> - Comparaison entre versions du syst√®me\n> - Documentation des r√©sultats d'analyse",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "7abbf986",
   "metadata": {},
   "source": "## 6. R√©sultats et Conclusion\n\nV√©rifiez les logs et l'√©tat final JSON affich√©s par l'ex√©cution pr√©c√©dente pour voir le r√©sultat de l'analyse collaborative.\n\n### R√©capitulatif du workflow complet\n\nLe notebook orchestrateur `Argument_Analysis_Executor.ipynb` impl√©mente un pipeline d'analyse rh√©torique en 7 √©tapes:\n\n| √âtape | Action | Dur√©e typique |\n|-------|--------|---------------|\n| 1. Configuration | Chargement `.env`, variables d'environnement | <1s |\n| 2. Interface/Batch | Configuration texte (UI ou batch) | Variable (0-60s) |\n| 3. Chargement agents | Import des 4 notebooks modulaires | 5-10s |\n| 4. Analyse informelle | D√©tection arguments + sophismes | 40-60s |\n| 5. Formalisation PL | Cr√©ation Belief Sets + requ√™tes | 30-50s |\n| 6. Validation | G√©n√©ration rapport JSON structur√© | <1s |\n| 7. Export | Sauvegarde `output/analysis_report.json` | <1s |\n\n**Total (mode batch)**: ~120-150 secondes\n\n### M√©thodologie d'analyse rh√©torique\n\nLe syst√®me combine deux approches compl√©mentaires:\n\n**Analyse informelle (InformalAnalysisAgent)**:\n- Utilise un LLM (GPT-4/Claude) pour comprendre le langage naturel\n- Identifie arguments, pr√©misses, conclusions\n- D√©tecte sophismes via taxonomie hi√©rarchique\n- Output: Structure JSON d√©crivant la rh√©torique\n\n**Analyse formelle (PropositionalLogicAgent)**:\n- Traduit les arguments en logique propositionnelle\n- Cr√©e des Belief Sets Tweety (biblioth√®que Java)\n- Ex√©cute requ√™tes de coh√©rence et d'implication\n- Output: Preuves formelles ou contre-exemples\n\n> **Avantage de l'approche hybride**: La combinaison LLM + logique formelle permet √† la fois la compr√©hension contextuelle (LLM) et la rigueur math√©matique (logique)."
  },
  {
   "cell_type": "markdown",
   "id": "a7a37b89",
   "metadata": {},
   "source": "## 7. Pistes d'Am√©lioration Futures\n\n### Am√©liorations techniques\n\n| Cat√©gorie | Am√©lioration propos√©e | Impact |\n|-----------|----------------------|--------|\n| **Logique formelle** | Impl√©menter FOL, logique modale (Tweety) | Expressivit√© accrue |\n| **Taxonomie sophismes** | Navigation profondeur variable, exemples | Pr√©cision d√©tection |\n| **Gestion erreurs** | Retry automatique, fallback gracieux | Robustesse production |\n| **Performance** | Cache LLM, parall√©lisation agents | R√©duction latence |\n| **√âtat RDF/KG** | Migration vers graphe s√©mantique (rdflib) | Requ√™tes complexes |\n\n### Am√©liorations p√©dagogiques\n\n**Visualisations interactives**:\n- Graphe d'arguments (NetworkX + Plotly)\n- Arbre taxonomique des sophismes\n- Timeline de l'analyse (Gantt chart)\n\n**Explications enrichies**:\n- D√©finitions des sophismes avec exemples historiques\n- Comparaison analyse informelle vs formelle\n- M√©triques de confiance par argument\n\n**Interface utilisateur**:\n- Dashboard Gradio/Streamlit pour upload de textes\n- Annotation collaborative des arguments\n- Export PDF avec rapport structur√©\n\n### Cas d'usage avanc√©s\n\n**Analyse de d√©bats politiques**:\n- D√©tection de manipulation rh√©torique\n- Comparaison positions de candidats\n- Fact-checking automatis√© (int√©gration sources externes)\n\n**√âducation √† la pens√©e critique**:\n- Exercices interactifs sur textes annot√©s\n- Quiz g√©n√©ratif sur d√©tection de sophismes\n- Feedback personnalis√© sur essais d'√©tudiants\n\n**Recherche acad√©mique**:\n- Corpus analysis (analyse de milliers de textes)\n- √âvolution diachronique de l'argumentation\n- Comparaison cultures/langues (multilingual)\n\n> **Roadmap prioritaire**: \n> 1. Finaliser int√©gration Tweety (Query execution)\n> 2. Impl√©menter visualisations graphiques\n> 3. Ajouter interface Gradio\n> 4. Publier package Python r√©utilisable"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}