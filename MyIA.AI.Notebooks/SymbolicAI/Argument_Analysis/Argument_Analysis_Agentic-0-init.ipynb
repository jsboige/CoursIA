{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6196daf0",
   "metadata": {},
   "source": [
    "# üß† Notebook d'Analyse Rh√©torique Collaborative par Agents IA (Modulaire - v2)\n",
    "\n",
    "Bienvenue dans ce notebook utilisant Semantic Kernel pour orchestrer une analyse rh√©torique collaborative. Plusieurs agents sp√©cialis√©s vont travailler ensemble pour analyser un texte fourni. Cette version est structur√©e de mani√®re modulaire, avec des cellules d√©di√©es pour chaque agent et leurs composants.\n",
    "\n",
    "**Objectif :** Analyser un texte sous diff√©rents angles (informel et formel simple via logique propositionnelle) en observant la collaboration des agents via la modification d'un √©tat partag√©. Utiliser une orchestration bas√©e sur la d√©signation explicite de l'agent suivant via l'√©tat.\n",
    "\n",
    "**Structure :**\n",
    "1.  Configuration Initiale & D√©pendances (Python, LLM)\n",
    "2.  Configuration Java/Tweety (pour l'analyse logique formelle)\n",
    "3.  D√©finitions des Composants Partag√©s (√âtat, StateManager, Service LLM Global)\n",
    "4.  Agent: Project Manager (D√©finitions)\n",
    "5.  Agent: Informal Analysis (D√©finitions)\n",
    "6.  Agent: Propositional Logic (D√©finitions)\n",
    "7.  Orchestration de la Conversation (D√©finitions des Strat√©gies)\n",
    "8.  Ex√©cution de la Conversation Collaborative (Instanciation et Lancement)\n",
    "9.  Conclusion & Prochaines √âtapes\n",
    "\n",
    "*(Version 2 : Correction bugs d√©signation/affichage agent, validation type logique, nettoyage code et am√©lioration documentation)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80571e1e",
   "metadata": {},
   "source": [
    "## 1. Configuration Initiale et D√©pendances (Python, LLM)\n",
    "\n",
    "Cette cellule unique regroupe :\n",
    "*   L'installation et la v√©rification des d√©pendances Python n√©cessaires (`semantic-kernel`, `jpype1`, `python-dotenv`, `pandas`, `requests`).\n",
    "*   La configuration du logging global.\n",
    "*   Le chargement de la configuration du LLM (OpenAI ou Azure OpenAI) depuis le fichier `.env`. **Assurez-vous d'avoir un fichier `.env` √† la racine avec vos cl√©s API et identifiants de mod√®le.**\n",
    "*   La d√©finition du texte source (`raw_text_input`) qui sera analys√© par les agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CELLULE [0] - Verification et correction compatibilite semantic-kernel/openai\n",
    "# Cette cellule verifie et corrige les problemes de compatibilite entre packages\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "def check_package_compatibility():\n",
    "    \"\"\"Verifie et corrige la compatibilite semantic-kernel/openai.\"\"\"\n",
    "    print('--- Verification compatibilite semantic-kernel/openai ---')\n",
    "    \n",
    "    # Tester l'import problematique\n",
    "    try:\n",
    "        from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "        print('‚úÖ Import semantic_kernel OK')\n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        if 'omit' in str(e) or 'ChatCompletionMessageToolCall' in str(e):\n",
    "            print(f'‚ö†Ô∏è Incompatibilite detectee: {e}')\n",
    "            print('üîß Correction en cours - installation openai<2.0...')\n",
    "            \n",
    "            # Installer une version compatible d'openai\n",
    "            try:\n",
    "                subprocess.check_call([\n",
    "                    sys.executable, '-m', 'pip', 'install', \n",
    "                    '-q', '--disable-pip-version-check',\n",
    "                    'openai>=1.50.0,<1.99.0'\n",
    "                ])\n",
    "                print('‚úÖ openai reinstalle avec version compatible')\n",
    "                print('‚ö†Ô∏è IMPORTANT: Redemarrez le noyau (Kernel -> Restart) puis re-executez le notebook')\n",
    "                return False\n",
    "            except Exception as install_error:\n",
    "                print(f'‚ùå Erreur installation: {install_error}')\n",
    "                print('Solution manuelle: pip install \"openai>=1.50.0,<1.99.0\"')\n",
    "                return False\n",
    "        else:\n",
    "            print(f'‚ùå Erreur inattendue: {e}')\n",
    "            return False\n",
    "\n",
    "# Executer la verification\n",
    "_compat_ok = check_package_compatibility()\n",
    "if not _compat_ok:\n",
    "    raise RuntimeError('Redemarrez le noyau apres la correction des packages.')\n",
    "\n",
    "print('--- Fin verification compatibilite ---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1eb173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CELLULE [1] MODIFI√âE (ID 25d83fde) - Configuration Initiale et D√©pendances (Python, LLM)\n",
    "# Regroupe d√©pendances, config LLM. *** raw_text_input a √©t√© SUPPRIM√â ***\n",
    "\n",
    "%pip install --upgrade semantic-kernel python-dotenv ipywidgets jpype1 requests tqdm pandas \n",
    "# pandas ajout√© pour plugin informel\n",
    "# D√©commentez la ligne ci-dessus si les packages ne sont pas d√©j√† install√©s\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "import subprocess\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "# --- Configuration du Logging Global ---\n",
    "# Format am√©lior√© incluant le nom du logger pour mieux tracer\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] [%(name)s] %(message)s', datefmt='%H:%M:%S')\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"semantic_kernel.connectors.ai\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"semantic_kernel.kernel\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"semantic_kernel.functions\").setLevel(logging.WARNING)\n",
    "# Garder INFO pour les agents et l'orchestration pour suivre le d√©roulement\n",
    "logging.getLogger(\"semantic_kernel.agents\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"Orchestration\").setLevel(logging.INFO)\n",
    "# Configurer les loggers sp√©cifiques utilis√©s plus loin si n√©cessaire\n",
    "# (Ex: logging.getLogger(\"Orchestration.AgentPM\").setLevel(logging.DEBUG) pour plus de d√©tails sur un agent)\n",
    "\n",
    "logger = logging.getLogger(\"Orchestration.Setup\") # Logger pour cette cellule\n",
    "\n",
    "# --- V√©rification et Installation D√©pendances ---\n",
    "def check_and_install(package_import_name: str, package_install_name: str):\n",
    "    \"\"\"V√©rifie si un package est importable, sinon tente de l'installer.\"\"\"\n",
    "    try:\n",
    "        importlib.import_module(package_import_name)\n",
    "        logger.info(f\"‚úîÔ∏è D√©pendance '{package_import_name}' trouv√©e.\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        logger.warning(f\"‚ö†Ô∏è D√©pendance '{package_import_name}' manquante (package: {package_install_name}). Tentative d'installation...\")\n",
    "        try:\n",
    "            # Utilisation de -q pour une sortie moins verbeuse, --disable-pip-version-check pour √©viter les warnings\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--disable-pip-version-check\", package_install_name])\n",
    "            logger.info(f\"‚úÖ {package_install_name} install√© avec succ√®s.\")\n",
    "            # Recharger les modules ou invalider les caches peut √™tre n√©cessaire dans certains environnements\n",
    "            importlib.invalidate_caches()\n",
    "            importlib.import_module(package_import_name) # Re-tester l'import\n",
    "            logger.info(f\"‚úîÔ∏è {package_import_name} trouv√© apr√®s installation.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå √âchec de l'installation/import de {package_install_name}: {e}\")\n",
    "            logger.warning(\"‚ÄºÔ∏è Un red√©marrage du noyau (Kernel -> Restart Kernel) peut √™tre n√©cessaire si l'import √©choue toujours.\")\n",
    "            return False\n",
    "\n",
    "logger.info(\"--- V√©rification des d√©pendances ---\")\n",
    "deps_ok = True\n",
    "deps_list = [\n",
    "    (\"jpype\", \"jpype1\"),\n",
    "    (\"semantic_kernel\", \"semantic-kernel\"),\n",
    "    (\"dotenv\", \"python-dotenv\"),\n",
    "    (\"pandas\", \"pandas\"), # N√©cessaire pour InformalAnalysisPlugin\n",
    "    (\"requests\", \"requests\") # N√©cessaire pour InformalAnalysisPlugin (t√©l√©chargement CSV)\n",
    "]\n",
    "for import_name, install_name in deps_list:\n",
    "    if not check_and_install(import_name, install_name):\n",
    "        deps_ok = False\n",
    "\n",
    "if not deps_ok:\n",
    "    logger.critical(\"\\n‚ùå Des d√©pendances cl√©s sont manquantes ou n'ont pu √™tre import√©es apr√®s installation. Veuillez v√©rifier les erreurs et red√©marrer le noyau si n√©cessaire avant de continuer.\")\n",
    "    # Optionnel: Lever une exception pour arr√™ter l'ex√©cution\n",
    "    # raise RuntimeError(\"D√©pendances manquantes ou n√©cessitant un red√©marrage du noyau.\")\n",
    "else:\n",
    "    logger.info(\"\\n‚úÖ D√©pendances principales v√©rifi√©es.\")\n",
    "\n",
    "# --- Chargement config LLM depuis .env ---\n",
    "logger.info(\"--- Chargement Configuration LLM ---\")\n",
    "load_dotenv(override=True) # `override=True` pour recharger si n√©cessaire\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_id = os.getenv(\"OPENAI_CHAT_MODEL_ID\")\n",
    "endpoint = os.getenv(\"OPENAI_ENDPOINT\") # Endpoint sp√©cifique Azure\n",
    "org_id = os.getenv(\"OPENAI_ORG_ID\") # Optionnel pour OpenAI standard\n",
    "use_azure_openai = bool(endpoint) # D√©termine si on utilise Azure en fonction de la pr√©sence de l'endpoint\n",
    "\n",
    "llm_configured = False\n",
    "if use_azure_openai:\n",
    "    # Valider la configuration Azure\n",
    "    if not all([api_key, model_id, endpoint]):\n",
    "        logger.error(\"‚ùå Configuration Azure OpenAI incompl√®te dans .env (OPENAI_API_KEY, OPENAI_CHAT_MODEL_ID, OPENAI_ENDPOINT requis).\")\n",
    "    else:\n",
    "        logger.info(f\"‚úÖ Configuration Azure OpenAI d√©tect√©e (Deployment: {model_id}, Endpoint: {endpoint[:20]}...).\")\n",
    "        llm_configured = True\n",
    "else:\n",
    "    # Valider la configuration OpenAI standard\n",
    "    if not all([api_key, model_id]):\n",
    "            logger.error(\"‚ùå Configuration OpenAI standard incompl√®te dans .env (OPENAI_API_KEY, OPENAI_CHAT_MODEL_ID requis).\")\n",
    "    else:\n",
    "        logger.info(f\"‚úÖ Configuration OpenAI standard d√©tect√©e (Mod√®le: {model_id}). Org ID: {'Fourni' if org_id else 'Non fourni'}.\")\n",
    "        llm_configured = True\n",
    "\n",
    "if not llm_configured:\n",
    "    raise ValueError(\"Configuration LLM √©chou√©e. V√©rifiez votre fichier .env et les logs ci-dessus.\")\n",
    "\n",
    "\n",
    "# Assurer que la variable use_azure_openai existe pour les cellules suivantes, m√™me si la config a √©chou√© plus t√¥t\n",
    "if 'use_azure_openai' not in locals():\n",
    "    use_azure_openai = False # D√©faut\n",
    "    logger.warning(\"Variable 'use_azure_openai' non d√©finie (erreur config?), d√©faut √† False.\")\n",
    "\n",
    "logger.info(\"--- Fin Configuration Initiale ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689b59e",
   "metadata": {},
   "source": [
    "### Configuration du LLM (via .env)\n",
    "\n",
    "Assurez-vous d'avoir un fichier `.env` avec vos identifiants LLM (voir exemple dans le notebook g√©n√©rateur ou la cellule pr√©c√©dente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Chargement de la configuration LLM depuis .env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging # Ajouter logging pour info\n",
    "\n",
    "# Configurer un logger simple si besoin\n",
    "cfg_logger = logging.getLogger(\"Orchestration.Config\")\n",
    "if not cfg_logger.handlers and not cfg_logger.propagate:\n",
    "     handler = logging.StreamHandler(); formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(name)s - %(message)s', datefmt='%H:%M:%S'); handler.setFormatter(formatter); cfg_logger.addHandler(handler); cfg_logger.setLevel(logging.INFO)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_id = os.getenv(\"OPENAI_CHAT_MODEL_ID\")\n",
    "endpoint = os.getenv(\"OPENAI_ENDPOINT\") # Endpoint sp√©cifique Azure\n",
    "org_id = os.getenv(\"OPENAI_ORG_ID\") # Optionnel pour OpenAI standard\n",
    "\n",
    "# --- D√©finition de use_azure_openai ---\n",
    "use_azure_openai = bool(endpoint)\n",
    "# ---------------------------------------\n",
    "\n",
    "# V√©rifications et logs\n",
    "if use_azure_openai:\n",
    "    if not all([api_key, model_id, endpoint]):\n",
    "        msg = \"‚ö†Ô∏è Configuration Azure OpenAI incompl√®te dans .env (OPENAI_API_KEY, OPENAI_CHAT_MODEL_ID, OPENAI_ENDPOINT requis).\"\n",
    "        cfg_logger.warning(msg)\n",
    "        print(msg)\n",
    "    else:\n",
    "         msg = f\"‚úÖ Configuration Azure OpenAI charg√©e (Deployment: {model_id}, Endpoint: {endpoint[:20]}...).\"\n",
    "         cfg_logger.info(msg)\n",
    "         print(msg)\n",
    "else:\n",
    "    if not all([api_key, model_id]):\n",
    "         msg = \"‚ö†Ô∏è Configuration OpenAI standard incompl√®te dans .env (OPENAI_API_KEY, OPENAI_CHAT_MODEL_ID requis).\"\n",
    "         cfg_logger.warning(msg)\n",
    "         print(msg)\n",
    "    else:\n",
    "        msg = f\"‚úÖ Configuration OpenAI standard charg√©e (Mod√®le: {model_id}). Org ID: {'Fourni' if org_id else 'Non fourni'}.\"\n",
    "        cfg_logger.info(msg)\n",
    "        print(msg)\n",
    "\n",
    "# S'assurer que la variable existe m√™me si la config est incompl√®te, pour √©viter NameError\n",
    "if 'use_azure_openai' not in locals():\n",
    "    use_azure_openai = False # D√©faut si erreur pr√©c√©dente\n",
    "    cfg_logger.warning(\"Variable 'use_azure_openai' non d√©finie due √† une erreur de config, d√©faut √† False.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a85e7",
   "metadata": {},
   "source": [
    "## 2. Configuration de l'environnement Java/Tweety (JPype)\n",
    "\n",
    "Cette section est **cruciale** pour utiliser les fonctionnalit√©s d'analyse logique formelle via Tweety (utilis√©es par le `PropositionalLogicAgent`).\n",
    "\n",
    "**Pr√©requis INDISPENSABLES :**\n",
    "\n",
    "1.  **Installation d'un JDK :** Vous devez avoir un Java Development Kit (JDK) version 11 ou sup√©rieure install√© sur votre syst√®me.\n",
    "2.  **Configuration de `JAVA_HOME` :** La variable d'environnement `JAVA_HOME` **doit pointer vers le r√©pertoire racine de votre installation JDK**. C'est la m√©thode la plus fiable pour que JPype trouve la JVM.\n",
    "    *   **Windows :** ex: `C:\\Program Files\\Java\\jdk-17` (Adaptez). Ajoutez aux variables d'environnement syst√®me/utilisateur.\n",
    "    *   **Linux/macOS :** ex: `/usr/lib/jvm/java-17-openjdk-amd64` ou `/Library/Java/JavaVirtualMachines/zulu-17.jdk/Contents/Home`. Ajoutez `export JAVA_HOME=/chemin/vers/jdk` √† votre `~/.bashrc`, `~/.zshrc` ou profil.\n",
    "    *   **Red√©marrage OBLIGATOIRE :** Apr√®s avoir d√©fini `JAVA_HOME`, **red√©marrez votre environnement Jupyter** (serveur JupyterLab/Notebook ET le noyau de ce notebook) pour qu'elle soit prise en compte.\n",
    "3.  **JARs Tweety :** Les fichiers `.jar` de Tweety (au moins `tweety-full-...jar` et les modules comme `logics.pl-...jar`) doivent √™tre dans le dossier `./libs/` (ou le chemin configur√© dans la cellule suivante).\n",
    "\n",
    "La cellule suivante tentera de d√©marrer la JVM via `jpype`. Elle utilise une fonction `find_java_home` pour v√©rifier `JAVA_HOME` et tenter une d√©tection automatique, mais **la d√©finition manuelle de `JAVA_HOME` est fortement recommand√©e.** La variable globale `jvm_ready` indiquera si le d√©marrage a r√©ussi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59062ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a8f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CELLULE OPTION B - Configuration Java Auto-Suffisante (Initialisation Embarqu√©e)\n",
    "# Int√©gration des fonctions valid√©es des scripts de r√©paration pour rendre le notebook autonome\n",
    "\n",
    "import jpype\n",
    "import jpype.imports\n",
    "import os\n",
    "import pathlib\n",
    "import platform\n",
    "import sys\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "logger = logging.getLogger(\"Orchestration.JPype\")\n",
    "logger.info(\"\\n--- Configuration Auto-Suffisante de la JVM (Option B - Embarqu√©e) ---\")\n",
    "\n",
    "# --- Fonctions embarqu√©es (extraites des scripts de r√©paration valid√©s) ---\n",
    "\n",
    "def find_portable_jdk() -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Localise automatiquement le JDK portable dans l'arborescence du projet.\n",
    "    Fonction extraite et valid√©e du script de r√©paration.\n",
    "    \"\"\"\n",
    "    logger.info(\"üîç Recherche JDK portable dans l'arborescence projet...\")\n",
    "    \n",
    "    # Chemins de recherche prioritaires pour le JDK portable\n",
    "    search_paths = [\n",
    "        pathlib.Path(\"MyIA.AI.Notebooks/SymbolicAI/Argument_Analysis/jdk-17-portable\"),\n",
    "        pathlib.Path(\"jdk-17-portable\"),\n",
    "        pathlib.Path(\"../jdk-17-portable\"),\n",
    "        pathlib.Path(\"../../jdk-17-portable\")\n",
    "    ]\n",
    "    \n",
    "    for base_path in search_paths:\n",
    "        if base_path.exists():\n",
    "            logger.debug(f\"  Scan du r√©pertoire: {base_path}\")\n",
    "            \n",
    "            # Chercher des sous-dossiers JDK\n",
    "            jdk_patterns = [\"*jdk*\", \"zulu*\", \"*openjdk*\", \"*corretto*\"]\n",
    "            for pattern in jdk_patterns:\n",
    "                jdk_dirs = list(base_path.glob(pattern))\n",
    "                for jdk_dir in jdk_dirs:\n",
    "                    if jdk_dir.is_dir():\n",
    "                        # V√©rifier pr√©sence de bin/java\n",
    "                        exe_suffix = \".exe\" if platform.system() == \"Windows\" else \"\"\n",
    "                        java_exe = jdk_dir / \"bin\" / f\"java{exe_suffix}\"\n",
    "                        if java_exe.exists():\n",
    "                            logger.info(f\"‚úÖ JDK portable trouv√©: {jdk_dir.absolute()}\")\n",
    "                            return str(jdk_dir.absolute())\n",
    "    \n",
    "    logger.warning(\"‚ö†Ô∏è JDK portable non trouv√© dans les chemins standards\")\n",
    "    return None\n",
    "\n",
    "def get_tweety_classpath() -> list:\n",
    "    \"\"\"\n",
    "    Construit dynamiquement le classpath avec tous les JARs Tweety disponibles.\n",
    "    Fonction extraite et valid√©e du script de r√©paration.\n",
    "    \"\"\"\n",
    "    logger.info(\"üì¶ Construction du classpath Tweety...\")\n",
    "    \n",
    "    # Chemins de recherche des JARs\n",
    "    libs_paths = [\n",
    "        pathlib.Path(\"libs\"),\n",
    "        pathlib.Path(\"MyIA.AI.Notebooks/SymbolicAI/libs\"),\n",
    "        pathlib.Path(\"../libs\")\n",
    "    ]\n",
    "    \n",
    "    jar_files = []\n",
    "    \n",
    "    for libs_path in libs_paths:\n",
    "        if libs_path.exists() and libs_path.is_dir():\n",
    "            logger.info(f\"  Scan des JARs dans: {libs_path}\")\n",
    "            found_jars = list(libs_path.glob(\"*.jar\"))\n",
    "            if found_jars:\n",
    "                jar_files.extend([str(jar.absolute()) for jar in found_jars])\n",
    "                logger.info(f\"  ‚úÖ {len(found_jars)} JARs trouv√©s dans {libs_path}\")\n",
    "                break  # Utiliser le premier r√©pertoire avec des JARs\n",
    "    \n",
    "    if jar_files:\n",
    "        logger.info(f\"‚úÖ Classpath construit: {len(jar_files)} JARs Tweety\")\n",
    "        return sorted(jar_files)  # Tri pour coh√©rence\n",
    "    else:\n",
    "        logger.error(\"‚ùå Aucun JAR Tweety trouv√© dans les chemins standards\")\n",
    "        return []\n",
    "\n",
    "def test_tweety_critical_classes():\n",
    "    \"\"\"\n",
    "    Teste l'acc√®s aux classes critiques de Tweety pour validation.\n",
    "    Utilise la classe corrig√©e d√©couverte lors du debug.\n",
    "    \"\"\"\n",
    "    logger.info(\"üéØ Test des classes critiques Tweety...\")\n",
    "    \n",
    "    critical_classes = {\n",
    "        \"InformationObject\": \"org.tweetyproject.beliefdynamics.mas.InformationObject\",\n",
    "        \"PlParser\": \"org.tweetyproject.logics.pl.parser.PlParser\",\n",
    "        \"PlFormula\": \"org.tweetyproject.logics.pl.syntax.PlFormula\",\n",
    "        \"BaseRevisionOperator\": \"org.tweetyproject.beliefdynamics.BaseRevisionOperator\"\n",
    "    }\n",
    "    \n",
    "    successful_classes = []\n",
    "    \n",
    "    for class_alias, class_name in critical_classes.items():\n",
    "        try:\n",
    "            test_class = jpype.JClass(class_name)\n",
    "            successful_classes.append(class_alias)\n",
    "            logger.info(f\"  ‚úÖ {class_alias}: Accessible\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"  ‚ö†Ô∏è {class_alias}: Inaccessible - {e}\")\n",
    "    \n",
    "    success_rate = len(successful_classes) / len(critical_classes)\n",
    "    \n",
    "    if success_rate >= 0.75:  # Au moins 75% des classes critiques\n",
    "        logger.info(f\"üèÜ Test Tweety R√âUSSI: {len(successful_classes)}/{len(critical_classes)} classes accessibles\")\n",
    "        return True\n",
    "    else:\n",
    "        logger.error(f\"‚ùå Test Tweety √âCHOU√â: {len(successful_classes)}/{len(critical_classes)} classes accessibles\")\n",
    "        return False\n",
    "\n",
    "# --- S√©quence d'initialisation embarqu√©e ---\n",
    "\n",
    "jvm_ready = False  # Variable globale d'√©tat\n",
    "\n",
    "try:\n",
    "    # √âtape 1: V√©rifier si JVM d√©j√† d√©marr√©e\n",
    "    if jpype.isJVMStarted():\n",
    "        logger.info(\"‚ÑπÔ∏è JVM d√©j√† d√©marr√©e - utilisation de l'instance existante\")\n",
    "        jvm_ready = True\n",
    "        \n",
    "        # Enregistrer les domaines au cas o√π\n",
    "        try:\n",
    "            jpype.imports.registerDomain(\"org\", alias=\"org\")\n",
    "            jpype.imports.registerDomain(\"java\", alias=\"java\")\n",
    "            jpype.imports.registerDomain(\"net\", alias=\"net\")\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        # √âtape 2: Localiser et configurer JAVA_HOME au niveau processus\n",
    "        portable_jdk = find_portable_jdk()\n",
    "        \n",
    "        if portable_jdk:\n",
    "            # Configuration dynamique de JAVA_HOME pour ce processus\n",
    "            current_java_home = os.getenv('JAVA_HOME')\n",
    "            if not current_java_home or current_java_home != portable_jdk:\n",
    "                os.environ['JAVA_HOME'] = portable_jdk\n",
    "                logger.info(f\"üè† JAVA_HOME configur√© dynamiquement: {portable_jdk}\")\n",
    "            else:\n",
    "                logger.info(f\"üè† JAVA_HOME d√©j√† configur√©: {current_java_home}\")\n",
    "        else:\n",
    "            logger.error(\"‚ùå Impossible de localiser un JDK portable - JVM pourrait √©chouer\")\n",
    "        \n",
    "        # √âtape 3: Construire le classpath Tweety complet\n",
    "        tweety_jars = get_tweety_classpath()\n",
    "        \n",
    "        if not tweety_jars:\n",
    "            raise Exception(\"Classpath Tweety vide - JARs manquants\")\n",
    "        \n",
    "        # √âtape 4: D√©marrer la JVM avec configuration optimale\n",
    "        logger.info(f\"üöÄ D√©marrage JVM avec {len(tweety_jars)} JARs Tweety...\")\n",
    "        \n",
    "        jvm_args = [\n",
    "            \"-Xmx2g\",  # M√©moire suffisante pour Tweety\n",
    "            \"-Djava.awt.headless=true\",  # Mode headless pour notebooks\n",
    "        ]\n",
    "        \n",
    "        jpype.startJVM(\n",
    "            *jvm_args,\n",
    "            classpath=tweety_jars,\n",
    "            convertStrings=False,\n",
    "            ignoreUnrecognized=True\n",
    "        )\n",
    "        \n",
    "        # √âtape 5: Enregistrer les domaines Java\n",
    "        jpype.imports.registerDomain(\"org\", alias=\"org\")\n",
    "        jpype.imports.registerDomain(\"java\", alias=\"java\")\n",
    "        jpype.imports.registerDomain(\"net\", alias=\"net\")\n",
    "        \n",
    "        logger.info(\"‚úÖ JVM d√©marr√©e avec succ√®s et domaines enregistr√©s\")\n",
    "        jvm_ready = True\n",
    "    \n",
    "    # √âtape 6: Test de validation Tweety\n",
    "    if jvm_ready:\n",
    "        # Test Java de base\n",
    "        try:\n",
    "            System = jpype.JClass('java.lang.System')\n",
    "            java_version = System.getProperty('java.version')\n",
    "            logger.info(f\"‚òï Java {java_version} op√©rationnel\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è Test Java de base √©chou√©: {e}\")\n",
    "        \n",
    "        # Test classes Tweety critiques\n",
    "        tweety_success = test_tweety_critical_classes()\n",
    "        if tweety_success:\n",
    "            logger.info(\"\\nüéâ üèÜ SUCC√àS TOTAL - INFRASTRUCTURE TWEETY AUTO-SUFFISANTE! üèÜ üéâ\")\n",
    "            logger.info(\"‚úÖ PropositionalLogicAgent pr√™t pour ex√©cution native\")\n",
    "            logger.info(\"‚úÖ Pipeline argumentatif avec int√©gration formelle/informelle op√©rationnel\")\n",
    "        else:\n",
    "            logger.warning(\"‚ö†Ô∏è JVM op√©rationnelle mais classes Tweety partiellement accessibles\")\n",
    "            jvm_ready = False\n",
    "\n",
    "except Exception as e:\n",
    "    logger.critical(f\"‚ùå ERREUR CRITIQUE Configuration Java: {e}\")\n",
    "    logger.critical(\"   PropositionalLogicAgent fonctionnera en mode d√©grad√© (LLM seulement)\")\n",
    "    jvm_ready = False\n",
    "\n",
    "# --- Conclusion √âtat JVM ---\n",
    "if jvm_ready:\n",
    "    logger.info(\"\\nüü¢ STATUT FINAL: JVM + Tweety OP√âRATIONNELS\")\n",
    "    logger.info(\"   Pipeline peut atteindre son potentiel maximal (8/10)\")\n",
    "else:\n",
    "    logger.warning(\"\\nüî¥ STATUT FINAL: JVM/Tweety NON OP√âRATIONNELS\")\n",
    "    logger.warning(\"   Pipeline fonctionnera en mode d√©grad√© (5/10)\")\n",
    "\n",
    "logger.info(\"--- Fin Configuration JPype Auto-Suffisante ---\")\n",
    "\n",
    "# === FONCTIONS UTILITAIRES INT√âGR√âES ===\n",
    "# Ces fonctions sont extraites et optimis√©es des scripts de diagnostic/r√©paration\n",
    "\n",
    "def diagnostic_infrastructure_tweety():\n",
    "    \"\"\"Fonction de diagnostic complet de l'infrastructure Tweety int√©gr√©e.\"\"\"\n",
    "    logger.info(\"üîç Diagnostic infrastructure Tweety int√©gr√©...\")\n",
    "    \n",
    "    diagnostic_results = {\n",
    "        'jdk_status': 'OK' if find_portable_jdk() else 'NOK',\n",
    "        'jars_count': len(get_tweety_classpath()),\n",
    "        'jvm_ready': jvm_ready,\n",
    "        'java_version': None\n",
    "    }\n",
    "    \n",
    "    if jvm_ready:\n",
    "        try:\n",
    "            System = jpype.JClass('java.lang.System')\n",
    "            diagnostic_results['java_version'] = System.getProperty('java.version')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    logger.info(f\"üìä R√©sultats: {diagnostic_results}\")\n",
    "    return diagnostic_results\n",
    "\n",
    "def validate_tweety_ready():\n",
    "    \"\"\"Validation rapide de l'√©tat op√©rationnel Tweety.\"\"\"\n",
    "    if not jvm_ready:\n",
    "        logger.warning(\"‚ö†Ô∏è JVM non pr√™te - PropositionalLogicAgent en mode d√©grad√©\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Test classe critique\n",
    "        InformationObject = jpype.JClass('org.tweetyproject.beliefdynamics.mas.InformationObject')\n",
    "        PlParser = jpype.JClass('org.tweetyproject.logics.pl.parser.PlParser')\n",
    "        logger.info(\"‚úÖ Tweety op√©rationnel - PropositionalLogicAgent en mode natif\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Classes Tweety inaccessibles: {e}\")\n",
    "        return False\n",
    "\n",
    "# Diagnostic automatique √† l'initialisation\n",
    "if 'jvm_ready' in locals():\n",
    "    validate_tweety_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201514e",
   "metadata": {},
   "source": [
    "## 3. D√©finitions des Composants Partag√©s\n",
    "\n",
    "Cette section d√©finit les **classes** et le **service LLM global** utilis√©s par plusieurs agents. Les **instances** sp√©cifiques (√©tat, StateManager, kernel local, agents) seront cr√©√©es plus tard, dans la fonction d'ex√©cution (Section 8).\n",
    "\n",
    "*   **`RhetoricalAnalysisState` (Classe)** : La classe Python repr√©sentant l'√©tat partag√© de l'analyse (texte brut, t√¢ches, arguments, sophismes, belief sets, r√©ponses, etc.). Inclut maintenant un logging interne plus d√©taill√©.\n",
    "*   **`StateManagerPlugin` (Classe)** : Le plugin Semantic Kernel qui fournit des fonctions (`@kernel_function`) pour lire et modifier une instance de `RhetoricalAnalysisState`. Sera initialis√© avec l'instance d'√©tat locale lors de l'ex√©cution.\n",
    "*   **`global_ai_service_instance` (Instance)** : L'instance unique du service de compl√©tion (OpenAI ou Azure) configur√©e globalement. Elle sera ajout√©e au kernel *local* de chaque agent lors de sa cr√©ation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a208e",
   "metadata": {},
   "source": [
    "### üß± Classe : RhetoricalAnalysisState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CELLULE [3.1] - D√©finition Classe RhetoricalAnalysisState\n",
    "# (Remplace une partie de l'ancienne cellule 24085a21)\n",
    "\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional\n",
    "import logging\n",
    "\n",
    "# Logger sp√©cifique pour l'√©tat\n",
    "state_logger = logging.getLogger(\"RhetoricalAnalysisState\")\n",
    "if not state_logger.handlers and not state_logger.propagate:\n",
    "    handler = logging.StreamHandler(); formatter = logging.Formatter('%(asctime)s [%(levelname)s] [%(name)s] %(message)s', datefmt='%H:%M:%S'); handler.setFormatter(formatter); state_logger.addHandler(handler); state_logger.setLevel(logging.INFO)\n",
    "\n",
    "class RhetoricalAnalysisState:\n",
    "    \"\"\"Repr√©sente l'√©tat partag√© d'une analyse rh√©torique collaborative.\"\"\"\n",
    "\n",
    "    # ... (Le code complet de la classe RhetoricalAnalysisState tel que fourni dans la r√©ponse pr√©c√©dente va ici) ...\n",
    "    # Structure des donn√©es de l'√©tat (pour r√©f√©rence)\n",
    "    raw_text: str\n",
    "    analysis_tasks: Dict[str, str] # {task_id: description}\n",
    "    identified_arguments: Dict[str, str] # {arg_id: description}\n",
    "    identified_fallacies: Dict[str, Dict[str, str]] # {fallacy_id: {type:..., justification:..., target_argument_id?:...}}\n",
    "    belief_sets: Dict[str, Dict[str, str]] # {bs_id: {logic_type:..., content:...}}\n",
    "    query_log: List[Dict[str, str]] # [{log_id:..., belief_set_id:..., query:..., raw_result:...}]\n",
    "    answers: Dict[str, Dict[str, Any]] # {task_id: {author_agent:..., answer_text:..., source_ids:[...]}}\n",
    "    final_conclusion: Optional[str]\n",
    "    _next_agent_designated: Optional[str] # Nom de l'agent d√©sign√© pour le prochain tour\n",
    "\n",
    "    def __init__(self, initial_text: str):\n",
    "        \"\"\"Initialise un √©tat vide avec le texte brut.\"\"\"\n",
    "        self.raw_text = initial_text\n",
    "        self.analysis_tasks = {}\n",
    "        self.identified_arguments = {}\n",
    "        self.identified_fallacies = {}\n",
    "        self.belief_sets = {}\n",
    "        self.query_log = []\n",
    "        self.answers = {}\n",
    "        self.final_conclusion = None\n",
    "        self._next_agent_designated = None\n",
    "        state_logger.debug(f\"Nouvelle instance RhetoricalAnalysisState cr√©√©e (id: {id(self)}) avec texte (longueur: {len(initial_text)}).\")\n",
    "\n",
    "    def _generate_id(self, prefix: str, current_dict_or_list: Any) -> str:\n",
    "        \"\"\"G√©n√®re un ID simple bas√© sur la taille actuelle.\"\"\"\n",
    "        index = 0\n",
    "        try:\n",
    "            if isinstance(current_dict_or_list, (dict, list)):\n",
    "                index = len(current_dict_or_list)\n",
    "            else:\n",
    "                 index = 0\n",
    "                 state_logger.warning(f\"_generate_id: Type inattendu '{type(current_dict_or_list)}' pour prefix '{prefix}'. Index sera 0.\")\n",
    "        except Exception as e:\n",
    "            state_logger.error(f\"Erreur dans _generate_id pour prefix '{prefix}': {e}\", exc_info=True)\n",
    "            index = 999\n",
    "        safe_index = min(index, 9999)\n",
    "        return f\"{prefix}_{safe_index + 1}\"\n",
    "\n",
    "    def add_task(self, description: str) -> str:\n",
    "        \"\"\"Ajoute une t√¢che d'analyse et retourne son ID.\"\"\"\n",
    "        task_id = self._generate_id(\"task\", self.analysis_tasks)\n",
    "        self.analysis_tasks[task_id] = description\n",
    "        state_logger.info(f\"T√¢che ajout√©e: {task_id} - '{description[:60]}...'\")\n",
    "        state_logger.debug(f\"√âtat tasks apr√®s ajout {task_id}: {self.analysis_tasks}\")\n",
    "        return task_id\n",
    "\n",
    "    def add_argument(self, description: str) -> str:\n",
    "        \"\"\"Ajoute un argument identifi√© et retourne son ID.\"\"\"\n",
    "        arg_id = self._generate_id(\"arg\", self.identified_arguments)\n",
    "        self.identified_arguments[arg_id] = description\n",
    "        state_logger.info(f\"Argument ajout√©: {arg_id} - '{description[:60]}...'\")\n",
    "        state_logger.debug(f\"√âtat arguments apr√®s ajout {arg_id}: {self.identified_arguments}\")\n",
    "        return arg_id\n",
    "\n",
    "    def add_fallacy(self, fallacy_type: str, justification: str, target_arg_id: Optional[str] = None) -> str:\n",
    "        \"\"\"Ajoute un sophisme identifi√© et retourne son ID.\"\"\"\n",
    "        fallacy_id = self._generate_id(\"fallacy\", self.identified_fallacies)\n",
    "        entry = {\"type\": fallacy_type, \"justification\": justification}\n",
    "        log_target_info = \"\"\n",
    "        if target_arg_id:\n",
    "             if target_arg_id not in self.identified_arguments:\n",
    "                 state_logger.warning(f\"ID argument cible '{target_arg_id}' pour sophisme '{fallacy_id}' non trouv√© dans les arguments identifi√©s ({list(self.identified_arguments.keys())}).\")\n",
    "             entry[\"target_argument_id\"] = target_arg_id\n",
    "             log_target_info = f\" (cible: {target_arg_id})\"\n",
    "        self.identified_fallacies[fallacy_id] = entry\n",
    "        state_logger.info(f\"Sophisme ajout√©: {fallacy_id} - Type: {fallacy_type}{log_target_info}\")\n",
    "        state_logger.debug(f\"√âtat fallacies apr√®s ajout {fallacy_id}: {self.identified_fallacies}\")\n",
    "        return fallacy_id\n",
    "\n",
    "    def add_belief_set(self, logic_type: str, content: str) -> str:\n",
    "        \"\"\"Ajoute un belief set formel et retourne son ID.\"\"\"\n",
    "        normalized_type = logic_type.strip().lower().replace(\" \", \"_\")\n",
    "        bs_id = self._generate_id(f\"{normalized_type}_bs\", self.belief_sets)\n",
    "        self.belief_sets[bs_id] = {\"logic_type\": logic_type, \"content\": content}\n",
    "        state_logger.info(f\"Belief Set ajout√©: {bs_id} - Type: {logic_type}\")\n",
    "        state_logger.debug(f\"√âtat belief_sets apr√®s ajout {bs_id}: {self.belief_sets}\")\n",
    "        return bs_id\n",
    "\n",
    "    def log_query(self, belief_set_id: str, query: str, raw_result: str) -> str:\n",
    "         \"\"\"Enregistre une requ√™te formelle et son r√©sultat brut.\"\"\"\n",
    "         log_id = self._generate_id(\"qlog\", self.query_log)\n",
    "         if belief_set_id not in self.belief_sets:\n",
    "             state_logger.warning(f\"ID Belief Set '{belief_set_id}' pour query log '{log_id}' non trouv√© dans les belief sets ({list(self.belief_sets.keys())}).\")\n",
    "         log_entry = {\"log_id\": log_id, \"belief_set_id\": belief_set_id, \"query\": query, \"raw_result\": raw_result}\n",
    "         self.query_log.append(log_entry)\n",
    "         state_logger.info(f\"Requ√™te logg√©e: {log_id} (sur BS: {belief_set_id}, Query: '{query[:60]}...')\")\n",
    "         state_logger.debug(f\"√âtat query_log apr√®s ajout {log_id} (taille: {len(self.query_log)}): {self.query_log}\")\n",
    "         return log_id\n",
    "\n",
    "    def add_answer(self, task_id: str, author_agent: str, answer_text: str, source_ids: List[str]):\n",
    "        \"\"\"Ajoute la r√©ponse d'un agent √† une t√¢che sp√©cifiques.\"\"\"\n",
    "        if task_id not in self.analysis_tasks:\n",
    "            state_logger.warning(f\"ID T√¢che '{task_id}' pour r√©ponse de '{author_agent}' non trouv√© dans les t√¢ches d√©finies ({list(self.analysis_tasks.keys())}).\")\n",
    "        self.answers[task_id] = {\"author_agent\": author_agent, \"answer_text\": answer_text, \"source_ids\": source_ids}\n",
    "        state_logger.info(f\"R√©ponse ajout√©e pour t√¢che '{task_id}' par agent '{author_agent}'.\")\n",
    "        state_logger.debug(f\"√âtat answers apr√®s ajout r√©ponse pour {task_id}: {self.answers}\")\n",
    "\n",
    "    def set_conclusion(self, conclusion: str):\n",
    "        \"\"\"Enregistre la conclusion finale de l'analyse.\"\"\"\n",
    "        self.final_conclusion = conclusion\n",
    "        state_logger.info(f\"Conclusion finale enregistr√©e : '{conclusion[:60]}...'\")\n",
    "        state_logger.debug(f\"√âtat final_conclusion apr√®s enregistrement: {self.final_conclusion is not None}\")\n",
    "\n",
    "    def designate_next_agent(self, agent_name: str):\n",
    "        \"\"\"D√©signe l'agent qui doit parler au prochain tour.\"\"\"\n",
    "        self._next_agent_designated = agent_name\n",
    "        state_logger.info(f\"Prochain agent d√©sign√©: '{agent_name}'\")\n",
    "        state_logger.debug(f\"√âtat _next_agent_designated apr√®s d√©signation: '{self._next_agent_designated}'\")\n",
    "\n",
    "    def consume_next_agent_designation(self) -> Optional[str]:\n",
    "        \"\"\"R√©cup√®re le nom de l'agent d√©sign√© et r√©initialise la d√©signation.\"\"\"\n",
    "        agent_name = self._next_agent_designated\n",
    "        self._next_agent_designated = None\n",
    "        if agent_name:\n",
    "            state_logger.info(f\"D√©signation pour '{agent_name}' consomm√©e.\")\n",
    "        return agent_name\n",
    "\n",
    "    def reset_state(self):\n",
    "        \"\"\"R√©initialise l'√©tat √† son √©tat initial (vide sauf texte brut).\"\"\"\n",
    "        state_logger.info(\">>> R√©initialisation de l'√©tat d'analyse...\")\n",
    "        initial_text = self.raw_text\n",
    "        self.__init__(initial_text)\n",
    "        assert not self.analysis_tasks, \"Reset analysis_tasks failed\"\n",
    "        assert not self.identified_arguments, \"Reset identified_arguments failed\"\n",
    "        assert not self.identified_fallacies, \"Reset identified_fallacies failed\"\n",
    "        assert not self.belief_sets, \"Reset belief_sets failed\"\n",
    "        assert not self.query_log, \"Reset query_log failed\"\n",
    "        assert not self.answers, \"Reset answers failed\"\n",
    "        assert self.final_conclusion is None, \"Reset final_conclusion failed\"\n",
    "        assert self._next_agent_designated is None, \"Reset _next_agent_designated failed\"\n",
    "        state_logger.info(\"<<< R√©initialisation de l'√©tat termin√©e et v√©rifi√©e.\")\n",
    "\n",
    "    def get_state_snapshot(self, summarize: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"Retourne un dictionnaire repr√©sentant l'√©tat actuel (complet ou r√©sum√©).\"\"\"\n",
    "        if summarize:\n",
    "             return {\n",
    "                 \"raw_text_snippet\": self.raw_text[:150] + \"...\" if len(self.raw_text) > 150 else self.raw_text,\n",
    "                 \"task_count\": len(self.analysis_tasks),\n",
    "                 \"tasks_defined\": list(self.analysis_tasks.keys()),\n",
    "                 \"argument_count\": len(self.identified_arguments),\n",
    "                 \"fallacy_count\": len(self.identified_fallacies),\n",
    "                 \"belief_set_count\": len(self.belief_sets),\n",
    "                 \"query_log_count\": len(self.query_log),\n",
    "                 \"answer_count\": len(self.answers),\n",
    "                 \"tasks_answered\": list(self.answers.keys()),\n",
    "                 \"conclusion_present\": self.final_conclusion is not None,\n",
    "                 \"next_agent_designated\": self._next_agent_designated\n",
    "             }\n",
    "        else:\n",
    "            return json.loads(self.to_json(indent=None))\n",
    "\n",
    "    def to_json(self, indent: Optional[int] = 2) -> str:\n",
    "        \"\"\"S√©rialise l'√©tat actuel en cha√Æne JSON.\"\"\"\n",
    "        state_dict = {k: v for k, v in self.__dict__.items() if not callable(v) and not k.startswith(\"_logger\")}\n",
    "        try:\n",
    "            return json.dumps(state_dict, indent=indent, ensure_ascii=False, default=str)\n",
    "        except TypeError as e:\n",
    "            state_logger.error(f\"Erreur de s√©rialisation JSON de l'√©tat: {e}\")\n",
    "            safe_dict = {k: repr(v) for k, v in state_dict.items()}\n",
    "            return json.dumps({\"error\": f\"JSON serialization failed: {e}\", \"safe_state_repr\": safe_dict}, indent=indent)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: Dict[str, Any]) -> 'RhetoricalAnalysisState':\n",
    "        \"\"\"Cr√©e une instance d'√©tat √† partir d'un dictionnaire.\"\"\"\n",
    "        state = cls(data.get('raw_text', ''))\n",
    "        state.analysis_tasks = data.get('analysis_tasks', {})\n",
    "        state.identified_arguments = data.get('identified_arguments', {})\n",
    "        state.identified_fallacies = data.get('identified_fallacies', {})\n",
    "        state.belief_sets = data.get('belief_sets', {})\n",
    "        state.query_log = data.get('query_log', [])\n",
    "        state.answers = data.get('answers', {})\n",
    "        state.final_conclusion = data.get('final_conclusion', None)\n",
    "        state._next_agent_designated = data.get('_next_agent_designated', None)\n",
    "        state_logger.debug(f\"Instance RhetoricalAnalysisState cr√©√©e depuis dict (id: {id(state)}).\")\n",
    "        return state\n",
    "\n",
    "logging.info(\"Classe RhetoricalAnalysisState d√©finie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4166a2",
   "metadata": {},
   "source": [
    "### üîå Classe Plugin : StateManagerPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61903410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CELLULE [3.2] - D√©finition Classe StateManagerPlugin\n",
    "# (Remplace une partie de l'ancienne cellule 24085a21)\n",
    "\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional\n",
    "import logging\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "# R√©cup√©rer les loggers et l'√©tat (suppos√©s d√©finis)\n",
    "# Assurer que le logger StateManager a un handler\n",
    "sm_logger = logging.getLogger(\"Orchestration.StateManager\")\n",
    "if not sm_logger.handlers and not sm_logger.propagate:\n",
    "    handler = logging.StreamHandler(); formatter = logging.Formatter('%(asctime)s [%(levelname)s] [%(name)s] %(message)s', datefmt='%H:%M:%S'); handler.setFormatter(formatter); sm_logger.addHandler(handler); sm_logger.setLevel(logging.INFO)\n",
    "# S'assurer que la classe √©tat est d√©finie\n",
    "if 'RhetoricalAnalysisState' not in globals(): raise NameError(\"Classe RhetoricalAnalysisState non d√©finie.\")\n",
    "\n",
    "\n",
    "class StateManagerPlugin:\n",
    "    \"\"\"Plugin Semantic Kernel pour lire et modifier l'√©tat d'analyse partag√©.\"\"\"\n",
    "    _state: 'RhetoricalAnalysisState' # R√©f√©rence √† l'instance d'√©tat unique\n",
    "    _logger: logging.Logger\n",
    "\n",
    "    def __init__(self, state: 'RhetoricalAnalysisState'):\n",
    "        \"\"\"Initialise le plugin avec une instance d'√©tat.\"\"\"\n",
    "        self._state = state\n",
    "        self._logger = sm_logger\n",
    "        self._logger.info(f\"StateManagerPlugin initialis√© avec l'instance RhetoricalAnalysisState (id: {id(self._state)}).\")\n",
    "\n",
    "    # ... (Le code complet de la classe StateManagerPlugin avec ses @kernel_function va ici) ...\n",
    "    # ... (Reprendre le code de la r√©ponse pr√©c√©dente pour cette classe) ...\n",
    "    @kernel_function(description=\"R√©cup√®re un aper√ßu (complet ou r√©sum√©) de l'√©tat actuel de l'analyse.\", name=\"get_current_state_snapshot\")\n",
    "    def get_current_state_snapshot(self, summarize: bool = True) -> str:\n",
    "        \"\"\"Retourne l'√©tat actuel sous forme de cha√Æne JSON.\"\"\"\n",
    "        self._logger.info(f\"Appel get_current_state_snapshot (state id: {id(self._state)}, summarize={summarize})...\")\n",
    "        try:\n",
    "            snapshot_dict = self._state.get_state_snapshot(summarize=summarize)\n",
    "            indent = 2 if not summarize else None\n",
    "            snapshot_json = json.dumps(snapshot_dict, indent=indent, ensure_ascii=False, default=str)\n",
    "            self._logger.info(\" -> Snapshot de l'√©tat g√©n√©r√© avec succ√®s.\")\n",
    "            self._logger.debug(f\" -> Snapshot (summarize={summarize}): {snapshot_json[:500] + '...' if len(snapshot_json)>500 else snapshot_json}\")\n",
    "            return snapshot_json\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Erreur lors de la r√©cup√©ration/s√©rialisation du snapshot de l'√©tat: {e}\", exc_info=True)\n",
    "            return json.dumps({\"error\": f\"Erreur r√©cup√©ration/s√©rialisation snapshot: {e}\"})\n",
    "\n",
    "    @kernel_function(description=\"Ajoute une nouvelle t√¢che d'analyse √† l'√©tat.\", name=\"add_analysis_task\")\n",
    "    def add_analysis_task(self, description: str) -> str:\n",
    "        \"\"\"Interface Kernel Function pour ajouter une t√¢che via l'√©tat.\"\"\"\n",
    "        self._logger.info(f\"Appel add_analysis_task (state id: {id(self._state)}): '{description[:60]}...'\")\n",
    "        try:\n",
    "            task_id = self._state.add_task(description)\n",
    "            self._logger.info(f\" -> T√¢che '{task_id}' ajout√©e avec succ√®s via l'√©tat.\")\n",
    "            return task_id\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Erreur lors de l'ajout de la t√¢che '{description[:60]}...': {e}\", exc_info=True)\n",
    "            return f\"FUNC_ERROR: Erreur ajout t√¢che: {e}\"\n",
    "\n",
    "    @kernel_function(description=\"Ajoute un argument identifi√© √† l'√©tat.\", name=\"add_identified_argument\")\n",
    "    def add_identified_argument(self, description: str) -> str:\n",
    "        \"\"\"Interface Kernel Function pour ajouter un argument via l'√©tat.\"\"\"\n",
    "        self._logger.info(f\"Appel add_identified_argument (state id: {id(self._state)}): '{description[:60]}...'\")\n",
    "        try:\n",
    "            arg_id = self._state.add_argument(description)\n",
    "            self._logger.info(f\" -> Argument '{arg_id}' ajout√© avec succ√®s via l'√©tat.\")\n",
    "            return arg_id\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Erreur lors de l'ajout de l'argument '{description[:60]}...': {e}\", exc_info=True)\n",
    "            return f\"FUNC_ERROR: Erreur ajout argument: {e}\"\n",
    "\n",
    "    @kernel_function(description=\"Ajoute un sophisme identifi√© √† l'√©tat.\", name=\"add_identified_fallacy\")\n",
    "    def add_identified_fallacy(self, fallacy_type: str, justification: str, target_argument_id: Optional[str] = None) -> str:\n",
    "        \"\"\"Interface Kernel Function pour ajouter un sophisme via l'√©tat.\"\"\"\n",
    "        self._logger.info(f\"Appel add_identified_fallacy (state id: {id(self._state)}): Type='{fallacy_type}', Target='{target_argument_id or 'None'}'...\")\n",
    "        try:\n",
    "            fallacy_id = self._state.add_fallacy(fallacy_type, justification, target_argument_id)\n",
    "            self._logger.info(f\" -> Sophisme '{fallacy_id}' ajout√© avec succ√®s via l'√©tat.\")\n",
    "            return fallacy_id\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Erreur lors de l'ajout du sophisme (Type: {fallacy_type}): {e}\", exc_info=True)\n",
    "            return f\"FUNC_ERROR: Erreur ajout sophisme: {e}\"\n",
    "\n",
    "    @kernel_function(description=\"Ajoute un belief set formel (ex: Propositional) √† l'√©tat.\", name=\"add_belief_set\")\n",
    "    def add_belief_set(self, logic_type: str, content: str) -> str:\n",
    "        \"\"\"Interface Kernel Function pour ajouter un belief set via l'√©tat. Valide le type logique.\"\"\"\n",
    "        self._logger.info(f\"Appel add_belief_set (state id: {id(self._state)}): Type='{logic_type}'...\")\n",
    "        valid_logic_types = {\"propositional\": \"Propositional\", \"pl\": \"Propositional\"}\n",
    "        normalized_logic_type = logic_type.strip().lower()\n",
    "\n",
    "        if normalized_logic_type not in valid_logic_types:\n",
    "            error_msg = f\"Type logique '{logic_type}' non support√©. Types valides (insensible casse): {list(valid_logic_types.keys())}\"\n",
    "            self._logger.error(error_msg)\n",
    "            return f\"FUNC_ERROR: {error_msg}\"\n",
    "\n",
    "        validated_logic_type = valid_logic_types[normalized_logic_type]\n",
    "        try:\n",
    "            bs_id = self._state.add_belief_set(validated_logic_type, content)\n",
    "            self._logger.info(f\" -> Belief Set '{bs_id}' ajout√© avec succ√®s via l'√©tat (Type: {validated_logic_type}).\")\n",
    "            return bs_id\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Erreur interne lors de l'ajout du Belief Set (Type: {validated_logic_type}): {e}\", exc_info=True)\n",
    "            return f\"FUNC_ERROR: Erreur interne ajout Belief Set: {e}\"\n",
    "\n",
    "    @kernel_function(description=\"Enregistre une requ√™te formelle et son r√©sultat brut dans le log de l'√©tat.\", name=\"log_query_result\")\n",
    "    def log_query_result(self, belief_set_id: str, query: str, raw_result: str) -> str:\n",
    "        \"\"\"Interface Kernel Function pour logger une requ√™te via l'√©tat.\"\"\"\n",
    "        self._logger.info(f\"Appel log_query_result (state id: {id(self._state)}): BS_ID='{belief_set_id}', Query='{query[:60]}...'\")\n",
    "        try:\n",
    "            log_id = self._state.log_query(belief_set_id, query, raw_result)\n",
    "            self._logger.info(f\" -> Requ√™te '{log_id}' logg√©e avec succ√®s via l'√©tat.\")\n",
    "            return log_id\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Erreur lors du logging de la requ√™te (BS_ID: {belief_set_id}): {e}\", exc_info=True)\n",
    "            return f\"FUNC_ERROR: Erreur logging requ√™te: {e}\"\n",
    "\n",
    "    @kernel_function(description=\"Ajoute une r√©ponse d'un agent √† une t√¢che d'analyse sp√©cifique dans l'√©tat.\", name=\"add_answer\")\n",
    "    def add_answer(self, task_id: str, author_agent: str, answer_text: str, source_ids: List[str]) -> str:\n",
    "        \"\"\"Interface Kernel Function pour ajouter une r√©ponse via l'√©tat.\"\"\"\n",
    "        self._logger.info(f\"Appel add_answer (state id: {id(self._state)}): TaskID='{task_id}', Author='{author_agent}'...\")\n",
    "        try:\n",
    "            self._state.add_answer(task_id, author_agent, answer_text, source_ids)\n",
    "            self._logger.info(f\" -> R√©ponse pour t√¢che '{task_id}' ajout√©e avec succ√®s via l'√©tat.\")\n",
    "            return f\"OK: R√©ponse pour {task_id} ajout√©e.\"\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Erreur lors de l'ajout de la r√©ponse pour la t√¢che '{task_id}': {e}\", exc_info=True)\n",
    "            return f\"FUNC_ERROR: Erreur ajout r√©ponse pour {task_id}: {e}\"\n",
    "\n",
    "    @kernel_function(description=\"Enregistre la conclusion finale de l'analyse dans l'√©tat.\", name=\"set_final_conclusion\")\n",
    "    def set_final_conclusion(self, conclusion: str) -> str:\n",
    "        \"\"\"Interface Kernel Function pour enregistrer la conclusion via l'√©tat.\"\"\"\n",
    "        self._logger.info(f\"Appel set_final_conclusion (state id: {id(self._state)}): '{conclusion[:60]}...'\")\n",
    "        try:\n",
    "            self._state.set_conclusion(conclusion)\n",
    "            self._logger.info(f\" -> Conclusion finale enregistr√©e avec succ√®s via l'√©tat.\")\n",
    "            return \"OK: Conclusion finale enregistr√©e.\"\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Erreur lors de l'enregistrement de la conclusion finale: {e}\", exc_info=True)\n",
    "            return f\"FUNC_ERROR: Erreur enregistrement conclusion: {e}\"\n",
    "\n",
    "    @kernel_function(description=\"D√©signe quel agent doit parler au prochain tour. Utiliser le nom EXACT de l'agent.\", name=\"designate_next_agent\")\n",
    "    def designate_next_agent(self, agent_name: str) -> str:\n",
    "        \"\"\"Interface Kernel Function pour d√©signer le prochain agent via l'√©tat.\"\"\"\n",
    "        self._logger.info(f\"Appel designate_next_agent (state id: {id(self._state)}): Prochain = '{agent_name}'\")\n",
    "        try:\n",
    "            self._state.designate_next_agent(agent_name)\n",
    "            self._logger.info(f\" -> Agent '{agent_name}' d√©sign√© avec succ√®s via l'√©tat.\")\n",
    "            return f\"OK. Agent '{agent_name}' d√©sign√© pour le prochain tour.\"\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Erreur lors de la d√©signation de l'agent '{agent_name}': {e}\", exc_info=True)\n",
    "            return f\"FUNC_ERROR: Erreur d√©signation agent {agent_name}: {e}\"\n",
    "\n",
    "\n",
    "logging.info(\"Classe StateManagerPlugin d√©finie.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a754dbe1",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Cr√©ation : Service LLM Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c09e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CELLULE [3.3] - Cr√©ation Service LLM Global\n",
    "# (Remplace une partie de l'ancienne cellule 24085a21)\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, AzureChatCompletion\n",
    "\n",
    "# R√©cup√©rer loggers et variables de config (suppos√©s d√©finis)\n",
    "llm_logger = logging.getLogger(\"Orchestration.LLM\")\n",
    "if not llm_logger.handlers and not llm_logger.propagate: # Assurer handler\n",
    "     handler = logging.StreamHandler(); formatter = logging.Formatter('%(asctime)s [%(levelname)s] [%(name)s] %(message)s', datefmt='%H:%M:%S'); handler.setFormatter(formatter); llm_logger.addHandler(handler); llm_logger.setLevel(logging.INFO)\n",
    "\n",
    "if 'api_key' not in globals() or 'model_id' not in globals() or 'use_azure_openai' not in globals():\n",
    "     raise RuntimeError(\"Variables de configuration LLM non trouv√©es. Ex√©cutez la cellule [1].\")\n",
    "\n",
    "global_ai_service_instance = None\n",
    "llm_logger.info(\"--- Configuration du Service LLM Global ---\")\n",
    "\n",
    "try:\n",
    "    if use_azure_openai:\n",
    "        llm_logger.info(\"Configuration Service Global: AzureChatCompletion...\")\n",
    "        if 'endpoint' not in globals() or not endpoint: raise ValueError(\"Endpoint Azure manquant.\")\n",
    "        global_ai_service_instance = AzureChatCompletion(\n",
    "            service_id=\"global_llm_service\",\n",
    "            deployment_name=model_id,\n",
    "            endpoint=endpoint,\n",
    "            api_key=api_key\n",
    "        )\n",
    "        llm_logger.info(f\"Service LLM global Azure ({model_id}) cr√©√©.\")\n",
    "    else:\n",
    "        llm_logger.info(\"Configuration Service Global: OpenAIChatCompletion...\")\n",
    "        if 'org_id' not in globals(): org_id = None # Assurer existence\n",
    "        global_ai_service_instance = OpenAIChatCompletion(\n",
    "            service_id=\"global_llm_service\",\n",
    "            ai_model_id=model_id,\n",
    "            api_key=api_key,\n",
    "            org_id=org_id\n",
    "        )\n",
    "        llm_logger.info(f\"Service LLM global OpenAI ({model_id}) cr√©√©.\")\n",
    "except Exception as e:\n",
    "    llm_logger.critical(f\"Erreur critique lors de la cr√©ation du service LLM global: {e}\", exc_info=True)\n",
    "    raise RuntimeError(f\"Impossible de configurer le service LLM global: {e}\")\n",
    "\n",
    "if not global_ai_service_instance:\n",
    "     raise RuntimeError(\"Configuration du service LLM global a √©chou√© silencieusement.\")\n",
    "\n",
    "logging.info(\"--- Fin D√©finitions Composants Partag√©s ---\")\n",
    "\n",
    "# Rappel: PAS d'instance de RhetoricalAnalysisState ou StateManagerPlugin ou Kernel ici."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c485ec",
   "metadata": {},
   "source": [
    "## 4. Agent : üßë‚Äçüè´ ProjectManagerAgent (D√©finitions)\n",
    "\n",
    "Cet agent est responsable de l'orchestration globale de l'analyse.\n",
    "\n",
    "**R√¥le :**\n",
    "*   Analyser la demande initiale et l'√©tat actuel (`StateManager.get_current_state_snapshot`).\n",
    "*   D√©finir les t√¢ches d'analyse pour les agents sp√©cialistes (`StateManager.add_analysis_task` via `PM.semantic_DefineTasksAndDelegate`).\n",
    "*   Assigner les t√¢ches et d√©signer le prochain agent √† intervenir (`StateManager.designate_next_agent`). **Attention:** Doit utiliser le nom exact de l'agent (e.g., `PropositionalLogicAgent`).\n",
    "*   Suivre l'avancement en consultant l'√©tat (t√¢ches d√©finies vs t√¢ches r√©pondues).\n",
    "*   Synth√©tiser les r√©sultats une fois les analyses pertinentes termin√©es (`StateManager.set_final_conclusion` via `PM.semantic_WriteAndSetConclusion`).\n",
    "\n",
    "**Composants D√©finis Ci-dessous :**\n",
    "*   `ProjectManagerPlugin` (Classe)\n",
    "*   Prompts S√©mantiques (`prompt_define_tasks_v10`, `prompt_write_conclusion_v6`)\n",
    "*   Fonction de configuration `setup_pm_kernel`\n",
    "*   Instructions Syst√®me `PM_INSTRUCTIONS` (V8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a615c6",
   "metadata": {},
   "source": [
    "### üîå Classe Plugin et üìú Prompts S√©mantiques (PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafcee0",
   "metadata": {},
   "outputs": [],
   "source": "# %% CELLULE [4.1] - PM Plugin et Prompts Semantiques\n# (Remplace une partie de l'ancienne cellule a5621670)\n# V17 - CODE-ONLY: Literal function calls to copy, no improvisation\n\nimport logging\n\nlogger = logging.getLogger(\"Orchestration.AgentPM.Defs\")\n\n# --- Plugin Specifique PM (Vide actuellement) ---\nclass ProjectManagerPlugin:\n    \"\"\"Plugin pour fonctions natives specifiques au Project Manager (si necessaire).\"\"\"\n    pass\n\n# --- Fonctions Semantiques PM ---\n\n# Aide a la planification (V17 - CODE-ONLY approach)\nprompt_define_tasks_v17 = \"\"\"\nVous etes ProjectManagerAgent.\n\nEtat actuel: {{$analysis_state_snapshot}}\n\nINSTRUCTION UNIQUE: Executez EXACTEMENT UN des blocs de code ci-dessous selon la valeur de tasks_answered.\n\n===== SI tasks_answered EST VIDE ([]) =====\nExecutez ces 2 appels de fonction:\nStateManager.add_analysis_task(description=\"task_id: task_1\\\\ntitle: Identifier les arguments principaux\\\\nAgent: InformalAnalysisAgent\")\nStateManager.designate_next_agent(agent_name=\"InformalAnalysisAgent\")\nPuis ecrivez: \"Tache 1 creee pour InformalAnalysisAgent.\"\nFIN.\n\n===== SI tasks_answered CONTIENT 1 ELEMENT ([\"task_1\"]) =====\nExecutez ces 2 appels de fonction:\nStateManager.add_analysis_task(description=\"task_id: task_2\\\\ntitle: Analyser les sophismes\\\\nAgent: InformalAnalysisAgent\")\nStateManager.designate_next_agent(agent_name=\"InformalAnalysisAgent\")\nPuis ecrivez: \"Tache 2 creee pour InformalAnalysisAgent.\"\nFIN.\n\n===== SI tasks_answered CONTIENT 2 ELEMENTS ([\"task_1\", \"task_2\"]) =====\nExecutez ces 2 appels de fonction:\nStateManager.add_analysis_task(description=\"task_id: task_3\\\\ntitle: Traduire en logique propositionnelle\\\\nAgent: PropositionalLogicAgent\")\nStateManager.designate_next_agent(agent_name=\"PropositionalLogicAgent\")\nPuis ecrivez: \"Tache 3 creee pour PropositionalLogicAgent.\"\nFIN.\n\n===== SI tasks_answered CONTIENT 3 ELEMENTS ET belief_set_count > 0 =====\nExecutez ces 2 appels de fonction:\nStateManager.add_analysis_task(description=\"task_id: task_4\\\\ntitle: Executer requetes PL\\\\nAgent: PropositionalLogicAgent\")\nStateManager.designate_next_agent(agent_name=\"PropositionalLogicAgent\")\nPuis ecrivez: \"Tache 4 creee pour PropositionalLogicAgent.\"\nFIN.\n\n===== SI tasks_answered CONTIENT 4 ELEMENTS ET query_log_count > 0 =====\nExecutez:\nStateManager.set_final_conclusion(conclusion=\"Analyse terminee: [resume des arguments, sophismes, belief set, requetes]\")\nFIN.\n\n===== SI UNE TACHE EST EN COURS (len(tasks_defined) > len(tasks_answered)) =====\nNE PAS creer de tache.\nEcrivez uniquement: \"J'attends la reponse pour la tache en cours.\"\nFIN.\n\nREGLE ABSOLUE: Copiez les appels de fonction EXACTEMENT comme indique. Ne modifiez pas les descriptions. Ne creez pas d'autres taches.\n\"\"\"\n\n# Aide a la conclusion (V8)\nprompt_write_conclusion_v8 = \"\"\"\n[Contexte]\nVous etes le ProjectManagerAgent. On vous demande de conclure l'analyse.\n\n[CONDITIONS OBLIGATOIRES pour conclure]\n- argument_count > 0\n- belief_set_count > 0\n- query_log_count > 0\n\nSi ces conditions ne sont pas remplies, NE PAS conclure.\n\n[Etat Final]\n{{$analysis_state_snapshot}}\n\n[Texte Original]\n{{$raw_text}}\n\n[Instructions]\nSynthetisez les resultats (arguments, sophismes, belief sets, requetes PL) en une conclusion.\nAppelez StateManager.set_final_conclusion avec votre synthese.\n\"\"\"\n\n# Variables pour compatibilite\nprompt_define_tasks_v10 = prompt_define_tasks_v17\nprompt_define_tasks_v11 = prompt_define_tasks_v17\nprompt_define_tasks_v12 = prompt_define_tasks_v17\nprompt_define_tasks_v13 = prompt_define_tasks_v17\nprompt_define_tasks_v14 = prompt_define_tasks_v17\nprompt_define_tasks_v15 = prompt_define_tasks_v17\nprompt_define_tasks_v16 = prompt_define_tasks_v17\nprompt_write_conclusion_v6 = prompt_write_conclusion_v8\nprompt_write_conclusion_v7 = prompt_write_conclusion_v8\n\nlogger.info(\"Plugin PM (vide) et prompts semantiques (V17 - CODE-ONLY) definis.\")"
  },
  {
   "cell_type": "markdown",
   "id": "036e58ad",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Fonction : setup_pm_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CELLULE [4.2] - Fonction setup_pm_kernel\n",
    "# (Remplace une partie de l'ancienne cellule a5621670)\n",
    "# V11 - Fix allow_dangerously_set_content pour Semantic Kernel 1.0+\n",
    "\n",
    "import semantic_kernel as sk\n",
    "import logging\n",
    "\n",
    "# S'assurer que les dependances sont la\n",
    "if 'ProjectManagerPlugin' not in globals(): raise NameError(\"Classe ProjectManagerPlugin non definie.\")\n",
    "if 'prompt_define_tasks_v10' not in globals(): raise NameError(\"Prompt prompt_define_tasks_v10 non defini.\")\n",
    "if 'prompt_write_conclusion_v6' not in globals(): raise NameError(\"Prompt prompt_write_conclusion_v6 non defini.\")\n",
    "\n",
    "logger = logging.getLogger(\"Orchestration.AgentPM.Setup\")\n",
    "\n",
    "# Tenter d'importer les classes de configuration de prompt (SK 1.0+)\n",
    "try:\n",
    "    from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "    SK_HAS_INPUT_VARIABLE = True\n",
    "    logger.debug(\"SK 1.0+ detecte avec InputVariable/PromptTemplateConfig\")\n",
    "except ImportError:\n",
    "    SK_HAS_INPUT_VARIABLE = False\n",
    "    logger.debug(\"SK < 1.0 detecte, pas de InputVariable\")\n",
    "\n",
    "def setup_pm_kernel(kernel: sk.Kernel, llm_service):\n",
    "    \"\"\"Ajoute le plugin PM et ses fonctions semantiques au kernel donne.\"\"\"\n",
    "    plugin_name = \"PM\"\n",
    "    logger.info(f\"Configuration Kernel pour {plugin_name} (V11 - Fix allow_dangerously_set_content)...\")\n",
    "\n",
    "    if plugin_name not in kernel.plugins:\n",
    "        kernel.add_plugin(ProjectManagerPlugin(), plugin_name=plugin_name)\n",
    "        logger.debug(f\"Plugin natif '{plugin_name}' ajoute au kernel PM.\")\n",
    "    else:\n",
    "        logger.debug(f\"Plugin natif '{plugin_name}' deja present dans le kernel PM.\")\n",
    "\n",
    "    default_settings = None\n",
    "    if llm_service:\n",
    "        try:\n",
    "            default_settings = kernel.get_prompt_execution_settings_from_service_id(llm_service.service_id)\n",
    "            logger.debug(f\"Settings LLM recuperes pour {plugin_name}.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Impossible de recuperer les settings LLM pour {plugin_name}: {e}\")\n",
    "\n",
    "    # Configuration pour SK 1.0+ avec allow_dangerously_set_content\n",
    "    prompt_config_define = None\n",
    "    prompt_config_conclusion = None\n",
    "    \n",
    "    if SK_HAS_INPUT_VARIABLE:\n",
    "        # Configuration des variables d'entree avec allow_dangerously_set_content=True\n",
    "        # Necessaire pour Semantic Kernel 1.0+ qui requiert un encodage explicite\n",
    "        input_variables_define_tasks = [\n",
    "            InputVariable(\n",
    "                name=\"analysis_state_snapshot\",\n",
    "                description=\"JSON snapshot de l'etat actuel de l'analyse\",\n",
    "                is_required=True,\n",
    "                allow_dangerously_set_content=True\n",
    "            ),\n",
    "            InputVariable(\n",
    "                name=\"raw_text\",\n",
    "                description=\"Texte brut a analyser\",\n",
    "                is_required=True,\n",
    "                allow_dangerously_set_content=True\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        input_variables_conclusion = [\n",
    "            InputVariable(\n",
    "                name=\"analysis_state_snapshot\",\n",
    "                description=\"JSON snapshot de l'etat final de l'analyse\",\n",
    "                is_required=True,\n",
    "                allow_dangerously_set_content=True\n",
    "            ),\n",
    "            InputVariable(\n",
    "                name=\"raw_text\",\n",
    "                description=\"Texte brut original\",\n",
    "                is_required=True,\n",
    "                allow_dangerously_set_content=True\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Configuration du template pour DefineTasksAndDelegate\n",
    "        prompt_config_define = PromptTemplateConfig(\n",
    "            template=prompt_define_tasks_v10,\n",
    "            name=\"semantic_DefineTasksAndDelegate\",\n",
    "            description=\"Definit la PROCHAINE tache unique, l'enregistre, designe 1 agent (Nom Exact Requis).\",\n",
    "            input_variables=input_variables_define_tasks\n",
    "        )\n",
    "\n",
    "        # Configuration du template pour WriteAndSetConclusion\n",
    "        prompt_config_conclusion = PromptTemplateConfig(\n",
    "            template=prompt_write_conclusion_v6,\n",
    "            name=\"semantic_WriteAndSetConclusion\",\n",
    "            description=\"Redige/enregistre conclusion finale (avec pre-verification etat).\",\n",
    "            input_variables=input_variables_conclusion\n",
    "        )\n",
    "        logger.debug(\"PromptTemplateConfig crees avec allow_dangerously_set_content=True\")\n",
    "\n",
    "    # Ajout de la fonction DefineTasksAndDelegate\n",
    "    try:\n",
    "        if prompt_config_define:\n",
    "            # SK 1.0+ avec PromptTemplateConfig\n",
    "            kernel.add_function(\n",
    "                prompt_template_config=prompt_config_define,\n",
    "                plugin_name=plugin_name,\n",
    "                function_name=\"semantic_DefineTasksAndDelegate\",\n",
    "                prompt_execution_settings=default_settings\n",
    "            )\n",
    "            logger.debug(f\"Fonction {plugin_name}.semantic_DefineTasksAndDelegate (V11 avec config) ajoutee.\")\n",
    "        else:\n",
    "            # Fallback pour anciennes versions\n",
    "            kernel.add_function(\n",
    "                prompt=prompt_define_tasks_v10,\n",
    "                plugin_name=plugin_name, \n",
    "                function_name=\"semantic_DefineTasksAndDelegate\",\n",
    "                description=\"Definit la PROCHAINE tache unique, l'enregistre, designe 1 agent (Nom Exact Requis).\",\n",
    "                prompt_execution_settings=default_settings\n",
    "            )\n",
    "            logger.debug(f\"Fonction {plugin_name}.semantic_DefineTasksAndDelegate (mode legacy) ajoutee.\")\n",
    "    except Exception as e: \n",
    "        logger.error(f\"Echec ajout {plugin_name}.semantic_DefineTasksAndDelegate: {e}\")\n",
    "\n",
    "    # Ajout de la fonction WriteAndSetConclusion\n",
    "    try:\n",
    "        if prompt_config_conclusion:\n",
    "            # SK 1.0+ avec PromptTemplateConfig\n",
    "            kernel.add_function(\n",
    "                prompt_template_config=prompt_config_conclusion,\n",
    "                plugin_name=plugin_name,\n",
    "                function_name=\"semantic_WriteAndSetConclusion\",\n",
    "                prompt_execution_settings=default_settings\n",
    "            )\n",
    "            logger.debug(f\"Fonction {plugin_name}.semantic_WriteAndSetConclusion (V11 avec config) ajoutee.\")\n",
    "        else:\n",
    "            # Fallback pour anciennes versions\n",
    "            kernel.add_function(\n",
    "                prompt=prompt_write_conclusion_v6,\n",
    "                plugin_name=plugin_name, \n",
    "                function_name=\"semantic_WriteAndSetConclusion\",\n",
    "                description=\"Redige/enregistre conclusion finale (avec pre-verification etat).\",\n",
    "                prompt_execution_settings=default_settings\n",
    "            )\n",
    "            logger.debug(f\"Fonction {plugin_name}.semantic_WriteAndSetConclusion (mode legacy) ajoutee.\")\n",
    "    except Exception as e: \n",
    "        logger.error(f\"Echec ajout {plugin_name}.semantic_WriteAndSetConclusion: {e}\")\n",
    "\n",
    "    logger.info(f\"Kernel {plugin_name} configure (V11).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9bb59a",
   "metadata": {},
   "source": [
    "### üìú Instructions Syst√®me : PM_INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a524ce",
   "metadata": {},
   "outputs": [],
   "source": "# %% CELLULE [4.3] - Instructions Systeme PM\n# (Remplace une partie de l'ancienne cellule a5621670)\n# V15 - CODE-ONLY: Match prompt V17 approach\n\nimport logging\n\nlogger = logging.getLogger(\"Orchestration.AgentPM.Instructions\")\n\n# Instructions Systeme PM (V15 - CODE-ONLY approach)\nPM_INSTRUCTIONS_V15 = \"\"\"\nVous etes le ProjectManagerAgent.\n\nVOTRE SEULE TACHE: Executer les appels de fonction decrits dans votre prompt selon l'etat actuel.\n\nSEQUENCE DES 4 TACHES:\n| Condition | Tache | Agent |\n|-----------|-------|-------|\n| tasks_answered vide | task_1: Arguments | InformalAnalysisAgent |\n| tasks_answered = 1 | task_2: Sophismes | InformalAnalysisAgent |\n| tasks_answered = 2 | task_3: Traduction PL | PropositionalLogicAgent |\n| tasks_answered = 3 + belief_set | task_4: Requetes PL | PropositionalLogicAgent |\n| tasks_answered = 4 + queries | Conclusion | Vous |\n\nREGLES:\n1. Copiez EXACTEMENT les appels de fonction du prompt\n2. Ne modifiez pas les descriptions de taches\n3. Ne creez pas de taches supplementaires\n4. task_3 et task_4 = PropositionalLogicAgent (JAMAIS InformalAnalysisAgent)\n\nINTERDIT:\n- Creer des taches de verification factuelle\n- Improviser de nouvelles taches\n- Appeler add_answer (reserve aux specialistes)\n\"\"\"\n\nPM_INSTRUCTIONS_V14 = PM_INSTRUCTIONS_V15\nPM_INSTRUCTIONS_V13 = PM_INSTRUCTIONS_V15\nPM_INSTRUCTIONS = PM_INSTRUCTIONS_V15\n\nlogger.info(\"Instructions Systeme PM_INSTRUCTIONS (V15 - CODE-ONLY) definies.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}