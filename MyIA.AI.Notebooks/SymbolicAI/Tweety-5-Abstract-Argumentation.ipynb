{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argumentation Abstraite et Structuree\n",
    "\n",
    "Ce notebook couvre les frameworks Dung, ASPIC+, DeLP, ABA et ASP.\n",
    "\n",
    "**Pre-requis**: Executez d'abord [Tweety-1-Setup.ipynb](Tweety-1-Setup.ipynb) pour configurer l'environnement.\n",
    "\n",
    "**Navigation**: [Precedent](Tweety-4-Belief-Revision.ipynb) | [Suivant](Tweety-6-Advanced-Argumentation.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# --- Initialisation JVM Tweety + Outils Externes ---\nprint(\"--- Verification JVM Tweety ---\")\njvm_ready = False\n\nimport jpype\nimport jpype.imports\nimport os\nimport pathlib\nimport shutil\nimport platform\n\n# === Configuration des outils externes (standalone) ===\nEXTERNAL_TOOLS = {\n    \"CLINGO\": \"\",\n    \"SPASS\": \"\",\n}\n\ndef get_tool_path(tool_name):\n    \"\"\"Retourne le chemin valide d'un outil ou None.\"\"\"\n    path_str = EXTERNAL_TOOLS.get(tool_name, \"\")\n    if not path_str: \n        return None\n    if shutil.which(path_str):\n        return path_str\n    path_obj = pathlib.Path(path_str)\n    if path_obj.is_file():\n        return str(path_obj.resolve())\n    # Also check if it's a directory (for Tweety compatibility)\n    if path_obj.is_dir():\n        return str(path_obj.resolve())\n    return None\n\n# Auto-detection Clingo (binaire)\n# IMPORTANT: TweetyProject ClingoSolver expects a DIRECTORY path, not the full executable path.\n# It appends \"/clingo\" (Unix) or \"/clingo.exe\" (Windows) internally when invoking the solver.\nclingo_paths = [\n    shutil.which(\"clingo\"),\n    shutil.which(\"clingo.exe\"),\n    pathlib.Path(\"ext_tools/clingo/clingo.exe\"),\n    pathlib.Path(\"Argument_Analysis/ext_tools/clingo/clingo.exe\"),\n    pathlib.Path(\"../ext_tools/clingo/clingo.exe\"),\n]\nfor cp in clingo_paths:\n    if cp:\n        if isinstance(cp, str):\n            # For system PATH clingo, use the directory containing it\n            cp_path = pathlib.Path(cp)\n            EXTERNAL_TOOLS[\"CLINGO\"] = str(cp_path.parent.resolve())\n            break\n        elif cp.exists():\n            # For local clingo.exe, store the DIRECTORY path (parent)\n            EXTERNAL_TOOLS[\"CLINGO\"] = str(cp.parent.resolve())\n            break\n\n# Auto-detection SPASS\nspass_paths = [\n    shutil.which(\"SPASS\"),\n    shutil.which(\"SPASS.exe\"),\n    pathlib.Path(\"ext_tools/spass/SPASS.exe\"),\n    pathlib.Path(\"Argument_Analysis/ext_tools/spass/SPASS.exe\"),\n    pathlib.Path(\"../ext_tools/spass/SPASS.exe\"),\n]\nfor sp in spass_paths:\n    if sp:\n        if isinstance(sp, str):\n            EXTERNAL_TOOLS[\"SPASS\"] = sp\n            break\n        elif sp.exists():\n            EXTERNAL_TOOLS[\"SPASS\"] = str(sp.resolve())\n            break\n\n# === Initialisation JVM ===\nif jpype.isJVMStarted():\n    print(\"JVM deja en cours d'execution.\")\n    jvm_ready = True\nelse:\n    jdk_portable = pathlib.Path(\"jdk-17-portable\")\n    if not jdk_portable.exists():\n        jdk_portable = pathlib.Path(\"Argument_Analysis/jdk-17-portable\")\n    \n    if jdk_portable.exists():\n        zulu_dirs = list(jdk_portable.glob(\"zulu*\"))\n        if zulu_dirs:\n            java_home = zulu_dirs[0]\n            os.environ[\"JAVA_HOME\"] = str(java_home.resolve())\n            print(f\"JDK portable trouve: {java_home.name}\")\n    \n    if not os.environ.get(\"JAVA_HOME\"):\n        print(\"ERREUR: JAVA_HOME non defini et JDK portable non trouve.\")\n        print(\"JVM non disponible.\")\n    else:\n        LIB_DIR = pathlib.Path(\"libs\")\n        if not LIB_DIR.exists():\n            LIB_DIR = pathlib.Path(\"Argument_Analysis/libs\")\n        \n        if LIB_DIR.exists():\n            jar_files = list(LIB_DIR.glob(\"*.jar\"))\n            if jar_files:\n                classpath = os.pathsep.join(str(j.resolve()) for j in jar_files)\n                try:\n                    jpype.startJVM(classpath=[classpath])\n                    print(f\"JVM demarree avec {len(jar_files)} JARs.\")\n                    jvm_ready = True\n                except Exception as e:\n                    print(f\"Erreur demarrage JVM: {e}\")\n\nif jvm_ready:\n    print(\"JVM prete pour Tweety.\")\n    tools = [t for t, p in EXTERNAL_TOOLS.items() if p]\n    if tools:\n        print(f\"Outils externes: {', '.join(tools)}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9f36b8ea",
   "metadata": {},
   "source": [
    "## Partie 4 : Argumentation Abstraite et Structurée\n",
    "<a id=\"partie4\"></a>\n",
    "\n",
    "Nous entrons maintenant au cœur de l'argumentation computationnelle, en commençant par le cadre fondateur de Dung et en progressant vers des approches qui prennent en compte la structure interne des arguments. Cette partie est souvent plus stable car elle repose sur des modules centraux de Tweety."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772b0f0",
   "metadata": {},
   "source": [
    "### 4.1 Cadres d'Argumentation Abstraits (Dung)\n",
    "<a id=\"4.1\"></a>\n",
    "\n",
    "Le cadre de Dung (Abstract Argumentation Framework - AAF) est la base de nombreuses extensions. Il modélise les conflits entre arguments de manière abstraite.\n",
    "\n",
    "* Un ensemble d'**Arguments** (`Argument`) considérés comme des entités atomiques.\n",
    "* Une relation d'**Attaque** (`Attack`) binaire entre arguments ($a$ attaque $b$).\n",
    "* L'ensemble forme une **Théorie de Dung** (`DungTheory`).\n",
    "\n",
    "L'objectif est de déterminer des ensembles d'arguments collectivement acceptables, appelés **extensions**, selon différentes **sémantiques** (Conflict-Free, Admissible, Complete, Grounded, Preferred, Stable, etc.). Tweety fournit des **raisonneurs** (`org.tweetyproject.arg.dung.reasoner.*`) pour calculer ces extensions.\n",
    "\n",
    "* **Conflict-Free (CF)**: Aucun argument dans l'extension n'attaque un autre argument de l'extension.\n",
    "* **Admissible (ADM)**: Conflict-Free + chaque argument de l'extension est défendu par l'extension contre ses attaquants.\n",
    "* **Complete (COM)**: Admissible + contient tous les arguments qu'elle défend.\n",
    "* **Grounded (GR)**: L'extension complète minimale (calculée itérativement, sceptique).\n",
    "* **Preferred (PRF)**: Une extension complète maximale (par inclusion). Il peut y en avoir plusieurs (crédule).\n",
    "* **Stable (ST)**: Conflict-Free + attaque tous les arguments qui ne sont pas dans l'extension. Peut ne pas exister, mais si elle existe, elle est aussi Preferred et Complete.\n",
    "* **CF2**: Sémantique gérant les cycles impairs via la décomposition en Composantes Fortement Connexes (SCC).\n",
    "\n",
    "Tweety fournit des **raisonneurs** (`org.tweetyproject.arg.dung.reasoner.*`) pour calculer ces extensions (ex: `SimpleGroundedReasoner`, `SimpleStableReasoner`, `SccCF2Reasoner`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c07b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.1.1 Cadres d'Argumentation Abstraits (Dung) : Bases et Sémantiques ---\n",
      "❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\n"
     ]
    }
   ],
   "source": [
    "# --- 4.1.1 Cadres d'Argumentation Abstraits (Dung) : Bases et Sémantiques ---\n",
    "print(\"\\n--- 4.1.1 Cadres d'Argumentation Abstraits (Dung) : Bases et Sémantiques ---\")\n",
    "\n",
    "# Vérifier si la JVM est prête\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple Dung...\")\n",
    "    try:\n",
    "        # Imports nécessaires pour Dung\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "        # Importer plusieurs raisonneurs\n",
    "        from org.tweetyproject.arg.dung.reasoner import (\n",
    "            SimpleGroundedReasoner, SimpleStableReasoner, SimplePreferredReasoner,\n",
    "            SimpleCompleteReasoner, SimpleAdmissibleReasoner, SimpleConflictFreeReasoner\n",
    "        )\n",
    "        # Importer Semantics si besoin pour certains raisonneurs plus avancés (non utilisés ici)\n",
    "        # from org.tweetyproject.arg.dung.semantics import Semantics\n",
    "        from java.util import Collection # Pour vérifier taille retour\n",
    "\n",
    "        print(\"✔️ Imports Dung réussis.\")\n",
    "\n",
    "        # --- Exemple 1: A <-> B -> C ---\n",
    "        af1 = DungTheory()\n",
    "        a1 = Argument(\"a1\"); b1 = Argument(\"b1\"); c1 = Argument(\"c1\")\n",
    "        # Ajouter des arguments\n",
    "        af1.add(a1); af1.add(b1); af1.add(c1)\n",
    "        # Ajouter des attaques\n",
    "        af1.add(Attack(a1, b1)); af1.add(Attack(b1, a1)); af1.add(Attack(b1, c1))\n",
    "\n",
    "        print(\"\\n--- AF1: a1 <-> b1 -> c1 ---\")\n",
    "        print(\"Cadre :\", af1)\n",
    "\n",
    "        # Calculer les extensions pour différentes sémantiques\n",
    "        print(\"\\nCalcul des extensions pour AF1:\")\n",
    "        try:\n",
    "            # Grounded: getModel() retourne une Extension, getModels() retourne une Collection<Extension>\n",
    "            grounded_ext = SimpleGroundedReasoner().getModel(af1) # Plus direct pour grounded\n",
    "            print(f\" - Grounded   : {{{grounded_ext}}}\") # Afficher comme un ensemble pour la cohérence\n",
    "        except Exception as e: print(f\"   Erreur Grounded: {e}\")\n",
    "        try:\n",
    "            stable_exts = SimpleStableReasoner().getModels(af1)\n",
    "            print(f\" - Stable     ({stable_exts.size()}):\", stable_exts)\n",
    "        except Exception as e: print(f\"   Erreur Stable: {e}\")\n",
    "        try:\n",
    "            preferred_exts = SimplePreferredReasoner().getModels(af1)\n",
    "            print(f\" - Preferred  ({preferred_exts.size()}):\", preferred_exts)\n",
    "        except Exception as e: print(f\"   Erreur Preferred: {e}\")\n",
    "        try:\n",
    "            complete_exts = SimpleCompleteReasoner().getModels(af1)\n",
    "            print(f\" - Complete   ({complete_exts.size()}):\", complete_exts)\n",
    "        except Exception as e: print(f\"   Erreur Complete: {e}\")\n",
    "        try:\n",
    "            admissible_exts = SimpleAdmissibleReasoner().getModels(af1)\n",
    "            # Convertir la Collection Java en liste Python pour len()\n",
    "            # Note: Cela peut être coûteux si la collection est énorme\n",
    "            admissible_list = list(admissible_exts)\n",
    "            print(f\" - Admissible ({len(admissible_list)}):\", admissible_exts) # Afficher la collection Java\n",
    "        except Exception as e: print(f\"   Erreur Admissible: {e}\")\n",
    "        try:\n",
    "            conflict_free_exts = SimpleConflictFreeReasoner().getModels(af1)\n",
    "            cf_list = list(conflict_free_exts)\n",
    "            print(f\" - ConflictFree ({len(cf_list)}):\", conflict_free_exts) # Attention, peut être très grand\n",
    "        except Exception as e: print(f\"   Erreur ConflictFree: {e}\")\n",
    "\n",
    "\n",
    "        # --- Exemple 2: Cycle a->b->c->a ---\n",
    "        af_cycle = DungTheory()\n",
    "        a_cy = Argument(\"a_cy\"); b_cy = Argument(\"b_cy\"); c_cy = Argument(\"c_cy\")\n",
    "        af_cycle.add(a_cy); af_cycle.add(b_cy); af_cycle.add(c_cy)\n",
    "        af_cycle.add(Attack(a_cy, b_cy)); af_cycle.add(Attack(b_cy, c_cy)); af_cycle.add(Attack(c_cy, a_cy))\n",
    "\n",
    "        print(\"\\n--- AF Cycle: a -> b -> c -> a ---\")\n",
    "        print(\"Cadre :\", af_cycle)\n",
    "        print(\"\\nCalcul des extensions pour AF Cycle:\")\n",
    "        try:\n",
    "            print(\" - Grounded   :\", SimpleGroundedReasoner().getModel(af_cycle)) # {}\n",
    "        except Exception as e: print(f\"   Erreur Grounded: {e}\")\n",
    "        try:\n",
    "            stable_exts_cy = SimpleStableReasoner().getModels(af_cycle)\n",
    "            print(f\" - Stable     ({stable_exts_cy.size()}):\", stable_exts_cy) # {}\n",
    "        except Exception as e: print(f\"   Erreur Stable: {e}\")\n",
    "        try:\n",
    "            preferred_exts_cy = SimplePreferredReasoner().getModels(af_cycle)\n",
    "            print(f\" - Preferred  ({preferred_exts_cy.size()}):\", preferred_exts_cy) # [{}]\n",
    "        except Exception as e: print(f\"   Erreur Preferred: {e}\")\n",
    "        try:\n",
    "            complete_exts_cy = SimpleCompleteReasoner().getModels(af_cycle)\n",
    "            print(f\" - Complete   ({complete_exts_cy.size()}):\", complete_exts_cy) # [{}]\n",
    "        except Exception as e: print(f\"   Erreur Complete: {e}\")\n",
    "\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour l'Argumentation Abstraite : {e}\")\n",
    "        print(\"   Vérifiez le JAR 'org.tweetyproject.arg.dung'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple Dung: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace()) # Décommenter pour trace Java complète\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple Dung: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd9e2eb",
   "metadata": {},
   "source": [
    "#### 4.1.2 Sémantique CF2\n",
    "<a id=\"4.1.2\"></a>\n",
    "\n",
    "La sémantique CF2 ([Baroni, Giacomin, Guida, *SCC-recursive semantics for abstract argumentation frameworks*, 2005](https://link.springer.com/chapter/10.1007/11557791_3)) est une alternative aux sémantiques classiques qui gère différemment les cycles, notamment les cycles impairs. Elle se base sur une décomposition du graphe d'argumentation en Composantes Fortement Connexes (SCCs). Tweety fournit le `SccCF2Reasoner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d3062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.1.2 Sémantique CF2 ---\n",
      "❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\n"
     ]
    }
   ],
   "source": [
    "# --- 4.1.2 Sémantique CF2 ---\n",
    "print(\"\\n--- 4.1.2 Sémantique CF2 ---\")\n",
    "\n",
    "# Vérifier si la JVM est prête\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple CF2...\")\n",
    "    try:\n",
    "        # Imports (peuvent être déjà faits, mais sécurité)\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "        from org.tweetyproject.arg.dung.reasoner import SccCF2Reasoner\n",
    "        from org.tweetyproject.arg.dung.semantics import Extension # Pour type hinting éventuel\n",
    "        from java.util import Collection\n",
    "\n",
    "        print(\"✔️ Imports Dung (pour CF2) réussis.\")\n",
    "\n",
    "        # --- Exemple AF2 : Cycle a->b->c->d->e->a, e->f ---\n",
    "        # (Recréation pour autonomie de la cellule)\n",
    "        af2 = DungTheory()\n",
    "        args_cf2_map = {name: Argument(name) for name in \"abcdef\"} # Utiliser un dictionnaire\n",
    "        for arg in args_cf2_map.values(): af2.add(arg)\n",
    "\n",
    "        attacks_cf2 = [(\"a\",\"b\"), (\"b\",\"c\"), (\"c\",\"d\"), (\"d\",\"e\"), (\"e\",\"a\"), (\"e\",\"f\")]\n",
    "        for s, t in attacks_cf2:\n",
    "             # S'assurer que les arguments existent avant d'ajouter l'attaque\n",
    "             if s in args_cf2_map and t in args_cf2_map:\n",
    "                  af2.add(Attack(args_cf2_map[s], args_cf2_map[t]))\n",
    "             else:\n",
    "                  print(f\"WARN: Argument(s) non trouvé(s) pour l'attaque ({s},{t})\")\n",
    "\n",
    "        print(\"\\n--- AF pour CF2 : Cycle a->b->c->d->e->a, e->f ---\")\n",
    "        print(\"Cadre :\", af2)\n",
    "\n",
    "        # --- Raisonnement CF2 ---\n",
    "        cf2_reasoner = SccCF2Reasoner()\n",
    "        print(\"\\nCalcul des extensions CF2:\")\n",
    "        try:\n",
    "            cf2_extensions_collection = cf2_reasoner.getModels(af2) # Retourne Collection<Extension>\n",
    "            if cf2_extensions_collection.isEmpty():\n",
    "                 print(\"  (Aucune extension CF2 trouvée)\")\n",
    "            else:\n",
    "                 # Itérer sur la collection Java\n",
    "                 ext_iterator = cf2_extensions_collection.iterator()\n",
    "                 count = 0\n",
    "                 while ext_iterator.hasNext():\n",
    "                      ext = ext_iterator.next()\n",
    "                      # Pour un affichage plus propre des arguments dans l'extension:\n",
    "                      args_in_ext = \", \".join(sorted([str(arg.getName()) for arg in ext]))\n",
    "                      print(f\"  - {{{args_in_ext}}}\")\n",
    "                      count += 1\n",
    "                 print(f\"  ({count} extension(s) trouvée(s))\")\n",
    "\n",
    "        except jpype.JException as e_cf2_java:\n",
    "             print(f\"  ❌ Erreur Java lors du raisonnement CF2: {e_cf2_java.message()}\")\n",
    "             # print(e_cf2_java.stacktrace())\n",
    "        except Exception as e_cf2_py:\n",
    "              print(f\"  ❌ Erreur Python lors du raisonnement CF2: {e_cf2_py}\")\n",
    "\n",
    "    # Gestion globale\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour CF2 : {e}. Vérifiez le JAR 'arg.dung'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple CF2: {e_java.message()}\")\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple CF2: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec4a75c",
   "metadata": {},
   "source": [
    "#### 4.1.3 Génération de Cadres d'Argumentation\n",
    "<a id=\"4.1.3\"></a>\n",
    "\n",
    "Tweety fournit des outils pour générer aléatoirement des cadres d'argumentation abstraits (`DungTheory`), ce qui est utile pour les tests, benchmarks ou simulations. `DefaultDungTheoryGenerator` est un générateur simple paramétrable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31064b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.1.3 Génération de Cadres Dung ---\n",
      "❌ ERREUR: JVM non démarrée.\n"
     ]
    }
   ],
   "source": [
    "# --- 4.1.3 Génération de Cadres Dung ---\n",
    "print(\"\\n--- 4.1.3 Génération de Cadres Dung ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple de génération...\")\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "        from org.tweetyproject.arg.dung.util import DefaultDungTheoryGenerator, DungTheoryGenerationParameters\n",
    "\n",
    "        print(\"✔️ Imports pour génération Dung réussis.\")\n",
    "\n",
    "        # Paramètres de génération\n",
    "        params = DungTheoryGenerationParameters()\n",
    "        params.numberOfArguments = 6\n",
    "        params.attackProbability = 0.25\n",
    "        # CORRECTION: La ligne suivante est retirée car le champ n'existe probablement plus\n",
    "        # params.allowSelfAttacks = False\n",
    "        print(f\"ℹ️ Paramètres de génération: {params.numberOfArguments} args, proba_attaque={params.attackProbability} (comportement par défaut pour auto-attaques)\")\n",
    "\n",
    "        generator = DefaultDungTheoryGenerator(params)\n",
    "\n",
    "        # Générer UN cadre\n",
    "        generated_af = generator.next()\n",
    "\n",
    "        print(\"\\nCadre généré aléatoirement :\")\n",
    "        print(f\"  Arguments: {generated_af.getNodes()}\")\n",
    "        print(f\"  Attaques : {generated_af.getAttacks()}\")\n",
    "        print(f\"  Représentation compacte: {generated_af}\")\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour la génération Dung : {e}. Vérifiez le JAR 'arg.dung'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple génération Dung: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple génération Dung: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17ce72",
   "metadata": {},
   "source": [
    "#### 4.1.4 Apprentissage de Cadres d'Argumentation (depuis Labellisations)\n",
    "<a id=\"4.1.4\"></a>\n",
    "\n",
    "L'apprentissage de cadre vise à reconstruire un cadre d'argumentation (ou un ensemble de cadres possibles) à partir d'informations partielles, typiquement des exemples de labellisations d'arguments (IN, OUT, UNDEC) selon une certaine sémantique. Tweety propose `SimpleAFLearner` pour cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e02a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.1.4 Apprentissage de Cadres Dung ---\n",
      "!! SECTION COMMENTÉE !!\n",
      "L'exécution de cet exemple échoue en raison d'une ClassCastException interne à Tweety\n",
      "(Tautology cannot be cast to AssociativePlFormula) lors de l'appel à getLabeling/learnLabeling\n",
      "pour le cadre d'argumentation spécifique utilisé ici. Ceci semble être un bug interne.\n"
     ]
    }
   ],
   "source": [
    "# --- 4.1.4 Apprentissage de Cadres Dung (depuis Labellisations) ---\n",
    "print(\"\\n--- 4.1.4 Apprentissage de Cadres Dung ---\")\n",
    "\n",
    "print(\"!! SECTION COMMENTÉE !!\")\n",
    "print(\"L'exécution de cet exemple échoue en raison d'une ClassCastException interne à Tweety\")\n",
    "print(\"(Tautology cannot be cast to AssociativePlFormula) lors de l'appel à getLabeling/learnLabeling\")\n",
    "print(\"pour le cadre d'argumentation spécifique utilisé ici. Ceci semble être un bug interne.\")\n",
    "\n",
    "# if not jvm_ready:\n",
    "#     print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "# else:\n",
    "#     print(\"ℹ️ JVM prête. Exécution de l'exemple d'apprentissage...\")\n",
    "#     try:\n",
    "#         # Imports\n",
    "#         import jpype\n",
    "#         from jpype.types import *\n",
    "#         from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "#         from org.tweetyproject.arg.dung.learning import SimpleAFLearner\n",
    "#         from org.tweetyproject.arg.dung.learning.syntax import Entity\n",
    "#         from org.tweetyproject.arg.dung.semantics import Semantics\n",
    "#         # Import de Label retiré (correction précédente)\n",
    "#\n",
    "#         print(\"✔️ Imports pour apprentissage Dung réussis.\")\n",
    "#\n",
    "#         # 1. Définir le cadre \"caché\"\n",
    "#         hidden_af = DungTheory()\n",
    "#         a_learn = Argument(\"a\"); b_learn = Argument(\"b\"); c_learn = Argument(\"c\")\n",
    "#         hidden_af.add(a_learn); hidden_af.add(b_learn); hidden_af.add(c_learn)\n",
    "#         hidden_af.add(Attack(a_learn, b_learn)); hidden_af.add(Attack(b_learn, a_learn)); hidden_af.add(Attack(b_learn, c_learn))\n",
    "#         print(\"\\nCadre caché (à apprendre):\", hidden_af)\n",
    "#\n",
    "#         # 2. Créer l'Oracle\n",
    "#         oracle = Entity(hidden_af)\n",
    "#         arguments_known = oracle.getArguments()\n",
    "#         print(\"Arguments connus par l'apprenant:\", arguments_known)\n",
    "#\n",
    "#         # 3. Créer l'Apprenant\n",
    "#         learner = SimpleAFLearner(arguments_known)\n",
    "#         print(f\"État initial apprenant: {learner.getNumberOfFrameworks()} cadres compatibles possibles.\")\n",
    "#\n",
    "#         # 4. Apprendre depuis des labellisations\n",
    "#         # Labellisation Stable\n",
    "#         print(\"\\nApprentissage depuis labellisation Stable:\")\n",
    "#         try:\n",
    "#              labeling_stable = oracle.getLabeling(Semantics.STABLE_SEMANTICS) # C'est ici que l'erreur se produit\n",
    "#              print(f\"  Oracle fournit Labellisation STABLE: {labeling_stable}\")\n",
    "#              learner.learnLabeling(labeling_stable)\n",
    "#              print(f\"  Après STABLE: {learner.getNumberOfFrameworks()} cadres compatibles restants.\")\n",
    "#         except jpype.JException as e_stable:\n",
    "#               print(f\"  Erreur lors de l'obtention/apprentissage de la labellisation Stable: {e_stable.message()}\")\n",
    "#               # Afficher la stacktrace Java peut aider à confirmer l'erreur interne\n",
    "#               # print(e_stable.stacktrace())\n",
    "#\n",
    "#         # Labellisation Conflict-Free (pourrait aussi échouer)\n",
    "#         print(\"\\nApprentissage depuis labellisation Conflict-Free:\")\n",
    "#         try:\n",
    "#              labeling_cf = oracle.getLabeling(Semantics.CONFLICTFREE_SEMANTICS)\n",
    "#              print(f\"  Oracle fournit Labellisation CONFLICT_FREE: {labeling_cf}\")\n",
    "#              learner.learnLabeling(labeling_cf)\n",
    "#              print(f\"  Après CONFLICT_FREE: {learner.getNumberOfFrameworks()} cadres compatibles restants.\")\n",
    "#         except jpype.JException as e_cf:\n",
    "#              print(f\"  Erreur lors de l'obtention/apprentissage de la labellisation ConflictFree: {e_cf.message()}\")\n",
    "#\n",
    "#\n",
    "#         # 5. Obtenir le(s) cadre(s) appris\n",
    "#         # Ce code ne sera probablement pas atteint\n",
    "#         learned_af = learner.getModel()\n",
    "#         print(\"\\nCadre appris (un des cadres compatibles) :\")\n",
    "#         print(str(learned_af))\n",
    "#\n",
    "#     # ... (Blocs except ImportError, JException, Exception comme avant) ...\n",
    "#     except ImportError as e:\n",
    "#        print(f\"❌ Erreur d'import pour l'apprentissage Dung : {e}.\")\n",
    "#     except jpype.JException as e_java:\n",
    "#        print(f\"❌ Erreur Java générale dans l'exemple apprentissage Dung: {e_java.message()}\")\n",
    "#     except Exception as e_gen:\n",
    "#        print(f\"❌ Erreur Python inattendue dans l'exemple apprentissage Dung: {e_gen}\")\n",
    "#        import traceback\n",
    "#        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ee0f8",
   "metadata": {},
   "source": [
    "### 4.2 ASPIC+\n",
    "<a id=\"4.2\"></a>\n",
    "\n",
    "ASPIC+ est un framework mature et largement utilisé pour l'argumentation **structurée**. Contrairement à Dung où les arguments sont abstraits, ASPIC+ construit des arguments logiques à partir d'une base de connaissances et de règles d'inférence, en distinguant règles strictes et règles défaisables.\n",
    "\n",
    "* **Base de Connaissances (KB)**: Contient des axiomes (faits certains) et des règles.\n",
    "* **Règles d'inférence**:\n",
    "    * Strictes (`StrictInferenceRule`, `->`): Si les prémisses sont acceptées, la conclusion l'est nécessairement.\n",
    "    * Défaisables (`DefeasibleInferenceRule`, `=>`): Si les prémisses sont acceptées, la conclusion l'est plausiblement, mais la règle elle-même peut être attaquée (undercutting) ou la conclusion réfutée (rebutting).\n",
    "* **Préférences**: Un ordre (souvent partiel) peut être défini sur les règles défaisables pour résoudre les attaques \"rebutting\".\n",
    "* **Arguments**: Construits par chaînage de règles depuis les axiomes.\n",
    "* **Attaques**: Peuvent viser la conclusion (rebutting), une sous-conclusion (undermining sur conclusion intermédiaire) ou une règle défaisable (undercutting).\n",
    "* **`AspicArgumentationTheory`**: Représente la théorie ASPIC+. Nécessite un `RuleFormulaGenerator` pour spécifier la logique sous-jacente (ex: `PlFormulaGenerator` pour la logique propositionnelle).\n",
    "* **Conversion vers Dung (`asDungTheory`)**: Permet d'analyser la théorie ASPIC+ en la transformant en un AAF standard, sur lequel on peut appliquer les sémantiques de Dung (Grounded, Preferred, etc.).\n",
    "\n",
    "L'exemple suivant utilise la logique propositionnelle comme langage sous-jacent, basé sur `AspicExample.java`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340ab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.2.1 ASPIC+ : Construction et Conversion en Dung (PL) ---\n",
      "❌ ERREUR: JVM non démarrée.\n"
     ]
    }
   ],
   "source": [
    "# --- 4.2.1 ASPIC+ : Construction et Conversion en Dung (PL) ---\n",
    "print(\"\\n--- 4.2.1 ASPIC+ : Construction et Conversion en Dung (PL) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple ASPIC+...\")\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        # Logique Propositionnelle comme base\n",
    "        from org.tweetyproject.logics.pl.syntax import Proposition, Negation, PlFormula\n",
    "        # Classes ASPIC+\n",
    "        from org.tweetyproject.arg.aspic.syntax import AspicArgumentationTheory, DefeasibleInferenceRule, StrictInferenceRule\n",
    "        from org.tweetyproject.arg.aspic.ruleformulagenerator import PlFormulaGenerator # Crucial pour PL\n",
    "        # Classes Dung pour la conversion et le raisonnement\n",
    "        from org.tweetyproject.arg.dung.syntax import Argument as DungArgument, Attack as DungAttack, DungTheory\n",
    "        from org.tweetyproject.arg.dung.reasoner import SimpleGroundedReasoner\n",
    "\n",
    "        print(\"✔️ Imports ASPIC+ (PL) et Dung réussis.\")\n",
    "\n",
    "        # --- Théorie ASPIC+ ---\n",
    "        # Nécessite un générateur pour la logique sous-jacente (ici PL)\n",
    "        pl_formula_generator = PlFormulaGenerator()\n",
    "        aspic_theory = AspicArgumentationTheory(pl_formula_generator)\n",
    "        # Spécifier aussi le générateur pour les formules DANS les règles\n",
    "        aspic_theory.setRuleFormulaGenerator(pl_formula_generator)\n",
    "\n",
    "        # Propositions\n",
    "        a = Proposition(\"a\"); b = Proposition(\"b\"); c = Proposition(\"c\"); d_prop = Proposition(\"d\") # Renommé\n",
    "\n",
    "        # Règles Défaisables (=>)\n",
    "        # r1: b, c => a\n",
    "        r1_def = DefeasibleInferenceRule()\n",
    "        r1_def.setConclusion(a)\n",
    "        r1_def.addPremise(b); r1_def.addPremise(c)\n",
    "        aspic_theory.addRule(r1_def)\n",
    "\n",
    "        # r2: b => d\n",
    "        r2_def = DefeasibleInferenceRule()\n",
    "        r2_def.setConclusion(d_prop)\n",
    "        r2_def.addPremise(b)\n",
    "        aspic_theory.addRule(r2_def)\n",
    "\n",
    "        # r3: a => !d\n",
    "        r3_def = DefeasibleInferenceRule()\n",
    "        r3_def.setConclusion(Negation(d_prop))\n",
    "        r3_def.addPremise(a)\n",
    "        aspic_theory.addRule(r3_def)\n",
    "\n",
    "        # (Pas de règles strictes dans cet exemple)\n",
    "\n",
    "        # Axiomes (faits certains ->)\n",
    "        aspic_theory.addAxiom(b) # -> b\n",
    "        aspic_theory.addAxiom(c) # -> c\n",
    "\n",
    "        print(\"\\n--- Théorie ASPIC+ ---\")\n",
    "        print(str(aspic_theory)) # Utilise toString()\n",
    "\n",
    "        # --- Conversion en Cadre de Dung ---\n",
    "        print(\"\\n--- Conversion en AF de Dung ---\")\n",
    "        try:\n",
    "            # asDungTheory() génère le graphe d'attaque basé sur la théorie ASPIC+\n",
    "            dung_equivalent = aspic_theory.asDungTheory()\n",
    "\n",
    "            print(\"Arguments générés par ASPIC+:\")\n",
    "            args_aspic = dung_equivalent.getNodes()\n",
    "            if args_aspic.isEmpty():\n",
    "                print(\"  (Aucun argument généré)\")\n",
    "            else:\n",
    "                for arg in args_aspic:\n",
    "                    # L'affichage d'un argument ASPIC+ peut être complexe\n",
    "                    print(f\"  - {arg}\")\n",
    "\n",
    "            print(\"\\nAttaques générées par ASPIC+:\")\n",
    "            attacks_aspic = dung_equivalent.getAttacks()\n",
    "            if attacks_aspic.isEmpty():\n",
    "                 print(\"  (Aucune attaque générée)\")\n",
    "            else:\n",
    "                for att in attacks_aspic:\n",
    "                    print(f\"  - {att}\")\n",
    "\n",
    "            # --- Raisonnement sur l'AF équivalent ---\n",
    "            print(\"\\nRaisonnement sur l'AF de Dung équivalent:\")\n",
    "            grounded_reasoner_dung = SimpleGroundedReasoner()\n",
    "            grounded_extension = grounded_reasoner_dung.getModel(dung_equivalent)\n",
    "            print(f\" - Extension Grounded : {grounded_extension}\")\n",
    "\n",
    "            # Pourrait-on vérifier si 'a' est acceptable ?\n",
    "            # Il faudrait trouver l'argument ASPIC correspondant à 'a'\n",
    "            # C'est plus complexe, on se contente de l'extension pour l'instant.\n",
    "\n",
    "        except jpype.JException as e_conv_java:\n",
    "            print(f\"❌ Erreur Java lors de la conversion ASPIC->Dung: {e_conv_java.message()}\")\n",
    "            # print(e_conv_java.stacktrace())\n",
    "        except Exception as e_conv_py:\n",
    "            print(f\"❌ Erreur Python lors de la conversion ASPIC->Dung: {e_conv_py}\")\n",
    "\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour ASPIC+ : {e}. Vérifiez le JAR 'arg.aspic'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple ASPIC+: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple ASPIC+: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06220aec",
   "metadata": {},
   "source": [
    "### 4.3 Defeasible Logic Programming (DeLP)\n",
    "<a id=\"4.3\"></a>\n",
    "\n",
    "*(Section à compléter avec l'exemple `DeLPExample.java`)*\n",
    "\n",
    "DeLP combine la programmation logique avec le raisonnement défaisable. Il utilise des règles strictes et des règles défaisables (`-<`). Un argument est construit pour supporter un littéral, et la notion de \"warrant\" (justification) est déterminée en comparant les arguments pour et contre ce littéral, en utilisant un critère de comparaison comme la spécificité généralisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573f125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.3 Defeasible Logic Programming (DeLP) ---\n",
      "❌ ERREUR: JVM non démarrée.\n"
     ]
    }
   ],
   "source": [
    "# --- 4.3 Defeasible Logic Programming (DeLP) ---\n",
    "print(\"\\n--- 4.3 Defeasible Logic Programming (DeLP) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple DeLP...\")\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        import pathlib\n",
    "        from java.io import StringReader\n",
    "        from java.util import ArrayList\n",
    "\n",
    "        # Imports DeLP\n",
    "        from org.tweetyproject.arg.delp.parser import DelpParser\n",
    "        from org.tweetyproject.arg.delp.reasoner import DelpReasoner\n",
    "        from org.tweetyproject.arg.delp.semantics import GeneralizedSpecificity\n",
    "        from org.tweetyproject.arg.delp.syntax import DefeasibleLogicProgram\n",
    "\n",
    "        # Imports FOL/Commons nécessaires\n",
    "        from org.tweetyproject.logics.fol.syntax import FolFormula, FolSignature, FolAtom\n",
    "        # ** CORRECTION: Importer Constant et Predicate depuis commons.syntax **\n",
    "        from org.tweetyproject.logics.commons.syntax import Constant, Predicate\n",
    "\n",
    "        print(\"✔️ Imports DeLP, FOL et Commons nécessaires réussis.\")\n",
    "\n",
    "        # --- Parsing du programme DeLP ---\n",
    "        # (Code de chargement depuis fichier ou chaîne inchangé)\n",
    "        delp_filename = \"birds2.txt\"\n",
    "        delp_filepath = pathlib.Path(\"resources\") / delp_filename\n",
    "        delp_program = None\n",
    "        parser_delp = DelpParser() # Parser pour le programme\n",
    "\n",
    "        if not delp_filepath.is_file():\n",
    "            print(f\"❌ ERREUR: Fichier DeLP requis '{delp_filepath}' non trouvé !\")\n",
    "            print(\"   Utilisation d'un exemple intégré (birds.txt simplifié).\")\n",
    "            birds_program_str = \"\"\"\n",
    "            Bird(X) <- Chicken(X). Bird(X) <- Penguin(X). ~Flies(X) <- Penguin(X).\n",
    "            Chicken(tina). Penguin(tweety). Scared(tina).\n",
    "            Flies(X) -< Bird(X). ~Flies(X) -< Chicken(X). Flies(X) -< Chicken(X), Scared(X).\n",
    "            Nests_in_trees(X) -< Flies(X).\n",
    "            \"\"\"\n",
    "            try:\n",
    "                 string_reader = StringReader(birds_program_str)\n",
    "                 delp_program = parser_delp.parseBeliefBase(string_reader); string_reader.close()\n",
    "                 print(\"✔️ Programme chargé avec succès depuis la chaîne intégrée.\")\n",
    "            except Exception as e_str: print(f\"❌ Erreur parsing chaîne intégrée: {e_str}\"); delp_program = None\n",
    "        else:\n",
    "            print(f\"\\nChargement du programme DeLP depuis: {delp_filepath}\")\n",
    "            try:\n",
    "                 delp_program = parser_delp.parseBeliefBaseFromFile(str(delp_filepath))\n",
    "                 print(\"✔️ Programme chargé avec succès depuis le fichier.\")\n",
    "            except Exception as e_file: print(f\"❌ Erreur chargement fichier: {e_file}\"); delp_program = None\n",
    "\n",
    "\n",
    "        # --- Raisonnement DeLP ---\n",
    "        if delp_program is not None:\n",
    "            print(\"\\nProgramme DeLP chargé:\\n\", str(delp_program))\n",
    "\n",
    "            # DEBUG Signature (inchangé)\n",
    "            sig_delp = None\n",
    "            try:\n",
    "                sig_delp = delp_program.getSignature()\n",
    "                print(\"\\nDEBUG Signature extraite par DelpParser:\")\n",
    "                print(sig_delp)\n",
    "                if hasattr(sig_delp, 'getPredicates'): print(\"Predicates:\", sig_delp.getPredicates())\n",
    "                if hasattr(sig_delp, 'getConstants'): print(\"Constants:\", sig_delp.getConstants())\n",
    "            except Exception as e_sig: print(f\"⚠️ Erreur récupération/affichage signature: {e_sig}\")\n",
    "\n",
    "            # Construction programmatique des requêtes (inchangée, mais utilise les classes importées correctement)\n",
    "            print(\"\\nConstruction programmatique des requêtes FOL...\")\n",
    "            queries_fol_obj = {}\n",
    "            try:\n",
    "                # Redéfinir Predicate/Constant avec les classes importées de commons.syntax\n",
    "                Flies = Predicate(\"Flies\", 1)\n",
    "                Nests = Predicate(\"Nests_in_trees\", 1)\n",
    "                tina = Constant(\"tina\")\n",
    "                tweety = Constant(\"tweety\")\n",
    "\n",
    "                # Construire les FolAtom (le constructeur prend Predicate, List<Term>)\n",
    "                # Créer une ArrayList Java pour les arguments\n",
    "                args_tina = ArrayList([tina])\n",
    "                args_tweety = ArrayList([tweety])\n",
    "\n",
    "                # Utiliser JObject pour passer la liste Java de manière sûre\n",
    "                queries_fol_obj[\"Flies(tina)\"] = FolAtom(Flies, JObject(args_tina, \"java.util.List\"))\n",
    "                queries_fol_obj[\"Flies(tweety)\"] = FolAtom(Flies, JObject(args_tweety, \"java.util.List\"))\n",
    "                queries_fol_obj[\"Nests_in_trees(tina)\"] = FolAtom(Nests, JObject(args_tina, \"java.util.List\"))\n",
    "                queries_fol_obj[\"Nests_in_trees(tweety)\"] = FolAtom(Nests, JObject(args_tweety, \"java.util.List\"))\n",
    "\n",
    "                print(\"✔️ Requêtes construites programmatiquement.\")\n",
    "\n",
    "            except Exception as e_build:\n",
    "                print(f\"❌ Erreur lors de la construction programmatique des requêtes: {e_build}\")\n",
    "                queries_fol_obj = None\n",
    "\n",
    "            if queries_fol_obj:\n",
    "                reasoner_delp = DelpReasoner(GeneralizedSpecificity())\n",
    "                FolFormula_class = jpype.JClass(\"org.tweetyproject.logics.fol.syntax.FolFormula\")\n",
    "\n",
    "                print(\"\\nÉvaluation des requêtes DeLP (construites programmatiquement):\")\n",
    "                for q_str, query_formula_obj in queries_fol_obj.items():\n",
    "                    print(f\"  Querying '{q_str}'...\", end=\"\")\n",
    "                    try:\n",
    "                        result_delp = reasoner_delp.query(delp_program, JObject(query_formula_obj, FolFormula_class))\n",
    "                        print(f\" Résultat: {result_delp}\")\n",
    "                    except jpype.JException as e_query_java:\n",
    "                        print(f\" ERREUR JAVA: {e_query_java.message()}\")\n",
    "                    except Exception as e_query_py:\n",
    "                         print(f\" ERREUR PYTHON: {e_query_py}\")\n",
    "            else:\n",
    "                 print(\"\\n❌ Construction des requêtes échouée, raisonnement sauté.\")\n",
    "        else:\n",
    "            print(\"\\n❌ Aucun programme DeLP chargé ou erreur de chargement, raisonnement sauté.\")\n",
    "\n",
    "    # ... (Blocs except globaux inchangés) ...\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import pour DeLP/Commons/FOL : {e}.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale: {e_java.message()}\")\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e355de",
   "metadata": {},
   "source": [
    "### 4.4 Assumption-Based Argumentation (ABA)\n",
    "<a id=\"4.4\"></a>\n",
    "\n",
    "*(Section à compléter avec l'exemple `AbaExample.java`)*\n",
    "\n",
    "En ABA, certains littéraux sont désignés comme des **hypothèses** (assumptions). Les arguments sont dérivés en utilisant des règles logiques (similaires à ASPIC+) à partir de ces hypothèses. Une attaque d'un argument vers un autre se produit si la conclusion du premier est le **contraire** d'une hypothèse utilisée dans le second.\n",
    "\n",
    "* **`AbaTheory`**: Contient les règles, l'ensemble des hypothèses, et la définition des contraires.\n",
    "* **Logique sous-jacente**: Peut être PL ou FOL.\n",
    "* **Raisonnement**: Souvent basé sur la conversion en AF de Dung (`FlatAbaReasoner`, `PreferredReasoner`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0785a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.4 Assumption-Based Argumentation (ABA) ---\n",
      "❌ ERREUR: JVM non démarrée.\n"
     ]
    }
   ],
   "source": [
    "# --- 4.4 Assumption-Based Argumentation (ABA) ---\n",
    "print(\"\\n--- 4.4 Assumption-Based Argumentation (ABA) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple ABA...\")\n",
    "    try:\n",
    "        # Imports (inchangés)\n",
    "        import jpype; from jpype.types import *; import pathlib; from java.io import StringReader\n",
    "        from org.tweetyproject.arg.aba.parser import AbaParser\n",
    "        from org.tweetyproject.arg.aba.syntax import AbaTheory, Assumption\n",
    "        from org.tweetyproject.logics.pl.parser import PlParser\n",
    "        from org.tweetyproject.logics.pl.syntax import Proposition, PlFormula\n",
    "        from org.tweetyproject.logics.fol.parser import FolParser\n",
    "        from org.tweetyproject.logics.fol.syntax import FolFormula, FolSignature\n",
    "        from org.tweetyproject.logics.pl.sat import SatSolver, Sat4jSolver\n",
    "        from org.tweetyproject.arg.aba.reasoner import FlatAbaReasoner, PreferredReasoner\n",
    "        from org.tweetyproject.arg.dung.semantics import Semantics\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory\n",
    "\n",
    "        print(\"✔️ Imports ABA et dépendances réussis.\")\n",
    "\n",
    "        # --- Exemple 1: Propositional Logic (PL) ---\n",
    "        print(\"\\n--- Exemple ABA avec Logique Propositionnelle ---\")\n",
    "        # (Code PL inchangé, il fonctionnait)\n",
    "        SatSolver.setDefaultSolver(Sat4jSolver())\n",
    "        pl_parser_for_aba = PlParser()\n",
    "        aba_parser_pl = AbaParser(pl_parser_for_aba)\n",
    "        aba_pl_filename = \"example2.aba\"\n",
    "        aba_pl_filepath = pathlib.Path(\"resources\") / aba_pl_filename\n",
    "        aba_theory_pl = None\n",
    "        if not aba_pl_filepath.is_file():\n",
    "            print(f\"❌ ERREUR: Fichier ABA (PL) requis '{aba_pl_filepath}' non trouvé !\")\n",
    "        else:\n",
    "            print(f\"Chargement ABA (PL) depuis fichier: {aba_pl_filepath}\")\n",
    "            try:\n",
    "                 aba_theory_pl = aba_parser_pl.parseBeliefBaseFromFile(str(aba_pl_filepath))\n",
    "                 print(\"✔️ Théorie ABA (PL) chargée depuis fichier.\")\n",
    "            except Exception as e_fpl: print(f\"❌ Erreur chargement fichier ABA (PL): {e_fpl}\")\n",
    "\n",
    "        if aba_theory_pl is not None:\n",
    "            print(\"\\nThéorie ABA (PL):\", str(aba_theory_pl))\n",
    "            reasoner_flat_pref = FlatAbaReasoner(Semantics.PREFERRED_SEMANTICS)\n",
    "            reasoner_pref_aba = PreferredReasoner()\n",
    "            assumption_pl = Assumption(Proposition(\"a\"))\n",
    "            print(\"\\nRequêtes sur la théorie ABA (PL):\")\n",
    "            print(f\" - Query '{assumption_pl}' (Flat Preferred)? {reasoner_flat_pref.query(aba_theory_pl, assumption_pl)}\")\n",
    "            print(f\" - Query '{assumption_pl}' (ABA Preferred)? {reasoner_pref_aba.query(aba_theory_pl, assumption_pl)}\")\n",
    "\n",
    "\n",
    "        # --- Exemple 2: First-Order Logic (FOL) ---\n",
    "        print(\"\\n\\n--- Exemple ABA avec Logique du Premier Ordre ---\")\n",
    "        aba_fol_filename = \"smp_fol.aba\"\n",
    "        aba_fol_filepath = pathlib.Path(\"resources\") / aba_fol_filename\n",
    "        aba_theory_fol = None\n",
    "\n",
    "        if not aba_fol_filepath.is_file():\n",
    "             print(f\"❌ ERREUR: Fichier ABA (FOL) requis '{aba_fol_filepath}' non trouvé !\")\n",
    "        else:\n",
    "            fol_parser_for_aba = FolParser()\n",
    "            # ** CORRECTION : Ajouter des sauts de ligne '\\n' **\n",
    "            sig_fol_str = \"\"\"\n",
    "            Male = {a, b}\n",
    "            Female = {c, d}\n",
    "            type(Pair(Male, Female))\n",
    "            type(ContraryPair(Male, Female))\n",
    "            type(MPrefers(Male, Female, Female))\n",
    "            type(WPrefers(Female, Male, Male))\n",
    "            \"\"\"\n",
    "            try:\n",
    "                 sig_fol_aba = fol_parser_for_aba.parseSignature(sig_fol_str)\n",
    "                 fol_parser_for_aba.setSignature(sig_fol_aba)\n",
    "                 print(\"✔️ Signature FOL pour ABA définie.\")\n",
    "\n",
    "                 aba_parser_fol = AbaParser(fol_parser_for_aba)\n",
    "                 # Important si les termes sont séparés par ';' dans le .aba\n",
    "                 # smp_fol.aba utilise bien ';', donc on décommente :\n",
    "                 aba_parser_fol.setSymbolComma(\";\")\n",
    "                 print(\"ℹ️ Utilisation de ';' comme séparateur pour le parser ABA FOL.\")\n",
    "\n",
    "\n",
    "                 print(f\"Chargement ABA (FOL) depuis fichier: {aba_fol_filepath}\")\n",
    "                 try:\n",
    "                      aba_theory_fol = aba_parser_fol.parseBeliefBaseFromFile(str(aba_fol_filepath))\n",
    "                      print(\"✔️ Théorie ABA (FOL) chargée depuis fichier.\")\n",
    "                 except Exception as e_ffol: print(f\"❌ Erreur chargement fichier ABA (FOL): {e_ffol}\")\n",
    "\n",
    "                 if aba_theory_fol is not None:\n",
    "                       print(\"\\nThéorie ABA (FOL):\\n\", str(aba_theory_fol))\n",
    "                       # Raisonnement ABA (FOL)\n",
    "                       reasoner_flat_stable_fol = FlatAbaReasoner(Semantics.STABLE_SEMANTICS)\n",
    "                       reasoner_pref_aba_fol = PreferredReasoner()\n",
    "                       FolFormula_class = jpype.JClass(\"org.tweetyproject.logics.fol.syntax.FolFormula\")\n",
    "                       # Vérifier que 'Pair(a,d)' est bien une assumption dans smp_fol.aba\n",
    "                       # Elle l'est, comme 'Pair(b,c)', etc.\n",
    "                       assumption_fol_query_str = \"Pair(a,d)\"\n",
    "                       assumption_fol = Assumption(JObject(fol_parser_for_aba.parseFormula(assumption_fol_query_str), FolFormula_class))\n",
    "                       print(\"\\nRequêtes sur la théorie ABA (FOL):\")\n",
    "                       # print(f\" - Modèles (Flat Stable): {reasoner_flat_stable_fol.getModels(aba_theory_fol)}\")\n",
    "                       print(f\" - Query '{assumption_fol}' (ABA Preferred)? {reasoner_pref_aba_fol.query(aba_theory_fol, assumption_fol)}\")\n",
    "\n",
    "            except jpype.JException as e_sig_java: print(f\"❌ Erreur Java lors de la config FOL pour ABA: {e_sig_java.message()}\")\n",
    "            except Exception as e_sig_py: print(f\"❌ Erreur Python lors de la config FOL pour ABA: {e_sig_py}\")\n",
    "\n",
    "    # ... (Blocs except globaux inchangés) ...\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import pour ABA : {e}.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale: {e_java.message()}\")\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de9718",
   "metadata": {},
   "source": [
    "### 4.5 Argumentation Déductive (PL)\n",
    "<a id=\"4.5\"></a>\n",
    "\n",
    "Cette approche, souvent associée à Besnard & Hunter, construit des arguments comme des paires `(Support, Conclusion)` où `Support` est un sous-ensemble minimal et consistant de la base de connaissances qui implique logiquement la `Conclusion`.\n",
    "\n",
    "* **`DeductiveKnowledgeBase`**: Une simple `PlBeliefSet` dans l'implémentation de Tweety.\n",
    "* **Argument**: Généré implicitement par le raisonneur.\n",
    "* **Attaque**: Un argument `(S1, C1)` attaque `(S2, C2)` si `C1` est la négation d'un élément de `S2` (attaque \"undercut\" classique) ou la négation de `C2` (attaque \"rebut\" classique).\n",
    "* **Raisonnement (`SimpleDeductiveReasoner`)**: Construit un arbre d'arguments/contre-arguments pour une requête donnée.\n",
    "    * **`Categorizer`**: Détermine la force initiale d'un argument (ex: `ClassicalCategorizer`).\n",
    "    * **`Accumulator`**: Agrège la force des arguments/contre-arguments dans l'arbre (ex: `SimpleAccumulator`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ba855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Erreur d'import pour Argumentation Déductive : Attempt to create Java package 'org' without jvm\n",
      "   Vérifiez le JAR 'org.tweetyproject.arg.deductive'.\n"
     ]
    }
   ],
   "source": [
    "# --- 4.5 Argumentation Déductive (PL) ---\n",
    "# Correction: Le package pour ClassicalCategorizer et SimpleAccumulator était 'categorizer' et 'accumulator', pas 'semantics'.\n",
    "try:\n",
    "    from org.tweetyproject.logics.pl.parser import PlParser\n",
    "    from org.tweetyproject.arg.deductive.syntax import DeductiveKnowledgeBase\n",
    "    from org.tweetyproject.arg.deductive.reasoner import SimpleDeductiveReasoner, AbstractDeductiveArgumentationReasoner\n",
    "    # Correction des imports:\n",
    "    from org.tweetyproject.arg.deductive.categorizer import ClassicalCategorizer\n",
    "    from org.tweetyproject.arg.deductive.accumulator import SimpleAccumulator\n",
    "\n",
    "    from org.tweetyproject.logics.pl.sat import Sat4jSolver, SatSolver # Souvent nécessaire en interne\n",
    "\n",
    "    # --- Initialisation ---\n",
    "    SatSolver.setDefaultSolver(Sat4jSolver())\n",
    "    parser_ded = PlParser()\n",
    "    kb_ded = DeductiveKnowledgeBase() # Est essentiellement un PlBeliefSet\n",
    "\n",
    "    # Base de connaissances de l'exemple\n",
    "    formulas_ded = [\"s\", \"!s || h\", \"f\", \"!f || !h\", \"v\", \"!v || !h\"]\n",
    "    for f_str in formulas_ded: kb_ded.add(parser_ded.parseFormula(f_str))\n",
    "\n",
    "    print(\"KB Déductive:\\n\", kb_ded)\n",
    "\n",
    "    # --- Raisonnement ---\n",
    "    # Utilise un catégoriseur classique et un accumulateur simple\n",
    "    ded_reasoner = SimpleDeductiveReasoner(ClassicalCategorizer(), SimpleAccumulator())\n",
    "\n",
    "    query_ded = parser_ded.parseFormula(\"h\") # La requête est \"h\"\n",
    "    result_ded = ded_reasoner.query(kb_ded, query_ded)\n",
    "\n",
    "    print(f\"\\nQuery '{query_ded}'? {result_ded}\") # Devrait être ACCEPTED ou REJECTED\n",
    "\n",
    "except ImportError as e:\n",
    "     print(f\"❌ Erreur d'import pour Argumentation Déductive : {e}\")\n",
    "     print(\"   Vérifiez le JAR 'org.tweetyproject.arg.deductive'.\")\n",
    "except Exception as e:\n",
    "     print(f\"❌ Erreur lors de l'exécution de l'exemple Déductif: {e}\")\n",
    "     import traceback\n",
    "     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d237ec",
   "metadata": {},
   "source": [
    "### 4.6 Answer Set Programming (ASP)\n",
    "<a id=\"4.6\"></a>\n",
    "\n",
    "ASP est un paradigme de programmation déclarative puissant pour résoudre des problèmes combinatoires complexes, souvent utilisé en représentation de connaissances et raisonnement. Un programme ASP est un ensemble de règles logiques (similaires à Prolog mais avec une sémantique différente basée sur les \"modèles stables\" ou \"answer sets\").\n",
    "\n",
    "* **Syntaxe :** Règles de la forme `tete :- corps.` où `corps` est une conjonction de littéraux. Utilise la négation par défaut (`not`) et la négation classique (`-`). Permet les contraintes (règles sans tête) et les règles de choix/agrégats.\n",
    "* **Sémantique :** Les \"answer sets\" sont des ensembles minimaux d'atomes vrais qui satisfont toutes les règles du programme.\n",
    "* **Tweety :** Permet de définir des `Program`mes ASP (`org.tweetyproject.lp.asp.syntax`). Le raisonnement nécessite un **solveur externe** comme **Clingo** (de la suite Potassco). Tweety fournit `ClingoSolver` pour l'interfacer, ainsi qu'un `GringoGrounder` (Gringo est le \"grounder\" de Clingo qui instancie les variables).\n",
    "* **Pré-requis :** Nécessite l'installation de **Clingo** ([Potassco](https://potassco.org/)) et la configuration du chemin vers l'exécutable Clingo dans `EXTERNAL_TOOLS['CLINGO']` (Cellule 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff79c6",
   "metadata": {},
   "outputs": [],
   "source": "# --- 4.6 Answer Set Programming (ASP) ---\nprint(\"\\n--- 4.6 Answer Set Programming (ASP) ---\")\n\nif not jvm_ready:\n    print(\"❌ ERREUR: JVM non démarrée.\")\nelse:\n    print(\"ℹ️ JVM prête. Exécution de l'exemple ASP...\")\n    asp_imports_ok = False\n    try:\n        # Imports (inchangés)\n        import jpype\n        from jpype.types import *\n        from java.util import ArrayList, List as JavaList, Collection\n        from org.tweetyproject.lp.asp.syntax import (\n            Program, ASPRule, ASPAtom, DefaultNegation, StrictNegation,\n            ClassicalHead, AggregateHead, AggregateAtom, ASPHead, ASPBodyElement\n        )\n        from org.tweetyproject.logics.commons.syntax import Constant, Predicate, Variable\n        from org.tweetyproject.lp.asp.reasoner import ClingoSolver\n        from org.tweetyproject.lp.asp.grounder import GringoGrounder\n        from org.tweetyproject.lp.asp.semantics import AnswerSet\n\n        # Récupérer get_tool_path\n        if 'get_tool_path' not in globals() or 'EXTERNAL_TOOLS' not in globals():\n            raise NameError(\"La fonction 'get_tool_path' ou 'EXTERNAL_TOOLS' n'est pas définie.\")\n\n        # Récupérer le chemin Clingo configuré par l'utilisateur\n        CLINGO_PATH = get_tool_path('CLINGO') # Renvoie None si non configuré ou invalide\n\n        print(\"✔️ Imports ASP réussis.\")\n        asp_imports_ok = True\n\n        # --- Programme ASP Simple (Construction inchangée) ---\n        print(\"\\n--- Programme ASP Simple ---\")\n        p = ASPAtom(\"p\"); r_atom = ASPAtom(\"r\"); q = ASPAtom(\"q\"); b_atom = ASPAtom(\"b\") # Renommé r -> r_atom\n        body1 = ArrayList(); body1.add(DefaultNegation(r_atom))\n        r1_asp = ASPRule(ClassicalHead(p), JObject(body1, JavaList))\n        body2 = ArrayList(); body2.add(StrictNegation(q)); body2.add(DefaultNegation(b_atom))\n        r2_asp = ASPRule(ClassicalHead(r_atom), JObject(body2, JavaList))\n        body3 = ArrayList(); body3.add(b_atom)\n        r3_asp = ASPRule(ClassicalHead(StrictNegation(q)), JObject(body3, JavaList))\n        body4 = ArrayList()\n        r4_asp = ASPRule(ClassicalHead(b_atom), JObject(body4, JavaList))\n        rules_prog1 = ArrayList([r1_asp, r2_asp, r3_asp, r4_asp])\n        program1 = Program(JObject(rules_prog1, Collection))\n        print(\"Programme 1:\\n\", str(program1))\n\n\n        # --- Programme ASP Suspects (Construction inchangée) ---\n        print(\"\\n--- Programme ASP Suspects ---\")\n        motive = Predicate(\"motive\", 1); guilty = Predicate(\"guilty\", 1); innocent = Predicate(\"innocent\", 1)\n        harry = Constant(\"harry\"); sally = Constant(\"sally\")\n        Suspect = Variable(\"Suspect\")\n        motive_h = ASPAtom(motive, [harry]); motive_s = ASPAtom(motive, [sally]) # Mettre les termes dans une liste\n        guilty_h = ASPAtom(guilty, [harry])\n        innocent_S = ASPAtom(innocent, [Suspect]); motive_S = ASPAtom(motive, [Suspect])\n        guilty_S = ASPAtom(guilty, [Suspect])\n        r1_sus = ASPRule(ClassicalHead(motive_h), JObject(ArrayList(), JavaList))\n        r2_sus = ASPRule(ClassicalHead(motive_s), JObject(ArrayList(), JavaList))\n        r3_sus = ASPRule(ClassicalHead(guilty_h), JObject(ArrayList(), JavaList))\n        body4_sus = ArrayList(); body4_sus.add(motive_S); body4_sus.add(DefaultNegation(guilty_S))\n        r4_sus = ASPRule(ClassicalHead(innocent_S), JObject(body4_sus, JavaList))\n        rules_prog2 = ArrayList([r1_sus, r2_sus, r3_sus, r4_sus])\n        program2 = Program(JObject(rules_prog2, Collection))\n        print(\"Programme 2:\\n\", str(program2))\n\n\n        # --- Raisonnement avec Clingo ---\n        if not CLINGO_PATH:\n            print(\"\\n⚠️ Clingo non configuré ou chemin invalide dans EXTERNAL_TOOLS['CLINGO'] (Cellule 10).\")\n            print(\"   Veuillez installer Clingo (via pip/conda ou manuellement) et configurer le chemin.\")\n            print(\"   Raisonnement ASP sauté.\")\n        else:\n            print(f\"\\nUtilisation de Clingo trouvé/configuré à: {CLINGO_PATH}\")\n            try:\n                # Instancier AVEC le chemin (doit être un REPERTOIRE, pas l'exe)\n                solver_instance = ClingoSolver(JString(CLINGO_PATH))\n                print(f\"\\nCalcul des Answer Sets pour Programme 2...\")\n                # getModels(Program)\n                answer_sets_collection = solver_instance.getModels(program2)\n\n                print(f\"Answer Sets trouvés ({answer_sets_collection.size()}):\")\n                if answer_sets_collection.isEmpty():\n                    print(\"   (Aucun Answer Set)\")\n                else:\n                    count = 1\n                    for ans_set in answer_sets_collection:\n                        # AnswerSet extends InterpretationSet - utiliser toString() ou itérer directement\n                        # L'objet AnswerSet est itérable (Set<ASPLiteral>)\n                        try:\n                            atoms_in_set = \", \".join(sorted([str(atom) for atom in ans_set]))\n                            print(f\"   - AS {count}: {{{atoms_in_set}}}\")\n                        except Exception:\n                            # Fallback: utiliser toString()\n                            print(f\"   - AS {count}: {ans_set}\")\n                        count += 1\n\n                # --- Grounding (Optionnel) ---\n                print(\"\\nTentative de Grounding...\")\n                try:\n                    grounder_instance = GringoGrounder(JString(CLINGO_PATH))\n                    ground_program = grounder_instance.getGroundProgram(program2)\n                    print(\"   ✔️ Grounding réussi.\")\n                    print(f\"     (Nombre de règles groundées: {ground_program.size()})\")\n                    # print(\"Programme Groundé:\\n\", str(ground_program)) # Potentiellement très long\n                except Exception as e_ground:\n                    print(f\"   ❌ Erreur lors du grounding: {e_ground}\")\n\n            except jpype.JException as e_clingo_java:\n                print(f\"❌ Erreur Java lors de l'appel à Clingo: {e_clingo_java.message()}\")\n                print(\"   Vérifiez que le chemin vers Clingo est correct et que Clingo fonctionne.\")\n                # print(e_clingo_java.stacktrace())\n            except Exception as e_clingo_py:\n                print(f\"❌ Erreur Python lors de l'appel à Clingo: {e_clingo_py}\")\n                import traceback; traceback.print_exc()\n\n\n    # ... (Blocs except globaux inchangés) ...\n    except ImportError as e: print(f\"❌ Erreur d'import pour ASP : {e}. Vérifiez le JAR 'lp.asp'.\")\n    except jpype.JException as e_java: print(f\"❌ Erreur Java générale ASP: {e_java.message()}\")\n    except Exception as e_gen: print(f\"❌ Erreur Python inattendue ASP: {e_gen}\"); import traceback; traceback.print_exc()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Navigation\n",
    "\n",
    "- **Precedent**: [Tweety-4-Belief-Revision.ipynb](Tweety-4-Belief-Revision.ipynb)\n",
    "- **Suivant**: [Tweety-6-Advanced-Argumentation.ipynb](Tweety-6-Advanced-Argumentation.ipynb)\n",
    "- **Index**: [Tweety-1-Setup.ipynb](Tweety-1-Setup.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp-jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}