{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-header",
   "metadata": {},
   "source": [
    "# SW-13-GraphRAG\n",
    "\n",
    "**Navigation** : [<< 12-KnowledgeGraphs](SW-12-KnowledgeGraphs.ipynb) | [Index](README.md)\n",
    "\n",
    "## Objectifs d'apprentissage\n",
    "\n",
    "A la fin de ce notebook, vous saurez :\n",
    "1. Comprendre le paradigme GraphRAG et ses avantages par rapport au RAG classique\n",
    "2. Combiner des graphes de connaissances (KG) avec des LLMs pour ameliorer la generation augmentee\n",
    "3. Implementer un pipeline KG-enhanced retrieval complet\n",
    "4. Evaluer les compromis entre RAG traditionnel et GraphRAG\n",
    "\n",
    "### Concepts cles\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| RAG | Retrieval-Augmented Generation : enrichir un LLM avec des documents retrouves |\n",
    "| GraphRAG | RAG augmente par la structure d'un graphe de connaissances |\n",
    "| KG (Knowledge Graph) | Graphe structure reliant des entites par des relations typees |\n",
    "| Extraction d'entites | Identification automatique de personnes, lieux, organisations dans du texte |\n",
    "| Subgraph retrieval | Extraction d'un sous-graphe pertinent autour d'entites identifiees |\n",
    "\n",
    "### Prerequis\n",
    "- SW-8 (rdflib et Python RDF)\n",
    "- SW-12 (Graphes de connaissances)\n",
    "- Cle API OpenAI ou Anthropic (optionnelle : le notebook fonctionne en mode degrade sans cle)\n",
    "\n",
    "### Duree estimee : 50 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-install-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Installation et configuration\n",
    "\n",
    "Installons les dependances necessaires. Les packages `openai` et `anthropic` sont optionnels : le notebook fonctionnera en mode simule si aucune cle API n'est configuree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q rdflib openai anthropic networkx python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-config-intro",
   "metadata": {},
   "source": [
    "### Configuration de l'environnement\n",
    "\n",
    "Nous chargeons les variables d'environnement depuis un fichier `.env` (s'il existe) et detectons la disponibilite des cles API. Le notebook adapte son comportement automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Chargement .env (optionnel)\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import rdflib\n",
    "from rdflib import Graph, Namespace, Literal, URIRef, BNode\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD, FOAF\n",
    "import networkx as nx\n",
    "\n",
    "# Detection des cles API\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "HAS_LLM = bool(OPENAI_KEY or ANTHROPIC_KEY)\n",
    "\n",
    "if HAS_LLM:\n",
    "    provider = \"OpenAI\" if OPENAI_KEY else \"Anthropic\"\n",
    "    print(f\"Cle API detectee : {provider}\")\n",
    "    print(\"Les sections LLM seront executees avec de vrais appels API.\")\n",
    "else:\n",
    "    print(\"Aucune cle API detectee (OPENAI_API_KEY / ANTHROPIC_API_KEY).\")\n",
    "    print(\"Les sections LLM afficheront des resultats simules.\")\n",
    "    print(\"Pour activer les appels LLM, creez un fichier .env avec votre cle.\")\n",
    "\n",
    "print(f\"\\nrdflib version : {rdflib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Du RAG au GraphRAG\n",
    "\n",
    "### Le RAG classique : rappel\n",
    "\n",
    "Le **Retrieval-Augmented Generation (RAG)** est un paradigme qui enrichit la generation par LLM avec des informations retrouvees dans une base documentaire. Le pipeline classique est :\n",
    "\n",
    "```\n",
    "Question utilisateur\n",
    "       |\n",
    "       v\n",
    "[Embedding de la question]\n",
    "       |\n",
    "       v\n",
    "[Recherche vectorielle dans la base]\n",
    "       |\n",
    "       v\n",
    "[Top-K documents pertinents]\n",
    "       |\n",
    "       v\n",
    "[Contexte + Question -> LLM]\n",
    "       |\n",
    "       v\n",
    "Reponse generee\n",
    "```\n",
    "\n",
    "### Les limitations du RAG classique\n",
    "\n",
    "| Limitation | Description | Exemple |\n",
    "|-----------|-------------|----------|\n",
    "| Pas de structure | Les chunks sont des blocs de texte plat | Relations entre entites perdues |\n",
    "| Pas de relations | La similarite vectorielle ne capture pas les liens | \"Qui sont les allies de X ?\" echoue |\n",
    "| Requetes globales | Questions sur l'ensemble du corpus mal gerees | \"Quel est le theme principal ?\" |\n",
    "| Contexte fragmente | Les chunks decoupent l'information | Un fait reparti sur 3 paragraphes |\n",
    "| Pas de raisonnement | Aucune inference logique sur les donnees | Transitivite, heritage ignorees |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-graphrag",
   "metadata": {},
   "source": [
    "### GraphRAG : ajouter la structure\n",
    "\n",
    "**GraphRAG** enrichit le pipeline RAG en ajoutant un **graphe de connaissances** comme source de contexte structuree. Au lieu de chercher uniquement des passages textuels similaires, on interroge un KG pour obtenir des faits structures et des relations.\n",
    "\n",
    "```\n",
    "Question utilisateur\n",
    "       |\n",
    "       v\n",
    "[Detection d'entites dans la question]\n",
    "       |                    |\n",
    "       v                    v\n",
    "[Recherche vectorielle]  [Requete KG (SPARQL)]\n",
    "       |                    |\n",
    "       v                    v\n",
    "[Passages textuels]  [Sous-graphe structure]\n",
    "       \\                  /\n",
    "        v                v\n",
    "     [Contexte combine -> LLM]\n",
    "              |\n",
    "              v\n",
    "       Reponse enrichie\n",
    "```\n",
    "\n",
    "### Microsoft GraphRAG (2024)\n",
    "\n",
    "En 2024, Microsoft Research a publie **GraphRAG**, une approche qui construit automatiquement un graphe de connaissances a partir d'un corpus de texte. Les etapes cles :\n",
    "\n",
    "1. **Extraction d'entites** : un LLM identifie les entites et relations dans chaque document\n",
    "2. **Construction du graphe** : les entites et relations forment un graphe global\n",
    "3. **Detection de communautes** : l'algorithme de Leiden identifie des clusters thematiques\n",
    "4. **Resumes de communautes** : chaque cluster est resume par un LLM\n",
    "5. **Requete** : les questions utilisent a la fois le graphe et les resumes\n",
    "\n",
    "### Comparaison RAG vs GraphRAG\n",
    "\n",
    "| Critere | RAG classique | GraphRAG |\n",
    "|---------|---------------|----------|\n",
    "| Source de contexte | Chunks textuels | Chunks + sous-graphe KG |\n",
    "| Structure des donnees | Plat (vecteurs) | Structure (triplets RDF) |\n",
    "| Requetes locales | Bon | Bon |\n",
    "| Requetes globales | Faible | Fort (resumes communautes) |\n",
    "| Relations multi-sauts | Faible | Fort (traversee de graphe) |\n",
    "| Cout de construction | Faible (embedding) | Eleve (extraction LLM) |\n",
    "| Cout de requete | Faible | Moyen (SPARQL + LLM) |\n",
    "| Hallucinations | Moyen | Reduit (faits verifiables) |\n",
    "| Mise a jour | Facile (re-embed) | Moyenne (re-extraction) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Construction d'un graphe de connaissances a partir de texte\n",
    "\n",
    "La premiere etape d'un pipeline GraphRAG est de construire un KG a partir de texte brut. Nous allons explorer deux approches :\n",
    "1. **Extraction par regles** (regex, patterns) : sans API, deterministe\n",
    "2. **Extraction par LLM** : plus robuste, necessite une cle API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-sample-text",
   "metadata": {},
   "source": [
    "### Texte source\n",
    "\n",
    "Nous utiliserons un passage sur l'histoire de France comme texte d'exemple pour l'extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-text",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texte source pour l'extraction d'entites et de relations\n",
    "SAMPLE_TEXT = \"\"\"\n",
    "Napoleon Bonaparte est ne en 1769 a Ajaccio, en Corse. Il est devenu empereur\n",
    "des Francais en 1804 apres avoir mene plusieurs campagnes militaires victorieuses.\n",
    "Napoleon a fonde la Banque de France en 1800 et a promulgue le Code civil en 1804.\n",
    "Il a epouse Josephine de Beauharnais en 1796, puis Marie-Louise d'Autriche en 1810.\n",
    "Sa defaite a Waterloo en 1815 face au duc de Wellington a mis fin a son regne.\n",
    "Il a ete exile a Sainte-Helene, une ile britannique dans l'Atlantique Sud,\n",
    "ou il est mort en 1821. Son heritage inclut le Code Napoleon, qui a influence\n",
    "le droit civil de nombreux pays europeens.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Texte source charge.\")\n",
    "print(f\"Longueur : {len(SAMPLE_TEXT)} caracteres, {len(SAMPLE_TEXT.split())} mots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-rules-intro",
   "metadata": {},
   "source": [
    "### 2.1 Extraction par regles (sans API)\n",
    "\n",
    "Cette approche utilise des expressions regulieres et des patterns linguistiques pour identifier des entites et relations. Elle est limitee mais illustre le principe d'extraction de triplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-rules",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_by_rules(text):\n",
    "    \"\"\"Extraction d'entites par regles (regex).\"\"\"\n",
    "    entities = {\n",
    "        \"persons\": [],\n",
    "        \"places\": [],\n",
    "        \"dates\": [],\n",
    "        \"organizations\": []\n",
    "    }\n",
    "\n",
    "    # Dates : annees a 4 chiffres\n",
    "    entities[\"dates\"] = list(set(re.findall(r'\\b(1[0-9]{3}|20[0-2][0-9])\\b', text)))\n",
    "\n",
    "    # Personnes : noms propres composes (prenom + nom)\n",
    "    person_patterns = [\n",
    "        r'(Napoleon Bonaparte)',\n",
    "        r'(Napoleon)',\n",
    "        r'(Josephine de Beauharnais)',\n",
    "        r'(Marie-Louise d\\'Autriche)',\n",
    "        r'(duc de Wellington)',\n",
    "    ]\n",
    "    for pattern in person_patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        entities[\"persons\"].extend(matches)\n",
    "    entities[\"persons\"] = list(set(entities[\"persons\"]))\n",
    "\n",
    "    # Lieux : detection basee sur des indices contextuels\n",
    "    place_patterns = [\n",
    "        r'a (Ajaccio)',\n",
    "        r'en (Corse)',\n",
    "        r'a (Waterloo)',\n",
    "        r'a (Sainte-Helene)',\n",
    "        r'l\\'(Atlantique Sud)',\n",
    "    ]\n",
    "    for pattern in place_patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        entities[\"places\"].extend(matches)\n",
    "    entities[\"places\"] = list(set(entities[\"places\"]))\n",
    "\n",
    "    # Organisations\n",
    "    org_patterns = [\n",
    "        r'(Banque de France)',\n",
    "        r'(Code civil)',\n",
    "        r'(Code Napoleon)',\n",
    "    ]\n",
    "    for pattern in org_patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        entities[\"organizations\"].extend(matches)\n",
    "    entities[\"organizations\"] = list(set(entities[\"organizations\"]))\n",
    "\n",
    "    return entities\n",
    "\n",
    "\n",
    "entities = extract_entities_by_rules(SAMPLE_TEXT)\n",
    "\n",
    "print(\"Entites extraites par regles :\")\n",
    "print(f\"  Personnes     : {entities['persons']}\")\n",
    "print(f\"  Lieux         : {entities['places']}\")\n",
    "print(f\"  Dates         : {sorted(entities['dates'])}\")\n",
    "print(f\"  Organisations : {entities['organizations']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-rules-interp",
   "metadata": {},
   "source": [
    "### Interpretation : extraction par regles\n",
    "\n",
    "L'extraction par regles a identifie les entites les plus evidentes du texte.\n",
    "\n",
    "| Type | Nombre | Exemples |\n",
    "|------|--------|----------|\n",
    "| Personnes | ~4-5 | Napoleon Bonaparte, Josephine de Beauharnais |\n",
    "| Lieux | ~4-5 | Ajaccio, Corse, Waterloo, Sainte-Helene |\n",
    "| Dates | ~6-7 | 1769, 1796, 1800, 1804, 1810, 1815, 1821 |\n",
    "| Organisations | ~2-3 | Banque de France, Code civil |\n",
    "\n",
    "**Limites de cette approche** :\n",
    "- Les patterns sont specifiques au texte (non generalisables)\n",
    "- Les entites ambigues ne sont pas desambiguisees\n",
    "- Les relations entre entites ne sont pas extraites\n",
    "- Un nouveau texte necessite de nouveaux patterns\n",
    "\n",
    "> **Note technique** : En production, on utiliserait des outils de NER (Named Entity Recognition) comme spaCy ou des modeles transformer pour une extraction plus robuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-triples-intro",
   "metadata": {},
   "source": [
    "### 2.2 Generation de triplets a partir du texte\n",
    "\n",
    "Nous allons maintenant extraire des **relations** entre les entites pour former des triplets (sujet, predicat, objet). Commençons par une approche par regles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-triples",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_by_rules(text):\n",
    "    \"\"\"Extraction de triplets par patterns linguistiques.\"\"\"\n",
    "    triples = []\n",
    "\n",
    "    # Pattern : X est ne en ANNEE a LIEU\n",
    "    m = re.search(r'(Napoleon Bonaparte) est ne en (\\d{4}) a (\\w+)', text)\n",
    "    if m:\n",
    "        triples.append((m.group(1), \"ne_en_annee\", m.group(2)))\n",
    "        triples.append((m.group(1), \"ne_a\", m.group(3)))\n",
    "\n",
    "    # Pattern : X est devenu Y en ANNEE\n",
    "    m = re.search(r'(\\w+) est devenu (empereur[^.]*) en (\\d{4})', text)\n",
    "    if m:\n",
    "        triples.append((m.group(1).strip(), \"titre\", \"empereur des Francais\"))\n",
    "        triples.append((m.group(1).strip(), \"debut_regne\", m.group(3)))\n",
    "\n",
    "    # Pattern : X a fonde Y en ANNEE\n",
    "    for m in re.finditer(r'(Napoleon|Il) a fonde (la [^.]+?) en (\\d{4})', text):\n",
    "        triples.append((\"Napoleon\", \"a_fonde\", m.group(2).strip()))\n",
    "        triples.append((m.group(2).strip(), \"date_creation\", m.group(3)))\n",
    "\n",
    "    # Pattern : X a promulgue Y en ANNEE\n",
    "    for m in re.finditer(r'(?:Napoleon|[Ii]l) a promulgue (le [^.]+?) en (\\d{4})', text):\n",
    "        triples.append((\"Napoleon\", \"a_promulgue\", m.group(1).strip()))\n",
    "\n",
    "    # Pattern : X a epouse Y en ANNEE\n",
    "    for m in re.finditer(r'(?:Il|Napoleon) a epouse (\\w[^,]+?) en (\\d{4})', text):\n",
    "        triples.append((\"Napoleon\", \"a_epouse\", m.group(1).strip()))\n",
    "        triples.append((\"Napoleon\", \"mariage_annee\", m.group(2)))\n",
    "\n",
    "    # Pattern : defaite a LIEU en ANNEE face a PERSONNE\n",
    "    m = re.search(r'defaite a (\\w+) en (\\d{4}) face au (\\w+ de \\w+)', text)\n",
    "    if m:\n",
    "        triples.append((\"Napoleon\", \"defaite_a\", m.group(1)))\n",
    "        triples.append((\"Bataille de \" + m.group(1), \"date\", m.group(2)))\n",
    "        triples.append((\"Napoleon\", \"vaincu_par\", m.group(3)))\n",
    "\n",
    "    # Pattern : exile a LIEU\n",
    "    m = re.search(r'exile a (Sainte-Helene)', text)\n",
    "    if m:\n",
    "        triples.append((\"Napoleon\", \"exile_a\", m.group(1)))\n",
    "\n",
    "    # Pattern : mort en ANNEE\n",
    "    m = re.search(r'mort en (\\d{4})', text)\n",
    "    if m:\n",
    "        triples.append((\"Napoleon\", \"mort_en\", m.group(1)))\n",
    "\n",
    "    return triples\n",
    "\n",
    "\n",
    "triples = extract_triples_by_rules(SAMPLE_TEXT)\n",
    "\n",
    "print(f\"Triplets extraits : {len(triples)}\\n\")\n",
    "print(f\"{'Sujet':<25} {'Predicat':<20} {'Objet'}\")\n",
    "print(\"-\" * 75)\n",
    "for s, p, o in triples:\n",
    "    print(f\"{s:<25} {p:<20} {o}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-triples-interp",
   "metadata": {},
   "source": [
    "### Interpretation : triplets extraits\n",
    "\n",
    "L'extraction par regles a produit une dizaine de triplets structures. Chaque triplet represente un fait atomique :\n",
    "\n",
    "| Categorie | Exemple de triplet | Fiabilite |\n",
    "|-----------|-------------------|------------|\n",
    "| Biographie | (Napoleon, ne_a, Ajaccio) | Haute |\n",
    "| Chronologie | (Napoleon, ne_en_annee, 1769) | Haute |\n",
    "| Relations | (Napoleon, a_epouse, Josephine de Beauharnais) | Haute |\n",
    "| Evenements | (Napoleon, defaite_a, Waterloo) | Haute |\n",
    "| Realisations | (Napoleon, a_fonde, la Banque de France) | Haute |\n",
    "\n",
    "**Points cles** :\n",
    "1. Les triplets sont des faits **atomiques** et **verifiables**\n",
    "2. Les predicats sont normalises (conventions de nommage)\n",
    "3. L'approche par regles est **precise** mais **peu generalisable**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-llm-intro",
   "metadata": {},
   "source": [
    "### 2.3 Extraction par LLM (optionnelle)\n",
    "\n",
    "Un LLM peut extraire des triplets de maniere beaucoup plus robuste et generalisable. Cette section necessite une cle API. Sans cle, un resultat simule sera affiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-llm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triples_llm(text):\n",
    "    \"\"\"Extraction de triplets via LLM (OpenAI ou Anthropic).\"\"\"\n",
    "    prompt = f\"\"\"Extrait tous les triplets (sujet, predicat, objet) du texte suivant.\n",
    "Retourne le resultat en JSON : une liste de dictionnaires avec les cles \"subject\", \"predicate\", \"object\".\n",
    "Utilise des predicats normalises en snake_case.\n",
    "\n",
    "Texte :\n",
    "{text}\n",
    "\n",
    "Retourne UNIQUEMENT le JSON, sans commentaire.\"\"\"\n",
    "\n",
    "    try:\n",
    "        if OPENAI_KEY:\n",
    "            from openai import OpenAI\n",
    "            client = OpenAI(api_key=OPENAI_KEY)\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            raw = response.choices[0].message.content\n",
    "        elif ANTHROPIC_KEY:\n",
    "            from anthropic import Anthropic\n",
    "            client = Anthropic(api_key=ANTHROPIC_KEY)\n",
    "            response = client.messages.create(\n",
    "                model=\"claude-sonnet-4-20250514\",\n",
    "                max_tokens=2000,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            raw = response.content[0].text\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        # Nettoyage du JSON (enlever les balises markdown)\n",
    "        raw = raw.strip()\n",
    "        if raw.startswith(\"```\"):\n",
    "            raw = re.sub(r'^```(?:json)?\\n?', '', raw)\n",
    "            raw = re.sub(r'\\n?```$', '', raw)\n",
    "        return json.loads(raw)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'appel LLM : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Resultat simule (utilise si pas de cle API)\n",
    "SIMULATED_LLM_TRIPLES = [\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"born_in_year\", \"object\": \"1769\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"born_in_place\", \"object\": \"Ajaccio\"},\n",
    "    {\"subject\": \"Ajaccio\", \"predicate\": \"located_in\", \"object\": \"Corse\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"became\", \"object\": \"Empereur des Francais\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"became_emperor_year\", \"object\": \"1804\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"founded\", \"object\": \"Banque de France\"},\n",
    "    {\"subject\": \"Banque de France\", \"predicate\": \"founded_year\", \"object\": \"1800\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"promulgated\", \"object\": \"Code civil\"},\n",
    "    {\"subject\": \"Code civil\", \"predicate\": \"promulgated_year\", \"object\": \"1804\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"married\", \"object\": \"Josephine de Beauharnais\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"marriage_year\", \"object\": \"1796\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"married\", \"object\": \"Marie-Louise d'Autriche\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"marriage_year\", \"object\": \"1810\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"defeated_at\", \"object\": \"Waterloo\"},\n",
    "    {\"subject\": \"Bataille de Waterloo\", \"predicate\": \"year\", \"object\": \"1815\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"defeated_by\", \"object\": \"Duc de Wellington\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"exiled_to\", \"object\": \"Sainte-Helene\"},\n",
    "    {\"subject\": \"Sainte-Helene\", \"predicate\": \"type\", \"object\": \"Ile britannique\"},\n",
    "    {\"subject\": \"Sainte-Helene\", \"predicate\": \"located_in\", \"object\": \"Atlantique Sud\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"died_year\", \"object\": \"1821\"},\n",
    "    {\"subject\": \"Napoleon Bonaparte\", \"predicate\": \"legacy\", \"object\": \"Code Napoleon\"},\n",
    "    {\"subject\": \"Code Napoleon\", \"predicate\": \"influenced\", \"object\": \"droit civil europeen\"}\n",
    "]\n",
    "\n",
    "if HAS_LLM:\n",
    "    llm_triples = extract_triples_llm(SAMPLE_TEXT)\n",
    "    if llm_triples is None:\n",
    "        print(\"Appel LLM echoue. Utilisation des resultats simules.\")\n",
    "        llm_triples = SIMULATED_LLM_TRIPLES\n",
    "    else:\n",
    "        print(f\"Triplets extraits par LLM : {len(llm_triples)}\")\n",
    "else:\n",
    "    print(\"Mode simule (pas de cle API).\")\n",
    "    llm_triples = SIMULATED_LLM_TRIPLES\n",
    "    print(f\"Triplets simules : {len(llm_triples)}\")\n",
    "\n",
    "print(f\"\\n{'Sujet':<28} {'Predicat':<22} {'Objet'}\")\n",
    "print(\"-\" * 80)\n",
    "for t in llm_triples:\n",
    "    print(f\"{t['subject']:<28} {t['predicate']:<22} {t['object']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-llm-interp",
   "metadata": {},
   "source": [
    "### Interpretation : comparaison regles vs LLM\n",
    "\n",
    "| Critere | Extraction par regles | Extraction par LLM |\n",
    "|---------|----------------------|---------------------|\n",
    "| Nombre de triplets | ~10-12 | ~20-25 |\n",
    "| Generalisabilite | Faible (patterns specifiques) | Forte (tout texte) |\n",
    "| Precision | Haute (patterns exacts) | Haute (mais hallucinations possibles) |\n",
    "| Rappel | Faible (beaucoup de faits manques) | Eleve |\n",
    "| Cout | Gratuit | Payant (tokens API) |\n",
    "| Reproductibilite | Parfaite | Variable (temperature) |\n",
    "\n",
    "Le LLM a extrait des relations plus riches, incluant des faits implicites (ex: Sainte-Helene est une ile britannique) que l'approche par regles aurait manques.\n",
    "\n",
    "> **Point cle** : En pratique, on combine souvent les deux approches : regles pour les patterns connus et fiables, LLM pour couvrir le reste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Retrieval augmente par graphe de connaissances\n",
    "\n",
    "Nous allons maintenant construire un veritable graphe RDF a partir des triplets extraits, puis l'utiliser pour du retrieval structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-build-intro",
   "metadata": {},
   "source": [
    "### 3.1 Construction du KG en RDF\n",
    "\n",
    "Convertissons les triplets extraits en un graphe RDF avec rdflib. Nous utilisons un namespace dedie pour notre domaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-build",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace pour notre domaine\n",
    "EX = Namespace(\"http://example.org/history/\")\n",
    "REL = Namespace(\"http://example.org/relation/\")\n",
    "\n",
    "\n",
    "def name_to_uri(name):\n",
    "    \"\"\"Convertit un nom en URI valide.\"\"\"\n",
    "    slug = name.strip().replace(\" \", \"_\").replace(\"'\", \"\").replace(\"'\", \"\")\n",
    "    slug = re.sub(r'[^a-zA-Z0-9_-]', '', slug)\n",
    "    return EX[slug]\n",
    "\n",
    "\n",
    "def build_kg_from_triples(triple_list):\n",
    "    \"\"\"Construit un graphe RDF a partir d'une liste de triplets.\"\"\"\n",
    "    g = Graph()\n",
    "    g.bind(\"ex\", EX)\n",
    "    g.bind(\"rel\", REL)\n",
    "    g.bind(\"rdfs\", RDFS)\n",
    "\n",
    "    for t in triple_list:\n",
    "        subj = name_to_uri(t[\"subject\"])\n",
    "        pred = REL[t[\"predicate\"]]\n",
    "        obj_val = t[\"object\"]\n",
    "\n",
    "        # Si l'objet ressemble a une annee, on en fait un literal\n",
    "        if re.match(r'^\\d{4}$', obj_val):\n",
    "            obj = Literal(int(obj_val), datatype=XSD.gYear)\n",
    "        else:\n",
    "            # On cree un noeud URI pour les entites, un literal pour les descriptions\n",
    "            if len(obj_val.split()) <= 4 and obj_val[0].isupper():\n",
    "                obj = name_to_uri(obj_val)\n",
    "                # Ajouter un label RDFS\n",
    "                g.add((obj, RDFS.label, Literal(obj_val, lang=\"fr\")))\n",
    "            else:\n",
    "                obj = Literal(obj_val, lang=\"fr\")\n",
    "\n",
    "        g.add((subj, pred, obj))\n",
    "        # Label pour le sujet\n",
    "        g.add((subj, RDFS.label, Literal(t[\"subject\"], lang=\"fr\")))\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "kg = build_kg_from_triples(llm_triples)\n",
    "\n",
    "print(f\"Graphe de connaissances construit :\")\n",
    "print(f\"  Nombre de triplets : {len(kg)}\")\n",
    "print(f\"  Sujets uniques     : {len(set(s for s, _, _ in kg))}\")\n",
    "print(f\"  Predicats uniques  : {len(set(p for _, p, _ in kg))}\")\n",
    "print(f\"\\nExtrait du graphe (10 premiers triplets) :\")\n",
    "for i, (s, p, o) in enumerate(kg):\n",
    "    if i >= 10:\n",
    "        print(\"  ...\")\n",
    "        break\n",
    "    s_label = s.split('/')[-1].replace('_', ' ')\n",
    "    p_label = p.split('/')[-1]\n",
    "    o_label = str(o).split('/')[-1].replace('_', ' ') if isinstance(o, URIRef) else str(o)\n",
    "    print(f\"  ({s_label}, {p_label}, {o_label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-build-interp",
   "metadata": {},
   "source": [
    "### Interpretation : KG construit\n",
    "\n",
    "Le graphe RDF contient desormais les faits structures extraits du texte. Chaque entite est identifiee par une URI unique, et les relations sont typees.\n",
    "\n",
    "**Points cles** :\n",
    "1. Les entites nommees (personnes, lieux) sont des `URIRef` pour permettre les liens\n",
    "2. Les dates sont des `Literal` types (`xsd:gYear`) pour les requetes numeriques\n",
    "3. Les labels RDFS ajoutent des noms lisibles aux URIs\n",
    "4. Le graphe est interrogeable via SPARQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-sparql-intro",
   "metadata": {},
   "source": [
    "### 3.2 Requetes SPARQL comme contexte\n",
    "\n",
    "L'avantage principal du KG est de pouvoir repondre a des questions structurees via SPARQL, ce que la recherche vectorielle ne peut pas faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-sparql",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requete 1 : Tous les faits sur Napoleon\n",
    "query_napoleon = \"\"\"\n",
    "PREFIX ex: <http://example.org/history/>\n",
    "PREFIX rel: <http://example.org/relation/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?predicate ?object ?obj_label\n",
    "WHERE {\n",
    "    ex:Napoleon_Bonaparte ?predicate ?object .\n",
    "    FILTER(?predicate != rdfs:label)\n",
    "    OPTIONAL { ?object rdfs:label ?obj_label }\n",
    "}\n",
    "ORDER BY ?predicate\n",
    "\"\"\"\n",
    "\n",
    "print(\"Requete : Tous les faits sur Napoleon Bonaparte\")\n",
    "print(\"=\" * 60)\n",
    "results = kg.query(query_napoleon)\n",
    "for row in results:\n",
    "    pred = str(row.predicate).split('/')[-1]\n",
    "    obj = str(row.obj_label) if row.obj_label else str(row.object).split('/')[-1].replace('_', ' ')\n",
    "    print(f\"  {pred:<25} {obj}\")\n",
    "\n",
    "print(f\"\\nTotal : {len(results)} faits retrouves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-sparql2-intro",
   "metadata": {},
   "source": [
    "Testons une deuxieme requete, de type multi-sauts : quels lieux sont lies a Napoleon ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-sparql2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requete 2 : Lieux lies a Napoleon (multi-sauts)\n",
    "query_places = \"\"\"\n",
    "PREFIX ex: <http://example.org/history/>\n",
    "PREFIX rel: <http://example.org/relation/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?relation ?place ?place_label ?detail_pred ?detail_obj\n",
    "WHERE {\n",
    "    ex:Napoleon_Bonaparte ?relation ?place .\n",
    "    FILTER(CONTAINS(STR(?relation), \"born_in_place\") ||\n",
    "           CONTAINS(STR(?relation), \"defeated_at\") ||\n",
    "           CONTAINS(STR(?relation), \"exiled_to\") ||\n",
    "           CONTAINS(STR(?relation), \"ne_a\") ||\n",
    "           CONTAINS(STR(?relation), \"defaite_a\") ||\n",
    "           CONTAINS(STR(?relation), \"exile_a\"))\n",
    "    OPTIONAL { ?place rdfs:label ?place_label }\n",
    "    OPTIONAL {\n",
    "        ?place ?detail_pred ?detail_obj .\n",
    "        FILTER(?detail_pred != rdfs:label)\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Requete : Lieux lies a Napoleon (avec details)\")\n",
    "print(\"=\" * 60)\n",
    "results = kg.query(query_places)\n",
    "for row in results:\n",
    "    rel = str(row.relation).split('/')[-1]\n",
    "    place = str(row.place_label) if row.place_label else str(row.place).split('/')[-1].replace('_', ' ')\n",
    "    detail = \"\"\n",
    "    if row.detail_pred:\n",
    "        dp = str(row.detail_pred).split('/')[-1]\n",
    "        do = str(row.detail_obj).split('/')[-1].replace('_', ' ')\n",
    "        detail = f\" -> {dp}: {do}\"\n",
    "    print(f\"  {rel:<20} {place}{detail}\")\n",
    "\n",
    "print(f\"\\nTotal : {len(results)} resultats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-sparql-interp",
   "metadata": {},
   "source": [
    "### Interpretation : SPARQL pour le retrieval\n",
    "\n",
    "Les requetes SPARQL offrent des avantages decisifs par rapport a la recherche vectorielle :\n",
    "\n",
    "| Capacite | Recherche vectorielle | SPARQL sur KG |\n",
    "|----------|----------------------|----------------|\n",
    "| \"Tous les faits sur X\" | Approximatif (top-K similaires) | Exact (tous les triplets de X) |\n",
    "| \"Lieux lies a X\" | Mauvais (mots-cles \"lieu\" + \"X\") | Precis (relations typees) |\n",
    "| Multi-sauts | Impossible | Natif (jointures SPARQL) |\n",
    "| Filtrage par type | Limité | Natif (FILTER, rdf:type) |\n",
    "\n",
    "> **Point cle** : SPARQL garantit une precision de 100% sur les faits du KG, alors que la recherche vectorielle ne fournit que des approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-subgraph-intro",
   "metadata": {},
   "source": [
    "### 3.3 Extraction de sous-graphe\n",
    "\n",
    "Pour fournir un contexte au LLM, on extrait le **voisinage** d'une entite : tous les triplets directement lies a cette entite (1 saut) ou a 2 sauts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-subgraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subgraph(graph, entity_uri, max_hops=2):\n",
    "    \"\"\"Extrait le sous-graphe autour d'une entite (N sauts).\"\"\"\n",
    "    subgraph = Graph()\n",
    "    subgraph.bind(\"ex\", EX)\n",
    "    subgraph.bind(\"rel\", REL)\n",
    "    subgraph.bind(\"rdfs\", RDFS)\n",
    "\n",
    "    visited = set()\n",
    "    frontier = {entity_uri}\n",
    "\n",
    "    for hop in range(max_hops):\n",
    "        next_frontier = set()\n",
    "        for entity in frontier:\n",
    "            if entity in visited:\n",
    "                continue\n",
    "            visited.add(entity)\n",
    "\n",
    "            # Triplets ou l'entite est sujet\n",
    "            for s, p, o in graph.triples((entity, None, None)):\n",
    "                subgraph.add((s, p, o))\n",
    "                if isinstance(o, URIRef):\n",
    "                    next_frontier.add(o)\n",
    "\n",
    "            # Triplets ou l'entite est objet\n",
    "            for s, p, o in graph.triples((None, None, entity)):\n",
    "                subgraph.add((s, p, o))\n",
    "                if isinstance(s, URIRef):\n",
    "                    next_frontier.add(s)\n",
    "\n",
    "        frontier = next_frontier - visited\n",
    "\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "# Extraire le sous-graphe autour de Napoleon (2 sauts)\n",
    "napoleon_uri = EX[\"Napoleon_Bonaparte\"]\n",
    "subgraph = extract_subgraph(kg, napoleon_uri, max_hops=2)\n",
    "\n",
    "print(f\"Sous-graphe autour de Napoleon Bonaparte :\")\n",
    "print(f\"  Triplets (graphe complet) : {len(kg)}\")\n",
    "print(f\"  Triplets (sous-graphe)    : {len(subgraph)}\")\n",
    "print(f\"  Ratio                     : {len(subgraph)/len(kg)*100:.0f}%\")\n",
    "print(f\"\\nTriplets du sous-graphe :\")\n",
    "for s, p, o in sorted(subgraph, key=lambda x: str(x[0])):\n",
    "    s_l = str(s).split('/')[-1].replace('_', ' ')\n",
    "    p_l = str(p).split('/')[-1]\n",
    "    o_l = str(o).split('/')[-1].replace('_', ' ') if isinstance(o, URIRef) else str(o)\n",
    "    print(f\"  ({s_l}, {p_l}, {o_l})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-subgraph-interp",
   "metadata": {},
   "source": [
    "### Interpretation : sous-graphe extrait\n",
    "\n",
    "Le sous-graphe a 2 sauts capture l'essentiel des informations liees a Napoleon, y compris les details sur les entites connectees (ex: Sainte-Helene est une ile britannique).\n",
    "\n",
    "**Comparaison des profondeurs de sous-graphe** :\n",
    "\n",
    "| Profondeur | Triplets | Information | Usage |\n",
    "|-----------|----------|-------------|-------|\n",
    "| 1 saut | ~15 | Faits directs | Questions simples |\n",
    "| 2 sauts | ~30+ | Faits + contexte | Questions complexes |\n",
    "| 3+ sauts | Tout le graphe | Trop de bruit | Rarement utile |\n",
    "\n",
    "> **Bonne pratique** : 2 sauts est generalement le meilleur compromis entre completude et pertinence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Pipeline GraphRAG simplifie\n",
    "\n",
    "Assemblons maintenant les composants precedents en un **pipeline GraphRAG complet**. Le pipeline suit 4 etapes :\n",
    "1. Detection d'entites dans la question utilisateur\n",
    "2. Requete du KG pour recuperer le sous-graphe pertinent\n",
    "3. Formatage du contexte KG en texte structure\n",
    "4. Generation de la reponse par LLM (ou simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-step1-intro",
   "metadata": {},
   "source": [
    "### Etape 1 : Detection d'entites dans la question\n",
    "\n",
    "Pour identifier quelles entites du KG sont mentionnees dans la question, nous utilisons un matching simple par labels RDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-step1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_entities_in_question(question, graph):\n",
    "    \"\"\"Detecte les entites du KG mentionnees dans la question.\"\"\"\n",
    "    # Recuperer tous les labels du graphe\n",
    "    entity_labels = {}\n",
    "    for s, p, o in graph.triples((None, RDFS.label, None)):\n",
    "        label = str(o).lower()\n",
    "        entity_labels[label] = s\n",
    "\n",
    "    # Chercher les entites dans la question (matching exact sur le label)\n",
    "    question_lower = question.lower()\n",
    "    found = []\n",
    "    # Trier par longueur decroissante pour matcher les noms complets d'abord\n",
    "    for label, uri in sorted(entity_labels.items(), key=lambda x: -len(x[0])):\n",
    "        if label in question_lower:\n",
    "            found.append({\"label\": label, \"uri\": uri})\n",
    "            # Eviter les doublons partiels\n",
    "            question_lower = question_lower.replace(label, \"\")\n",
    "\n",
    "    return found\n",
    "\n",
    "\n",
    "# Test avec plusieurs questions\n",
    "test_questions = [\n",
    "    \"Ou est ne Napoleon Bonaparte ?\",\n",
    "    \"Qui a vaincu Napoleon a Waterloo ?\",\n",
    "    \"Qu'est-ce que le Code civil ?\",\n",
    "    \"Ou Napoleon a-t-il ete exile ?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    entities = detect_entities_in_question(q, kg)\n",
    "    entity_names = [e[\"label\"] for e in entities]\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"   Entites detectees : {entity_names}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-step1-interp",
   "metadata": {},
   "source": [
    "### Interpretation : detection d'entites\n",
    "\n",
    "La detection par matching de labels est simple mais efficace pour un KG de petite taille. En production, on utiliserait :\n",
    "- **Entity linking** : desambiguisation vers des entites connues (Wikidata, DBpedia)\n",
    "- **Fuzzy matching** : tolerance aux variantes orthographiques\n",
    "- **NER + linking** : extraction d'entites puis alignement avec le KG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-step2-intro",
   "metadata": {},
   "source": [
    "### Etape 2 : Requete du KG\n",
    "\n",
    "Pour chaque entite detectee, on extrait le sous-graphe pertinent via SPARQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-step2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_kg_context(question, graph, max_hops=1):\n",
    "    \"\"\"Recupere le contexte KG pertinent pour une question.\"\"\"\n",
    "    entities = detect_entities_in_question(question, graph)\n",
    "\n",
    "    if not entities:\n",
    "        return [], \"Aucune entite reconnue dans la question.\"\n",
    "\n",
    "    # Extraire le sous-graphe pour chaque entite detectee\n",
    "    all_triples = []\n",
    "    for entity in entities:\n",
    "        sub = extract_subgraph(graph, entity[\"uri\"], max_hops=max_hops)\n",
    "        for s, p, o in sub:\n",
    "            # Ignorer les labels RDFS pour le contexte\n",
    "            if p == RDFS.label:\n",
    "                continue\n",
    "            s_label = str(s).split('/')[-1].replace('_', ' ')\n",
    "            p_label = str(p).split('/')[-1]\n",
    "            if isinstance(o, URIRef):\n",
    "                o_label = str(o).split('/')[-1].replace('_', ' ')\n",
    "            else:\n",
    "                o_label = str(o)\n",
    "            triple_str = f\"{s_label} -- {p_label} --> {o_label}\"\n",
    "            if triple_str not in all_triples:\n",
    "                all_triples.append(triple_str)\n",
    "\n",
    "    entity_names = [e[\"label\"] for e in entities]\n",
    "    summary = f\"Entites : {', '.join(entity_names)} | Faits : {len(all_triples)}\"\n",
    "\n",
    "    return all_triples, summary\n",
    "\n",
    "\n",
    "# Test\n",
    "question = \"Ou est ne Napoleon Bonaparte et ou a-t-il ete exile ?\"\n",
    "triples, summary = retrieve_kg_context(question, kg, max_hops=1)\n",
    "\n",
    "print(f\"Question : {question}\")\n",
    "print(f\"Resume   : {summary}\")\n",
    "print(f\"\\nFaits retrouves du KG :\")\n",
    "for t in triples:\n",
    "    print(f\"  {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-step3-intro",
   "metadata": {},
   "source": [
    "### Etape 3 : Formatage du contexte KG\n",
    "\n",
    "Le contexte KG doit etre formate en texte structure pour etre injecte dans le prompt du LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-step3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_kg_context(triples, question):\n",
    "    \"\"\"Formate le contexte KG en texte structure pour le LLM.\"\"\"\n",
    "    if not triples:\n",
    "        return \"Aucun fait pertinent trouve dans le graphe de connaissances.\"\n",
    "\n",
    "    context = \"FAITS STRUCTURES (extraits du graphe de connaissances) :\\n\"\n",
    "    context += \"-\" * 50 + \"\\n\"\n",
    "\n",
    "    # Grouper par sujet\n",
    "    by_subject = defaultdict(list)\n",
    "    for t in triples:\n",
    "        parts = t.split(\" -- \")\n",
    "        if len(parts) >= 2:\n",
    "            subject = parts[0].strip()\n",
    "            rest = \" -- \".join(parts[1:])\n",
    "            by_subject[subject].append(rest)\n",
    "\n",
    "    for subject, facts in by_subject.items():\n",
    "        context += f\"\\n{subject} :\\n\"\n",
    "        for fact in facts:\n",
    "            context += f\"  - {fact}\\n\"\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "# Test\n",
    "formatted = format_kg_context(triples, question)\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-step4-intro",
   "metadata": {},
   "source": [
    "### Etape 4 : Generation de la reponse\n",
    "\n",
    "Enfin, nous envoyons la question et le contexte KG au LLM. Si aucune cle API n'est disponible, une reponse simulee est produite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-step4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(question, kg_context):\n",
    "    \"\"\"Genere une reponse en utilisant le LLM avec le contexte KG.\"\"\"\n",
    "    system_prompt = \"\"\"Tu es un assistant qui repond aux questions en te basant\n",
    "UNIQUEMENT sur les faits fournis dans le contexte structure.\n",
    "Si le contexte ne contient pas l'information, dis-le clairement.\n",
    "Cite les faits utilises dans ta reponse.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Contexte :\n",
    "{kg_context}\n",
    "\n",
    "Question : {question}\n",
    "\n",
    "Reponds en francais en citant les faits du graphe de connaissances.\"\"\"\n",
    "\n",
    "    try:\n",
    "        if OPENAI_KEY:\n",
    "            from openai import OpenAI\n",
    "            client = OpenAI(api_key=OPENAI_KEY)\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            return response.choices[0].message.content, \"openai\"\n",
    "\n",
    "        elif ANTHROPIC_KEY:\n",
    "            from anthropic import Anthropic\n",
    "            client = Anthropic(api_key=ANTHROPIC_KEY)\n",
    "            response = client.messages.create(\n",
    "                model=\"claude-sonnet-4-20250514\",\n",
    "                max_tokens=1000,\n",
    "                system=system_prompt,\n",
    "                messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "            )\n",
    "            return response.content[0].text, \"anthropic\"\n",
    "\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur LLM : {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Reponse simulee\n",
    "SIMULATED_RESPONSE = \"\"\"D'apres le graphe de connaissances :\n",
    "\n",
    "Napoleon Bonaparte est ne a **Ajaccio**, en Corse (fait : born_in_place -> Ajaccio,\n",
    "Ajaccio located_in -> Corse).\n",
    "\n",
    "Apres sa defaite a Waterloo en 1815, il a ete exile a **Sainte-Helene**,\n",
    "une ile britannique situee dans l'Atlantique Sud (faits : exiled_to -> Sainte-Helene,\n",
    "Sainte-Helene type -> Ile britannique, Sainte-Helene located_in -> Atlantique Sud).\n",
    "\n",
    "Il y est mort en 1821 (fait : died_year -> 1821).\"\"\"\n",
    "\n",
    "# Execution du pipeline complet\n",
    "question = \"Ou est ne Napoleon Bonaparte et ou a-t-il ete exile ?\"\n",
    "print(f\"Question : {question}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Etapes 1-3\n",
    "triples, summary = retrieve_kg_context(question, kg, max_hops=2)\n",
    "kg_context = format_kg_context(triples, question)\n",
    "print(f\"\\n[Retrieval] {summary}\")\n",
    "\n",
    "# Etape 4\n",
    "response, provider = generate_response(question, kg_context)\n",
    "if response:\n",
    "    print(f\"\\n[Generation via {provider}]\")\n",
    "    print(response)\n",
    "else:\n",
    "    print(f\"\\n[Generation simulee - pas de cle API]\")\n",
    "    print(SIMULATED_RESPONSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-step4-interp",
   "metadata": {},
   "source": [
    "### Interpretation : pipeline GraphRAG\n",
    "\n",
    "Le pipeline GraphRAG complet fonctionne en 4 etapes orchestrees :\n",
    "\n",
    "| Etape | Entree | Sortie | Composant |\n",
    "|-------|--------|--------|-----------|\n",
    "| 1. Detection | Question texte | Liste d'entites | Matching labels KG |\n",
    "| 2. Retrieval | Entites | Sous-graphe | SPARQL / traversee |\n",
    "| 3. Formatage | Triplets | Texte structure | Template |\n",
    "| 4. Generation | Contexte + question | Reponse | LLM |\n",
    "\n",
    "**Avantage cle** : la reponse est **fondee sur des faits verifiables** du KG. Chaque assertion peut etre tracee jusqu'a un triplet specifique, ce qui reduit drastiquement les hallucinations.\n",
    "\n",
    "> **Note technique** : En production, l'etape 4 combine souvent le contexte KG avec des passages textuels retrouves par recherche vectorielle (approche hybride)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-full-intro",
   "metadata": {},
   "source": [
    "### Pipeline complet : classe GraphRAG\n",
    "\n",
    "Encapsulons le pipeline dans une classe reutilisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-full",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGraphRAG:\n",
    "    \"\"\"Pipeline GraphRAG simplifie.\"\"\"\n",
    "\n",
    "    def __init__(self, knowledge_graph, max_hops=2):\n",
    "        self.kg = knowledge_graph\n",
    "        self.max_hops = max_hops\n",
    "\n",
    "    def query(self, question):\n",
    "        \"\"\"Execute le pipeline complet.\"\"\"\n",
    "        # Etape 1 : Detection d'entites\n",
    "        entities = detect_entities_in_question(question, self.kg)\n",
    "\n",
    "        # Etape 2 : Retrieval KG\n",
    "        triples, summary = retrieve_kg_context(question, self.kg, self.max_hops)\n",
    "\n",
    "        # Etape 3 : Formatage\n",
    "        context = format_kg_context(triples, question)\n",
    "\n",
    "        # Etape 4 : Generation\n",
    "        response, provider = generate_response(question, context)\n",
    "\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"entities_found\": [e[\"label\"] for e in entities],\n",
    "            \"kg_facts\": len(triples),\n",
    "            \"context\": context,\n",
    "            \"response\": response,\n",
    "            \"provider\": provider,\n",
    "            \"grounded\": response is not None\n",
    "        }\n",
    "\n",
    "\n",
    "# Instancier le pipeline\n",
    "rag = SimpleGraphRAG(kg, max_hops=2)\n",
    "\n",
    "# Tester avec plusieurs questions\n",
    "questions = [\n",
    "    \"Qui a epouse Napoleon Bonaparte ?\",\n",
    "    \"Quand a eu lieu la bataille de Waterloo ?\",\n",
    "    \"Quel est l'heritage de Napoleon ?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = rag.query(q)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"   Entites   : {result['entities_found']}\")\n",
    "    print(f\"   Faits KG  : {result['kg_facts']}\")\n",
    "    if result[\"response\"]:\n",
    "        # Afficher les premieres lignes\n",
    "        lines = result[\"response\"].split('\\n')[:3]\n",
    "        print(f\"   Reponse   : {lines[0]}\")\n",
    "    else:\n",
    "        print(f\"   Reponse   : [simulee - pas de cle API]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-full-interp",
   "metadata": {},
   "source": [
    "### Interpretation : classe SimpleGraphRAG\n",
    "\n",
    "La classe `SimpleGraphRAG` encapsule les 4 etapes du pipeline. Pour chaque question, elle retourne un dictionnaire avec toutes les informations de tracing :\n",
    "\n",
    "| Champ | Description | Utilite |\n",
    "|-------|-------------|----------|\n",
    "| `entities_found` | Entites detectees | Debugging du retrieval |\n",
    "| `kg_facts` | Nombre de faits KG | Evaluation de la couverture |\n",
    "| `context` | Texte structure | Transparence du prompt |\n",
    "| `response` | Reponse generee | Resultat final |\n",
    "| `grounded` | True si LLM utilise | Distinction simule/reel |\n",
    "\n",
    "**Points cles** :\n",
    "1. Le pipeline est **modulaire** : chaque etape peut etre amelioree independamment\n",
    "2. Le **tracing** permet de verifier quels faits ont ete utilises\n",
    "3. Le mode degrade (sans API) reste informatif grace au contexte KG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Ontologies dans le RAG\n",
    "\n",
    "Les ontologies (OWL, RDFS) jouent un role crucial dans GraphRAG en apportant de la **semantique formelle** au graphe de connaissances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-disambiguation",
   "metadata": {},
   "source": [
    "### 5.1 Desambiguisation des requetes\n",
    "\n",
    "Les ontologies definissent des hierarchies de classes et de proprietes qui aident a comprendre le sens des termes. Par exemple :\n",
    "\n",
    "```turtle\n",
    "# Hierarchie de classes\n",
    "ex:Personne rdf:type owl:Class .\n",
    "ex:Dirigeant rdfs:subClassOf ex:Personne .\n",
    "ex:Empereur rdfs:subClassOf ex:Dirigeant .\n",
    "ex:Napoleon rdf:type ex:Empereur .\n",
    "\n",
    "# Hierarchie de proprietes\n",
    "ex:ne_a rdfs:domain ex:Personne ;\n",
    "        rdfs:range ex:Lieu .\n",
    "```\n",
    "\n",
    "**Avantages pour le retrieval** :\n",
    "\n",
    "| Capacite | Sans ontologie | Avec ontologie |\n",
    "|----------|---------------|----------------|\n",
    "| \"Tous les dirigeants\" | Uniquement ceux tagges \"dirigeant\" | Empereurs, rois, presidents (par heritage) |\n",
    "| \"Lieu de naissance\" | Matching exact \"ne_a\" | Aussi \"born_in\", \"birthPlace\" (equivalences) |\n",
    "| Validation | Aucune | \"ne_a\" attend un Lieu, pas une Date |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s5-ontology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrichir le KG avec une mini-ontologie\n",
    "HIST = Namespace(\"http://example.org/ontology/history#\")\n",
    "kg.bind(\"hist\", HIST)\n",
    "\n",
    "# Classes\n",
    "kg.add((HIST.Personne, RDF.type, OWL.Class))\n",
    "kg.add((HIST.Dirigeant, RDF.type, OWL.Class))\n",
    "kg.add((HIST.Dirigeant, RDFS.subClassOf, HIST.Personne))\n",
    "kg.add((HIST.Empereur, RDF.type, OWL.Class))\n",
    "kg.add((HIST.Empereur, RDFS.subClassOf, HIST.Dirigeant))\n",
    "kg.add((HIST.Lieu, RDF.type, OWL.Class))\n",
    "kg.add((HIST.Evenement, RDF.type, OWL.Class))\n",
    "kg.add((HIST.Institution, RDF.type, OWL.Class))\n",
    "\n",
    "# Typage des instances\n",
    "kg.add((EX.Napoleon_Bonaparte, RDF.type, HIST.Empereur))\n",
    "kg.add((EX.Ajaccio, RDF.type, HIST.Lieu))\n",
    "kg.add((EX.Corse, RDF.type, HIST.Lieu))\n",
    "kg.add((EX.Waterloo, RDF.type, HIST.Lieu))\n",
    "kg.add((EX[\"Sainte-Helene\"], RDF.type, HIST.Lieu))\n",
    "kg.add((EX.Banque_de_France, RDF.type, HIST.Institution))\n",
    "kg.add((EX.Bataille_de_Waterloo, RDF.type, HIST.Evenement))\n",
    "\n",
    "# Proprietes avec domaine et range\n",
    "kg.add((REL.born_in_place, RDFS.domain, HIST.Personne))\n",
    "kg.add((REL.born_in_place, RDFS.range, HIST.Lieu))\n",
    "kg.add((REL.defeated_at, RDFS.domain, HIST.Personne))\n",
    "kg.add((REL.defeated_at, RDFS.range, HIST.Lieu))\n",
    "\n",
    "# Requete : trouver tous les lieux (par type)\n",
    "query_lieux = \"\"\"\n",
    "PREFIX hist: <http://example.org/ontology/history#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?lieu ?label\n",
    "WHERE {\n",
    "    ?lieu a hist:Lieu .\n",
    "    OPTIONAL { ?lieu rdfs:label ?label }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Lieux identifies par type ontologique :\")\n",
    "for row in kg.query(query_lieux):\n",
    "    name = str(row.label) if row.label else str(row.lieu).split('/')[-1].replace('_', ' ')\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "# Requete : inference via rdfs:subClassOf\n",
    "print(\"\\nHierarchie de classes :\")\n",
    "print(\"  Empereur --> subClassOf --> Dirigeant --> subClassOf --> Personne\")\n",
    "print(f\"  Napoleon est un Empereur : type direct\")\n",
    "print(f\"  Napoleon est un Dirigeant : par inference (subClassOf)\")\n",
    "print(f\"  Napoleon est une Personne : par inference transitive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-ontology-interp",
   "metadata": {},
   "source": [
    "### Interpretation : ontologies et retrieval\n",
    "\n",
    "L'ajout d'une ontologie au KG apporte trois benefices majeurs pour le retrieval :\n",
    "\n",
    "| Benefice | Mecanisme | Exemple |\n",
    "|----------|-----------|----------|\n",
    "| **Categorisation** | `rdf:type` + `rdfs:subClassOf` | Trouver \"tous les lieux\" par type |\n",
    "| **Desambiguisation** | `rdfs:domain` / `rdfs:range` | \"ne_a\" attend un Lieu, pas une Date |\n",
    "| **Inference** | Heritage de classes | Un Empereur EST un Dirigeant |\n",
    "\n",
    "> **Point cle** : Les ontologies permettent au systeme GraphRAG de repondre a des questions que l'utilisateur n'a pas formulees exactement selon les termes du KG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-validation-intro",
   "metadata": {},
   "source": [
    "### 5.2 Validation des sorties LLM\n",
    "\n",
    "Le KG peut aussi servir a **valider** les affirmations d'un LLM apres generation, en verifiant si elles sont coherentes avec les faits connus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s5-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_claim(graph, subject_name, predicate_name, object_value):\n",
    "    \"\"\"Verifie si une affirmation est coherente avec le KG.\"\"\"\n",
    "    subject_uri = name_to_uri(subject_name)\n",
    "\n",
    "    # Chercher les triplets correspondants\n",
    "    for s, p, o in graph.triples((subject_uri, None, None)):\n",
    "        p_label = str(p).split('/')[-1].lower()\n",
    "        o_label = str(o).split('/')[-1].replace('_', ' ').lower() if isinstance(o, URIRef) else str(o).lower()\n",
    "\n",
    "        if predicate_name.lower() in p_label:\n",
    "            if object_value.lower() in o_label or o_label in object_value.lower():\n",
    "                return \"CONFIRME\", f\"Triplet trouve : ({subject_name}, {p_label}, {o_label})\"\n",
    "            else:\n",
    "                return \"CONTREDIT\", f\"KG dit : {o_label} (pas {object_value})\"\n",
    "\n",
    "    return \"NON VERIFIE\", \"Aucun triplet correspondant dans le KG\"\n",
    "\n",
    "\n",
    "# Tester des affirmations\n",
    "claims = [\n",
    "    (\"Napoleon Bonaparte\", \"born_in\", \"Ajaccio\"),      # Vrai\n",
    "    (\"Napoleon Bonaparte\", \"born_in\", \"Paris\"),          # Faux\n",
    "    (\"Napoleon Bonaparte\", \"died\", \"1821\"),              # Vrai\n",
    "    (\"Napoleon Bonaparte\", \"allied_with\", \"Angleterre\"), # Non verifiable\n",
    "]\n",
    "\n",
    "print(\"Validation d'affirmations contre le KG :\")\n",
    "print(\"=\" * 65)\n",
    "for subj, pred, obj in claims:\n",
    "    status, detail = validate_claim(kg, subj, pred, obj)\n",
    "    print(f\"  '{subj} {pred} {obj}'\")\n",
    "    print(f\"    -> {status} : {detail}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-validation-interp",
   "metadata": {},
   "source": [
    "### Interpretation : validation factuelle\n",
    "\n",
    "La validation par KG produit trois resultats possibles :\n",
    "\n",
    "| Statut | Signification | Action |\n",
    "|--------|---------------|--------|\n",
    "| **CONFIRME** | Le fait existe dans le KG | Confiance elevee |\n",
    "| **CONTREDIT** | Le KG contient un fait different | Alerte hallucination |\n",
    "| **NON VERIFIE** | Le KG n'a pas d'information | Confiance moderee |\n",
    "\n",
    "**Points cles** :\n",
    "1. La validation post-generation reduit les hallucinations factuelles\n",
    "2. Les faits **CONTREDITS** sont les plus precieux (detection d'erreurs)\n",
    "3. Les faits **NON VERIFIES** necessitent d'autres sources de verification\n",
    "\n",
    "> **Note technique** : Cette approche est utilisee en production par des systemes comme Babelscape REBEL et Meta KILT pour le fact-checking automatise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Evaluation et limitations\n",
    "\n",
    "### 6.1 Reduction des hallucinations\n",
    "\n",
    "L'avantage principal de GraphRAG est la **reduction des hallucinations** grace au grounding factuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s6-eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation d'evaluation : comparaison RAG vs GraphRAG\n",
    "evaluation_results = {\n",
    "    \"questions\": [\n",
    "        \"Ou est ne Napoleon ?\",\n",
    "        \"Qui Napoleon a-t-il epouse ?\",\n",
    "        \"Quand a eu lieu Waterloo ?\",\n",
    "        \"Quel est l'heritage de Napoleon ?\",\n",
    "        \"Quels lieux sont lies a Napoleon ?\"\n",
    "    ],\n",
    "    \"rag_classic\": {\n",
    "        \"correct\": [True, True, True, True, False],\n",
    "        \"hallucinations\": [False, False, False, True, True],\n",
    "        \"complete\": [True, False, True, False, False]  # RAG manque des details\n",
    "    },\n",
    "    \"graphrag\": {\n",
    "        \"correct\": [True, True, True, True, True],\n",
    "        \"hallucinations\": [False, False, False, False, False],\n",
    "        \"complete\": [True, True, True, True, True]\n",
    "    }\n",
    "}\n",
    "\n",
    "n = len(evaluation_results[\"questions\"])\n",
    "rag_accuracy = sum(evaluation_results[\"rag_classic\"][\"correct\"]) / n\n",
    "rag_halluc = sum(evaluation_results[\"rag_classic\"][\"hallucinations\"]) / n\n",
    "rag_complete = sum(evaluation_results[\"rag_classic\"][\"complete\"]) / n\n",
    "\n",
    "grag_accuracy = sum(evaluation_results[\"graphrag\"][\"correct\"]) / n\n",
    "grag_halluc = sum(evaluation_results[\"graphrag\"][\"hallucinations\"]) / n\n",
    "grag_complete = sum(evaluation_results[\"graphrag\"][\"complete\"]) / n\n",
    "\n",
    "print(\"Evaluation comparative (donnees simulees)\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Metrique':<25} {'RAG classique':>15} {'GraphRAG':>15}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Precision':<25} {rag_accuracy:>14.0%} {grag_accuracy:>14.0%}\")\n",
    "print(f\"{'Hallucinations':<25} {rag_halluc:>14.0%} {grag_halluc:>14.0%}\")\n",
    "print(f\"{'Completude':<25} {rag_complete:>14.0%} {grag_complete:>14.0%}\")\n",
    "print(f\"\\nNote : Ces resultats illustrent les tendances observees\")\n",
    "print(f\"dans la litterature (Microsoft GraphRAG 2024, etc.).\")\n",
    "print(f\"Les chiffres exacts varient selon le domaine et le corpus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-eval-interp",
   "metadata": {},
   "source": [
    "### Interpretation : evaluation comparative\n",
    "\n",
    "Les resultats (simules ici pour illustration) refletent les tendances documentees dans la litterature :\n",
    "\n",
    "| Metrique | RAG classique | GraphRAG | Explication |\n",
    "|----------|--------------|----------|-------------|\n",
    "| Precision | ~80% | ~100% | KG fournit des faits verifies |\n",
    "| Hallucinations | ~40% | ~0% | Grounding factuel |\n",
    "| Completude | ~60% | ~100% | Traversee de graphe multi-sauts |\n",
    "\n",
    "> **Reference** : L'article original de Microsoft (Edge et al., 2024) rapporte une amelioration de 20-30% sur les questions globales par rapport au RAG classique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-cost-intro",
   "metadata": {},
   "source": [
    "### 6.2 Analyse des couts\n",
    "\n",
    "GraphRAG introduit un cout supplementaire de construction et maintenance du KG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s6-cost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation des couts (ordres de grandeur)\n",
    "cost_analysis = [\n",
    "    (\"Construction de l'index\", \"Embedding vectoriel\", \"Extraction KG par LLM\"),\n",
    "    (\"Cout par document (1000 tokens)\", \"~$0.001 (embedding)\", \"~$0.01-0.05 (extraction LLM)\"),\n",
    "    (\"Cout par requete\", \"~$0.001 (embedding query)\", \"~$0.005 (SPARQL + embedding)\"),\n",
    "    (\"Stockage\", \"Vecteurs (~1KB/doc)\", \"Triplets (~0.5KB/doc) + index\"),\n",
    "    (\"Temps d'indexation\", \"Secondes (embedding)\", \"Minutes (extraction LLM)\"),\n",
    "    (\"Temps de requete\", \"~100ms (ANN search)\", \"~200ms (SPARQL + ANN)\"),\n",
    "    (\"Mise a jour\", \"Re-embed le document\", \"Re-extraire les entites\"),\n",
    "]\n",
    "\n",
    "print(\"Analyse des couts : RAG classique vs GraphRAG\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Dimension':<30} {'RAG classique':<22} {'GraphRAG'}\")\n",
    "print(\"-\" * 75)\n",
    "for dimension, rag, graphrag in cost_analysis:\n",
    "    print(f\"{dimension:<30} {rag:<22} {graphrag}\")\n",
    "\n",
    "print(f\"\\nConclusion : GraphRAG coute 5-50x plus cher a construire,\")\n",
    "print(f\"mais produit des reponses plus fiables et structurees.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-when",
   "metadata": {},
   "source": [
    "### 6.3 Quand utiliser GraphRAG vs RAG classique ?\n",
    "\n",
    "| Critere | Privilegier RAG classique | Privilegier GraphRAG |\n",
    "|---------|--------------------------|----------------------|\n",
    "| Volume de donnees | Grand corpus (>100K docs) | Corpus moyen (<10K docs) |\n",
    "| Nature des questions | Questions locales (\"de quoi parle ce document ?\") | Questions globales ou relationnelles |\n",
    "| Besoin de precision | Tolerant aux approximations | Exigence de faits verifiables |\n",
    "| Budget | Limite | Disponible |\n",
    "| Frequence de mise a jour | Elevee (donnees volatiles) | Moderee (donnees stables) |\n",
    "| Domaine | General, ouvert | Specialise (medical, juridique, technique) |\n",
    "| Relations | Peu importantes | Centrales (reseaux, genealogies, supply chain) |\n",
    "\n",
    "> **Recommandation pratique** : Pour la plupart des cas d'usage, une approche **hybride** (RAG vectoriel + KG) offre le meilleur compromis. On utilise le KG pour les faits critiques et la recherche vectorielle pour le contexte general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Directions futures\n",
    "\n",
    "Le domaine GraphRAG evolue rapidement. Voici les tendances majeures pour 2025-2027."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-neurosymbolic",
   "metadata": {},
   "source": [
    "### 7.1 Convergence neuro-symbolique\n",
    "\n",
    "L'IA **neuro-symbolique** combine les forces des reseaux de neurones (apprentissage, generalisation) avec celles des systemes symboliques (raisonnement, explicabilite) :\n",
    "\n",
    "```\n",
    "Approche neuronale pure        Approche hybride           Approche symbolique pure\n",
    "  (LLM, embeddings)      (GraphRAG, neuro-symbolique)    (logique, ontologies)\n",
    "       |                          |                              |\n",
    "  Apprentissage             Apprentissage +                Raisonnement\n",
    "  statistique               raisonnement                   formel\n",
    "       |                          |                              |\n",
    "  + Generalisation          + Precision                    + Garanties\n",
    "  + Flexibilite             + Explicabilite                + Explicabilite\n",
    "  - Hallucinations          + Reduction                    - Fragilite\n",
    "  - Opacite                   hallucinations               - Couverture limitee\n",
    "```\n",
    "\n",
    "GraphRAG est une forme concrete de cette convergence : le KG apporte la structure symbolique, le LLM apporte la flexibilite neuronale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-embeddings",
   "metadata": {},
   "source": [
    "### 7.2 KG Embeddings\n",
    "\n",
    "Les **KG Embeddings** representent les entites et relations d'un graphe dans un espace vectoriel continu, permettant de combiner le meilleur des deux mondes :\n",
    "\n",
    "| Methode | Principe | Avantage |\n",
    "|---------|----------|----------|\n",
    "| **TransE** (2013) | Relation = translation vectorielle : h + r = t | Simple, rapide |\n",
    "| **RotatE** (2019) | Relation = rotation dans l'espace complexe | Capture les patterns (symetrie, inversion) |\n",
    "| **CompGCN** (2020) | GNN sur le KG, compositions de relations | Raisonnement multi-sauts |\n",
    "| **NodePiece** (2022) | Tokenisation des noeuds, transferable | Scalable, inductif |\n",
    "\n",
    "**Principe de TransE** :\n",
    "\n",
    "Pour un triplet (h, r, t), le modele apprend des vecteurs tels que :\n",
    "\n",
    "$$\\vec{h} + \\vec{r} \\approx \\vec{t}$$\n",
    "\n",
    "Exemple : vec(Paris) + vec(capitale_de) = vec(France)\n",
    "\n",
    "**Application au GraphRAG** : les embeddings de KG permettent de retrouver des entites similaires meme si elles ne sont pas directement liees dans le graphe, combinant precision structurelle et generalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-agentic",
   "metadata": {},
   "source": [
    "### 7.3 Agentic RAG avec outils KG\n",
    "\n",
    "Les **agents IA** (systemes autonomes bases sur LLM) peuvent utiliser le KG comme un **outil** parmi d'autres :\n",
    "\n",
    "```\n",
    "Agent IA\n",
    "  |\n",
    "  |-- Outil : Recherche vectorielle (RAG classique)\n",
    "  |-- Outil : Requete SPARQL (GraphRAG)\n",
    "  |-- Outil : Validation factuelle (KG check)\n",
    "  |-- Outil : Calcul (Python/Wolfram)\n",
    "  |-- Outil : Navigation web\n",
    "  |\n",
    "  v\n",
    "L'agent choisit dynamiquement quel outil utiliser\n",
    "selon la question posee.\n",
    "```\n",
    "\n",
    "Cette approche est plus flexible qu'un pipeline fixe : l'agent decide quand interroger le KG vs faire une recherche vectorielle vs valider un fait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-table",
   "metadata": {},
   "source": [
    "### 7.4 Tendances 2025-2027\n",
    "\n",
    "| Tendance | Horizon | Impact | Maturite |\n",
    "|----------|---------|--------|----------|\n",
    "| GraphRAG open-source (LlamaIndex, LangChain) | 2025 | Democratisation | Production |\n",
    "| KG Embeddings + LLMs | 2025-2026 | Retrieval hybride | Recherche avancee |\n",
    "| Agentic RAG avec KG comme outil | 2025-2026 | Flexibilite | Emerging |\n",
    "| Construction automatique de KG (LLM-powered) | 2025 | Reduction cout construction | Production |\n",
    "| KG temporels (faits avec validite) | 2026 | Precision temporelle | Recherche |\n",
    "| KG multimodaux (texte + images + tables) | 2026-2027 | Couverture | Recherche |\n",
    "| Federated GraphRAG (KGs distribues) | 2027 | Scale + vie privee | Conceptuel |\n",
    "\n",
    "> **Point cle** : GraphRAG est au croisement de deux tendances majeures de l'IA : les **LLMs** (generation) et les **graphes de connaissances** (structure). Leur convergence est une direction de recherche tres active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-exercises-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercices\n",
    "\n",
    "### Exercice 1 : Extraction d'entites par regles\n",
    "\n",
    "Ecrivez une fonction `extract_entities_science(text)` qui extrait des entites (scientifiques, theories, institutions) a partir du texte suivant sur la physique moderne. Utilisez des expressions regulieres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ex1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHYSICS_TEXT = \"\"\"\n",
    "Albert Einstein a publie la theorie de la relativite restreinte en 1905 a Berne.\n",
    "Il a recu le prix Nobel de physique en 1921 pour l'effet photoelectrique.\n",
    "Max Planck a introduit le quantum d'action en 1900 a Berlin.\n",
    "Niels Bohr a propose son modele atomique en 1913 a Copenhague.\n",
    "Werner Heisenberg a formule le principe d'incertitude en 1927.\n",
    "\"\"\"\n",
    "\n",
    "def extract_entities_science(text):\n",
    "    \"\"\"Exercice : extraire les entites scientifiques du texte.\"\"\"\n",
    "    entities = {\n",
    "        \"scientists\": [],\n",
    "        \"theories\": [],\n",
    "        \"dates\": [],\n",
    "        \"places\": []\n",
    "    }\n",
    "\n",
    "    # TODO : Implementez l'extraction\n",
    "    # Indices :\n",
    "    #   - Dates : re.findall(r'\\b(\\d{4})\\b', text)\n",
    "    #   - Scientifiques : patterns \"Prenom Nom\"\n",
    "    #   - Theories : patterns \"theorie de...\", \"principe de...\", \"modele...\"\n",
    "    #   - Lieux : patterns \"a Ville\"\n",
    "\n",
    "    return entities\n",
    "\n",
    "\n",
    "# Testez votre solution\n",
    "# result = extract_entities_science(PHYSICS_TEXT)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-ex2-intro",
   "metadata": {},
   "source": [
    "### Exercice 2 : Mini KG et requete de contexte\n",
    "\n",
    "Construisez un mini graphe RDF sur le systeme solaire (planetes, etoile, satellites) et ecrivez une fonction qui retourne le contexte KG pour la question \"Quels sont les satellites de Jupiter ?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ex2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_solar_system_kg():\n",
    "    \"\"\"Exercice : construire un KG du systeme solaire.\"\"\"\n",
    "    g = Graph()\n",
    "    ASTRO = Namespace(\"http://example.org/astro/\")\n",
    "    g.bind(\"astro\", ASTRO)\n",
    "\n",
    "    # TODO : Ajoutez des triplets pour :\n",
    "    # - Le Soleil (type: Etoile)\n",
    "    # - Les planetes (Terre, Jupiter, Mars...)\n",
    "    #   avec relation \"orbite_autour\" -> Soleil\n",
    "    # - Les satellites (Lune, Europe, Io, Ganymede, Callisto...)\n",
    "    #   avec relation \"orbite_autour\" -> leur planete\n",
    "    # - Des proprietes : diametre, distance_au_soleil, etc.\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "def query_satellites(graph, planet_name):\n",
    "    \"\"\"Exercice : requete SPARQL pour les satellites d'une planete.\"\"\"\n",
    "    # TODO : Ecrivez une requete SPARQL qui retourne\n",
    "    # tous les satellites orbitant autour de planet_name\n",
    "    pass\n",
    "\n",
    "\n",
    "# Testez votre solution\n",
    "# kg_solar = build_solar_system_kg()\n",
    "# satellites = query_satellites(kg_solar, \"Jupiter\")\n",
    "# print(f\"Satellites de Jupiter : {satellites}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-ex3-intro",
   "metadata": {},
   "source": [
    "### Exercice 3 : Pipeline GraphRAG pour un domaine specifique\n",
    "\n",
    "Concevez un pipeline GraphRAG pour le domaine **medical** (maladies, symptomes, traitements). Definissez :\n",
    "1. Le schema du KG (classes, proprietes)\n",
    "2. Des exemples de triplets\n",
    "3. Des exemples de questions et le sous-graphe attendu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ex3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_medical_graphrag():\n",
    "    \"\"\"Exercice : concevoir un pipeline GraphRAG medical.\"\"\"\n",
    "\n",
    "    # TODO : Definissez le schema (classes et proprietes)\n",
    "    schema = {\n",
    "        \"classes\": [\n",
    "            # ex: \"Maladie\", \"Symptome\", \"Traitement\", \"Medicament\", \"Organe\"\n",
    "        ],\n",
    "        \"properties\": [\n",
    "            # ex: (\"a_symptome\", \"Maladie\", \"Symptome\"),\n",
    "            #     (\"traite_par\", \"Maladie\", \"Traitement\"),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # TODO : Exemples de triplets\n",
    "    example_triples = [\n",
    "        # ex: (\"Grippe\", \"a_symptome\", \"Fievre\"),\n",
    "        #     (\"Grippe\", \"traite_par\", \"Paracetamol\"),\n",
    "    ]\n",
    "\n",
    "    # TODO : Exemples de questions et sous-graphes attendus\n",
    "    example_queries = [\n",
    "        # ex: {\n",
    "        #     \"question\": \"Quels sont les symptomes de la grippe ?\",\n",
    "        #     \"expected_subgraph\": [...],\n",
    "        # }\n",
    "    ]\n",
    "\n",
    "    return schema, example_triples, example_queries\n",
    "\n",
    "\n",
    "# Testez votre conception\n",
    "# schema, triples, queries = design_medical_graphrag()\n",
    "# print(f\"Classes : {schema['classes']}\")\n",
    "# print(f\"Triplets : {len(triples)}\")\n",
    "# print(f\"Questions : {len(queries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-conclusion-series",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion de la serie Web Semantique\n",
    "\n",
    "Ce notebook conclut la **serie de 13 notebooks** sur le Web Semantique. Voici un recapitulatif du parcours complet.\n",
    "\n",
    "### Parcours d'apprentissage\n",
    "\n",
    "| # | Notebook | Theme | Competences acquises |\n",
    "|---|----------|-------|---------------------|\n",
    "| 1 | SW-1-Setup | Installation | Environnement dotNetRDF, premier graphe |\n",
    "| 2 | SW-2-RDFBasics | Fondations RDF | Triplets, noeuds, serialisation |\n",
    "| 3 | SW-3-GraphOperations | Manipulation | Lecture, ecriture, fusion, selection |\n",
    "| 4 | SW-4-SPARQL | Requetes | SELECT, FILTER, OPTIONAL, UNION |\n",
    "| 5 | SW-5-LinkedData | Donnees liees | DBpedia, Wikidata, SERVICE |\n",
    "| 6 | SW-6-RDFS | Schema | Classes, proprietes, inference |\n",
    "| 7 | SW-7-OWL | Ontologies | OWL 2, raisonnement, profils |\n",
    "| 8 | SW-8-PythonRDF | Python RDF | rdflib, SPARQLWrapper, transition .NET -> Python |\n",
    "| 9 | SW-9-SHACL | Validation | Shapes, contraintes, qualite |\n",
    "| 10 | SW-10-JSONLD | JSON-LD | Schema.org, donnees web structurees |\n",
    "| 11 | SW-11-RDFStar | RDF 1.2 | Quoted triples, SPARQL-Star |\n",
    "| 12 | SW-12-KnowledgeGraphs | Graphes de connaissances | Construction, kglab, visualisation |\n",
    "| 13 | **SW-13-GraphRAG** | **KG + LLMs** | **Pipeline GraphRAG, extraction, validation** |\n",
    "\n",
    "### Progression thematique\n",
    "\n",
    "```\n",
    "Partie 1 (SW-1 a 4) : FONDATIONS\n",
    "  RDF -> Triplets -> Graphes -> SPARQL\n",
    "\n",
    "Partie 2 (SW-5 a 7) : SEMANTIQUE\n",
    "  Linked Data -> RDFS -> OWL\n",
    "\n",
    "Partie 3 (SW-8 a 11) : ECOSYSTEME MODERNE\n",
    "  Python -> SHACL -> JSON-LD -> RDF 1.2\n",
    "\n",
    "Partie 4 (SW-12 a 13) : INTELLIGENCE ARTIFICIELLE\n",
    "  Knowledge Graphs -> GraphRAG (KG + LLMs)\n",
    "```\n",
    "\n",
    "### Competences transversales\n",
    "\n",
    "| Competence | Notebooks | Niveau atteint |\n",
    "|-----------|-----------|----------------|\n",
    "| Modelisation de donnees en graphe | 1-3, 8, 12 | Avance |\n",
    "| Interrogation SPARQL | 4-5, 8, 13 | Avance |\n",
    "| Ontologies et inference | 6-7 | Intermediaire |\n",
    "| Validation et qualite | 9 | Intermediaire |\n",
    "| Integration Web | 10-11 | Intermediaire |\n",
    "| IA et graphes de connaissances | 12-13 | Introduction |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-further-reading",
   "metadata": {},
   "source": [
    "### Pour aller plus loin\n",
    "\n",
    "**Articles de reference** :\n",
    "- Edge et al. (2024), *\"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"*, Microsoft Research\n",
    "- Bordes et al. (2013), *\"Translating Embeddings for Modeling Multi-relational Data\"* (TransE)\n",
    "- Sun et al. (2019), *\"RotatE: Knowledge Graph Embedding by Relational Rotation\"*\n",
    "- Pan et al. (2024), *\"Unifying Large Language Models and Knowledge Graphs: A Roadmap\"*\n",
    "\n",
    "**Outils et frameworks** :\n",
    "- [Microsoft GraphRAG](https://github.com/microsoft/graphrag) : implementation open-source\n",
    "- [LlamaIndex Knowledge Graph](https://docs.llamaindex.ai/) : integration KG dans LlamaIndex\n",
    "- [LangChain Graph](https://python.langchain.com/) : GraphRAG dans LangChain\n",
    "- [Neo4j + LLM](https://neo4j.com/labs/genai-ecosystem/) : graphes de proprietes + IA generative\n",
    "\n",
    "**Standards W3C couverts dans la serie** :\n",
    "- RDF 1.1 / 1.2, SPARQL 1.1, RDFS 1.0, OWL 2, SHACL 1.0, JSON-LD 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resume\n",
    "\n",
    "| Element | Ce que nous avons appris |\n",
    "|---------|-------------------------|\n",
    "| RAG vs GraphRAG | GraphRAG ajoute un KG structure au pipeline RAG classique |\n",
    "| Extraction d'entites | Par regles (deterministe) ou par LLM (flexible) |\n",
    "| Construction de KG | Texte -> triplets -> graphe RDF avec rdflib |\n",
    "| KG-enhanced retrieval | SPARQL + sous-graphe pour un contexte structure |\n",
    "| Pipeline GraphRAG | Detection -> Requete KG -> Formatage -> Generation LLM |\n",
    "| Ontologies et RAG | Desambiguisation, inference, validation factuelle |\n",
    "| Evaluation | Reduction hallucinations, precision accrue, cout plus eleve |\n",
    "| Directions futures | Neuro-symbolique, KG embeddings, Agentic RAG |\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation** : [<< 12-KnowledgeGraphs](SW-12-KnowledgeGraphs.ipynb) | [Index](README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 2,
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}