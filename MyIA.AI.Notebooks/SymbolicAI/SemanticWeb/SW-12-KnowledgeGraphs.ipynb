{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# SW-12-KnowledgeGraphs\n\n**Navigation** : [<< 11-RDFStar](SW-11-RDFStar.ipynb) | [Index](README.md) | [13-GraphRAG >>](SW-13-GraphRAG.ipynb)\n\n## Graphes de Connaissances : Construction et Exploration\n\n### Duree estimee : 55 minutes\n\n---\n\n## Objectifs d'apprentissage\n\nA la fin de ce notebook, vous saurez :\n1. Definir ce qu'est un Knowledge Graph et le situer dans l'ecosysteme des donnees structurees\n2. Construire un KG a partir de donnees tabulaires (CSV) avec rdflib\n3. Utiliser kglab comme couche d'abstraction pour manipuler des Knowledge Graphs\n4. Visualiser un KG avec NetworkX (matplotlib) et pyvis (interactif HTML)\n5. Manipuler des ontologies OWL avec OWLReady2 et lancer le raisonneur HermiT\n6. Evaluer la qualite d'un Knowledge Graph (completude, coherence)\n\n### Concepts cles\n\n| Concept | Description |\n|---------|-------------|\n| Knowledge Graph | Graphe de connaissances reliant entites et relations semantiques |\n| kglab | Bibliotheque Python d'abstraction pour les KG (au-dessus de rdflib) |\n| OWLReady2 | Bibliotheque Python pour manipuler des ontologies OWL et lancer des raisonneurs |\n| NetworkX | Bibliotheque Python de theorie des graphes, utilisee pour la visualisation |\n| pyvis | Visualisation interactive de graphes en HTML/JavaScript |\n\n### Prerequis\n- SW-8 (SHACL) et SW-9 (Linked Data) pour les fondations RDF/SPARQL\n- Python 3.10+ avec les dependances du fichier `requirements.txt`"
  },
  {
   "cell_type": "markdown",
   "id": "install-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0. Installation des dependances\n",
    "\n",
    "Installons les bibliotheques necessaires pour ce notebook. Si elles sont deja presentes dans votre environnement, cette etape sera rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-cell",
   "metadata": {},
   "outputs": [],
   "source": "%pip install -q rdflib owlready2 kglab networkx matplotlib pyvis pandas"
  },
  {
   "cell_type": "markdown",
   "id": "install-verify-intro",
   "metadata": {},
   "source": [
    "Verifions que les imports fonctionnent correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-verify",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"rdflib    : {rdflib.__version__}\")\n",
    "print(f\"pandas    : {pd.__version__}\")\n",
    "print(f\"networkx  : {nx.__version__}\")\n",
    "print(f\"matplotlib: {matplotlib.__version__}\")\n",
    "\n",
    "# kglab et owlready2 n'exposent pas toujours __version__\n",
    "try:\n",
    "    import kglab\n",
    "    print(f\"kglab     : OK\")\n",
    "except ImportError as e:\n",
    "    print(f\"kglab     : NON DISPONIBLE ({e})\")\n",
    "\n",
    "try:\n",
    "    import owlready2\n",
    "    print(f\"owlready2 : OK\")\n",
    "except ImportError as e:\n",
    "    print(f\"owlready2 : NON DISPONIBLE ({e})\")\n",
    "\n",
    "try:\n",
    "    from pyvis.network import Network\n",
    "    print(f\"pyvis     : OK\")\n",
    "except ImportError as e:\n",
    "    print(f\"pyvis     : NON DISPONIBLE ({e})\")\n",
    "\n",
    "print(\"\\nEnvironnement pret.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "| Bibliotheque | Role dans ce notebook |\n",
    "|--------------|----------------------|\n",
    "| rdflib | Construction et interrogation du graphe RDF |\n",
    "| pandas | Chargement des donnees CSV |\n",
    "| kglab | Couche d'abstraction Knowledge Graph |\n",
    "| owlready2 | Manipulation d'ontologies OWL + raisonnement HermiT |\n",
    "| networkx | Representation et visualisation de graphes |\n",
    "| matplotlib | Rendu graphique statique |\n",
    "| pyvis | Visualisation interactive (HTML) |\n",
    "\n",
    "> **Note technique** : kglab et pyvis sont optionnels. Les sections correspondantes utilisent des blocs `try/except` pour fonctionner meme si ces bibliotheques ne sont pas installees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Qu'est-ce qu'un Knowledge Graph ?\n",
    "\n",
    "### Definition et historique\n",
    "\n",
    "Un **Knowledge Graph** (graphe de connaissances) est un graphe oriente etiquete qui represente des entites du monde reel et les relations entre elles, enrichi par une couche semantique (ontologie, types, contraintes).\n",
    "\n",
    "Le terme a ete popularise par **Google en 2012** avec le lancement du *Google Knowledge Graph*, mais le concept existait deja sous d'autres formes :\n",
    "\n",
    "| Annee | Evenement | Impact |\n",
    "|-------|-----------|--------|\n",
    "| 2001 | Article fondateur de Tim Berners-Lee sur le Web semantique | Vision initiale |\n",
    "| 2006 | Lancement de DBpedia (extraction RDF de Wikipedia) | Premier KG ouvert a grande echelle |\n",
    "| 2012 | Google Knowledge Graph (\"Things, not strings\") | Adoption industrielle massive |\n",
    "| 2012 | Lancement de Wikidata | Base de connaissances collaborative |\n",
    "| 2017-20 | Adoption par Amazon, LinkedIn, Uber, Airbnb | KG d'entreprise |\n",
    "| 2023-25 | Integration KG + LLM (GraphRAG, grounding) | Convergence IA symbolique/neuronale |\n",
    "\n",
    "### Maturite industrielle (2024-2025)\n",
    "\n",
    "Les Knowledge Graphs sont aujourd'hui une technologie mature avec un retour sur investissement documente de **300-320%** dans les grandes entreprises (source : Gartner, Forrester). Ils servent de socle pour :\n",
    "- La recherche semantique (Google, Bing)\n",
    "- Les systemes de recommandation (Amazon, Netflix)\n",
    "- Le grounding de LLM (reduction des hallucinations via GraphRAG)\n",
    "- La conformite reglementaire (finance, sante)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-comparison",
   "metadata": {},
   "source": [
    "### Knowledge Graphs vs bases de donnees vs graphes RDF\n",
    "\n",
    "Un Knowledge Graph n'est ni une simple base de donnees relationnelle, ni un graphe RDF brut. Il se situe a l'intersection de plusieurs technologies :\n",
    "\n",
    "| Caracteristique | Base relationnelle | Graphe RDF | Knowledge Graph |\n",
    "|----------------|-------------------|------------|----------------|\n",
    "| Modele de donnees | Tables (lignes/colonnes) | Triplets (S-P-O) | Triplets + ontologie |\n",
    "| Schema | Rigide (DDL) | Flexible | Flexible + contraintes |\n",
    "| Identifiants | Cles primaires | URIs | URIs + labels |\n",
    "| Requetes | SQL | SPARQL | SPARQL + inference |\n",
    "| Raisonnement | Non | Basique (RDFS) | OWL, regles, raisonneur |\n",
    "| Interoperabilite | Faible (schema proprietaire) | Forte (standards W3C) | Forte + vocabulaires partages |\n",
    "| Exemples | PostgreSQL, MySQL | Triple Store brut | Google KG, Wikidata |\n",
    "\n",
    "**En resume** : Un Knowledge Graph = un graphe RDF + une ontologie + des mecanismes de qualite et de raisonnement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-major-kgs",
   "metadata": {},
   "source": [
    "### Principaux Knowledge Graphs dans le monde\n",
    "\n",
    "| Knowledge Graph | Organisation | Taille estimee | Usage principal |\n",
    "|----------------|-------------|---------------|----------------|\n",
    "| Google Knowledge Graph | Google | 500+ milliards de faits | Recherche, Assistant |\n",
    "| Wikidata | Wikimedia Foundation | 100+ millions d'items | Encyclopedie, Linked Data |\n",
    "| DBpedia | Communaute open-source | 400+ millions de triplets | Recherche academique |\n",
    "| Amazon Product Graph | Amazon | Milliards d'entites produit | Recommandation, catalogue |\n",
    "| LinkedIn Knowledge Graph | LinkedIn | 800+ millions de profils | Recrutement, reseau |\n",
    "| Microsoft Academic Graph | Microsoft | 250+ millions d'articles | Recherche scientifique |\n",
    "\n",
    "> **Point cle** : Tous ces KG utilisent des standards du Web semantique (RDF, OWL, SPARQL) comme fondation, meme s'ils ajoutent des couches proprietaires au-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Construire un Knowledge Graph a partir de donnees structurees\n",
    "\n",
    "Dans cette section, nous allons transformer un fichier CSV de films en un Knowledge Graph RDF. Cette operation est fondamentale : la plupart des KG d'entreprise sont construits a partir de donnees existantes (CSV, bases relationnelles, APIs).\n",
    "\n",
    "### Approche\n",
    "\n",
    "1. Charger le CSV avec pandas\n",
    "2. Definir un vocabulaire RDF (classes et proprietes)\n",
    "3. Transformer chaque ligne en triplets RDF\n",
    "4. Verifier le graphe resultant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-load-intro",
   "metadata": {},
   "source": [
    "### 2.1 Chargement des donnees CSV\n",
    "\n",
    "Le fichier `data/movies.csv` contient 12 films avec les colonnes : titre, annee, realisateur, genre, acteur principal, second acteur, note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/movies.csv\")\n",
    "print(f\"Nombre de films : {len(df)}\")\n",
    "print(f\"Colonnes : {list(df.columns)}\")\n",
    "print()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-csv-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Le dataset contient **12 films** avec des realisateurs varies (Nolan, Tarantino, Cameron, Jeunet, Wachowski, Nakache). On observe :\n",
    "- Des acteurs partages entre films (Leonardo DiCaprio dans Inception et Titanic, Audrey Tautou dans deux films de Jeunet)\n",
    "- Des genres distincts (Science-Fiction, Action, Crime, Western, Comedie, Romance)\n",
    "- Des notes entre 7.9 et 9.0\n",
    "\n",
    "Ces relations croisees (acteur-film, realisateur-film, genre) sont exactement ce que le Knowledge Graph va capturer sous forme de triplets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-vocab-intro",
   "metadata": {},
   "source": [
    "### 2.2 Definition du vocabulaire RDF\n",
    "\n",
    "Avant de creer les triplets, nous definissons les classes et proprietes de notre Knowledge Graph. Nous utilisons le vocabulaire **schema.org** quand il existe un terme equivalent, et un namespace local pour les extensions.\n",
    "\n",
    "| Entite/Relation | URI schema.org | URI local (fallback) |\n",
    "|----------------|---------------|---------------------|\n",
    "| Film | `schema:Movie` | - |\n",
    "| Personne | `schema:Person` | - |\n",
    "| Genre | - | `movies:Genre` |\n",
    "| a realise | `schema:director` | - |\n",
    "| a joue dans | `schema:actor` | - |\n",
    "| a pour genre | `schema:genre` | - |\n",
    "| annee de sortie | `schema:datePublished` | - |\n",
    "| note | `schema:aggregateRating` | - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-vocab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef, RDF, RDFS, XSD\n",
    "from rdflib.namespace import FOAF\n",
    "import re\n",
    "\n",
    "# Namespaces\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "MOVIES = Namespace(\"http://example.org/movies/\")\n",
    "PERSONS = Namespace(\"http://example.org/persons/\")\n",
    "GENRES = Namespace(\"http://example.org/genres/\")\n",
    "\n",
    "# Helper : transformer un nom en identifiant URI valide\n",
    "def to_uri_id(name: str) -> str:\n",
    "    \"\"\"Convertit un nom en identifiant URI (ASCII, sans espaces).\"\"\"\n",
    "    # Supprimer les accents et caracteres speciaux\n",
    "    clean = name.strip().replace(\" \", \"_\").replace(\".\", \"\")\n",
    "    clean = re.sub(r'[^a-zA-Z0-9_-]', '', clean)\n",
    "    return clean\n",
    "\n",
    "print(\"Namespaces definis :\")\n",
    "print(f\"  SCHEMA  = {SCHEMA}\")\n",
    "print(f\"  MOVIES  = {MOVIES}\")\n",
    "print(f\"  PERSONS = {PERSONS}\")\n",
    "print(f\"  GENRES  = {GENRES}\")\n",
    "print()\n",
    "print(\"Exemples de conversion URI :\")\n",
    "print(f\"  'Christopher Nolan' -> {to_uri_id('Christopher Nolan')}\")\n",
    "print(f\"  'Kill Bill Vol.1'   -> {to_uri_id('Kill Bill Vol.1')}\")\n",
    "print(f\"  'Science-Fiction'   -> {to_uri_id('Science-Fiction')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-vocab-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Nous avons defini quatre espaces de noms :\n",
    "- **SCHEMA** : vocabulaire standard schema.org pour les types et proprietes connus\n",
    "- **MOVIES** : namespace local pour les instances de films\n",
    "- **PERSONS** : namespace local pour les instances de personnes\n",
    "- **GENRES** : namespace local pour les instances de genres\n",
    "\n",
    "La fonction `to_uri_id()` nettoie les noms pour produire des URIs valides (pas d'accents, pas d'espaces).\n",
    "\n",
    "> **Bonne pratique** : Reutiliser des vocabulaires existants (schema.org, FOAF, Dublin Core) avant de creer ses propres termes. Cela favorise l'interoperabilite avec d'autres KG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-build-intro",
   "metadata": {},
   "source": [
    "### 2.3 Transformation CSV vers triplets RDF\n",
    "\n",
    "Chaque ligne du CSV va generer plusieurs triplets. Pour un film donne, nous creons :\n",
    "- L'entite film (type `schema:Movie`)\n",
    "- L'entite realisateur (type `schema:Person`)\n",
    "- Les entites acteurs (type `schema:Person`)\n",
    "- L'entite genre (type `movies:Genre`)\n",
    "- Les relations entre ces entites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-kg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation du graphe RDF\n",
    "g = Graph()\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "g.bind(\"movies\", MOVIES)\n",
    "g.bind(\"persons\", PERSONS)\n",
    "g.bind(\"genres\", GENRES)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "\n",
    "# Compteurs pour le suivi\n",
    "stats = {\"movies\": 0, \"persons\": set(), \"genres\": set(), \"triples\": 0}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # --- Entite Film ---\n",
    "    movie_uri = MOVIES[to_uri_id(row[\"title\"])]\n",
    "    g.add((movie_uri, RDF.type, SCHEMA.Movie))\n",
    "    g.add((movie_uri, SCHEMA.name, Literal(row[\"title\"], lang=\"en\")))\n",
    "    g.add((movie_uri, SCHEMA.datePublished, Literal(row[\"year\"], datatype=XSD.integer)))\n",
    "    g.add((movie_uri, SCHEMA.aggregateRating, Literal(row[\"rating\"], datatype=XSD.float)))\n",
    "    stats[\"movies\"] += 1\n",
    "\n",
    "    # --- Entite Realisateur ---\n",
    "    director_uri = PERSONS[to_uri_id(row[\"director\"])]\n",
    "    g.add((director_uri, RDF.type, SCHEMA.Person))\n",
    "    g.add((director_uri, SCHEMA.name, Literal(row[\"director\"])))\n",
    "    g.add((movie_uri, SCHEMA.director, director_uri))\n",
    "    stats[\"persons\"].add(row[\"director\"])\n",
    "\n",
    "    # --- Entites Acteurs ---\n",
    "    for actor_col in [\"actor1\", \"actor2\"]:\n",
    "        actor_name = row[actor_col]\n",
    "        actor_uri = PERSONS[to_uri_id(actor_name)]\n",
    "        g.add((actor_uri, RDF.type, SCHEMA.Person))\n",
    "        g.add((actor_uri, SCHEMA.name, Literal(actor_name)))\n",
    "        g.add((movie_uri, SCHEMA.actor, actor_uri))\n",
    "        stats[\"persons\"].add(actor_name)\n",
    "\n",
    "    # --- Entite Genre ---\n",
    "    genre_uri = GENRES[to_uri_id(row[\"genre\"])]\n",
    "    g.add((genre_uri, RDF.type, MOVIES.Genre))\n",
    "    g.add((genre_uri, RDFS.label, Literal(row[\"genre\"], lang=\"fr\")))\n",
    "    g.add((movie_uri, SCHEMA.genre, genre_uri))\n",
    "    stats[\"genres\"].add(row[\"genre\"])\n",
    "\n",
    "print(f\"Knowledge Graph construit avec succes.\")\n",
    "print(f\"  Films      : {stats['movies']}\")\n",
    "print(f\"  Personnes  : {len(stats['persons'])} (realisateurs + acteurs uniques)\")\n",
    "print(f\"  Genres     : {len(stats['genres'])}\")\n",
    "print(f\"  Triplets   : {len(g)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "build-kg-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Le graphe contient un nombre significatif de triplets pour seulement 12 films. Cela illustre la richesse du modele RDF : chaque film genere environ 8-10 triplets (type, nom, annee, note, realisateur, 2 acteurs, genre, plus les types des entites liees).\n",
    "\n",
    "**Structure du KG** :\n",
    "\n",
    "| Type d'entite | Nombre | Exemples |\n",
    "|--------------|--------|----------|\n",
    "| Film (`schema:Movie`) | 12 | Inception, The Dark Knight, Pulp Fiction |\n",
    "| Personne (`schema:Person`) | ~20 | Christopher Nolan, Leonardo DiCaprio |\n",
    "| Genre (`movies:Genre`) | ~6 | Science-Fiction, Action, Crime |\n",
    "\n",
    "> **Point cle** : Les entites partagees (meme realisateur pour plusieurs films, meme acteur) ne sont creees qu'une fois grace aux URIs uniques. C'est la force du modele graphe par rapport aux tables relationnelles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-sparql-intro",
   "metadata": {},
   "source": [
    "### 2.4 Verification par SPARQL\n",
    "\n",
    "Interrogeons le graphe pour verifier que les relations sont correctes. Listons les films avec leur realisateur et leur note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sparql-verify",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requete SPARQL : films, realisateurs et notes\n",
    "query = \"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?title ?director_name ?rating\n",
    "WHERE {\n",
    "    ?movie a schema:Movie ;\n",
    "           schema:name ?title ;\n",
    "           schema:director ?director ;\n",
    "           schema:aggregateRating ?rating .\n",
    "    ?director schema:name ?director_name .\n",
    "}\n",
    "ORDER BY DESC(?rating)\n",
    "\"\"\"\n",
    "\n",
    "results = g.query(query)\n",
    "print(f\"{'Film':<30} {'Realisateur':<25} {'Note'}\")\n",
    "print(\"-\" * 65)\n",
    "for row in results:\n",
    "    print(f\"{str(row.title):<30} {str(row.director_name):<25} {row.rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sparql-verify-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "La requete SPARQL confirme que les 12 films sont correctement relies a leur realisateur et leur note. Le tri par note decroissante montre The Dark Knight en tete (9.0) et Titanic/Avatar en bas (7.9).\n",
    "\n",
    "> **Lien avec SW-5** : Cette requete utilise les memes patterns SPARQL (SELECT, WHERE, ORDER BY) vus dans le notebook sur SPARQL, appliques ici a notre propre KG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sparql-actors-intro",
   "metadata": {},
   "source": [
    "Cherchons maintenant les acteurs qui apparaissent dans plusieurs films -- une requete qui serait complexe en SQL mais naturelle en SPARQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sparql-actors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requete : acteurs apparaissant dans plus d'un film\n",
    "query_actors = \"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "\n",
    "SELECT ?actor_name (COUNT(?movie) AS ?nb_films) (GROUP_CONCAT(?title; separator=\", \") AS ?films)\n",
    "WHERE {\n",
    "    ?movie a schema:Movie ;\n",
    "           schema:name ?title ;\n",
    "           schema:actor ?actor .\n",
    "    ?actor schema:name ?actor_name .\n",
    "}\n",
    "GROUP BY ?actor_name\n",
    "HAVING (COUNT(?movie) > 1)\n",
    "ORDER BY DESC(?nb_films)\n",
    "\"\"\"\n",
    "\n",
    "results_actors = g.query(query_actors)\n",
    "print(f\"{'Acteur':<25} {'Nb films':<10} {'Films'}\")\n",
    "print(\"-\" * 70)\n",
    "for row in results_actors:\n",
    "    print(f\"{str(row.actor_name):<25} {row.nb_films:<10} {row.films}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sparql-actors-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Cette requete revele les acteurs partages entre films. Leonardo DiCaprio et Audrey Tautou apparaissent chacun dans 2 films. Ces connexions croisees sont l'essence meme d'un Knowledge Graph : elles emergent naturellement de la structure en graphe, sans jointures explicites.\n",
    "\n",
    "| Pattern detecte | Signification pour le KG |\n",
    "|----------------|------------------------|\n",
    "| Acteur multi-films | Noeud de forte connectivite (hub) |\n",
    "| Realisateur multi-films | Cluster thematique (filmographie) |\n",
    "| Genre partage | Communaute semantique |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-serialize-intro",
   "metadata": {},
   "source": [
    "### 2.5 Serialisation du Knowledge Graph\n",
    "\n",
    "Exportons le KG en format Turtle pour inspection et reutilisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serialize-kg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialisation en Turtle (affichage des 50 premieres lignes)\n",
    "turtle_output = g.serialize(format=\"turtle\")\n",
    "lines = turtle_output.split(\"\\n\")\n",
    "print(f\"Taille totale : {len(lines)} lignes\\n\")\n",
    "print(\"--- Extrait (50 premieres lignes) ---\\n\")\n",
    "for line in lines[:50]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serialize-kg-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Le format Turtle est lisible par l'humain et montre clairement la structure du KG. On observe :\n",
    "- Les **prefixes** declares en haut (schema, movies, persons, genres)\n",
    "- Les **entites** regroupees avec le raccourci `;` (plusieurs predicats pour le meme sujet)\n",
    "- Les **URIs** coherents et lisibles grace a notre fonction `to_uri_id()`\n",
    "\n",
    "> **Note** : En production, on sauvegarderait ce fichier Turtle dans un Triple Store (cf. SW-10) pour le rendre interrogeable via un endpoint SPARQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. kglab : couche d'abstraction Knowledge Graph\n",
    "\n",
    "**kglab** est une bibliotheque Python creee par Paco Nathan qui fournit une couche d'abstraction au-dessus de rdflib. Elle simplifie les operations courantes sur les Knowledge Graphs :\n",
    "- Chargement/sauvegarde multi-format\n",
    "- Requetes SPARQL avec resultats pandas\n",
    "- Integration avec NetworkX pour la visualisation\n",
    "- Mesures de graphe (centralite, communautes)\n",
    "\n",
    "### Pourquoi kglab ?\n",
    "\n",
    "| Operation | rdflib pur | kglab |\n",
    "|-----------|-----------|-------|\n",
    "| SPARQL -> DataFrame | 5-10 lignes | 1 ligne |\n",
    "| Visualisation graphe | Manuel (NetworkX) | Integre |\n",
    "| Chargement multi-fichiers | Boucle manuelle | `load_rdf()` iteratif |\n",
    "| Statistiques du graphe | A coder | Methodes integrees |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3-create-intro",
   "metadata": {},
   "source": [
    "### 3.1 Creation d'un KnowledgeGraph kglab\n",
    "\n",
    "Nous allons creer un objet `kglab.KnowledgeGraph` et y charger les triplets de notre graphe de films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kglab-create",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import kglab\n",
    "\n",
    "    # Definir les namespaces pour kglab\n",
    "    namespaces = {\n",
    "        \"schema\": \"http://schema.org/\",\n",
    "        \"movies\": \"http://example.org/movies/\",\n",
    "        \"persons\": \"http://example.org/persons/\",\n",
    "        \"genres\": \"http://example.org/genres/\",\n",
    "    }\n",
    "\n",
    "    # Creer le KnowledgeGraph kglab\n",
    "    kg = kglab.KnowledgeGraph(\n",
    "        name=\"Movie Knowledge Graph\",\n",
    "        namespaces=namespaces\n",
    "    )\n",
    "\n",
    "    # Charger les triplets depuis notre graphe rdflib\n",
    "    # kglab utilise rdflib en interne, on peut acceder au graphe sous-jacent\n",
    "    for s, p, o in g:\n",
    "        kg._g.add((s, p, o))\n",
    "\n",
    "    # Copier les bindings de namespaces\n",
    "    for prefix, uri in g.namespaces():\n",
    "        kg._g.bind(prefix, uri)\n",
    "\n",
    "    print(f\"KnowledgeGraph kglab cree : '{kg.name}'\")\n",
    "    print(f\"Nombre de triplets : {len(kg._g)}\")\n",
    "\n",
    "    KGLAB_AVAILABLE = True\n",
    "\n",
    "except ImportError:\n",
    "    print(\"kglab n'est pas installe. Cette section est ignoree.\")\n",
    "    print(\"Installez-le avec : pip install kglab\")\n",
    "    KGLAB_AVAILABLE = False\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la creation du KG kglab : {e}\")\n",
    "    print(\"Nous continuerons avec rdflib directement.\")\n",
    "    KGLAB_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kglab-create-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "L'objet `kglab.KnowledgeGraph` encapsule un graphe rdflib en ajoutant des methodes de haut niveau. En interne, `kg._g` est un `rdflib.Graph` standard, ce qui garantit la compatibilite.\n",
    "\n",
    "> **Note technique** : kglab est en maintenance depuis 2023. Si la bibliotheque n'est pas disponible, les sections suivantes utilisent rdflib directement comme alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3-sparql-intro",
   "metadata": {},
   "source": [
    "### 3.2 Requetes SPARQL via kglab\n",
    "\n",
    "L'un des avantages de kglab est la conversion directe des resultats SPARQL en DataFrame pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kglab-sparql",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requete SPARQL avec conversion DataFrame\n",
    "sparql_query = \"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "\n",
    "SELECT ?director_name (COUNT(?movie) AS ?nb_films) (AVG(?rating) AS ?avg_rating)\n",
    "WHERE {\n",
    "    ?movie a schema:Movie ;\n",
    "           schema:director ?director ;\n",
    "           schema:aggregateRating ?rating .\n",
    "    ?director schema:name ?director_name .\n",
    "}\n",
    "GROUP BY ?director_name\n",
    "ORDER BY DESC(?avg_rating)\n",
    "\"\"\"\n",
    "\n",
    "if KGLAB_AVAILABLE:\n",
    "    # Methode kglab : resultats SPARQL -> DataFrame\n",
    "    try:\n",
    "        result_df = kg.query_as_df(sparql_query)\n",
    "        print(\"Resultats via kglab.query_as_df() :\\n\")\n",
    "        print(result_df.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"kglab query_as_df non disponible ({e}), utilisation de rdflib :\")\n",
    "        KGLAB_AVAILABLE = False\n",
    "\n",
    "if not KGLAB_AVAILABLE:\n",
    "    # Alternative rdflib : conversion manuelle\n",
    "    results = g.query(sparql_query)\n",
    "    rows = []\n",
    "    for row in results:\n",
    "        rows.append({\n",
    "            \"director_name\": str(row.director_name),\n",
    "            \"nb_films\": int(row.nb_films),\n",
    "            \"avg_rating\": round(float(row.avg_rating), 2)\n",
    "        })\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    print(\"Resultats via rdflib + pandas :\\n\")\n",
    "    print(result_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kglab-sparql-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Le tableau montre la note moyenne par realisateur. Les realisateurs ayant plusieurs films permettent de calculer une moyenne significative :\n",
    "\n",
    "| Avantage | kglab | rdflib pur |\n",
    "|----------|-------|------------|\n",
    "| Conversion DataFrame | `query_as_df()` (1 ligne) | Boucle manuelle (5+ lignes) |\n",
    "| Types de donnees | Automatique | Casting manuel |\n",
    "| Code necessaire | Minimal | Verbeux |\n",
    "\n",
    "> **Point cle** : Que l'on utilise kglab ou rdflib, le moteur SPARQL sous-jacent est le meme. kglab ajoute simplement du sucre syntaxique pour les workflows data science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Visualisation du Knowledge Graph\n",
    "\n",
    "La visualisation est essentielle pour comprendre la structure d'un KG. Nous allons utiliser deux approches complementaires :\n",
    "1. **NetworkX + matplotlib** : graphiques statiques, integres au notebook\n",
    "2. **pyvis** : graphiques interactifs en HTML, pour l'exploration\n",
    "\n",
    "### Approche\n",
    "\n",
    "Nous devons d'abord convertir les triplets RDF en un graphe NetworkX (noeuds + aretes), puis appliquer un layout et un style visuel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-convert-intro",
   "metadata": {},
   "source": [
    "### 4.1 Conversion RDF vers NetworkX\n",
    "\n",
    "Nous allons extraire les relations cles (realisateur, acteur, genre) et les convertir en aretes d'un graphe NetworkX oriente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rdf-to-networkx",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Requete SPARQL pour extraire les relations du KG\n",
    "extract_query = \"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "PREFIX movies: <http://example.org/movies/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?movie_title ?rel_type ?target_name\n",
    "WHERE {\n",
    "    {\n",
    "        ?movie a schema:Movie ; schema:name ?movie_title ; schema:director ?person .\n",
    "        ?person schema:name ?target_name .\n",
    "        BIND(\"director\" AS ?rel_type)\n",
    "    }\n",
    "    UNION\n",
    "    {\n",
    "        ?movie a schema:Movie ; schema:name ?movie_title ; schema:actor ?person .\n",
    "        ?person schema:name ?target_name .\n",
    "        BIND(\"actor\" AS ?rel_type)\n",
    "    }\n",
    "    UNION\n",
    "    {\n",
    "        ?movie a schema:Movie ; schema:name ?movie_title ; schema:genre ?genre .\n",
    "        ?genre rdfs:label ?target_name .\n",
    "        BIND(\"genre\" AS ?rel_type)\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Construction du graphe NetworkX\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Dictionnaires pour le typage des noeuds\n",
    "node_types = {}  # nom_noeud -> type (movie, person, genre)\n",
    "\n",
    "results = g.query(extract_query)\n",
    "for row in results:\n",
    "    movie = str(row.movie_title)\n",
    "    target = str(row.target_name)\n",
    "    rel = str(row.rel_type)\n",
    "\n",
    "    # Ajouter les noeuds avec leur type\n",
    "    node_types[movie] = \"movie\"\n",
    "    if rel == \"genre\":\n",
    "        node_types[target] = \"genre\"\n",
    "    else:\n",
    "        node_types[target] = \"person\"\n",
    "\n",
    "    G.add_edge(movie, target, relation=rel)\n",
    "\n",
    "print(f\"Graphe NetworkX construit :\")\n",
    "print(f\"  Noeuds : {G.number_of_nodes()}\")\n",
    "print(f\"  Aretes : {G.number_of_edges()}\")\n",
    "print(f\"  Types  : {dict((t, sum(1 for v in node_types.values() if v == t)) for t in set(node_types.values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rdf-to-networkx-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Le graphe NetworkX capture les trois types de relations du KG. Les noeuds sont repartis en trois categories :\n",
    "\n",
    "| Type de noeud | Couleur (section suivante) | Role dans le graphe |\n",
    "|--------------|--------------------------|--------------------|\n",
    "| Film (`movie`) | Bleu clair | Noeud central, connecte a realisateur + acteurs + genre |\n",
    "| Personne (`person`) | Vert clair | Peut etre realisateur et/ou acteur |\n",
    "| Genre (`genre`) | Orange | Noeud de regroupement thematique |\n",
    "\n",
    "> **Note** : Un graphe NetworkX oriente (`DiGraph`) preserve la direction des relations (film -> realisateur, film -> acteur, film -> genre)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-matplotlib-intro",
   "metadata": {},
   "source": [
    "### 4.2 Visualisation statique avec matplotlib\n",
    "\n",
    "Nous allons colorer les noeuds par type et dimensionner les labels pour une bonne lisibilite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matplotlib-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Couleurs par type de noeud\n",
    "    color_map = {\"movie\": \"#6BAED6\", \"person\": \"#74C476\", \"genre\": \"#FD8D3C\"}\n",
    "    node_colors = [color_map.get(node_types.get(n, \"movie\"), \"#CCCCCC\") for n in G.nodes()]\n",
    "\n",
    "    # Tailles : les films sont plus gros (noeuds centraux)\n",
    "    node_sizes = [800 if node_types.get(n) == \"movie\" else 500 for n in G.nodes()]\n",
    "\n",
    "    # Couleurs des aretes par type de relation\n",
    "    edge_color_map = {\"director\": \"#E41A1C\", \"actor\": \"#377EB8\", \"genre\": \"#FF7F00\"}\n",
    "    edge_colors = [edge_color_map.get(G.edges[e].get(\"relation\", \"\"), \"#999999\") for e in G.edges()]\n",
    "\n",
    "    # Layout avec seed pour reproductibilite\n",
    "    pos = nx.spring_layout(G, k=2.5, iterations=50, seed=42)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(18, 12))\n",
    "\n",
    "    # Dessiner les aretes\n",
    "    nx.draw_networkx_edges(G, pos, ax=ax, edge_color=edge_colors,\n",
    "                           alpha=0.6, arrows=True, arrowsize=15,\n",
    "                           connectionstyle=\"arc3,rad=0.1\")\n",
    "\n",
    "    # Dessiner les noeuds\n",
    "    nx.draw_networkx_nodes(G, pos, ax=ax, node_color=node_colors,\n",
    "                           node_size=node_sizes, alpha=0.9, edgecolors=\"#333333\",\n",
    "                           linewidths=1.5)\n",
    "\n",
    "    # Labels avec taille reduite pour lisibilite\n",
    "    nx.draw_networkx_labels(G, pos, ax=ax, font_size=7, font_weight=\"bold\")\n",
    "\n",
    "    # Legende\n",
    "    import matplotlib.patches as mpatches\n",
    "    legend_items = [\n",
    "        mpatches.Patch(color=\"#6BAED6\", label=\"Film\"),\n",
    "        mpatches.Patch(color=\"#74C476\", label=\"Personne\"),\n",
    "        mpatches.Patch(color=\"#FD8D3C\", label=\"Genre\"),\n",
    "        mpatches.Patch(color=\"#E41A1C\", label=\"Relation: director\"),\n",
    "        mpatches.Patch(color=\"#377EB8\", label=\"Relation: actor\"),\n",
    "        mpatches.Patch(color=\"#FF7F00\", label=\"Relation: genre\"),\n",
    "    ]\n",
    "    ax.legend(handles=legend_items, loc=\"upper left\", fontsize=9, framealpha=0.9)\n",
    "\n",
    "    ax.set_title(\"Knowledge Graph des Films - Visualisation statique (NetworkX + matplotlib)\",\n",
    "                 fontsize=14, fontweight=\"bold\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la visualisation matplotlib : {e}\")\n",
    "    print(\"Verifiez que matplotlib est correctement installe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matplotlib-viz-interp",
   "metadata": {},
   "source": [
    "### Interpretation : structure du Knowledge Graph\n",
    "\n",
    "**Sortie obtenue** : Un graphe oriente avec des noeuds colores par type et des aretes colorees par relation.\n",
    "\n",
    "**Observations structurelles** :\n",
    "\n",
    "| Observation | Signification |\n",
    "|-------------|---------------|\n",
    "| Les films (bleu) sont des noeuds centraux | Ils connectent personnes et genres |\n",
    "| Christopher Nolan connecte 3 films | Hub de forte connectivite (realisateur prolifique) |\n",
    "| Le genre Science-Fiction regroupe plusieurs films | Communaute thematique visible |\n",
    "| Leonardo DiCaprio relie Inception et Titanic | Pont entre deux realisateurs differents |\n",
    "\n",
    "**Points cles** :\n",
    "1. Le layout `spring_layout` place naturellement les noeuds fortement connectes au centre\n",
    "2. Les genres agissent comme des noeuds de regroupement (clustering)\n",
    "3. Les acteurs partages creent des ponts entre clusters de realisateurs\n",
    "\n",
    "> **Limite** : Avec plus de 50-100 noeuds, la visualisation statique devient difficile a lire. On passe alors a pyvis pour l'exploration interactive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-pyvis-intro",
   "metadata": {},
   "source": [
    "### 4.3 Visualisation interactive avec pyvis\n",
    "\n",
    "pyvis genere un fichier HTML interactif ou l'on peut zoomer, deplacer les noeuds et explorer les connexions. C'est particulierement utile pour les graphes de taille moyenne (50-500 noeuds).\n",
    "\n",
    "> **Note** : pyvis genere un fichier `.html`. Dans un environnement Jupyter standard, il s'affiche dans un iframe. En environnement headless, seul le fichier est cree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pyvis-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pyvis.network import Network\n",
    "    import os\n",
    "\n",
    "    # Creer le reseau pyvis\n",
    "    net = Network(\n",
    "        height=\"600px\",\n",
    "        width=\"100%\",\n",
    "        directed=True,\n",
    "        notebook=True,\n",
    "        cdn_resources=\"in_line\"  # Embarquer les ressources pour portabilite\n",
    "    )\n",
    "\n",
    "    # Configuration physique pour un meilleur layout\n",
    "    net.barnes_hut(gravity=-3000, central_gravity=0.3, spring_length=200)\n",
    "\n",
    "    # Couleurs et formes par type\n",
    "    style_map = {\n",
    "        \"movie\":  {\"color\": \"#6BAED6\", \"shape\": \"dot\", \"size\": 25},\n",
    "        \"person\": {\"color\": \"#74C476\", \"shape\": \"dot\", \"size\": 18},\n",
    "        \"genre\":  {\"color\": \"#FD8D3C\", \"shape\": \"diamond\", \"size\": 20},\n",
    "    }\n",
    "\n",
    "    # Ajouter les noeuds\n",
    "    for node in G.nodes():\n",
    "        ntype = node_types.get(node, \"movie\")\n",
    "        style = style_map.get(ntype, style_map[\"movie\"])\n",
    "        net.add_node(\n",
    "            node, label=node,\n",
    "            color=style[\"color\"],\n",
    "            shape=style[\"shape\"],\n",
    "            size=style[\"size\"],\n",
    "            title=f\"{node} ({ntype})\"\n",
    "        )\n",
    "\n",
    "    # Ajouter les aretes\n",
    "    edge_style = {\n",
    "        \"director\": {\"color\": \"#E41A1C\", \"width\": 2},\n",
    "        \"actor\":    {\"color\": \"#377EB8\", \"width\": 1.5},\n",
    "        \"genre\":    {\"color\": \"#FF7F00\", \"width\": 1, \"dashes\": True},\n",
    "    }\n",
    "\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        rel = data.get(\"relation\", \"\")\n",
    "        style = edge_style.get(rel, {\"color\": \"#999\", \"width\": 1})\n",
    "        net.add_edge(u, v, title=rel, color=style[\"color\"], width=style[\"width\"])\n",
    "\n",
    "    # Sauvegarder en HTML\n",
    "    output_html = \"movie_kg_interactive.html\"\n",
    "    net.show(output_html)\n",
    "    print(f\"Visualisation interactive sauvegardee dans : {output_html}\")\n",
    "    print(f\"Noeuds : {len(net.nodes)}, Aretes : {len(net.edges)}\")\n",
    "    print(\"\\nOuvrez le fichier HTML dans un navigateur pour explorer le graphe.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"pyvis n'est pas installe. Visualisation interactive non disponible.\")\n",
    "    print(\"Installez-le avec : pip install pyvis\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur pyvis : {e}\")\n",
    "    print(\"La visualisation interactive n'a pas pu etre generee.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pyvis-viz-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "pyvis genere un fichier HTML autonome qui permet :\n",
    "- **Zoom** : molette de la souris\n",
    "- **Deplacement** : clic-glisse sur un noeud\n",
    "- **Info-bulle** : survol d'un noeud affiche son type\n",
    "- **Physique** : les noeuds s'organisent automatiquement (algorithme Barnes-Hut)\n",
    "\n",
    "| Aspect | matplotlib (statique) | pyvis (interactif) |\n",
    "|--------|----------------------|--------------------|\n",
    "| Integration notebook | Native | Via iframe/HTML |\n",
    "| Exploration | Limitee | Zoom, deplacement, filtrage |\n",
    "| Grands graphes | Difficile (>50 noeuds) | Correct (jusqu'a ~500 noeuds) |\n",
    "| Partage | Image PNG/PDF | Fichier HTML autonome |\n",
    "| Interactivite | Aucune | Survol, clic, physique |\n",
    "\n",
    "> **Bonne pratique** : Pour l'exploration et la decouverte, utiliser pyvis. Pour les rapports et publications, utiliser matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-filtered-intro",
   "metadata": {},
   "source": [
    "### 4.4 Visualisation filtree : filmographie d'un realisateur\n",
    "\n",
    "Pour mieux comprendre les sous-structures du KG, visualisons uniquement les films d'un realisateur donne et leurs connexions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filtered-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Filtrer les films de Christopher Nolan\n",
    "    filter_query = \"\"\"\n",
    "    PREFIX schema: <http://schema.org/>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "    SELECT ?movie_title ?rel_type ?target_name\n",
    "    WHERE {\n",
    "        ?movie a schema:Movie ;\n",
    "               schema:name ?movie_title ;\n",
    "               schema:director ?director .\n",
    "        ?director schema:name \"Christopher Nolan\" .\n",
    "        {\n",
    "            ?movie schema:actor ?person .\n",
    "            ?person schema:name ?target_name .\n",
    "            BIND(\"actor\" AS ?rel_type)\n",
    "        }\n",
    "        UNION\n",
    "        {\n",
    "            ?movie schema:genre ?genre .\n",
    "            ?genre rdfs:label ?target_name .\n",
    "            BIND(\"genre\" AS ?rel_type)\n",
    "        }\n",
    "        UNION\n",
    "        {\n",
    "            ?movie schema:director ?dir .\n",
    "            ?dir schema:name ?target_name .\n",
    "            BIND(\"director\" AS ?rel_type)\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    # Construire le sous-graphe filtre\n",
    "    G_nolan = nx.DiGraph()\n",
    "    nolan_types = {}\n",
    "\n",
    "    for row in g.query(filter_query):\n",
    "        movie = str(row.movie_title)\n",
    "        target = str(row.target_name)\n",
    "        rel = str(row.rel_type)\n",
    "        nolan_types[movie] = \"movie\"\n",
    "        if rel == \"genre\":\n",
    "            nolan_types[target] = \"genre\"\n",
    "        else:\n",
    "            nolan_types[target] = \"person\"\n",
    "        G_nolan.add_edge(movie, target, relation=rel)\n",
    "\n",
    "    # Couleurs\n",
    "    nolan_colors = [color_map.get(nolan_types.get(n, \"movie\"), \"#CCC\") for n in G_nolan.nodes()]\n",
    "    nolan_sizes = [900 if nolan_types.get(n) == \"movie\" else 600 for n in G_nolan.nodes()]\n",
    "    nolan_edge_colors = [edge_color_map.get(G_nolan.edges[e].get(\"relation\", \"\"), \"#999\")\n",
    "                         for e in G_nolan.edges()]\n",
    "\n",
    "    pos_nolan = nx.spring_layout(G_nolan, k=3.0, iterations=50, seed=42)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 9))\n",
    "    nx.draw_networkx_edges(G_nolan, pos_nolan, ax=ax, edge_color=nolan_edge_colors,\n",
    "                           alpha=0.7, arrows=True, arrowsize=18,\n",
    "                           connectionstyle=\"arc3,rad=0.1\")\n",
    "    nx.draw_networkx_nodes(G_nolan, pos_nolan, ax=ax, node_color=nolan_colors,\n",
    "                           node_size=nolan_sizes, alpha=0.9, edgecolors=\"#333\",\n",
    "                           linewidths=1.5)\n",
    "    nx.draw_networkx_labels(G_nolan, pos_nolan, ax=ax, font_size=9, font_weight=\"bold\")\n",
    "\n",
    "    legend_items = [\n",
    "        mpatches.Patch(color=\"#6BAED6\", label=\"Film\"),\n",
    "        mpatches.Patch(color=\"#74C476\", label=\"Personne\"),\n",
    "        mpatches.Patch(color=\"#FD8D3C\", label=\"Genre\"),\n",
    "    ]\n",
    "    ax.legend(handles=legend_items, loc=\"upper left\", fontsize=10)\n",
    "    ax.set_title(\"Filmographie de Christopher Nolan - Sous-graphe du KG\",\n",
    "                 fontsize=13, fontweight=\"bold\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\nSous-graphe Nolan : {G_nolan.number_of_nodes()} noeuds, {G_nolan.number_of_edges()} aretes\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la visualisation filtree : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filtered-viz-interp",
   "metadata": {},
   "source": [
    "### Interpretation : filmographie Nolan\n",
    "\n",
    "**Sortie obtenue** : Le sous-graphe de Christopher Nolan montre ses 3 films (Inception, The Dark Knight, Interstellar) avec leurs acteurs et genres.\n",
    "\n",
    "| Observation | Detail |\n",
    "|-------------|--------|\n",
    "| Nolan est le noeud central | Connecte aux 3 films (hub realisateur) |\n",
    "| Science-Fiction domine | 2 films sur 3 (Inception, Interstellar) |\n",
    "| Pas d'acteur partage | Chaque film a un casting distinct dans ce dataset |\n",
    "\n",
    "**Points cles** :\n",
    "1. Le filtrage SPARQL est plus efficace que le filtrage Python post-hoc\n",
    "2. Les sous-graphes permettent d'analyser des clusters specifiques du KG\n",
    "3. Cette technique est utilisee en production pour les \"profils\" d'entites (ex: fiche artiste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. OWLReady2 pour la manipulation d'ontologies\n",
    "\n",
    "**OWLReady2** est une bibliotheque Python permettant de :\n",
    "- Charger des ontologies OWL 2 (formats RDF/XML, OWL/XML)\n",
    "- Naviguer dans les classes, proprietes et instances\n",
    "- Modifier l'ontologie programmatiquement\n",
    "- Lancer le raisonneur **HermiT** (integre) pour inferer de nouvelles connaissances\n",
    "\n",
    "### Comparaison avec dotNetRDF OntologyGraph\n",
    "\n",
    "| Aspect | OWLReady2 (Python) | dotNetRDF OntologyGraph (C#) |\n",
    "|--------|-------------------|-----------------------------|\n",
    "| Langage | Python | C# |\n",
    "| Raisonneur integre | HermiT (Java, transparent) | Non (externe) |\n",
    "| API | Orientee objet Python | API .NET |\n",
    "| Stockage | SQLite (persistant) | Memoire |\n",
    "| Standards | OWL 2 complet | OWL partiel |\n",
    "\n",
    "> **Lien avec SW-7** : Dans le notebook sur OWL, nous avons utilise dotNetRDF pour manipuler des ontologies en C#. Ici, nous explorons l'equivalent Python avec OWLReady2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5-load-intro",
   "metadata": {},
   "source": [
    "### 5.1 Chargement de l'ontologie universitaire\n",
    "\n",
    "Le fichier `data/university.owl` contient une ontologie OWL 2 avec des classes (Person, Student, Professor, Course, Department), des proprietes (enrolledIn, teaches, memberOf) et des instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owlready-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import owlready2\n",
    "    import os\n",
    "\n",
    "    # Charger l'ontologie depuis le fichier local\n",
    "    onto_path = os.path.abspath(\"data/university.owl\")\n",
    "    print(f\"Chargement de : {onto_path}\")\n",
    "\n",
    "    onto = owlready2.get_ontology(f\"file://{onto_path}\").load()\n",
    "\n",
    "    print(f\"\\nOntologie chargee : {onto.base_iri}\")\n",
    "    print(f\"Nom : {onto.name}\")\n",
    "\n",
    "    OWLREADY_AVAILABLE = True\n",
    "\n",
    "except ImportError:\n",
    "    print(\"owlready2 n'est pas installe.\")\n",
    "    print(\"Installez-le avec : pip install owlready2\")\n",
    "    OWLREADY_AVAILABLE = False\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement de l'ontologie : {e}\")\n",
    "    OWLREADY_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owlready-load-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "OWLReady2 charge l'ontologie en memoire et cree des objets Python accessibles directement. Le `base_iri` identifie l'ontologie de maniere unique.\n",
    "\n",
    "> **Note technique** : OWLReady2 utilise SQLite en arriere-plan pour stocker l'ontologie. Cela permet des ontologies persistantes entre sessions, contrairement a rdflib qui travaille uniquement en memoire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5-explore-intro",
   "metadata": {},
   "source": [
    "### 5.2 Exploration : classes, proprietes, instances\n",
    "\n",
    "Listons les elements de l'ontologie pour comprendre sa structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owlready-explore",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OWLREADY_AVAILABLE:\n",
    "    # --- Classes ---\n",
    "    print(\"=== Classes ===\")\n",
    "    for cls in onto.classes():\n",
    "        parents = [p.name for p in cls.is_a if hasattr(p, 'name')]\n",
    "        print(f\"  {cls.name} (sous-classe de: {', '.join(parents) if parents else 'Thing'})\")\n",
    "\n",
    "    # --- Object Properties ---\n",
    "    print(\"\\n=== Object Properties ===\")\n",
    "    for prop in onto.object_properties():\n",
    "        domain = [d.name for d in prop.domain] if prop.domain else [\"?\"]\n",
    "        range_ = [r.name for r in prop.range] if prop.range else [\"?\"]\n",
    "        print(f\"  {prop.name} : {', '.join(domain)} -> {', '.join(range_)}\")\n",
    "\n",
    "    # --- Datatype Properties ---\n",
    "    print(\"\\n=== Datatype Properties ===\")\n",
    "    for prop in onto.data_properties():\n",
    "        domain = [d.name for d in prop.domain] if prop.domain else [\"?\"]\n",
    "        range_ = [str(r) for r in prop.range] if prop.range else [\"?\"]\n",
    "        print(f\"  {prop.name} : {', '.join(domain)} -> {', '.join(range_)}\")\n",
    "\n",
    "    # --- Instances ---\n",
    "    print(\"\\n=== Instances ===\")\n",
    "    for ind in onto.individuals():\n",
    "        types = [t.name for t in ind.is_a if hasattr(t, 'name')]\n",
    "        print(f\"  {ind.name} (type: {', '.join(types)})\")\n",
    "else:\n",
    "    print(\"OWLReady2 non disponible. Section ignoree.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owlready-explore-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "L'ontologie universitaire contient une hierarchie de classes bien structuree :\n",
    "\n",
    "```\n",
    "Thing\n",
    "  +-- Person\n",
    "  |     +-- Student\n",
    "  |     |     +-- GraduateStudent\n",
    "  |     +-- Professor (disjoint de Student)\n",
    "  +-- Course\n",
    "  +-- Department\n",
    "```\n",
    "\n",
    "| Element | Nombre | Exemples |\n",
    "|---------|--------|----------|\n",
    "| Classes | 5 | Person, Student, Professor, Course, Department |\n",
    "| Object Properties | 4 | enrolledIn, teaches, memberOf, advisedBy |\n",
    "| Datatype Properties | 2 | name, credits |\n",
    "| Instances | 5+ | prof_dupont, etud_martin, etud_bernard |\n",
    "\n",
    "> **Point cle** : La contrainte `disjointWith` entre Professor et Student signifie qu'une personne ne peut pas etre les deux a la fois. Le raisonneur peut detecter des violations de cette contrainte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5-reasoner-intro",
   "metadata": {},
   "source": [
    "### 5.3 Raisonnement avec HermiT\n",
    "\n",
    "Le raisonneur **HermiT** est un raisonneur OWL 2 DL complet, integre a OWLReady2 (via Java). Il peut :\n",
    "- Inferer les types d'instances (classification)\n",
    "- Detecter les inconsistances\n",
    "- Calculer les classes equivalentes\n",
    "- Verifier la satisfaisabilite\n",
    "\n",
    "Lancons le raisonneur sur notre ontologie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owlready-reasoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OWLREADY_AVAILABLE:\n",
    "    try:\n",
    "        # Afficher l'etat avant raisonnement\n",
    "        print(\"=== Avant raisonnement ===\")\n",
    "        for ind in onto.individuals():\n",
    "            types_before = [t.name for t in ind.is_a if hasattr(t, 'name')]\n",
    "            print(f\"  {ind.name} est de type : {types_before}\")\n",
    "\n",
    "        # Lancer le raisonneur HermiT\n",
    "        print(\"\\nLancement du raisonneur HermiT...\")\n",
    "        with onto:\n",
    "            owlready2.sync_reasoner_hermit(infer_property_values=True)\n",
    "        print(\"Raisonnement termine.\")\n",
    "\n",
    "        # Afficher l'etat apres raisonnement\n",
    "        print(\"\\n=== Apres raisonnement ===\")\n",
    "        for ind in onto.individuals():\n",
    "            types_after = [t.name for t in ind.is_a if hasattr(t, 'name')]\n",
    "            print(f\"  {ind.name} est de type : {types_after}\")\n",
    "\n",
    "        # Verifier la coherence\n",
    "        inconsistent = list(owlready2.default_world.inconsistent_classes())\n",
    "        if inconsistent:\n",
    "            print(f\"\\nClasses inconsistantes detectees : {inconsistent}\")\n",
    "        else:\n",
    "            print(\"\\nAucune inconsistance detectee. L'ontologie est coherente.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du raisonnement : {e}\")\n",
    "        print(\"\\nNote : HermiT necessite Java (JRE) installe sur le systeme.\")\n",
    "        print(\"Si Java n'est pas disponible, le raisonnement ne peut pas s'executer.\")\n",
    "else:\n",
    "    print(\"OWLReady2 non disponible. Section ignoree.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owlready-reasoner-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Le raisonneur HermiT effectue plusieurs types d'inferences :\n",
    "\n",
    "| Type d'inference | Description | Exemple |\n",
    "|-----------------|-------------|--------|\n",
    "| Classification | Infere les types implicites | GraduateStudent est aussi Student et Person |\n",
    "| Coherence | Verifie les contraintes | Professor et Student sont disjoints |\n",
    "| Proprietes | Propage les valeurs | Si etud_martin est GraduateStudent, il est aussi Person |\n",
    "\n",
    "**Points cles** :\n",
    "1. Le raisonnement OWL va au-dela de l'inference RDFS (classes equivalentes, restrictions, disjonctions)\n",
    "2. HermiT est garanti complet pour OWL 2 DL (il trouve toutes les consequences logiques)\n",
    "3. En production, le raisonnement est souvent execute hors-ligne (materialisation) plutot qu'a la volee\n",
    "\n",
    "> **Note technique** : HermiT necessite une JVM. Si Java n'est pas installe, utilisez `sync_reasoner_pellet()` ou installez Java avec `apt install default-jre` / `choco install openjdk`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Qualite et validation d'un Knowledge Graph\n",
    "\n",
    "Un Knowledge Graph n'a de valeur que si ses donnees sont **completes**, **coherentes** et **a jour**. Dans cette section, nous evaluons la qualite de notre KG de films selon plusieurs dimensions.\n",
    "\n",
    "### Dimensions de qualite\n",
    "\n",
    "| Dimension | Question | Methode de verification |\n",
    "|-----------|----------|------------------------|\n",
    "| Completude | Y a-t-il des donnees manquantes ? | SPARQL OPTIONAL + COUNT |\n",
    "| Coherence | Les valeurs sont-elles valides ? | Contraintes de domaine/range |\n",
    "| Unicite | Y a-t-il des doublons ? | SPARQL COUNT + GROUP BY |\n",
    "| Conformite | Le KG respecte-t-il son schema ? | SHACL (cf. SW-9) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6-completeness-intro",
   "metadata": {},
   "source": [
    "### 6.1 Verification de completude\n",
    "\n",
    "Verifions si tous les films ont un realisateur, un genre et une note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-completeness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification de completude\n",
    "completeness_query = \"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "\n",
    "SELECT ?title\n",
    "    (BOUND(?director) AS ?has_director)\n",
    "    (BOUND(?rating) AS ?has_rating)\n",
    "    (BOUND(?genre) AS ?has_genre)\n",
    "    (COUNT(?actor) AS ?nb_actors)\n",
    "WHERE {\n",
    "    ?movie a schema:Movie ;\n",
    "           schema:name ?title .\n",
    "    OPTIONAL { ?movie schema:director ?director }\n",
    "    OPTIONAL { ?movie schema:aggregateRating ?rating }\n",
    "    OPTIONAL { ?movie schema:genre ?genre }\n",
    "    OPTIONAL { ?movie schema:actor ?actor }\n",
    "}\n",
    "GROUP BY ?title ?director ?rating ?genre\n",
    "ORDER BY ?title\n",
    "\"\"\"\n",
    "\n",
    "results = g.query(completeness_query)\n",
    "print(f\"{'Film':<30} {'Realisateur':<13} {'Note':<8} {'Genre':<8} {'Acteurs'}\")\n",
    "print(\"-\" * 75)\n",
    "complete = 0\n",
    "total = 0\n",
    "for row in results:\n",
    "    total += 1\n",
    "    has_dir = \"OK\" if row.has_director else \"MANQUANT\"\n",
    "    has_rat = \"OK\" if row.has_rating else \"MANQUANT\"\n",
    "    has_gen = \"OK\" if row.has_genre else \"MANQUANT\"\n",
    "    nb_act = int(row.nb_actors)\n",
    "    is_complete = (row.has_director and row.has_rating and row.has_genre and nb_act >= 1)\n",
    "    if is_complete:\n",
    "        complete += 1\n",
    "    print(f\"{str(row.title):<30} {has_dir:<13} {has_rat:<8} {has_gen:<8} {nb_act}\")\n",
    "\n",
    "print(f\"\\nCompletude : {complete}/{total} films complets ({100*complete/total:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-completeness-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "La verification montre que notre KG est complet pour les proprietes verifiees. Tous les films ont :\n",
    "- Un realisateur\n",
    "- Une note\n",
    "- Un genre\n",
    "- Au moins un acteur\n",
    "\n",
    "En production, les KG sont rarement complets a 100%. Les lacunes typiques incluent :\n",
    "- Dates manquantes (films anciens)\n",
    "- Acteurs secondaires non renseignes\n",
    "- Genres multiples non captures (un film peut etre a la fois Action et Science-Fiction)\n",
    "\n",
    "> **Lien avec SW-9** : La validation SHACL permet de formaliser ces regles de completude sous forme de \"shapes\" (contraintes declaratives) plutot que de requetes ad-hoc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6-consistency-intro",
   "metadata": {},
   "source": [
    "### 6.2 Verification de coherence\n",
    "\n",
    "Verifions que les valeurs sont dans des plages raisonnables (annees, notes) et que les genres sont valides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification de coherence des valeurs\n",
    "consistency_checks = []\n",
    "\n",
    "# Check 1 : Annees dans une plage valide (1900-2025)\n",
    "year_query = \"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "SELECT ?title ?year\n",
    "WHERE {\n",
    "    ?movie a schema:Movie ;\n",
    "           schema:name ?title ;\n",
    "           schema:datePublished ?year .\n",
    "    FILTER (?year < 1900 || ?year > 2025)\n",
    "}\n",
    "\"\"\"\n",
    "invalid_years = list(g.query(year_query))\n",
    "consistency_checks.append((\n",
    "    \"Annees valides (1900-2025)\",\n",
    "    len(invalid_years) == 0,\n",
    "    f\"{len(invalid_years)} film(s) hors plage\" if invalid_years else \"OK\"\n",
    "))\n",
    "\n",
    "# Check 2 : Notes dans une plage valide (0-10)\n",
    "rating_query = \"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "SELECT ?title ?rating\n",
    "WHERE {\n",
    "    ?movie a schema:Movie ;\n",
    "           schema:name ?title ;\n",
    "           schema:aggregateRating ?rating .\n",
    "    FILTER (?rating < 0 || ?rating > 10)\n",
    "}\n",
    "\"\"\"\n",
    "invalid_ratings = list(g.query(rating_query))\n",
    "consistency_checks.append((\n",
    "    \"Notes valides (0-10)\",\n",
    "    len(invalid_ratings) == 0,\n",
    "    f\"{len(invalid_ratings)} film(s) hors plage\" if invalid_ratings else \"OK\"\n",
    "))\n",
    "\n",
    "# Check 3 : Pas de doublon de titre\n",
    "dup_query = \"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "SELECT ?title (COUNT(?movie) AS ?count)\n",
    "WHERE {\n",
    "    ?movie a schema:Movie ; schema:name ?title .\n",
    "}\n",
    "GROUP BY ?title\n",
    "HAVING (COUNT(?movie) > 1)\n",
    "\"\"\"\n",
    "duplicates = list(g.query(dup_query))\n",
    "consistency_checks.append((\n",
    "    \"Pas de titres dupliques\",\n",
    "    len(duplicates) == 0,\n",
    "    f\"{len(duplicates)} doublon(s)\" if duplicates else \"OK\"\n",
    "))\n",
    "\n",
    "# Check 4 : Genres connus\n",
    "genre_query = \"\"\"\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX movies: <http://example.org/movies/>\n",
    "SELECT (COUNT(DISTINCT ?genre) AS ?nb_genres)\n",
    "WHERE {\n",
    "    ?genre a movies:Genre ; rdfs:label ?label .\n",
    "}\n",
    "\"\"\"\n",
    "genre_count = list(g.query(genre_query))\n",
    "nb = int(genre_count[0][0]) if genre_count else 0\n",
    "consistency_checks.append((\n",
    "    f\"Genres definis ({nb} trouves)\",\n",
    "    nb > 0,\n",
    "    \"OK\" if nb > 0 else \"Aucun genre\"\n",
    "))\n",
    "\n",
    "# Affichage du rapport\n",
    "print(\"=== Rapport de coherence du Knowledge Graph ===\")\n",
    "print()\n",
    "print(f\"{'Verification':<35} {'Statut':<8} {'Detail'}\")\n",
    "print(\"-\" * 65)\n",
    "for check_name, passed, detail in consistency_checks:\n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "    print(f\"{check_name:<35} {status:<8} {detail}\")\n",
    "\n",
    "total_pass = sum(1 for _, p, _ in consistency_checks if p)\n",
    "print(f\"\\nResultat : {total_pass}/{len(consistency_checks)} verifications reussies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-consistency-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Le rapport de coherence verifie quatre aspects cles :\n",
    "\n",
    "| Verification | Ce qu'elle detecte | Equivalent SHACL |\n",
    "|-------------|-------------------|------------------|\n",
    "| Annees valides | Films avec des annees aberrantes | `sh:minInclusive`, `sh:maxInclusive` |\n",
    "| Notes valides | Notes hors echelle 0-10 | `sh:datatype xsd:float` + bornes |\n",
    "| Pas de doublons | Titres identiques (collision URI) | `sh:uniqueLang` ou contrainte custom |\n",
    "| Genres definis | Genres sans label | `sh:minCount 1` sur rdfs:label |\n",
    "\n",
    "**Points cles** :\n",
    "1. Ces verifications ad-hoc sont utiles en developpement, mais en production on prefere **SHACL** (cf. SW-9)\n",
    "2. La qualite d'un KG est un processus continu, pas un controle ponctuel\n",
    "3. Les pipelines de construction de KG incluent systematiquement une etape de validation\n",
    "\n",
    "> **Bonne pratique** : Definir les regles de qualite en SHACL des la conception du KG, et les executer a chaque mise a jour (CI/CD semantique)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6-stats-intro",
   "metadata": {},
   "source": [
    "### 6.3 Statistiques globales du Knowledge Graph\n",
    "\n",
    "Pour completer l'analyse, calculons des metriques structurelles du KG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques structurelles du KG\n",
    "stats_queries = {\n",
    "    \"Triplets totaux\": \"SELECT (COUNT(*) AS ?c) WHERE { ?s ?p ?o }\",\n",
    "    \"Sujets uniques\": \"SELECT (COUNT(DISTINCT ?s) AS ?c) WHERE { ?s ?p ?o }\",\n",
    "    \"Predicats uniques\": \"SELECT (COUNT(DISTINCT ?p) AS ?c) WHERE { ?s ?p ?o }\",\n",
    "    \"Films\": \"PREFIX schema: <http://schema.org/> SELECT (COUNT(?m) AS ?c) WHERE { ?m a schema:Movie }\",\n",
    "    \"Personnes\": \"PREFIX schema: <http://schema.org/> SELECT (COUNT(DISTINCT ?p) AS ?c) WHERE { ?p a schema:Person }\",\n",
    "    \"Genres\": \"PREFIX movies: <http://example.org/movies/> SELECT (COUNT(?g) AS ?c) WHERE { ?g a movies:Genre }\",\n",
    "}\n",
    "\n",
    "print(\"=== Statistiques du Knowledge Graph ===\")\n",
    "print()\n",
    "for label, query in stats_queries.items():\n",
    "    result = list(g.query(query))\n",
    "    count = int(result[0][0]) if result else 0\n",
    "    print(f\"  {label:<25} : {count}\")\n",
    "\n",
    "# Ratio triplets/entites\n",
    "total_triples = int(list(g.query(stats_queries[\"Triplets totaux\"]))[0][0])\n",
    "total_subjects = int(list(g.query(stats_queries[\"Sujets uniques\"]))[0][0])\n",
    "if total_subjects > 0:\n",
    "    print(f\"\\n  Ratio triplets/entite   : {total_triples/total_subjects:.1f}\")\n",
    "    print(f\"  (mesure la richesse descriptive moyenne par entite)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-stats-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Le ratio **triplets/entite** est un indicateur cle de la richesse descriptive du KG :\n",
    "\n",
    "| Ratio | Interpretation |\n",
    "|-------|---------------|\n",
    "| < 2 | KG squelettique (presque que des types) |\n",
    "| 2-5 | KG de base (type + quelques proprietes) |\n",
    "| 5-10 | KG riche (proprietes detaillees, relations multiples) |\n",
    "| > 10 | KG tres detaille (metadata, annotations, provenance) |\n",
    "\n",
    "**Recapitulatif qualite** :\n",
    "\n",
    "| Dimension | Resultat | Methode |\n",
    "|-----------|----------|--------|\n",
    "| Completude | 100% des films complets | SPARQL OPTIONAL |\n",
    "| Coherence | Toutes les valeurs valides | SPARQL FILTER |\n",
    "| Unicite | Pas de doublons | SPARQL GROUP BY + HAVING |\n",
    "| Richesse | Ratio triplets/entite correct | Statistiques globales |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercices\n",
    "\n",
    "### Exercice 1 : Construire un KG etudiants/cours\n",
    "\n",
    "A partir du modele de la section 2, construisez un Knowledge Graph representant des etudiants et des cours. Creez un DataFrame pandas avec les colonnes `student_name`, `course_name`, `grade`, `professor`, puis transformez-le en triplets RDF.\n",
    "\n",
    "**Indices** :\n",
    "- Utilisez les namespaces `schema:Person`, `schema:Course`\n",
    "- Creez une propriete `ex:enrolledIn` pour la relation etudiant -> cours\n",
    "- Ajoutez les notes comme proprietes de la relation (hint : utiliser un noeud blank ou RDF-star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1 : Construire un KG etudiants/cours\n",
    "# TODO : Completez le code ci-dessous\n",
    "\n",
    "# Etape 1 : Creer un DataFrame\n",
    "student_data = {\n",
    "    \"student_name\": [\"Alice Dupont\", \"Bob Martin\", \"Claire Leroy\", \"Alice Dupont\", \"Bob Martin\"],\n",
    "    \"course_name\": [\"Web Semantique\", \"Web Semantique\", \"Intelligence Artificielle\",\n",
    "                    \"Intelligence Artificielle\", \"Bases de Donnees\"],\n",
    "    \"grade\": [16, 14, 18, 15, 12],\n",
    "    \"professor\": [\"Prof. Durand\", \"Prof. Durand\", \"Prof. Moreau\",\n",
    "                  \"Prof. Moreau\", \"Prof. Petit\"]\n",
    "}\n",
    "df_students = pd.DataFrame(student_data)\n",
    "print(df_students)\n",
    "\n",
    "# Etape 2 : Transformer en triplets RDF\n",
    "# g_students = Graph()\n",
    "# ... votre code ici ...\n",
    "\n",
    "# Etape 3 : Verifier avec une requete SPARQL\n",
    "# ... votre code ici ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise2-intro",
   "metadata": {},
   "source": [
    "### Exercice 2 : Visualiser le KG filtre par realisateur\n",
    "\n",
    "En reprenant le code de la section 4.4, modifiez la requete SPARQL pour filtrer les films de **Quentin Tarantino** et visualisez le sous-graphe resultant.\n",
    "\n",
    "**Bonus** : Ajoutez les notes des films comme taille des noeuds (film mieux note = noeud plus gros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 : Sous-graphe de Quentin Tarantino\n",
    "# TODO : Modifiez la requete filter_query de la section 4.4\n",
    "# Remplacez \"Christopher Nolan\" par \"Quentin Tarantino\"\n",
    "# Visualisez le resultat\n",
    "\n",
    "# tarantino_query = \"\"\"\n",
    "# ... votre requete ici ...\n",
    "# \"\"\"\n",
    "\n",
    "# G_tarantino = nx.DiGraph()\n",
    "# ... votre code ici ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise3-intro",
   "metadata": {},
   "source": [
    "### Exercice 3 : Charger et raisonner avec OWLReady2\n",
    "\n",
    "Chargez l'ontologie `data/university.owl` avec OWLReady2, puis :\n",
    "1. Ajoutez programmatiquement un nouvel etudiant (instance de `GraduateStudent`)\n",
    "2. Inscrivez-le a un cours existant\n",
    "3. Lancez le raisonneur HermiT\n",
    "4. Verifiez que le raisonneur infere bien qu'il est aussi `Student` et `Person`\n",
    "\n",
    "**Indice** : Utilisez `onto.GraduateStudent(\"new_student\")` pour creer une instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3 : Ajouter un etudiant et raisonner\n",
    "# TODO : Completez le code ci-dessous\n",
    "\n",
    "# if OWLREADY_AVAILABLE:\n",
    "#     # Recharger l'ontologie pour repartir d'un etat propre\n",
    "#     onto2 = owlready2.get_ontology(f\"file://{onto_path}\").load()\n",
    "#\n",
    "#     # Etape 1 : Creer un nouvel etudiant\n",
    "#     # ... votre code ici ...\n",
    "#\n",
    "#     # Etape 2 : L'inscrire a un cours\n",
    "#     # ... votre code ici ...\n",
    "#\n",
    "#     # Etape 3 : Lancer le raisonneur\n",
    "#     # ... votre code ici ...\n",
    "#\n",
    "#     # Etape 4 : Verifier les types inferes\n",
    "#     # ... votre code ici ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resume\n",
    "\n",
    "| Element | Ce que nous avons appris |\n",
    "|---------|------------------------|\n",
    "| Knowledge Graph | Graphe d'entites + relations + ontologie, adopte massivement en industrie |\n",
    "| Construction CSV -> RDF | pandas + rdflib pour transformer des donnees tabulaires en triplets |\n",
    "| kglab | Couche d'abstraction Python, SPARQL -> DataFrame en 1 ligne |\n",
    "| Visualisation NetworkX | Graphes statiques avec couleurs par type et layout spring |\n",
    "| Visualisation pyvis | Graphes interactifs HTML pour l'exploration |\n",
    "| OWLReady2 | Manipulation d'ontologies OWL + raisonneur HermiT integre |\n",
    "| Qualite du KG | Completude, coherence, unicite -- SHACL pour formaliser |\n",
    "\n",
    "### Ce qui change par rapport aux notebooks precedents\n",
    "\n",
    "| Avant (SW-1 a SW-11) | Maintenant (SW-12) |\n",
    "|----------------------|-------------------|\n",
    "| Triplets individuels | Knowledge Graph structure |\n",
    "| Graphe comme stockage | Graphe comme outil d'analyse |\n",
    "| Visualisation textuelle | Visualisation graphique (NetworkX, pyvis) |\n",
    "| Ontologie theorique | Raisonnement automatise (HermiT) |\n",
    "| Validation manuelle | Pipeline de qualite |\n",
    "\n",
    "### Prochaine etape\n",
    "\n",
    "Dans le notebook suivant (**SW-13-GraphRAG**), nous verrons comment combiner un Knowledge Graph avec un LLM pour creer un systeme de question-reponse augmente par le graphe (GraphRAG) -- la convergence entre IA symbolique et IA neuronale.\n",
    "\n",
    "---\n",
    "\n",
    "**Navigation** : [<< 11-RDFStar](SW-11-RDFStar.ipynb) | [Index](README.md) | [13-GraphRAG >>](SW-13-GraphRAG.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}