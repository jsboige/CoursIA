{
  "_meta": {
    "title": "Qwen Image Edit - Nunchaku INT4 Lightning Text-to-Image",
    "description": "INT4 quantized workflow using SVDQuant for low VRAM (3-4GB). Lightning 4-step variant for fast generation.",
    "version": "1.0.0",
    "author": "CoursIA GenAI Team",
    "date": "2026-01-21",
    "source": "Based on nunchaku-ai/ComfyUI-nunchaku examples",
    "models_required": {
      "diffusion_model": "diffusion_models/svdq-int4_r128-qwen-image-edit-lightningv1.0-4steps.safetensors (~8GB)",
      "text_encoder": "text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors (8.8GB)",
      "vae": "vae/qwen_image_vae.safetensors (243MB)"
    },
    "nodes_used": [
      "NunchakuQwenImageDiTLoader",
      "CLIPLoader",
      "VAELoader",
      "ModelSamplingAuraFlow",
      "CFGNorm",
      "TextEncodeQwenImageEditPlus",
      "ConditioningZeroOut",
      "EmptySD3LatentImage",
      "KSampler",
      "VAEDecode",
      "SaveImage"
    ],
    "performance": {
      "vram_required_gb": 4,
      "steps": 4,
      "estimated_time_seconds": 20
    }
  },
  "1": {
    "class_type": "VAELoader",
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "_meta": {"title": "Load VAE (16-channel)"}
  },
  "2": {
    "class_type": "CLIPLoader",
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "sd3"
    },
    "_meta": {"title": "Load CLIP (Qwen 2.5 VL FP8)"}
  },
  "3": {
    "class_type": "NunchakuQwenImageDiTLoader",
    "inputs": {
      "model_name": "svdq-int4_r128-qwen-image-edit-lightningv1.0-4steps.safetensors",
      "cpu_offload": "auto"
    },
    "_meta": {"title": "Load Nunchaku INT4 Lightning Model"}
  },
  "4": {
    "class_type": "ModelSamplingAuraFlow",
    "inputs": {
      "model": ["3", 0],
      "shift": 1.0
    },
    "_meta": {"title": "Model Sampling AuraFlow (shift=1.0 for Lightning)"}
  },
  "5": {
    "class_type": "CFGNorm",
    "inputs": {
      "model": ["4", 0],
      "strength": 1.0
    },
    "_meta": {"title": "CFG Normalization (strength=1.0)"}
  },
  "6": {
    "class_type": "TextEncodeQwenImageEditPlus",
    "inputs": {
      "clip": ["2", 0],
      "vae": ["1", 0],
      "prompt": "A serene mountain landscape at sunset with a lake reflecting the orange sky"
    },
    "_meta": {"title": "Qwen Text Encoder (positive)"}
  },
  "7": {
    "class_type": "ConditioningZeroOut",
    "inputs": {
      "conditioning": ["6", 0]
    },
    "_meta": {"title": "Zero Out Conditioning (negative)"}
  },
  "8": {
    "class_type": "EmptySD3LatentImage",
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "_meta": {"title": "Empty Latent (1024x1024, 16 channels)"}
  },
  "9": {
    "class_type": "KSampler",
    "inputs": {
      "model": ["5", 0],
      "positive": ["6", 0],
      "negative": ["7", 0],
      "latent_image": ["8", 0],
      "seed": 42,
      "steps": 4,
      "cfg": 1.0,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 1.0
    },
    "_meta": {"title": "KSampler (euler/beta, CFG=1.0, 4 steps Lightning)"}
  },
  "10": {
    "class_type": "VAEDecode",
    "inputs": {
      "samples": ["9", 0],
      "vae": ["1", 0]
    },
    "_meta": {"title": "VAE Decode"}
  },
  "11": {
    "class_type": "SaveImage",
    "inputs": {
      "images": ["10", 0],
      "filename_prefix": "qwen_nunchaku_t2i"
    },
    "_meta": {"title": "Save Image"}
  }
}
