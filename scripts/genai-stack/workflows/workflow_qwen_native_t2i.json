{
  "_meta": {
    "title": "Qwen Image Edit 2509 - Native Text-to-Image",
    "description": "100% native ComfyUI workflow for Qwen FP8 text-to-image generation - Validated Phase 29",
    "version": "2.1.0",
    "author": "CoursIA GenAI Team",
    "date": "2026-01-20",
    "source": "docs/suivis/genai-image/phase-29-corrections-qwen/SYNTHESE-COMPLETE-PHASE-29.md",
    "models_required": {
      "diffusion_model": "diffusion_models/qwen_image_edit_2509_fp8_e4m3fn.safetensors (20GB)",
      "text_encoder": "text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors (8.8GB)",
      "vae": "vae/qwen_image_vae.safetensors (243MB)"
    },
    "nodes_used": [
      "VAELoader",
      "CLIPLoader",
      "UNETLoader",
      "ModelSamplingAuraFlow",
      "CFGNorm",
      "TextEncodeQwenImageEdit",
      "ConditioningZeroOut",
      "EmptySD3LatentImage",
      "KSampler",
      "VAEDecode",
      "SaveImage"
    ]
  },
  "1": {
    "class_type": "VAELoader",
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "_meta": {"title": "Load VAE (16-channel)"}
  },
  "2": {
    "class_type": "CLIPLoader",
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "sd3"
    },
    "_meta": {"title": "Load CLIP (Qwen 2.5 VL FP8)"}
  },
  "3": {
    "class_type": "UNETLoader",
    "inputs": {
      "unet_name": "qwen_image_edit_2509_fp8_e4m3fn.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "_meta": {"title": "Load Diffusion Model (FP8)"}
  },
  "4": {
    "class_type": "ModelSamplingAuraFlow",
    "inputs": {
      "model": ["3", 0],
      "shift": 3.0
    },
    "_meta": {"title": "Model Sampling AuraFlow (shift=3.0)"}
  },
  "5": {
    "class_type": "CFGNorm",
    "inputs": {
      "model": ["4", 0],
      "strength": 1.0
    },
    "_meta": {"title": "CFG Normalization (strength=1.0)"}
  },
  "6": {
    "class_type": "TextEncodeQwenImageEdit",
    "inputs": {
      "clip": ["2", 0],
      "prompt": "A serene mountain landscape at sunset with a lake reflecting the orange sky",
      "vae": ["1", 0]
    },
    "_meta": {"title": "Qwen Text Encoder (positive)"}
  },
  "7": {
    "class_type": "ConditioningZeroOut",
    "inputs": {
      "conditioning": ["6", 0]
    },
    "_meta": {"title": "Zero Out Conditioning (negative)"}
  },
  "8": {
    "class_type": "EmptySD3LatentImage",
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "_meta": {"title": "Empty Latent (1024x1024, 16 channels)"}
  },
  "9": {
    "class_type": "KSampler",
    "inputs": {
      "model": ["5", 0],
      "positive": ["6", 0],
      "negative": ["7", 0],
      "latent_image": ["8", 0],
      "seed": 42,
      "steps": 20,
      "cfg": 1.0,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 1.0
    },
    "_meta": {"title": "KSampler (euler/beta, CFG=1.0, 20 steps)"}
  },
  "10": {
    "class_type": "VAEDecode",
    "inputs": {
      "samples": ["9", 0],
      "vae": ["1", 0]
    },
    "_meta": {"title": "VAE Decode"}
  },
  "11": {
    "class_type": "SaveImage",
    "inputs": {
      "images": ["10", 0],
      "filename_prefix": "qwen_native_t2i"
    },
    "_meta": {"title": "Save Image"}
  }
}
